{
  "data": [
    {
      "id": "2412.00648",
      "abstract": "Rotating the activation and weight matrices to reduce the influence of outliers in large language models (LLMs) has recently attracted significant attention, particularly in the context of model quantization. Prior studies have shown that in low-precision quantization scenarios, such as 4-bit weights and 4-bit activations (W4A4), randomized Hadamard transforms can achieve significantly higher accuracy than randomized orthogonal transforms. Notably, the reason behind this phenomenon remains unknown. In this paper, we find that these transformations show substantial improvement in eliminating outliers for common tokens and achieve similar quantization error. The primary reason for the accuracy difference lies in the fact that randomized Hadamard transforms can slightly reduce the quantization error for tokens with massive activations while randomized orthogonal transforms increase the quantization error. Due to the extreme rarity of these tokens and their critical impact on model accuracy, we consider this a long-tail optimization problem, and therefore construct a simple yet effective method: a weighted loss function. Additionally, we propose an optimization strategy for the rotation matrix that involves alternating optimization of quantization parameters while employing orthogonal Procrustes transforms to refine the rotation matrix. This makes the distribution of the rotated activation values more conducive to quantization, especially for tokens with massive activations. Our method enhances the Rotated LLMs by achieving dual free, Outlier-Free and Massive Activation-Free, dubbed as DFRot. Extensive experiments demonstrate the effectiveness and efficiency of DFRot. By tuning the rotation matrix using just a single sample, DFRot achieves a perplexity improvement of 0.98 and 0.95 on W4A4KV4 and W4A4KV16, respectively, for LLaMA3-70B, a model known for its quantization challenges.",
      "authors": [
        "Jingyang Xiang",
        "Sai Qian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-01T02:55:08+00:00",
          "link": "https://arxiv.org/abs/2412.00648v1",
          "size": "21182kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T04:14:31+00:00",
          "link": "https://arxiv.org/abs/2412.00648v2",
          "size": "21182kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T03:23:53+00:00",
          "link": "https://arxiv.org/abs/2412.00648v3",
          "size": "17622kb",
          "version": "v3"
        }
      ],
      "title": "DFRot: Achieving Outlier-Free and Massive Activation-Free for Rotated LLMs with Refined Rotation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00648",
        "PDF": "https://arxiv.org/pdf/2412.00648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantization techniques and optimization strategies for large language models, particularly through matrix transformations. It does not discuss LLM training data processing or data engineering."
      },
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/jingyangxiang/dfrot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03701",
      "abstract": "Gradient descent is the primary workhorse for optimizing large-scale problems in machine learning. However, its performance is highly sensitive to the choice of the learning rate. A key limitation of gradient descent is its lack of natural scaling, which often necessitates expensive line searches or heuristic tuning to determine an appropriate step size. In this paper, we address this limitation by incorporating Hessian information to scale the gradient direction. By accounting for the curvature of the function along the gradient, our adaptive, Hessian-aware scaling method ensures a local unit step size guarantee, even in nonconvex settings. Near a local minimum that satisfies the second-order sufficient conditions, our approach achieves linear convergence with a unit step size. We show that our method converges globally under a significantly weaker version of the standard Lipschitz gradient smoothness assumption. Even when Hessian information is inexact, the local unit step size guarantee and global convergence properties remain valid under mild conditions. Finally, we validate our theoretical results empirically on a range of convex and nonconvex machine learning tasks, showcasing the effectiveness of the approach.",
      "authors": [
        "Oscar Smee",
        "Fred Roosta",
        "Stephen J. Wright"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T01:22:23+00:00",
          "link": "https://arxiv.org/abs/2502.03701v1",
          "size": "488kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T03:29:59+00:00",
          "link": "https://arxiv.org/abs/2502.03701v2",
          "size": "2777kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T08:23:39+00:00",
          "link": "https://arxiv.org/abs/2502.03701v3",
          "size": "2777kb",
          "version": "v3"
        }
      ],
      "title": "First-ish Order Methods: Hessian-aware Scalings of Gradient Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03701",
        "HTML": "https://arxiv.org/html/2502.03701v3",
        "PDF": "https://arxiv.org/pdf/2502.03701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving gradient descent methods using Hessian-aware scaling. It does not involve the processing or creation of LLM training data."
      },
      "tasks": [
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12355",
      "abstract": "Drug overdose remains a critical global health issue, often driven by misuse of opioids, painkillers, and psychiatric medications. Traditional research methods face limitations, whereas social media offers real-time insights into self-reported substance use and overdose symptoms. This study proposes an AI-driven NLP framework trained on annotated social media data to detect commonly used drugs and associated overdose symptoms. Using a hybrid annotation strategy with LLMs and human annotators, we applied traditional ML models, neural networks, and advanced transformer-based models. Our framework achieved 98% accuracy in multi-class and 97% in multi-label classification, outperforming baseline models by up to 8%. These findings highlight the potential of AI for supporting public health surveillance and personalized intervention strategies.",
      "authors": [
        "Muhammad Ahmad",
        "Fida Ullah",
        "Ummhy Habiba",
        "ldar Batyrshin and Grigori Sidorov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T02:33:19+00:00",
          "link": "https://arxiv.org/abs/2504.12355v1",
          "size": "939kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:35:20+00:00",
          "link": "https://arxiv.org/abs/2504.12355v2",
          "size": "942kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12355",
        "PDF": "https://arxiv.org/pdf/2504.12355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study utilizes LLMs in a framework for drug detection on social media but details more on model architecture and application rather than focusing intensively on LLM training data processing methods."
      },
      "tasks": [
        "Multi-Label Classification",
        "MUlTI-LABEL-ClASSIFICATION"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05823",
      "abstract": "Domain generalization (DG) and algorithmic fairness are two critical challenges in machine learning. However, most DG methods focus only on minimizing expected risk in the unseen target domain without considering algorithmic fairness. Conversely, fairness methods typically do not account for domain shifts, so the fairness achieved during training may not generalize to unseen test domains. In this work, we bridge these gaps by studying the problem of Fair Domain Generalization (FairDG), which aims to minimize both expected risk and fairness violations in unseen target domains. We derive novel mutual information-based upper bounds for expected risk and fairness violations in multi-class classification tasks with multi-group sensitive attributes. These bounds provide key insights for algorithm design from an information-theoretic perspective. Guided by these insights, we introduce PAFDG (Pareto-Optimal Fairness for Domain Generalization), a practical framework that solves the FairDG problem and models the utility-fairness trade-off through Pareto optimization. Experiments on real-world vision and language datasets show that PAFDG achieves superior utility-fairness trade-offs compared to existing methods.",
      "authors": [
        "Tangzheng Lian",
        "Guanyu Hu",
        "Dimitrios Kollias",
        "Xinyu Yang",
        "and Oya Celiktutan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T09:43:40+00:00",
          "link": "https://arxiv.org/abs/2507.05823v1",
          "size": "736kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T18:47:45+00:00",
          "link": "https://arxiv.org/abs/2507.05823v2",
          "size": "796kb",
          "version": "v2"
        }
      ],
      "title": "Fair Domain Generalization: An Information-Theoretic View",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05823",
        "HTML": "https://arxiv.org/html/2507.05823v2",
        "PDF": "https://arxiv.org/pdf/2507.05823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Fair Domain Generalization and algorithmic fairness in machine learning, but does not address LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08892",
      "abstract": "Generative AI can be used in multi-actor environments with purposes ranging from social science modeling to interactive narrative and AI evaluation. Supporting this diversity of use cases -- which we classify as Simulationist, Dramatist, and Evaluationist -- demands a flexible scenario definition framework. We argue here that a good approach is to take inspiration from tabletop role-playing games (TTRPGs), where a Game Master (GM) is responsible for the environment and generates all parts of the story not directly determined by the voluntary actions of player characters. We argue that the Entity-Component architectural pattern is useful here. In such a system, the GM is not a hardcoded computer game but is itself a configurable entity, composed of components just like any other actor. By design, the approach allows for a separation between the underlying implementation details handled by an engineer, the creation of reusable components, and their composition and configuration managed by a designer who constructs entities from the components. This separation of concerns is instrumental for achieving rapid iteration, maintaining modularity, and ultimately to ensure scalability. We describe the ongoing evolution of the Concordia library in terms of this philosophy, demonstrating how it allows users to effectively configure scenarios that align with their specific goals.",
      "authors": [
        "Alexander Sasha Vezhnevets",
        "Jayd Matyas",
        "Logan Cross",
        "Davide Paglieri",
        "Minsuk Chang",
        "William A. Cunningham",
        "Simon Osindero",
        "William S. Isaac",
        "Joel Z. Leibo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:31:09+00:00",
          "link": "https://arxiv.org/abs/2507.08892v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Actor Generative Artificial Intelligence as a Game Engine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08892",
        "HTML": "https://arxiv.org/html/2507.08892v1",
        "PDF": "https://arxiv.org/pdf/2507.08892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on using generative AI for simulation and narrative purposes, without any significant contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09153",
      "abstract": "Natural disasters often disrupt communication networks and severely hamper emergency response and disaster management. Existing solutions, such as portable communication units and cloud-based network architectures, have improved disaster resilience but fall short if both the Radio Access Network (RAN) and backhaul infrastructure become inoperable. To address these challenges, we propose a demand-driven communication system supported by High Altitude Platform Stations (HAPS) to restore communication in an affected area and enable effective disaster relief. The proposed emergency response network is a promising solution as it provides a rapidly deployable, resilient communications infrastructure. The proposed HAPS-based communication can play a crucial role not only in ensuring connectivity for mobile users but also in restoring backhaul connections when terrestrial networks fail. As a bridge between the disaster management center and the affected areas, it can facilitate the exchange of information in real time, collect data from the affected regions, and relay crucial updates to emergency responders. Enhancing situational awareness, coordination between relief agencies, and ensuring efficient resource allocation can significantly strengthen disaster response capabilities. In this paper, simulations show that HAPS with hybrid optical/THz links boosts backhaul capacity and resilience, even in harsh conditions. HAPS-enabled RAN in S- and Ka-bands ensures reliable communication for first responders and disaster-affected populations. This paper also explores the integration of HAPS into emergency communication frameworks and standards, as it has the potential to improve network resilience and support effective disaster management.",
      "authors": [
        "Bilal Karaman",
        "Ilhan Ba\\c{s}t\\\"urk",
        "Ferdi Kara",
        "Engin Zeydan",
        "Esra Aycan Beyaz{\\i}t",
        "Sezai Ta\\c{s}k{\\i}n",
        "Emil Bj\\\"ornson",
        "Halim Yanikomeroglu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T05:55:56+00:00",
          "link": "https://arxiv.org/abs/2507.09153v1",
          "size": "8228kb",
          "version": "v1"
        }
      ],
      "title": "On-Demand HAPS-Assisted Communication System for Public Safety in Emergency and Disaster Response",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09153",
        "HTML": "https://arxiv.org/html/2507.09153v1",
        "PDF": "https://arxiv.org/pdf/2507.09153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a communication system for disaster management using HAPS. It does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09199",
      "abstract": "Issue-commit linking, which connects issues with commits that fix them, is crucial for software maintenance. Existing approaches have shown promise in automatically recovering these links. Evaluations of these techniques assess their ability to identify genuine links from plausible but false links. However, these evaluations overlook the fact that, in reality, when a repository has more commits, the presence of more plausible yet unrelated commits may interfere with the tool in differentiating the correct fix commits. To address this, we propose the Realistic Distribution Setting (RDS) and use it to construct a more realistic evaluation dataset that includes 20 open-source projects. By evaluating tools on this dataset, we observe that the performance of the state-of-the-art deep learning-based approach drops by more than half, while the traditional Information Retrieval method, VSM, outperforms it.\n  Inspired by these observations, we propose EasyLink, which utilizes a vector database as a modern Information Retrieval technique. To address the long-standing problem of the semantic gap between issues and commits, EasyLink leverages a large language model to rerank the commits retrieved from the database. Under our evaluation, EasyLink achieves an average Precision@1 of 75.91%, improving over the state-of-the-art by over four times. Additionally, this paper provides practical guidelines for advancing research in issue-commit link recovery.",
      "authors": [
        "Huihui Huang",
        "Ratnadira Widyasari",
        "Ting Zhang",
        "Ivana Clairine Irsan",
        "Jieke Shi",
        "Han Wei Ang",
        "Frank Liauw",
        "Eng Lieh Ouh",
        "Lwin Khin Shar",
        "Hong Jin Kang",
        "David Lo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:42:10+00:00",
          "link": "https://arxiv.org/abs/2507.09199v1",
          "size": "4362kb",
          "version": "v1"
        }
      ],
      "title": "Back to the Basics: Rethinking Issue-Commit Linking with LLM-Assisted Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09199",
        "HTML": "https://arxiv.org/html/2507.09199v1",
        "PDF": "https://arxiv.org/pdf/2507.09199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving issue-commit linking using LLMs for reranking but does not address LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09668",
      "abstract": "Pyramid transforms are constructive methods for analyzing sequences in a multiscale fashion. Traditionally, these transforms rely on stationary upsampling and downsampling operations. In this paper, we propose employing nonstationary subdivision schemes as upsampling operators that vary according to the refinement level. These schemes offer greater flexibility, enabling the development of advanced multiscale transforms, including geometric multiscale analysis. We establish the fundamental properties of these nonstationary operators and demonstrate their effectiveness in capturing and analyzing geometric features. In particular, we present applications to highlight their utility in detecting geometric structures in planar objects.",
      "authors": [
        "Hadar Landau",
        "Wael Mattar",
        "Nir Sharon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:03:46+00:00",
          "link": "https://arxiv.org/abs/2507.09668v1",
          "size": "2051kb",
          "version": "v1"
        }
      ],
      "title": "Pyramid transforms via nonstationary subdivision schemes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09668",
        "HTML": "https://arxiv.org/html/2507.09668v1",
        "PDF": "https://arxiv.org/pdf/2507.09668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes new mathematical transforms for geometric analysis and does not involve processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09955",
      "abstract": "DeepSeek, a Chinese Artificial Intelligence (AI) startup, has released their V3 and R1 series models, which attracted global attention due to their low cost, high performance, and open-source advantages. This paper begins by reviewing the evolution of large AI models focusing on paradigm shifts, the mainstream Large Language Model (LLM) paradigm, and the DeepSeek paradigm. Subsequently, the paper highlights novel algorithms introduced by DeepSeek, including Multi-head Latent Attention (MLA), Mixture-of-Experts (MoE), Multi-Token Prediction (MTP), and Group Relative Policy Optimization (GRPO). The paper then explores DeepSeek engineering breakthroughs in LLM scaling, training, inference, and system-level optimization architecture. Moreover, the impact of DeepSeek models on the competitive AI landscape is analyzed, comparing them to mainstream LLMs across various fields. Finally, the paper reflects on the insights gained from DeepSeek innovations and discusses future trends in the technical and engineering development of large AI models, particularly in data, training, and reasoning.",
      "authors": [
        "Luolin Xiong",
        "Haofen Wang",
        "Xi Chen",
        "Lu Sheng",
        "Yun Xiong",
        "Jingping Liu",
        "Yanghua Xiao",
        "Huajun Chen",
        "Qing-Long Han",
        "Yang Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:10:30+00:00",
          "link": "https://arxiv.org/abs/2507.09955v1",
          "size": "2986kb",
          "version": "v1"
        }
      ],
      "title": "DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09955",
        "HTML": "https://arxiv.org/html/2507.09955v1",
        "PDF": "https://arxiv.org/pdf/2507.09955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses model architectures and technical evolutions in large AI models, without focusing on LLM training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10338",
      "abstract": "Assertion-Based Verification (ABV) is critical for ensuring functional correctness in modern hardware systems. However, manually writing high-quality SVAs remains labor-intensive and error-prone. To bridge this gap, we propose AssertCoder, a novel unified framework that automatically generates high-quality SVAs directly from multimodal hardware design specifications. AssertCoder employs a modality-sensitive preprocessing to parse heterogeneous specification formats (text, tables, diagrams, and formulas), followed by a set of dedicated semantic analyzers that extract structured representations aligned with signal-level semantics. These representations are utilized to drive assertion synthesis via multi-step chain-of-thought (CoT) prompting. The framework incorporates a mutation-based evaluation approach to assess assertion quality via model checking and further refine the generated assertions. Experimental evaluation across three real-world Register-Transfer Level (RTL) designs demonstrates AssertCoder's superior performance, achieving an average increase of 8.4% in functional correctness and 5.8% in mutation detection compared to existing state-of-the-art approaches.",
      "authors": [
        "Enyuan Tian",
        "Yiwei Ci",
        "Qiusong Yang",
        "Yufeng Li",
        "Zhichao Lyu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Hardware Architecture (cs.AR)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:43:14+00:00",
          "link": "https://arxiv.org/abs/2507.10338v1",
          "size": "2098kb",
          "version": "v1"
        }
      ],
      "title": "AssertCoder: LLM-Based Assertion Generation via Multimodal Specification Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10338",
        "HTML": "https://arxiv.org/html/2507.10338v1",
        "PDF": "https://arxiv.org/pdf/2507.10338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating assertions for hardware verification, primarily employing LLMs for assertion synthesis rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10426",
      "abstract": "In the paper where he first defined Communication Complexity, Yao asks: \\emph{Is computing $CC(f)$ (the 2-way communication complexity of a given function $f$) NP-complete?} The problem of deciding whether $CC(f) \\le k$, when given the communication matrix for $f$ and a number $k$, is easily seen to be in NP. Kushilevitz and Weinreb have shown that this problem is cryptographically hard. Here we show it is NP-hard.",
      "authors": [
        "Shuichi Hirahara",
        "Rahul Ilango",
        "Bruno Loff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:15:54+00:00",
          "link": "https://arxiv.org/abs/2507.10426v1",
          "size": "70kb",
          "version": "v1"
        }
      ],
      "title": "Communication Complexity is NP-hard",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10426",
        "HTML": "https://arxiv.org/html/2507.10426v1",
        "PDF": "https://arxiv.org/pdf/2507.10426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about the computational complexity of communication complexity and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.12226",
      "abstract": "This paper delves into the widespread implementation of Electronic Medical Records (EMR) within healthcare facilities across Indonesia. It examines the driving forces behind EMR adoption, particularly the role of government regulations, and addresses the challenges encountered by clinic owners and healthcare providers in transitioning to these digital systems. Furthermore, this paper highlights the significant benefits and transformative advantages of EMR systems, such as enhanced decision-making through real-time data access (around 15-20 minutes time saved for patient waiting time and approximately saved 20-25 minutes for all service duration), reduction in healthcare costs over time due to improved resource management, and increased patient satisfaction by providing faster and more personalized care. EMR systems also ensure higher levels of data security and privacy, adhering to national healthcare standards, while supporting continuous monitoring and updates that enhance system resilience and functionality. The findings are substantiated through case studies, such as case study at LAPAS II Purwokerto Clinic and case study at PMI Purbalingga Clinic and user testimonials from clinics that have successfully implemented EMR solutions in compliance with the standards established by the Ministry of Communication and Informatics (Kominfo) and the Ministry of Health (Kemenkes).",
      "authors": [
        "Rasyid Juliansyah",
        "Bukhori Muhammad Aqid",
        "Andien Putri Salsabila",
        "Kurnia Nurfiyanti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T04:42:56+00:00",
          "link": "https://arxiv.org/abs/2410.12226v1",
          "size": "405kb",
          "version": "v1"
        }
      ],
      "title": "Implementation of EMR System in Indonesian Health Facilities: Benefits and Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12226",
        "PDF": "https://arxiv.org/pdf/2410.12226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the implementation of EMR systems and their benefits in healthcare, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.17114",
      "abstract": "Given a circuit $C : \\{0,1\\}^n \\to \\{0,1\\}^m$ from a circuit class $F$, with $m > n$, finding a $y \\in \\{0,1\\}^m$ such that $\\forall x \\in \\{0,1\\}^n$, $C(x) \\ne y$, is the range avoidance problem (denoted by $F$-$avoid$). Deterministic polynomial time algorithms (even with access to $NP$ oracles) solving this problem is known to imply explicit constructions of various pseudorandom objects like hard Boolean functions, linear codes, PRGs etc. Deterministic polynomial time algorithms are known for $NC^0_2$-$avoid$ when $m > n$, and for $NC^0_3$-$avoid$ when $m \\ge \\frac{n^2}{\\log n}$, where $NC^0_k$ is the class of circuits with bounded fan-in which have constant depth and the output depends on at most $k$ of the input bits. On the other hand, it is also known that $NC^0_3$-$avoid$ when $m = n+O\\left(n^{2/3}\\right)$ is at least as hard as explicit construction of rigid matrices.\n  In this paper, we propose a new approach to solving range avoidance problem via hypergraphs. We formulate the problem in terms of Turan-type problems in hypergraphs of the following kind - for a fixed $k$-uniform hypergraph $H'$, what is the maximum number of edges that can exist in a $k$-uniform hypergraph $H$ which does not have a sub-hypergraph isomorphic to $H'$? We use our approach to show (using known Turan-type bounds) that there is a constant $c$ such that $mon$-$NC^0_3$-$avoid$ can be solved in deterministic polynomial time when $m > cn^2$. To improve the stretch constraint to linear, we show a new Turan-type theorem for a hypergraph structure (which we call the the loose $chi$-cycles) and use it to show that $mon$-$NC^0_3$-$avoid$ can be solved in deterministic polynomial time when $m > n$, thus improving the known bounds of $NC^0_3$-avoid for the case of monotone circuits.",
      "authors": [
        "Neha Kuntewar and Jayalal Sarma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T12:58:38+00:00",
          "link": "https://arxiv.org/abs/2503.17114v1",
          "size": "34kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T18:46:49+00:00",
          "link": "https://arxiv.org/abs/2503.17114v2",
          "size": "33kb",
          "version": "v2"
        }
      ],
      "title": "Range Avoidance in Boolean Circuits via Turan-type Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17114",
        "HTML": "https://arxiv.org/html/2503.17114v2",
        "PDF": "https://arxiv.org/pdf/2503.17114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a theoretical approach to solving a range avoidance problem using hypergraphs. It is focused on computational complexity and circuit analysis without targeting LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03924",
      "abstract": "Recent methods have shown that pre-trained diffusion models can be fine-tuned to enable generative inverse rendering by learning image-conditioned noise-to-intrinsic mapping. Despite their remarkable progress, they struggle to robustly produce high-quality results as the noise-to-intrinsic paradigm essentially utilizes noisy images with deteriorated structure and appearance for intrinsic prediction, while it is common knowledge that structure and appearance information in an image are crucial for inverse rendering. To address this issue, we present DNF-Intrinsic, a robust yet efficient inverse rendering approach fine-tuned from a pre-trained diffusion model, where we propose to take the source image rather than Gaussian noise as input to directly predict deterministic intrinsic properties via flow matching. Moreover, we design a generative renderer to constrain that the predicted intrinsic properties are physically faithful to the source image. Experiments on both synthetic and real-world datasets show that our method clearly outperforms existing state-of-the-art methods.",
      "authors": [
        "Rongjia Zheng",
        "Qing Zhang",
        "Chengjiang Long",
        "Wei-Shi Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T07:11:58+00:00",
          "link": "https://arxiv.org/abs/2507.03924v1",
          "size": "41207kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:11:47+00:00",
          "link": "https://arxiv.org/abs/2507.03924v2",
          "size": "41207kb",
          "version": "v2"
        }
      ],
      "title": "DNF-Intrinsic: Deterministic Noise-Free Diffusion for Indoor Inverse Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03924",
        "HTML": "https://arxiv.org/html/2507.03924v2",
        "PDF": "https://arxiv.org/pdf/2507.03924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning a pre-trained diffusion model for inverse rendering, which may involve some data preparation steps, but its main focus is not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09089",
      "abstract": "Despite widespread adoption, the impact of AI tools on software development in the wild remains understudied. We conduct a randomized controlled trial (RCT) to understand how AI tools at the February-June 2025 frontier affect the productivity of experienced open-source developers. 16 developers with moderate AI experience complete 246 tasks in mature projects on which they have an average of 5 years of prior experience. Each task is randomly assigned to allow or disallow usage of early 2025 AI tools. When AI tools are allowed, developers primarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet. Before starting tasks, developers forecast that allowing AI will reduce completion time by 24%. After completing the study, developers estimate that allowing AI reduced completion time by 20%. Surprisingly, we find that allowing AI actually increases completion time by 19%--AI tooling slowed developers down. This slowdown also contradicts predictions from experts in economics (39% shorter) and ML (38% shorter). To understand this result, we collect and evaluate evidence for 20 properties of our setting that a priori could contribute to the observed slowdown effect--for example, the size and quality standards of projects, or prior developer experience with AI tooling. Although the influence of experimental artifacts cannot be entirely ruled out, the robustness of the slowdown effect across our analyses suggests it is unlikely to primarily be a function of our experimental design.",
      "authors": [
        "Joel Becker",
        "Nate Rush",
        "Elizabeth Barnes",
        "David Rein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:16:33+00:00",
          "link": "https://arxiv.org/abs/2507.09089v1",
          "size": "15205kb",
          "version": "v1"
        }
      ],
      "title": "Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09089",
        "PDF": "https://arxiv.org/pdf/2507.09089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores the impact of AI tools on software developer productivity and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09826",
      "abstract": "Neural networks have achieved remarkable success in time series classification, but their reliance on large amounts of labeled data for training limits their applicability in cold-start scenarios. Moreover, they lack interpretability, reducing transparency in decision-making. In contrast, dynamic time warping (DTW) combined with a nearest neighbor classifier is widely used for its effectiveness in limited-data settings and its inherent interpretability. However, as a non-parametric method, it is not trainable and cannot leverage large amounts of labeled data, making it less effective than neural networks in rich-resource scenarios. In this work, we aim to develop a versatile model that adapts to cold-start conditions and becomes trainable with labeled data, while maintaining interpretability. We propose a dynamic length-shortening algorithm that transforms time series into prototypes while preserving key structural patterns, thereby enabling the reformulation of the DTW recurrence relation into an equivalent recurrent neural network. Based on this, we construct a trainable model that mimics DTW's alignment behavior. As a neural network, it becomes trainable when sufficient labeled data is available, while still retaining DTW's inherent interpretability. We apply the model to several benchmark time series classification tasks and observe that it significantly outperforms previous approaches in low-resource settings and remains competitive in rich-resource settings.",
      "authors": [
        "Jintao Qu",
        "Zichong Wang",
        "Chenhao Wu",
        "Wenbin Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:15:21+00:00",
          "link": "https://arxiv.org/abs/2507.09826v1",
          "size": "401kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Neural Networks and Dynamic Time Warping for Adaptive Time Series Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09826",
        "PDF": "https://arxiv.org/pdf/2507.09826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving time series classification through a dynamic length-shortening algorithm and a trainable model mimicking DTW's alignment behavior. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09990",
      "abstract": "Large language models (LLMs) typically require fine-tuning for domain-specific tasks, and LoRA offers a computationally efficient approach by training low-rank adapters. LoRA is also communication-efficient for federated LLMs when multiple users collaboratively fine-tune a global LLM model without sharing their proprietary raw data. However, even the transmission of local adapters between a server and clients risks serious privacy leakage. Applying differential privacy (DP) to federated LoRA encounters a dilemma: adding noise to both adapters amplifies synthetic noise on the model, while fixing one adapter impairs the learnability of fine-tuning. In this paper, we propose FedASK (Differentially Private Federated Low Rank Adaptation with Double Sketching) , a novel federated LoRA framework to enable effective updating of both low-rank adapters with robust differential privacy. Inspired by randomized SVD, our key idea is a two-stage sketching pipeline. This pipeline first aggregates carefully sketched, privacy-preserving local updates, and then reconstructs the global matrices on the server to facilitate effective updating of both adapters. We theoretically prove FedASK's differential privacy guarantee and its exact aggregation property. Comprehensive experiments demonstrate that FedASK consistently outperforms baseline methods across a variety of privacy settings and data distributions.",
      "authors": [
        "Ming Wen",
        "Jiaqi Zhu",
        "Yuedong Xu",
        "Yipeng Zhou",
        "Dingding Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:17:24+00:00",
          "link": "https://arxiv.org/abs/2507.09990v1",
          "size": "1479kb",
          "version": "v1"
        }
      ],
      "title": "Differentially Private Federated Low Rank Adaptation Beyond Fixed-Matrix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09990",
        "HTML": "https://arxiv.org/html/2507.09990v1",
        "PDF": "https://arxiv.org/pdf/2507.09990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses federated LLM training with differential privacy, involving data privacy during adaptation; however, it does not focus on LLM training data processing methods or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10149",
      "abstract": "We propose a mathematically rigorous framework for identifying and completing Coincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators. Unlike existing auction based systems such as CoWSwap, our approach introduces an asset matrix formulation that not only verifies feasibility using oracle prices and formal conservation laws but also completes partial CoW cycles of swap orders that are discovered using graph traversal and are settled using imbalance correction. We define bridging orders and show that the resulting execution is slippage free and capital preserving for LPs. Applied to real world Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW cycles and supports the insertion of synthetic orders for atomic cycle closure. This work can be thought of as the detailing of a potential delta-neutral strategy by liquidity providing market makers: a structured CoW cycle execution.",
      "authors": [
        "Abhimanyu Nag",
        "Madhur Prabhakar",
        "Tanuj Behl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Trading and Market Microstructure (q-fin.TR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:53:25+00:00",
          "link": "https://arxiv.org/abs/2507.10149v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10149",
        "HTML": "https://arxiv.org/html/2507.10149v1",
        "PDF": "https://arxiv.org/pdf/2507.10149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a mechanism for swap trade execution in decentralized exchanges, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.15585",
      "abstract": "Classical manipulator motion planners work across different robot embodiments. However they plan on a pre-specified static environment representation, and are not scalable to unseen dynamic environments. Neural Motion Planners (NMPs) are an appealing alternative to conventional planners as they incorporate different environmental constraints to learn motion policies directly from raw sensor observations. Contemporary state-of-the-art NMPs can successfully plan across different environments. However none of the existing NMPs generalize across robot embodiments. In this paper we propose Cross-Embodiment Motion Policy (XMoP), a neural policy for learning to plan over a distribution of manipulators. XMoP implicitly learns to satisfy kinematic constraints for a distribution of robots and $\\textit{zero-shot}$ transfers the planning behavior to unseen robotic manipulators within this distribution. We achieve this generalization by formulating a whole-body control policy that is trained on planning demonstrations from over three million procedurally sampled robotic manipulators in different simulated environments. Despite being completely trained on synthetic embodiments and environments, our policy exhibits strong sim-to-real generalization across manipulators with different kinematic variations and degrees of freedom with a single set of frozen policy parameters. We evaluate XMoP on $7$ commercial manipulators and show successful cross-embodiment motion planning, achieving an average $70\\%$ success rate on baseline benchmarks. Furthermore, we demonstrate our policy sim-to-real on two unseen manipulators solving novel planning problems across three real-world domains even with dynamic obstacles.",
      "authors": [
        "Prabin Kumar Rath",
        "Nakul Gopalan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T22:35:17+00:00",
          "link": "https://arxiv.org/abs/2409.15585v1",
          "size": "16685kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T05:32:03+00:00",
          "link": "https://arxiv.org/abs/2409.15585v2",
          "size": "16633kb",
          "version": "v2"
        }
      ],
      "title": "XMoP: Whole-Body Control Policy for Zero-shot Cross-Embodiment Neural Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15585",
        "HTML": "https://arxiv.org/html/2409.15585v2",
        "PDF": "https://arxiv.org/pdf/2409.15585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural motion planning across different robotic embodiments, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.07426",
      "abstract": "Reliable machine learning and statistical analysis rely on diverse, well-distributed training data. However, real-world datasets are often limited in size and exhibit underrepresentation across key subpopulations, leading to biased predictions and reduced performance, particularly in supervised tasks such as classification. To address these challenges, we propose Conditional Data Synthesis Augmentation (CoDSA), a novel framework that leverages generative models, such as diffusion models, to synthesize high-fidelity data for improving model performance across multimodal domains including tabular, textual, and image data. CoDSA generates synthetic samples that faithfully capture the conditional distributions of the original data, with a focus on under-sampled or high-interest regions. Through transfer learning, CoDSA fine-tunes pre-trained generative models to enhance the realism of synthetic data and increase sample density in sparse areas. This process preserves inter-modal relationships, mitigates data imbalance, improves domain adaptation, and boosts generalization. We also introduce a theoretical framework that quantifies the statistical accuracy improvements enabled by CoDSA as a function of synthetic sample volume and targeted region allocation, providing formal guarantees of its effectiveness. Extensive experiments demonstrate that CoDSA consistently outperforms non-adaptive augmentation strategies and state-of-the-art baselines in both supervised and unsupervised settings.",
      "authors": [
        "Xinyu Tian and Xiaotong Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T03:38:11+00:00",
          "link": "https://arxiv.org/abs/2504.07426v1",
          "size": "3651kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T23:40:51+00:00",
          "link": "https://arxiv.org/abs/2504.07426v2",
          "size": "2455kb",
          "version": "v2"
        }
      ],
      "title": "Conditional Data Synthesis Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07426",
        "HTML": "https://arxiv.org/html/2504.07426v2",
        "PDF": "https://arxiv.org/pdf/2504.07426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces Conditional Data Synthesis Augmentation (CoDSA), a framework for generating synthetic data to enhance model performance, which involves data synthesis and processing to improve dataset quality, relevant to LLM training data."
      },
      "tasks": [
        "Domain Adaptation",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09005",
      "abstract": "We introduce a novel framework that integrates Neural Radiance Fields (NeRF) with Material Point Method (MPM) simulation to infer granular material properties from visual observations. Our approach begins by generating synthetic experimental data, simulating an plow interacting with sand. The experiment is rendered into realistic images as the photographic observations. These observations include multi-view images of the experiment's initial state and time-sequenced images from two fixed cameras. Using NeRF, we reconstruct the 3D geometry from the initial multi-view images, leveraging its capability to synthesize novel viewpoints and capture intricate surface details. The reconstructed geometry is then used to initialize material point positions for the MPM simulation, where the friction angle remains unknown. We render images of the simulation under the same camera setup and compare them to the observed images. By employing Bayesian optimization, we minimize the image loss to estimate the best-fitting friction angle. Our results demonstrate that friction angle can be estimated with an error within 2 degrees, highlighting the effectiveness of inverse analysis through purely visual observations. This approach offers a promising solution for characterizing granular materials in real-world scenarios where direct measurement is impractical or impossible.",
      "authors": [
        "Cheng-Hsi Hsiao",
        "Krishna Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:15:59+00:00",
          "link": "https://arxiv.org/abs/2507.09005v1",
          "size": "6696kb",
          "version": "v1"
        }
      ],
      "title": "From images to properties: a NeRF-driven framework for granular material parameter inversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09005",
        "HTML": "https://arxiv.org/html/2507.09005v1",
        "PDF": "https://arxiv.org/pdf/2507.09005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel framework for inferring material properties using NeRF and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10047",
      "abstract": "This research introduces MP-RBFN, a novel formulation leveraging Radial Basis Function Networks for efficiently learning Motion Primitives derived from optimal control problems for autonomous driving. While traditional motion planning approaches based on optimization are highly accurate, they are often computationally prohibitive. In contrast, sampling-based methods demonstrate high performance but impose constraints on the geometric shape of trajectories. MP-RBFN combines the strengths of both by coupling the high-fidelity trajectory generation of sampling-based methods with an accurate description of vehicle dynamics. Empirical results show compelling performance compared to previous methods, achieving a precise description of motion primitives at low inference times. MP-RBFN yields a seven times higher accuracy in generating optimized motion primitives compared to existing semi-analytic approaches. We demonstrate the practical applicability of MP-RBFN for motion planning by integrating the method into a sampling-based trajectory planner. MP-RBFN is available as open-source software at https://github.com/TUM-AVS/RBFN-Motion-Primitives.",
      "authors": [
        "Marc Kaufeld",
        "Mattia Piccinini",
        "Johannes Betz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:26:41+00:00",
          "link": "https://arxiv.org/abs/2507.10047v1",
          "size": "1846kb",
          "version": "v1"
        }
      ],
      "title": "MP-RBFN: Learning-based Vehicle Motion Primitives using Radial Basis Function Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10047",
        "HTML": "https://arxiv.org/html/2507.10047v1",
        "PDF": "https://arxiv.org/pdf/2507.10047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for vehicle motion planning using Radial Basis Function Networks, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02072",
      "abstract": "Monocular Depth and Surface Normals Estimation (MDSNE) is crucial for tasks such as 3D reconstruction, autonomous navigation, and underwater exploration. Current methods rely either on discriminative models, which struggle with transparent or reflective surfaces, or generative models, which, while accurate, are computationally expensive. This paper presents a novel deep learning model for MDSNE, specifically tailored for underwater environments, using a hybrid architecture that integrates Convolutional Neural Networks (CNNs) with Transformers, leveraging the strengths of both approaches. Training effective MDSNE models is often hampered by noisy real-world datasets and the limited generalization of synthetic datasets. To address this, we generate pseudo-labeled real data using multiple pre-trained MDSNE models. To ensure the quality of this data, we propose the Depth Normal Evaluation and Selection Algorithm (DNESA), which evaluates and selects the most reliable pseudo-labeled samples using domain-specific metrics. A lightweight student model is then trained on this curated dataset. Our model reduces parameters by 90% and training costs by 80%, allowing real-time 3D perception on resource-constrained devices. Key contributions include: a novel and efficient MDSNE model, the DNESA algorithm, a domain-specific data pipeline, and a focus on real-time performance and scalability. Designed for real-world underwater applications, our model facilitates low-cost deployments in underwater robots and autonomous vehicles, bridging the gap between research and practical implementation.",
      "authors": [
        "Alzayat Saleh",
        "Melanie Olsen",
        "Bouchra Senadji and Mostafa Rahimi Azghadi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T22:41:12+00:00",
          "link": "https://arxiv.org/abs/2410.02072v1",
          "size": "18771kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T01:18:17+00:00",
          "link": "https://arxiv.org/abs/2410.02072v2",
          "size": "18371kb",
          "version": "v2"
        }
      ],
      "title": "A Practical Approach to Underwater Depth and Surface Normals Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02072",
        "HTML": "https://arxiv.org/html/2410.02072v2",
        "PDF": "https://arxiv.org/pdf/2410.02072"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a new dataset using pseudo-labeled real data for training an underwater depth and surface normals estimation model. It includes detailed data processing steps like the DNESA algorithm for data evaluation and selection."
      },
      "tasks": [
        "3D Reconstruction",
        "Autonomous Navigation",
        "Autonomous Vehicles",
        "Surface Normals Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.15260",
      "abstract": "Most research on within-day dynamic traffic equilibrium with information provision implicitly considers travel time information, often assuming information to be perfect or imperfect based on travelers' perception error. However, lacking explicit formulation of information limits insightful analysis of information impact on dynamic traffic equilibrium and the potential benefits of leveraging information provision to improve system-level performance. To address this gap, this paper proposes a within-day dynamic traffic equilibrium model that explicitly formulates strategic information provision as an endogenous element. In the proposed framework, two classes of travelers receive different types of travel time information: one class receives instantaneous travel time reflecting the prevailing traffic conditions, while the other class receives strategic forecasts of travel times, generated by accounting for travelers' reactions to instantaneous information based on strategic thinking from behavioral game theory. The resulting multi-class within-day dynamic equilibrium differs from existing models by explicitly modeling information provision and consideration of information consistency. The inherent dynamics of real-time updated traffic information, traffic conditions, and travelers' choice behaviors are analytically modeled, with the resulting dynamic equilibrium formulated as a fixed-point problem. The theoretical propositions and numerical findings offer rich insights into the impact of information on the traffic network, strategic forecast information penetration, the relationship between the proposed equilibrium and traditional dynamic traffic equilibria, and information accuracy. This research contributes to a deeper understanding of the interplay between information and traffic dynamics, paving the way for more effective traffic management strategies.",
      "authors": [
        "Xiaoyu Ma and Xiaozheng He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-20T03:01:38+00:00",
          "link": "https://arxiv.org/abs/2410.15260v1",
          "size": "3946kb",
          "version": "v1"
        }
      ],
      "title": "Multi-class within-day dynamic traffic equilibrium with strategic travel time information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15260",
        "PDF": "https://arxiv.org/pdf/2410.15260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a model for dynamic traffic equilibrium with strategic travel time information. It does not focus on LLM training data processing, collection, or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.01973",
      "abstract": "Financial Large Language Models (FinLLMs), such as open FinGPT and proprietary BloombergGPT, have demonstrated great potential in select areas of financial services. Beyond this earlier language-centric approach, Multimodal Financial Foundation Models (MFFMs) can digest interleaved multimodal financial data, including fundamental data, market data, data analytics, macroeconomic, and alternative data (e.g., natural language, audio, images, and video). In this position paper, presented at the MFFM Workshop joined with ACM International Conference on AI in Finance (ICAIF) 2024, we describe the progress, prospects, and challenges of MFFMs. This paper also highlights ongoing research on FinAgents in the \\textbf{SecureFinAI Lab}\\footnote{\\https://openfin.engineering.columbia.edu/} at Columbia University. We believe that MFFMs will enable a deeper understanding of the underlying complexity associated with numerous financial tasks and data, streamlining the operation of financial services and investment processes. Github Repo https://github.com/Open-Finance-Lab/Awesome-MFFMs/.",
      "authors": [
        "Xiao-Yang Liu Yanglet and Yupeng Cao and Li Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T10:08:34+00:00",
          "link": "https://arxiv.org/abs/2506.01973v1",
          "size": "5991kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:52:48+00:00",
          "link": "https://arxiv.org/abs/2506.01973v2",
          "size": "4610kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Financial Foundation Models (MFFMs): Progress, Prospects, and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01973",
        "HTML": "https://arxiv.org/html/2506.01973v2",
        "PDF": "https://arxiv.org/pdf/2506.01973"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a position paper on multimodal financial models, discussing progress and challenges, without a focus on LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/open-finance-lab/awesome-mffms"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09414",
      "abstract": "Automated test generation for game-like programs presents unique challenges due to their non-deterministic behavior and complex control structures. The NEATEST framework has been used for automated testing in Scratch games, employing neuroevolution-based test generation optimized for statement coverage. However, statement coverage alone is often insufficient for fault detection, as it does not guarantee execution of all logical branches. This paper introduces a branch coverage-based fitness function to enhance test effectiveness in automated game testing. We extend NEATEST by integrating a branch fitness function that prioritizes control-dependent branches, guiding the neuroevolution process to maximize branch exploration. To evaluate the effectiveness of this approach, empirical experiments were conducted on 25 Scratch games, comparing Neatest with Statement Coverage (NSC) against Neatest with Branch Coverage (NBC). A mutation analysis was also performed to assess the fault detection capabilities of both techniques. The results demonstrate that NBC achieves higher branch coverage than NSC in 13 out of 25 games, particularly in programs with complex conditional structures. Moreover, NBC achieves a lower false positive rate in mutation testing, making it a more reliable approach for identifying faulty behavior in game programs. These findings confirm that branch coverage-based test generation improves test coverage and fault detection in Scratch programs.",
      "authors": [
        "Khizra Sohail",
        "Atif Aftab Ahmed Jilani",
        "and Nigar Azhar Butt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T22:36:47+00:00",
          "link": "https://arxiv.org/abs/2507.09414v1",
          "size": "1632kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing NeuroEvolution-Based Game Testing: A Branch Coverage Approach for Scratch Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09414",
        "HTML": "https://arxiv.org/html/2507.09414v1",
        "PDF": "https://arxiv.org/pdf/2507.09414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with test generation in game testing, which is unrelated to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09629",
      "abstract": "While Knowledge Editing (KE) has been widely explored in English, its behavior in morphologically rich languages like Arabic remains underexamined. In this work, we present the first study of Arabic KE. We evaluate four methods (ROME, MEMIT, ICE, and LTE) on Arabic translations of the ZsRE and Counterfact benchmarks, analyzing both multilingual and cross-lingual settings. Our experiments on Llama-2-7B-chat show show that parameter-based methods struggle with cross-lingual generalization, while instruction-tuned methods perform more robustly. We extend Learning-To-Edit (LTE) to a multilingual setting and show that joint Arabic-English training improves both editability and transfer. We release Arabic KE benchmarks and multilingual training for LTE data to support future research.",
      "authors": [
        "Basel Mousi",
        "Nadir Durrani",
        "Fahim Dalvi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T13:49:52+00:00",
          "link": "https://arxiv.org/abs/2507.09629v1",
          "size": "4753kb",
          "version": "v1"
        }
      ],
      "title": "An Exploration of Knowledge Editing for Arabic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09629",
        "HTML": "https://arxiv.org/html/2507.09629v1",
        "PDF": "https://arxiv.org/pdf/2507.09629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores knowledge editing in the Arabic language, focusing on evaluation methods and benchmarks rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09637",
      "abstract": "Code review is a well-established and valued practice in the software engineering community contributing to both code quality and interpersonal benefits. However, there are challenges in both tools and processes that give rise to misalignments and frustrations. Recent research seeks to address this by automating code review entirely, but we believe that this risks losing the majority of the interpersonal benefits such as knowledge transfer and shared ownership.\n  We believe that by better understanding the cognitive processes involved in code review, it would be possible to improve tool support, with out without AI, and make code review both more efficient, more enjoyable, while increasing or maintaining all of its benefits. In this paper, we conduct an ethnographic think-aloud study involving 10 participants and 34 code reviews. We build a cognitive model of code review bottom up through thematic, statistical, temporal, and sequential analysis of the transcribed material. Through the data, the similarities between the cognitive process in code review and decision-making processes, especially recognition-primed decision-making, become apparent.\n  The result is the Code Review as Decision-Making (CRDM) model that shows how the developers move through two phases during the code review; first an orientation phase to establish context and rationale and then an analytical phase to understand, assess, and plan the rest of the review. Throughout the process several decisions must be taken, on writing comments, finding more information, voting, running the code locally, verifying continuous integration results, etc.\n  Analysis software and process-coded data publicly available at: https://doi.org/10.5281/zenodo.15758266",
      "authors": [
        "Lo Gullstrand Heander",
        "and Emma S\\\"oderberg",
        "and Christofer Rydenf\\\"alt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:04:16+00:00",
          "link": "https://arxiv.org/abs/2507.09637v1",
          "size": "1885kb",
          "version": "v1"
        }
      ],
      "title": "Code Review as Decision-Making -- Building a Cognitive Model from the Questions Asked During Code Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09637",
        "HTML": "https://arxiv.org/html/2507.09637v1",
        "PDF": "https://arxiv.org/pdf/2507.09637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses code review practices, and cognitive models but does not focus on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10194",
      "abstract": "How can we learn a representation with high predictive power while preserving user privacy? We present an adversarial representation learning method for sanitizing sensitive content from the learned representation. Specifically, we introduce a variant of entropy - focal entropy, which mitigates the potential information leakage of the existing entropy-based approaches. We showcase feasibility on multiple benchmarks. The results suggest high target utility at moderate privacy leakage.",
      "authors": [
        "Tassilo Klein and Moin Nabi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:01:08+00:00",
          "link": "https://arxiv.org/abs/2507.10194v1",
          "size": "16422kb",
          "version": "v1"
        }
      ],
      "title": "Learning Private Representations through Entropy-based Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10194",
        "HTML": "https://arxiv.org/html/2507.10194v1",
        "PDF": "https://arxiv.org/pdf/2507.10194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial representation learning and privacy preservation, but does not discuss any aspects of processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10413",
      "abstract": "The consensus problem, briefly stated, consists of having processes in an asynchronous distributed system agree on a value. It is widely known that the consensus problem does not have a deterministic solution that ensures both termination and consistency, if there is at least one faulty process in the system. This result, known as the FLP impossibility theorem, led to several generalizations and developments in theoretical distributed computing. This paper argues that the FLP impossibility theorem holds even under a generalized definition of computation through oracles. Furthermore, using a theoretical machinery from complex systems, this paper also posits that inconsistency may be an emergent feature of consensus over distributed systems by examining how a system transitions phases. Under the same complex systems framework, this paper examines paraconsistent logics, arguing that while inconsistency is not an emergent feature for these logics, triviality may be. Lastly, some attention is given to the possibility of developing consensus algorithms capable of paraconsistent reasoning.",
      "authors": [
        "Gabriel Rocha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computational Complexity (cs.CC)",
        "Information Theory (cs.IT)",
        "Logic in Computer Science (cs.LO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:55:14+00:00",
          "link": "https://arxiv.org/abs/2507.10413v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Consensus, Inconsistency, Emergence: what's paraconsistency got to do with it?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10413",
        "HTML": "https://arxiv.org/html/2507.10413v1",
        "PDF": "https://arxiv.org/pdf/2507.10413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on theoretical distributed computing problems related to consensus, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.14211",
      "abstract": "App reviews reflect various user requirements that can aid in planning maintenance tasks. Recently, proposed approaches for automatically classifying user reviews rely on machine learning algorithms. A previous study demonstrated that models trained on existing labeled datasets exhibit poor performance when predicting new ones. Therefore, a comprehensive labeled dataset is essential to train a more precise model. In this paper, we propose a novel approach that assists in augmenting labeled datasets by utilizing information extracted from an additional source, GitHub issues, that contains valuable information about user requirements. First, we identify issues concerning review intentions (bug reports, feature requests, and others) by examining the issue labels. Then, we analyze issue bodies and define 19 language patterns for extracting targeted information. Finally, we augment the manually labeled review dataset with a subset of processed issues through the Within-App, Within-Context, and Between-App Analysis methods. We conducted several experiments to evaluate the proposed approach. Our results demonstrate that using labeled issues for data augmentation can improve the F1-score to 6.3 in bug reports and 7.2 in feature requests. Furthermore, we identify an effective range of 0.3 to 0.7 for the auxiliary volume, which provides better performance improvements.",
      "authors": [
        "Yasaman Abedini and Abbas Heydarnoori"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-27T22:01:24+00:00",
          "link": "https://arxiv.org/abs/2308.14211v1",
          "size": "1595kb",
          "version": "v1"
        },
        {
          "date": "2024-07-03T08:54:04+00:00",
          "link": "https://arxiv.org/abs/2308.14211v2",
          "size": "2099kb",
          "version": "v2"
        },
        {
          "date": "2024-07-24T04:04:26+00:00",
          "link": "https://arxiv.org/abs/2308.14211v3",
          "size": "2005kb",
          "version": "v3"
        }
      ],
      "title": "Can GitHub Issues Help in App Review Classifications?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.14211",
        "HTML": "https://arxiv.org/html/2308.14211",
        "PDF": "https://arxiv.org/pdf/2308.14211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel approach to augment labeled datasets by using information from GitHub issues, involving detailed data processing steps to enhance data quality, which is a core aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.06989",
      "abstract": "This paper presents the first large-scale empirical study of commercial personally identifiable information (PII) removal systems -- commercial services that claim to improve privacy by automating the removal of PII from data broker's databases. Popular examples of such services include DeleteMe, Mozilla Monitor, Incogni, among many others. The claims these services make may be very appealing to privacy-conscious Web users, but how effective these services actually are at improving privacy has not been investigated. This work aims to improve our understanding of commercial PII removal services in multiple ways. First, we conduct a user study where participants purchase subscriptions from four popular PII removal services, and report (i) what PII the service find, (ii) from which data brokers, (iii) whether the service is able to have the information removed, and (iv) whether the identified information actually is PII describing the participant. And second, by comparing the claims and promises the services makes (e.g. which and how many data brokers each service claims to cover). We find that these services have significant accuracy and coverage issues that limit the usefulness of these services as a privacy-enhancing technology. For example, we find that the measured services are unable to remove the majority of the identified PII records from data broker's (48.2% of the successfully removed found records) and that most records identified by these services are not PII about the user (study participants found that only 41.1% of records identified by these services were PII about themselves).",
      "authors": [
        "Jiahui He",
        "Pete Snyder",
        "Hamed Haddadi",
        "Fabi\\'an E. Bustamante and Gareth Tyson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-11T14:32:27+00:00",
          "link": "https://arxiv.org/abs/2505.06989v1",
          "size": "393kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T08:39:26+00:00",
          "link": "https://arxiv.org/abs/2505.06989v2",
          "size": "434kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T12:32:51+00:00",
          "link": "https://arxiv.org/abs/2505.06989v3",
          "size": "363kb",
          "version": "v3"
        }
      ],
      "title": "Measuring the Accuracy and Effectiveness of PII Removal Services",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06989",
        "HTML": "https://arxiv.org/html/2505.06989v3",
        "PDF": "https://arxiv.org/pdf/2505.06989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes the effectiveness of commercial PII removal services. It does not involve processing of LLM training data, creation of datasets, or enhancement of data quality specific to language model training."
      },
      "repo_urls": [
        "https://github.com/HHHeJiahui/Data-Broker-Extractor"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09425",
      "abstract": "Cell-free massive multiple-input multiple-output (MIMO)-aided integrated sensing and communication (ISAC) systems are investigated where distributed access points jointly serve users and sensing targets. We demonstrate that only a subset of access points (APs) has to be activated for both tasks, while deactivating redundant APs is essential for power savings. This motivates joint active AP selection and power control for optimizing energy efficiency. The resultant problem is a mixed-integer nonlinear program (MINLP). To address this, we propose a model-based Branch-and-Bound approach as a strong baseline to guide a semi-supervised heterogeneous graph neural network (HetGNN) for selecting the best active APs and the power allocation. Comprehensive numerical results demonstrate that the proposed HetGNN reduces power consumption by 20-25\\% and runs nearly 10,000 times faster than model-based benchmarks.",
      "authors": [
        "Nguyen Xuan Tung and Le Tung Giang and Trinh Van Chien and Hoang Trong Minh and Lajos Hanzo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:30:18+00:00",
          "link": "https://arxiv.org/abs/2507.09425v1",
          "size": "227kb",
          "version": "v1"
        }
      ],
      "title": "Joint Access Point Activation and Power Allocation for Cell-Free Massive MIMO Aided ISAC Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09425",
        "HTML": "https://arxiv.org/html/2507.09425v1",
        "PDF": "https://arxiv.org/pdf/2507.09425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with power allocation and access point activation in network systems, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10115",
      "abstract": "We propose a multi-camera multi-target (MCMT) tracking framework that ensures consistent global identity assignment across views using trajectory and appearance cues. The pipeline starts with BoT-SORT-based single-camera tracking, followed by an initial glance phase to initialize global IDs via trajectory-feature matching. In later frames, new tracklets are matched to existing global identities through a prioritized global matching strategy. New global IDs are only introduced when no sufficiently similar trajectory or feature match is found. 3D positions are estimated using depth maps and calibration for spatial validation.",
      "authors": [
        "Hamidreza Hashempoor"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:57:53+00:00",
          "link": "https://arxiv.org/abs/2507.10115v1",
          "size": "1440kb",
          "version": "v1"
        }
      ],
      "title": "Glance-MCMT: A General MCMT Framework with Glance Initialization and Progressive Association",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10115",
        "HTML": "https://arxiv.org/html/2507.10115v1",
        "PDF": "https://arxiv.org/pdf/2507.10115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a tracking framework for multi-camera systems, involving identity assignment and trajectory matching, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10216",
      "abstract": "As large language models (LLMs) become increasingly central to Arabic NLP applications, evaluating their understanding of regional dialects and cultural nuances is essential, particularly in linguistically diverse settings like Saudi Arabia. This paper introduces \\texttt{Absher}, a comprehensive benchmark specifically designed to assess LLMs performance across major Saudi dialects. \\texttt{Absher} comprises over 18,000 multiple-choice questions spanning six distinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage, Cultural Interpretation, and Location Recognition. These questions are derived from a curated dataset of dialectal words, phrases, and proverbs sourced from various regions of Saudi Arabia. We evaluate several state-of-the-art LLMs, including multilingual and Arabic-specific models. We also provide detailed insights into their capabilities and limitations. Our results reveal notable performance gaps, particularly in tasks requiring cultural inference or contextual understanding. Our findings highlight the urgent need for dialect-aware training and culturally aligned evaluation methodologies to improve LLMs performance in real-world Arabic applications.",
      "authors": [
        "Renad Al-Monef",
        "Hassan Alhuzali",
        "Nora Alturayeif",
        "Ashwag Alasmari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:33:07+00:00",
          "link": "https://arxiv.org/abs/2507.10216v1",
          "size": "1653kb",
          "version": "v1"
        }
      ],
      "title": "Absher: A Benchmark for Evaluating Large Language Models Understanding of Saudi Dialects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10216",
        "HTML": "https://arxiv.org/html/2507.10216v1",
        "PDF": "https://arxiv.org/pdf/2507.10216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a benchmark for evaluating LLMs on Saudi dialects, which involves using a curated dataset but does not focus on novel LLM training-data processing techniques or data engineering contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.00922",
      "abstract": "We study infinite horizon Markov decision processes (MDPs) with \"fast-slow\" structure, where some state variables evolve rapidly (\"fast states\") while others change more gradually (\"slow states\"). This structure commonly arises in practice when decisions must be made at high frequencies over long horizons, and where slowly changing information still plays a critical role in determining optimal actions. Examples include inventory control under slowly changing demand indicators or dynamic pricing with gradually shifting consumer behavior. Modeling the problem at the natural decision frequency leads to MDPs with discount factors close to one, making them computationally challenging. We propose a novel approximation strategy that \"freezes\" slow states during phases of lower-level planning and subsequently applies value iteration to an auxiliary upper-level MDP that evolves on a slower timescale. Freezing states for short periods of time leads to easier-to-solve lower-level problems, while a slower upper-level timescale allows for a more favorable discount factor. On the theoretical side, we analyze the regret incurred by our frozen-state approach, which leads to simple insights on how to trade off regret versus computational cost. Empirically, we benchmark our new frozen-state methods on three domains, (i) inventory control with fixed order costs, (ii) a gridworld problem with spatial tasks, and (iii) dynamic pricing with reference-price effects. We demonstrate that the new methods produce high-quality policies with significantly less computation, and we show that simply omitting slow states is often a poor heuristic.",
      "authors": [
        "Yijia Wang",
        "Daniel R. Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-03T01:35:24+00:00",
          "link": "https://arxiv.org/abs/2301.00922v1",
          "size": "526kb",
          "version": "v1"
        },
        {
          "date": "2025-04-07T18:55:35+00:00",
          "link": "https://arxiv.org/abs/2301.00922v2",
          "size": "1766kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T14:49:35+00:00",
          "link": "https://arxiv.org/abs/2301.00922v3",
          "size": "1764kb",
          "version": "v3"
        }
      ],
      "title": "Faster Reinforcement Learning by Freezing Slow States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.00922",
        "HTML": "https://arxiv.org/html/2301.00922v3",
        "PDF": "https://arxiv.org/pdf/2301.00922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel approach to solve Markov Decision Processes (MDPs) efficiently rather than LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.12167",
      "abstract": "We consider two symmetry metrics commonly used to analyze partisan gerrymandering: the Mean-Median Difference (MM) and Partisan Bias (PB). Our main results compare, for combinations of seats and votes achievable in districted elections, the number of districts won by each party to the extent of potential deviation from the ideal metric values, taking into account the political geography of the state. These comparisons are motivated by examples where the MM and PB have been used in efforts to detect when a districting plan awards extreme number of districts won by some party. These examples include expert testimony, public-facing apps, recommendations by experts to redistricting commissions, and public policy proposals. To achieve this goal we perform both theoretical and empirical analyses of the MM and PB. In our theoretical analysis, we consider vote-share, seat-share pairs (V, S) for which one can construct election data having vote share V and seat share S, and turnout is equal in each district. We calculate the range of values that MM and PB can achieve on that constructed election data. In the process, we find the range of (V,S) pairs that achieve MM = 0, and see that the corresponding range for PB is the same set of (V,S) pairs. We show how the set of such (V,S) pairs allowing for MM = 0 (and PB = 0) changes when turnout in each district is allowed to vary. By observing the results of this theoretical analysis, we can show that the values taken on by these metrics do not necessarily attain more extreme values in plans with more extreme numbers of districts won. We also analyze specific example elections, showing how these metrics can return unintuitive results. We follow this with an empirical study, where we show that on 18 different U.S. maps these metrics can fail to detect extreme seats outcomes.",
      "authors": [
        "Daryl DeFord and Ellen Veomett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Combinatorics (math.CO)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T00:39:30+00:00",
          "link": "https://arxiv.org/abs/2406.12167v1",
          "size": "19430kb",
          "version": "v1"
        },
        {
          "date": "2024-09-27T00:07:03+00:00",
          "link": "https://arxiv.org/abs/2406.12167v2",
          "size": "12905kb",
          "version": "v2"
        },
        {
          "date": "2025-01-16T19:36:55+00:00",
          "link": "https://arxiv.org/abs/2406.12167v3",
          "size": "12916kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T17:16:59+00:00",
          "link": "https://arxiv.org/abs/2406.12167v4",
          "size": "12913kb",
          "version": "v4"
        }
      ],
      "title": "Bounds and Bugs: The Limits of Symmetry Metrics to Detect Partisan Gerrymandering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12167",
        "HTML": "https://arxiv.org/html/2406.12167v4",
        "PDF": "https://arxiv.org/pdf/2406.12167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on metrics for partisan gerrymandering, involving theoretical and empirical analyses of electoral outcomes and not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04189",
      "abstract": "Despite the recent strides in video generation, state-of-the-art methods still struggle with elements of visual detail. One particularly challenging case is the class of videos in which the intricate motion of the hand coupled with a mostly stable and otherwise distracting environment is necessary to convey the execution of some complex action and its effects. To address these challenges, we introduce a new method for video generation that focuses on hand-centric actions. Our diffusion-based method incorporates two distinct innovations. First, we propose an automatic method to generate the motion area -- the region in the video in which the detailed activities occur -- guided by both the visual context and the action text prompt, rather than assuming this region can be provided manually as is now commonplace. Second, we introduce a critical Hand Refinement Loss to guide the diffusion model to focus on smooth and consistent hand poses. We evaluate our method on challenging augmented datasets based on EpicKitchens and Ego4D, demonstrating significant improvements over state-of-the-art methods in terms of action clarity, especially of the hand motion in the target region, across diverse environments and actions. Video results can be found in https://excitedbutter.github.io/project_page",
      "authors": [
        "Yayuan Li",
        "Zhi Cao",
        "Jason J. Corso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T14:29:10+00:00",
          "link": "https://arxiv.org/abs/2412.04189v1",
          "size": "25407kb",
          "version": "v1"
        },
        {
          "date": "2024-12-09T16:45:51+00:00",
          "link": "https://arxiv.org/abs/2412.04189v2",
          "size": "38727kb",
          "version": "v2"
        },
        {
          "date": "2024-12-11T21:13:49+00:00",
          "link": "https://arxiv.org/abs/2412.04189v3",
          "size": "3312kb",
          "version": "v3"
        },
        {
          "date": "2025-04-28T21:44:46+00:00",
          "link": "https://arxiv.org/abs/2412.04189v4",
          "size": "7047kb",
          "version": "v4"
        },
        {
          "date": "2025-07-14T02:27:36+00:00",
          "link": "https://arxiv.org/abs/2412.04189v5",
          "size": "7030kb",
          "version": "v5"
        }
      ],
      "title": "HANDI: Hand-Centric Text-and-Image Conditioned Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04189",
        "HTML": "https://arxiv.org/html/2412.04189v5",
        "PDF": "https://arxiv.org/pdf/2412.04189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a video generation method focusing on hand-centric actions but does not involve processing or creating training data for LLMs."
      },
      "tasks": [
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10474",
      "abstract": "The aging population is growing rapidly, and so is the danger of falls in older adults. A major cause of injury is falling, and detection in time can greatly save medical expenses and recovery time. However, to provide timely intervention and avoid unnecessary alarms, detection systems must be effective and reliable while addressing privacy concerns regarding the user. In this work, we propose a framework for detecting falls using several complementary systems: a semi-supervised federated learning-based fall detection system (SF2D), an indoor localization and navigation system, and a vision-based human fall recognition system. A wearable device and an edge device identify a fall scenario in the first system. On top of that, the second system uses an indoor localization technique first to localize the fall location and then navigate a robot to inspect the scenario. A vision-based detection system running on an edge device with a mounted camera on a robot is used to recognize fallen people. Each of the systems of this proposed framework achieves different accuracy rates. Specifically, the SF2D has a 0.81% failure rate equivalent to 99.19% accuracy, while the vision-based fallen people detection achieves 96.3% accuracy. However, when we combine the accuracy of these two systems with the accuracy of the navigation system (95% success rate), our proposed framework creates a highly reliable performance for fall detection, with an overall accuracy of 99.99%. Not only is the proposed framework safe for older adults, but it is also a privacy-preserving solution for detecting falls.",
      "authors": [
        "Seyed Alireza Rahimi Azghadi",
        "Truong-Thanh-Hung Nguyen",
        "Helene Fournier",
        "Monica Wachowicz",
        "Rene Richard",
        "Francis Palma",
        "Hung Cao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:55:11+00:00",
          "link": "https://arxiv.org/abs/2507.10474v1",
          "size": "4570kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Multi-Stage Fall Detection Framework with Semi-supervised Federated Learning and Robotic Vision Confirmation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10474",
        "HTML": "https://arxiv.org/html/2507.10474v1",
        "PDF": "https://arxiv.org/pdf/2507.10474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a fall detection system using federated learning and vision systems, focusing on privacy and reliability. There is no mention of processing data for LLM training or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.08969",
      "abstract": "In recent years, numerous researchers have begun investigating how virtual reality (VR) tracking and interaction data can be used for a variety of machine learning purposes, including user identification, predicting cybersickness, and estimating learning gains. One constraint for this research area is the dearth of open datasets. In this paper, we present a new open dataset captured with our VR-based Full-scale Assembly Simulation Testbed (FAST). This dataset consists of data collected from 108 participants (50 females, 56 males, 2 non-binary) learning how to assemble two distinct full-scale structures in VR. In addition to explaining how the dataset was collected and describing the data included, we discuss how the dataset may be used by future researchers.",
      "authors": [
        "Alec G. Moore",
        "Tiffany D. Do",
        "Nayan N. Chawla",
        "Antonia Jimenez Iriarte",
        "and Ryan P. McMahan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-13T21:30:01+00:00",
          "link": "https://arxiv.org/abs/2403.08969v1",
          "size": "10080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T13:16:20+00:00",
          "link": "https://arxiv.org/abs/2403.08969v2",
          "size": "10080kb",
          "version": "v2"
        }
      ],
      "title": "The Full-scale Assembly Simulation Testbed (FAST) Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08969",
        "HTML": "https://arxiv.org/html/2403.08969v2",
        "PDF": "https://arxiv.org/pdf/2403.08969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes the creation of a new VR-based dataset but does not discuss training-data processing for LLMs or any methodologies for improving data quality specific to LLM training situations."
      },
      "tasks": [
        "User Identification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10395",
      "abstract": "Recent advances in large language models (LLMs) have enabled multimodal foundation models to tackle both image understanding and generation within a unified framework. Despite these gains, unified models often underperform compared to specialized models in either task. A key challenge in developing unified models lies in the inherent differences between the visual features needed for image understanding versus generation, as well as the distinct training processes required for each modality. In this work, we introduce Pisces, an auto-regressive multimodal foundation model that addresses this challenge through a novel decoupled visual encoding architecture and tailored training techniques optimized for multimodal generation. Combined with meticulous data curation, pretraining, and finetuning, Pisces achieves competitive performance in both image understanding and image generation. We evaluate Pisces on over 20 public benchmarks for image understanding, where it demonstrates strong performance across a wide range of tasks. Additionally, on GenEval, a widely adopted benchmark for image generation, Pisces exhibits robust generative capabilities. Our extensive analysis reveals the synergistic relationship between image understanding and generation, and the benefits of using separate visual encoders, advancing the field of unified multimodal models.",
      "authors": [
        "Zhiyang Xu",
        "Jiuhai Chen",
        "Zhaojiang Lin",
        "Xichen Pan",
        "Lifu Huang",
        "Tianyi Zhou",
        "Madian Khabsa",
        "Qifan Wang",
        "Di Jin",
        "Michihiro Yasunaga",
        "Lili Yu",
        "Xi Victoria Lin",
        "Shaoliang Nie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T06:37:34+00:00",
          "link": "https://arxiv.org/abs/2506.10395v1",
          "size": "4600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T20:42:24+00:00",
          "link": "https://arxiv.org/abs/2506.10395v2",
          "size": "4601kb",
          "version": "v2"
        }
      ],
      "title": "Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10395",
        "HTML": "https://arxiv.org/html/2506.10395v2",
        "PDF": "https://arxiv.org/pdf/2506.10395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions meticulous data curation, pretraining, and finetuning for a multimodal model, but does not focus on LLM training data processing as its primary contribution."
      },
      "tasks": [
        "Image Generation",
        "multimodal generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04219",
      "abstract": "Current unlearning methods for LLMs optimize on the private information they seek to remove by incorporating it into their training objectives. We argue this not only risks reinforcing exposure to sensitive data, it also fundamentally contradicts the principle of minimizing its use. As a remedy, we propose a novel unlearning method - Partial Model Collapse (PMC), which does not require unlearning targets in the unlearning objective. Our approach is inspired by recent observations that training generative models on their own generations leads to distribution collapse, effectively removing information from the model. Our core idea is to leverage this collapse for unlearning by triggering collapse partially on the sensitive data. We theoretically analyze that our approach converges to the desired outcome, i.e. the LLM unlearns the information in the forget set. We empirically demonstrate that PMC overcomes two key limitations of existing unlearning approaches that explicitly optimize on unlearning targets, and more effectively removes private information from model outputs. Overall, our contributions represent an important step toward more comprehensive unlearning that aligns with real-world privacy constraints. Code available at https://www.cs.cit.tum.de/daml/partial-model-collapse/.",
      "authors": [
        "Yan Scholten",
        "Sophie Xhonneux",
        "Leo Schwinn",
        "Stephan G\\\"unnemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T03:08:49+00:00",
          "link": "https://arxiv.org/abs/2507.04219v1",
          "size": "1477kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:16:41+00:00",
          "link": "https://arxiv.org/abs/2507.04219v2",
          "size": "1477kb",
          "version": "v2"
        }
      ],
      "title": "Model Collapse Is Not a Bug but a Feature in Machine Unlearning for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04219",
        "PDF": "https://arxiv.org/pdf/2507.04219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for machine unlearning in LLMs, specifically removing sensitive information from models, but it does not focus on the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08945",
      "abstract": "Conventional Retrieval Augmented Generation (RAG) approaches are common in text-based applications. However, they struggle with structured, interconnected datasets like knowledge graphs, where understanding underlying relationships is crucial for accurate retrieval. A common direction in graph-based retrieval employs iterative, rule-based traversal guided by Large Language Models (LLMs). Such existing iterative methods typically combine reasoning with single hop traversal at each step, making them vulnerable to LLM reasoning errors and hallucinations that ultimately hinder the retrieval of relevant information.\n  To address these limitations, we propose GraphRunner, a novel graph-based retrieval framework that operates in three distinct stages: planning, verification, and execution. This introduces high-level traversal actions that enable multi-hop exploration in a single step. It also generates a holistic traversal plan, which is verified against the graph structure and pre-defined traversal actions, reducing reasoning errors and detecting hallucinations before execution. GraphRunner significantly reduces LLM reasoning errors and detects hallucinations through validation. Our evaluation using the GRBench dataset shows that GraphRunner consistently outperforms existing approaches, achieving 10-50% performance improvements over the strongest baseline while reducing inference cost by 3.0-12.9x and response generation time by 2.5-7.1x, making it significantly more robust and efficient for graph-based retrieval tasks.",
      "authors": [
        "Savini Kashmira",
        "Jayanaka L. Dantanarayana",
        "Kriszti\\'an Flautner",
        "Lingjia Tang",
        "Jason Mars"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:10:01+00:00",
          "link": "https://arxiv.org/abs/2507.08945v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "GraphRunner: A Multi-Stage Framework for Efficient and Accurate Graph-Based Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08945",
        "HTML": "https://arxiv.org/html/2507.08945v1",
        "PDF": "https://arxiv.org/pdf/2507.08945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a retrieval framework for text-based applications and graph-based retrievals but does not address LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09071",
      "abstract": "Large vision-language models (VLMs) enable the joint processing of text and images. However, the inclusion of vision data significantly expands the prompt length. Along with the quadratic complexity of the attention computation, this results in a longer prefill duration. An approach to mitigate this bottleneck is to leverage the inherent sparsity in the attention computation. In our analysis of attention patterns in VLMs, we observe that a substantial portion of layers exhibit minimal cross-image attention, except through attention-sink tokens per image. These sparse attention patterns fall into distinct categories: sink-only, document mask and a hybrid document-sink mask. Based on this, we propose BlindSight: a training-free approach to optimize VLM inference using a input template-aware attention sparsity mask. We utilize samples from a dataset to derive a prompt-agnostic sparsity categorization for every attention head. We evaluate the proposed technique using VLMs such as Qwen2-VL, Qwen2.5-VL and Gemma-3. BlindSight results in a 32%-41% reduction in FLOPs on average with -2%-+2% accuracy compared to the original model in most evaluated multi-image understanding benchmarks.",
      "authors": [
        "Tharun Adithya Srikrishnan",
        "Deval Shah",
        "Steven K. Reinhardt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:15:30+00:00",
          "link": "https://arxiv.org/abs/2507.09071v1",
          "size": "13696kb",
          "version": "v1"
        }
      ],
      "title": "BlindSight: Harnessing Sparsity for Efficient VLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09071",
        "HTML": "https://arxiv.org/html/2507.09071v1",
        "PDF": "https://arxiv.org/pdf/2507.09071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method to optimize VLM inference using sparsity in attention computation, but it does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09427",
      "abstract": "Justification logics are an explication of modal logic; boxes are replaced with proof terms formally through realisation theorems. This can be achieved syntactically using a cut-free proof system e.g. using sequent, hypersequent or nested sequent calculi. In constructive modal logic, boxes and diamonds are decoupled and not De Morgan dual. Kuznets, Marin and Stra{\\ss}burger provide a justification counterpart to constructive modal logic CK and some extensions by making diamonds explicit by introducing new terms called satisfiers. We continue the line of work to provide a justification counterpart to Fischer Servi's intuitionistic modal logic IK and its extensions with the t and 4 axioms. We: extend the syntax of proof terms to accommodate the additional axioms of intuitionistic modal logic; provide an axiomatisation of these justification logics; provide a syntactic realisation procedure using a cut-free nested sequent system for intuitionistic modal logic introduced by Stra{\\ss}burger.",
      "authors": [
        "Sonia Marin and Paaras Padhiar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:35:02+00:00",
          "link": "https://arxiv.org/abs/2507.09427v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "Justification Logic for Intuitionistic Modal Logic (Extended Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09427",
        "HTML": "https://arxiv.org/html/2507.09427v1",
        "PDF": "https://arxiv.org/pdf/2507.09427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on justification logic and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10055",
      "abstract": "Direct and natural interaction is essential for intuitive human-robot collaboration, eliminating the need for additional devices such as joysticks, tablets, or wearable sensors. In this paper, we present a lightweight deep learning-based hand gesture recognition system that enables humans to control collaborative robots naturally and efficiently. This model recognizes eight distinct hand gestures with only 1,103 parameters and a compact size of 22 KB, achieving an accuracy of 93.5%. To further optimize the model for real-world deployment on edge devices, we applied quantization and pruning using TensorFlow Lite, reducing the final model size to just 7 KB. The system was successfully implemented and tested on a Universal Robot UR5 collaborative robot within a real-time robotic framework based on ROS2. The results demonstrate that even extremely lightweight models can deliver accurate and responsive hand gesture-based control for collaborative robots, opening new possibilities for natural human-robot interaction in constrained environments.",
      "authors": [
        "Muhtadin",
        "I Wayan Agus Darmawan",
        "Muhammad Hilmi Rusydiansyah",
        "I Ketut Eddy Purnama",
        "Chastine Fatichah",
        "Mauridhi Hery Purnomo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:40:24+00:00",
          "link": "https://arxiv.org/abs/2507.10055v1",
          "size": "1403kb",
          "version": "v1"
        }
      ],
      "title": "Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10055",
        "PDF": "https://arxiv.org/pdf/2507.10055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a hand gesture recognition system for robots using deep learning. It does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10348",
      "abstract": "Model-Heterogeneous Federated Learning (Hetero-FL) has attracted growing attention for its ability to aggregate knowledge from heterogeneous models while keeping private data locally. To better aggregate knowledge from clients, ensemble distillation, as a widely used and effective technique, is often employed after global aggregation to enhance the performance of the global model. However, simply combining Hetero-FL and ensemble distillation does not always yield promising results and can make the training process unstable. The reason is that existing methods primarily focus on logit distillation, which, while being model-agnostic with softmax predictions, fails to compensate for the knowledge bias arising from heterogeneous models. To tackle this challenge, we propose a stable and efficient Feature Distillation for model-heterogeneous Federated learning, dubbed FedFD, that can incorporate aligned feature information via orthogonal projection to integrate knowledge from heterogeneous models better. Specifically, a new feature-based ensemble federated knowledge distillation paradigm is proposed. The global model on the server needs to maintain a projection layer for each client-side model architecture to align the features separately. Orthogonal techniques are employed to re-parameterize the projection layer to mitigate knowledge bias from heterogeneous models and thus maximize the distilled knowledge. Extensive experiments show that FedFD achieves superior performance compared to state-of-the-art methods.",
      "authors": [
        "Yichen Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:51:18+00:00",
          "link": "https://arxiv.org/abs/2507.10348v1",
          "size": "606kb",
          "version": "v1"
        }
      ],
      "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10348",
        "HTML": "https://arxiv.org/html/2507.10348v1",
        "PDF": "https://arxiv.org/pdf/2507.10348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses feature distillation in federated learning, which indirectly relates to training data but focuses more on enhancing model performance than processing the data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13535",
      "abstract": "We consider the problem of computing the probability of maximality (PoM) of a Gaussian random vector, i.e., the probability for each dimension to be maximal. This is a key challenge in applications ranging from Bayesian optimization to reinforcement learning, where the PoM not only helps with finding an optimal action, but yields a fine-grained analysis of the action domain, crucial in tasks such as drug discovery. Existing techniques are costly, scaling polynomially in computation and memory with the vector size. We introduce LITE, the first approach for estimating Gaussian PoM with almost-linear time and memory complexity. LITE achieves SOTA accuracy on a number of tasks, while being in practice several orders of magnitude faster than the baselines. This also translates to a better performance on downstream tasks such as entropy estimation and optimal control of bandits. Theoretically, we cast LITE as entropy-regularized UCB and connect it to prior PoM estimators.",
      "authors": [
        "Nicolas Menet",
        "Jonas H\\\"ubotter",
        "Parnian Kassraie",
        "Andreas Krause (ETH Z\\\"urich)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T10:32:21+00:00",
          "link": "https://arxiv.org/abs/2501.13535v1",
          "size": "5052kb",
          "version": "v1"
        },
        {
          "date": "2025-02-15T16:41:42+00:00",
          "link": "https://arxiv.org/abs/2501.13535v2",
          "size": "4873kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T13:08:16+00:00",
          "link": "https://arxiv.org/abs/2501.13535v3",
          "size": "4865kb",
          "version": "v3"
        }
      ],
      "title": "LITE: Efficiently Estimating Gaussian Probability of Maximality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13535",
        "PDF": "https://arxiv.org/pdf/2501.13535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for estimating Gaussian probabilities, relevant for optimization and control tasks, not linked to LLM training data processing."
      },
      "tasks": [
        "Bayesian Optimization",
        "Drug Discovery"
      ],
      "repo_urls": [
        "https://github.com/lasgroup/lite"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09688",
      "abstract": "When planning transportation whose operation requires non-consumable resources, the peak demand for allocated resources is often of higher interest than the duration of resource usage. For instance, it is more cost-effective to deliver parcels with a single truck over eight hours than to use two trucks for four hours, as long as the time suffices. To model such scenarios, we introduce the novel minimum peak cost flow over time problem, whose objective is to minimise the maximum cost at all points in time rather than minimising the integral of costs. We focus on minimising peak costs of temporally repeated flows. These are desirable for practical applications due to their simple structure. This yields the minimum-peak-cost Temporally Repeated flow problem (MPC-TRF).\n  We show that the simple structure of temporally repeated flows comes with the drawback of arbitrarily bad approximation ratios compared to general flows over time. Furthermore, our complexity analysis shows the integral version of MPC-TRF is strongly NP-hard, even under strong restrictions. On the positive side, we identify two benign special cases: unit-cost series-parallel networks and networks with time horizon at least twice as long as the longest path in the network (with respect to the transit time). In both cases, we show that integral optimal flows if the desired flow value equals the maximum flow value and fractional optimal flows for arbitrary flow values can be found in polynomial time. For each of these cases, we provide an explicit algorithm that constructs an optimal solution.",
      "authors": [
        "Mariia Anapolska",
        "Emma Ahrens",
        "Christina B\\\"using",
        "Felix Engelhardt",
        "Timo Gersing",
        "Corinna Mathwieser",
        "Sabrian Schmitz",
        "Sophia Wrede"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.09688v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "Minimum-Peak-Cost Flows Over Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09688",
        "PDF": "https://arxiv.org/pdf/2507.09688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new optimization problem related to flow networks and does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09733",
      "abstract": "We present the first foundational AI model for universal physics simulation that learns physical laws directly from boundary-condition data without requiring a priori equation encoding. Traditional physics-informed neural networks (PINNs) and finite-difference methods necessitate explicit mathematical formulation of governing equations, fundamentally limiting their generalizability and discovery potential. Our sketch-guided diffusion transformer approach reimagines computational physics by treating simulation as a conditional generation problem, where spatial boundary conditions guide the synthesis of physically accurate steady-state solutions.\n  By leveraging enhanced diffusion transformer architectures with novel spatial relationship encoding, our model achieves direct boundary-to-equilibrium mapping and is generalizable to diverse physics domains. Unlike sequential time-stepping methods that accumulate errors over iterations, our approach bypasses temporal integration entirely, directly generating steady-state solutions with SSIM > 0.8 while maintaining sub-pixel boundary accuracy. Our data-informed approach enables physics discovery through learned representations analyzable via Layer-wise Relevance Propagation (LRP), revealing emergent physical relationships without predetermined mathematical constraints. This work represents a paradigm shift from AI-accelerated physics to AI-discovered physics, establishing the first truly universal physics simulation framework.",
      "authors": [
        "Bradley Camburn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:12:34+00:00",
          "link": "https://arxiv.org/abs/2507.09733v1",
          "size": "3834kb",
          "version": "v1"
        }
      ],
      "title": "Universal Physics Simulation: A Foundational Diffusion Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09733",
        "HTML": "https://arxiv.org/html/2507.09733v1",
        "PDF": "https://arxiv.org/pdf/2507.09733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a model for physics simulations, emphasizing a new diffusion-based approach to simulate physical laws. It does not involve LLM training data processing or dataset generation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.03778",
      "abstract": "Flowshop problems play a prominent role in operations research, and have considerable practical significance. The single-machine flowshop problem is of particular theoretical interest. Until now the problem of minimizing late jobs or job tardiness can only be solved exactly by computationally-intensive methods such as dynamic programming or linear programming. In this paper we introduce, test, and optimize two new heuristic algorithms for mixed tardiness and late job minimization in single-machine flowshops. The two algorithms both build partial schedules iteratively. Both also retain Pareto optimal solutions at intermediate stages, to take into account both tardiness and late jobs within the partial schedule, as well as the effect of partial completion time on not-yet scheduled jobs. Both algorithms can be applied to scenarios with hundreds of jobs, with execution times running from less than a second to a few minutes. Although they are slower than dispatch rule-based heuristics, the solutions obtained are far better. We also compare a neural-network solution, which performs poorly.",
      "authors": [
        "Matthew Gradwohl",
        "Guidio Sewa",
        "Oke Blessing Oghojafor",
        "Richard Wilouwou",
        "Muminu Adamu",
        "Christopher Thron"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T04:57:48+00:00",
          "link": "https://arxiv.org/abs/2409.03778v1",
          "size": "861kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T14:21:04+00:00",
          "link": "https://arxiv.org/abs/2409.03778v2",
          "size": "864kb",
          "version": "v2"
        }
      ],
      "title": "Two Pareto Optimum-based Heuristic Algorithms for Minimizing Tardiness and Late Jobs in the Single Machine Flowshop Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03778",
        "HTML": "https://arxiv.org/html/2409.03778v2",
        "PDF": "https://arxiv.org/pdf/2409.03778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses heuristic algorithms for flowshop problems in operations research, which is not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03940",
      "abstract": "The rapid advancement in large language models (LLMs) has significantly enhanced their ability to generate coherent and contextually relevant text, raising concerns about the misuse of AI-generated content and making it critical to detect it. However, the task remains challenging, particularly in unseen domains or with unfamiliar LLMs. Leveraging LLM next-token distribution outputs offers a theoretically appealing approach for detection, as they encapsulate insights from the models' extensive pre-training on diverse corpora. Despite its promise, zero-shot methods that attempt to operationalize these outputs have met with limited success. We hypothesize that one of the problems is that they use the mean to aggregate next-token distribution metrics across tokens, when some tokens are naturally easier or harder to predict and should be weighted differently. Based on this idea, we propose the Perplexity Attention Weighted Network (PAWN), which uses the last hidden states of the LLM and positions to weight the sum of a series of features based on metrics from the next-token distribution across the sequence length. Although not zero-shot, our method allows us to cache the last hidden states and next-token distribution metrics on disk, greatly reducing the training resource requirements. PAWN shows competitive and even better performance in-distribution than the strongest baselines (fine-tuned LMs) with a fraction of their trainable parameters. Our model also generalizes better to unseen domains and source models, with smaller variability in the decision boundary across distribution shifts. It is also more robust to adversarial attacks, and if the backbone has multilingual capabilities, it presents decent generalization to languages not seen during supervised training, with LLaMA3-1B reaching a mean macro-averaged F1 score of 81.46% in cross-validation with nine languages.",
      "authors": [
        "Pablo Miralles-Gonz\\'alez",
        "Javier Huertas-Tato",
        "Alejandro Mart\\'in",
        "David Camacho"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T17:00:49+00:00",
          "link": "https://arxiv.org/abs/2501.03940v1",
          "size": "217kb",
          "version": "v1"
        },
        {
          "date": "2025-01-22T10:39:50+00:00",
          "link": "https://arxiv.org/abs/2501.03940v2",
          "size": "220kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T07:05:28+00:00",
          "link": "https://arxiv.org/abs/2501.03940v3",
          "size": "203kb",
          "version": "v3"
        }
      ],
      "title": "Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03940",
        "HTML": "https://arxiv.org/html/2501.03940v3",
        "PDF": "https://arxiv.org/pdf/2501.03940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for AI-generated text detection using LLM outputs, focusing on model mechanisms and performance rather than on the processing or preparation of LLM training data."
      },
      "tasks": [
        "All",
        "Text Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.24859",
      "abstract": "Steering vectors are a lightweight method for controlling text properties by adding a learned bias to language model activations at inference time. So far, steering vectors have predominantly been evaluated in multiple-choice settings, while their effectiveness in free-form generation tasks remains understudied. Moving \"Beyond Multiple Choice,\" we thoroughly evaluate the effectiveness of steering vectors in adaptively controlling topical focus, sentiment, toxicity, and readability in abstractive summaries of the NEWTS dataset. We find that steering effectively controls the targeted summary properties, but high steering strengths consistently degrade both intrinsic and extrinsic text quality. Compared to steering, prompting offers weaker control, while preserving text quality. Combining steering and prompting yields the strongest control over text properties and offers the most favorable efficacy-quality trade-off at moderate steering strengths. Our results underscore the practical trade-off between control strength and text quality preservation when applying steering vectors to free-form generation tasks.",
      "authors": [
        "Joschka Braun",
        "Carsten Eickhoff",
        "Seyed Ali Bahrainian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T17:57:15+00:00",
          "link": "https://arxiv.org/abs/2505.24859v1",
          "size": "3403kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T23:10:37+00:00",
          "link": "https://arxiv.org/abs/2505.24859v2",
          "size": "3411kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24859",
        "HTML": "https://arxiv.org/html/2505.24859v2",
        "PDF": "https://arxiv.org/pdf/2505.24859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses steering vectors for controlling text properties during text generation, which is more about inference adjustments than the processing of training data itself."
      },
      "tasks": [
        "Form",
        "Language Modeling",
        "Language Modelling",
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03558",
      "abstract": "Brain stroke is a leading cause of mortality and long-term disability worldwide, underscoring the need for precise and rapid prediction techniques. Computed Tomography (CT) scan is considered one of the most effective methods for diagnosing brain strokes. Most stroke classification techniques use a single slice-level prediction mechanism, requiring radiologists to manually select the most critical CT slice from the original CT volume. Although clinical evaluations are often used in traditional diagnostic procedures, machine learning (ML) has opened up new avenues for improving stroke diagnosis. To supplement traditional diagnostic techniques, this study investigates machine learning models for early brain stroke prediction using CT scan images. This research proposes a novel machine learning approach to brain stroke detection, focusing on optimizing classification performance with pre-trained deep learning models and advanced optimization strategies. Pre-trained models, including DenseNet201, InceptionV3, MobileNetV2, ResNet50, and Xception, are used for feature extraction. Feature engineering techniques, including BFO, PCA, and LDA, further enhance model performance. These features are then classified using machine learning algorithms, including SVC, RF, XGB, DT, LR, KNN, and GNB. Our experiments demonstrate that the combination of MobileNetV2, LDA, and SVC achieved the highest classification accuracy of 97.93%, significantly outperforming other model-optimizer-classifier combinations. The results underline the effectiveness of integrating lightweight pre-trained models with robust optimization and classification techniques for brain stroke diagnosis.",
      "authors": [
        "Md. Sabbir Hossen",
        "Eshat Ahmed Shuvo",
        "Shibbir Ahmed Arif",
        "Pabon Shaha",
        "Md. Saiduzzaman",
        "Mostofa Kamal Nasir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T13:11:29+00:00",
          "link": "https://arxiv.org/abs/2507.03558v1",
          "size": "3991kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T05:47:35+00:00",
          "link": "https://arxiv.org/abs/2507.03558v2",
          "size": "3606kb",
          "version": "v2"
        }
      ],
      "title": "An Efficient Deep Learning Framework for Brain Stroke Diagnosis Using Computed Tomography (CT) Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03558",
        "HTML": "https://arxiv.org/html/2507.03558v2",
        "PDF": "https://arxiv.org/pdf/2507.03558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a deep learning framework for brain stroke diagnosis using CT images, focusing on model optimization and classification accuracy. There is no discussion of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean. We also provide a characterization for the case when $m=p=2$.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.05297v3",
          "size": "100kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T09:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.05297v4",
          "size": "320kb",
          "version": "v4"
        }
      ],
      "title": "Continuous Classification Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297v4",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides theoretical results on fuzzy classification aggregation functions, with no discussion on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09010",
      "abstract": "Edge inference for large language models (LLM) offers secure, low-latency, and cost-effective inference solutions. We emphasize that an edge accelerator should achieve high area efficiency and minimize external memory access (EMA) during the memory-bound decode stage, while maintaining high energy efficiency during the compute intensive prefill stage. This paper proposes an edge LLM inference accelerator featuring a hybrid systolic array (HSA) architecture that optimizes inference efficiency in both stages. To further reduce EMA, we adopt MXINT4 weight quantization and propose an optimized dataflow tailored for HSA, ensuring negligible dequantization overhead and achieving 100% hardware utilization with minimal accuracy loss under edge DRAM bandwidth constraints. For non-linear operations, we incorporate optimized root mean square normalization (RMSNorm) and rotary position embedding (RoPE) units, reducing their latency, area, and memory access overhead while enabling end-to-end inference on our accelerator. Our solution achieves 247/117 (token/s/mm2) while running a 1.3B LLM on long-input/long-output scenarios, providing >2.45x/13.5x improvement over existing approaches, while maintaining superior energy efficiency in token generation.",
      "authors": [
        "Chun-Ting Chen",
        "HanGyeol Mun",
        "Jian Meng",
        "Mohamed S. Abdelfattah",
        "Jae-sun Seo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:27:30+00:00",
          "link": "https://arxiv.org/abs/2507.09010v1",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Systolic Array Accelerator with Optimized Dataflow for Edge Large Language Model Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09010",
        "HTML": "https://arxiv.org/html/2507.09010v1",
        "PDF": "https://arxiv.org/pdf/2507.09010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents hardware architecture optimizations for LLM inference, focusing on energy efficiency and inference speed, not on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09369",
      "abstract": "This report presents a taxonomy and examples of potential omnicidal events resulting from AI: scenarios where all or almost all humans are killed. These events are not presented as inevitable, but as possibilities that we can work to avoid. Insofar as large institutions require a degree of public support in order to take certain actions, we hope that by presenting these possibilities in public, we can help to support preventive measures against catastrophic risks from AI.",
      "authors": [
        "Andrew Critch",
        "Jacob Tsimerman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:23:36+00:00",
          "link": "https://arxiv.org/abs/2507.09369v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "A Taxonomy of Omnicidal Futures Involving Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09369",
        "HTML": "https://arxiv.org/html/2507.09369v1",
        "PDF": "https://arxiv.org/pdf/2507.09369"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This report is about potential omnicidal events from AI and does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09480",
      "abstract": "Taylor's formula holds significant importance in function representation, such as solving differential difference equations, ordinary differential equations, partial differential equations, and further promotes applications in visual perception, complex control, fluid mechanics, weather forecasting and thermodynamics. However, the Taylor's formula suffers from the curse of dimensionality and error propagation during derivative computation in discrete situations. In this paper, we propose a new discrete differential operator to estimate derivatives and to represent continuous smooth function locally using the Vandermonde coefficient matrix derived from truncated Taylor series. Our method simultaneously computes all derivatives of orders less than the number of sample points, inherently mitigating error propagation. Utilizing equidistant uniform sampling, it achieves high-order accuracy while alleviating the curse of dimensionality. We mathematically establish rigorous error bounds for both derivative estimation and function representation, demonstrating tighter bounds for lower-order derivatives. We extend our method to the two-dimensional case, enabling its use for multivariate derivative calculations. Experiments demonstrate the effectiveness and superiority of the proposed method compared to the finite forward difference method for derivative estimation and cubic spline and linear interpolation for function representation. Consequently, our technique offers broad applicability across domains such as vision representation, feature extraction, fluid mechanics, and cross-media imaging.",
      "authors": [
        "Guoyou Wang",
        "Yihua Tan",
        "Shiqi Liu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:43:23+00:00",
          "link": "https://arxiv.org/abs/2507.09480v1",
          "size": "8989kb",
          "version": "v1"
        }
      ],
      "title": "Discrete Differential Principle for Continuous Smooth Function Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09480",
        "HTML": "https://arxiv.org/html/2507.09480v1",
        "PDF": "https://arxiv.org/pdf/2507.09480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a mathematical approach to function representation and derivative estimation, unrelated to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09676",
      "abstract": "A key assumption fuelling optimism about the progress of large language models (LLMs) in accurately and comprehensively modelling the world is that the truth is systematic: true statements about the world form a whole that is not just consistent, in that it contains no contradictions, but coherent, in that the truths are inferentially interlinked. This holds out the prospect that LLMs might in principle rely on that systematicity to fill in gaps and correct inaccuracies in the training data: consistency and coherence promise to facilitate progress towards comprehensiveness in an LLM's representation of the world. However, philosophers have identified compelling reasons to doubt that the truth is systematic across all domains of thought, arguing that in normative domains, in particular, the truth is largely asystematic. I argue that insofar as the truth in normative domains is asystematic, this renders it correspondingly harder for LLMs to make progress, because they cannot then leverage the systematicity of truth. And the less LLMs can rely on the systematicity of truth, the less we can rely on them to do our practical deliberation for us, because the very asystematicity of normative domains requires human agency to play a greater role in practical thought.",
      "authors": [
        "Matthieu Queloz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:23:31+00:00",
          "link": "https://arxiv.org/abs/2507.09676v1",
          "size": "820kb",
          "version": "v1"
        }
      ],
      "title": "Can AI Rely on the Systematicity of Truth? The Challenge of Modelling Normative Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09676",
        "PDF": "https://arxiv.org/pdf/2507.09676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the philosophical aspects of truth systematicity in relation to LLMs but does not address any technical aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09730",
      "abstract": "The accuracy of floating-random-walk (FRW) based capacitance extraction stands only when the recursive FRW transitions are sampled unbiasedly according to surrounding dielectrics. Advanced technology profiles, featuring complicated non-stratified dielectrics, challenge the accuracy of existing FRW transition schemes that approximate dielectrics with stratified or eight-octant patterns. In this work, we propose an algorithm named MicroWalk, enabling accurate FRW transitions for arbitrary dielectrics while keeping high efficiency. It is provably unbiased and equivalent to using transition probabilities solved by finite difference method, but at orders of magnitude lower cost (802$\\times$ faster). An enhanced 3-D capacitance solver is developed with a hybrid strategy for complicated dielectrics, combining MicroWalk with the special treatment for the first transition cube and the analytical algorithm for stratified cubes. Experiments on real-world structures show that our solver achieves a significant accuracy advantage over existing FRW solvers, while preserving high efficiency.",
      "authors": [
        "Jiechen Huang and Wenjian Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:07:32+00:00",
          "link": "https://arxiv.org/abs/2507.09730v1",
          "size": "914kb",
          "version": "v1"
        }
      ],
      "title": "Efficient FRW Transitions via Stochastic Finite Differences for Handling Non-Stratified Dielectrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09730",
        "HTML": "https://arxiv.org/html/2507.09730v1",
        "PDF": "https://arxiv.org/pdf/2507.09730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on capacitance extraction via stochastic finite differences and does not include any discussion on LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2204.01298",
      "abstract": "Capsule networks are biologically inspired neural networks that group neurons into vectors called capsules, each explicitly representing an object or one of its parts. The routing mechanism connects capsules in consecutive layers, forming a hierarchical structure between parts and objects, also known as a parse tree. Capsule networks often attempt to model all elements in an image, requiring large network sizes to handle complexities such as intricate backgrounds or irrelevant objects. However, this comprehensive modeling leads to increased parameter counts and computational inefficiencies. Our goal is to enable capsule networks to focus only on the object of interest, reducing the number of parse trees. We accomplish this with REM (Routing Entropy Minimization), a technique that minimizes the entropy of the parse tree-like structure. REM drives the model parameters distribution towards low entropy configurations through a pruning mechanism, significantly reducing the generation of intra-class parse trees. This empowers capsules to learn more stable and succinct representations with fewer parameters and negligible performance loss.",
      "authors": [
        "Riccardo Renzulli",
        "Enzo Tartaglione",
        "Marco Grangetto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2022-04-04T08:13:16+00:00",
          "link": "https://arxiv.org/abs/2204.01298v1",
          "size": "860kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T15:35:47+00:00",
          "link": "https://arxiv.org/abs/2204.01298v2",
          "size": "6289kb",
          "version": "v2"
        }
      ],
      "title": "Capsule Networks Do Not Need to Model Everything",
      "links": {
        "Abstract": "https://arxiv.org/abs/2204.01298",
        "HTML": "https://arxiv.org/html/2204.01298v2",
        "PDF": "https://arxiv.org/pdf/2204.01298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses capsule networks and a technique known as REM for minimizing entropy in parse trees, without any mention of LLM training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2312.05357",
      "abstract": "The development of signal unmixing algorithms is essential for leveraging multimodal datasets acquired through a wide array of scientific imaging technologies, including hyperspectral or time-resolved acquisitions. In experimental physics, enhancing the spatio-temporal resolution or expanding the number of detection channels often leads to diminished sampling rate and signal-to-noise ratio, significantly affecting the efficacy of signal unmixing algorithms. We propose Latent Unmixing, a new approach which applies bandpass filters to the latent space of a multidimensional convolutional neural network to disentangle overlapping signal components. It enables better isolation and quantification of individual signal contributions, especially in the context of undersampled distributions. Using multidimensional convolution kernels to process all dimensions simultaneously enhances the network's ability to extract information from adjacent pixels, and time or spectral bins. This approach enables more effective separation of components in cases where individual pixels do not provide clear, well-resolved information. We showcase the method's practical use in experimental physics through two test cases that highlight the versatility of our approach: fluorescence lifetime microscopy and mode decomposition in optical fibers. The latent unmixing method extracts valuable information from complex signals that cannot be resolved by standard methods. It opens up new possibilities in optics and photonics for multichannel separation at an increased sampling rate.",
      "authors": [
        "Catherine Bouchard",
        "Andr\\'eanne Desch\\^enes",
        "Vincent Boulanger",
        "Jean-Michel Bellavance",
        "Julia Chabbert",
        "Alexy Pelletier-Rioux",
        "Flavie Lavoie-Cardinal",
        "and Christian Gagn\\'e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-08T20:34:37+00:00",
          "link": "https://arxiv.org/abs/2312.05357v1",
          "size": "12256kb",
          "version": "v1"
        },
        {
          "date": "2024-04-06T02:42:44+00:00",
          "link": "https://arxiv.org/abs/2312.05357v2",
          "size": "18960kb",
          "version": "v2"
        },
        {
          "date": "2024-11-01T19:47:26+00:00",
          "link": "https://arxiv.org/abs/2312.05357v3",
          "size": "37383kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T19:04:57+00:00",
          "link": "https://arxiv.org/abs/2312.05357v4",
          "size": "21371kb",
          "version": "v4"
        }
      ],
      "title": "Unmixing Optical Signals from Undersampled Volumetric Measurements by Filtering the Pixel Latent Variables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.05357",
        "PDF": "https://arxiv.org/pdf/2312.05357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on signal unmixing algorithms in optical signals and does not discuss LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.05256",
      "abstract": "Modern compilers, such as LLVM, are complex pieces of software. Due to their complexity, manual testing is unlikely to suffice, yet formal verification is difficult to scale. End-to-end fuzzing can be used, but it has difficulties in achieving high coverage of some components of LLVM.\n  In this paper, we implement IRFuzzer to investigate the effectiveness of specialized fuzzing of the LLVM compiler backend. We focus on two approaches to improve the fuzzer: guaranteed input validity using constrained mutations and improved feedback quality. The mutator in IRFuzzer is capable of generating a wide range of LLVM IR inputs, including structured control flow, vector types, and function definitions. The system instruments coding patterns in the compiler to monitor the execution status of instruction selection. The instrumentation not only provides a new coverage feedback called matcher table coverage, but also provides an architecture specific guidance to the mutator.\n  We show that IRFuzzer is more effective than existing fuzzers by fuzzing on 29 mature LLVM backend targets. In the process, we reported 74 confirmed new bugs in LLVM upstream, out of which 49 have been fixed, five have been back ported to LLVM 15, showing that specialized fuzzing provides useful and actionable insights to LLVM developers.",
      "authors": [
        "Yuyang Rong",
        "Zhanghan Yu",
        "Zhenkai Weng",
        "Stephen Neuendorffer",
        "Hao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T21:02:33+00:00",
          "link": "https://arxiv.org/abs/2402.05256v1",
          "size": "2410kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:30:08+00:00",
          "link": "https://arxiv.org/abs/2402.05256v2",
          "size": "1968kb",
          "version": "v2"
        }
      ],
      "title": "IRFuzzer: Specialized Fuzzing for LLVM Backend Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.05256",
        "PDF": "https://arxiv.org/pdf/2402.05256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on fuzzing for the LLVM compiler, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.14830",
      "abstract": "Monte Carlo methods have led to profound insights into the strong-coupling behaviour of lattice gauge theories and produced remarkable results such as first-principles computations of hadron masses. Despite tremendous progress over the last four decades, fundamental challenges such as the sign problem and the inability to simulate real-time dynamics remain. Neural network quantum states have emerged as an alternative method that seeks to overcome these challenges. In this work, we use gauge-invariant neural network quantum states to accurately compute the ground state of $\\mathbb{Z}_N$ lattice gauge theories in $2+1$ dimensions. Using transfer learning, we study the distinct topological phases and the confinement phase transition of these theories. For $\\mathbb{Z}_2$, we identify a continuous transition and compute critical exponents, finding excellent agreement with existing numerics for the expected Ising universality class. In the $\\mathbb{Z}_3$ case, we observe a weakly first-order transition and identify the critical coupling. Our findings suggest that neural network quantum states are a promising method for precise studies of lattice gauge theory.",
      "authors": [
        "Anuj Apte",
        "Anthony Ashmore",
        "Clay Cordova",
        "Tzu-Chen Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "High Energy Physics - Lattice (hep-lat)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Theory (hep-th)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-23T17:46:49+00:00",
          "link": "https://arxiv.org/abs/2405.14830v1",
          "size": "1314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T21:27:19+00:00",
          "link": "https://arxiv.org/abs/2405.14830v2",
          "size": "1314kb",
          "version": "v2"
        }
      ],
      "title": "Deep learning lattice gauge theories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14830",
        "HTML": "https://arxiv.org/html/2405.14830v2",
        "PDF": "https://arxiv.org/pdf/2405.14830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies deep learning approaches to lattice gauge theories and does not deal with LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12932",
      "abstract": "Recently, a distributed middleware application called contract automata runtime environment ({\\tt CARE}) has been introduced to realise service applications specified using a dialect of finite-state automata. In this paper, we detail the formal modelling, verification and testing of {\\tt CARE}. We provide a formalisation as a network of stochastic timed automata. The model is verified against the desired properties with the tool {\\sc Uppaal}, utilising exhaustive and statistical model checking techniques. Abstract tests are generated from the {\\sc Uppaal} models that are concretised for testing {\\tt CARE}. This research emphasises the advantages of employing formal modelling, verification and testing processes to enhance the dependability of an open-source distributed application. We discuss the methodology used for modelling the application and generating concrete tests from the abstract model, addressing the issues that have been identified and fixed.",
      "authors": [
        "Davide Basile"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T15:03:25+00:00",
          "link": "https://arxiv.org/abs/2501.12932v1",
          "size": "1842kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:53:40+00:00",
          "link": "https://arxiv.org/abs/2501.12932v2",
          "size": "1958kb",
          "version": "v2"
        }
      ],
      "title": "Formal Analysis of the Contract Automata Runtime Environment with Uppaal: Modelling, Verification and Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12932",
        "HTML": "https://arxiv.org/html/2501.12932v2",
        "PDF": "https://arxiv.org/pdf/2501.12932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on formal modelling, verification, and testing processes for a distributed application and does not discuss any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08805",
      "abstract": "This paper introduces iREACT, a novel VR simulation addressing key limitations in traditional cardiac arrest (CA) training. Conventional methods struggle to replicate the dynamic nature of real CA events, hindering Crew Resource Management (CRM) skill development. iREACT provides a non-linear, collaborative environment where teams respond to changing patient states, mirroring real CA complexities. By capturing multi-modal data (user actions, cognitive load, visual gaze) and offering real-time and post-session feedback, iREACT enhances CRM assessment beyond traditional methods. A formative evaluation with medical experts underscores its usability and educational value, with potential applications in other high-stakes training scenarios to improve teamwork, communication, and decision-making.",
      "authors": [
        "Mike Kentros",
        "Manos Kamarianakis",
        "Michael Cole",
        "Vitaliy Popov",
        "Antonis Protopsaltis",
        "George Papagiannakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T12:48:47+00:00",
          "link": "https://arxiv.org/abs/2507.08805v1",
          "size": "6384kb",
          "version": "v1"
        }
      ],
      "title": "Non-linear, Team-based VR Training for Cardiac Arrest Care with enhanced CRM Toolkit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08805",
        "HTML": "https://arxiv.org/html/2507.08805v1",
        "PDF": "https://arxiv.org/pdf/2507.08805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on VR training for medical scenarios, specifically cardiac arrest care, without any connection to LLM training data or processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08831",
      "abstract": "Vision-Language Navigation in Continuous Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key research problem in embodied AI. However, most navigation policies are sensitive to viewpoint changes, i.e., variations in camera height and viewing angle that alter the agent's observation. In this paper, we introduce a generalized scenario, V2-VLNCE (VLNCE with Varied Viewpoints), and propose VIL (View Invariant Learning), a view-invariant post-training strategy that enhances the robustness of existing navigation policies to changes in camera viewpoint. VIL employs a contrastive learning framework to learn sparse and view-invariant features. Additionally, we introduce a teacher-student framework for the Waypoint Predictor Module, a core component of most VLNCE baselines, where a view-dependent teacher model distills knowledge into a view-invariant student model. We employ an end-to-end training paradigm to jointly optimize these components, thus eliminating the cost for individual module training. Empirical results show that our method outperforms state-of-the-art approaches on V2-VLNCE by 8-15% measured on Success Rate for two standard benchmark datasets R2R-CE and RxR-CE. Furthermore, we evaluate VIL under the standard VLNCE setting and find that, despite being trained for varied viewpoints, it often still improves performance. On the more challenging RxR-CE dataset, our method also achieved state-of-the-art performance across all metrics when compared to other map-free methods. This suggests that adding VIL does not diminish the standard viewpoint performance and can serve as a plug-and-play post-training method.",
      "authors": [
        "Josh Qixuan Sun",
        "Xiaoying Xing",
        "Huaiyuan Weng",
        "Chul Min Yeum",
        "Mark Crowley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T18:04:35+00:00",
          "link": "https://arxiv.org/abs/2507.08831v1",
          "size": "3427kb",
          "version": "v1"
        }
      ],
      "title": "View Invariant Learning for Vision-Language Navigation in Continuous Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08831",
        "HTML": "https://arxiv.org/html/2507.08831v1",
        "PDF": "https://arxiv.org/pdf/2507.08831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on enhancing navigation models via a view-invariant learning framework but does not significantly address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09227",
      "abstract": "There has been increasing interest in the generation of high-quality, realistic synthetic medical images in recent years. Such synthetic datasets can mitigate the scarcity of public datasets for artificial intelligence research, and can also be used for educational purposes. In this paper, we propose a combination of diffusion-based generation (PanoDiff) and Super-Resolution (SR) for generating synthetic dental panoramic radiographs (PRs). The former generates a low-resolution (LR) seed of a PR (256 X 128) which is then processed by the SR model to yield a high-resolution (HR) PR of size 1024 X 512. For SR, we propose a state-of-the-art transformer that learns local-global relationships, resulting in sharper edges and textures. Experimental results demonstrate a Frechet inception distance score of 40.69 between 7243 real and synthetic images (in HR). Inception scores were 2.55, 2.30, 2.90 and 2.98 for real HR, synthetic HR, real LR and synthetic LR images, respectively. Among a diverse group of six clinical experts, all evaluating a mixture of 100 synthetic and 100 real PRs in a time-limited observation, the average accuracy in distinguishing real from synthetic images was 68.5% (with 50% corresponding to random guessing).",
      "authors": [
        "Sanyam Jain",
        "Bruna Neves de Freitas",
        "Andreas Basse-OConnor",
        "Alexandros Iosifidis and Ruben Pauwels"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:52:10+00:00",
          "link": "https://arxiv.org/abs/2507.09227v1",
          "size": "29249kb",
          "version": "v1"
        }
      ],
      "title": "PanoDiff-SR: Synthesizing Dental Panoramic Radiographs using Diffusion and Super-resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09227",
        "HTML": "https://arxiv.org/html/2507.09227v1",
        "PDF": "https://arxiv.org/pdf/2507.09227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a method for generating synthetic radiographs but lacks a focus on the processing of LLM training data or datasets in contexts relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09815",
      "abstract": "Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and cyclists, is a critical challenge for autonomous driving systems, as crashes involving VRUs often result in severe or fatal consequences. While multimodal large language models (MLLMs) have shown promise in enhancing scene understanding and decision making in autonomous vehicles, there is currently no standardized benchmark to quantitatively evaluate their reasoning abilities in complex, safety-critical scenarios involving VRUs. To address this gap, we present VRU-Accident, a large-scale vision-language benchmark designed to evaluate MLLMs in high-risk traffic scenarios involving VRUs. VRU-Accident comprises 1K real-world dashcam accident videos, annotated with 6K multiple-choice question-answer pairs across six safety-critical categories (with 24K candidate options and 3.4K unique answer choices), as well as 1K dense scene descriptions. Unlike prior works, our benchmark focuses explicitly on VRU-vehicle accidents, providing rich, fine-grained annotations that capture both spatial-temporal dynamics and causal semantics of accidents. To assess the current landscape of MLLMs, we conduct a comprehensive evaluation of 17 state-of-the-art models on the multiple-choice VQA task and on the dense captioning task. Our findings reveal that while MLLMs perform reasonably well on visually grounded attributes, they face significant challenges in reasoning and describing accident causes, types, and preventability.",
      "authors": [
        "Younggun Kim",
        "Ahmed S. Abdelrahman",
        "and Mohamed Abdel-Aty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T22:14:35+00:00",
          "link": "https://arxiv.org/abs/2507.09815v1",
          "size": "28629kb",
          "version": "v1"
        }
      ],
      "title": "VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09815",
        "HTML": "https://arxiv.org/html/2507.09815v1",
        "PDF": "https://arxiv.org/pdf/2507.09815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper presents a vision-language benchmark for MLLMs, it focuses on evaluation in accident scene understanding, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10082",
      "abstract": "The unscented Kalman filter is a nonlinear estimation algorithm commonly used in navigation applications. The prediction of the mean and covariance matrix is crucial to the stable behavior of the filter. This prediction is done by propagating the sigma points according to the dynamic model at hand. In this paper, we introduce an innovative method to propagate the sigma points according to the nonlinear dynamic model of the navigation error state vector. This improves the filter accuracy and navigation performance. We demonstrate the benefits of our proposed approach using real sensor data recorded by an autonomous underwater vehicle during several scenarios.",
      "authors": [
        "Amit Levy and Itzik Klein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:08:29+00:00",
          "link": "https://arxiv.org/abs/2507.10082v1",
          "size": "165kb",
          "version": "v1"
        }
      ],
      "title": "Unscented Kalman Filter with a Nonlinear Propagation Model for Navigation Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10082",
        "HTML": "https://arxiv.org/html/2507.10082v1",
        "PDF": "https://arxiv.org/pdf/2507.10082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing navigation performance using the unscented Kalman filter and does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.17934",
      "abstract": "In recent years, Unmanned Aerial Vehicles (UAVs) have been utilized as effective platforms for carrying Wi-Fi Access Points (APs) and cellular Base Stations (BSs), enabling low-cost, agile, and flexible wireless networks with high Quality of Service (QoS). The next generation of wireless communications will rely on increasingly higher frequencies, which are easily obstructed by obstacles. One of the most critical concepts yet to be fully addressed is positioning the UAV at optimal coordinates while accounting for obstacles. To ensure a line of sight (LoS) between UAVs and user equipment (UE), improve QoS, and establish reliable wireless links with maximum coverage, obstacles must be integrated into the proposed placement algorithms. This paper introduces a simulation-based measurement approach for characterizing an air-to-ground (AG) channel in a simple scenario. By considering obstacles, we present a novel perspective on channel characterization. The results, in terms of throughput, packet delivery, packet loss, and delay, are compared using the proposed positioning approach.",
      "authors": [
        "Kamal Shayegan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T19:45:21+00:00",
          "link": "https://arxiv.org/abs/2412.17934v1",
          "size": "642kb",
          "version": "v1"
        },
        {
          "date": "2024-12-30T11:14:58+00:00",
          "link": "https://arxiv.org/abs/2412.17934v2",
          "size": "643kb",
          "version": "v2"
        },
        {
          "date": "2025-02-14T14:31:57+00:00",
          "link": "https://arxiv.org/abs/2412.17934v3",
          "size": "643kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T11:10:54+00:00",
          "link": "https://arxiv.org/abs/2412.17934v4",
          "size": "644kb",
          "version": "v4"
        }
      ],
      "title": "UAV Communications: Impact of Obstacles on Channel Characteristics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17934",
        "PDF": "https://arxiv.org/pdf/2412.17934"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses UAV communication and channel characteristics with obstacles, and does not relate to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.08782",
      "abstract": "The increasing penetration of Distributed Energy Resources (DERs) in the distribution system has led to the emergence of a new market actor - the aggregator. The aggregator serves as a facilitator, enabling flexibility asset owners to get access to different markets. In which, EVs aggregators are gaining more attention due to their expanding use and potential to provide services in various types of markets, particularly in the reserve market. Currently, TSO indirectly utilizes these resources under the management of the distribution system operators (DSO), which can negatively impact the distribution grid. Conversely, adjustments from DSOs can impact service provision to TSO due to the shortage of TSO usage information. These factors highlight the importance of evaluating the service provision from aggregators under different TSO-DSO coordination schemes. This paper focuses on the provision of flexibility from electric vehicles (EVs) aggregators for balancing service in the TSO-DSO hybrid-managed and compares it with the DSO-managed coordination schemes. The behavior of aggregators reacting to price fluctuations and TSO requests under different coordination schemes and simulation scenarios is thoroughly evaluated. Additionally, their impact on the grid is analyzed through the DSO's congestion management process and validated using data from a real part of the Dutch distribution network. Results find that the hybrid-managed coordination scheme gives more benefit to the aggregator than the DSO-managed scheme and the EVs aggregator will gain more profit in winter than summer due to more upward regulation service is needed.",
      "authors": [
        "Hang Nguyen",
        "Phuong Nguyen",
        "Koen Kok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T20:48:57+00:00",
          "link": "https://arxiv.org/abs/2502.08782v1",
          "size": "7424kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T21:17:54+00:00",
          "link": "https://arxiv.org/abs/2502.08782v2",
          "size": "1758kb",
          "version": "v2"
        }
      ],
      "title": "Balancing service provision by EV aggregator in different TSO-DSO coordination schemes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08782",
        "HTML": "https://arxiv.org/html/2502.08782v2",
        "PDF": "https://arxiv.org/pdf/2502.08782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper revolves around energy resource management by EV aggregators and coordination schemes, with no focus on LLM training data processing or dataset creation."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08965",
      "abstract": "In the information retrieval (IR) domain, evaluation plays a crucial role in optimizing search experiences and supporting diverse user intents. In the recent LLM era, research has been conducted to automate document relevance labels, as these labels have traditionally been assigned by crowd-sourced workers - a process that is both time and consuming and costly. This study focuses on LLM-generated usefulness labels, a crucial evaluation metric that considers the user's search intents and task objectives, an aspect where relevance falls short. Our experiment utilizes task-level, query-level, and document-level features along with user search behavior signals, which are essential in defining the usefulness of a document. Our research finds that (i) pre-trained LLMs can generate moderate usefulness labels by understanding the comprehensive search task session, (ii) pre-trained LLMs perform better judgement in short search sessions when provided with search session contexts. Additionally, we investigated whether LLMs can capture the unique divergence between relevance and usefulness, along with conducting an ablation study to identify the most critical metrics for accurate usefulness label generation. In conclusion, this work explores LLM-generated usefulness labels by evaluating critical metrics and optimizing for practicality in real-world settings.",
      "authors": [
        "Mouly Dewan",
        "Jiqun Liu",
        "Chirag Shah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T00:07:39+00:00",
          "link": "https://arxiv.org/abs/2503.08965v1",
          "size": "3622kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T12:59:42+00:00",
          "link": "https://arxiv.org/abs/2503.08965v2",
          "size": "6158kb",
          "version": "v2"
        }
      ],
      "title": "LLM-Driven Usefulness Labeling for IR Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08965",
        "HTML": "https://arxiv.org/html/2503.08965v2",
        "PDF": "https://arxiv.org/pdf/2503.08965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the use of LLMs to generate document usefulness labels for IR evaluation, which indirectly involves LLMs but focuses more on evaluation metrics rather than processing LLM training data itself."
      },
      "models": [
        {
          "model_path": "moulydewan/Llama-3.1-8B-Instruct-Finetuned-THUIR",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/moulydewan/Llama-3.1-8B-Instruct-Finetuned-THUIR"
        }
      ],
      "tasks": [
        "Information Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23724",
      "abstract": "Test-time Adaptation (TTA) adapts a given model to testing domain data with potential domain shifts through online unsupervised learning, yielding impressive performance. However, to date, existing TTA methods primarily focus on single-model adaptation. In this work, we investigate an intriguing question: how does cross-model knowledge influence the TTA process? Our findings reveal that, in TTA's unsupervised online setting, each model can provide complementary, confident knowledge to the others, even when there are substantial differences in model size. For instance, a smaller model like MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base (86.6M parameters). In light of this, we propose COCA, a Cross-Model Co-Learning framework for TTA, which mainly consists of two main strategies. 1) Co-adaptation adaptively integrates complementary knowledge from other models throughout the TTA process, reducing individual model biases. 2) Self-adaptation enhances each model's unique strengths via unsupervised learning, enabling diverse adaptation to the target domain. Extensive experiments show that COCA, which can also serve as a plug-and-play module, significantly boosts existing SOTAs, on models with various sizes--including ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example, with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy on ImageNet-C from 51.7% to 64.5%. The code is publicly available at https://github.com/ycarobot/COCA.",
      "authors": [
        "Chang'an Yi",
        "Xiaohui Deng",
        "Guohao Chen",
        "Yan Zhou",
        "Qinghua Lu",
        "Shuaicheng Niu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:54:50+00:00",
          "link": "https://arxiv.org/abs/2506.23724v1",
          "size": "531kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T16:23:39+00:00",
          "link": "https://arxiv.org/abs/2506.23724v2",
          "size": "531kb",
          "version": "v2"
        }
      ],
      "title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23724",
        "HTML": "https://arxiv.org/html/2506.23724v2",
        "PDF": "https://arxiv.org/pdf/2506.23724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about test-time adaptation through cross-model co-learning, focusing on model adaptation and performance but not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09102",
      "abstract": "Diffusion-based models, widely used in text-to-image generation, have proven effective in 2D representation learning. Recently, this framework has been extended to 3D self-supervised learning by constructing a conditional point generator for enhancing 3D representations. However, its performance remains constrained by the 3D diffusion model, which is trained on the available 3D datasets with limited size. We hypothesize that the robust capabilities of text-to-image diffusion models, particularly Stable Diffusion (SD), which is trained on large-scale datasets, can help overcome these limitations. To investigate this hypothesis, we propose PointSD, a framework that leverages the SD model for 3D self-supervised learning. By replacing the SD model's text encoder with a 3D encoder, we train a point-to-image diffusion model that allows point clouds to guide the denoising of rendered noisy images. With the trained point-to-image diffusion model, we use noise-free images as the input and point clouds as the condition to extract SD features. Next, we train a 3D backbone by aligning its features with these SD features, thereby facilitating direct semantic learning. Comprehensive experiments on downstream point cloud tasks and ablation studies demonstrate that the SD model can enhance point cloud self-supervised learning. Code is publicly available at https://github.com/wdttt/PointSD.",
      "authors": [
        "Yiyang Chen",
        "Shanshan Zhao",
        "Lunhao Duan",
        "Changxing Ding",
        "Dacheng Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:20:07+00:00",
          "link": "https://arxiv.org/abs/2507.09102v1",
          "size": "21729kb",
          "version": "v1"
        }
      ],
      "title": "Harnessing Text-to-Image Diffusion Models for Point Cloud Self-Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09102",
        "HTML": "https://arxiv.org/html/2507.09102v1",
        "PDF": "https://arxiv.org/pdf/2507.09102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for 3D self-supervised learning using text-to-image diffusion models, without focusing on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10005",
      "abstract": "In recent years, graph-based machine learning techniques, such as reinforcement learning and graph neural networks, have garnered significant attention. While some recent studies have started to explore the relationship between the graph structure of neural networks and their predictive performance, they often limit themselves to a narrow range of model networks, particularly lacking mesoscale structures such as communities. Our work advances this area by conducting a more comprehensive investigation, incorporating realistic network structures characterized by heterogeneous degree distributions and community structures, which are typical characteristics of many real networks. These community structures offer a nuanced perspective on network architecture. Our analysis employs model networks such as random and scale-free networks, alongside a comparison with a biological neural network and its subsets for more detailed analysis. We examine the impact of these structural attributes on the performance of image classification tasks. Our findings reveal that structural properties do affect performance to some extent. Specifically, networks featuring coherent, densely interconnected communities demonstrate enhanced learning capabilities. The comparison with the biological neural network emphasizes the relevance of our findings to real-world structures, suggesting an intriguing connection worth further exploration. This study contributes meaningfully to network science and machine learning, providing insights that could inspire the design of more biologically informed neural networks.",
      "authors": [
        "Yash Arya",
        "Sang Hoon Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:39:19+00:00",
          "link": "https://arxiv.org/abs/2507.10005v1",
          "size": "767kb",
          "version": "v1"
        }
      ],
      "title": "Effects of structural properties of neural networks on machine learning performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10005",
        "HTML": "https://arxiv.org/html/2507.10005v1",
        "PDF": "https://arxiv.org/pdf/2507.10005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies the effects of structural properties of neural networks on their performance and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10546",
      "abstract": "Neural Disjunctive Normal Form (DNF) based models are powerful and interpretable approaches to neuro-symbolic learning and have shown promising results in classification and reinforcement learning settings without prior knowledge of the tasks. However, their performance is degraded by the thresholding of the post-training symbolic translation process. We show here that part of the performance degradation during translation is due to its failure to disentangle the learned knowledge represented in the form of the networks' weights. We address this issue by proposing a new disentanglement method; by splitting nodes that encode nested rules into smaller independent nodes, we are able to better preserve the models' performance. Through experiments on binary, multiclass, and multilabel classification tasks (including those requiring predicate invention), we demonstrate that our disentanglement method provides compact and interpretable logical representations for the neural DNF-based models, with performance closer to that of their pre-translation counterparts. Our code is available at https://github.com/kittykg/disentangling-ndnf-classification.",
      "authors": [
        "Kexin Gu Baugh",
        "Vincent Perreault",
        "Matthew Baugh",
        "Luke Dickens",
        "Katsumi Inoue",
        "Alessandra Russo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:33+00:00",
          "link": "https://arxiv.org/abs/2507.10546v1",
          "size": "354kb",
          "version": "v1"
        }
      ],
      "title": "Disentangling Neural Disjunctive Normal Form Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10546",
        "HTML": "https://arxiv.org/html/2507.10546v1",
        "PDF": "https://arxiv.org/pdf/2507.10546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a new disentanglement method for neural DNF models, and focuses on classification tasks, without any relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.14530",
      "abstract": "Centralized version control systems (VCS) are vital for software development but pose risks of data loss and ownership disputes. While blockchain offers a decentralized alternative, existing solutions are often hindered by high latency, compromising the real-time collaboration essential for modern workflows. This study introduces a novel hybrid architecture combining the security of the Ethereum blockchain and the InterPlanetary File System (IPFS) with two key contributions: 1) Shamir's Secret Sharing (SSS) to create a trust-minimized model for key distribution, and 2) an authoritative-first, optimistic-fallback retrieval protocol utilizing a temporary middleware to decouple the user experience from blockchain confirmation delays. We implemented a full prototype and conducted a comprehensive performance evaluation on the public Sepolia testnet. Our results demonstrate that this architecture not only provides a secure, auditable, and resilient platform for source code hosting but also achieves highly competitive user-perceived performance. Our user-perceived push time reduces submission latency by up to 49% compared to a standard git push for common repository sizes, proving that a well-designed decentralized VCS can balance the core tenets of security and decentralization with the practical need for speed and efficiency.",
      "authors": [
        "Md. Rafid Haque",
        "Sakibul Islam Munna",
        "Sabbir Ahmed",
        "Md. Tahmid Islam",
        "Md Mehedi Hassan Onik",
        "and A.B.M. Ashikur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-22T16:57:38+00:00",
          "link": "https://arxiv.org/abs/2409.14530v1",
          "size": "1090kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T06:27:36+00:00",
          "link": "https://arxiv.org/abs/2409.14530v2",
          "size": "861kb",
          "version": "v2"
        }
      ],
      "title": "An Integrated Blockchain and IPFS Solution for Secure and Efficient Source Code Repository Hosting using Middleman Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14530",
        "HTML": "https://arxiv.org/html/2409.14530v2",
        "PDF": "https://arxiv.org/pdf/2409.14530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This is about secure source code repository hosting with blockchain and IPFS, unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05201",
      "abstract": "Artificial intelligence (AI) has significant potential in healthcare applications, but its training and deployment faces challenges due to healthcare's diverse data, complex tasks, and the need to preserve privacy. Foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications. We introduce MedGemma, a collection of medical vision-language foundation models based on Gemma 3 4B and 27B. MedGemma demonstrates advanced medical understanding and reasoning on images and text, significantly exceeding the performance of similar-sized generative models and approaching the performance of task-specific models, while maintaining the general capabilities of the Gemma 3 base models. For out-of-distribution tasks, MedGemma achieves 2.6-10% improvement on medical multimodal question answering, 15.5-18.1% improvement on chest X-ray finding classification, and 10.8% improvement on agentic evaluations compared to the base models. Fine-tuning MedGemma further improves performance in subdomains, reducing errors in electronic health record information retrieval by 50% and reaching comparable performance to existing specialized state-of-the-art methods for pneumothorax classification and histopathology patch classification. We additionally introduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP. MedSigLIP powers the visual understanding capabilities of MedGemma and as an encoder achieves comparable or better performance than specialized medical image encoders. Taken together, the MedGemma collection provides a strong foundation of medical image and text capabilities, with potential to significantly accelerate medical research and development of downstream applications. The MedGemma collection, including tutorials and model weights, can be found at https://goo.gle/medgemma.",
      "authors": [
        "Andrew Sellergren",
        "Sahar Kazemzadeh",
        "Tiam Jaroensri",
        "Atilla Kiraly",
        "Madeleine Traverse",
        "Timo Kohlberger",
        "Shawn Xu",
        "Fayaz Jamil",
        "C\\'ian Hughes",
        "Charles Lau",
        "Justin Chen",
        "Fereshteh Mahvar",
        "Liron Yatziv",
        "Tiffany Chen",
        "Bram Sterling",
        "Stefanie Anna Baby",
        "Susanna Maria Baby",
        "Jeremy Lai",
        "Samuel Schmidgall",
        "Lu Yang",
        "Kejia Chen",
        "Per Bjornsson",
        "Shashir Reddy",
        "Ryan Brush",
        "Kenneth Philbrick",
        "Mercy Asiedu",
        "Ines Mezerreg",
        "Howard Hu",
        "Howard Yang",
        "Richa Tiwari",
        "Sunny Jansen",
        "Preeti Singh",
        "Yun Liu",
        "Shekoofeh Azizi",
        "Aishwarya Kamath",
        "Johan Ferret",
        "Shreya Pathak",
        "Nino Vieillard",
        "Ramona Merhej",
        "Sarah Perrin",
        "Tatiana Matejovicova",
        "Alexandre Ram\\'e",
        "Morgane Riviere",
        "Louis Rouillard",
        "Thomas Mesnard",
        "Geoffrey Cideron",
        "Jean-bastien Grill",
        "Sabela Ramos",
        "Edouard Yvinec",
        "Michelle Casbon",
        "Elena Buchatskaya",
        "Jean-Baptiste Alayrac",
        "Dmitry Lepikhin",
        "Vlad Feinberg",
        "Sebastian Borgeaud",
        "Alek Andreev",
        "Cassidy Hardin",
        "Robert Dadashi",
        "L\\'eonard Hussenot",
        "Armand Joulin",
        "Olivier Bachem",
        "Yossi Matias",
        "Katherine Chou",
        "Avinatan Hassidim",
        "Kavi Goel",
        "Clement Farabet",
        "Joelle Barral",
        "Tris Warkentin",
        "Jonathon Shlens",
        "David Fleet",
        "Victor Cotruta",
        "Omar Sanseviero",
        "Gus Martins",
        "Phoebe Kirk",
        "Anand Rao",
        "Shravya Shetty",
        "David F. Steiner",
        "Can Kirmizibayrak",
        "Rory Pilgrim",
        "Daniel Golden",
        "Lin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T17:01:44+00:00",
          "link": "https://arxiv.org/abs/2507.05201v1",
          "size": "1982kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:08:06+00:00",
          "link": "https://arxiv.org/abs/2507.05201v2",
          "size": "1928kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T19:13:40+00:00",
          "link": "https://arxiv.org/abs/2507.05201v3",
          "size": "1928kb",
          "version": "v3"
        }
      ],
      "title": "MedGemma Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05201",
        "HTML": "https://arxiv.org/html/2507.05201v3",
        "PDF": "https://arxiv.org/pdf/2507.05201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces MedGemma, focusing on healthcare applications of AI, and discusses fine-tuning for medical tasks. However, it doesn't emphasize the processing or creation of training data itself."
      },
      "models": [
        {
          "model_path": "unsloth/medgemma-27b-it-GGUF",
          "downloads": "2644",
          "likes": "7",
          "trending_score": "7.0",
          "link": "https://huggingface.co/unsloth/medgemma-27b-it-GGUF"
        },
        {
          "model_path": "unsloth/medgemma-4b-it-GGUF",
          "downloads": "13339",
          "likes": "32",
          "trending_score": "4.0",
          "link": "https://huggingface.co/unsloth/medgemma-4b-it-GGUF"
        },
        {
          "model_path": "unsloth/medgemma-27b-it",
          "downloads": "50",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/unsloth/medgemma-27b-it"
        },
        {
          "model_path": "google/medgemma-27b-it",
          "downloads": "1303",
          "likes": "90",
          "trending_score": "90.0",
          "link": "https://huggingface.co/google/medgemma-27b-it"
        },
        {
          "model_path": "google/medgemma-4b-it",
          "downloads": "89571",
          "likes": "477",
          "trending_score": "46.0",
          "link": "https://huggingface.co/google/medgemma-4b-it"
        },
        {
          "model_path": "google/medsiglip-448",
          "downloads": "1618",
          "likes": "41",
          "trending_score": "41.0",
          "link": "https://huggingface.co/google/medsiglip-448"
        },
        {
          "model_path": "unsloth/medgemma-4b-it",
          "downloads": "2165",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/unsloth/medgemma-4b-it"
        },
        {
          "model_path": "gabriellarson/medgemma-27b-it-GGUF",
          "downloads": "431",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/gabriellarson/medgemma-27b-it-GGUF"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10321",
      "abstract": "The aerospace industry has experienced significant transformations over the last decade, driven by technological advancements and innovative solutions in goods and personal transportation. This evolution has spurred the emergence of numerous start-ups that now face challenges traditionally encountered by established aerospace companies. Among these challenges is the efficient processing of digital intra-device communication interfaces for onboard equipment - a critical component for ensuring seamless system integration and functionality. Addressing this challenge requires solutions that emphasize clear and consistent interface descriptions, automation of processes, and reduced labor-intensive efforts.\n  This paper presents a novel process and toolchain designed to streamline the development of digital interfaces and onboard software, which our team has successfully applied in several completed projects. The proposed approach focuses on automation and flexibility while maintaining compliance with design assurance requirements.",
      "authors": [
        "Viktor Sinitsyn",
        "Nils Schlautmann",
        "Florian Schwaiger",
        "Florian Holzapfel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:30:06+00:00",
          "link": "https://arxiv.org/abs/2507.10321v1",
          "size": "3288kb",
          "version": "v1"
        }
      ],
      "title": "Streamlined Airborne Software Development for Large UAVs: From Unified Data Collection to Automated Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10321",
        "HTML": "https://arxiv.org/html/2507.10321v1",
        "PDF": "https://arxiv.org/pdf/2507.10321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the development and automation of airborne software for UAVs focusing on communication interfaces, which does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10547",
      "abstract": "Visual tokenizers are pivotal in multimodal large models, acting as bridges between continuous inputs and discrete tokens. Nevertheless, training high-compression-rate VQ-VAEs remains computationally demanding, often necessitating thousands of GPU hours. This work demonstrates that a pre-trained VAE can be efficiently transformed into a VQ-VAE by controlling quantization noise within the VAE's tolerance threshold. We present \\textbf{Quantize-then-Rectify (ReVQ)}, a framework leveraging pre-trained VAEs to enable rapid VQ-VAE training with minimal computational overhead. By integrating \\textbf{channel multi-group quantization} to enlarge codebook capacity and a \\textbf{post rectifier} to mitigate quantization errors, ReVQ compresses ImageNet images into at most 512 tokens while sustaining competitive reconstruction quality (rFID = 1.06). Significantly, ReVQ reduces training costs by over two orders of magnitude relative to state-of-the-art approaches: ReVQ finishes full training on a single NVIDIA 4090 in approximately 22 hours, whereas comparable methods require 4.5 days on 32 A100 GPUs. Experimental results show that ReVQ achieves superior efficiency-reconstruction trade-offs.",
      "authors": [
        "Borui Zhang",
        "Qihang Rao",
        "Wenzhao Zheng",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:41+00:00",
          "link": "https://arxiv.org/abs/2507.10547v1",
          "size": "6623kb",
          "version": "v1"
        }
      ],
      "title": "Quantize-then-Rectify: Efficient VQ-VAE Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10547",
        "HTML": "https://arxiv.org/html/2507.10547v1",
        "PDF": "https://arxiv.org/pdf/2507.10547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on efficient VQ-VAE training for visual tokenizers in multimodal models and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07625",
      "abstract": "Training-free conditional generation based on flow matching aims to leverage pre-trained unconditional flow matching models to perform conditional generation without retraining. Recently, a successful training-free conditional generation approach incorporates conditions via posterior sampling, which relies on the availability of a score function in the unconditional diffusion model. However, flow matching models do not possess an explicit score function, rendering such a strategy inapplicable. Approximate posterior sampling for flow matching has been explored, but it is limited to linear inverse problems. In this paper, we propose Flow Matching-based Posterior Sampling (FMPS) to expand its application scope. We introduce a correction term by steering the velocity field. This correction term can be reformulated to incorporate a surrogate score function, thereby bridging the gap between flow matching models and score-based posterior sampling. Hence, FMPS enables the posterior sampling to be adjusted within the flow matching framework. Further, we propose two practical implementations of the correction mechanism: one aimed at improving generation quality, and the other focused on computational efficiency. Experimental results on diverse conditional generation tasks demonstrate that our method achieves superior generation quality compared to existing state-of-the-art approaches, validating the effectiveness and generality of FMPS.",
      "authors": [
        "Kaiyu Song",
        "Hanjiang Lai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T08:14:39+00:00",
          "link": "https://arxiv.org/abs/2411.07625v1",
          "size": "6467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T03:46:26+00:00",
          "link": "https://arxiv.org/abs/2411.07625v2",
          "size": "2554kb",
          "version": "v2"
        }
      ],
      "title": "Unraveling the Connections between Flow Matching and Diffusion Probabilistic Models in Training-free Conditional Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07625",
        "HTML": "https://arxiv.org/html/2411.07625v2",
        "PDF": "https://arxiv.org/pdf/2411.07625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses conditional generation and the development of flow matching models, without a focus on LLM training data processing or enhancement."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.13766",
      "abstract": "The combination of Large Language Models (LLM) and Automatic Speech Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can serve as a powerful personalized assistant to enable audio-based interaction for users. Compared to text-based interaction, edge ASR-LLM allows accessible and natural audio interactions. Unfortunately, existing ASR-LLM models are mainly trained in high-performance computing environments and produce substantial model weights, making them difficult to deploy on edge devices. More importantly, to better serve users' personalized needs, the ASR-LLM must be able to learn from each distinct user, given that audio input often contains highly personalized characteristics that necessitate personalized on-device training. Since individually fine-tuning the ASR or LLM often leads to suboptimal results due to modality-specific limitations, end-to-end training ensures seamless integration of audio features and language understanding (cross-modal alignment), ultimately enabling a more personalized and efficient adaptation on edge devices. However, due to the complex training requirements and substantial computational demands of existing approaches, cross-modal alignment between ASR audio and LLM can be challenging on edge devices. In this work, we propose a resource-efficient cross-modal alignment framework that bridges ASR and LLMs on edge devices to handle personalized audio input. Our framework enables efficient ASR-LLM alignment on resource-constrained devices like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while improving the alignment quality by more than 50\\%. To the best of our knowledge, this is the first work to study efficient ASR-LLM alignment on resource-constrained edge devices.",
      "authors": [
        "Ruiyang Qin",
        "Dancheng Liu",
        "Gelei Xu",
        "Zheyu Yan",
        "Chenhui Xu",
        "Yuting Hu",
        "Shaocong Wang",
        "X. Sharon Hu",
        "Jinjun Xiong",
        "Yiyu Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T00:29:58+00:00",
          "link": "https://arxiv.org/abs/2411.13766v1",
          "size": "580kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T05:12:26+00:00",
          "link": "https://arxiv.org/abs/2411.13766v2",
          "size": "580kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T21:56:53+00:00",
          "link": "https://arxiv.org/abs/2411.13766v3",
          "size": "572kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T21:47:39+00:00",
          "link": "https://arxiv.org/abs/2411.13766v4",
          "size": "572kb",
          "version": "v4"
        }
      ],
      "title": "Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13766",
        "HTML": "https://arxiv.org/html/2411.13766v4",
        "PDF": "https://arxiv.org/pdf/2411.13766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses automatic speech recognition and large language model alignment, mainly focusing on resource-efficient training on edge devices rather than training data processing for LLMs."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Automatic Speech Recognition (ASR)",
        "cross-modal alignment",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02951",
      "abstract": "We introduce KodCode, a synthetic dataset that addresses the persistent challenge of acquiring high-quality, verifiable training data across diverse difficulties and domains for training Large Language Models for coding. Existing code-focused resources typically fail to ensure either the breadth of coverage (e.g., spanning simple coding tasks to advanced algorithmic problems) or verifiable correctness (e.g., unit tests). In contrast, KodCode comprises question-solution-test triplets that are systematically validated via a self-verification procedure. Our pipeline begins by synthesizing a broad range of coding questions, then generates solutions and test cases with additional attempts allocated to challenging problems. Finally, post-training data synthesis is done by rewriting questions into diverse formats and generating responses under a test-based reject sampling procedure from a reasoning model (DeepSeek R1). This pipeline yields a large-scale, robust and diverse coding dataset. KodCode is suitable for supervised fine-tuning and the paired unit tests also provide great potential for RL tuning. Fine-tuning experiments on coding benchmarks (HumanEval(+), MBPP(+), BigCodeBench, and LiveCodeBench) demonstrate that KodCode-tuned models achieve state-of-the-art performance, surpassing models like Qwen2.5-Coder-32B-Instruct and DeepSeek-R1-Distill-Llama-70B.",
      "authors": [
        "Zhangchen Xu",
        "Yang Liu",
        "Yueqin Yin",
        "Mingyuan Zhou",
        "Radha Poovendran"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T19:17:36+00:00",
          "link": "https://arxiv.org/abs/2503.02951v1",
          "size": "6515kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T02:08:21+00:00",
          "link": "https://arxiv.org/abs/2503.02951v2",
          "size": "2505kb",
          "version": "v2"
        }
      ],
      "title": "KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02951",
        "HTML": "https://arxiv.org/html/2503.02951v2",
        "PDF": "https://arxiv.org/pdf/2503.02951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces KodCode, a synthetic dataset with detailed data processing steps for coding tasks. It enhances training data quality for LLMs by including verifiable question-solution-test triplets, relevant for training data processing."
      },
      "datasets": [
        {
          "dataset_name": "KodCode/KodCode-V1",
          "downloads": "642",
          "likes": "84",
          "link": "https://huggingface.co/datasets/KodCode/KodCode-V1"
        },
        {
          "dataset_name": "KodCode/KodCode-V1-SFT-R1",
          "downloads": "437",
          "likes": "28",
          "link": "https://huggingface.co/datasets/KodCode/KodCode-V1-SFT-R1"
        },
        {
          "dataset_name": "KodCode/KodCode-V1-SFT-4o",
          "downloads": "381",
          "likes": "6",
          "link": "https://huggingface.co/datasets/KodCode/KodCode-V1-SFT-4o"
        },
        {
          "dataset_name": "KodCode/KodCode-Light-RL-10K",
          "downloads": "175",
          "likes": "3",
          "link": "https://huggingface.co/datasets/KodCode/KodCode-Light-RL-10K"
        }
      ],
      "tasks": [
        "HumanEval",
        "mbpp"
      ],
      "repo_urls": [
        "https://github.com/KodCode-AI/kodcode"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.03982",
      "abstract": "In a Hilbert space, we study the strong convergence of alternating projections between two inconsistent affine subspaces with varying relaxation on one side. New convergence results are obtained by seeing the alternating projections as a Landweber iteration with variable steps.",
      "authors": [
        "Nguyen T. Thao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Functional Analysis (math.FA)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T21:10:23+00:00",
          "link": "https://arxiv.org/abs/2505.03982v1",
          "size": "6kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T11:54:19+00:00",
          "link": "https://arxiv.org/abs/2505.03982v2",
          "size": "41kb",
          "version": "v2"
        }
      ],
      "title": "Alternating projections between two inconsistent affine subspaces with varying relaxation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03982",
        "HTML": "https://arxiv.org/html/2505.03982v2",
        "PDF": "https://arxiv.org/pdf/2505.03982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates alternating projections in affine subspaces within a Hilbert space, focusing on convergence results. It does not involve LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04959",
      "abstract": "Video-to-audio (V2A) generation shows great potential in fields such as film production. Despite significant advances, current V2A methods relying on global video information struggle with complex scenes and generating audio tailored to specific objects. To address these limitations, we introduce Hear-Your-Click, an interactive V2A framework enabling users to generate sounds for specific objects by clicking on the frame. To achieve this, we propose Object-aware Contrastive Audio-Visual Fine-tuning (OCAV) with a Mask-guided Visual Encoder (MVE) to obtain object-level visual features aligned with audio. Furthermore, we tailor two data augmentation strategies, Random Video Stitching (RVS) and Mask-guided Loudness Modulation (MLM), to enhance the model's sensitivity to segmented objects. To measure audio-visual correspondence, we designed a new evaluation metric, the CAV score. Extensive experiments demonstrate that our framework offers more precise control and improves generation performance across various metrics. Project Page: https://github.com/SynapGrid/Hear-Your-Click",
      "authors": [
        "Yingshan Liang",
        "Keyu Fan",
        "Zhicheng Du",
        "Yiran Wang",
        "Qingyang Shi",
        "Xinyu Zhang",
        "Jiasheng Lu",
        "Peiwu Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:01:50+00:00",
          "link": "https://arxiv.org/abs/2507.04959v1",
          "size": "6127kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:31:19+00:00",
          "link": "https://arxiv.org/abs/2507.04959v2",
          "size": "6127kb",
          "version": "v2"
        }
      ],
      "title": "Hear-Your-Click: Interactive Object-Specific Video-to-Audio Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04959",
        "HTML": "https://arxiv.org/html/2507.04959v2",
        "PDF": "https://arxiv.org/pdf/2507.04959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for object-specific video-to-audio generation, with no discussion on LLM training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07223",
      "abstract": "Modern AI workloads such as large language models (LLMs) and retrieval-augmented generation (RAG) impose severe demands on memory, communication bandwidth, and resource flexibility. Traditional GPU-centric architectures struggle to scale due to growing inter-GPU communication overheads. This report introduces key AI concepts and explains how Transformers revolutionized data representation in LLMs. We analyze large-scale AI hardware and data center designs, identifying scalability bottlenecks in hierarchical systems. To address these, we propose a modular data center architecture based on Compute Express Link (CXL) that enables disaggregated scaling of memory, compute, and accelerators. We further explore accelerator-optimized interconnects-collectively termed XLink (e.g., UALink, NVLink, NVLink Fusion)-and introduce a hybrid CXL-over-XLink design to reduce long-distance data transfers while preserving memory coherence. We also propose a hierarchical memory model that combines local and pooled memory, and evaluate lightweight CXL implementations, HBM, and silicon photonics for efficient scaling. Our evaluations demonstrate improved scalability, throughput, and flexibility in AI infrastructure.",
      "authors": [
        "Myoungsoo Jung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:57:04+00:00",
          "link": "https://arxiv.org/abs/2507.07223v1",
          "size": "23292kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T15:21:59+00:00",
          "link": "https://arxiv.org/abs/2507.07223v2",
          "size": "23293kb",
          "version": "v2"
        }
      ],
      "title": "Compute Can't Handle the Truth: Why Communication Tax Prioritizes Memory and Interconnects in Modern AI Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07223",
        "PDF": "https://arxiv.org/pdf/2507.07223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on AI infrastructure and hardware optimization rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08851",
      "abstract": "Understanding open-world semantics is critical for robotic planning and control, particularly in unstructured outdoor environments. Current vision-language mapping approaches rely on object-centric segmentation priors, which often fail outdoors due to semantic ambiguities and indistinct semantic class boundaries. We propose OTAS - an Open-vocabulary Token Alignment method for Outdoor Segmentation. OTAS overcomes the limitations of open-vocabulary segmentation models by extracting semantic structure directly from the output tokens of pretrained vision models. By clustering semantically similar structures across single and multiple views and grounding them in language, OTAS reconstructs a geometrically consistent feature field that supports open-vocabulary segmentation queries. Our method operates zero-shot, without scene-specific fine-tuning, and runs at up to ~17 fps. OTAS provides a minor IoU improvement over fine-tuned and open-vocabulary 2D segmentation methods on the Off-Road Freespace Detection dataset. Our model achieves up to a 151% IoU improvement over open-vocabulary mapping methods in 3D segmentation on TartanAir. Real-world reconstructions demonstrate OTAS' applicability to robotic applications. The code and ROS node will be made publicly available upon paper acceptance.",
      "authors": [
        "Simon Schwaiger",
        "Stefan Thalhammer",
        "Wilfried W\\\"ober",
        "Gerald Steinbauer-Wagner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:49:03+00:00",
          "link": "https://arxiv.org/abs/2507.08851v1",
          "size": "5889kb",
          "version": "v1"
        }
      ],
      "title": "OTAS: Open-vocabulary Token Alignment for Outdoor Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08851",
        "HTML": "https://arxiv.org/html/2507.08851v1",
        "PDF": "https://arxiv.org/pdf/2507.08851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on semantic token alignment for outdoor segmentation in robotics, without contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09792",
      "abstract": "Computer-aided design (CAD) is the digital construction of 2D and 3D objects, and is central to a wide range of engineering and manufacturing applications like automobile and aviation. Despite its importance, CAD modeling remains largely a time-intensive, manual task. Recent works have attempted to automate this process with small transformer-based models and handcrafted CAD sequence representations. However, there has been little effort to leverage the potential of large language models (LLMs) for sequential CAD design. In this work, we introduce a new large-scale dataset of more than 170k CAD models annotated with high-quality, human-like descriptions generated with our pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs to generate CAD sequences represented in a JSON-based format from natural language descriptions, demonstrating the viability and effectiveness of this approach for text-conditioned CAD generation. Because simple metrics often fail to reflect the quality of generated objects, we introduce geometric and topological metrics based on sphericity, mean curvature, and Euler characteristic to provide richer structural insights. Our experiments and ablation studies on both synthetic and human-annotated data demonstrate that CADmium is able to automate CAD design, drastically speeding up the design of new objects. The dataset, code, and fine-tuned models are available online.",
      "authors": [
        "Prashant Govindarajan",
        "Davide Baldelli",
        "Jay Pathak",
        "Quentin Fournier",
        "Sarath Chandar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:11:53+00:00",
          "link": "https://arxiv.org/abs/2507.09792v1",
          "size": "17032kb",
          "version": "v1"
        }
      ],
      "title": "CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09792",
        "HTML": "https://arxiv.org/html/2507.09792v1",
        "PDF": "https://arxiv.org/pdf/2507.09792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a new large-scale dataset of CAD models, including detailed data processing steps to generate high-quality annotations with GPT-4.1, aligning strongly with data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10059",
      "abstract": "Large Language Models (LLM) have achieved remarkable performance across a large number of tasks, but face critical deployment and usage barriers due to substantial computational requirements. Model compression methods, which aim to reduce model size while preserving its capacity, are an important means to mitigate these issues. Promising approaches along these lines, such as structured pruning, typically require costly empirical search for optimal variants and may run the risk of ignoring better solutions. In this work we introduce GeLaCo, an evolutionary approach to LLM compression via layer collapse. Our approach supports an efficient exploration of the compression solution space via population-based search and a module-wise similarity fitness function capturing attention, feed-forward, and hidden state representations. GeLaCo also supports both single and multi-objective evolutionary compression search, establishing the first Pareto frontier along compression and quality axes. We evaluate GeLaCo solutions via both perplexity-based and generative evaluations over foundational and instruction-tuned models, outperforming state-of-the-art alternatives.",
      "authors": [
        "David Ponce",
        "Thierry Etchegoyhen",
        "Javier Del Ser"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:44:59+00:00",
          "link": "https://arxiv.org/abs/2507.10059v1",
          "size": "1267kb",
          "version": "v1"
        }
      ],
      "title": "GeLaCo: An Evolutionary Approach to Layer Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10059",
        "HTML": "https://arxiv.org/html/2507.10059v1",
        "PDF": "https://arxiv.org/pdf/2507.10059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model compression method for LLMs, focusing on reducing model size rather than processing or handling LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.13613",
      "abstract": "4D Gaussian Splatting (4DGS) has recently emerged as a promising technique for capturing complex dynamic 3D scenes with high fidelity. It utilizes a 4D Gaussian representation and a GPU-friendly rasterizer, enabling rapid rendering speeds. Despite its advantages, 4DGS faces significant challenges, notably the requirement of millions of 4D Gaussians, each with extensive associated attributes, leading to substantial memory and storage cost. This paper introduces a memory-efficient framework for 4DGS. We streamline the color attribute by decomposing it into a per-Gaussian direct color component with only 3 parameters and a shared lightweight alternating current color predictor. This approach eliminates the need for spherical harmonics coefficients, which typically involve up to 144 parameters in classic 4DGS, thereby creating a memory-efficient 4D Gaussian representation. Furthermore, we introduce an entropy-constrained Gaussian deformation technique that uses a deformation field to expand the action range of each Gaussian and integrates an opacity-based entropy loss to limit the number of Gaussians, thus forcing our model to use as few Gaussians as possible to fit a dynamic scene well. With simple half-precision storage and zip compression, our framework achieves a storage reduction by approximately 190$\\times$ and 125$\\times$ on the Technicolor and Neural 3D Video datasets, respectively, compared to the original 4DGS. Meanwhile, it maintains comparable rendering speeds and scene representation quality, setting a new standard in the field. Code is available at https://github.com/Xinjie-Q/MEGA.",
      "authors": [
        "Xinjie Zhang",
        "Zhening Liu",
        "Yifan Zhang",
        "Xingtong Ge",
        "Dailan He",
        "Tongda Xu",
        "Yan Wang",
        "Zehong Lin",
        "Shuicheng Yan",
        "Jun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T14:47:08+00:00",
          "link": "https://arxiv.org/abs/2410.13613v1",
          "size": "10449kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T14:07:34+00:00",
          "link": "https://arxiv.org/abs/2410.13613v2",
          "size": "3859kb",
          "version": "v2"
        }
      ],
      "title": "MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13613",
        "HTML": "https://arxiv.org/html/2410.13613v2",
        "PDF": "https://arxiv.org/pdf/2410.13613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a memory-efficient framework for 4D Gaussian Splatting, which is a technique for rendering dynamic 3D scenes. It does not address LLM training data processing or creation."
      },
      "tasks": [
        "Attribute"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.06513",
      "abstract": "Robot navigation in dynamic, crowded environments poses a significant challenge due to the inherent uncertainties in the obstacle model. In this work, we propose a risk-adaptive approach based on the Conditional Value-at-Risk Barrier Function (CVaR-BF), where the risk level is automatically adjusted to accept the minimum necessary risk, achieving a good performance in terms of safety and optimization feasibility under uncertainty. Additionally, we introduce a dynamic zone-based barrier function which characterizes the collision likelihood by evaluating the relative state between the robot and the obstacle. By integrating risk adaptation with this new function, our approach adaptively expands the safety margin, enabling the robot to proactively avoid obstacles in highly dynamic environments. Comparisons and ablation studies demonstrate that our method outperforms existing social navigation approaches, and validate the effectiveness of our proposed framework.",
      "authors": [
        "Xinyi Wang",
        "Taekyung Kim",
        "Bardh Hoxha",
        "Georgios Fainekos and Dimitra Panagou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T01:23:44+00:00",
          "link": "https://arxiv.org/abs/2504.06513v1",
          "size": "1166kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T15:20:52+00:00",
          "link": "https://arxiv.org/abs/2504.06513v2",
          "size": "633kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T12:45:35+00:00",
          "link": "https://arxiv.org/abs/2504.06513v3",
          "size": "636kb",
          "version": "v3"
        }
      ],
      "title": "Safe Navigation in Uncertain Crowded Environments Using Risk Adaptive CVaR Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06513",
        "HTML": "https://arxiv.org/html/2504.06513v3",
        "PDF": "https://arxiv.org/pdf/2504.06513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with robot navigation and risk adaptive barrier functions, which are outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04209",
      "abstract": "We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and G\\'acs-K\\\"orner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).",
      "authors": [
        "Anderson de Andrade"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T01:39:00+00:00",
          "link": "https://arxiv.org/abs/2507.04209v1",
          "size": "6kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:03:51+00:00",
          "link": "https://arxiv.org/abs/2507.04209v2",
          "size": "4kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T17:20:12+00:00",
          "link": "https://arxiv.org/abs/2507.04209v3",
          "size": "5kb",
          "version": "v3"
        }
      ],
      "title": "Mutual Information Bounds for Lossy Common Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04209",
        "HTML": "https://arxiv.org/html/2507.04209v3",
        "PDF": "https://arxiv.org/pdf/2507.04209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with mutual information bounds in lossless common information and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08906",
      "abstract": "Physics-informed machine learning (PIML) is an emerging framework that integrates physical knowledge into machine learning models. This physical prior often takes the form of a partial differential equation (PDE) system that the regression function must satisfy. In the first part of this dissertation, we analyze the statistical properties of PIML methods. In particular, we study the properties of physics-informed neural networks (PINNs) in terms of approximation, consistency, overfitting, and convergence. We then show how PIML problems can be framed as kernel methods, making it possible to apply the tools of kernel ridge regression to better understand their behavior. In addition, we use this kernel formulation to develop novel physics-informed algorithms and implement them efficiently on GPUs. The second part explores industrial applications in forecasting energy signals during atypical periods. We present results from the Smarter Mobility challenge on electric vehicle charging occupancy and examine the impact of mobility on electricity demand. Finally, we introduce a physics-constrained framework for designing and enforcing constraints in time series, applying it to load forecasting and tourism forecasting in various countries.",
      "authors": [
        "Nathan Doum\\`eche"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:47:09+00:00",
          "link": "https://arxiv.org/abs/2507.08906v1",
          "size": "10197kb",
          "version": "v1"
        }
      ],
      "title": "Physics-informed machine learning: A mathematical framework with applications to time series forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08906",
        "PDF": "https://arxiv.org/pdf/2507.08906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses physics-informed machine learning frameworks, focusing on integrating physical knowledge into ML models and applications in time series forecasting. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09069",
      "abstract": "Given $n \\geq 3$, a combinatorial object called a \\textit{ pedigree } is defined using $3$-element subsets from $[n]$ obeying certain conditions. The convex hull of pedigrees is called the pedigree polytope for $n$. Pedigrees are in $1-1$ correspondence with Hamiltonian cycles. Properties of pedigrees, pedigree polytopes, adjacency structure of the graph of the pedigree polytope and their implication on the adjacency structure of the Symmetric Travelling Salesman problem (STSP) polytope have been studied earlier in the literature by the author.\n  The question: Given $X$, does it belong to the pedigree polytope for $n$? is called the membership problem. This article provides proof that the membership problem for pedigree polytopes can be solved efficiently. Due to the pedigree's stem property, we can check the membership problem sequentially for $ k \\in [4, n]$. One constructs a layered network, recursively, to check membership in the pedigree polytope. Proof of the proposed framework's validity is given. This article's significant and far-reaching contribution is that the membership problem has a strongly polynomial-time framework.\n  Since the polynomial solvability of the membership problem implies that one can solve efficiently any linear optimisation problem over the pedigree polytope. And a specific linear optimisation over the pedigree polytope (the multistage insertion formulation) solves the STSP.\n  The consequence of this result is that we have proof of $NP = P$. A recent book by the author entitled \\textit{Pedigree Polytopes} brings together published results on pedigrees and some new results, mainly in Chapters 5 and 6. The primary purpose of this article is to present the latest results from that book in a self-contained fashion so that experts can vet the same. Some of the proofs and presentation of concepts in this article are new.",
      "authors": [
        "Tiru Arthanari (Department of ISOM",
        "University of Auckland",
        "Auckland",
        "New Zealand)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:13:40+00:00",
          "link": "https://arxiv.org/abs/2507.09069v1",
          "size": "1219kb",
          "version": "v1"
        }
      ],
      "title": "On the Importance of Studying the Membership Problem for Pedigree Polytopes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09069",
        "HTML": "https://arxiv.org/html/2507.09069v1",
        "PDF": "https://arxiv.org/pdf/2507.09069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the mathematical study of pedigree polytopes and their properties, with no mention of LLM training data processing or dataset-related contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09070",
      "abstract": "Zero-shot voice conversion (VC) synthesizes speech in a target speaker's voice while preserving linguistic and paralinguistic content. However, timbre leakage-where source speaker traits persist-remains a challenge, especially in neural codec and LLM-based VC, where quantized representations entangle speaker identity with content. We introduce SemAlignVC, an architecture designed to prevent timbre leakage using SemAlign, a novel method that aligns text and audio representations to ensure speaker-independent semantic encoding. This disentangled representation conditions an autoregressive transformer for high-fidelity conversion without explicit speaker embeddings. Experiments show SemAlignVC significantly reduces timbre leakage, outperforming baselines in speaker timbre similarity, intelligibility, and naturalness, making it a robust, privacy-preserving, and generalizable VC solution. Audio samples can be accessed at https://shivammehta25.github.io/SemAlignVC/",
      "authors": [
        "Shivam Mehta",
        "Yingru Liu",
        "Zhenyu Tang",
        "Kainan Peng",
        "Vimal Manohar",
        "Shun Zhang",
        "Mike Seltzer",
        "Qing He",
        "Mingbo Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:14:07+00:00",
          "link": "https://arxiv.org/abs/2507.09070v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "SemAlignVC: Enhancing zero-shot timbre conversion using semantic alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09070",
        "HTML": "https://arxiv.org/html/2507.09070v1",
        "PDF": "https://arxiv.org/pdf/2507.09070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for zero-shot voice conversion using semantic alignment, but it does not focus on LLM training data processing or involve creating or improving datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09161",
      "abstract": "Large language models have shown a remarkable ability to extract meaning from unstructured data, offering new ways to interpret biomedical signals beyond traditional numerical methods. In this study, we present a matrix factorization framework for bioacoustic signal analysis which is enhanced by large language models. The focus is on separating bioacoustic signals that commonly overlap in clinical recordings, using matrix factorization to decompose the mixture into interpretable components. A large language model is then applied to the separated signals to associate distinct acoustic patterns with potential medical conditions such as cardiac rhythm disturbances or respiratory abnormalities. Recordings were obtained from a digital stethoscope applied to a clinical manikin to ensure a controlled and high-fidelity acquisition environment. This hybrid approach does not require labeled data or prior knowledge of source types, and it provides a more interpretable and accessible framework for clinical decision support. The method demonstrates promise for integration into future intelligent diagnostic tools.",
      "authors": [
        "Yasaman Torabi",
        "Shahram Shirani",
        "James P. Reilly"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T06:44:43+00:00",
          "link": "https://arxiv.org/abs/2507.09161v1",
          "size": "640kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models and Non-Negative Matrix Factorization for Bioacoustic Signal Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09161",
        "PDF": "https://arxiv.org/pdf/2507.09161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a framework for bioacoustic signal decomposition using matrix factorization and large language models. It does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09291",
      "abstract": "Floorplans provide a compact representation of the building's structure, revealing not only layout information but also detailed semantics such as the locations of windows and doors. However, contemporary floorplan localization techniques mostly focus on matching depth-based structural cues, ignoring the rich semantics communicated within floorplans. In this work, we introduce a semantic-aware localization framework that jointly estimates depth and semantic rays, consolidating over both for predicting a structural-semantic probability volume. Our probability volume is constructed in a coarse-to-fine manner: We first sample a small set of rays to obtain an initial low-resolution probability volume. We then refine these probabilities by performing a denser sampling only in high-probability regions and process the refined values for predicting a 2D location and orientation angle. We conduct an evaluation on two standard floorplan localization benchmarks. Our experiments demonstrate that our approach substantially outperforms state-of-the-art methods, achieving significant improvements in recall metrics compared to prior works. Moreover, we show that our framework can easily incorporate additional metadata such as room labels, enabling additional gains in both accuracy and efficiency.",
      "authors": [
        "Yuval Grader",
        "Hadar Averbuch-Elor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.09291v1",
          "size": "9674kb",
          "version": "v1"
        }
      ],
      "title": "Supercharging Floorplan Localization with Semantic Rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09291",
        "HTML": "https://arxiv.org/html/2507.09291v1",
        "PDF": "https://arxiv.org/pdf/2507.09291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a semantic-aware localization framework for floorplans and does not address LLM training data collection, processing, or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09463",
      "abstract": "Flying multiple quadrotors in close proximity presents a significant challenge due to complex aerodynamic interactions, particularly downwash effects that are known to destabilize vehicles and degrade performance. Traditionally, multi-quadrotor systems rely on conservative strategies, such as collision avoidance zones around the robot volume, to circumvent this effect. This restricts their capabilities by requiring a large volume for the operation of a multi-quadrotor system, limiting their applicability in dense environments. This work provides a comprehensive, data-driven analysis of the downwash effect, with a focus on characterizing, analyzing, and understanding forces, moments, and velocities in both single and multi-quadrotor configurations. We use measurements of forces and torques to characterize vehicle interactions, and particle image velocimetry (PIV) to quantify the spatial features of the downwash wake for a single quadrotor and an interacting pair of quadrotors. This data can be used to inform physics-based strategies for coordination, leverage downwash for optimized formations, expand the envelope of operation, and improve the robustness of multi-quadrotor control.",
      "authors": [
        "Anoop Kiran",
        "Nora Ayanian",
        "Kenneth Breuer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:00:15+00:00",
          "link": "https://arxiv.org/abs/2507.09463v1",
          "size": "9185kb",
          "version": "v1"
        }
      ],
      "title": "Influence of Static and Dynamic Downwash Interactions on Multi-Quadrotor Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09463",
        "PDF": "https://arxiv.org/pdf/2507.09463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes downwash effects in multi-quadrotor systems and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09884",
      "abstract": "Large language models (LLMs) increasingly rely on reinforcement learning (RL) to enhance their reasoning capabilities through feedback. A critical challenge is verifying the consistency of model-generated responses and reference answers, since these responses are often lengthy, diverse, and nuanced. Rule-based verifiers struggle with complexity, prompting the use of model-based verifiers. However, specialized verifiers lack flexibility, while general LLM judges can be inconsistent. Existing research primarily focuses on building better verifiers, yet a systematic evaluation of different types of verifiers' performance across domains remains lacking, severely constraining the reliable development of Reinforcement Learning with Verifiable Reward (RLVR). To address this, we propose VerifyBench--a cross-domain comprehensive benchmark for systematically evaluating verifiers. We construct 4,000 expert-level questions covering mathematics, physics, chemistry, and biology. Each question is equipped with reference answers and diverse responses. The reliability of the evaluation is ensured through a rigorous annotation process conducted by a multidisciplinary expert team. We design a four-dimensional experimental framework to comprehensively compare the performance boundaries of specialized verifiers and general LLMs under combined conditions of extracted answers vs. complete responses, and short vs. long outputs. Our evaluation uncovers fundamental trade-offs in verifiers: while specialized verifiers achieve leading accuracy, they exhibit deficiencies in recall; general models show stronger inclusivity but unstable precision. More importantly, we discover verifiers' high sensitivity to input structure and inherent limitations in cross-domain generalization, providing critical insights into the bottlenecks of current verifier technology.",
      "authors": [
        "Xuzhao Li and Xuchen Li and Shiyu Hu and Yongzhen Guo and Wentao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:45:24+00:00",
          "link": "https://arxiv.org/abs/2507.09884v1",
          "size": "5338kb",
          "version": "v1"
        }
      ],
      "title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09884",
        "HTML": "https://arxiv.org/html/2507.09884v1",
        "PDF": "https://arxiv.org/pdf/2507.09884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses benchmarking and evaluating reasoning verifiers for LLMs, but it does not address LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10123",
      "abstract": "We study the optimal placement of an unlimited-capacity battery in power grids under a centralized market model, where the independent system operator (ISO) aims to minimize total generation costs through load shifting. The optimal battery placement is not well understood by the existing literature, especially regarding the influence of network topology on minimizing generation costs. Our work starts with decomposing the Mixed-Integer Linear Programming (MILP) problem into a series of Linear Programming (LP) formulations. For power grids with sufficiently large generation capacity or tree topologies, we derive analytical cost expressions demonstrating that, under reasonable assumptions, the weighted degree is the only topological factor for optimal battery placement. We also discuss the minor impact of higher-order topological conditions on tree-topology networks. To find the localized nature of a single battery's impact, we establish that the relative cost-saving benefit of a single battery decreases as the network scales. Furthermore, we design a low-complexity algorithm for weakly-cyclic networks. Numerical experiments show that our algorithm is not only approximately 100 times faster than commercial solvers but also maintains high accuracy even when some theoretical assumptions are relaxed.",
      "authors": [
        "Ruotong Sun",
        "Ermin Wei and Lihui Yi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:07:16+00:00",
          "link": "https://arxiv.org/abs/2507.10123v1",
          "size": "1947kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Battery Placement in Power Grid",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10123",
        "HTML": "https://arxiv.org/html/2507.10123v1",
        "PDF": "https://arxiv.org/pdf/2507.10123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses battery placement in power grids using optimization algorithms, which is not related to LLM training data or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.09536",
      "abstract": "Many empirical networks originate from correlational data, arising in domains as diverse as psychology, neuroscience, genomics, microbiology, finance, and climate science. Specialized algorithms and theory have been developed in different application domains for working with such networks, as well as in statistics, network science, and computer science, often with limited communication between practitioners in different fields. This leaves significant room for cross-pollination across disciplines. A central challenge is that it is not always clear how to best transform correlation matrix data into networks for the application at hand, and probably the most widespread method, i.e., thresholding on the correlation value to create either unweighted or weighted networks, suffers from multiple problems. In this article, we review various methods of constructing and analyzing correlation networks, ranging from thresholding and its improvements to weighted networks, regularization, dynamic correlation networks, threshold-free approaches, comparison with null models, and more. Finally, we propose and discuss recommended practices and a variety of key open questions currently confronting this field.",
      "authors": [
        "Naoki Masuda",
        "Zachary M. Boyd",
        "Diego Garlaschelli",
        "Peter J. Mucha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-16T03:26:10+00:00",
          "link": "https://arxiv.org/abs/2311.09536v1",
          "size": "311kb",
          "version": "v1"
        },
        {
          "date": "2024-10-03T16:50:28+00:00",
          "link": "https://arxiv.org/abs/2311.09536v2",
          "size": "615kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T18:10:26+00:00",
          "link": "https://arxiv.org/abs/2311.09536v3",
          "size": "617kb",
          "version": "v3"
        }
      ],
      "title": "Introduction to correlation networks: Interdisciplinary approaches beyond thresholding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.09536",
        "HTML": "https://arxiv.org/html/2311.09536v3",
        "PDF": "https://arxiv.org/pdf/2311.09536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for constructing and analyzing correlation networks from empirical data but does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.01069",
      "abstract": "Image Quality Assessment (IQA) and Image Aesthetic Assessment (IAA) aim to simulate human subjective perception of image visual quality and aesthetic appeal. Despite distinct learning objectives, they have underlying interconnectedness due to consistent human assessment perception. In this paper, we propose Unified vision-language pre-training of Quality and Aesthetics (UniQA}), to extract useful and common representations from two tasks, thereby benefiting them simultaneously. However, the lack of text in the IQA datasets and the textual noise in the IAA datasets pose severe challenges for multimodal pre-training. To address this, we (1) utilize multimodal large language models (MLLMs) to generate high-quality text descriptions; (2) use the generated text for IAA as metadata to purify noisy IAA data. To effectively adapt the pre-trained UniQA to downstream tasks, we further propose a lightweight adapter that utilizes versatile cues to fully exploit the extensive knowledge of the pre-trained model. UniQA demonstrates high competitiveness in various image assessment tasks, including classical IQA and IAA tasks, few-label IQA, and other downstream tasks, showing promise as a foundational assessment model. Codes are available at https://github.com/zht8506/UniQA.",
      "authors": [
        "Hantao Zhou",
        "Longxiang Tang",
        "Rui Yang",
        "Guanyi Qin",
        "Yan Zhang",
        "Yutao Li",
        "Xiu Li",
        "Runze Hu",
        "Guangtao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-03T07:40:10+00:00",
          "link": "https://arxiv.org/abs/2406.01069v1",
          "size": "10320kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:31:45+00:00",
          "link": "https://arxiv.org/abs/2406.01069v2",
          "size": "2115kb",
          "version": "v2"
        }
      ],
      "title": "UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.01069",
        "HTML": "https://arxiv.org/html/2406.01069v2",
        "PDF": "https://arxiv.org/pdf/2406.01069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper involves generating text descriptions and purifying noisy data for multimodal pre-training, contributing to dataset improvement and training data processing in vision-language tasks."
      },
      "tasks": [
        "Image Quality Assessment"
      ],
      "repo_urls": [
        "https://github.com/zht8506/uniqa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02393",
      "abstract": "Chain-of-thought reasoning and scratchpads have emerged as critical tools for enhancing the computational capabilities of transformers. While theoretical results show that polynomial-length scratchpads can extend transformers' expressivity from $TC^0$ to $PTIME$, their required length remains poorly understood. Empirical evidence even suggests that transformers need scratchpads even for many problems in $TC^0$, such as Parity or Multiplication, challenging optimistic bounds derived from circuit complexity. In this work, we initiate the study of systematic lower bounds for the number of chain-of-thought steps across different algorithmic problems, in the hard-attention regime. We study a variety of algorithmic problems, and provide bounds that are tight up to logarithmic factors. Overall, these results contribute to emerging understanding of the power and limitations of chain-of-thought reasoning.",
      "authors": [
        "Alireza Amiri",
        "Xinting Huang",
        "Mark Rofin",
        "Michael Hahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T15:14:01+00:00",
          "link": "https://arxiv.org/abs/2502.02393v1",
          "size": "891kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T15:52:20+00:00",
          "link": "https://arxiv.org/abs/2502.02393v2",
          "size": "891kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T18:49:06+00:00",
          "link": "https://arxiv.org/abs/2502.02393v3",
          "size": "1173kb",
          "version": "v3"
        }
      ],
      "title": "Lower Bounds for Chain-of-Thought Reasoning in Hard-Attention Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02393",
        "HTML": "https://arxiv.org/html/2502.02393v3",
        "PDF": "https://arxiv.org/pdf/2502.02393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding the limits of chain-of-thought reasoning in transformers. It does not address data processing or engineering in the context of LLM training data."
      },
      "tasks": [
        "Hard Attention"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07998",
      "abstract": "LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.",
      "authors": [
        "Shitian Zhao",
        "Haoquan Zhang",
        "Shaoheng Lin",
        "Ming Li",
        "Qilong Wu",
        "Kaipeng Zhang",
        "Chen Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.07998v1",
          "size": "12300kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:36:19+00:00",
          "link": "https://arxiv.org/abs/2507.07998v2",
          "size": "12301kb",
          "version": "v2"
        }
      ],
      "title": "PyVision: Agentic Vision with Dynamic Tooling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07998",
        "PDF": "https://arxiv.org/pdf/2507.07998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses dynamic tooling and agentic vision with machine learning models, but does not address LLM training data processing or the creation of datasets in its methodology."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08979",
      "abstract": "We introduce Projection-based Reduction of Implicit Spurious bias in vision-language Models (PRISM), a new data-free and task-agnostic solution for bias mitigation in VLMs like CLIP. VLMs often inherit and amplify biases in their training data, leading to skewed predictions. PRISM is designed to debias VLMs without relying on predefined bias categories or additional external data. It operates in two stages: first, an LLM is prompted with simple class prompts to generate scene descriptions that contain spurious correlations. Next, PRISM uses our novel contrastive-style debiasing loss to learn a projection that maps the embeddings onto a latent space that minimizes spurious correlations while preserving the alignment between image and text embeddings.Extensive experiments demonstrate that PRISM outperforms current debiasing methods on the commonly used Waterbirds and CelebA datasets We make our code public at: https://github.com/MahdiyarMM/PRISM.",
      "authors": [
        "Mahdiyar Molahasani",
        "Azadeh Motamedi",
        "Michael Greenspan",
        "Il-Min Kim",
        "Ali Etemad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:24:58+00:00",
          "link": "https://arxiv.org/abs/2507.08979v1",
          "size": "438kb",
          "version": "v1"
        }
      ],
      "title": "PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided Embedding Projection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08979",
        "HTML": "https://arxiv.org/html/2507.08979v1",
        "PDF": "https://arxiv.org/pdf/2507.08979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses bias mitigation in models using LLM-guided projection but does not primarily focus on LLM training data processing. It involves model manipulation rather than data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09209",
      "abstract": "The rapid advancements in Vision Language Models (VLMs) have prompted the development of multi-modal medical assistant systems. Despite this progress, current models still have inherent probabilistic uncertainties, often producing erroneous or unverified responses-an issue with serious implications in medical applications. Existing methods aim to enhance the performance of Medical Vision Language Model (MedVLM) by adjusting model structure, fine-tuning with high-quality data, or through preference fine-tuning. However, these training-dependent strategies are costly and still lack sufficient alignment with clinical expertise. To address these issues, we propose an expert-in-the-loop framework named Expert-Controlled Classifier-Free Guidance (Expert-CFG) to align MedVLM with clinical expertise without additional training. This framework introduces an uncertainty estimation strategy to identify unreliable outputs. It then retrieves relevant references to assist experts in highlighting key terms and applies classifier-free guidance to refine the token embeddings of MedVLM, ensuring that the adjusted outputs are correct and align with expert highlights. Evaluations across three medical visual question answering benchmarks demonstrate that the proposed Expert-CFG, with 4.2B parameters and limited expert annotations, outperforms state-of-the-art models with 13B parameters. The results demonstrate the feasibility of deploying such a system in resource-limited settings for clinical use.",
      "authors": [
        "Xiao Liang",
        "Di Wang",
        "Zhicheng Jiao",
        "Ronghan Li",
        "Pengfei Yang",
        "Quan Wang",
        "Tat-Seng Chua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:03:30+00:00",
          "link": "https://arxiv.org/abs/2507.09209v1",
          "size": "8734kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09209",
        "HTML": "https://arxiv.org/html/2507.09209v1",
        "PDF": "https://arxiv.org/pdf/2507.09209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions fine-tuning with high-quality data but focuses primarily on aligning models with clinical expertise using expert framework methods, without substantial emphasis on data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09435",
      "abstract": "The material point method (MPM), a hybrid Lagrangian-Eulerian particle method, is increasingly used to simulate large-deformation and history-dependent behavior of geomaterials. While explicit time integration dominates current MPM implementations due to its algorithmic simplicity, such schemes are unsuitable for quasi-static and long-term processes typical in geomechanics. Implicit MPM formulations are free of these limitations but remain less adopted, largely due to the difficulty of computing the Jacobian matrix required for Newton-type solvers, especially when consistent tangent operators should be derived for complex constitutive models. In this paper, we introduce GeoWarp -- an implicit MPM framework for geomechanics built on NVIDIA Warp -- that exploits GPU parallelism and reverse-mode automatic differentiation to compute Jacobians without manual derivation. To enhance efficiency, we develop a sparse Jacobian construction algorithm that leverages the localized particle-grid interactions intrinsic to MPM. The framework is verified through forward and inverse examples in large-deformation elastoplasticity and coupled poromechanics. Results demonstrate that GeoWarp provides a robust, scalable, and extensible platform for differentiable implicit MPM simulation in computational geomechanics.",
      "authors": [
        "Yidong Zhao",
        "Xuan Li",
        "Chenfanfu Jiang",
        "Jinhyun Choo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Mathematical Software (cs.MS)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T00:11:36+00:00",
          "link": "https://arxiv.org/abs/2507.09435v1",
          "size": "18119kb",
          "version": "v1"
        }
      ],
      "title": "GeoWarp: An automatically differentiable and GPU-accelerated implicit MPM framework for geomechanics based on NVIDIA Warp",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09435",
        "HTML": "https://arxiv.org/html/2507.09435v1",
        "PDF": "https://arxiv.org/pdf/2507.09435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a GPU-accelerated framework for geomechanics simulation, without addressing any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09439",
      "abstract": "Understanding causal relationships in multivariate time series (MTS) is essential for effective decision-making in fields such as finance and marketing, where complex dependencies and lagged effects challenge conventional analytical approaches. We introduce Dynamic Sparse Causal-Attention Temporal Networks for Interpretable Causality Discovery in MTS (DyCAST-Net), a novel architecture designed to enhance causal discovery by integrating dilated temporal convolutions and dynamic sparse attention mechanisms. DyCAST-Net effectively captures multiscale temporal dependencies through dilated convolutions while leveraging an adaptive thresholding strategy in its attention mechanism to eliminate spurious connections, ensuring both accuracy and interpretability. A statistical shuffle test validation further strengthens robustness by filtering false positives and improving causal inference reliability. Extensive evaluations on financial and marketing datasets demonstrate that DyCAST-Net consistently outperforms existing models such as TCDF, GCFormer, and CausalFormer. The model provides a more precise estimation of causal delays and significantly reduces false discoveries, particularly in noisy environments. Moreover, attention heatmaps offer interpretable insights, uncovering hidden causal patterns such as the mediated effects of advertising on consumer behavior and the influence of macroeconomic indicators on financial markets. Case studies illustrate DyCAST-Net's ability to detect latent mediators and lagged causal factors, making it particularly effective in high-dimensional, dynamic settings. The model's architecture enhanced by RMSNorm stabilization and causal masking ensures scalability and adaptability across diverse application domains",
      "authors": [
        "Meriem Zerkouk",
        "Miloud Mihoubi",
        "Belkacem Chikhaoui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T01:03:27+00:00",
          "link": "https://arxiv.org/abs/2507.09439v1",
          "size": "10311kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Sparse Causal-Attention Temporal Networks for Interpretable Causality Discovery in Multivariate Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09439",
        "HTML": "https://arxiv.org/html/2507.09439v1",
        "PDF": "https://arxiv.org/pdf/2507.09439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel model architecture for causal discovery in multivariate time series and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09539",
      "abstract": "Symbolic execution is a powerful technique for analyzing the behavior of software yet scalability remains a challenge due to state explosion in control and data flow. Existing tools typically aim at managing control flow internally, often at the expense of completeness, while offloading reasoning over data flow to SMT solvers. Moreover, reasoning typically happens on source code or intermediate representation level to leverage structural information, making machine code generation part of the trust base. We are interested in changing the equation in two non-trivial ways: pushing reasoning down to machine code level, and then offloading reasoning entirely into SMT solvers and other, possibly more efficient solver technology. In more abstract terms, we are asking if bit-precise reasoning technology can be made scalable on software, and not just hardware. For this purpose, we developed two tools called rotor and bitme for model generation and bounded model checking, respectively. We chose RISC-V restricted to integer arithmetic as modeling target for rotor since RISC-V integer semantics is essentially equivalent to established SMT semantics over bitvectors and arrays of bitvectors. While state-of-the-art SMT solvers struggle in our experiments, we have evidence that there is potential for improvement. To show the potential, we have slightly generalized and then implemented in bitme two types of binary decision diagrams (BDDs): algebraic decision diagrams (ADDs) and context-free-language ordered binary decision diagrams (CFLOBDDs). Bitme uses BDDs to propagate program input through models, essentially generalizing constant propagation to domain propagation. SMT solvers only get involved when model input cannot be propagated, significanly speeding up SMT solving. We then study the impact on state explosion of CFLOBDDs, which are potentially more scalable than ADDs.",
      "authors": [
        "Anna Bolotina",
        "Christoph M. Kirsch",
        "Stefanie Muroya Lei",
        "Matthias Pleschinger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:43:37+00:00",
          "link": "https://arxiv.org/abs/2507.09539v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "Bounded Model Checking of RISC-V Machine Code with Context-Free-Language Ordered Binary Decision Diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09539",
        "HTML": "https://arxiv.org/html/2507.09539v1",
        "PDF": "https://arxiv.org/pdf/2507.09539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses symbolic execution and bounded model checking on RISC-V machine code, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.09470",
      "abstract": "We study a new class of Markov games, \\emph(multi-player) zero-sum Markov Games} with \\emph{Networked separable interactions} (zero-sum NMGs), to model the local interaction structure in non-cooperative multi-agent sequential decision-making. We define a zero-sum NMG as a model where {the payoffs of the auxiliary games associated with each state are zero-sum and} have some separable (i.e., polymatrix) structure across the neighbors over some interaction network. We first identify the necessary and sufficient conditions under which an MG can be presented as a zero-sum NMG, and show that the set of Markov coarse correlated equilibrium (CCE) collapses to the set of Markov Nash equilibrium (NE) in these games, in that the product of per-state marginalization of the former for all players yields the latter. Furthermore, we show that finding approximate Markov \\emph{stationary} CCE in infinite-horizon discounted zero-sum NMGs is \\texttt{PPAD}-hard, unless the underlying network has a ``star topology''. Then, we propose fictitious-play-type dynamics, the classical learning dynamics in normal-form games, for zero-sum NMGs, and establish convergence guarantees to Markov stationary NE under a star-shaped network structure. Finally, in light of the hardness result, we focus on computing a Markov \\emph{non-stationary} NE and provide finite-iteration guarantees for a series of value-iteration-based algorithms. We also provide numerical experiments to corroborate our theoretical results.",
      "authors": [
        "Chanwoo Park",
        "Kaiqing Zhang",
        "Asuman Ozdaglar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-13T19:05:11+00:00",
          "link": "https://arxiv.org/abs/2307.09470v1",
          "size": "1072kb",
          "version": "v1"
        },
        {
          "date": "2024-03-21T19:12:08+00:00",
          "link": "https://arxiv.org/abs/2307.09470v2",
          "size": "226kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T20:06:53+00:00",
          "link": "https://arxiv.org/abs/2307.09470v3",
          "size": "226kb",
          "version": "v3"
        }
      ],
      "title": "Multi-Player Zero-Sum Markov Games with Networked Separable Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.09470",
        "PDF": "https://arxiv.org/pdf/2307.09470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on zero-sum Markov games and interaction structures, not on processing or creating LLM training data."
      },
      "conference": "multi-player-zero-sum-markov-games-with",
      "conference_url_abs": "https://openreview.net/forum?id=GiiOpKinGm",
      "tasks": [
        "Decision Making",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.05204",
      "abstract": "Objective: To detect and classify features of stigmatizing and biased language in intensive care electronic health records (EHRs) using natural language processing techniques. Materials and Methods: We first created a lexicon and regular expression lists from literature-driven stem words for linguistic features of stigmatizing patient labels, doubt markers, and scare quotes within EHRs. The lexicon was further extended using Word2Vec and GPT 3.5, and refined through human evaluation. These lexicons were used to search for matches across 18 million sentences from the de-identified Medical Information Mart for Intensive Care-III (MIMIC-III) dataset. For each linguistic bias feature, 1000 sentence matches were sampled, labeled by expert clinical and public health annotators, and used to supervised learning classifiers. Results: Lexicon development from expanded literature stem-word lists resulted in a doubt marker lexicon containing 58 expressions, and a stigmatizing labels lexicon containing 127 expressions. Classifiers for doubt markers and stigmatizing labels had the highest performance, with macro F1-scores of .84 and .79, positive-label recall and precision values ranging from .71 to .86, and accuracies aligning closely with human annotator agreement (.87). Discussion: This study demonstrated the feasibility of supervised classifiers in automatically identifying stigmatizing labels and doubt markers in medical text, and identified trends in stigmatizing language use in an EHR setting. Additional labeled data may help improve lower scare quote model performance. Conclusions: Classifiers developed in this study showed high model performance and can be applied to identify patterns and target interventions to reduce stigmatizing labels and doubt markers in healthcare systems.",
      "authors": [
        "Drew Walker",
        "Annie Thorne",
        "Sudeshna Das",
        "Jennifer Love",
        "Hannah LF Cooper",
        "Melvin Livingston III",
        "Abeed Sarker"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-08T16:40:18+00:00",
          "link": "https://arxiv.org/abs/2405.05204v1",
          "size": "1344kb",
          "version": "v1"
        }
      ],
      "title": "CARE-SD: Classifier-based analysis for recognizing and eliminating stigmatizing and doubt marker labels in electronic health records: model development and validation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.05204",
        "PDF": "https://arxiv.org/pdf/2405.05204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the classification of stigmatizing language in electronic health records, with no contribution to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/drew-walkerr/care-sd-stigma-and-doubt-ehr-detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.18611",
      "abstract": "Creation of synthetic data models has represented a significant advancement across diverse scientific fields, but this technology also brings important privacy considerations for users. This work focuses on enhancing a non-parametric copula-based synthetic data generation model, DPNPC, by incorporating Differential Privacy through an Enhanced Fourier Perturbation method. The model generates synthetic data for mixed tabular databases while preserving privacy. We compare DPNPC with three other models (PrivBayes, DP-Copula, and DP-Histogram) across three public datasets, evaluating privacy, utility, and execution time. DPNPC outperforms others in modeling multivariate dependencies, maintaining privacy for small $\\epsilon$ values, and reducing training times. However, limitations include the need to assess the model's performance with different encoding methods and consider additional privacy attacks. Future research should address these areas to enhance privacy-preserving synthetic data generation.",
      "authors": [
        "Pablo A. Osorio-Marulanda",
        "John Esteban Castro Ramirez",
        "Mikel Hern\\'andez Jim\\'enez",
        "Nicolas Moreno Reyes and Gorka Epelde Unanue"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T10:18:14+00:00",
          "link": "https://arxiv.org/abs/2409.18611v1",
          "size": "1662kb",
          "version": "v1"
        }
      ],
      "title": "Differentially Private Non Parametric Copulas: Generating synthetic data with non parametric copulas under privacy guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18611",
        "PDF": "https://arxiv.org/pdf/2409.18611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on generating synthetic data with privacy considerations, which involves data generation but is not specifically about LLM training data processing."
      },
      "tasks": [
        "Privacy Preserving",
        "Synthetic Data Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09009",
      "abstract": "Methods: We developed a self-supervised deep learning model that extracts meaningful patterns from multi-modal signals (Electroencephalography (EEG), Electrocardiography (ECG), and respiratory signals). The model was trained on data from 4,398 participants. Projection scores were derived by contrasting embeddings from individuals with and without CVD outcomes. External validation was conducted in an independent cohort with 1,093 participants. The source code is available on https://github.com/miraclehetech/sleep-ssl. Results: The projection scores revealed distinct and clinically meaningful patterns across modalities. ECG-derived features were predictive of both prevalent and incident cardiac conditions, particularly CVD mortality. EEG-derived features were predictive of incident hypertension and CVD mortality. Respiratory signals added complementary predictive value. Combining these projection scores with the Framingham Risk Score consistently improved predictive performance, achieving area under the curve values ranging from 0.607 to 0.965 across different outcomes. Findings were robustly replicated and validated in the external testing cohort. Conclusion: Our findings demonstrate that the proposed framework can generate individualized CVD risk scores directly from PSG data. The resulting projection scores have the potential to be integrated into clinical practice, enhancing risk assessment and supporting personalized care.",
      "authors": [
        "Zhengxiao He",
        "Huayu Li",
        "Geng Yuan",
        "William D.S. Killgore",
        "Stuart F. Quan",
        "Chen X. Chen",
        "Ao Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:24:10+00:00",
          "link": "https://arxiv.org/abs/2507.09009v1",
          "size": "1123kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Cardiovascular Risk Profiling Using Self-Supervised Learning of Polysomnography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09009",
        "PDF": "https://arxiv.org/pdf/2507.09009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multimodal cardiovascular risk profiling using self-supervised learning and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09382",
      "abstract": "Canonical correlation analysis (CCA) is a technique for finding correlations between different data modalities and learning low-dimensional representations. As fairness becomes crucial in machine learning, fair CCA has gained attention. However, previous approaches often overlook the impact on downstream classification tasks, limiting applicability. We propose a novel fair CCA method for fair representation learning, ensuring the projected features are independent of sensitive attributes, thus enhancing fairness without compromising accuracy. We validate our method on synthetic data and real-world data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), demonstrating its ability to maintain high correlation analysis performance while improving fairness in classification tasks. Our work enables fair machine learning in neuroimaging studies where unbiased analysis is essential.",
      "authors": [
        "Bojian Hou",
        "Zhanliang Wang",
        "Zhuoping Zhou",
        "Boning Tong",
        "Zexuan Wang",
        "Jingxuan Bao",
        "Duy Duong-Tran",
        "Qi Long",
        "Li Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T19:36:10+00:00",
          "link": "https://arxiv.org/abs/2507.09382v1",
          "size": "2640kb",
          "version": "v1"
        }
      ],
      "title": "Fair CCA for Fair Representation Learning: An ADNI Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09382",
        "HTML": "https://arxiv.org/html/2507.09382v1",
        "PDF": "https://arxiv.org/pdf/2507.09382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with fair representation learning via CCA, emphasizing fairness in feature projection for machine learning rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09423",
      "abstract": "Recommender systems face a critical challenge in the item cold-start problem, which limits content diversity and exacerbates popularity bias by struggling to recommend new items. While existing solutions often rely on auxiliary data, but this paper illuminates a distinct, yet equally pressing, issue stemming from the inherent user-centricity of many recommender systems. We argue that in environments with large and rapidly expanding item inventories, the traditional focus on finding the \"best item for a user\" can inadvertently obscure the ideal audience for nascent content. To counter this, we introduce the concept of item-centric recommendations, shifting the paradigm to identify the optimal users for new items. Our initial realization of this vision involves an item-centric control integrated into an exploration system. This control employs a Bayesian model with Beta distributions to assess candidate items based on a predicted balance between user satisfaction and the item's inherent quality. Empirical online evaluations reveal that this straightforward control markedly improves cold-start targeting efficacy, enhances user satisfaction with newly explored content, and significantly increases overall exploration efficiency.",
      "authors": [
        "Dong Wang",
        "Junyi Jiao",
        "Arnab Bhadury",
        "Yaping Zhang",
        "Mingyan Gao",
        "Onkar Dalal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:22:23+00:00",
          "link": "https://arxiv.org/abs/2507.09423v1",
          "size": "310kb",
          "version": "v1"
        }
      ],
      "title": "Item-centric Exploration for Cold Start Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09423",
        "HTML": "https://arxiv.org/html/2507.09423v1",
        "PDF": "https://arxiv.org/pdf/2507.09423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses recommender systems and the item cold-start problem, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10056",
      "abstract": "Poultry farming is a vital component of the global food supply chain, yet it remains highly vulnerable to infectious diseases such as coccidiosis, salmonellosis, and Newcastle disease. This study proposes a lightweight machine learning-based approach to detect these diseases by analyzing poultry fecal images. We utilize multi-color space feature extraction (RGB, HSV, LAB) and explore a wide range of color, texture, and shape-based descriptors, including color histograms, local binary patterns (LBP), wavelet transforms, and edge detectors. Through a systematic ablation study and dimensionality reduction using PCA and XGBoost feature selection, we identify a compact global feature set that balances accuracy and computational efficiency. An artificial neural network (ANN) classifier trained on these features achieved 95.85% accuracy while requiring no GPU and only 638 seconds of execution time in Google Colab. Compared to deep learning models such as Xception and MobileNetV3, our proposed model offers comparable accuracy with drastically lower resource usage. This work demonstrates a cost-effective, interpretable, and scalable alternative to deep learning for real-time poultry disease detection in low-resource agricultural settings.",
      "authors": [
        "A. K. M. Shoriful Islam",
        "Md. Rakib Hassan",
        "Macbah Uddin and Md. Shahidur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.10056v1",
          "size": "1679kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Model for Poultry Disease Detection from Fecal Images Using Multi-Color Space Feature Optimization and Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10056",
        "HTML": "https://arxiv.org/html/2507.10056v1",
        "PDF": "https://arxiv.org/pdf/2507.10056"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on disease detection from poultry fecal images using machine learning, which does not involve LLM training data processing or contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10065",
      "abstract": "We present MoVieS, a novel feed-forward model that synthesizes 4D dynamic novel views from monocular videos in one second. MoVieS represents dynamic 3D scenes using pixel-aligned grids of Gaussian primitives, explicitly supervising their time-varying motion. This allows, for the first time, the unified modeling of appearance, geometry and motion, and enables view synthesis, reconstruction and 3D point tracking within a single learning-based framework. By bridging novel view synthesis with dynamic geometry reconstruction, MoVieS enables large-scale training on diverse datasets with minimal dependence on task-specific supervision. As a result, it also naturally supports a wide range of zero-shot applications, such as scene flow estimation and moving object segmentation. Extensive experiments validate the effectiveness and efficiency of MoVieS across multiple tasks, achieving competitive performance while offering several orders of magnitude speedups.",
      "authors": [
        "Chenguo Lin",
        "Yuchen Lin",
        "Panwang Pan",
        "Yifan Yu",
        "Honglei Yan",
        "Katerina Fragkiadaki",
        "Yadong Mu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:49:57+00:00",
          "link": "https://arxiv.org/abs/2507.10065v1",
          "size": "3791kb",
          "version": "v1"
        }
      ],
      "title": "MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10065",
        "HTML": "https://arxiv.org/html/2507.10065v1",
        "PDF": "https://arxiv.org/pdf/2507.10065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on dynamic view synthesis from monocular videos and does not involve processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.17349",
      "abstract": "We consider in this paper a numerical approximation of Poisson-Nernst-Planck-Navier- Stokes (PNP-NS) system. We construct a decoupled semi-discrete and fully discrete scheme that enjoys the properties of positivity preserving, mass conserving, and unconditionally energy stability. Then, we establish the well-posedness and regularity of the initial and (periodic) boundary value problem of the PNP-NS system under suitable assumptions on the initial data, and carry out a rigorous convergence analysis for the fully discretized scheme. We also present some numerical results to validate the positivity-preserving property and the accuracy of our scheme.",
      "authors": [
        "Ziyao Yu",
        "Qing Cheng",
        "Jie Shen",
        "Changyou Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-29T04:15:44+00:00",
          "link": "https://arxiv.org/abs/2311.17349v1",
          "size": "2966kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T03:58:10+00:00",
          "link": "https://arxiv.org/abs/2311.17349v2",
          "size": "1007kb",
          "version": "v2"
        }
      ],
      "title": "A decoupled structure preserving scheme for the Poisson-Nernst-Planck Navier-Stokes equations and its error analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.17349",
        "HTML": "https://arxiv.org/html/2311.17349v2",
        "PDF": "https://arxiv.org/pdf/2311.17349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical approximation techniques for the Poisson-Nernst-Planck-Navier-Stokes system, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10009",
      "abstract": "Phase shifting profilometry (PSP) is widely used in high-precision 3D scanning due to its high accuracy, robustness, and pixel-wise handling. However, a fundamental assumption of PSP that the object should remain static does not hold in dynamic measurement, making PSP susceptible to object motion. To address this challenge, our proposed solution, phase-sequential binomial self-compensation (P-BSC), sums successive motion-affected phase frames weighted by binomial coefficients. This approach exponentially reduces the motion error in a pixel-wise and frame-wise loopable manner. Despite its efficacy, P-BSC suffers from high computational overhead and error accumulation due to its reliance on multi-frame phase calculations and weighted summations. Inspired by P-BSC, we propose an image-sequential binomial self-compensation (I-BSC) to weight sum the homogeneous fringe images instead of successive phase frames, which generalizes the BSC concept from phase sequences to image sequences. I-BSC computes the arctangent function only once, resolving both limitations in P-BSC. Extensive analysis, simulations, and experiments show that 1) the proposed BSC outperforms existing methods in reducing motion error while achieving a quasi-single-shot frame rate, i.e., depth map frame rate equals to the camera's acquisition rate, enabling 3D reconstruction with high pixel-depth-temporal resolution; 2) compared to P-BSC, our I-BSC reduces the computational complexity by one polynomial order, thereby accelerating the computational frame rate by several to dozen times, while also reaching faster motion error convergence.",
      "authors": [
        "Geyou Zhang",
        "Kai Liu",
        "Ce Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:41:56+00:00",
          "link": "https://arxiv.org/abs/2507.10009v1",
          "size": "18775kb",
          "version": "v1"
        }
      ],
      "title": "Binomial Self-Compensation: Mechanism and Suppression of Motion Error in Phase-Shifting Profilometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10009",
        "HTML": "https://arxiv.org/html/2507.10009v1",
        "PDF": "https://arxiv.org/pdf/2507.10009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with reducing motion error in 3D scanning using phase-shifting profilometry. It does not involve LLM training data processing or creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10132",
      "abstract": "Accurate forecasting of energy demand and supply is critical for optimizing sustainable energy systems, yet it is challenged by the variability of renewable sources and dynamic consumption patterns. This paper introduces a neural framework that integrates continuous-time Neural Ordinary Differential Equations (Neural ODEs), graph attention, multi-resolution wavelet transformations, and adaptive learning of frequencies to address the issues of time series prediction. The model employs a robust ODE solver, using the Runge-Kutta method, paired with graph-based attention and residual connections to better understand both structural and temporal patterns. Through wavelet-based feature extraction and adaptive frequency modulation, it adeptly captures and models diverse, multi-scale temporal dynamics. When evaluated across seven diverse datasets: ETTh1, ETTh2, ETTm1, ETTm2 (electricity transformer temperature), and Waste, Solar, and Hydro (renewable energy), this architecture consistently outperforms state-of-the-art baselines in various forecasting metrics, proving its robustness in capturing complex temporal dependencies. Furthermore, the model enhances interpretability through SHAP analysis, making it suitable for sustainable energy applications.",
      "authors": [
        "Usman Gani Joy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:23:18+00:00",
          "link": "https://arxiv.org/abs/2507.10132v1",
          "size": "5785kb",
          "version": "v1"
        }
      ],
      "title": "Wavelet-Enhanced Neural ODE and Graph Attention for Interpretable Energy Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10132",
        "HTML": "https://arxiv.org/html/2507.10132v1",
        "PDF": "https://arxiv.org/pdf/2507.10132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a neural framework for energy forecasting using time series data, with no mention of LLM training data processing or the creation of new datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10205",
      "abstract": "We show how a recently published 2d model for traffic flow can be further improved. Besides other improvements and simplifications, we present not only a method to compute the necessary time step restrictions, but also a subcycling for the inflow and outflow. This drastically reduces computational cost on large domains with coarse grids, i.\\,e.\\ for simulations of a whole region instead of a small part of a city or town.",
      "authors": [
        "Friedemann Kemm"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Numerical Analysis (cs.NA)",
        "Systems and Control (cs.SY)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:20:30+00:00",
          "link": "https://arxiv.org/abs/2507.10205v1",
          "size": "23105kb",
          "version": "v1"
        }
      ],
      "title": "A new time-stepping strategy and boundary treatment to improve recent 2d traffic model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10205",
        "HTML": "https://arxiv.org/html/2507.10205v1",
        "PDF": "https://arxiv.org/pdf/2507.10205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper improves a 2D traffic model with a new time-stepping strategy and boundary treatment, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10296",
      "abstract": "Hierarchical clustering is a widely used method for unsupervised learning with numerous applications. However, in the application of modern algorithms, the datasets studied are usually large and dynamic. If the hierarchical clustering is sensitive to small perturbations of the dataset, the usability of the algorithm will be greatly reduced. In this paper, we focus on the hierarchical $k$ -median clustering problem, which bridges hierarchical and centroid-based clustering while offering theoretical appeal, practical utility, and improved interpretability. We analyze the average sensitivity of algorithms for this problem by measuring the expected change in the output when a random data point is deleted. We propose an efficient algorithm for hierarchical $k$-median clustering and theoretically prove its low average sensitivity and high clustering quality. Additionally, we show that single linkage clustering and a deterministic variant of the CLNSS algorithm exhibit high average sensitivity, making them less stable. Finally, we validate the robustness and effectiveness of our algorithm through experiments.",
      "authors": [
        "Shijie Li",
        "Weiqiang He",
        "Ruobing Bai",
        "Pan Peng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:02:31+00:00",
          "link": "https://arxiv.org/abs/2507.10296v1",
          "size": "1997kb",
          "version": "v1"
        }
      ],
      "title": "Average Sensitivity of Hierarchical $k$-Median Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10296",
        "HTML": "https://arxiv.org/html/2507.10296v1",
        "PDF": "https://arxiv.org/pdf/2507.10296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the average sensitivity of hierarchical clustering algorithms, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.06238",
      "abstract": "Despite their success in many domains, large language models (LLMs) remain under-studied in scenarios requiring optimal decision-making under uncertainty. This is crucial as many real-world applications, ranging from personalized recommendations to healthcare interventions, demand that LLMs not only predict but also actively learn to make optimal decisions through exploration. In this work, we measure LLMs' (in)ability to make optimal decisions in bandits, a state-less reinforcement learning setting relevant to many applications. We develop a comprehensive suite of environments, including both context-free and contextual bandits with varying task difficulties, to benchmark LLMs' performance. Motivated by the existence of optimal exploration algorithms, we propose efficient ways to integrate this algorithmic knowledge into LLMs: by providing explicit algorithm-guided support during inference; and through algorithm distillation via in-context demonstrations and fine-tuning, using synthetic data generated from these algorithms. Impressively, these techniques allow us to achieve superior exploration performance with smaller models, surpassing larger models on various tasks. We conducted an extensive ablation study to shed light on various factors, such as task difficulty and data representation, that influence the efficiency of LLM exploration. Additionally, we conduct a rigorous analysis of the LLM's exploration efficiency using the concept of regret, linking its ability to explore to the model size and underlying algorithm.",
      "authors": [
        "Allen Nie",
        "Yi Su",
        "Bo Chang",
        "Jonathan N. Lee",
        "Ed H. Chi",
        "Quoc V. Le",
        "Minmin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T17:54:03+00:00",
          "link": "https://arxiv.org/abs/2410.06238v1",
          "size": "191kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:16:18+00:00",
          "link": "https://arxiv.org/abs/2410.06238v2",
          "size": "196kb",
          "version": "v2"
        }
      ],
      "title": "EVOLvE: Evaluating and Optimizing LLMs For In-Context Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06238",
        "HTML": "https://arxiv.org/html/2410.06238v2",
        "PDF": "https://arxiv.org/pdf/2410.06238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning using synthetic data generated from exploration algorithms, which involves training-data processing but is not the primary focus."
      },
      "tasks": [
        "Decision Making Under Uncertainty",
        "Multi-Armed Bandits"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18314",
      "abstract": "Many video-to-audio (VTA) methods have been proposed for dubbing silent AI-generated videos. An efficient quality assessment method for AI-generated audio-visual content (AGAV) is crucial for ensuring audio-visual quality. Existing audio-visual quality assessment methods struggle with unique distortions in AGAVs, such as unrealistic and inconsistent elements. To address this, we introduce AGAVQA-3k, the first large-scale AGAV quality assessment dataset, comprising $3,382$ AGAVs from $16$ VTA methods. AGAVQA-3k includes two subsets: AGAVQA-MOS, which provides multi-dimensional scores for audio quality, content consistency, and overall quality, and AGAVQA-Pair, designed for optimal AGAV pair selection. We further propose AGAV-Rater, a LMM-based model that can score AGAVs, as well as audio and music generated from text, across multiple dimensions, and selects the best AGAV generated by VTA methods to present to the user. AGAV-Rater achieves state-of-the-art performance on AGAVQA-3k, Text-to-Audio, and Text-to-Music datasets. Subjective tests also confirm that AGAV-Rater enhances VTA performance and user experience. The dataset and code is available at https://github.com/charlotte9524/AGAV-Rater.",
      "authors": [
        "Yuqin Cao",
        "Xiongkuo Min",
        "Yixuan Gao",
        "Wei Sun",
        "Guangtao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T12:43:47+00:00",
          "link": "https://arxiv.org/abs/2501.18314v1",
          "size": "1492kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:08:07+00:00",
          "link": "https://arxiv.org/abs/2501.18314v2",
          "size": "1478kb",
          "version": "v2"
        }
      ],
      "title": "AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18314",
        "HTML": "https://arxiv.org/html/2501.18314v2",
        "PDF": "https://arxiv.org/pdf/2501.18314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset (AGAVQA-3k) for audio-visual quality assessment, but the primary focus is on evaluating AI-generated content rather than LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.10826",
      "abstract": "We consider off-policy selection and learning in contextual bandits, where the learner aims to select or train a reward-maximizing policy using data collected by a fixed behavior policy. Our contribution is two-fold. First, we propose a novel off-policy selection method that leverages a new betting-based confidence bound applied to an inverse propensity weight sequence. Our theoretical analysis reveals that this method achieves a significantly improved, variance-adaptive guarantee over prior work. Second, we propose a novel and generic condition on the optimization objective for off-policy learning that strikes a different balance between bias and variance. One special case, which we call freezing, tends to induce low variance, which is preferred in small-data regimes. Our analysis shows that it matches the best existing guarantees. In our empirical study, our selection method outperforms existing methods, and freezing exhibits improved performance in small-sample regimes.",
      "authors": [
        "J. Jon Ryu",
        "Jeongyeol Kwon",
        "Benjamin Koppe",
        "Kwang-Sung Jun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-15T15:01:16+00:00",
          "link": "https://arxiv.org/abs/2502.10826v1",
          "size": "563kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:33:46+00:00",
          "link": "https://arxiv.org/abs/2502.10826v2",
          "size": "1168kb",
          "version": "v2"
        }
      ],
      "title": "Improved Offline Contextual Bandits with Second-Order Bounds: Betting and Freezing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10826",
        "HTML": "https://arxiv.org/html/2502.10826v2",
        "PDF": "https://arxiv.org/pdf/2502.10826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with optimization in contextual bandits and off-policy selection, without contributing to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Multi-Armed Bandits"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09144",
      "abstract": "Forecasting the evolution of 3D scenes and generating unseen scenarios via occupancy-based world models offers substantial potential for addressing corner cases in autonomous driving systems. While tokenization has revolutionized image and video generation, efficiently tokenizing complex 3D scenes remains a critical challenge for 3D world models. To address this, we propose $I^{2}$-World, an efficient framework for 4D occupancy forecasting. Our method decouples scene tokenization into intra-scene and inter-scene tokenizers. The intra-scene tokenizer employs a multi-scale residual quantization strategy to hierarchically compress 3D scenes while preserving spatial details. The inter-scene tokenizer residually aggregates temporal dependencies across timesteps. This dual design preserves the compactness of 3D tokenizers while retaining the dynamic expressiveness of 4D tokenizers. Unlike decoder-only GPT-style autoregressive models, $I^{2}$-World adopts an encoder-decoder architecture. The encoder aggregates spatial context from the current scene and predicts a transformation matrix to enable high-level control over scene generation. The decoder, conditioned on this matrix and historical tokens, ensures temporal consistency during generation. Experiments demonstrate that $I^{2}$-World achieves state-of-the-art performance, outperforming existing methods by 25.1\\% in mIoU and 36.9\\% in IoU for 4D occupancy forecasting while exhibiting exceptional computational efficiency: it requires merely 2.9 GB of training memory and achieves real-time inference at 37.0 FPS. Our code is available on https://github.com/lzzzzzm/II-World.",
      "authors": [
        "Zhimin Liao",
        "Ping Wei",
        "Ruijie Zhang",
        "Shuaijia Chen",
        "Haoxuan Wang",
        "Ziyang Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T05:14:39+00:00",
          "link": "https://arxiv.org/abs/2507.09144v1",
          "size": "5824kb",
          "version": "v1"
        }
      ],
      "title": "$I^{2}$-World: Intra-Inter Tokenization for Efficient Dynamic 4D Scene Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09144",
        "HTML": "https://arxiv.org/html/2507.09144v1",
        "PDF": "https://arxiv.org/pdf/2507.09144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper involves tokenization of 4D scenes and addresses efficient dynamic scene forecasting, it is not focused on LLM training data processing or collection for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09475",
      "abstract": "Explicit discretizations of stochastic differential equations often encounter instability when the coefficients are not globally Lipschitz. The truncated schemes and tamed schemes have been proposed to handle this difficulty, but truncated schemes involve analyzing of the stopping times while the tamed schemes suffer from the reduced order of accuracy. We propose a modified tamed scheme by introducing an additional cut-off function in the taming, which enjoys the convenience for error analysis and preserving the original order of explicit discretization. While the strategy could be applied to any explicit discretization, we perform rigorous analysis of the modified tamed scheme for the Euler discretization as an example. Then, we apply the modified tamed scheme to the stochastic gradient Langevin dynamics for sampling with super-linear drift, and obtain a uniform-in-time near-sharp error estimate under relative entropy.",
      "authors": [
        "Zichang Ju",
        "Lei Li",
        "Yuliang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:21:39+00:00",
          "link": "https://arxiv.org/abs/2507.09475v1",
          "size": "64kb",
          "version": "v1"
        }
      ],
      "title": "A modified tamed scheme for stochastic differential equations with superlinear drifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09475",
        "HTML": "https://arxiv.org/html/2507.09475v1",
        "PDF": "https://arxiv.org/pdf/2507.09475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a mathematical scheme for stochastic differential equations and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09682",
      "abstract": "We propose a novel approach, OrQstrator, which is a modular framework for conducting quantum circuit optimization in the Noisy Intermediate-Scale Quantum (NISQ) era. Our framework is powered by Deep Reinforcement Learning (DRL). Our orchestration engine intelligently selects among three complementary circuit optimizers: A DRL-based circuit rewriter trained to reduce depth and gate count via learned rewrite sequences; a domain-specific optimizer that performs efficient local gate resynthesis and numeric optimization; a parameterized circuit instantiator that improves compilation by optimizing template circuits during gate set translation. These modules are coordinated by a central orchestration engine that learns coordination policies based on circuit structure, hardware constraints, and backend-aware performance features such as gate count, depth, and expected fidelity. The system outputs an optimized circuit for hardware-aware transpilation and execution, leveraging techniques from an existing state-of-the-art approach, called the NISQ Analyzer, to adapt to backend constraints.",
      "authors": [
        "Laura Baird and Armin Moin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:38:39+00:00",
          "link": "https://arxiv.org/abs/2507.09682v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09682",
        "HTML": "https://arxiv.org/html/2507.09682v1",
        "PDF": "https://arxiv.org/pdf/2507.09682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for optimizing quantum circuits using deep reinforcement learning, and it does not involve processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10375",
      "abstract": "Real-world visual perception requires invariance to diverse transformations, yet current methods rely heavily on specialized architectures or training on predefined augmentations, limiting generalization. We propose FOCAL, a test-time, data-driven framework that achieves robust perception by leveraging internet-scale visual priors from foundation models. By generating and optimizing candidate transformations toward visually typical, \"canonical\" views, FOCAL enhances robustness without re-training or architectural changes. Our experiments demonstrate improved robustness of CLIP and SAM across challenging transformations, including 2D/3D rotations, illumination shifts (contrast and color), and day-night variations. We also highlight potential applications in active vision. Our approach challenges the assumption that transform-specific training is necessary, instead offering a scalable path to invariance. Our code is available at: https://github.com/sutkarsh/focal.",
      "authors": [
        "Utkarsh Singhal",
        "Ryan Feng",
        "Stella X. Yu",
        "Atul Prakash"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:14:38+00:00",
          "link": "https://arxiv.org/abs/2507.10375v1",
          "size": "9497kb",
          "version": "v1"
        }
      ],
      "title": "Test-Time Canonicalization by Foundation Models for Robust Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10375",
        "HTML": "https://arxiv.org/html/2507.10375v1",
        "PDF": "https://arxiv.org/pdf/2507.10375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It proposes a framework (FOCAL) for enhancing perception robustness using foundation models without involving LLM training data processing or relevant data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10466",
      "abstract": "We introduce a programming language that allows for the coherent control of arbitrary quantum operations. The problem of defining coherent control beyond the unitary case, using, for example, a quantum conditional in the presence of recursion or iteration has long been known to be a major difficulty. We resolve this problem by defining an operational semantics based on appropriate Kraus decompositions and a denotational semantics based on vacuum-extensions. We show that the language is universal for vacuum-extensions and that the two semantics are adequate. Moreover, we define a notion of observational equivalence: two programs are equivalent if their probability of termination is the same in any context. The denotational semantics is shown to be fully abstract for observational equivalence.",
      "authors": [
        "Kathlee Barsse",
        "Romain P\\'echoux",
        "Simon Perdrix"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:45:54+00:00",
          "link": "https://arxiv.org/abs/2507.10466v1",
          "size": "112kb",
          "version": "v1"
        }
      ],
      "title": "A Quantum Programming Language for Coherent Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10466",
        "PDF": "https://arxiv.org/pdf/2507.10466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a quantum programming language and its semantics, with no discussion related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.18805",
      "abstract": "The classic notion of \\emph{truthfulness} requires that no agent has a profitable manipulation -- an untruthful report that, for \\emph{some} combination of reports of the other agents, increases her utility. This strong notion implicitly assumes that the manipulating agent either knows what all other agents are going to report, or is willing to take the risk and act as-if she knows their reports.\n  Without knowledge of the others' reports, most manipulations are \\emph{risky} -- they might decrease the manipulator's utility for some other combinations of reports by the other agents. Accordingly, a recent paper (Bu, Song and Tao, ``On the existence of truthful fair cake cutting mechanisms'', Artificial Intelligence 319 (2023), 103904) suggests a relaxed notion, which we refer to as \\emph{risk-avoiding truthfulness (RAT)}, which requires only that no agent can gain from a \\emph{safe} manipulation -- one that is sometimes beneficial and never harmful.\n  Truthfulness and RAT are two extremes: the former considers manipulators with complete knowledge of others, whereas the latter considers manipulators with no knowledge at all. In reality, agents often know about some -- but not all -- of the other agents. This paper introduces the \\emph{RAT-degree} of a mechanism, defined as the smallest number of agents whose reports, if known, may allow another agent to safely manipulate, or $n$ if there is no such number. This notion interpolates between classic truthfulness (degree $n$) and RAT (degree at least $1$): a mechanism with a higher RAT-degree is harder to manipulate safely.\n  To illustrate the generality and applicability of this concept, we analyze the RAT-degree of prominent mechanisms across various social choice settings, including auctions, indivisible goods allocations, cake-cutting, voting, and two-sided matching.",
      "authors": [
        "Eden Hartman",
        "Erel Segal-Halevi",
        "Biaoshuai Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Multiagent Systems (cs.MA)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T04:19:48+00:00",
          "link": "https://arxiv.org/abs/2502.18805v1",
          "size": "1275kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T07:59:07+00:00",
          "link": "https://arxiv.org/abs/2502.18805v2",
          "size": "425kb",
          "version": "v2"
        }
      ],
      "title": "It's Not All Black and White: Degree of Truthfulness for Risk-Avoiding Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18805",
        "HTML": "https://arxiv.org/html/2502.18805v2",
        "PDF": "https://arxiv.org/pdf/2502.18805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the concept of risk-avoiding truthfulness in mechanisms, unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00684",
      "abstract": "We introduce RegionFocus, a visual test-time scaling approach for Vision Language Model Agents. Understanding webpages is challenging due to the visual complexity of GUI images and the large number of interface elements, making accurate action selection difficult. Our approach dynamically zooms in on relevant regions, reducing background clutter and improving grounding accuracy. To support this process, we propose an image-as-map mechanism that visualizes key landmarks at each step, providing a transparent action record and enables the agent to effectively choose among action candidates. Even with a simple region selection strategy, we observe significant performance gains of 28+\\% on Screenspot-pro and 24+\\% on WebVoyager benchmarks on top of two state-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL, highlighting the effectiveness of visual test-time scaling in interactive settings. We achieve a new state-of-the-art grounding performance of 61.6\\% on the ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model. Our code will be released publicly at https://github.com/tiangeluo/RegionFocus.",
      "authors": [
        "Tiange Luo",
        "Lajanugen Logeswaran",
        "Justin Johnson",
        "Honglak Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T17:45:59+00:00",
          "link": "https://arxiv.org/abs/2505.00684v1",
          "size": "7604kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:45:50+00:00",
          "link": "https://arxiv.org/abs/2505.00684v2",
          "size": "7293kb",
          "version": "v2"
        }
      ],
      "title": "Visual Test-time Scaling for GUI Agent Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00684",
        "HTML": "https://arxiv.org/html/2505.00684v2",
        "PDF": "https://arxiv.org/pdf/2505.00684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a visual test-time scaling approach for GUI understanding in vision language model agents, without focusing on LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/tiangeluo/regionfocus"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05819",
      "abstract": "We study the problem of learning junta distributions on $\\{0, 1\\}^n$, where a distribution is a $k$-junta if its probability mass function depends on a subset of at most $k$ variables. We make two main contributions:\n  - We show that learning $k$-junta distributions is \\emph{computationally} equivalent to learning $k$-parity functions with noise (LPN), a landmark problem in computational learning theory.\n  - We design an algorithm for learning junta distributions whose statistical complexity is optimal, up to polylogarithmic factors. Computationally, our algorithm matches the complexity of previous (non-sample-optimal) algorithms.\n  Combined, our two contributions imply that our algorithm cannot be significantly improved, statistically or computationally, barring a breakthrough for LPN.",
      "authors": [
        "Lorenzo Beretta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T06:44:35+00:00",
          "link": "https://arxiv.org/abs/2505.05819v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T22:58:22+00:00",
          "link": "https://arxiv.org/abs/2505.05819v2",
          "size": "51kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T21:37:06+00:00",
          "link": "https://arxiv.org/abs/2505.05819v3",
          "size": "35kb",
          "version": "v3"
        }
      ],
      "title": "New Statistical and Computational Results for Learning Junta Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05819",
        "HTML": "https://arxiv.org/html/2505.05819v3",
        "PDF": "https://arxiv.org/pdf/2505.05819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses learning junta distributions and its computational equivalence to a known problem in computational learning theory (LPN). It does not cover LLM training data processing or related data quality improvement methodologies."
      },
      "tasks": [
        "Learning Theory"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09023",
      "abstract": "The pharmaceutical industry faces unprecedented challenges in drug discovery, with traditional approaches struggling to meet modern therapeutic development demands. This paper introduces a novel AI framework, Tippy, that transforms laboratory automation through specialized AI agents operating within the Design-Make-Test-Analyze (DMTA) cycle. Our multi-agent system employs five specialized agents - Supervisor, Molecule, Lab, Analysis, and Report, with Safety Guardrail oversight - each designed to excel in specific phases of the drug discovery pipeline. Tippy represents the first production-ready implementation of specialized AI agents for automating the DMTA cycle, providing a concrete example of how AI can transform laboratory workflows. By leveraging autonomous AI agents that reason, plan, and collaborate, we demonstrate how Tippy accelerates DMTA cycles while maintaining scientific rigor essential for pharmaceutical research. The system shows significant improvements in workflow efficiency, decision-making speed, and cross-disciplinary coordination, offering a new paradigm for AI-assisted drug discovery.",
      "authors": [
        "Yao Fehlis",
        "Charles Crain",
        "Aidan Jensen",
        "Michael Watson",
        "James Juhasz",
        "Paul Mandel",
        "Betty Liu",
        "Shawn Mahon",
        "Daren Wilson",
        "Nick Lynch-Jonely",
        "Ben Leedom",
        "David Fuller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:13:13+00:00",
          "link": "https://arxiv.org/abs/2507.09023v1",
          "size": "614kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating Drug Discovery Through Agentic AI: A Multi-Agent Approach to Laboratory Automation in the DMTA Cycle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09023",
        "HTML": "https://arxiv.org/html/2507.09023v1",
        "PDF": "https://arxiv.org/pdf/2507.09023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an AI framework for automating drug discovery processes and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09118",
      "abstract": "Continual learning aims to enable models to learn sequentially from continuously incoming data while retaining performance on previously learned tasks. With the Contrastive Language-Image Pre-trained model (CLIP) exhibiting strong capabilities across various downstream tasks, there has been growing interest in leveraging CLIP for continual learning in such scenarios. Most existing works overlook the inherent modality gap in CLIP, a key factor in its generalization and adaptability. In this paper, we analyze the variations in the modality gap during the fine-tuning of vision-language pre-trained models. Our observations reveal that the modality gap effectively reflects the extent to which pre-trained knowledge is preserved. Based on these insights, we propose a simple yet effective method, MG-CLIP, that improves CLIP's performance in class-incremental learning. Our approach leverages modality gap preservation to mitigate forgetting and modality gap compensation to enhance the capacity for new data, introducing a novel modality-gap-based perspective for continual learning. Extensive experiments on multiple benchmarks demonstrate that our method outperforms existing approaches without requiring additional replay data. Our code is available at https://github.com/linlany/MindtheGap.",
      "authors": [
        "Linlan Huang",
        "Xusheng Cao",
        "Haori Lu",
        "Yifan Meng",
        "Fei Yang",
        "Xialei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:28:42+00:00",
          "link": "https://arxiv.org/abs/2507.09118v1",
          "size": "2885kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Gap: Preserving and Compensating for the Modality Gap in CLIP-Based Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09118",
        "HTML": "https://arxiv.org/html/2507.09118v1",
        "PDF": "https://arxiv.org/pdf/2507.09118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on continual learning with CLIP and modality gap issues. It does not discuss any processing or creation of LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09577",
      "abstract": "Surgical video segmentation is a critical task in computer-assisted surgery, essential for enhancing surgical quality and patient outcomes. Recently, the Segment Anything Model 2 (SAM2) framework has demonstrated remarkable advancements in both image and video segmentation. However, the inherent limitations of SAM2's greedy selection memory design are amplified by the unique properties of surgical videos-rapid instrument movement, frequent occlusion, and complex instrument-tissue interaction-resulting in diminished performance in the segmentation of complex, long videos. To address these challenges, we introduce Memory Augmented (MA)-SAM2, a training-free video object segmentation strategy, featuring novel context-aware and occlusion-resilient memory models. MA-SAM2 exhibits strong robustness against occlusions and interactions arising from complex instrument movements while maintaining accuracy in segmenting objects throughout videos. Employing a multi-target, single-loop, one-prompt inference further enhances the efficiency of the tracking process in multi-instrument videos. Without introducing any additional parameters or requiring further training, MA-SAM2 achieved performance improvements of 4.36% and 6.1% over SAM2 on the EndoVis2017 and EndoVis2018 datasets, respectively, demonstrating its potential for practical surgical applications.",
      "authors": [
        "Ming Yin",
        "Fu Wang",
        "Xujiong Ye",
        "Yanda Meng",
        "Zeyu Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:05:25+00:00",
          "link": "https://arxiv.org/abs/2507.09577v1",
          "size": "4843kb",
          "version": "v1"
        }
      ],
      "title": "Memory-Augmented SAM2 for Training-Free Surgical Video Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09577",
        "HTML": "https://arxiv.org/html/2507.09577v1",
        "PDF": "https://arxiv.org/pdf/2507.09577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Discusses a method for video segmentation in surgical videos without training, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09649",
      "abstract": "Human-machine interaction through augmented reality (AR) and virtual reality (VR) is increasingly prevalent, requiring accurate and efficient gaze estimation which hinges on the accuracy of eye segmentation to enable smooth user experiences. We introduce EyeSeg, a novel eye segmentation framework designed to overcome key challenges that existing approaches struggle with: motion blur, eyelid occlusion, and train-test domain gaps. In these situations, existing models struggle to extract robust features, leading to suboptimal performance. Noting that these challenges can be generally quantified by uncertainty, we design EyeSeg as an uncertainty-aware eye segmentation framework for AR/VR wherein we explicitly model the uncertainties by performing Bayesian uncertainty learning of a posterior under the closed set prior. Theoretically, we prove that a statistic of the learned posterior indicates segmentation uncertainty levels and empirically outperforms existing methods in downstream tasks, such as gaze estimation. EyeSeg outputs an uncertainty score and the segmentation result, weighting and fusing multiple gaze estimates for robustness, which proves to be effective especially under motion blur, eyelid occlusion and cross-domain challenges. Moreover, empirical results suggest that EyeSeg achieves segmentation improvements of MIoU, E1, F1, and ACC surpassing previous approaches. The code is publicly available at https://github.com/JethroPeng/EyeSeg.",
      "authors": [
        "Zhengyuan Peng",
        "Jianqing Xu",
        "Shen Li",
        "Jiazhen Ji",
        "Yuge Huang",
        "Jingyun Zhang",
        "Jinmin Li",
        "Shouhong Ding",
        "Rizen Guo",
        "Xin Tan",
        "Lizhuang Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:33:10+00:00",
          "link": "https://arxiv.org/abs/2507.09649v1",
          "size": "2052kb",
          "version": "v1"
        }
      ],
      "title": "EyeSeg: An Uncertainty-Aware Eye Segmentation Framework for AR/VR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09649",
        "HTML": "https://arxiv.org/html/2507.09649v1",
        "PDF": "https://arxiv.org/pdf/2507.09649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on eye segmentation in AR/VR applications and uncertainty modeling, with no relevance to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09958",
      "abstract": "Inductive bias is a key factor in spatial regression models, determining how well a model can learn from limited data and capture spatial patterns. This work revisits the inductive biases in Geographically Neural Network Weighted Regression (GNNWR) and identifies limitations in current approaches for modeling spatial non-stationarity. While GNNWR extends traditional Geographically Weighted Regression by using neural networks to learn spatial weighting functions, existing implementations are often restricted by fixed distance-based schemes and limited inductive bias. We propose to generalize GNNWR by incorporating concepts from convolutional neural networks, recurrent neural networks, and transformers, introducing local receptive fields, sequential context, and self-attention into spatial regression. Through extensive benchmarking on synthetic spatial datasets with varying heterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic methods in capturing nonlinear and complex spatial relationships. Our results also reveal that model performance depends strongly on data characteristics, with local models excelling in highly heterogeneous or small-sample scenarios, and global models performing better with larger, more homogeneous data. These findings highlight the importance of inductive bias in spatial modeling and suggest future directions, including learnable spatial weighting functions, hybrid neural architectures, and improved interpretability for models handling non-stationary spatial data.",
      "authors": [
        "Zhenyuan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:13:18+00:00",
          "link": "https://arxiv.org/abs/2507.09958v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09958",
        "HTML": "https://arxiv.org/html/2507.09958v1",
        "PDF": "https://arxiv.org/pdf/2507.09958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on spatial regression models, specifically addressing inductive biases in Geographically Neural Network Weighted Regression, without contributing to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10485",
      "abstract": "Catastrophic forgetting is the primary challenge that hinders continual learning, which refers to a neural network ability to sequentially learn multiple tasks while retaining previously acquired knowledge. Elastic Weight Consolidation, a regularization-based approach inspired by synaptic consolidation in biological neural systems, has been used to overcome this problem. In this study prior research is replicated and extended by evaluating EWC in supervised learning settings using the PermutedMNIST and RotatedMNIST benchmarks. Through systematic comparisons with L2 regularization and stochastic gradient descent (SGD) without regularization, we analyze how different approaches balance knowledge retention and adaptability. Our results confirm what was shown in previous research, showing that EWC significantly reduces forgetting compared to naive training while slightly compromising learning efficiency on new tasks. Moreover, we investigate the impact of dropout regularization and varying hyperparameters, offering insights into the generalization of EWC across diverse learning scenarios. These results underscore EWC's potential as a viable solution for lifelong learning in neural networks.",
      "authors": [
        "Brandon Shuen Yi Loke",
        "Filippo Quadri",
        "Gabriel Vivanco",
        "Maximilian Casagrande",
        "Sa\\'ul Fenollosa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:04:05+00:00",
          "link": "https://arxiv.org/abs/2507.10485v1",
          "size": "1359kb",
          "version": "v1"
        }
      ],
      "title": "Overcoming catastrophic forgetting in neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10485",
        "HTML": "https://arxiv.org/html/2507.10485v1",
        "PDF": "https://arxiv.org/pdf/2507.10485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with catastrophic forgetting in neural networks through a regularization approach, focusing on model training techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11760",
      "abstract": "Spiking Neural Networks (SNNs) have the potential to drastically reduce the energy requirements of AI systems. However, mainstream accelerators like GPUs and TPUs are designed for the high arithmetic intensity of standard ANNs so are not well-suited to SNN simulation. FPGAs are well-suited to applications with low arithmetic intensity as they have high off-chip memory bandwidth and large amounts of on-chip memory. Here, we present a novel RISC-V-based soft vector processor (FeNN), tailored to simulating SNNs on FPGAs. Unlike most dedicated neuromorphic hardware, FeNN is fully programmable and designed to be integrated with applications running on standard computers from the edge to the cloud. We demonstrate that, by using stochastic rounding and saturation, FeNN can achieve high numerical precision with low hardware utilisation and that a single FeNN core can simulate an SNN classifier faster than both an embedded GPU and the Loihi neuromorphic system.",
      "authors": [
        "Zainab Aizaz",
        "James C. Knight and Thomas Nowotny"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T13:13:54+00:00",
          "link": "https://arxiv.org/abs/2506.11760v1",
          "size": "1012kb",
          "version": "v1"
        }
      ],
      "title": "FeNN: A RISC-V vector processor for Spiking Neural Network acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11760",
        "HTML": "https://arxiv.org/html/2506.11760",
        "PDF": "https://arxiv.org/pdf/2506.11760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a vector processor for SNN acceleration, rather than discussing LLM training data processing or relevant data-engineering techniques."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/neworderofjamie/riscv_ise"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08950",
      "abstract": "This paper investigates the asymptotic behavior of the deterministic and stochastic Cram\\'er-Rao Bounds (CRB) for semi-blind channel estimation in massive multiple-input multiple-output (MIMO) systems. We derive and analyze mathematically tractable expressions for both metrics under various asymptotic regimes, which govern the growth rates of the number of antennas, the number of users, the training sequence length, and the transmission block length. Unlike the existing work, our results show that the CRB can be made arbitrarily small as the transmission block length increases, but only when the training sequence length grows at the same rate and the number of users remains fixed. However, if the number of training sequences remains proportional to the number of users, the channel estimation error is always lower-bounded by a non-vanishing constant. Numerical results are presented to support our findings and demonstrate the advantages of semi-blind channel estimation in reducing the required number of training sequences.",
      "authors": [
        "Xue Zhang",
        "Abla Kammoun",
        "Mohamed-Slim Alouini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:13:44+00:00",
          "link": "https://arxiv.org/abs/2507.08950v1",
          "size": "790kb",
          "version": "v1"
        }
      ],
      "title": "Fundamental limits via CRB of semi-blind channel estimation in Massive MIMO systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08950",
        "HTML": "https://arxiv.org/html/2507.08950v1",
        "PDF": "https://arxiv.org/pdf/2507.08950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work deals with channel estimation in MIMO systems and does not discuss LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09482",
      "abstract": "Human emotions are complex, with sarcasm being a subtle and distinctive form. Despite progress in sarcasm research, sarcasm generation remains underexplored, primarily due to the overreliance on textual modalities and the neglect of visual cues, as well as the mismatch between image content and sarcastic intent in existing datasets. In this paper, we introduce M2SaG, a multimodal sarcasm generation dataset with 4,970 samples, each containing an image, a sarcastic text, and a sarcasm target. To benchmark M2SaG, we propose ViSP, a generation framework that integrates Proximal Policy Optimization (PPO) and contrastive learning. PPO utilizes reward scores from DIP to steer the generation of sarcastic texts, while contrastive learning encourages the model to favor outputs with higher reward scores. These strategies improve overall generation quality and produce texts with more pronounced sarcastic intent. We evaluate ViSP across five metric sets and find it surpasses all baselines, including large language models, underscoring their limitations in sarcasm generation. Furthermore, we analyze the distributions of Sarcasm Scores and Factual Incongruity for both M2SaG and the texts generated by ViSP. The generated texts exhibit higher mean Sarcasm Scores (0.898 vs. 0.770) and Factual Incongruity (0.768 vs. 0.739), demonstrating that ViSP produces higher-quality sarcastic content than the original dataset. % The dataset and code will be publicly available. Our dataset and code will be released at \\textit{https://github.com/wclapply/ViSP}.",
      "authors": [
        "Changli Wang",
        "Rui Wu",
        "Fang Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:03:05+00:00",
          "link": "https://arxiv.org/abs/2507.09482v1",
          "size": "1156kb",
          "version": "v1"
        }
      ],
      "title": "ViSP: A PPO-Driven Framework for Sarcasm Generation with Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09482",
        "HTML": "https://arxiv.org/html/2507.09482v1",
        "PDF": "https://arxiv.org/pdf/2507.09482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a core contribution by introducing a new dataset (M2SaG) for sarcasm generation and details the data processing involved in creating the dataset, which contributes to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09740",
      "abstract": "In the study of complex dynamical systems, understanding and accurately modeling the underlying physical processes is crucial for predicting system behavior and designing effective interventions. Yet real-world systems exhibit pronounced input (or system) variability and are observed through noisy, limited data conditions that confound traditional discovery methods that assume fixed-coefficient deterministic models. In this work, we theorize that accounting for system variability together with measurement noise is the key to consistently discover the governing equations underlying dynamical systems. As such, we introduce a stochastic inverse physics-discovery (SIP) framework that treats the unknown coefficients as random variables and infers their posterior distribution by minimizing the Kullback-Leibler divergence between the push-forward of the posterior samples and the empirical data distribution. Benchmarks on four canonical problems -- the Lotka-Volterra predator-prey system (multi- and single-trajectory), the historical Hudson Bay lynx-hare data, the chaotic Lorenz attractor, and fluid infiltration in porous media using low- and high-viscosity liquids -- show that SIP consistently identifies the correct equations and lowers coefficient root-mean-square error by an average of 82\\% relative to the Sparse Identification of Nonlinear Dynamics (SINDy) approach and its Bayesian variant. The resulting posterior distributions yield 95\\% credible intervals that closely track the observed trajectories, providing interpretable models with quantified uncertainty. SIP thus provides a robust, data-efficient approach for consistent physics discovery in noisy, variable, and data-limited settings.",
      "authors": [
        "Ridwan Olabiyi",
        "Han Hu",
        "and Ashif Iquebal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:31:25+00:00",
          "link": "https://arxiv.org/abs/2507.09740v1",
          "size": "3724kb",
          "version": "v1"
        }
      ],
      "title": "Discovering Governing Equations in the Presence of Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09740",
        "HTML": "https://arxiv.org/html/2507.09740v1",
        "PDF": "https://arxiv.org/pdf/2507.09740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presents a framework for discovering governing equations in dynamical systems, focusing on handling uncertainty and noise. It does not pertain to LLM training data processing or data engineering operations relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10419",
      "abstract": "We propose LoRA-MCL, a training scheme that extends next-token prediction in language models with a method designed to decode diverse, plausible sentence continuations at inference time. Traditional language modeling is an intrinsically ill-posed problem: given a context, multiple futures may be equally plausible. Our approach leverages Multiple Choice Learning (MCL) and the Winner-Takes-All (WTA) loss to efficiently handle ambiguity through Low-Rank Adaptation (LoRA). We provide a theoretical interpretation of applying Multiple Choice Learning to Language Modeling, assuming the data is generated from a mixture of distributions. To illustrate the proposed approach, we use data sampled from mixtures of Markov chains. We then demonstrate with extensive experiments on real-world visual and audio captioning tasks that our method achieves high diversity and relevance in generated outputs.",
      "authors": [
        "Victor Letzelter",
        "Hugo Malard",
        "Mathieu Fontaine",
        "Ga\\\"el Richard",
        "Slim Essid",
        "Andrei Bursuc",
        "Patrick P\\'erez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:00:51+00:00",
          "link": "https://arxiv.org/abs/2507.10419v1",
          "size": "7145kb",
          "version": "v1"
        }
      ],
      "title": "Multiple Choice Learning of Low Rank Adapters for Language Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10419",
        "HTML": "https://arxiv.org/html/2507.10419v1",
        "PDF": "https://arxiv.org/pdf/2507.10419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces LoRA-MCL for language modeling diversity, it primarily focuses on model architecture without specific emphasis on training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10496",
      "abstract": "Transformers are increasingly prevalent for multi-view computer vision tasks, where geometric relationships between viewpoints are critical for 3D perception. To leverage these relationships, multi-view transformers must use camera geometry to ground visual tokens in 3D space. In this work, we compare techniques for conditioning transformers on cameras: token-level raymap encodings, attention-level relative pose encodings, and a new relative encoding we propose -- Projective Positional Encoding (PRoPE) -- that captures complete camera frustums, both intrinsics and extrinsics, as a relative positional encoding. Our experiments begin by showing how relative camera conditioning improves performance in feedforward novel view synthesis, with further gains from PRoPE. This holds across settings: scenes with both shared and varying intrinsics, when combining token- and attention-level conditioning, and for generalization to inputs with out-of-distribution sequence lengths and camera intrinsics. We then verify that these benefits persist for different tasks, stereo depth estimation and discriminative spatial cognition, as well as larger model sizes.",
      "authors": [
        "Ruilong Li",
        "Brent Yi",
        "Junchen Liu",
        "Hang Gao",
        "Yi Ma",
        "Angjoo Kanazawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:22:45+00:00",
          "link": "https://arxiv.org/abs/2507.10496v1",
          "size": "3801kb",
          "version": "v1"
        }
      ],
      "title": "Cameras as Relative Positional Encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10496",
        "HTML": "https://arxiv.org/html/2507.10496v1",
        "PDF": "https://arxiv.org/pdf/2507.10496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with transformer techniques for multi-view computer vision tasks, without focusing on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09051",
      "abstract": "Mental health (MH) apps often require sensitive user data to customize services for mental wellness needs. However, such data collection practices in some MH apps raise significant privacy concerns for users. These concerns are often mentioned in app reviews, but other feedback categories, such as reliability and usability, tend to take precedence. This poses a significant challenge in automatically identifying privacy requirements-relevant reviews (privacy reviews) that can be utilized to extract privacy requirements and address users' privacy concerns. Thus, this study introduces SAGE, a context-aware approach to automatically mining privacy reviews from MH apps using Natural Language Inference (NLI) with MH domain-specific privacy hypotheses (provides domain-specific context awareness) and a GPT model (eliminates the need for fine-tuning). The quantitative evaluation of SAGE on a dataset of 204K app reviews achieved an F1 score of 0.85 without any fine-tuning, outperforming the fine-tuned baseline classifiers BERT and T5. Furthermore, SAGE extracted 748 privacy reviews previously overlooked by keyword-based methods, demonstrating its effectiveness through qualitative evaluation. These reviews can later be refined into actionable privacy requirement artifacts.",
      "authors": [
        "Aakash Sorathiya and Gouri Ginde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:53:56+00:00",
          "link": "https://arxiv.org/abs/2507.09051v1",
          "size": "267kb",
          "version": "v1"
        }
      ],
      "title": "SAGE: A Context-Aware Approach for Mining Privacy Requirements Relevant Reviews from Mental Health Apps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09051",
        "HTML": "https://arxiv.org/html/2507.09051v1",
        "PDF": "https://arxiv.org/pdf/2507.09051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a method to extract privacy requirements from app reviews using NLI and an LLM. It does not contribute to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09768",
      "abstract": "In recent years, deep learning-based single-channel speech separation has improved considerably, in large part driven by increasingly compute- and parameter-efficient neural network architectures. Most such architectures are, however, designed with a fixed compute and parameter budget, and consequently cannot scale to varying compute demands or resources, which limits their use in embedded and heterogeneous devices such as mobile phones and hearables. To enable such use-cases we design a neural network architecture for speech separation capable of early-exit, and we propose an uncertainty-aware probabilistic framework to jointly model the clean speech signal and error variance which we use to derive probabilistic early-exit conditions in terms of desired signal-to-noise ratios. We evaluate our methods on both speech separation and enhancement tasks, and we show that a single early-exit model can be competitive with state-of-the-art models trained at many compute and parameter budgets. Our framework enables fine-grained dynamic compute-scaling of speech separation networks while achieving state-of-the-art performance and interpretable exit conditions.",
      "authors": [
        "Kenny Falk{\\ae}r Olsen. Mads {\\O}stergaard",
        "Karl Ulb{\\ae}k",
        "S{\\o}ren F{\\o}ns Nielsen",
        "Rasmus Malik H{\\o}egh Lindrup",
        "Bj{\\o}rn Sand Jensen",
        "Morten M{\\o}rup"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:52:34+00:00",
          "link": "https://arxiv.org/abs/2507.09768v1",
          "size": "1882kb",
          "version": "v1"
        }
      ],
      "title": "Knowing When to Quit: Probabilistic Early Exits for Speech Separation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09768",
        "HTML": "https://arxiv.org/html/2507.09768v1",
        "PDF": "https://arxiv.org/pdf/2507.09768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural network architecture design for speech separation, emphasizing compute scaling and efficiency, with no indication of involvement in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09992",
      "abstract": "Fear is a critical brain function for detecting danger and learning to avoid specific stimuli that can lead to danger. While fear is believed to have evolved under pressure from predators, experimentally reproducing the evolution is challenging. To investigate the relationship between environmental conditions, the evolution of fear, and the evolution of other rewards, such as food reward and social reward, we developed a distributed evolutionary simulation. In our simulation, prey and predator agents co-evolve their innate reward functions, including a possibly fear-like term for observing predators, and learn behaviors via reinforcement learning. Surprisingly, our simulation revealed that social reward for observing the same species is more important for prey to survive, and fear-like negative reward for observing predators evolves only after acquiring social reward. We also found that the predator with increased hunting ability (larger mouth) amplified fear emergence, but also that fear evolution is more stable with non-evolving predators that are bad at chasing prey. Additionally, unlike for predators, we found that positive rewards evolve in opposition to fear for stationary threats, as areas with abundant leftover food develop around them. These findings suggest that fear and social reward have had a complex interplay with each other through evolution, along with the nature of predators and threats.",
      "authors": [
        "Yuji Kanagawa and Kenji Doya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:27:18+00:00",
          "link": "https://arxiv.org/abs/2507.09992v1",
          "size": "1635kb",
          "version": "v1"
        }
      ],
      "title": "Evolution of Fear and Social Rewards in Prey-Predator Relationship",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09992",
        "HTML": "https://arxiv.org/html/2507.09992v1",
        "PDF": "https://arxiv.org/pdf/2507.09992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on evolutionary simulations of prey-predator dynamics, without involving LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10204",
      "abstract": "Inspection of complex underwater structures with tethered underwater vehicles is often hindered by the risk of tether entanglement. We propose REACT (real-time entanglement-aware coverage path planning for tethered underwater vehicles), a framework designed to overcome this limitation. REACT comprises a fast geometry-based tether model using the signed distance field (SDF) map for accurate, real-time simulation of taut tether configurations around arbitrary structures in 3D. This model enables an efficient online replanning strategy by enforcing a maximum tether length constraint, thereby actively preventing entanglement. By integrating REACT into a coverage path planning framework, we achieve safe and optimal inspection paths, previously challenging due to tether constraints. The complete REACT framework's efficacy is validated in a pipe inspection scenario, demonstrating safe, entanglement-free navigation and full-coverage inspection. Simulation results show that REACT achieves complete coverage while maintaining tether constraints and completing the total mission 20% faster than conventional planners, despite a longer inspection time due to proactive avoidance of entanglement that eliminates extensive post-mission disentanglement. Real-world experiments confirm these benefits, where REACT completes the full mission, while the baseline planner fails due to physical tether entanglement.",
      "authors": [
        "Abdelhakim Amer",
        "Mohit Mehindratta",
        "Yury Brodskiy",
        "Bilal Wehbe and Erdal Kayacan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:18:01+00:00",
          "link": "https://arxiv.org/abs/2507.10204v1",
          "size": "690kb",
          "version": "v1"
        }
      ],
      "title": "REACT: Real-time Entanglement-Aware Coverage Path Planning for Tethered Underwater Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10204",
        "HTML": "https://arxiv.org/html/2507.10204v1",
        "PDF": "https://arxiv.org/pdf/2507.10204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces REACT for tethered underwater vehicles focusing on path planning and entanglement-aware navigation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09103",
      "abstract": "Current state-of-the-art generative approaches frequently rely on a two-stage training procedure, where an autoencoder (often a VAE) first performs dimensionality reduction, followed by training a generative model on the learned latent space. While effective, this introduces computational overhead and increased sampling times. We challenge this paradigm by proposing Consistency Training of Variational AutoEncoders (CoVAE), a novel single-stage generative autoencoding framework that adopts techniques from consistency models to train a VAE architecture. The CoVAE encoder learns a progressive series of latent representations with increasing encoding noise levels, mirroring the forward processes of diffusion and flow matching models. This sequence of representations is regulated by a time dependent $\\beta$ parameter that scales the KL loss. The decoder is trained using a consistency loss with variational regularization, which reduces to a conventional VAE loss at the earliest latent time. We show that CoVAE can generate high-quality samples in one or few steps without the use of a learned prior, significantly outperforming equivalent VAEs and other single-stage VAEs methods. Our approach provides a unified framework for autoencoding and diffusion-style generative modeling and provides a viable route for one-step generative high-performance autoencoding. Our code is publicly available at https://github.com/gisilvs/covae.",
      "authors": [
        "Gianluigi Silvestri",
        "Luca Ambrogioni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:32:08+00:00",
          "link": "https://arxiv.org/abs/2507.09103v1",
          "size": "9628kb",
          "version": "v1"
        }
      ],
      "title": "CoVAE: Consistency Training of Variational Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09103",
        "HTML": "https://arxiv.org/html/2507.09103v1",
        "PDF": "https://arxiv.org/pdf/2507.09103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses improvements in VAE generative modeling, focusing on methods for generative autoencoding rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10014",
      "abstract": "Coccidioidomycosis, commonly known as Valley Fever, remains a significant public health concern in endemic regions of the southwestern United States. This study develops the first graph neural network (GNN) model for forecasting Valley Fever incidence in Arizona. The model integrates surveillance case data with environmental predictors using graph structures, including soil conditions, atmospheric variables, agricultural indicators, and air quality metrics. Our approach explores correlation-based relationships among variables influencing disease transmission. The model captures critical delays in disease progression through lagged effects, enhancing its capacity to reflect complex temporal dependencies in disease ecology. Results demonstrate that the GNN architecture effectively models Valley Fever trends and provides insights into key environmental drivers of disease incidence. These findings can inform early warning systems and guide resource allocation for disease prevention efforts in high-risk areas.",
      "authors": [
        "Ali Sarabi",
        "Arash Sarabi",
        "Hao Yan",
        "Beckett Sterner",
        "and Petar Jevti\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:50:25+00:00",
          "link": "https://arxiv.org/abs/2507.10014v1",
          "size": "1313kb",
          "version": "v1"
        }
      ],
      "title": "Forecasting Coccidioidomycosis (Valley Fever) in Arizona: A Graph Neural Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10014",
        "HTML": "https://arxiv.org/html/2507.10014v1",
        "PDF": "https://arxiv.org/pdf/2507.10014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on forecasting Valley Fever using a graph neural network approach, integrating case data with environmental predictors. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10000",
      "abstract": "Graph Neural Networks (GNNs) with equivariant properties have achieved significant success in modeling complex dynamic systems and molecular properties. However, their expressiveness ability is limited by: (1) Existing methods often overlook the over-smoothing issue caused by traditional GNN models, as well as the gradient explosion or vanishing problems in deep GNNs. (2) Most models operate on first-order information, neglecting that the real world often consists of second-order systems, which further limits the model's representation capabilities. To address these issues, we propose the \\textbf{Du}al \\textbf{S}econd-order \\textbf{E}quivariant \\textbf{G}raph \\textbf{O}rdinary Differential Equation (\\method{}) for equivariant representation. Specifically, \\method{} apply the dual second-order equivariant graph ordinary differential equations (Graph ODEs) on graph embeddings and node coordinates, simultaneously. Theoretically, we first prove that \\method{} maintains the equivariant property. Furthermore, we provide theoretical insights showing that \\method{} effectively alleviates the over-smoothing problem in both feature representation and coordinate update. Additionally, we demonstrate that the proposed \\method{} mitigates the exploding and vanishing gradients problem, facilitating the training of deep multi-layer GNNs. Extensive experiments on benchmark datasets validate the superiority of the proposed \\method{} compared to baselines.",
      "authors": [
        "Yingxu Wang",
        "Nan Yin",
        "Mingyan Xiao",
        "Xinhao Yi",
        "Siwei Liu",
        "Shangsong Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T07:15:05+00:00",
          "link": "https://arxiv.org/abs/2411.10000v1",
          "size": "2167kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T03:51:37+00:00",
          "link": "https://arxiv.org/abs/2411.10000v2",
          "size": "1446kb",
          "version": "v2"
        }
      ],
      "title": "DuSEGO: Dual Second-order Equivariant Graph Ordinary Differential Equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10000",
        "HTML": "https://arxiv.org/html/2411.10000v2",
        "PDF": "https://arxiv.org/pdf/2411.10000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Graph Neural Networks with a focus on second-order equivariant models, tackling issues like over-smoothing and gradient problems. It does not involve LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.17075",
      "abstract": "Compilers are indispensable for transforming code written in high-level languages into performant machine code, but their general-purpose optimizations sometimes fall short. Domain experts might be aware of certain optimizations that the compiler is unable to apply or that are only valid in a particular domain. We have developed a system that allows domain experts to express rewrite rules to optimize code in the Julia programming language. Our system builds on e-graphs and equality saturation. It can apply optimizations in the presence of control flow and side effects. As Julia uses multiple dispatch, we allow users to constrain rewrite rules by argument types, and propagate type information through the e-graph representation. We propose an ILP formulation for optimal e-graph extraction taking into account dominance properties for code reuse and introduce CFG skeleton relaxation to rewrite calls to pure functions as well as those with side effects. Use cases demonstrate that our system can perform rewrites on high-level, domain-specific code, as well as on lower-level code such as Julia's broadcasting mechanism. Finally, we analyze the required compilation time.",
      "authors": [
        "Jules Merckx",
        "Tim Besard",
        "Bjorn De Sutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T11:40:49+00:00",
          "link": "https://arxiv.org/abs/2502.17075v1",
          "size": "1286kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T11:55:53+00:00",
          "link": "https://arxiv.org/abs/2502.17075v2",
          "size": "507kb",
          "version": "v2"
        }
      ],
      "title": "Equality Saturation for Optimizing High-Level Julia IR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17075",
        "HTML": "https://arxiv.org/html/2502.17075v2",
        "PDF": "https://arxiv.org/pdf/2502.17075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on code optimization in the Julia programming language using equality saturation and does not pertain to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08804",
      "abstract": "AI-augmented systems are traditionally designed to streamline human decision-making by minimizing cognitive load, clarifying arguments, and optimizing efficiency. However, in a world where algorithmic certainty risks becoming an Orwellian tool of epistemic control, true intellectual growth demands not passive acceptance but active struggle. Drawing on the dystopian visions of George Orwell and Philip K. Dick - where reality is unstable, perception malleable, and truth contested - this paper introduces Cognitive Dissonance AI (CD-AI): a novel framework that deliberately sustains uncertainty rather than resolving it. CD-AI does not offer closure, but compels users to navigate contradictions, challenge biases, and wrestle with competing truths. By delaying resolution and promoting dialectical engagement, CD-AI enhances reflective reasoning, epistemic humility, critical thinking, and adaptability in complex decision-making. This paper examines the theoretical foundations of the approach, presents an implementation model, explores its application in domains such as ethics, law, politics, and science, and addresses key ethical concerns - including decision paralysis, erosion of user autonomy, cognitive manipulation, and bias in AI reasoning. In reimagining AI as an engine of doubt rather than a deliverer of certainty, CD-AI challenges dominant paradigms of AI-augmented reasoning and offers a new vision - one in which AI sharpens the mind not by resolving conflict, but by sustaining it. Rather than reinforcing Huxleyan complacency or pacifying the user into intellectual conformity, CD-AI echoes Nietzsche's vision of the Uebermensch - urging users to transcend passive cognition through active epistemic struggle.",
      "authors": [
        "Delia Deliu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T03:18:05+00:00",
          "link": "https://arxiv.org/abs/2507.08804v1",
          "size": "363kb",
          "version": "v1"
        }
      ],
      "title": "Cognitive Dissonance Artificial Intelligence (CD-AI): The Mind at War with Itself. Harnessing Discomfort to Sharpen Critical Thinking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08804",
        "PDF": "https://arxiv.org/pdf/2507.08804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for cognitive dissonance in AI to enhance critical thinking, not related to any aspects of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09308",
      "abstract": "Recent advances in latent diffusion models have achieved remarkable results in high-fidelity RGB image synthesis by leveraging pretrained VAEs to compress and reconstruct pixel data at low computational cost. However, the generation of transparent or layered content (RGBA image) remains largely unexplored, due to the lack of large-scale benchmarks. In this work, we propose ALPHA, the first comprehensive RGBA benchmark that adapts standard RGB metrics to four-channel images via alpha blending over canonical backgrounds. We further introduce ALPHAVAE, a unified end-to-end RGBA VAE that extends a pretrained RGB VAE by incorporating a dedicated alpha channel. The model is trained with a composite objective that combines alpha-blended pixel reconstruction, patch-level fidelity, perceptual consistency, and dual KL divergence constraints to ensure latent fidelity across both RGB and alpha representations. Our RGBA VAE, trained on only 8K images in contrast to 1M used by prior methods, achieves a +4.9 dB improvement in PSNR and a +3.2% increase in SSIM over LayerDiffuse in reconstruction. It also enables superior transparent image generation when fine-tuned within a latent diffusion framework. Our code, data, and models are released on https://github.com/o0o0o00o0/AlphaVAE for reproducibility.",
      "authors": [
        "Zile Wang and Hao Yu and Jiabo Zhan and Chun Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:53:42+00:00",
          "link": "https://arxiv.org/abs/2507.09308v1",
          "size": "25563kb",
          "version": "v1"
        }
      ],
      "title": "AlphaVAE: Unified End-to-End RGBA Image Reconstruction and Generation with Alpha-Aware Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09308",
        "PDF": "https://arxiv.org/pdf/2507.09308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on RGBA image reconstruction and generation using a VAE model, without discussing any processing related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09422",
      "abstract": "We present for every $n\\ge4$ an $n$-player game in normal form with payoffs in $\\{0,1,2\\}$ that has a unique, fully mixed, Nash equilibrium in which all the probability weights are irradical (i.e., algebraic but not closed form expressible even with $m$-th roots for any integer $m$).",
      "authors": [
        "Edan Orzech",
        "Martin Rinard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:11:51+00:00",
          "link": "https://arxiv.org/abs/2507.09422v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "Nash Equilibria with Irradical Probabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09422",
        "HTML": "https://arxiv.org/html/2507.09422v1",
        "PDF": "https://arxiv.org/pdf/2507.09422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on game theory and Nash equilibria, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10447",
      "abstract": "With the rapid advancement of generative audio models, distinguishing between human-composed and generated music is becoming increasingly challenging. As a response, models for detecting fake music have been proposed. In this work, we explore the robustness of such systems under audio augmentations. To evaluate model generalization, we constructed a dataset consisting of both real and synthetic music generated using several systems. We then apply a range of audio transformations and analyze how they affect classification accuracy. We test the performance of a recent state-of-the-art musical deepfake detection model in the presence of audio augmentations. The performance of the model decreases significantly even with the introduction of light augmentations.",
      "authors": [
        "Tomasz Sroka",
        "Tomasz W\\k{e}\\.zowicz",
        "Dominik Sidorczuk",
        "Mateusz Modrzejewski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:15:02+00:00",
          "link": "https://arxiv.org/abs/2507.10447v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Fake Music Detection Performance Under Audio Augmentations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10447",
        "HTML": "https://arxiv.org/html/2507.10447v1",
        "PDF": "https://arxiv.org/pdf/2507.10447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates fake music detection under audio augmentations and does not involve LLM training data processing. It focuses on classification models and audio transformations specific to detecting musical deepfakes."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.11887",
      "abstract": "In this paper, we present a linear and reversible programming language with inductives types and recursion. The semantics of the languages is based on pattern-matching; we show how ensuring syntactical exhaustivity and non-overlapping of clauses is enough to ensure reversibility. The language allows to represent any Primitive Recursive Function. We then give a Curry-Howard correspondence with the logic $\\mu$MALL: linear logic extended with least fixed points allowing inductive statements. The critical part of our work is to show how primitive recursion yields circular proofs that satisfy $\\mu$MALL validity criterion and how the language simulates the cut-elimination procedure of $\\mu$MALL.",
      "authors": [
        "Kostia Chardonnet",
        "Alexis Saurin",
        "Beno\\^it Valiron"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-23T09:52:36+00:00",
          "link": "https://arxiv.org/abs/2302.11887v1",
          "size": "233kb",
          "version": "v1"
        },
        {
          "date": "2023-07-31T09:39:20+00:00",
          "link": "https://arxiv.org/abs/2302.11887v2",
          "size": "54kb",
          "version": "v2"
        },
        {
          "date": "2024-05-01T15:15:12+00:00",
          "link": "https://arxiv.org/abs/2302.11887v3",
          "size": "67kb",
          "version": "v3"
        },
        {
          "date": "2024-10-14T11:29:07+00:00",
          "link": "https://arxiv.org/abs/2302.11887v4",
          "size": "82kb",
          "version": "v4"
        },
        {
          "date": "2025-01-30T12:44:37+00:00",
          "link": "https://arxiv.org/abs/2302.11887v5",
          "size": "71kb",
          "version": "v5"
        },
        {
          "date": "2025-04-17T16:01:37+00:00",
          "link": "https://arxiv.org/abs/2302.11887v6",
          "size": "81kb",
          "version": "v6"
        },
        {
          "date": "2025-04-23T14:35:46+00:00",
          "link": "https://arxiv.org/abs/2302.11887v7",
          "size": "81kb",
          "version": "v7"
        },
        {
          "date": "2025-04-30T11:47:04+00:00",
          "link": "https://arxiv.org/abs/2302.11887v8",
          "size": "88kb",
          "version": "v8"
        },
        {
          "date": "2025-05-12T08:40:13+00:00",
          "link": "https://arxiv.org/abs/2302.11887v9",
          "size": "87kb",
          "version": "v9"
        },
        {
          "date": "2025-07-14T09:31:58+00:00",
          "link": "https://arxiv.org/abs/2302.11887v10",
          "size": "88kb",
          "version": "v10"
        }
      ],
      "title": "A Curry-Howard Correspondence for Linear, Reversible Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.11887",
        "PDF": "https://arxiv.org/pdf/2302.11887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a programming language and its logical correspondence, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18283",
      "abstract": "We define the local complexity of a neural network with continuous piecewise linear activations as a measure of the density of linear regions over an input data distribution. We show theoretically that ReLU networks that learn low-dimensional feature representations have a lower local complexity. This allows us to connect recent empirical observations on feature learning at the level of the weight matrices with concrete properties of the learned functions. In particular, we show that the local complexity serves as an upper bound on the total variation of the function over the input data distribution and thus that feature learning can be related to adversarial robustness. Lastly, we consider how optimization drives ReLU networks towards solutions with lower local complexity. Overall, this work contributes a theoretical framework towards relating geometric properties of ReLU networks to different aspects of learning such as feature learning and representation cost.",
      "authors": [
        "Niket Patel",
        "Guido Montufar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T08:42:39+00:00",
          "link": "https://arxiv.org/abs/2412.18283v1",
          "size": "25434kb",
          "version": "v1"
        },
        {
          "date": "2024-12-25T02:14:07+00:00",
          "link": "https://arxiv.org/abs/2412.18283v2",
          "size": "25434kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T02:07:39+00:00",
          "link": "https://arxiv.org/abs/2412.18283v3",
          "size": "18245kb",
          "version": "v3"
        }
      ],
      "title": "On the Local Complexity of Linear Regions in Deep ReLU Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18283",
        "PDF": "https://arxiv.org/pdf/2412.18283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a theoretical analysis of ReLU networks and does not involve LLM training data processing or dataset creation."
      },
      "tasks": [
        "Adversarial Robustness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07209",
      "abstract": "Implied-integer detection is a well-known presolving technique that is used by many Mixed-Integer Linear Programming solvers. Informally, a variable is said to be implied integer if its integrality is enforced implicitly by integrality of other variables and the constraints of a problem. In this work we formalize the definition of implied integrality by taking a polyhedral perspective. Our main result characterizes implied integrality as occurring when a subset of integer variables is fixed to integer values and the polyhedron on the remaining variables is integral. While integral polyhedra are well-understood theoretically, existing detection methods infer implied integrality only for one variable at a time. We introduce new detection methods based on the detection of integral polyhedra, extending existing techniques to multiple variables. Additionally, we discuss the computational complexity of recognizing implied integers. We conduct experiments using a new detection method that uses totally unimodular submatrices to identify implied integrality. For the MIPLIB 2017 collection dataset our results indicate that, on average, 18.8% of the variables are classified as implied integer after presolving, compared to just 3.3% identified by state-of-the-art techniques. Moreover, we are able to reduce the average percentage of variables whose integrality needs to be enforced after presolving from 70.2% to 59.0%.",
      "authors": [
        "Rolf van der Hulst",
        "Matthias Walter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T18:36:22+00:00",
          "link": "https://arxiv.org/abs/2504.07209v1",
          "size": "54kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T09:02:49+00:00",
          "link": "https://arxiv.org/abs/2504.07209v2",
          "size": "104kb",
          "version": "v2"
        }
      ],
      "title": "Implied Integrality in Mixed-Integer Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07209",
        "PDF": "https://arxiv.org/pdf/2504.07209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on implied integrality in mixed-integer optimization and optimization algorithms, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18527",
      "abstract": "Generating multi-view images from human instructions is crucial for 3D content creation. The primary challenges involve maintaining consistency across multiple views and effectively synthesizing shapes and textures under diverse conditions. In this paper, we propose the Multi-View Auto-Regressive (\\textbf{MV-AR}) method, which leverages an auto-regressive model to progressively generate consistent multi-view images from arbitrary prompts. Firstly, the next-token-prediction capability of the AR model significantly enhances its effectiveness in facilitating progressive multi-view synthesis. When generating widely-separated views, MV-AR can utilize all its preceding views to extract effective reference information. Subsequently, we propose a unified model that accommodates various prompts via architecture designing and training strategies. To address multiple conditions, we introduce condition injection modules for text, camera pose, image, and shape. To manage multi-modal conditions simultaneously, a progressive training strategy is employed. This strategy initially adopts the text-to-multi-view (t2mv) model as a baseline to enhance the development of a comprehensive X-to-multi-view (X2mv) model through the randomly dropping and combining conditions. Finally, to alleviate the overfitting problem caused by limited high-quality data, we propose the ``Shuffle View\" data augmentation technique, thus significantly expanding the training data by several magnitudes. Experiments demonstrate the performance and versatility of our MV-AR, which consistently generates consistent multi-view images across a range of conditions and performs on par with leading diffusion-based multi-view image generation models. The code and models are released at https://github.com/MILab-PKU/MVAR.",
      "authors": [
        "JiaKui Hu and Yuxiao Yang and Jialun Liu and Jinbo Wu and Chen Zhao and Yanye Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T11:28:37+00:00",
          "link": "https://arxiv.org/abs/2506.18527v1",
          "size": "2590kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T04:27:12+00:00",
          "link": "https://arxiv.org/abs/2506.18527v2",
          "size": "2590kb",
          "version": "v2"
        }
      ],
      "title": "Auto-Regressively Generating Multi-View Consistent Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18527",
        "HTML": "https://arxiv.org/html/2506.18527v2",
        "PDF": "https://arxiv.org/pdf/2506.18527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for generating multi-view images and mentions data augmentation to address limited data but does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03152",
      "abstract": "With the growing use of language models (LMs) in clinical environments, there is an immediate need to evaluate the accuracy and safety of LM-generated medical text. Currently, such evaluation relies solely on manual physician review. However, detecting errors in LM-generated text is challenging because 1) manual review is costly and 2) expert-composed reference outputs are often unavailable in real-world settings. While the \"LM-as-judge\" paradigm (a LM evaluating another LM) offers scalable evaluation, even frontier LMs can miss subtle but clinically significant errors. To address these challenges, we propose MedVAL, a self-supervised framework that leverages synthetic data to train evaluator LMs to assess whether LM-generated medical outputs are factually consistent with inputs, without requiring physician labels or reference outputs. To evaluate LM performance, we introduce MedVAL-Bench, a dataset containing 840 outputs annotated by physicians, following a physician-defined taxonomy of risk levels and error categories. Across 6 diverse medical tasks and 10 state-of-the-art LMs spanning open-source, proprietary, and medically adapted models, MedVAL fine-tuning significantly improves (p < 0.001) alignment with physicians on both seen and unseen tasks, increasing average F1 scores from 66% to 83%, with per-sample safety classification scores up to 86%. MedVAL improves the performance of even the best-performing proprietary LM (GPT-4o) by 8%. To support a scalable, risk-aware pathway towards clinical integration, we open-source the 1) codebase (https://github.com/StanfordMIMI/MedVAL), 2) MedVAL-Bench (https://huggingface.co/datasets/stanfordmimi/MedVAL-Bench), and 3) MedVAL-4B (https://huggingface.co/stanfordmimi/MedVAL-4B), the best-performing open-source LM. Our research provides the first evidence of LMs approaching expert-level validation ability for medical text.",
      "authors": [
        "Asad Aali",
        "Vasiliki Bikia",
        "Maya Varma",
        "Nicole Chiou",
        "Sophie Ostmeier",
        "Arnav Singhvi",
        "Magdalini Paschali",
        "Ashwin Kumar",
        "Andrew Johnston",
        "Karimar Amador-Martinez",
        "Eduardo Juan Perez Guerrero",
        "Paola Naovi Cruz Rivera",
        "Sergios Gatidis",
        "Christian Bluethgen",
        "Eduardo Pontes Reis",
        "Eddy D. Zandee van Rilland",
        "Poonam Laxmappa Hosamani",
        "Kevin R Keet",
        "Minjoung Go",
        "Evelyn Ling",
        "David B. Larson",
        "Curtis Langlotz",
        "Roxana Daneshjou",
        "Jason Hom",
        "Sanmi Koyejo",
        "Emily Alsentzer",
        "Akshay S. Chaudhari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T20:19:18+00:00",
          "link": "https://arxiv.org/abs/2507.03152v1",
          "size": "5655kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:51:35+00:00",
          "link": "https://arxiv.org/abs/2507.03152v2",
          "size": "5655kb",
          "version": "v2"
        }
      ],
      "title": "Expert-level validation of AI-generated medical text with scalable language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03152",
        "HTML": "https://arxiv.org/html/2507.03152v2",
        "PDF": "https://arxiv.org/pdf/2507.03152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes MedVAL, which involves synthetic data generation for training evaluator LMs, but the focus is primarily on evaluation rather than processing of LLM training data itself."
      },
      "models": [
        {
          "model_path": "stanfordmimi/MedVAL-4B",
          "downloads": "24",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/stanfordmimi/MedVAL-4B"
        },
        {
          "model_path": "stanfordmimi/MedVAL-4B-GGUF",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/stanfordmimi/MedVAL-4B-GGUF"
        }
      ],
      "datasets": [
        {
          "dataset_name": "stanfordmimi/MedVAL-Bench",
          "downloads": "104",
          "likes": "0",
          "link": "https://huggingface.co/datasets/stanfordmimi/MedVAL-Bench"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08036",
      "abstract": "Medical Visual Question Answering (MedVQA) is a promising tool to assist radiologists by automating medical image interpretation through question answering. Despite advances in models and datasets, MedVQA's integration into clinical workflows remains limited. This study systematically reviews 68 publications (2018-2024) and surveys 50 clinicians from India and Thailand to examine MedVQA's practical utility, challenges, and gaps. Following the Arksey and O'Malley scoping review framework, we used a two-pronged approach: (1) reviewing studies to identify key concepts, advancements, and research gaps in radiology workflows, and (2) surveying clinicians to capture their perspectives on MedVQA's clinical relevance. Our review reveals that nearly 60% of QA pairs are non-diagnostic and lack clinical relevance. Most datasets and models do not support multi-view, multi-resolution imaging, EHR integration, or domain knowledge, features essential for clinical diagnosis. Furthermore, there is a clear mismatch between current evaluation metrics and clinical needs. The clinician survey confirms this disconnect: only 29.8% consider MedVQA systems highly useful. Key concerns include the absence of patient history or domain knowledge (87.2%), preference for manually curated datasets (51.1%), and the need for multi-view image support (78.7%). Additionally, 66% favor models focused on specific anatomical regions, and 89.4% prefer dialogue-based interactive systems. While MedVQA shows strong potential, challenges such as limited multimodal analysis, lack of patient context, and misaligned evaluation approaches must be addressed for effective clinical integration.",
      "authors": [
        "Deepali Mishra",
        "Chaklam Silpasuwanchai",
        "Ashutosh Modi",
        "Madhumita Sushil",
        "Sorayouth Chumnanvej"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:51:20+00:00",
          "link": "https://arxiv.org/abs/2507.08036v1",
          "size": "7151kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T10:06:50+00:00",
          "link": "https://arxiv.org/abs/2507.08036v2",
          "size": "7152kb",
          "version": "v2"
        }
      ],
      "title": "Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08036",
        "PDF": "https://arxiv.org/pdf/2507.08036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey study reviewing Medical Visual QA and identifying challenges in clinical integration. It does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09037",
      "abstract": "Large language models (LLMs) are increasingly being used as decision aids. However, users have diverse values and preferences that can affect their decision-making, which requires novel methods for LLM alignment and personalization. Existing LLM comparison tools largely focus on benchmarking tasks, such as knowledge-based question answering. In contrast, our proposed ALIGN system focuses on dynamic personalization of LLM-based decision-makers through prompt-based alignment to a set of fine-grained attributes. Key features of our system include robust configuration management, structured output generation with reasoning, and several algorithm implementations with swappable LLM backbones, enabling different types of analyses. Our user interface enables a qualitative, side-by-side comparison of LLMs and their alignment to various attributes, with a modular backend for easy algorithm integration. Additionally, we perform a quantitative analysis comparing alignment approaches in two different domains: demographic alignment for public opinion surveys and value alignment for medical triage decision-making. The entire ALIGN framework is open source and will enable new research on reliable, responsible, and personalized LLM-based decision-makers.",
      "authors": [
        "Bharadwaj Ravichandran",
        "David Joy",
        "Paul Elliott",
        "Brian Hu",
        "Jadie Adams",
        "Christopher Funk",
        "Emily Veenhuis",
        "Anthony Hoogs",
        "Arslan Basharat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:33:38+00:00",
          "link": "https://arxiv.org/abs/2507.09037v1",
          "size": "1826kb",
          "version": "v1"
        }
      ],
      "title": "ALIGN: Prompt-based Attribute Alignment for Reliable, Responsible, and Personalized LLM-based Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09037",
        "HTML": "https://arxiv.org/html/2507.09037v1",
        "PDF": "https://arxiv.org/pdf/2507.09037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses LLM alignment and personalization for decision-making through prompt-based methods, and does not focus on LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09168",
      "abstract": "Text-guided image and 3D editing have advanced with diffusion-based models, yet methods like Delta Denoising Score often struggle with stability, spatial control, and editing strength. These limitations stem from reliance on complex auxiliary structures, which introduce conflicting optimization signals and restrict precise, localized edits. We introduce Stable Score Distillation (SSD), a streamlined framework that enhances stability and alignment in the editing process by anchoring a single classifier to the source prompt. Specifically, SSD utilizes Classifier-Free Guidance (CFG) equation to achieves cross-prompt alignment, and introduces a constant term null-text branch to stabilize the optimization process. This approach preserves the original content's structure and ensures that editing trajectories are closely aligned with the source prompt, enabling smooth, prompt-specific modifications while maintaining coherence in surrounding regions. Additionally, SSD incorporates a prompt enhancement branch to boost editing strength, particularly for style transformations. Our method achieves state-of-the-art results in 2D and 3D editing tasks, including NeRF and text-driven style edits, with faster convergence and reduced complexity, providing a robust and efficient solution for text-guided editing.",
      "authors": [
        "Haiming Zhu",
        "Yangyang Xu",
        "Chenshu Xu",
        "Tingrui Shen",
        "Wenxi Liu",
        "Yong Du",
        "Jun Yu",
        "Shengfeng He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:14:00+00:00",
          "link": "https://arxiv.org/abs/2507.09168v1",
          "size": "35839kb",
          "version": "v1"
        }
      ],
      "title": "Stable Score Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09168",
        "HTML": "https://arxiv.org/html/2507.09168v1",
        "PDF": "https://arxiv.org/pdf/2507.09168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Stable Score Distillation is about text-guided image and 3D editing. It involves diffusion-based models but does not include contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09252",
      "abstract": "We propose TPP-SD, a novel approach that accelerates Transformer temporal point process (TPP) sampling by adapting speculative decoding (SD) techniques from language models. By identifying the structural similarities between thinning algorithms for TPPs and speculative decoding for language models, we develop an efficient sampling framework that leverages a smaller draft model to generate multiple candidate events, which are then verified by the larger target model in parallel. TPP-SD maintains the same output distribution as autoregressive sampling while achieving significant acceleration. Experiments on both synthetic and real datasets demonstrate that our approach produces samples from identical distributions as standard methods, but with 2-6$\\times$ speedup. Our ablation studies analyze the impact of hyperparameters such as draft length and draft model size on sampling efficiency. TPP-SD bridges the gap between powerful Transformer TPP models and the practical need for rapid sequence sampling.",
      "authors": [
        "Shukai Gong",
        "Yiyang Fu",
        "Fengyuan Ran",
        "Feng Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:18:07+00:00",
          "link": "https://arxiv.org/abs/2507.09252v1",
          "size": "726kb",
          "version": "v1"
        }
      ],
      "title": "TPP-SD: Accelerating Transformer Point Process Sampling with Speculative Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09252",
        "HTML": "https://arxiv.org/html/2507.09252v1",
        "PDF": "https://arxiv.org/pdf/2507.09252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with improving sampling efficiency in temporal point processes using speculative decoding, without discussing processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09685",
      "abstract": "Proton Pump Inhibitors (PPIs) are the standard of care for gastric acid disorders but carry significant risks when administered chronically at high doses. Precise long-term control of gastric acidity is challenged by the impracticality of invasive gastric acid monitoring beyond 72 hours and wide inter-patient variability. We propose a noninvasive, symptom-based framework that tailors PPI dosing solely on patient-reported reflux and digestive symptom patterns. A Bayesian Neural Network prediction model learns to predict patient symptoms and quantifies its uncertainty from historical symptom scores, meal, and PPIs intake data. These probabilistic forecasts feed a chance-constrained Model Predictive Control (MPC) algorithm that dynamically computes future PPI doses to minimize drug usage while enforcing acid suppression with high confidence - without any direct acid measurement. In silico studies over diverse dietary schedules and virtual patient profiles demonstrate that our learning-augmented MPC reduces total PPI consumption by 65 percent compared to standard fixed regimens, while maintaining acid suppression with at least 95 percent probability. The proposed approach offers a practical path to personalized PPI therapy, minimizing treatment burden and overdose risk without invasive sensors.",
      "authors": [
        "Yutong Li and Ilya Kolmanovsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:46:41+00:00",
          "link": "https://arxiv.org/abs/2507.09685v1",
          "size": "1978kb",
          "version": "v1"
        }
      ],
      "title": "Symptom-Driven Personalized Proton Pump Inhibitors Therapy Using Bayesian Neural Networks and Model Predictive Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09685",
        "HTML": "https://arxiv.org/html/2507.09685v1",
        "PDF": "https://arxiv.org/pdf/2507.09685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a Bayesian Neural Network and Model Predictive Control for PPI dosing. It does not deal with LLM training data processing but instead focuses on personalized medical therapy."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09704",
      "abstract": "We propose a real-time method for reactive motion synthesis based on the known trajectory of input character, predicting instant reactions using only historical, user-controlled motions. Our method handles the uncertainty of future movements by introducing an intention predictor, which forecasts key joint intentions to make pose prediction more deterministic from the historical interaction. The intention is later encoded into the latent space of its reactive motion, matched with a codebook which represents mappings between input and output. It samples a categorical distribution for pose generation and strengthens model robustness through adversarial training. Unlike previous offline approaches, the system can recursively generate intentions and reactive motions using feedback from earlier steps, enabling real-time, long-term realistic interactive synthesis. Both quantitative and qualitative experiments show our approach outperforms other matching-based motion synthesis approaches, delivering superior stability and generalizability. In our method, user can also actively influence the outcome by controlling the moving directions, creating a personalized interaction path that deviates from predefined trajectories.",
      "authors": [
        "Xiaotang Zhang",
        "Ziyi Chang",
        "Qianhui Men",
        "Hubert Shum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:32:47+00:00",
          "link": "https://arxiv.org/abs/2507.09704v1",
          "size": "31947kb",
          "version": "v1"
        }
      ],
      "title": "Real-time and Controllable Reactive Motion Synthesis via Intention Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09704",
        "HTML": "https://arxiv.org/html/2507.09704v1",
        "PDF": "https://arxiv.org/pdf/2507.09704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reactive motion synthesis based on historical user-controlled motions, which does not involve processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.13728",
      "abstract": "Quantum state exclusion is an operational task that has significance in studying foundational questions related to interpreting quantum theory. In such a task, one is given a system whose state is randomly selected from a finite set, and the goal is to identify a state from the set that is not the true state of the system. An error, i.e., an unsuccessful exclusion, occurs if and only if the state identified is the true state. In this paper, we study the optimal error probability of quantum state exclusion and its error exponent -- the rate at which the error probability decays asymptotically -- from an information-theoretic perspective. Our main finding is a single-letter upper bound on the error exponent of state exclusion given by the multivariate log-Euclidean Chernoff divergence, and we prove that this improves upon the best previously known upper bound. We also extend our analysis to the more complicated task of quantum channel exclusion, and we establish a single-letter and efficiently computable upper bound on its error exponent, even assuming the use of adaptive strategies. We derive both upper bounds, for state and channel exclusion, based on one-shot analysis and formulate them as a type of multivariate divergence measure called a barycentric Chernoff divergence. Moreover, our result on channel exclusion has implications in two important special cases. First, for the special case of two hypotheses, our upper bound provides the first known efficiently computable upper bound on the error exponent of symmetric binary channel discrimination. Second, for the special case of classical channels, we show that our upper bound is achievable by a parallel strategy, thus solving the exact error exponent of classical channel exclusion and generalising a similar result on symmetric binary classical channel discrimination.",
      "authors": [
        "Kaiyuan Ji",
        "Hemant K. Mishra",
        "Mil\\'an Mosonyi",
        "and Mark M. Wilde"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-18T17:27:36+00:00",
          "link": "https://arxiv.org/abs/2407.13728v1",
          "size": "73kb",
          "version": "v1"
        },
        {
          "date": "2024-11-27T06:46:08+00:00",
          "link": "https://arxiv.org/abs/2407.13728v2",
          "size": "82kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T17:46:49+00:00",
          "link": "https://arxiv.org/abs/2407.13728v3",
          "size": "86kb",
          "version": "v3"
        }
      ],
      "title": "Barycentric bounds on the error exponents of quantum hypothesis exclusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.13728",
        "PDF": "https://arxiv.org/pdf/2407.13728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies quantum hypothesis exclusion and error exponents from an information-theoretic view, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07167",
      "abstract": "The combination of Oblivious RAM (ORAM) with Trusted Execution Environments (TEE) has found numerous real-world applications due to their complementary nature. TEEs alleviate the performance bottlenecks of ORAM, such as network bandwidth and roundtrip latency, and ORAM provides general-purpose protection for TEE applications against attacks exploiting memory access patterns. The defining property of this combination, which sets it apart from traditional ORAM designs, is its ability to ensure that memory accesses, both inside and outside of TEEs, are made oblivious, thus termed doubly oblivious RAM (O$_2$RAM). Efforts to develop O$_2$RAM with enhanced performance are ongoing.\n  In this work, we propose H$_2$O$_2$RAM, a high-performance doubly oblivious RAM construction. The distinguishing feature of our approach, compared to the existing tree-based doubly oblivious designs, is its first adoption of the hierarchical framework that enjoys inherently better data locality and parallelization. While the latest hierarchical solution, FutORAMa, achieves concrete efficiency in the classic client-server model by leveraging a relaxed assumption of sublinear-sized client-side private memory, adapting it to our scenario poses challenges due to the conflict between this relaxed assumption and our doubly oblivious requirement. To this end, we introduce several new efficient oblivious components to build a high-performance hierarchical O$_2$RAM (H$_2$O$_2$RAM). We implement our design and evaluate it on various scenarios. The results indicate that H$_2$O$_2$RAM reduces execution time by up to $\\sim 10^3$ times and saves memory usage by $5\\sim44$ times compared to state-of-the-art solutions.",
      "authors": [
        "Leqian Zheng",
        "Zheng Zhang",
        "Wentao Dong",
        "Yao Zhang",
        "Ye Wu",
        "Cong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T10:31:14+00:00",
          "link": "https://arxiv.org/abs/2409.07167v1",
          "size": "577kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T04:28:30+00:00",
          "link": "https://arxiv.org/abs/2409.07167v2",
          "size": "119kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T13:00:57+00:00",
          "link": "https://arxiv.org/abs/2409.07167v3",
          "size": "94kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T08:02:09+00:00",
          "link": "https://arxiv.org/abs/2409.07167v4",
          "size": "94kb",
          "version": "v4"
        }
      ],
      "title": "H$_2$O$_2$RAM: A High-Performance Hierarchical Doubly Oblivious RAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07167",
        "PDF": "https://arxiv.org/pdf/2409.07167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a high-performance hierarchical doubly oblivious RAM construction and does not address LLM training data processing or any related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.09135",
      "abstract": "Understanding land cover holds considerable potential for a myriad of practical applications, particularly as data accessibility transitions from being exclusive to governmental and commercial entities to now including the broader research community. Nevertheless, although the data is accessible to any community member interested in exploration, there exists a formidable learning curve and no standardized process for accessing, pre-processing, and leveraging the data for subsequent tasks. In this study, we democratize this data by presenting a flexible and efficient end to end pipeline for working with the Dynamic World dataset, a cutting-edge near-real-time land use/land cover (LULC) dataset. This includes a pre-processing and representation framework which tackles noise removal, efficient extraction of large amounts of data, and re-representation of LULC data in a format well suited for several downstream tasks. To demonstrate the power of our pipeline, we use it to extract data for an urbanization prediction problem and build a suite of machine learning models with excellent performance. This task is easily generalizable to the prediction of any type of land cover and our pipeline is also compatible with a series of other downstream tasks.",
      "authors": [
        "Victor Radermecker",
        "Andrea Zanon",
        "Nancy Thomas",
        "Annita Vapsi",
        "Saba Rahimi",
        "Rama Ramakrishnan",
        "Daniel Borrajo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T16:13:01+00:00",
          "link": "https://arxiv.org/abs/2410.09135v1",
          "size": "2677kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:09:39+00:00",
          "link": "https://arxiv.org/abs/2410.09135v2",
          "size": "5527kb",
          "version": "v2"
        }
      ],
      "title": "Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09135",
        "HTML": "https://arxiv.org/html/2410.09135v2",
        "PDF": "https://arxiv.org/pdf/2410.09135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a primary contribution by presenting a data preprocessing and representation framework for a land cover dataset, which enhances downstream tasks."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/victor-radermecker/advancedlandcoveranalytics-pipeline"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.21156",
      "abstract": "We introduce Cryptis, an extension of the Iris separation logic that can be used to verify cryptographic components using the symbolic model of cryptography. The combination of separation logic and cryptographic reasoning allows us to prove the correctness of a protocol and later reuse this result to verify larger systems that rely on the protocol. To make this integration possible, we propose novel specifications for authentication protocols that allow agents in a network to agree on the use of system resources. We evaluate our approach by verifying various authentication protocols and a key-value store server that uses these authentication protocols to connect to clients. Our results are formalized in Coq.",
      "authors": [
        "Arthur Azevedo de Amorim",
        "Amal Ahmed",
        "Marco Gaboardi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T15:33:37+00:00",
          "link": "https://arxiv.org/abs/2502.21156v1",
          "size": "92kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T01:10:13+00:00",
          "link": "https://arxiv.org/abs/2502.21156v2",
          "size": "64kb",
          "version": "v2"
        }
      ],
      "title": "Cryptis: Cryptographic Reasoning in Separation Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.21156",
        "PDF": "https://arxiv.org/pdf/2502.21156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on cryptographic reasoning within separation logic and does not discuss language model training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.17086",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable versatility, due to the lack of factual knowledge, their application to Question Answering (QA) tasks remains hindered by hallucination. While Retrieval-Augmented Generation mitigates these issues by integrating external knowledge, existing approaches rely heavily on in-context learning, whose performance is constrained by the fundamental reasoning capabilities of LLMs. In this paper, we propose Mujica, a Multi-hop Joint Intelligence for Complex Question Answering, comprising a planner that decomposes questions into a directed acyclic graph of subquestions and a worker that resolves questions via retrieval and reasoning. Additionally, we introduce MyGO (Minimalist policy Gradient Optimization), a novel reinforcement learning method that replaces traditional policy gradient updates with Maximum Likelihood Estimation (MLE) by sampling trajectories from an asymptotically optimal policy. MyGO eliminates the need for gradient rescaling and reference models, ensuring stable and efficient training. Empirical results across multiple datasets demonstrate the effectiveness of Mujica-MyGO in enhancing multi-hop QA performance for various LLMs, offering a scalable and resource-efficient solution for complex QA tasks.",
      "authors": [
        "Yihong Wu",
        "Liheng Ma",
        "Muzhi Li",
        "Jiaming Zhou",
        "Jianye Hao",
        "Ho-fung Leung",
        "Irwin King",
        "Yingxue Zhang",
        "Jian-Yun Nie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T18:33:03+00:00",
          "link": "https://arxiv.org/abs/2505.17086v1",
          "size": "428kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T17:26:34+00:00",
          "link": "https://arxiv.org/abs/2505.17086v2",
          "size": "466kb",
          "version": "v2"
        }
      ],
      "title": "Reinforcing Question Answering Agents with Minimalist Policy Gradient Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17086",
        "HTML": "https://arxiv.org/html/2505.17086v2",
        "PDF": "https://arxiv.org/pdf/2505.17086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on developing a reinforcement learning method for complex question answering. It does not make any contributions related to LLM training data processing or creation."
      },
      "tasks": [
        "Hallucination",
        "In-Context Learning",
        "Question Answering",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09324",
      "abstract": "Andr\\'eka and Maddux classified the relation algebras with at most 3 atoms, and in particular they showed that all of them are representable. Hirsch and Cristiani showed that the network satisfaction problem (NSP) for each of these algebras is in P or NP-hard. There are relation algebras with 4 atoms that are not representable, and there are many results in the literature about representations and non-representability of relation algebras with at most 4 atoms. We extend the result of Hirsch and Cristiani to relation algebras with at most 4 atoms: the NSP is always either in P or NP-hard. To this end, we construct universal, fully universal, or even normal representations for these algebras, whenever possible.",
      "authors": [
        "Manuel Bodirsky",
        "Moritz Jahn",
        "Mat\\v{e}j Kone\\v{c}n\\'y",
        "Simon Kn\\\"auer",
        "Paul Winkler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Rings and Algebras (math.RA)",
        "Computational Complexity (cs.CC)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:48:27+00:00",
          "link": "https://arxiv.org/abs/2507.09324v1",
          "size": "206kb",
          "version": "v1"
        }
      ],
      "title": "The Network Satisfaction Problem for Relation Algebras with at most 4 Atoms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09324",
        "PDF": "https://arxiv.org/pdf/2507.09324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses relation algebras and their properties, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09683",
      "abstract": "We study a distributed learning problem in which learning agents are embedded in a directed acyclic graph (DAG). There is a fixed and arbitrary distribution over feature/label pairs, and each agent or vertex in the graph is able to directly observe only a subset of the features -- potentially a different subset for every agent. The agents learn sequentially in some order consistent with a topological sort of the DAG, committing to a model mapping observations to predictions of the real-valued label. Each agent observes the predictions of their parents in the DAG, and trains their model using both the features of the instance that they directly observe, and the predictions of their parents as additional features. We ask when this process is sufficient to achieve \\emph{information aggregation}, in the sense that some agent in the DAG is able to learn a model whose error is competitive with the best model that could have been learned (in some hypothesis class) with direct access to \\emph{all} features, despite the fact that no single agent in the network has such access. We give upper and lower bounds for this problem for both linear and general hypothesis classes. Our results identify the \\emph{depth} of the DAG as the key parameter: information aggregation can occur over sufficiently long paths in the DAG, assuming that all of the relevant features are well represented along the path, and there are distributions over which information aggregation cannot occur even in the linear case, and even in arbitrarily large DAGs that do not have sufficient depth (such as a hub-and-spokes topology in which the spoke vertices collectively see all the features). We complement our theoretical results with a comprehensive set of experiments.",
      "authors": [
        "Michael Kearns",
        "Aaron Roth",
        "Emily Ryu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Science and Game Theory (cs.GT)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:42:59+00:00",
          "link": "https://arxiv.org/abs/2507.09683v1",
          "size": "4949kb",
          "version": "v1"
        }
      ],
      "title": "Networked Information Aggregation via Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09683",
        "HTML": "https://arxiv.org/html/2507.09683v1",
        "PDF": "https://arxiv.org/pdf/2507.09683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores information aggregation in distributed learning scenarios using graphs, and it does not involve any aspect of LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09693",
      "abstract": "Experiment commentary is crucial in describing the experimental procedures, delving into underlying scientific principles, and incorporating content-related safety guidelines. In practice, human teachers rely heavily on subject-specific expertise and invest significant time preparing such commentary. To address this challenge, we introduce the task of automatic commentary generation across multi-discipline scientific experiments. While recent progress in large multimodal models (LMMs) has demonstrated promising capabilities in video understanding and reasoning, their ability to generate fine-grained and insightful experiment commentary remains largely underexplored. In this paper, we make the following contributions: (i) We construct \\textit{ExpInstruct}, the first dataset tailored for experiment commentary generation, featuring over 7\\textit{K} step-level commentaries across 21 scientific subjects from 3 core disciplines (\\ie, science, healthcare and engineering). Each sample includes procedural descriptions along with potential scientific principles (\\eg, chemical equations and physical laws) and safety guidelines. (ii) We propose ExpStar, an automatic experiment commentary generation model that leverages a retrieval-augmented mechanism to adaptively access, evaluate, and utilize external knowledge. (iii) Extensive experiments show that our ExpStar substantially outperforms 14 leading LMMs, which highlights the superiority of our dataset and model. We believe that ExpStar holds great potential for advancing AI-assisted scientific experiment instruction.",
      "authors": [
        "Jiali Chen",
        "Yujie Jia",
        "Zihan Wu",
        "Jinyu Yang",
        "Jianpeng Chen",
        "Xusen Hei",
        "Jiayuan Xie",
        "Yi Cai",
        "Qing Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:09:58+00:00",
          "link": "https://arxiv.org/abs/2507.09693v1",
          "size": "2695kb",
          "version": "v1"
        }
      ],
      "title": "ExpStar: Towards Automatic Commentary Generation for Multi-discipline Scientific Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09693",
        "HTML": "https://arxiv.org/html/2507.09693v1",
        "PDF": "https://arxiv.org/pdf/2507.09693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the creation of 'ExpInstruct', a new dataset for scientific commentary generation with detailed data processing steps, such as step-level commentaries across multiple disciplines, which is relevant for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10106",
      "abstract": "As AI systems become increasingly capable and ubiquitous, ensuring the safety of these systems is critical. However, existing safety tools often target different aspects of model safety and cannot provide full assurance in isolation, highlighting a need for integrated and composite methodologies. This paper introduces BlueGlass, a framework designed to facilitate composite AI safety workflows by providing a unified infrastructure enabling the integration and composition of diverse safety tools that operate across model internals and outputs. Furthermore, to demonstrate the utility of this framework, we present three safety-oriented analyses on vision-language models for the task of object detection: (1) distributional evaluation, revealing performance trade-offs and potential failure modes across distributions; (2) probe-based analysis of layer dynamics highlighting shared hierarchical learning via phase transition; and (3) sparse autoencoders identifying interpretable concepts. More broadly, this work contributes foundational infrastructure and findings for building more robust and reliable AI systems.",
      "authors": [
        "Harshal Nandigramwar",
        "Syed Qutub",
        "Kay-Ulrich Scholl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:45:34+00:00",
          "link": "https://arxiv.org/abs/2507.10106v1",
          "size": "1204kb",
          "version": "v1"
        }
      ],
      "title": "BlueGlass: A Framework for Composite AI Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10106",
        "HTML": "https://arxiv.org/html/2507.10106v1",
        "PDF": "https://arxiv.org/pdf/2507.10106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It presents a framework for AI safety and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10228",
      "abstract": "Growing concerns around the trustworthiness of AI-enabled systems highlight the role of requirements engineering (RE) in addressing emergent, context-dependent properties that are difficult to specify without structured approaches. In this short vision paper, we propose the integration of two complementary approaches: AMDiRE, an artefact-based approach for RE, and PerSpecML, a perspective-based method designed to support the elicitation, analysis, and specification of machine learning (ML)-enabled systems. AMDiRE provides a structured, artefact-centric, process-agnostic methodology and templates that promote consistency and traceability in the results; however, it is primarily oriented toward deterministic systems. PerSpecML, in turn, introduces multi-perspective guidance to uncover concerns arising from the data-driven and non-deterministic behavior of ML-enabled systems. We envision a pathway to operationalize trustworthiness-related requirements, bridging stakeholder-driven concerns and structured artefact models. We conclude by outlining key research directions and open challenges to be discussed with the RE community.",
      "authors": [
        "Hugo Villamizar",
        "Daniel Mendez",
        "Marcos Kalinowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:49:26+00:00",
          "link": "https://arxiv.org/abs/2507.10228v1",
          "size": "703kb",
          "version": "v1"
        }
      ],
      "title": "Towards a Framework for Operationalizing the Specification of Trustworthy AI Requirements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10228",
        "HTML": "https://arxiv.org/html/2507.10228v1",
        "PDF": "https://arxiv.org/pdf/2507.10228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on requirements engineering for trustworthy AI systems and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10432",
      "abstract": "With the rapid advancements in Artificial Intelligence Generated Image (AGI) technology, the accurate assessment of their quality has become an increasingly vital requirement. Prevailing methods typically rely on cross-modal models like CLIP or BLIP to evaluate text-image alignment and visual quality. However, when applied to AGIs, these methods encounter two primary challenges: semantic misalignment and details perception missing. To address these limitations, we propose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment (SC-AGIQA), a unified framework that leverages text-visual semantic constraints to significantly enhance the comprehensive evaluation of both text-image consistency and perceptual distortion in AI-generated images. Our approach integrates key capabilities from multiple models and tackles the aforementioned challenges by introducing two core modules: the Text-assisted Semantic Alignment Module (TSAM), which leverages Multimodal Large Language Models (MLLMs) to bridge the semantic gap by generating an image description and comparing it against the original prompt for a refined consistency check, and the Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which draws inspiration from Human Visual System (HVS) properties by employing frequency domain analysis combined with perceptual sensitivity weighting to better quantify subtle visual distortions and enhance the capture of fine-grained visual quality details in images. Extensive experiments conducted on multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing state-of-the-art methods. The code is publicly available at https://github.com/mozhu1/SC-AGIQA.",
      "authors": [
        "Qiang Li and Qingsen Yan and Haojian Huang and Peng Wu and Haokui Zhang and Yanning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:21:05+00:00",
          "link": "https://arxiv.org/abs/2507.10432v1",
          "size": "4656kb",
          "version": "v1"
        }
      ],
      "title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10432",
        "HTML": "https://arxiv.org/html/2507.10432v1",
        "PDF": "https://arxiv.org/pdf/2507.10432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with image quality assessment using text-visual semantic constraints for AI-generated images. It does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.05821",
      "abstract": "Medical image segmentation is a critical task in computer vision, with UNet serving as a milestone architecture. The typical component of UNet family is the skip connection, however, their skip connections face two significant limitations: (1) they lack effective interaction between features at different scales, and (2) they rely on simple concatenation or addition operations, which constrain efficient information integration. While recent improvements to UNet have focused on enhancing encoder and decoder capabilities, these limitations remain overlooked. To overcome these challenges, we propose a novel multi-scale feature fusion method that reimagines the UNet decoding process as solving an initial value problem (IVP), treating skip connections as discrete nodes. By leveraging principles from the linear multistep method, we propose an adaptive ordinary differential equation method to enable effective multi-scale feature fusion. Our approach is independent of the encoder and decoder architectures, making it adaptable to various U-Net-like networks. Experiments on ACDC, KiTS2023, MSD brain tumor, and ISIC2017/2018 skin lesion segmentation datasets demonstrate improved feature utilization, reduced network parameters, and maintained high performance. The code is available at https://github.com/nayutayuki/FuseUNet.",
      "authors": [
        "Quansong He and Xiangde Min and Kaishen Wang and Tao He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T07:34:06+00:00",
          "link": "https://arxiv.org/abs/2506.05821v1",
          "size": "3439kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T05:10:07+00:00",
          "link": "https://arxiv.org/abs/2506.05821v2",
          "size": "3446kb",
          "version": "v2"
        }
      ],
      "title": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05821",
        "HTML": "https://arxiv.org/html/2506.05821v2",
        "PDF": "https://arxiv.org/pdf/2506.05821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes improvements in the architecture of U-Net for medical image segmentation, not in training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15285",
      "abstract": "Visual monitoring of industrial assembly tasks is critical for preventing equipment damage due to procedural errors and ensuring worker safety. Although commercial solutions exist, they typically require rigid workspace setups or the application of visual markers to simplify the problem. We introduce ViMAT, a novel AI-driven system for real-time visual monitoring of assembly tasks that operates without these constraints. ViMAT combines a perception module that extracts visual observations from multi-view video streams with a reasoning module that infers the most likely action being performed based on the observed assembly state and prior task knowledge. We validate ViMAT on two assembly tasks, involving the replacement of LEGO components and the reconfiguration of hydraulic press molds, demonstrating its effectiveness through quantitative and qualitative analysis in challenging real-world scenarios characterized by partial and uncertain visual observations. Project page: https://tev-fbk.github.io/ViMAT",
      "authors": [
        "Mattia Nardon",
        "Stefano Messelodi",
        "Antonio Granata",
        "Fabio Poiesi",
        "Alberto Danese",
        "Davide Boscaini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T09:08:42+00:00",
          "link": "https://arxiv.org/abs/2506.15285v1",
          "size": "8999kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:56:52+00:00",
          "link": "https://arxiv.org/abs/2506.15285v2",
          "size": "8948kb",
          "version": "v2"
        }
      ],
      "title": "AI-driven visual monitoring of industrial assembly tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15285",
        "HTML": "https://arxiv.org/html/2506.15285v2",
        "PDF": "https://arxiv.org/pdf/2506.15285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces an AI system for visual monitoring of industrial tasks, which is outside the scope of LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.22791",
      "abstract": "Semantic caching significantly reduces computational costs and improves efficiency by storing and reusing large language model (LLM) responses. However, existing systems rely primarily on matching individual queries, lacking awareness of multi-turn dialogue contexts, which leads to incorrect cache hits when similar queries appear in different conversational settings. This demonstration introduces ContextCache, a context-aware semantic caching system for multi-turn dialogues. ContextCache employs a two-stage retrieval architecture that first executes vector-based retrieval on the current query to identify potential matches and then integrates current and historical dialogue representations through self-attention mechanisms for precise contextual matching. Evaluation of real-world conversations shows that ContextCache improves precision and recall compared to existing methods. Additionally, cached responses exhibit approximately 10 times lower latency than direct LLM invocation, enabling significant computational cost reductions for LLM conversational applications.",
      "authors": [
        "Jianxin Yan",
        "Wangze Ni",
        "Lei Chen",
        "Xuemin Lin",
        "Peng Cheng",
        "Zhan Qin",
        "Kui Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:25:12+00:00",
          "link": "https://arxiv.org/abs/2506.22791v1",
          "size": "898kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:42:00+00:00",
          "link": "https://arxiv.org/abs/2506.22791v2",
          "size": "1310kb",
          "version": "v2"
        }
      ],
      "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22791",
        "HTML": "https://arxiv.org/html/2506.22791v2",
        "PDF": "https://arxiv.org/pdf/2506.22791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a semantic caching system for handling multi-turn dialogues, focusing on retrieval architecture rather than processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05914",
      "abstract": "Diffusion models have achieved remarkable success in various generative tasks, but training them remains highly resource-intensive, often requiring millions of images and many days of GPU computation. From a data-centric perspective addressing this limitation, we study diffusion dataset condensation as a new and challenging problem setting. The goal is to construct a \"synthetic\" sub-dataset with significantly fewer samples than the original dataset, enabling high-quality diffusion model training with greatly reduced cost. To the best of our knowledge, we are the first to formally investigate dataset condensation for diffusion models, whereas prior work focused on training discriminative models. To tackle this new challenge, we propose a novel Diffusion Dataset Condensation (D2C) framework, which consists of two phases: Select and Attach. The Select phase identifies a compact and diverse subset using a diffusion difficulty score and interval sampling. The Attach phase enhances the selected subset by attaching rich semantic and visual representations to strengthen the conditional signals. Extensive experiments across various dataset sizes, model architectures, and resolutions show that our D2C framework enables significantly faster diffusion model training with dramatically fewer data, while preserving high visual quality. Notably, for the SiT-XL/2 architecture, D2C achieves a 100x training speed-up, reaching a FID score of 4.3 in just 40k steps using only 0.8% of the training data.",
      "authors": [
        "Rui Huang",
        "Shitong Shao",
        "Zikai Zhou",
        "Pukun Zhao",
        "Hangyu Guo",
        "Tian Ye",
        "Lichen Bai",
        "Shuo Yang",
        "Zeke Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:00:04+00:00",
          "link": "https://arxiv.org/abs/2507.05914v1",
          "size": "11534kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T09:02:47+00:00",
          "link": "https://arxiv.org/abs/2507.05914v2",
          "size": "11534kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion Dataset Condensation: Training Your Diffusion Model Faster with Less Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05914",
        "HTML": "https://arxiv.org/html/2507.05914v2",
        "PDF": "https://arxiv.org/pdf/2507.05914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the Diffusion Dataset Condensation (D2C) framework, which involves the creation of a synthetic sub-dataset for diffusion model training, focusing on dataset condensation\u2014a core operation in training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08969",
      "abstract": "Introduction: Electronic health records (EHR) are a critical medium through which patient stigmatization is perpetuated among healthcare teams. Methods: We identified linguistic features of doubt markers and stigmatizing labels in MIMIC-III EHR via expanded lexicon matching and supervised learning classifiers. Predictors of rates of linguistic features were assessed using Poisson regression models. Results: We found higher rates of stigmatizing labels per chart among patients who were Black or African American (RR: 1.16), patients with Medicare/Medicaid or government-run insurance (RR: 2.46), self-pay (RR: 2.12), and patients with a variety of stigmatizing disease and mental health conditions. Patterns among doubt markers were similar, though male patients had higher rates of doubt markers (RR: 1.25). We found increased stigmatizing labels used by nurses (RR: 1.40), and social workers (RR: 2.25), with similar patterns of doubt markers. Discussion: Stigmatizing language occurred at higher rates among historically stigmatized patients, perpetuated by multiple provider types.",
      "authors": [
        "Drew Walker",
        "Jennifer Love",
        "Swati Rajwal",
        "Isabel C Walker",
        "Hannah LF Cooper",
        "Abeed Sarker",
        "Melvin Livingston III"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:55:28+00:00",
          "link": "https://arxiv.org/abs/2507.08969v1",
          "size": "166kb",
          "version": "v1"
        }
      ],
      "title": "Application of CARE-SD text classifier tools to assess distribution of stigmatizing and doubt-marking language features in EHR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08969",
        "PDF": "https://arxiv.org/pdf/2507.08969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper applies text classification tools to assess linguistic patterns in electronic health records, with no relevance to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09294",
      "abstract": "Surgical phase recognition plays a critical role in developing intelligent assistance systems for minimally invasive procedures such as Endoscopic Submucosal Dissection (ESD). However, the high visual similarity across different phases and the lack of structural cues in RGB images pose significant challenges. Depth information offers valuable geometric cues that can complement appearance features by providing insights into spatial relationships and anatomical structures. In this paper, we pioneer the use of depth information for surgical phase recognition and propose Geo-RepNet, a geometry-aware convolutional framework that integrates RGB image and depth information to enhance recognition performance in complex surgical scenes. Built upon a re-parameterizable RepVGG backbone, Geo-RepNet incorporates the Depth-Guided Geometric Prior Generation (DGPG) module that extracts geometry priors from raw depth maps, and the Geometry-Enhanced Multi-scale Attention (GEMA) to inject spatial guidance through geometry-aware cross-attention and efficient multi-scale aggregation. To evaluate the effectiveness of our approach, we construct a nine-phase ESD dataset with dense frame-level annotations from real-world ESD videos. Extensive experiments on the proposed dataset demonstrate that Geo-RepNet achieves state-of-the-art performance while maintaining robustness and high computational efficiency under complex and low-texture surgical environments.",
      "authors": [
        "Rui Tang",
        "Haochen Yin",
        "Guankun Wang",
        "Long Bai",
        "An Wang",
        "Huxin Gao",
        "Jiazheng Wang",
        "Hongliang Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:07:44+00:00",
          "link": "https://arxiv.org/abs/2507.09294v1",
          "size": "429kb",
          "version": "v1"
        }
      ],
      "title": "Geo-RepNet: Geometry-Aware Representation Learning for Surgical Phase Recognition in Endoscopic Submucosal Dissection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09294",
        "HTML": "https://arxiv.org/html/2507.09294v1",
        "PDF": "https://arxiv.org/pdf/2507.09294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a geometry-aware framework for surgical phase recognition using depth information. It does not connect to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09440",
      "abstract": "In-context learning (ICL) has emerged as a powerful capability of large pretrained transformers, enabling them to solve new tasks implicit in example input-output pairs without any gradient updates. Despite its practical success, the mechanisms underlying ICL remain largely mysterious. In this work we study synthetic linear regression to probe how transformers implement learning at inference time. Previous works have demonstrated that transformers match the performance of learning rules such as Ordinary Least Squares (OLS) regression or gradient descent and have suggested ICL is facilitated in transformers through the learned implementation of one of these techniques. In this work, we demonstrate through a suite of out-of-distribution generalization experiments that transformers trained for ICL fail to generalize after shifts in the prompt distribution, a behaviour that is inconsistent with the notion of transformers implementing algorithms such as OLS. Finally, we highlight the role of the pretraining corpus in shaping ICL behaviour through a spectral analysis of the learned representations in the residual stream. Inputs from the same distribution as the training data produce representations with a unique spectral signature: inputs from this distribution tend to have the same top two singular vectors. This spectral signature is not shared by out-of-distribution inputs, and a metric characterizing the presence of this signature is highly correlated with low loss.",
      "authors": [
        "Joshua Hill",
        "Benjamin Eyre",
        "and Elliot Creager"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T01:09:26+00:00",
          "link": "https://arxiv.org/abs/2507.09440v1",
          "size": "1258kb",
          "version": "v1"
        }
      ],
      "title": "Transformers Don't In-Context Learn Least Squares Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09440",
        "HTML": "https://arxiv.org/html/2507.09440v1",
        "PDF": "https://arxiv.org/pdf/2507.09440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the role of the pretraining corpus in shaping in-context learning behavior in transformers, but it does not make a primary contribution to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09612",
      "abstract": "Interactive segmentation (IS) improves annotation efficiency by segmenting target regions from user prompts, with widespread applications in real-world scenarios. Current approaches face a critical trade-off: dense-token methods achieve superior accuracy and detail preservation but suffer from prohibitively slow processing on CPU devices, while the Segment Anything Model (SAM) advances the field with sparse prompt tokens for fast inference but compromises segmentation quality. In this paper, we propose Inter2Former to address this challenge by optimizing computation allocation in dense-token processing, which introduces four key enhancements. First, we propose Dynamic Prompt Embedding (DPE) that adaptively processes only regions of interest while avoiding additional overhead from background tokens. Second, we introduce Dynamic Hybrid Attention (DHA), which leverages previous segmentation masks to route tokens through either full attention (O(N2)) for boundary regions or our proposed efficient BSQ attention (O(N)) for non-boundary regions. Third, we develop Hybrid Mixture of Experts (HMoE), which applies similar adaptive computation strategies in FFN modules with CPU-optimized parallel processing. Finally, we present Dynamic Local Upsampling (DLU), a reverse operation of DPE, which localizes objects with a lightweight MLP and performs fine-grained upsampling only in detected regions. Experimental results on high-precision IS benchmarks demonstrate that Inter2Former achieves SOTA performance with high efficiency on CPU devices.",
      "authors": [
        "You Huang",
        "Lichao Chen",
        "Jiayi Ji",
        "Liujuan Cao",
        "Shengchuan Zhang",
        "Rongrong Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:33:37+00:00",
          "link": "https://arxiv.org/abs/2507.09612v1",
          "size": "1756kb",
          "version": "v1"
        }
      ],
      "title": "Inter2Former: Dynamic Hybrid Attention for Efficient High-Precision Interactive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09612",
        "HTML": "https://arxiv.org/html/2507.09612v1",
        "PDF": "https://arxiv.org/pdf/2507.09612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes enhancements in interactive segmentation for efficiency and accuracy but does not mention LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09924",
      "abstract": "Continually updating model-based indexes in generative retrieval with new documents remains challenging, as full retraining is computationally expensive and impractical under resource constraints. We propose MixLoRA-DSI, a novel framework that combines an expandable mixture of Low-Rank Adaptation experts with a layer-wise out-of-distribution (OOD)-driven expansion strategy. Instead of allocating new experts for each new corpus, our proposed expansion strategy enables sublinear parameter growth by selectively introducing new experts only when significant number of OOD documents are detected. Experiments on NQ320k and MS MARCO Passage demonstrate that MixLoRA-DSI outperforms full-model update baselines, with minimal parameter overhead and substantially lower training costs.",
      "authors": [
        "Tuan-Luc Huynh",
        "Thuy-Trang Vu",
        "Weiqing Wang",
        "Trung Le",
        "Dragan Ga\\v{s}evi\\'c",
        "Yuan-Fang Li",
        "Thanh-Toan Do"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:04:32+00:00",
          "link": "https://arxiv.org/abs/2507.09924v1",
          "size": "239kb",
          "version": "v1"
        }
      ],
      "title": "MixLoRA-DSI: Dynamically Expandable Mixture-of-LoRA Experts for Rehearsal-Free Generative Retrieval over Dynamic Corpora",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09924",
        "HTML": "https://arxiv.org/html/2507.09924v1",
        "PDF": "https://arxiv.org/pdf/2507.09924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily addresses model update strategies for generative retrieval systems over dynamic corpora and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10223",
      "abstract": "Prosthetic legs play a pivotal role in clinical rehabilitation, allowing individuals with lower-limb amputations the ability to regain mobility and improve their quality of life. Gait analysis is fundamental for optimizing prosthesis design and alignment, directly impacting the mobility and life quality of individuals with lower-limb amputations. Vision-based machine learning (ML) methods offer a scalable and non-invasive solution to gait analysis, but face challenges in correctly detecting and analyzing prosthesis, due to their unique appearances and new movement patterns. In this paper, we aim to bridge this gap by introducing a multi-purpose dataset, namely ProGait, to support multiple vision tasks including Video Object Segmentation, 2D Human Pose Estimation, and Gait Analysis (GA). ProGait provides 412 video clips from four above-knee amputees when testing multiple newly-fitted prosthetic legs through walking trials, and depicts the presence, contours, poses, and gait patterns of human subjects with transfemoral prosthetic legs. Alongside the dataset itself, we also present benchmark tasks and fine-tuned baseline models to illustrate the practical application and performance of the ProGait dataset. We compared our baseline models against pre-trained vision models, demonstrating improved generalizability when applying the ProGait dataset for prosthesis-specific tasks. Our code is available at https://github.com/pittisl/ProGait and dataset at https://huggingface.co/datasets/ericyxy98/ProGait.",
      "authors": [
        "Xiangyu Yin",
        "Boyuan Yang",
        "Weichen Liu",
        "Qiyao Xue",
        "Abrar Alamri",
        "Goeran Fiedler",
        "Wei Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:40:57+00:00",
          "link": "https://arxiv.org/abs/2507.10223v1",
          "size": "4978kb",
          "version": "v1"
        }
      ],
      "title": "ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10223",
        "HTML": "https://arxiv.org/html/2507.10223v1",
        "PDF": "https://arxiv.org/pdf/2507.10223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a new video dataset for prosthesis users and provides benchmarks, but it primarily addresses vision tasks rather than LLM training data processing or extensive data engineering improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10280",
      "abstract": "Digital twins are increasingly applied in transportation modelling to replicate real-world traffic dynamics and evaluate mobility and energy efficiency. This study presents a SUMO-based digital twin that simulates mixed ICEV-EV traffic on a major motorway segment, leveraging multi-sensor data fusion from inductive loops, GPS probes, and toll records. The model is validated under both complete and partial information scenarios, achieving 93.1% accuracy in average speed estimation and 97.1% in average trip length estimation. Statistical metrics, including KL Divergence and Wasserstein Distance, demonstrate strong alignment between simulated and observed traffic patterns. Furthermore, CO2 emissions were overestimated by only 0.8-2.4%, and EV power consumption underestimated by 1.0-5.4%, highlighting the model's robustness even with incomplete vehicle classification information.",
      "authors": [
        "Haomiaomiao Wang",
        "Conor Fennell",
        "Swati Poojary and Mingming Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:48:02+00:00",
          "link": "https://arxiv.org/abs/2507.10280v1",
          "size": "2579kb",
          "version": "v1"
        }
      ],
      "title": "A SUMO-Based Digital Twin for Evaluation of Conventional and Electric Vehicle Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10280",
        "HTML": "https://arxiv.org/html/2507.10280v1",
        "PDF": "https://arxiv.org/pdf/2507.10280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a digital twin for traffic modeling using SUMO to simulate vehicle networks. It does not focus on LLM training data processing or any data engineering aspects specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.02871",
      "abstract": "Head-Related Transfer Functions (HRTFs) have fundamental applications for realistic rendering in immersive audio scenarios. However, they are strongly subject-dependent as they vary considerably depending on the shape of the ears, head and torso. Thus, personalization procedures are required for accurate binaural rendering. Recently, Denoising Diffusion Probabilistic Models (DDPMs), a class of generative learning techniques, have been applied to solve a variety of signal processing-related problems. In this paper, we propose a first approach for using DDPM conditioned on anthropometric measurements to generate personalized Head-Related Impulse Response (HRIR), the time-domain representation of HRTF. The results show the feasibility of DDPMs for HRTF personalization obtaining performance in line with state-of-the-art models.",
      "authors": [
        "Juan Camilo Albarrac\\'in S\\'anchez",
        "Luca Comanducci",
        "Mirco Pezzoli",
        "Fabio Antonacci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T09:26:59+00:00",
          "link": "https://arxiv.org/abs/2501.02871v1",
          "size": "1220kb",
          "version": "v1"
        }
      ],
      "title": "Towards HRTF Personalization using Denoising Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02871",
        "HTML": "https://arxiv.org/html/2501.02871",
        "PDF": "https://arxiv.org/pdf/2501.02871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses HRTF personalization using denoising diffusion models, which is unrelated to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.16465",
      "abstract": "Autonomous graphical user interface (GUI) agents powered by multimodal large language models have shown great promise. However, a critical yet underexplored issue persists: over-execution, where the agent executes tasks in a fully autonomous way, without adequate assessment of its action confidence to compromise an adaptive human-agent collaboration. This poses substantial risks in complex scenarios, such as those involving ambiguous user instructions, unexpected interruptions, and environmental hijacks. To address the issue, we introduce OS-Kairos, an adaptive GUI agent capable of predicting confidence levels at each interaction step and efficiently deciding whether to act autonomously or seek human intervention. OS-Kairos is developed through two key mechanisms: (i) collaborative probing that annotates confidence scores at each interaction step; (ii) confidence-driven interaction that leverages these confidence scores to elicit the ability of adaptive interaction. Experimental results show that OS-Kairos substantially outperforms existing models on our curated dataset featuring complex scenarios, as well as on established benchmarks such as AITZ and Meta-GUI, with 24.59\\%$\\sim$87.29\\% improvements in task success rate. OS-Kairos facilitates an adaptive human-agent collaboration, prioritizing effectiveness, generality, scalability, and efficiency for real-world GUI interaction. The dataset and codes are available at https://github.com/Wuzheng02/OS-Kairos.",
      "authors": [
        "Pengzhou Cheng",
        "Zheng Wu",
        "Zongru Wu",
        "Aston Zhang",
        "Zhuosheng Zhang",
        "Gongshen Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T12:31:16+00:00",
          "link": "https://arxiv.org/abs/2503.16465v1",
          "size": "20402kb",
          "version": "v1"
        },
        {
          "date": "2025-06-14T02:07:11+00:00",
          "link": "https://arxiv.org/abs/2503.16465v2",
          "size": "19254kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T15:56:44+00:00",
          "link": "https://arxiv.org/abs/2503.16465v3",
          "size": "19254kb",
          "version": "v3"
        }
      ],
      "title": "OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16465",
        "HTML": "https://arxiv.org/html/2503.16465v3",
        "PDF": "https://arxiv.org/pdf/2503.16465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents OS-Kairos, an adaptive GUI agent. It emphasizes adaptive interaction, confidence prediction, and improving GUI agent performance but does not address LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/wuzheng02/os-kairos"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09373",
      "abstract": "It is known how to compute the Zariski closure of a finitely generated monoid of matrices and, more generally, of a set of matrices specified by a regular language. This result was recently used to give a procedure to compute all polynomial invariants of a given affine program. Decidability of the more general problem of computing all polynomial invariants of affine programs with recursive procedure calls remains open. Mathematically speaking, the core challenge is to compute the Zariski closure of a set of matrices defined by a context-free language. In this paper, we approach the problem from two sides: Towards decidability, we give a procedure to compute the Zariski closure of sets of matrices given by one-counter languages (that is, languages accepted by one-dimensional vector addition systems with states and zero tests), a proper subclass of context-free languages. On the other side, we show that the problem becomes undecidable for indexed languages, a natural extension of context-free languages corresponding to nested pushdown automata. One of our main technical tools is a novel adaptation of Simon's factorization forests to infinite monoids of matrices.",
      "authors": [
        "Rida Ait El Manssour",
        "Mahsa Naraghi",
        "Mahsa Shirmohammadi",
        "James Worrell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:39:12+00:00",
          "link": "https://arxiv.org/abs/2507.09373v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Algebraic Closure of Matrix Sets Recognized by 1-VASS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09373",
        "HTML": "https://arxiv.org/html/2507.09373v1",
        "PDF": "https://arxiv.org/pdf/2507.09373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the algebraic closure of matrix sets using mathematical language theory and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09490",
      "abstract": "Playtesting is the process in which people play a video game for testing. It is critical for the quality assurance of gaming software. Manual playtesting is time-consuming and expensive. However, automating this process is challenging, as playtesting typically requires domain knowledge and problem-solving skills that most conventional testing tools lack. Recent advancements in artificial intelligence (AI) have opened up new possibilities for applying Large Language Models (LLMs) to playtesting. However, significant challenges remain: current LLMs cannot visually perceive game environments, and most existing research focuses on text-based games or games with robust APIs. Many non-text games lack APIs to provide textual descriptions of game states, making it almost impossible to naively apply LLMs for playtesting. This paper introduces Lap, our novel approach to LLM-based Automatic Playtesting, which uses ChatGPT to test match-3 games, a category of games where players match three or more identical tiles in a row or column to earn points. Lap encompasses three key phases: processing of game environments, prompting-based action generation, and action execution. Given a match-3 game, Lap takes a snapshot of the game board and converts it to a numeric matrix. It then prompts the ChatGPT-O1-mini API to suggest moves based on that matrix and tentatively applies the suggested moves to earn points and trigger changes in the game board. It repeats the above-mentioned three steps iteratively until timeout. For evaluation, we conducted a case study using Lap on an open-source match-3 game, CasseBonbons, and empirically compared it with three existing tools. Our results are promising: Lap outperformed existing tools by achieving higher code coverage and triggering more program crashes. This research sheds light on the future of automatic testing and LLM applications.",
      "authors": [
        "Yan Zhao and Chiwei Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:23:44+00:00",
          "link": "https://arxiv.org/abs/2507.09490v1",
          "size": "3497kb",
          "version": "v1"
        }
      ],
      "title": "Towards LLM-Based Automatic Playtest",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09490",
        "HTML": "https://arxiv.org/html/2507.09490v1",
        "PDF": "https://arxiv.org/pdf/2507.09490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces LLM-based playtesting, the mention of processing game environments involves transforming game states into inputs for LLM, which is peripheral to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2206.05974",
      "abstract": "An accelerated failure time (AFT) model assumes a log-linear relationship between failure times and a set of covariates. In contrast to other popular survival models that work on hazard functions, the effects of covariates are directly on failure times, whose interpretation is intuitive. The semiparametric AFT model that does not specify the error distribution is flexible and robust to departures from the distributional assumption. Owing to the desirable features, this class of models has been considered as a promising alternative to the popular Cox model in the analysis of censored failure time data. However, in these AFT models, a linear predictor for the mean is typically assumed. Little research has addressed the nonlinearity of predictors when modeling the mean. Deep neural networks (DNNs) have received a focal attention over the past decades and have achieved remarkable success in a variety of fields. DNNs have a number of notable advantages and have been shown to be particularly useful in addressing the nonlinearity. By taking advantage of this, we propose to apply DNNs in fitting AFT models using a Gehan-type loss, combined with a sub-sampling technique. Finite sample properties of the proposed DNN and rank based AFT model (DeepR-AFT) are investigated via an extensive stimulation study. DeepR-AFT shows a superior performance over its parametric or semiparametric counterparts when the predictor is nonlinear. For linear predictors, DeepR-AFT performs better when the dimensions of covariates are large. The proposed DeepR-AFT is illustrated using two real datasets, which demonstrates its superiority.",
      "authors": [
        "Gwangsu Kim and Sangwook Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-13T08:38:18+00:00",
          "link": "https://arxiv.org/abs/2206.05974v1",
          "size": "2461kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T01:35:15+00:00",
          "link": "https://arxiv.org/abs/2206.05974v2",
          "size": "89kb",
          "version": "v2"
        }
      ],
      "title": "Deep Neural Network Based Accelerated Failure Time Models using Rank Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.05974",
        "HTML": "https://arxiv.org/html/2206.05974v2",
        "PDF": "https://arxiv.org/pdf/2206.05974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with accelerated failure time models using deep neural networks with no relation to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.14410",
      "abstract": "Function-correcting codes (FCCs) protect specific function evaluations of a message against errors. This condition imposes a less stringent distance requirement than classical error-correcting codes (ECCs), allowing for reduced redundancy. FCCs were introduced by Lenz et al. (2021), who also established a lower bound on the optimal redundancy for FCCs over the binary field. Here, we derive an upper bound within a logarithmic factor of this lower bound. We show that the same lower bound holds for any finite field. Moreover, we show that this bound is tight for sufficiently large fields by demonstrating that it also serves as an upper bound. Furthermore, we construct an encoding scheme that achieves this optimal redundancy. Finally, motivated by these two extreme regimes, we conjecture that our bound serves as a valid upper bound across all finite fields.",
      "authors": [
        "Hoang Ly and Emina Soljanin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-19T21:50:21+00:00",
          "link": "https://arxiv.org/abs/2504.14410v1",
          "size": "240kb",
          "version": "v1"
        },
        {
          "date": "2025-04-22T02:40:49+00:00",
          "link": "https://arxiv.org/abs/2504.14410v2",
          "size": "232kb",
          "version": "v2"
        },
        {
          "date": "2025-04-28T03:33:04+00:00",
          "link": "https://arxiv.org/abs/2504.14410v3",
          "size": "15kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T10:26:56+00:00",
          "link": "https://arxiv.org/abs/2504.14410v4",
          "size": "16kb",
          "version": "v4"
        }
      ],
      "title": "On the Redundancy of Function-Correcting Codes over Finite Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14410",
        "HTML": "https://arxiv.org/html/2504.14410v4",
        "PDF": "https://arxiv.org/pdf/2504.14410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about function-correcting codes and redundancy over finite fields, with no connection to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07997",
      "abstract": "Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental models that compress continuous visual data into discrete tokens. Existing methods have tried to improve the quantization strategy for better reconstruction quality, however, there still exists a large gap between VQ-VAEs and VAEs. To narrow this gap, we propose MGVQ, a novel method to augment the representation capability of discrete codebooks, facilitating easier optimization for codebooks and minimizing information loss, thereby enhancing reconstruction quality. Specifically, we propose to retain the latent dimension to preserve encoded features and incorporate a set of sub-codebooks for quantization. Furthermore, we construct comprehensive zero-shot benchmarks featuring resolutions of 512p and 2k to evaluate the reconstruction performance of existing methods rigorously. MGVQ achieves the state-of-the-art performance on both ImageNet and 8 zero-shot benchmarks across all VQ-VAEs. Notably, compared with SD-VAE, we outperform them on ImageNet significantly, with rFID 0.49 v.s. 0.91, and achieve superior PSNR on all zero-shot benchmarks. These results highlight the superiority of MGVQ in reconstruction and pave the way for preserving fidelity in HD image processing tasks. Code will be publicly available at https://github.com/MKJia/MGVQ.",
      "authors": [
        "Mingkai Jia",
        "Wei Yin",
        "Xiaotao Hu",
        "Jiaxin Guo",
        "Xiaoyang Guo",
        "Qian Zhang",
        "Xiao-Xiao Long",
        "Ping Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.07997v1",
          "size": "21607kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:33:58+00:00",
          "link": "https://arxiv.org/abs/2507.07997v2",
          "size": "21607kb",
          "version": "v2"
        }
      ],
      "title": "MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07997",
        "HTML": "https://arxiv.org/html/2507.07997v2",
        "PDF": "https://arxiv.org/pdf/2507.07997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving VQ-VAE techniques for visual data compression and reconstruction quality, with no mention of LLM training data processing or new dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10535",
      "abstract": "Large Language Models (LLMs) have significantly advanced the state-of-the-art in various coding tasks. Beyond directly answering user queries, LLMs can also serve as judges, assessing and comparing the quality of responses generated by other models. Such an evaluation capability is crucial both for benchmarking different LLMs and for improving response quality through response ranking. However, despite the growing adoption of the LLM-as-a-Judge paradigm, its effectiveness in coding scenarios remains underexplored due to the absence of dedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a benchmark explicitly designed to evaluate the performance of LLM-as-a-Judge models across three critical coding tasks: code generation, code repair, and unit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge models, we find that recent thinking models significantly outperform non-thinking models on our carefully designed code judging tasks. Notably, even relatively small thinking models, such as Qwen3-8B, can outperform specially trained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still exhibit significant randomness in their judgment of coding tasks. For pairwise judging tasks, simply changing the order in which responses are presented can substantially impact accuracy. In addition, when judging code and unit tests written by different LLMs, LLM-as-a-Judge models also show variance in performance. This sensitivity raises concerns about the reliability and consistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal prompting strategies for LLM-as-a-Judge. We find that using pair-wise comparison outperforms scalar point-wise judging. Furthermore, retaining comments and reasoning in the full, unprocessed LLM response leads to improved judge performance.",
      "authors": [
        "Hongchao Jiang",
        "Yiming Chen",
        "Yushi Cao",
        "Hung-yi Lee",
        "Robby T. Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:56:29+00:00",
          "link": "https://arxiv.org/abs/2507.10535v1",
          "size": "644kb",
          "version": "v1"
        }
      ],
      "title": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10535",
        "PDF": "https://arxiv.org/pdf/2507.10535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating LLMs in coding tasks. It focuses on judging capabilities rather than the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.11870",
      "abstract": "Supervised Fine-Tuning (SFT) and Preference Optimization (PO) are key processes for aligning Language Models (LMs) with human preferences post pre-training. While SFT excels in efficiency and PO in effectiveness, they are often combined sequentially without integrating their optimization objectives. This approach ignores the opportunities to bridge their paradigm gap and take the strengths from both. In this paper, we interpret SFT and PO with two sub-processes -- Preference Estimation and Transition Optimization -- defined at token level within the Markov Decision Process (MDP). This modeling shows that SFT is only a special case of PO with inferior estimation and optimization. PO estimates the model's preference by its entire generation, while SFT only scores model's subsequent predicted tokens based on prior tokens from ground truth answer. These priors deviates from model's distribution, hindering the preference estimation and transition optimization. Building on this view, we introduce Intuitive Fine-Tuning (IFT) to integrate SFT and PO into a single process. Through a temporal residual connection, IFT brings better estimation and optimization by capturing LMs' intuitive sense of its entire answers. But it solely relies on a single policy and the same volume of non-preference-labeled data as SFT. Our experiments show that IFT performs comparably or even superiorly to SFT and some typical PO methods across several tasks, particularly those require generation, reasoning, and fact-following abilities. An explainable Frozen Lake game further validates the effectiveness of IFT for getting competitive policy.",
      "authors": [
        "Ermo Hua",
        "Biqing Qi",
        "Kaiyan Zhang",
        "Kai Tian",
        "Xingtai Lv",
        "Ning Ding",
        "Bowen Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T08:23:28+00:00",
          "link": "https://arxiv.org/abs/2405.11870v1",
          "size": "1415kb",
          "version": "v1"
        },
        {
          "date": "2024-05-28T16:14:58+00:00",
          "link": "https://arxiv.org/abs/2405.11870v2",
          "size": "1028kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T04:15:46+00:00",
          "link": "https://arxiv.org/abs/2405.11870v3",
          "size": "984kb",
          "version": "v3"
        }
      ],
      "title": "Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11870",
        "HTML": "https://arxiv.org/html/2405.11870v3",
        "PDF": "https://arxiv.org/pdf/2405.11870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses integrating different fine-tuning processes for LLMs, focusing on alignment rather than explicit training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/TsinghuaC3I/Intuitive-Fine-Tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.06275",
      "abstract": "Phase-only compressed sensing (PO-CS) concerns the recovery of sparse signals from the phases of complex measurements. Recent results show that sparse signals in the standard sphere $\\mathbb{S}^{n-1}$ can be exactly recovered from complex Gaussian phases by a linearization procedure, which recasts PO-CS as linear compressed sensing and then applies (quadratically constrained) basis pursuit to obtain $\\mathbf{x}^\\sharp$. This paper focuses on the instance optimality and robustness of $\\mathbf{x}^{\\sharp}$. First, we strengthen the nonuniform instance optimality of Jacques and Feuillen (2021) to a uniform one over the entire signal space. We show the existence of some universal constant $C$ such that $\\|\\mathbf{x}^\\sharp-\\mathbf{x}\\|_2\\le Cs^{-1/2}\\sigma_{\\ell_1}(\\mathbf{x},\\Sigma^n_s)$ holds for all $\\mathbf{x}$ in the unit Euclidean sphere, where $\\sigma_{\\ell_1}(\\mathbf{x},\\Sigma^n_s)$ is the $\\ell_1$ distance of $\\mathbf{x}$ to its closest $s$-sparse signal. This is achieved by showing the new sensing matrices corresponding to all approximately sparse signals simultaneously satisfy RIP. Second, we investigate the estimator's robustness to noise and corruption. We show that dense noise with entries bounded by some small $\\tau_0$, appearing either prior or posterior to retaining the phases, increments $\\|\\mathbf{x}^\\sharp-\\mathbf{x}\\|_2$ by $O(\\tau_0)$. This is near-optimal (up to log factors) for any algorithm. On the other hand, adversarial corruption, which changes an arbitrary $\\zeta_0$-fraction of the measurements to any phase-only values, increments $\\|\\mathbf{x}^\\sharp-\\mathbf{x}\\|_2$ by $O(\\sqrt{\\zeta_0\\log(1/\\zeta_0)})$. The developments are then combined to yield a robust instance optimal guarantee that resembles the standard one in linear compressed sensing.",
      "authors": [
        "Junren Chen",
        "Michael K. Ng",
        "Jonathan Scarlett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-12T16:37:48+00:00",
          "link": "https://arxiv.org/abs/2408.06275v1",
          "size": "162kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T06:34:14+00:00",
          "link": "https://arxiv.org/abs/2408.06275v2",
          "size": "123kb",
          "version": "v2"
        }
      ],
      "title": "Robust Instance Optimal Phase-Only Compressed Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06275",
        "HTML": "https://arxiv.org/html/2408.06275v2",
        "PDF": "https://arxiv.org/pdf/2408.06275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on phase-only compressed sensing and its optimization, which is unrelated to LLM training data processing or dataset development."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10061",
      "abstract": "Recent work on human animation usually involves audio, pose, or movement maps conditions, thereby achieves vivid animation quality. However, these methods often face practical challenges due to extra control conditions, cumbersome condition injection modules, or limitation to head region driving. Hence, we ask if it is possible to achieve striking half-body human animation while simplifying unnecessary conditions. To this end, we propose a half-body human animation method, dubbed EchoMimicV2, that leverages a novel Audio-Pose Dynamic Harmonization strategy, including Pose Sampling and Audio Diffusion, to enhance half-body details, facial and gestural expressiveness, and meanwhile reduce conditions redundancy. To compensate for the scarcity of half-body data, we utilize Head Partial Attention to seamlessly accommodate headshot data into our training framework, which can be omitted during inference, providing a free lunch for animation. Furthermore, we design the Phase-specific Denoising Loss to guide motion, detail, and low-level quality for animation in specific phases, respectively. Besides, we also present a novel benchmark for evaluating the effectiveness of half-body human animation. Extensive experiments and analyses demonstrate that EchoMimicV2 surpasses existing methods in both quantitative and qualitative evaluations.",
      "authors": [
        "Rang Meng",
        "Xingyu Zhang",
        "Yuming Li",
        "Chenguang Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T09:23:18+00:00",
          "link": "https://arxiv.org/abs/2411.10061v1",
          "size": "4884kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T10:02:14+00:00",
          "link": "https://arxiv.org/abs/2411.10061v2",
          "size": "4877kb",
          "version": "v2"
        }
      ],
      "title": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10061",
        "HTML": "https://arxiv.org/html/2411.10061v2",
        "PDF": "https://arxiv.org/pdf/2411.10061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for human animation with a focus on animation quality and reducing condition redundancy. It does not pertain to LLM training data processing or engineering."
      },
      "models": [
        {
          "model_path": "BadToBest/EchoMimicV2",
          "downloads": "0",
          "likes": "127",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BadToBest/EchoMimicV2"
        },
        {
          "model_path": "camenduru/EchoMimicV2",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/camenduru/EchoMimicV2"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Meng_EchoMimicV2_Towards_Striking_Simplified_and_Semi-Body_Human_Animation_CVPR_2025_paper.html",
      "tasks": [
        "Audio-Driven Body Animation",
        "Human Animation",
        "Image to Video Generation",
        "Subject-driven Video Generation",
        "Video Generation"
      ],
      "repo_urls": [
        "https://github.com/antgroup/echomimic_v2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09639",
      "abstract": "Can we simulate a sandbox society with generative agents to model human behavior, thereby reducing the over-reliance on real human trials for assessing public policies? In this work, we investigate the feasibility of simulating health-related decision-making, using vaccine hesitancy, defined as the delay in acceptance or refusal of vaccines despite the availability of vaccination services (MacDonald, 2015), as a case study. To this end, we introduce the VacSim framework with 100 generative agents powered by Large Language Models (LLMs). VacSim simulates vaccine policy outcomes with the following steps: 1) instantiate a population of agents with demographics based on census data; 2) connect the agents via a social network and model vaccine attitudes as a function of social dynamics and disease-related information; 3) design and evaluate various public health interventions aimed at mitigating vaccine hesitancy. To align with real-world results, we also introduce simulation warmup and attitude modulation to adjust agents' attitudes. We propose a series of evaluations to assess the reliability of various LLM simulations. Experiments indicate that models like Llama and Qwen can simulate aspects of human behavior but also highlight real-world alignment challenges, such as inconsistent responses with demographic profiles. This early exploration of LLM-driven simulations is not meant to serve as definitive policy guidance; instead, it serves as a call for action to examine social simulation for policy development.",
      "authors": [
        "Abe Bohan Hou",
        "Hongru Du",
        "Yichen Wang",
        "Jingyu Zhang",
        "Zixiao Wang",
        "Paul Pu Liang",
        "Daniel Khashabi",
        "Lauren Gardner",
        "Tianxing He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T02:54:15+00:00",
          "link": "https://arxiv.org/abs/2503.09639v1",
          "size": "1918kb",
          "version": "v1"
        },
        {
          "date": "2025-03-16T06:03:01+00:00",
          "link": "https://arxiv.org/abs/2503.09639v2",
          "size": "1918kb",
          "version": "v2"
        },
        {
          "date": "2025-04-02T15:30:46+00:00",
          "link": "https://arxiv.org/abs/2503.09639v3",
          "size": "1469kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T07:36:02+00:00",
          "link": "https://arxiv.org/abs/2503.09639v4",
          "size": "1392kb",
          "version": "v4"
        }
      ],
      "title": "Can A Society of Generative Agents Simulate Human Behavior and Inform Public Health Policy? A Case Study on Vaccine Hesitancy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09639",
        "HTML": "https://arxiv.org/html/2503.09639v4",
        "PDF": "https://arxiv.org/pdf/2503.09639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the VacSim framework for simulating human behavior in health policy but focuses on LLM-driven simulations rather than discussing LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.14836",
      "abstract": "Fine-tuning has become the standard practice for adapting pre-trained models to downstream tasks. However, the impact on model robustness is not well understood. In this work, we characterize the robustness-accuracy trade-off in fine-tuning. We evaluate the robustness and accuracy of fine-tuned models over 6 benchmark datasets and 7 different fine-tuning strategies. We observe a consistent trade-off between adversarial robustness and accuracy. Peripheral updates such as BitFit are more effective for simple tasks -- over 75% above the average measured by the area under the Pareto frontiers on CIFAR-10 and CIFAR-100. In contrast, fine-tuning information-heavy layers, such as attention layers via Compacter, achieves a better Pareto frontier on more complex tasks -- 57.5% and 34.6% above the average on Caltech-256 and CUB-200, respectively. Lastly, we observe that the robustness of fine-tuning against out-of-distribution data closely tracks accuracy. These insights emphasize the need for robustness-aware fine-tuning to ensure reliable real-world deployments.",
      "authors": [
        "Kunyang Li",
        "Jean-Charles Noirot Ferrand",
        "Ryan Sheatsley",
        "Blaine Hoak",
        "Yohan Beugin",
        "Eric Pauley",
        "Patrick McDaniel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T02:35:01+00:00",
          "link": "https://arxiv.org/abs/2503.14836v1",
          "size": "670kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:14:45+00:00",
          "link": "https://arxiv.org/abs/2503.14836v2",
          "size": "463kb",
          "version": "v2"
        }
      ],
      "title": "On the Robustness Tradeoff in Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14836",
        "HTML": "https://arxiv.org/html/2503.14836v2",
        "PDF": "https://arxiv.org/pdf/2503.14836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper evaluates fine-tuning strategies but does not focus on data processing, making its contribution to LLM training data processing minimal."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02679",
      "abstract": "In this work, we investigate the correlation between gender and contextual biases, focusing on elements such as action verbs, object nouns, and particularly on occupations. We introduce a novel dataset, GenderLexicon, and a framework that can estimate contextual bias and its related gender bias. Our model can interpret the bias with a score and thus improve the explainability of gender bias. Also, our findings confirm the existence of gender biases beyond occupational stereotypes. To validate our approach and demonstrate its effectiveness, we conduct evaluations on five diverse datasets, including a Japanese dataset.",
      "authors": [
        "Ahmed Sabir and Rajesh Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:42:03+00:00",
          "link": "https://arxiv.org/abs/2507.02679v1",
          "size": "6937kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T09:26:40+00:00",
          "link": "https://arxiv.org/abs/2507.02679v2",
          "size": "6937kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Gender Bias Beyond Occupational Titles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02679",
        "HTML": "https://arxiv.org/html/2507.02679v2",
        "PDF": "https://arxiv.org/pdf/2507.02679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper creates a novel dataset, GenderLexicon, aimed at understanding and quantifying gender bias, detailing the data processing steps involved in its creation."
      },
      "datasets": [
        {
          "dataset_name": "AhmedSSabir/GenderLex",
          "downloads": "81",
          "likes": "0",
          "link": "https://huggingface.co/datasets/AhmedSSabir/GenderLex"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09902",
      "abstract": "Fictitious play (FP) is a natural learning dynamic in two-player zero-sum games. Samuel Karlin conjectured in 1959 that FP converges at a rate of $O(t^{-1/2})$ to Nash equilibrium, where $t$ is the number of steps played. However, Daskalakis and Pan disproved the stronger form of this conjecture in 2014, where \\emph{adversarial} tie-breaking is allowed.\n  This paper disproves Karlin's conjecture in its weaker form. In particular, there exists a 10-by-10 zero-sum matrix game, in which FP converges at a rate of $\\Omega(t^{-1/3})$, and no ties occur except for the first step.",
      "authors": [
        "Yuanhao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:15:17+00:00",
          "link": "https://arxiv.org/abs/2507.09902v1",
          "size": "162kb",
          "version": "v1"
        }
      ],
      "title": "Tie-breaking Agnostic Lower Bound for Fictitious Play",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09902",
        "PDF": "https://arxiv.org/pdf/2507.09902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses theoretical bounds of fictitious play in game theory with no connection to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09949",
      "abstract": "In the dynamic realm of online recruitment, accurate job classification is paramount for optimizing job recommendation systems, search rankings, and labor market analyses. As job markets evolve, the increasing complexity of job titles and descriptions necessitates sophisticated models that can effectively leverage intricate relationships within job data. Traditional text classification methods often fall short, particularly due to their inability to fully utilize the hierarchical nature of industry categories. To address these limitations, we propose a novel representation learning and classification model that embeds jobs and hierarchical industry categories into a latent embedding space. Our model integrates the Standard Occupational Classification (SOC) system and an in-house hierarchical taxonomy, Carotene, to capture both graph and hierarchical relationships, thereby improving classification accuracy. By embedding hierarchical industry categories into a shared latent space, we tackle cold start issues and enhance the dynamic matching of candidates to job opportunities. Extensive experimentation on a large-scale dataset of job postings demonstrates the model's superior ability to leverage hierarchical structures and rich semantic features, significantly outperforming existing methods. This research provides a robust framework for improving job classification accuracy, supporting more informed decision-making in the recruitment industry.",
      "authors": [
        "Md Ahsanul Kabir",
        "Kareem Abdelfatah",
        "Mohammed Korayem",
        "Mohammad Al Hasan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.09949v1",
          "size": "512kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Job Classification with Similarity Graph Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09949",
        "HTML": "https://arxiv.org/html/2507.09949v1",
        "PDF": "https://arxiv.org/pdf/2507.09949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hierarchical job classification using graph structures, which is not related to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10218",
      "abstract": "The Reflow operation aims to straighten the inference trajectories of the rectified flow during training by constructing deterministic couplings between noises and images, thereby improving the quality of generated images in single-step or few-step generation. However, we identify critical limitations in Reflow, particularly its inability to rapidly generate high-quality images due to a distribution gap between images in its constructed deterministic couplings and real images. To address these shortcomings, we propose a novel alternative called Straighten Viscous Rectified Flow via Noise Optimization (VRFNO), which is a joint training framework integrating an encoder and a neural velocity field. VRFNO introduces two key innovations: (1) a historical velocity term that enhances trajectory distinction, enabling the model to more accurately predict the velocity of the current trajectory, and (2) the noise optimization through reparameterization to form optimized couplings with real images which are then utilized for training, effectively mitigating errors caused by Reflow's limitations. Comprehensive experiments on synthetic data and real datasets with varying resolutions show that VRFNO significantly mitigates the limitations of Reflow, achieving state-of-the-art performance in both one-step and few-step generation tasks.",
      "authors": [
        "Jimin Dai",
        "Jiexi Yan",
        "Jian Yang",
        "Lei Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:35:17+00:00",
          "link": "https://arxiv.org/abs/2507.10218v1",
          "size": "7279kb",
          "version": "v1"
        }
      ],
      "title": "Straighten Viscous Rectified Flow via Noise Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10218",
        "HTML": "https://arxiv.org/html/2507.10218v1",
        "PDF": "https://arxiv.org/pdf/2507.10218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals primarily with improving image generation through noise optimization and trajectory prediction, with no mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.03353",
      "abstract": "Large language models (LLMs) have revolutionized the state-of-the-art of many different natural language processing tasks. Although serving LLMs is computationally and memory demanding, the rise of Small Language Models (SLMs) offers new opportunities for resource-constrained users, who now are able to serve small models with cutting-edge performance. In this paper, we present a set of experiments designed to benchmark SLM inference at performance and energy levels. Our analysis provides a new perspective in serving, highlighting that the small memory footprint of SLMs allows for reaching the Pareto-optimal throughput within the resource capacity of a single accelerator. In this regard, we present an initial set of findings demonstrating how model replication can effectively improve resource utilization for serving SLMs.",
      "authors": [
        "Pol G.Recasens and Yue Zhu and Chen Wang and Eun Kyung Lee and Olivier Tardieu and Alaa Youssef and Jordi Torres and Josep Ll. Berral"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-04T10:45:07+00:00",
          "link": "https://arxiv.org/abs/2404.03353v1",
          "size": "3546kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T09:55:44+00:00",
          "link": "https://arxiv.org/abs/2404.03353v2",
          "size": "141kb",
          "version": "v2"
        }
      ],
      "title": "Towards Pareto Optimal Throughput in Small Language Model Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.03353",
        "HTML": "https://arxiv.org/html/2404.03353v2",
        "PDF": "https://arxiv.org/pdf/2404.03353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper deals with benchmarking small language model serving and resource utilization, focusing on model inference rather than LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Small Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.11873",
      "abstract": "We study the power of (competitive) algorithms with predictions in a multiagent setting. To this goal, we introduce a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.\n  We investigate the effect of using predictors for self and others' behavior in such a setting, as well as the new equilibria formed in this way.",
      "authors": [
        "Gabriel Istrate",
        "Cosmin Bonchi\\c{s}",
        "Victor Bogdan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Data Structures and Algorithms (cs.DS)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T08:30:11+00:00",
          "link": "https://arxiv.org/abs/2405.11873v1",
          "size": "538kb",
          "version": "v1"
        },
        {
          "date": "2025-01-14T20:06:32+00:00",
          "link": "https://arxiv.org/abs/2405.11873v2",
          "size": "544kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T20:30:22+00:00",
          "link": "https://arxiv.org/abs/2405.11873v3",
          "size": "328kb",
          "version": "v3"
        }
      ],
      "title": "Equilibria in multiagent online problems with predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11873",
        "HTML": "https://arxiv.org/html/2405.11873v3",
        "PDF": "https://arxiv.org/pdf/2405.11873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms with predictions in a multiagent setting and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.17279",
      "abstract": "Payload transport over flat terrain via multi-wheel robot carriers is well-understood, highly effective, and configurable. In this paper, our goal is to provide similar effectiveness and configurability for transport over rough terrain that is more suitable for legs rather than wheels. For this purpose, we consider multi-biped robot carriers, where wheels are replaced by multiple bipedal robots attached to the carrier. Our main contribution is to design a decentralized controller for such systems that can be effectively applied to varying numbers and configurations of rigidly attached bipedal robots without retraining. We present a reinforcement learning approach for training the controller in simulation that supports transfer to the real world. Our experiments in simulation provide quantitative metrics showing the effectiveness of the approach over a wide variety of simulated transport scenarios. In addition, we demonstrate the controller in the real-world for systems composed of two and three Cassie robots. To our knowledge, this is the first example of a scalable multi-biped payload transport system.",
      "authors": [
        "Bikram Pandit",
        "Ashutosh Gupta",
        "Mohitvishnu S. Gadde",
        "Addison Johnson",
        "Aayam Kumar Shrestha",
        "Helei Duan",
        "Jeremy Dao",
        "Alan Fern"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T05:08:44+00:00",
          "link": "https://arxiv.org/abs/2406.17279v1",
          "size": "4812kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T01:37:27+00:00",
          "link": "https://arxiv.org/abs/2406.17279v2",
          "size": "4815kb",
          "version": "v2"
        }
      ],
      "title": "Learning Decentralized Multi-Biped Control for Payload Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17279",
        "HTML": "https://arxiv.org/html/2406.17279v2",
        "PDF": "https://arxiv.org/pdf/2406.17279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on decentralized control for multi-biped robots and does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.07962",
      "abstract": "While self-attention has been instrumental in the success of Transformers, it can lead to over-concentration on a few tokens during training, resulting in suboptimal information flow. Enforcing doubly-stochastic constraints in attention matrices has been shown to improve structure and balance in attention distributions. However, existing methods rely on iterative Sinkhorn normalization, which is computationally costly. In this paper, we introduce a novel, fully parallelizable doubly-stochastic attention mechanism based on sliced optimal transport, leveraging Expected Sliced Transport Plans (ESP). Unlike prior approaches, our method enforces doubly stochasticity without iterative Sinkhorn normalization, significantly enhancing efficiency. To ensure differentiability, we incorporate a temperature-based soft sorting technique, enabling seamless integration into deep learning models. Experiments across multiple benchmark datasets, including image classification, point cloud classification, sentiment analysis, and neural machine translation, demonstrate that our enhanced attention regularization consistently improves performance across diverse applications. Our implementation code can be found at https://github.com/dariansal/ESPFormer.",
      "authors": [
        "Ashkan Shahbazi",
        "Elaheh Akbari",
        "Darian Salehi",
        "Xinran Liu",
        "Navid Naderializadeh",
        "Soheil Kolouri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T21:20:48+00:00",
          "link": "https://arxiv.org/abs/2502.07962v1",
          "size": "263kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T19:17:03+00:00",
          "link": "https://arxiv.org/abs/2502.07962v2",
          "size": "293kb",
          "version": "v2"
        }
      ],
      "title": "ESPFormer: Doubly-Stochastic Attention with Expected Sliced Transport Plans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07962",
        "HTML": "https://arxiv.org/html/2502.07962v2",
        "PDF": "https://arxiv.org/pdf/2502.07962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on a novel attention mechanism for Transformers and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08874",
      "abstract": "Timely identification of harmful brain activities via electroencephalography (EEG) is critical for brain disease diagnosis and treatment, which remains limited application due to inter-rater variability, resource constraints, and poor generalizability of existing artificial intelligence (AI) models. In this study, a convolutional neural network model, VIPEEGNet, was developed and validated using EEGs recorded from Massachusetts General Hospital/Harvard Medical School. The VIPEEGNet was developed and validated using two independent datasets, collected between 2006 and 2020. The development cohort included EEG recordings from 1950 patients, with 106,800 EEG segments annotated by at least one experts (ranging from 1 to 28). The online testing cohort consisted of EEG segments from a subset of an additional 1,532 patients, each annotated by at least 10 experts. For the development cohort (n=1950), the VIPEEGNet achieved high accuracy, with an AUROC for binary classification of seizure, LPD, GPD, LRDA, GRDA, and \"other\" categories at 0.972 (95% CI, 0.957-0.988), 0.962 (95% CI, 0.954-0.970), 0.972 (95% CI, 0.960-0.984), 0.938 (95% CI, 0.917-0.959), 0.949 (95% CI, 0.941-0.957), and 0.930 (95% CI, 0.926-0.935). For multi classification, the sensitivity of VIPEEGNET for the six categories ranges from 36.8% to 88.2% and the precision ranges from 55.6% to 80.4%, and performance similar to human experts. Notably, the external validation showed Kullback-Leibler Divergence (KLD)of 0.223 and 0.273, ranking top 2 among the existing 2,767 competing algorithms, while we only used 2.8% of the parameters of the first-ranked algorithm.",
      "authors": [
        "Yulin Sun",
        "Xiaopeng Si",
        "Runnan He",
        "Xiao Hu",
        "Peter Smielewski",
        "Wenlong Wang",
        "Xiaoguang Tong",
        "Wei Yue",
        "Meijun Pang",
        "Kuo Zhang",
        "Xizi Song",
        "Dong Ming",
        "Xiuyun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:22:13+00:00",
          "link": "https://arxiv.org/abs/2507.08874v1",
          "size": "1927kb",
          "version": "v1"
        }
      ],
      "title": "An Automated Classifier of Harmful Brain Activities for Clinical Usage Based on a Vision-Inspired Pre-trained Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08874",
        "HTML": "https://arxiv.org/html/2507.08874v1",
        "PDF": "https://arxiv.org/pdf/2507.08874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a CNN model for classifying EEG data, but it does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08977",
      "abstract": "Scientific modeling faces a core limitation: mechanistic models offer interpretability but collapse under real-world complexity, while machine learning models are flexible but require large labeled datasets, cannot infer unobservable quantities, and operate as black boxes. We introduce Simulation-Grounded Neural Networks (SGNNs), a general framework that uses mechanistic simulations as training data for neural networks. SGNNs are pretrained on synthetic corpora spanning diverse model structures, parameter regimes, stochasticity, and observational artifacts. We evaluated SGNNs across scientific disciplines and modeling tasks, and found that SGNNs achieved state-of-the-art results across settings: for prediction tasks, they nearly tripled COVID-19 forecasting skill versus CDC baselines, reduced chemical yield prediction error by one third, and maintained accuracy in ecological forecasting where task specific models failed. For inference tasks, SGNNs also accurately classified the source of information spread in simulated social networks and enabled supervised learning for unobservable targets, such as estimating COVID-19 transmissibility more accurately than traditional methods even in early outbreaks. Finally, SGNNs enable back-to-simulation attribution, a new form of mechanistic interpretability. Given real world input, SGNNs retrieve simulations based on what the model has learned to see as most similar, revealing which underlying dynamics the model believes are active. This provides process-level insight -- what the model thinks is happening -- not just which features mattered. SGNNs unify scientific theory with deep learning flexibility and unlock a new modeling paradigm -- transforming simulations from rigid, post hoc tools into flexible sources of supervision, enabling robust, interpretable inference even when ground truth is missing.",
      "authors": [
        "Carson Dudley",
        "Reiden Magdaleno",
        "Christopher Harding",
        "Marisa Eisenberg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:18:42+00:00",
          "link": "https://arxiv.org/abs/2507.08977v1",
          "size": "9462kb",
          "version": "v1"
        }
      ],
      "title": "Simulation as Supervision: Mechanistic Pretraining for Scientific Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08977",
        "HTML": "https://arxiv.org/html/2507.08977v1",
        "PDF": "https://arxiv.org/pdf/2507.08977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a method utilizing mechanistic simulations as training data for neural networks, which involves data generation and processing to improve model training quality, a key aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09003",
      "abstract": "The remarkable performance of Large Language Models (LLMs) has inspired many applications, which often necessitate edge-cloud collaboration due to connectivity, privacy, and cost considerations. Traditional methods primarily focus on selecting the best LLM model for optimizing performance, while neglecting the critical interplay between the components of the LLM serving pipeline (context retrieval, query preprocessing, etc.) or the changing latency and cost constraints. We introduce ECO-LLM (Edge-Cloud Orchestrator for LLMs), a novel system that reframes this problem as a joint optimization challenge and solves it by systematically exploring component configurations and dynamically selecting optimal strategies at the query level. ECO-LLM consists of two components: (1) the ECO-LLM Emulator, which efficiently explores the vast configuration space utilizing query clustering and pareto-optimal path selection, gathering domain-specific performance metrics without exhaustive evaluation; and (2) the ECO-LLM Runtime, which leverages these metrics to dynamically select optimal resolution strategies for user queries while meeting user-defined Service Level Objectives (SLOs). We evaluate ECO-LLM on a smart home and a smart car assistant scenarios. With an exhaustive exploration of all possible configurations for seen queries, ECO-LLM outperforms cloud-based models like GPT-4o in terms of accuracy (90% vs. 74% on average) while reducing costs by 90% and latency by 55%, demonstrating the value of its joint optimization at the query level. In practical deployment for previously unseen queries, ECO-LLM selects configurations that reduce costs by 62% or improve response times by 62% on average compared to state-of-the-art model routing approaches, while maintaining higher accuracy and consistently adhering to specified latency and cost constraints.",
      "authors": [
        "Prasoon Patidar (1)",
        "Alex Crown (2)",
        "Kevin Hsieh (2)",
        "Yifei Xu (2)",
        "Tusher Chakraborty (2)",
        "Ranveer Chandra (2)",
        "Yuvraj Agarwal (1) ((1) Carnegie Mellon University",
        "(2) Microsoft Research)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:11:04+00:00",
          "link": "https://arxiv.org/abs/2507.09003v1",
          "size": "2526kb",
          "version": "v1"
        }
      ],
      "title": "Orchestration for Domain-specific Edge-Cloud Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09003",
        "HTML": "https://arxiv.org/html/2507.09003v1",
        "PDF": "https://arxiv.org/pdf/2507.09003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing LLM inference performance via an edge-cloud orchestration system, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09026",
      "abstract": "We consider solutions to the linear quadratic Gaussian (LQG) regulator problem via policy gradient (PG) methods. Although PG methods have demonstrated strong theoretical guarantees in solving the linear quadratic regulator (LQR) problem, despite its nonconvex landscape, their theoretical understanding in the LQG setting remains limited. Notably, the LQG problem lacks gradient dominance in the classical parameterization, i.e., with a dynamic controller, which hinders global convergence guarantees. In this work, we study PG for the LQG problem by adopting an alternative parameterization of the set of stabilizing controllers and employing a lifting argument. We refer to this parameterization as a history representation of the control input as it is parameterized by past input and output data from the previous p time-steps. This representation enables us to establish gradient dominance and approximate smoothness for the LQG cost. We prove global convergence and per-iteration stability guarantees for policy gradient LQG in model-based and model-free settings. Numerical experiments on an open-loop unstable system are provided to support the global convergence guarantees and to illustrate convergence under different history lengths of the history representation.",
      "authors": [
        "Kasra Fallah",
        "Leonardo F. Toso",
        "James Anderson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:19:47+00:00",
          "link": "https://arxiv.org/abs/2507.09026v1",
          "size": "729kb",
          "version": "v1"
        }
      ],
      "title": "On the Gradient Domination of the LQG Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09026",
        "HTML": "https://arxiv.org/html/2507.09026v1",
        "PDF": "https://arxiv.org/pdf/2507.09026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the LQG problem using policy gradient methods, which is unrelated to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09188",
      "abstract": "Explainable Recommender System (ExRec) provides transparency to the recommendation process, increasing users' trust and boosting the operation of online services. With the rise of large language models (LLMs), whose extensive world knowledge and nuanced language understanding enable the generation of human-like, contextually grounded explanations, LLM-powered ExRec has gained great momentum. However, existing LLM-based ExRec models suffer from profile deviation and high retrieval overhead, hindering their deployment. To address these issues, we propose Retrieval-Augmented Recommendation Explanation Generation with Hierarchical Aggregation (REXHA). Specifically, we design a hierarchical aggregation based profiling module that comprehensively considers user and item review information, hierarchically summarizing and constructing holistic profiles. Furthermore, we introduce an efficient retrieval module using two types of pseudo-document queries to retrieve relevant reviews to enhance the generation of recommendation explanations, effectively reducing retrieval latency and improving the recall of relevant reviews. Extensive experiments demonstrate that our method outperforms existing approaches by up to 12.6% w.r.t. the explanation quality while achieving high retrieval efficiency.",
      "authors": [
        "Bangcheng Sun",
        "Yazhe Chen",
        "Jilin Yang",
        "Xiaodong Li",
        "Hui Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:15:05+00:00",
          "link": "https://arxiv.org/abs/2507.09188v1",
          "size": "380kb",
          "version": "v1"
        }
      ],
      "title": "Retrieval-Augmented Recommendation Explanation Generation with Hierarchical Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09188",
        "HTML": "https://arxiv.org/html/2507.09188v1",
        "PDF": "https://arxiv.org/pdf/2507.09188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on retrieval-augmented recommendation and explanation generation systems, not on LLM training data processing or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09928",
      "abstract": "We introduce a new solution concept for bounded rational agents in finite normal-form general-sum games called Generalized Quantal Response Equilibrium (GQRE) which generalizes Quantal Response Equilibrium~\\citep{mckelvey1995quantal}. In our setup, each player maximizes a smooth, regularized expected utility of the mixed profiles used, reflecting bounded rationality that subsumes stochastic choice. After establishing existence under mild conditions, we present computationally efficient no-regret independent learning via smoothened versions of the Frank-Wolfe algorithm. Our algorithm uses noisy but correlated gradient estimates generated via a simulation oracle that reports on repeated plays of the game. We analyze convergence properties of our algorithm under assumptions that ensure uniqueness of equilibrium, using a class of gap functions that generalize the Nash gap. We end by demonstrating the effectiveness of our method on a set of complex general-sum games such as high-rank two-player games, large action two-player games, and known examples of difficult multi-player games.",
      "authors": [
        "Apurv Shukla",
        "Vijay Subramanian",
        "Andy Zhao and Rahul Jain"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:14:46+00:00",
          "link": "https://arxiv.org/abs/2507.09928v1",
          "size": "3689kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Quantal Response Equilibrium: Existence and Efficient Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09928",
        "HTML": "https://arxiv.org/html/2507.09928v1",
        "PDF": "https://arxiv.org/pdf/2507.09928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a game-theory solution concept and learning algorithm, with no mention of LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10024",
      "abstract": "Design studies aim to create visualization solutions for real-world problems of different application domains. Recently, the emergence of large language models (LLMs) has introduced new opportunities to enhance the design study process, providing capabilities such as creative problem-solving, data handling, and insightful analysis. However, despite their growing popularity, there remains a lack of systematic understanding of how LLMs can effectively assist researchers in visualization-specific design studies. In this paper, we conducted a multi-stage qualitative study to fill this gap, involving 30 design study researchers from diverse backgrounds and expertise levels. Through in-depth interviews and carefully-designed questionnaires, we investigated strategies for utilizing LLMs, the challenges encountered, and the practices used to overcome them. We further compiled and summarized the roles that LLMs can play across different stages of the design study process. Our findings highlight practical implications to inform visualization practitioners, and provide a framework for leveraging LLMs to enhance the design study process in visualization research.",
      "authors": [
        "Shaolun Ruan",
        "Rui Sheng",
        "Xiaolin Wen",
        "Jiachen Wang",
        "Tianyi Zhang",
        "Yong Wang",
        "Tim Dwyer",
        "Jiannan Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:06:12+00:00",
          "link": "https://arxiv.org/abs/2507.10024v1",
          "size": "19939kb",
          "version": "v1"
        }
      ],
      "title": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10024",
        "HTML": "https://arxiv.org/html/2507.10024v1",
        "PDF": "https://arxiv.org/pdf/2507.10024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of LLMs in design studies for visualization, focusing on strategies and roles rather than data processing or creation relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.03692",
      "abstract": "Optimizing service schedules is pivotal to the reliable, efficient, and inclusive on-demand mobility. This pressing challenge is further exacerbated by the increasing needs of an aging population, the oversubscription of existing services, and the lack of effective solution methods. This study addresses the intricacies of service scheduling, by jointly optimizing rider trip planning and crew scheduling for a complex dynamic mobility service. The resulting optimization problems are extremely challenging computationally for state-of-the-art methods. To address this fundamental gap, this paper introduces the Joint Rider Trip Planning and Crew Shift Scheduling Problem (JRTPCSSP) and a novel solution method, called Attention and Gated GNN-Informed Column Generation (AGGNNI-CG), that hybridizes column generation and machine learning to obtain near-optimal solutions to the JRTPCSSP with real-life constraints of the application. The key idea of the machine-learning component is to dramatically reduce the number of paths to explore in the pricing problem, accelerating the most time-consuming component of the column generation. The machine learning component is a graph neural network with an attention mechanism and a gated architecture, which is particularly suited to cater for the different input sizes coming from daily operations. AGGNNI-CG has been applied to a challenging, real-world dataset from the Paratransit system of Chatham County in Georgia. It produces substantial improvements compared to the baseline column generation approach, which typically cannot produce high-quality feasible solutions in reasonable time on large-scale complex instances. AGGNNI-CG also produces significant improvements in service quality compared to the existing system.",
      "authors": [
        "Jiawei Lu",
        "Tinghan Ye",
        "Wenbo Chen",
        "Pascal Van Hentenryck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-08T06:46:39+00:00",
          "link": "https://arxiv.org/abs/2401.03692v1",
          "size": "1544kb",
          "version": "v1"
        },
        {
          "date": "2024-12-29T15:09:54+00:00",
          "link": "https://arxiv.org/abs/2401.03692v2",
          "size": "1645kb",
          "version": "v2"
        },
        {
          "date": "2025-01-08T16:05:00+00:00",
          "link": "https://arxiv.org/abs/2401.03692v3",
          "size": "1645kb",
          "version": "v3"
        },
        {
          "date": "2025-04-12T21:15:15+00:00",
          "link": "https://arxiv.org/abs/2401.03692v4",
          "size": "1274kb",
          "version": "v4"
        },
        {
          "date": "2025-06-16T03:57:28+00:00",
          "link": "https://arxiv.org/abs/2401.03692v5",
          "size": "1409kb",
          "version": "v5"
        }
      ],
      "title": "Boosting Column Generation with Graph Neural Networks for Joint Rider Trip Planning and Crew Shift Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.03692",
        "PDF": "https://arxiv.org/pdf/2401.03692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses optimization problems in mobility services using graph neural networks, with no focus on LLM training data processing or contributions to dataset creation or engineering for LLMs."
      },
      "tasks": [
        "Graph Neural Network",
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.17339",
      "abstract": "In this paper, we delve into the realm of 4-D light fields (LFs) to enhance underwater imaging plagued by light absorption, scattering, and other challenges. Contrasting with conventional 2-D RGB imaging, 4-D LF imaging excels in capturing scenes from multiple perspectives, thereby indirectly embedding geometric information. This intrinsic property is anticipated to effectively address the challenges associated with underwater imaging. By leveraging both explicit and implicit depth cues present in 4-D LF images, we propose a progressive, mutually reinforcing framework for underwater 4-D LF image enhancement and depth estimation. Specifically, our framework explicitly utilizes estimated depth information alongside implicit depth-related dynamic convolutional kernels to modulate output features. The entire framework decomposes this complex task, iteratively optimizing the enhanced image and depth information to progressively achieve optimal enhancement results. More importantly, we construct the first 4-D LF-based underwater image dataset for quantitative evaluation and supervised training of learning-based methods, comprising 75 underwater scenes and 3675 high-resolution 2K pairs. To craft vibrant and varied underwater scenes, we build underwater environments with various objects and adopt several types of degradation. Through extensive experimentation, we showcase the potential and superiority of 4-D LF-based underwater imaging vis-a-vis traditional 2-D RGB-based approaches. Moreover, our method effectively corrects color bias and achieves state-of-the-art performance. The dataset and code will be publicly available at https://github.com/linlos1234/LFUIE.",
      "authors": [
        "Yuji Lin",
        "Junhui Hou",
        "Xianqiang Lyu",
        "Qian Zhao",
        "Deyu Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-30T15:06:45+00:00",
          "link": "https://arxiv.org/abs/2408.17339v1",
          "size": "15290kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T06:37:27+00:00",
          "link": "https://arxiv.org/abs/2408.17339v2",
          "size": "31314kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Underwater Imaging with 4-D Light Fields: Dataset and Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.17339",
        "HTML": "https://arxiv.org/html/2408.17339v2",
        "PDF": "https://arxiv.org/pdf/2408.17339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper constructs a new dataset, the first 4-D LF-based underwater image dataset, with specified data processing steps for supervised training, showcasing dataset creation and enhancement techniques."
      },
      "tasks": [
        "2k",
        "Depth Estimation",
        "Image Enhancement"
      ],
      "repo_urls": [
        "https://github.com/linlos1234/lfuie"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19939",
      "abstract": "Reinforcement learning (RL) has demonstrated potential in autonomous driving (AD) decision tasks. However, applying RL to urban AD, particularly in intersection scenarios, still faces significant challenges. The lack of safety constraints makes RL vulnerable to risks. Additionally, cognitive limitations and environmental randomness can lead to unreliable decisions in safety-critical scenarios. Therefore, it is essential to quantify confidence in RL decisions to improve safety. This paper proposes an Uncertainty-aware Safety-Critical Decision and Control (USDC) framework, which generates a risk-averse policy by constructing a risk-aware ensemble distributional RL, while estimating uncertainty to quantify the policy's reliability. Subsequently, a high-order control barrier function (HOCBF) is employed as a safety filter to minimize intervention policy while dynamically enhancing constraints based on uncertainty. The ensemble critics evaluate both HOCBF and RL policies, embedding uncertainty to achieve dynamic switching between safe and flexible strategies, thereby balancing safety and efficiency. Simulation tests on unsignalized intersections in multiple tasks indicate that USDC can improve safety while maintaining traffic efficiency compared to baselines.",
      "authors": [
        "Ran Yu",
        "Zhuoren Li",
        "Lu Xiong",
        "Wei Han",
        "Bo Leng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T13:06:02+00:00",
          "link": "https://arxiv.org/abs/2505.19939v1",
          "size": "3598kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:48:57+00:00",
          "link": "https://arxiv.org/abs/2505.19939v2",
          "size": "3345kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19939",
        "HTML": "https://arxiv.org/html/2505.19939v2",
        "PDF": "https://arxiv.org/pdf/2505.19939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on decision and control for autonomous vehicles using reinforcement learning, without discussing LLM training data processing, engineering, or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07625",
      "abstract": "Two competing algorithms for solving Abel's equation $g(\\theta(x)) = g(x) + 1$, given $\\theta(x)$, have lately occupied our attention. For $\\theta(x) = x (1 - x^2)$, the EJ method outperforms the ML method, consistent with experience. An immense surprise, however, lay in store for us. Two other cubics, $x (1 - x + x^2)$ and $x (1 - x)^2$, display unexpectedly erratic behavior under EJ. The reliability of EJ is consequently in question; our wavering loyalty has shifted back to ML.",
      "authors": [
        "Steven Finch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T10:42:45+00:00",
          "link": "https://arxiv.org/abs/2506.07625v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T02:12:58+00:00",
          "link": "https://arxiv.org/abs/2506.07625v2",
          "size": "114kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T17:14:48+00:00",
          "link": "https://arxiv.org/abs/2506.07625v3",
          "size": "64kb",
          "version": "v3"
        }
      ],
      "title": "Half-Iterates and Delta Conjectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07625",
        "HTML": "https://arxiv.org/html/2506.07625v3",
        "PDF": "https://arxiv.org/pdf/2506.07625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The discussion involves solving Abel's equation and analysis of algorithms, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15723",
      "abstract": "In this article, we review modern approaches to building interpretable models of property markets using machine learning on the base of mass valuation of property in the Primorye region, Russia. The researcher, lacking expertise in this topic, encounters numerous difficulties in the effort to build a good model. The main source of this is the huge difference between noisy real market data and ideal data which is very common in all types of tutorials on machine learning. This paper covers all stages of modeling: the collection of initial data, identification of outliers, the search and analysis of patterns in the data, the formation and final choice of price factors, the building of the model, and the evaluation of its efficiency. For each stage, we highlight potential issues and describe sound methods for overcoming emerging difficulties on actual examples. We show that the combination of classical linear regression with interpolation methods of geostatistics allows to build an effective model for land parcels. For flats, when many objects are attributed to one spatial point the application of geostatistical methods is difficult. Therefore we suggest linear regression with automatic generation and selection of additional rules on the base of decision trees, so called the RuleFit method. Thus we show, that despite such a strong restriction as the requirement of interpretability which is important in practical aspects, for example, legal matters, it is still possible to build effective models of real property markets.",
      "authors": [
        "Irina G. Tanashkina",
        "Alexey S. Tanashkin",
        "Alexander S. Maksimchuik",
        "Anna Yu. Poshivailo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T13:17:18+00:00",
          "link": "https://arxiv.org/abs/2506.15723v1",
          "size": "5816kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T00:09:43+00:00",
          "link": "https://arxiv.org/abs/2506.15723v2",
          "size": "4793kb",
          "version": "v2"
        }
      ],
      "title": "Modern approaches to building interpretable models of the property market using machine learning on the base of mass cadastral valuation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15723",
        "HTML": "https://arxiv.org/html/2506.15723v2",
        "PDF": "https://arxiv.org/pdf/2506.15723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses data collection and preprocessing challenges in property market modeling, it focuses on model interpretability rather than LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09305",
      "abstract": "Path smoothness is often overlooked in path imitation learning from expert demonstrations. In this paper, we introduce a novel learning method, termed deep angular A* (DAA*), by incorporating the proposed path angular freedom (PAF) into A* to improve path similarity through adaptive path smoothness. The PAF aims to explore the effect of move angles on path node expansion by finding the trade-off between their minimum and maximum values, allowing for high adaptiveness for imitation learning. DAA* improves path optimality by closely aligning with the reference path through joint optimization of path shortening and smoothing, which correspond to heuristic distance and PAF, respectively. Throughout comprehensive evaluations on 7 datasets, including 4 maze datasets, 2 video-game datasets, and a real-world drone-view dataset containing 2 scenarios, we demonstrate remarkable improvements of our DAA* over neural A* in path similarity between the predicted and reference paths with a shorter path length when the shortest path is plausible, improving by 9.0% SPR, 6.9% ASIM, and 3.9% PSIM. Furthermore, when jointly learning pathfinding with both path loss and path probability map loss, DAA* significantly outperforms the state-of-the-art TransPath by 6.7% SPR, 6.5% PSIM, and 3.7% ASIM. We also discuss the minor trade-off between path optimality and search efficiency where applicable.",
      "authors": [
        "Zhiwei Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.09305v1",
          "size": "5270kb",
          "version": "v1"
        }
      ],
      "title": "DAA*: Deep Angular A Star for Image-based Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09305",
        "HTML": "https://arxiv.org/html/2507.09305v1",
        "PDF": "https://arxiv.org/pdf/2507.09305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new method for improving path similarity in image-based path planning, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09372",
      "abstract": "Deep learning-based hearing loss compensation (HLC) seeks to enhance speech intelligibility and quality for hearing impaired listeners using neural networks. One major challenge of HLC is the lack of a ground-truth target. Recent works have used neural networks to emulate non-differentiable auditory peripheral models in closed-loop frameworks, but this approach lacks flexibility. Alternatively, differentiable auditory models allow direct optimization, yet previous studies focused on individual listener profiles, or joint noise reduction (NR) and HLC without balancing each task. This work formulates NR and HLC as a multi-task learning problem, training a system to simultaneously predict denoised and compensated signals from noisy speech and audiograms using a differentiable auditory model. Results show the system achieves similar objective metric performance to systems trained for each task separately, while being able to adjust the balance between NR and HLC during inference.",
      "authors": [
        "Philippe Gonzalez",
        "Torsten Dau",
        "Tobias May"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:37:18+00:00",
          "link": "https://arxiv.org/abs/2507.09372v1",
          "size": "133kb",
          "version": "v1"
        }
      ],
      "title": "Controllable joint noise reduction and hearing loss compensation using a differentiable auditory model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09372",
        "HTML": "https://arxiv.org/html/2507.09372v1",
        "PDF": "https://arxiv.org/pdf/2507.09372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a learning-based approach for hearing loss compensation and noise reduction but does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09420",
      "abstract": "The detection and tracking of celestial surface terrain features are crucial for autonomous spaceflight applications, including Terrain Relative Navigation (TRN), Entry, Descent, and Landing (EDL), hazard analysis, and scientific data collection. Traditional photoclinometry-based pipelines often rely on extensive a priori imaging and offline processing, constrained by the computational limitations of radiation-hardened systems. While historically effective, these approaches typically increase mission costs and duration, operate at low processing rates, and have limited generalization. Recently, learning-based computer vision has gained popularity to enhance spacecraft autonomy and overcome these limitations. While promising, emerging techniques frequently impose computational demands exceeding the capabilities of typical spacecraft hardware for real-time operation and are further challenged by the scarcity of labeled training data for diverse extraterrestrial environments. In this work, we present novel formulations for in-situ landmark tracking via detection and description. We utilize lightweight, computationally efficient neural network architectures designed for real-time execution on current-generation spacecraft flight processors. For landmark detection, we propose improved domain adaptation methods that enable the identification of celestial terrain features with distinct, cheaply acquired training data. Concurrently, for landmark description, we introduce a novel attention alignment formulation that learns robust feature representations that maintain correspondence despite significant landmark viewpoint variations. Together, these contributions form a unified system for landmark tracking that demonstrates superior performance compared to existing state-of-the-art techniques.",
      "authors": [
        "Timothy Chase Jr",
        "Karthik Dantu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:00:52+00:00",
          "link": "https://arxiv.org/abs/2507.09420v1",
          "size": "1325kb",
          "version": "v1"
        }
      ],
      "title": "Domain Adaptation and Multi-view Attention for Learnable Landmark Tracking with Sparse Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09420",
        "HTML": "https://arxiv.org/html/2507.09420v1",
        "PDF": "https://arxiv.org/pdf/2507.09420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes techniques for landmark detection and tracking with sparse data but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09806",
      "abstract": "The Deep Prior framework has emerged as a powerful generative tool which can be used for reconstructing sound fields in an environment from few sparse pressure measurements. It employs a neural network that is trained solely on a limited set of available data and acts as an implicit prior which guides the solution of the underlying optimization problem. However, a significant limitation of the Deep Prior approach is its inability to generalize to new acoustic configurations, such as changes in the position of a sound source. As a consequence, the network must be retrained from scratch for every new setup, which is both computationally intensive and time-consuming. To address this, we investigate transfer learning in Deep Prior via Low-Rank Adaptation (LoRA), which enables efficient fine-tuning of a pre-trained neural network by introducing a low-rank decomposition of trainable parameters, thus allowing the network to adapt to new measurement sets with minimal computational overhead. We embed LoRA into a MultiResUNet-based Deep Prior model and compare its adaptation performance against full fine-tuning of all parameters as well as classical retraining, particularly in scenarios where only a limited number of microphones are used. The results indicate that fine-tuning, whether done completely or via LoRA, is especially advantageous when the source location is the sole changing parameter, preserving high physical fidelity, and highlighting the value of transfer learning for acoustics applications.",
      "authors": [
        "Mirco Pezzoli",
        "Federico Miotello",
        "Shoichi Koyama",
        "Fabio Antonacci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:51:32+00:00",
          "link": "https://arxiv.org/abs/2507.09806v1",
          "size": "257kb",
          "version": "v1"
        }
      ],
      "title": "Low-Rank Adaptation of Deep Prior Neural Networks For Room Impulse Response Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09806",
        "PDF": "https://arxiv.org/pdf/2507.09806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates low-rank adaptation in deep neural networks for sound field reconstruction, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09858",
      "abstract": "Safe navigation within a workspace is a fundamental skill for autonomous robots to accomplish more complex tasks. Harmonic potentials are artificial potential fields that are analytical, globally convergent and provably free of local minima. Thus, it has been widely used for generating safe and reliable robot navigation control policies. However, most existing methods do not allow customization of the harmonic potential fields nor the resulting paths, particularly regarding their topological properties. In this paper, we propose a novel method that automatically finds homotopy classes of paths that can be generated by valid harmonic potential fields. The considered complex workspaces can be as general as forest worlds consisting of numerous overlapping star-obstacles. The method is based on a hybrid optimization algorithm that searches over homotopy classes, selects the structure of each tree-of-stars within the forest, and optimizes over the continuous weight parameters for each purged tree via the projected gradient descent. The key insight is to transform the forest world to the unbounded point world via proper diffeomorphic transformations. It not only facilitates a simpler design of the multi-directional D-signature between non-homotopic paths, but also retain the safety and convergence properties. Extensive simulations and hardware experiments are conducted for non-trivial scenarios, where the navigation potentials are customized for desired homotopic properties. Project page: https://shuaikang-wang.github.io/CustFields.",
      "authors": [
        "Shuaikang Wang",
        "Tiecheng Guo and Meng Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:55:25+00:00",
          "link": "https://arxiv.org/abs/2507.09858v1",
          "size": "3009kb",
          "version": "v1"
        }
      ],
      "title": "Customize Harmonic Potential Fields via Hybrid Optimization over Homotopic Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09858",
        "HTML": "https://arxiv.org/html/2507.09858v1",
        "PDF": "https://arxiv.org/pdf/2507.09858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with robot navigation using harmonic potential fields and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09904",
      "abstract": "Evaluation of text-to-music systems is constrained by the cost and availability of collecting experts for assessment. AudioMOS 2025 Challenge track 1 is created to automatically predict music impression (MI) as well as text alignment (TA) between the prompt and the generated musical piece. This paper reports our winning system, which uses a dual-branch architecture with pre-trained MuQ and RoBERTa models as audio and text encoders. A cross-attention mechanism fuses the audio and text representations. For training, we reframe the MI and TA prediction as a classification task. To incorporate the ordinal nature of MOS scores, one-hot labels are converted to a soft distribution using a Gaussian kernel. On the official test set, a single model trained with this method achieves a system-level Spearman's Rank Correlation Coefficient (SRCC) of 0.991 for MI and 0.952 for TA, corresponding to a relative improvement of 21.21\\% in MI SRCC and 31.47\\% in TA SRCC over the challenge baseline.",
      "authors": [
        "Fabian Ritter-Gutierrez and Yi-Cheng Lin and Jui-Chiang Wei and Jeremy H.M. Wong and Nancy F. Chen and Hung-yi Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:18:15+00:00",
          "link": "https://arxiv.org/abs/2507.09904v1",
          "size": "482kb",
          "version": "v1"
        }
      ],
      "title": "ASTAR-NTU solution to AudioMOS Challenge 2025 Track1",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09904",
        "HTML": "https://arxiv.org/html/2507.09904v1",
        "PDF": "https://arxiv.org/pdf/2507.09904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reports a solution for the AudioMOS Challenge, using MuQ and RoBERTa models, without substantive focus on LLM training data processing or creation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10105",
      "abstract": "This paper presents a novel framework for whole-body torque control of humanoid robots without joint torque sensors, designed for systems with electric motors and high-ratio harmonic drives. The approach integrates Physics-Informed Neural Networks (PINNs) for friction modeling and Unscented Kalman Filtering (UKF) for joint torque estimation, within a real-time torque control architecture. PINNs estimate nonlinear static and dynamic friction from joint and motor velocity readings, capturing effects like motor actuation without joint movement. The UKF utilizes PINN-based friction estimates as direct measurement inputs, improving torque estimation robustness. Experimental validation on the ergoCub humanoid robot demonstrates improved torque tracking accuracy, enhanced energy efficiency, and superior disturbance rejection compared to the state-of-the-art Recursive Newton-Euler Algorithm (RNEA), using a dynamic balancing experiment. The framework's scalability is shown by consistent performance across robots with similar hardware but different friction characteristics, without re-identification. Furthermore, a comparative analysis with position control highlights the advantages of the proposed torque control approach. The results establish the method as a scalable and practical solution for sensorless torque control in humanoid robots, ensuring torque tracking, adaptability, and stability in dynamic environments.",
      "authors": [
        "Ines Sorrentino",
        "Giulio Romualdi",
        "Lorenzo Moretti",
        "Silvio Traversaro",
        "Daniele Pucci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:43:27+00:00",
          "link": "https://arxiv.org/abs/2507.10105v1",
          "size": "2476kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Neural Networks with Unscented Kalman Filter for Sensorless Joint Torque Estimation in Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10105",
        "HTML": "https://arxiv.org/html/2507.10105v1",
        "PDF": "https://arxiv.org/pdf/2507.10105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses sensorless joint torque estimation in humanoid robots using PINNs and UKF, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10464",
      "abstract": "Masked Autoencoders (MAEs) trained on audio spectrogram patches have emerged as a prominent approach for learning self-supervised audio representations. While several recent papers have evaluated key aspects of training MAEs on audio data, the majority of these approaches still leverage vanilla transformer building blocks, whereas the transformer community has seen steady integration of newer architectural advancements. In this work, we propose AudioMAE++, a revamped audio masked autoencoder with two such enhancements, namely macaron-style transformer blocks with gated linear units. When pretrained on the AudioSet dataset, the proposed AudioMAE++ models outperform existing MAE based approaches on 10 diverse downstream tasks, demonstrating excellent performance on audio classification and speech-based benchmarks. The proposed AudioMAE++ models also demonstrate excellent scaling characteristics, outperforming directly comparable standard MAE baselines with up to 4x more parameters.",
      "authors": [
        "Sarthak Yadav",
        "Sergios Theodoridis",
        "Zheng-Hua Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:41:03+00:00",
          "link": "https://arxiv.org/abs/2507.10464v1",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "title": "AudioMAE++: learning better masked audio representations with SwiGLU FFNs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10464",
        "HTML": "https://arxiv.org/html/2507.10464v1",
        "PDF": "https://arxiv.org/pdf/2507.10464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The focus is on improving audio representation learning with architecture advancements, and while it might indirectly involve dataset usage, it does not directly address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19158",
      "abstract": "Type 1 Diabetes (T1D) management is a complex task due to many variability factors. Artificial Pancreas (AP) systems have alleviated patient burden by automating insulin delivery through advanced control algorithms. However, the effectiveness of these systems depends on accurate modeling of glucose-insulin dynamics, which traditional mathematical models often fail to capture due to their inability to adapt to patient-specific variations. This study introduces a Biological-Informed Recurrent Neural Network (BIRNN) framework to address these limitations. The BIRNN leverages a Gated Recurrent Units (GRU) architecture augmented with physics-informed loss functions that embed physiological constraints, ensuring a balance between predictive accuracy and consistency with biological principles. The framework is validated using the commercial UVA/Padova simulator, outperforming traditional linear models in glucose prediction accuracy and reconstruction of unmeasured states, even under circadian variations in insulin sensitivity. The results demonstrate the potential of BIRNN for personalized glucose regulation and future adaptive control strategies in AP systems.",
      "authors": [
        "Stefano De Carli",
        "Nicola Licini",
        "Davide Previtali",
        "Fabio Previdi and Antonio Ferramosca"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T21:26:12+00:00",
          "link": "https://arxiv.org/abs/2503.19158v1",
          "size": "875kb",
          "version": "v1"
        },
        {
          "date": "2025-03-26T09:02:49+00:00",
          "link": "https://arxiv.org/abs/2503.19158v2",
          "size": "875kb",
          "version": "v2"
        }
      ],
      "title": "Integrating Biological-Informed Recurrent Neural Networks for Glucose-Insulin Dynamics Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19158",
        "HTML": "https://arxiv.org/html/2503.19158",
        "PDF": "https://arxiv.org/pdf/2503.19158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating a new model architecture for glucose-insulin dynamics modeling and does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09492",
      "abstract": "Hyperspectral image classification plays a pivotal role in precision agriculture, providing accurate insights into crop health monitoring, disease detection, and soil analysis. However, traditional methods struggle with high-dimensional data, spectral-spatial redundancy, and the scarcity of labeled samples, often leading to suboptimal performance. To address these challenges, we propose the Self-Adaptive Tensor- Regularized Network (SDTN), which combines tensor decomposition with regularization mechanisms to dynamically adjust tensor ranks, ensuring optimal feature representation tailored to the complexity of the data. Building upon SDTN, we propose the Tensor-Regularized Network (TRN), which integrates the features extracted by SDTN into a lightweight network capable of capturing spectral-spatial features at multiple scales. This approach not only maintains high classification accuracy but also significantly reduces computational complexity, making the framework highly suitable for real-time deployment in resource-constrained environments. Experiments on PaviaU datasets demonstrate significant improvements in accuracy and reduced model parameters compared to state-of-the-art methods.",
      "authors": [
        "Fuyin Ye",
        "Erwen Yao",
        "Jianyong Chen",
        "Fengmei He",
        "Junxiang Zhang",
        "Lihao Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:53:33+00:00",
          "link": "https://arxiv.org/abs/2507.09492v1",
          "size": "777kb",
          "version": "v1"
        }
      ],
      "title": "SDTN and TRN: Adaptive Spectral-Spatial Feature Extraction for Hyperspectral Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09492",
        "PDF": "https://arxiv.org/pdf/2507.09492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on hyperspectral image classification using novel tensor-based methods and does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09497",
      "abstract": "Modern enterprise environments demand intelligent systems capable of handling complex, dynamic, and multi-faceted tasks with high levels of autonomy and adaptability. However, traditional single-purpose AI systems often lack sufficient coordination, memory reuse, and task decomposition capabilities, limiting their scalability in realistic settings. To address these challenges, we present \\textbf{GoalfyMax}, a protocol-driven framework for end-to-end multi-agent collaboration. GoalfyMax introduces a standardized Agent-to-Agent (A2A) communication layer built on the Model Context Protocol (MCP), allowing independent agents to coordinate through asynchronous, protocol-compliant interactions. It incorporates the Experience Pack (XP) architecture, a layered memory system that preserves both task rationales and execution traces, enabling structured knowledge retention and continual learning. Moreover, our system integrates advanced features including multi-turn contextual dialogue, long-short term memory modules, and dynamic safety validation, supporting robust, real-time strategy adaptation. Empirical results on complex task orchestration benchmarks and case study demonstrate that GoalfyMax achieves superior adaptability, coordination, and experience reuse compared to baseline frameworks. These findings highlight its potential as a scalable, future-ready foundation for multi-agent intelligent systems.",
      "authors": [
        "Siyi Wu",
        "Zeyu Wang",
        "Xinyuan Song",
        "Zhengpeng Zhou",
        "Lifan Sun",
        "and Tianyu Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:13:52+00:00",
          "link": "https://arxiv.org/abs/2507.09497v1",
          "size": "565kb",
          "version": "v1"
        }
      ],
      "title": "GoalfyMax: A Protocol-Driven Multi-Agent System for Intelligent Experience Entities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09497",
        "HTML": "https://arxiv.org/html/2507.09497v1",
        "PDF": "https://arxiv.org/pdf/2507.09497"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes GoalfyMax, a protocol-driven multi-agent system, focusing on agent collaboration and adaptation; it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09565",
      "abstract": "We introduce a dataset for classifying wellness dimensions in social media user posts, covering six key aspects: physical, emotional, social, intellectual, spiritual, and vocational. The dataset is designed to capture these dimensions in user-generated content, with a comprehensive annotation framework developed under the guidance of domain experts. This framework allows for the classification of text spans into the appropriate wellness categories. We evaluate both traditional machine learning models and advanced transformer-based models for this multi-class classification task, with performance assessed using precision, recall, and F1-score, averaged over 10-fold cross-validation. Post-hoc explanations are applied to ensure the transparency and interpretability of model decisions. The proposed dataset contributes to region-specific wellness assessments in social media and paves the way for personalized well-being evaluations and early intervention strategies in mental health. We adhere to ethical considerations for constructing and releasing our experiments and dataset publicly on Github.",
      "authors": [
        "Heeba Shakeel",
        "Tanvir Ahmad",
        "Chandni Saxena"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:18:15+00:00",
          "link": "https://arxiv.org/abs/2507.09565v1",
          "size": "490kb",
          "version": "v1"
        }
      ],
      "title": "Holistix: A Dataset for Holistic Wellness Dimensions Analysis in Mental Health Narratives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09565",
        "HTML": "https://arxiv.org/html/2507.09565v1",
        "PDF": "https://arxiv.org/pdf/2507.09565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset for classifying wellness dimensions in mental health narratives with comprehensive annotation processes. It provides detailed steps in dataset creation, which directly relates to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09611",
      "abstract": "Artificial intelligence (AI) has made remarkable progress in recent years, yet its rapid expansion brings overlooked environmental and ethical challenges. This review explores four critical areas where AI's impact extends beyond performance: energy consumption, electronic waste (e-waste), inequality in compute access, and the hidden energy burden of cybersecurity systems. Drawing from recent studies and institutional reports, the paper highlights systemic issues such as high emissions from model training, rising hardware turnover, global infrastructure disparities, and the energy demands of securing AI. By connecting these concerns, the review contributes to Responsible AI discourse by identifying key research gaps and advocating for sustainable, transparent, and equitable development practices. Ultimately, it argues that AI's progress must align with ethical responsibility and environmental stewardship to ensure a more inclusive and sustainable technological future.",
      "authors": [
        "Jenis Winsta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:31:42+00:00",
          "link": "https://arxiv.org/abs/2507.09611v1",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "title": "The Hidden Costs of AI: A Review of Energy, E-Waste, and Inequality in Model Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09611",
        "HTML": "https://arxiv.org/html/2507.09611v1",
        "PDF": "https://arxiv.org/pdf/2507.09611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews the environmental and ethical challenges of AI, specifically focusing on energy consumption, e-waste, and inequality, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10196",
      "abstract": "Automated material model discovery disrupts the tedious and time-consuming cycle of iteratively calibrating and modifying manually designed models. Non-smooth L1-norm regularization is the backbone of automated model discovery; however, the current literature on automated material model discovery offers limited insights into the robust and efficient minimization of non-smooth objective functions. In this work, we examine the minimization of functions of the form f(w) + a ||w||_1, where w are the material model parameters, f is a metric that quantifies the mismatch between the material model and the observed data, and a is a regularization parameter that determines the sparsity of the solution. We investigate both the straightforward case where f is quadratic and the more complex scenario where it is non-quadratic or even non-convex. Importantly, we do not only focus on methods that solve the sparse regression problem for a given value of the regularization parameter a, but propose methods to efficiently compute the entire regularization path, facilitating the selection of a suitable a. Specifically, we present four algorithms and discuss their roles for automated material model discovery in mechanics: First, we recapitulate a well-known coordinate descent algorithm that solves the minimization problem assuming that f is quadratic for a given value of a, also known as the LASSO. Second, we discuss the algorithm LARS, which automatically determines the critical values of a, at which material parameters in w are set to zero. Third, we propose to use the proximal gradient method ISTA for automated material model discovery if f is not quadratic, and fourth, we suggest a pathwise extension of ISTA for computing the regularization path. We demonstrate the applicability of all algorithms for the discovery of hyperelastic material models from uniaxial tension and simple shear data.",
      "authors": [
        "Moritz Flaschel",
        "Trevor Hastie",
        "Ellen Kuhl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:03:06+00:00",
          "link": "https://arxiv.org/abs/2507.10196v1",
          "size": "1181kb",
          "version": "v1"
        }
      ],
      "title": "Non-smooth optimization meets automated material model discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10196",
        "HTML": "https://arxiv.org/html/2507.10196v1",
        "PDF": "https://arxiv.org/pdf/2507.10196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses optimization methods for material model discovery, not relevant to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.00043",
      "abstract": "While RNA has recently been recognized as an interesting small-molecule drug target, many challenges remain to be addressed before we take full advantage of it. This emphasizes the necessity to improve our understanding of its structures and functions. Over the years, sequencing technologies have produced an enormous amount of unlabeled RNA data, which hides a huge potential. Motivated by the successes of protein language models, we introduce RiboNucleic Acid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is the largest RNA language model to date, with 650M parameters pre-trained on 36M non-coding RNA sequences from several databases. It can extract hidden knowledge and capture the underlying structure information implicitly embedded within the RNA sequences. RiNALMo achieves state-of-the-art results on several downstream tasks. Notably, we show that its generalization capabilities overcome the inability of other deep learning methods for secondary structure prediction to generalize on unseen RNA families.",
      "authors": [
        "Rafael Josip Peni\\'c",
        "Tin Vla\\v{s}i\\'c",
        "Roland G. Huber",
        "Yue Wan",
        "Mile \\v{S}iki\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-29T14:50:58+00:00",
          "link": "https://arxiv.org/abs/2403.00043v1",
          "size": "14576kb",
          "version": "v1"
        },
        {
          "date": "2024-11-12T15:54:29+00:00",
          "link": "https://arxiv.org/abs/2403.00043v2",
          "size": "7166kb",
          "version": "v2"
        }
      ],
      "title": "RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.00043",
        "HTML": "https://arxiv.org/html/2403.00043",
        "PDF": "https://arxiv.org/pdf/2403.00043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a new RNA language model and its applications but does not discuss processes related to LLM training data preparation or generation."
      },
      "models": [
        {
          "model_path": "multimolecule/rinalmo",
          "downloads": "6001",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/multimolecule/rinalmo"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/lbcb-sci/rinalmo",
        "https://github.com/ml4bio/rna-fm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07192",
      "abstract": "Diffusion models, a type of generative model, have shown promise in time series forecasting. But they face limitations like rigid source distributions and limited sampling paths, which hinder their performance. Flow matching offers faster generation, higher-quality outputs, and greater flexibility, while also possessing the ability to utilize valuable information from the prediction errors of prior models, which were previously inaccessible yet critically important. To address these challenges and fully unlock the untapped potential of flow matching, we propose Conditional Guided Flow Matching (CGFM). CGFM extends flow matching by incorporating the outputs of an auxiliary model, enabling a previously unattainable capability in the field: learning from the errors of the auxiliary model. For time series forecasting tasks, it integrates historical data as conditions and guidance, constructs two-sided conditional probability paths, and uses a general affine path to expand the space of probability paths, ultimately leading to improved predictions. Extensive experiments show that CGFM consistently enhances and outperforms state-of-the-art models, highlighting its effectiveness in advancing forecasting methods.",
      "authors": [
        "Huibo Xu and Runlong Yu and Likang Wu and Xianquan Wang and Qi Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:03:31+00:00",
          "link": "https://arxiv.org/abs/2507.07192v1",
          "size": "2074kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T03:33:58+00:00",
          "link": "https://arxiv.org/abs/2507.07192v2",
          "size": "2074kb",
          "version": "v2"
        }
      ],
      "title": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07192",
        "HTML": "https://arxiv.org/html/2507.07192v2",
        "PDF": "https://arxiv.org/pdf/2507.07192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing time series forecasting using diffusion models and conditional flow matching, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09282",
      "abstract": "Dementia, a neurodegenerative disease, alters speech patterns, creating communication barriers and raising privacy concerns. Current speech technologies, such as automatic speech transcription (ASR), struggle with dementia and atypical speech, further challenging accessibility. This paper presents a novel dementia obfuscation in speech framework, ClaritySpeech, integrating ASR, text obfuscation, and zero-shot text-to-speech (TTS) to correct dementia-affected speech while preserving speaker identity in low-data environments without fine-tuning. Results show a 16% and 10% drop in mean F1 score across various adversarial settings and modalities (audio, text, fusion) for ADReSS and ADReSSo, respectively, maintaining 50% speaker similarity. We also find that our system improves WER (from 0.73 to 0.08 for ADReSS and 0.15 for ADReSSo) and speech quality from 1.65 to ~2.15, enhancing privacy and accessibility.",
      "authors": [
        "Dominika Woszczyk",
        "Ranya Aloufi",
        "Soteris Demetriou"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.09282v1",
          "size": "624kb",
          "version": "v1"
        }
      ],
      "title": "ClaritySpeech: Dementia Obfuscation in Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09282",
        "HTML": "https://arxiv.org/html/2507.09282v1",
        "PDF": "https://arxiv.org/pdf/2507.09282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a framework for dementia obfuscation in speech, which involves ASR and TTS techniques, with no focus on LLM training data processing or data engineering for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09583",
      "abstract": "The advent of powerful, accessible Large Language Models (LLMs) like Google's Gemini presents new opportunities for democratizing financial data analysis. This paper documents the design, implementation, and iterative debugging of a novel, serverless system for real-time stock analysis. The system leverages the Gemini API for qualitative assessment, automates data ingestion and processing via GitHub Actions, and presents the findings through a decoupled, static frontend. We detail the architectural evolution of the system, from initial concepts to a robust, event-driven pipeline, highlighting the practical challenges encountered during deployment. A significant portion of this paper is dedicated to a case study on the debugging process, covering common software errors, platform-specific permission issues, and rare, environment-level platform bugs. The final architecture operates at a near-zero cost, demonstrating a viable model for individuals to build sophisticated AI-powered financial tools. The operational application is publicly accessible, and the complete source code is available for review. We conclude by discussing the role of LLMs in financial analysis, the importance of robust debugging methodologies, and the emerging paradigm of human-AI collaboration in software development.",
      "authors": [
        "Taniv Ashraf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:29:51+00:00",
          "link": "https://arxiv.org/abs/2507.09583v1",
          "size": "7kb",
          "version": "v1"
        }
      ],
      "title": "A Serverless Architecture for Real-Time Stock Analysis using Large Language Models: An Iterative Development and Debugging Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09583",
        "HTML": "https://arxiv.org/html/2507.09583v1",
        "PDF": "https://arxiv.org/pdf/2507.09583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the architecture for real-time stock analysis using LLMs, primarily discussing system design and debugging, without centering on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09891",
      "abstract": "Characterization of quantum systems from experimental data is a central problem in quantum science and technology. But which measurements should be used to gather data in the first place? While optimal measurement choices can be worked out for small quantum systems, the optimization becomes intractable as the system size grows large. To address this problem, we introduce a deep neural network with a sequence model architecture that searches for efficient measurement choices in a data-driven, adaptive manner. The model can be applied to a variety of tasks, including the prediction of linear and nonlinear properties of quantum states, as well as state clustering and state tomography tasks. In all these tasks, we find that the measurement choices identified by our neural network consistently outperform the uniformly random choice. Intriguingly, for topological quantum systems, our model tends to recommend measurements at the system's boundaries, even when the task is to predict bulk properties. This behavior suggests that the neural network may have independently discovered a connection between boundaries and bulk, without having been provided any built-in knowledge of quantum physics.",
      "authors": [
        "Jiaxin Huang",
        "Yan Zhu",
        "Giulio Chiribella and Ya-Dong Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:50:42+00:00",
          "link": "https://arxiv.org/abs/2507.09891v1",
          "size": "8964kb",
          "version": "v1"
        }
      ],
      "title": "Sequence-Model-Guided Measurement Selection for Quantum State Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09891",
        "HTML": "https://arxiv.org/html/2507.09891v1",
        "PDF": "https://arxiv.org/pdf/2507.09891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about optimizing measurement choices for quantum state learning using a neural network. It does not involve processing LLM training data or creating datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09985",
      "abstract": "Touch is recognized as a vital sense for humans and an equally important modality for robots, especially for dexterous manipulation, material identification, and scenarios involving visual occlusion. Building upon very recent work in touch foundation models, this demonstration will feature Octopi-1.5, our latest visual-tactile-language model. Compared to its predecessor, Octopi-1.5 introduces the ability to process tactile signals from multiple object parts and employs a simple retrieval-augmented generation (RAG) module to improve performance on tasks and potentially learn new objects on-the-fly. The system can be experienced live through a new handheld tactile-enabled interface, the TMI, equipped with GelSight and TAC-02 tactile sensors. This convenient and accessible setup allows users to interact with Octopi-1.5 without requiring a robot. During the demonstration, we will showcase Octopi-1.5 solving tactile inference tasks by leveraging tactile inputs and commonsense knowledge. For example, in a Guessing Game, Octopi-1.5 will identify objects being grasped and respond to follow-up queries about how to handle it (e.g., recommending careful handling for soft fruits). We also plan to demonstrate Octopi-1.5's RAG capabilities by teaching it new items. With live interactions, this demonstration aims to highlight both the progress and limitations of VTLMs such as Octopi-1.5 and to foster further interest in this exciting field. Code for Octopi-1.5 and design files for the TMI gripper are available at https://github.com/clear-nus/octopi-1.5.",
      "authors": [
        "Samson Yu",
        "Kelvin Lin",
        "Harold Soh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:05:36+00:00",
          "link": "https://arxiv.org/abs/2507.09985v1",
          "size": "7416kb",
          "version": "v1"
        }
      ],
      "title": "Demonstrating the Octopi-1.5 Visual-Tactile-Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09985",
        "HTML": "https://arxiv.org/html/2507.09985v1",
        "PDF": "https://arxiv.org/pdf/2507.09985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While it mentions retrieval-augmented generation methods enhancing learning, the core focus is on multimodal integration rather than on specific training data processing improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.00365",
      "abstract": "Brain age is a critical measure that reflects the biological ageing process of the brain. The gap between brain age and chronological age, referred to as brain PAD (Predicted Age Difference), has been utilized to investigate neurodegenerative conditions. Brain age can be predicted using MRIs and machine learning techniques. However, existing methods are often sensitive to acquisition-related variabilities, such as differences in acquisition protocols, scanners, MRI sequences, and resolutions, significantly limiting their application in highly heterogeneous clinical settings. In this study, we introduce Synthetic Brain Age (SynthBA), a robust deep-learning model designed for predicting brain age. SynthBA utilizes an advanced domain randomization technique, ensuring effective operation across a wide array of acquisition-related variabilities. To assess the effectiveness and robustness of SynthBA, we evaluate its predictive capabilities on internal and external datasets, encompassing various MRI sequences and resolutions, and compare it with state-of-the-art techniques. Additionally, we calculate the brain PAD in a large cohort of subjects with Alzheimer's Disease (AD), demonstrating a significant correlation with AD-related measures of cognitive dysfunction. SynthBA holds the potential to facilitate the broader adoption of brain age prediction in clinical settings, where re-training or fine-tuning is often unfeasible. The SynthBA source code and pre-trained models are publicly available at https://github.com/LemuelPuglisi/SynthBA.",
      "authors": [
        "Lemuel Puglisi",
        "Alessia Rondinella",
        "Linda De Meo",
        "Francesco Guarnera",
        "Sebastiano Battiato",
        "Daniele Rav\\`i"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-01T08:58:40+00:00",
          "link": "https://arxiv.org/abs/2406.00365v1",
          "size": "1666kb",
          "version": "v1"
        },
        {
          "date": "2024-07-19T16:32:05+00:00",
          "link": "https://arxiv.org/abs/2406.00365v2",
          "size": "1666kb",
          "version": "v2"
        }
      ],
      "title": "SynthBA: Reliable Brain Age Estimation Across Multiple MRI Sequences and Resolutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00365",
        "HTML": "https://arxiv.org/html/2406.00365",
        "PDF": "https://arxiv.org/pdf/2406.00365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a deep-learning model for brain age prediction across MRI sequences and focuses on model robustness. It does not involve LLM training data processing or data engineering techniques."
      },
      "tasks": [
        "Age Estimation"
      ],
      "repo_urls": [
        "https://github.com/lemuelpuglisi/synthba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00555",
      "abstract": "Large language models (LLMs) are empowering decision-making in several applications, including tool or API usage and answering multiple-choice questions (MCQs). However, incorrect outputs pose significant risks in high-stakes domains like healthcare and finance. To quantify LLM uncertainty and thereby mitigate these risks, recent works employ conformal prediction (CP), a model- and distribution-agnostic framework that uses LLM outputs to generate a \\emph{prediction set} containing the true answer with high probability. Leveraging CP, we propose \\emph{conformal revision of questions} (CROQ), which revises the question by narrowing down the available choices to those in the prediction set and asking the LLM the revised question. We expect LLMs to be more accurate on revised questions with fewer choices. Furthermore, we expect CROQ to be effective when the prediction sets from CP are small. Commonly used logit scores often lead to large sets, diminishing CROQ's effectiveness. To overcome this, we propose CP-OPT, an optimization framework to learn scores that minimize set sizes while maintaining coverage. Our extensive experiments on MMLU, ToolAlpaca, and TruthfulQA datasets with multiple LLMs show that CROQ improves accuracy over the standard inference, with more pronounced gains when paired with CP-OPT.",
      "authors": [
        "Harit Vishwakarma",
        "Alan Mishler",
        "Thomas Cook",
        "Niccol\\`o Dalmasso",
        "Natraj Raman",
        "Sumitra Ganesh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Applications (stat.AP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T17:33:12+00:00",
          "link": "https://arxiv.org/abs/2501.00555v1",
          "size": "954kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T18:07:42+00:00",
          "link": "https://arxiv.org/abs/2501.00555v2",
          "size": "671kb",
          "version": "v2"
        }
      ],
      "title": "Prune 'n Predict: Optimizing LLM Decision-making with Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00555",
        "PDF": "https://arxiv.org/pdf/2501.00555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses conformal prediction to enhance LLM decision-making accuracy. While it addresses prediction improvement, it does not primarily focus on LLM training data processing or data engineering techniques."
      },
      "tasks": [
        "Conformal Prediction",
        "Decision Making",
        "MMLU",
        "Multiple-choice",
        "Prediction",
        "TruthfulQA",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23395",
      "abstract": "FastSet is a distributed protocol for decentralized finance and settlement, which is inspired from both actors and blockchains. Account holders cooperate by making claims, which can include payments, holding and transferring assets, accessing and updating shared data, medical records, digital identity, and mathematical theorems, among others. The claims are signed by their owners and are broadcast to a decentralized network of validators, which validate and settle them. Validators replicate the global state of the accounts and need not communicate with each other. In sharp contrast to blockchains, strong consistency is purposely given up as a requirement. Yet, many if not most of the blockchain benefits are preserved, while capitalizing on actor's massive parallelism. The protocol is proved to be correct, despite its massively parallel nature.",
      "authors": [
        "Xiaohong Chen and Grigore Rosu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T20:50:04+00:00",
          "link": "https://arxiv.org/abs/2506.23395v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T12:27:14+00:00",
          "link": "https://arxiv.org/abs/2506.23395v2",
          "size": "68kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T09:09:45+00:00",
          "link": "https://arxiv.org/abs/2506.23395v3",
          "size": "69kb",
          "version": "v3"
        }
      ],
      "title": "FastSet: Parallel Claim Settlement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23395",
        "HTML": "https://arxiv.org/html/2506.23395v3",
        "PDF": "https://arxiv.org/pdf/2506.23395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a distributed protocol for decentralized finance and settlement, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23425",
      "abstract": "Load flow analysis is a fundamental technique used by electrical engineers to simulate and evaluate power system behavior under steady-state conditions. It enables efficient operation and control by determining how active and reactive power flows throughout the system. Selecting an appropriate solution method is critical to ensuring reliable and economical operation of power generation, transmission, and distribution networks. While the conventional loop method may be used in small-scale systems, it is limited by its reliance on impedance-based load data and its inability to scale to complex networks. In contrast, iterative techniques such as the Gauss-Seidel (GS) and Newton-Raphson (NR) methods are better suited for analyzing large systems. Of these, the NR method offers significant advantages due to its quadratic convergence and improved numerical stability. This study presents a power flow analysis of a 5-bus system using the Newton-Raphson approach. The system was modeled and simulated in PowerWorld Simulator (PWS), and a custom MATLAB implementation was developed to verify the results under a base case scenario. The comparative analysis demonstrates that the NR method provides accurate and robust solutions for power flow problems, making it well-suited for evaluating system performance under various operating conditions.",
      "authors": [
        "Sampson E. Nwachukwu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:15:51+00:00",
          "link": "https://arxiv.org/abs/2506.23425v1",
          "size": "1497kb",
          "version": "v1"
        }
      ],
      "title": "Power Flow Analysis of a 5-Bus Power System Based on Newton-Raphson Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23425",
        "PDF": "https://arxiv.org/pdf/2506.23425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on power flow analysis in electrical systems using the Newton-Raphson method, which is unrelated to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10422",
      "abstract": "The widespread adoption of generative AI (GenAI) tools such as GitHub Copilot and ChatGPT is transforming software development. Since generated source code is virtually impossible to distinguish from manually written code, their real-world usage and impact on open-source software development remain poorly understood. In this paper, we introduce the concept of self-admitted GenAI usage, that is, developers explicitly referring to the use of GenAI tools for content creation in software artifacts. Using this concept as a lens to study how GenAI tools are integrated into open-source software projects, we analyze a curated sample of more than 250,000 GitHub repositories, identifying 1,292 such self-admissions across 156 repositories in commit messages, code comments, and project documentation. Using a mixed methods approach, we derive a taxonomy of 32 tasks, 10 content types, and 11 purposes associated with GenAI usage based on 284 qualitatively coded mentions. We then analyze 13 documents with policies and usage guidelines for GenAI tools and conduct a developer survey to uncover the ethical, legal, and practical concerns behind them. Our findings reveal that developers actively manage how GenAI is used in their projects, highlighting the need for project-level transparency, attribution, and quality control practices in the new era of AI-assisted software development. Finally, we examine the longitudinal impact of GenAI adoption on code churn in 151 repositories with self-admitted GenAI usage and find no general increase, contradicting popular narratives on the impact of GenAI on software development.",
      "authors": [
        "Tao Xiao",
        "Youmei Fan",
        "Fabio Calefato",
        "Christoph Treude",
        "Raula Gaikovina Kula",
        "Hideaki Hata",
        "Sebastian Baltes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:05:49+00:00",
          "link": "https://arxiv.org/abs/2507.10422v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "Self-Admitted GenAI Usage in Open-Source Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10422",
        "HTML": "https://arxiv.org/html/2507.10422v1",
        "PDF": "https://arxiv.org/pdf/2507.10422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores generative AI usage in software development and its implications but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.12318",
      "abstract": "Fingerprinting large language models (LLMs) is essential for verifying model ownership, ensuring authenticity, and preventing misuse. Traditional fingerprinting methods often require significant computational overhead or white-box verification access. In this paper, we introduce UTF, a novel and efficient approach to fingerprinting LLMs by leveraging under-trained tokens. Under-trained tokens are tokens that the model has not fully learned during its training phase. By utilizing these tokens, we perform supervised fine-tuning to embed specific input-output pairs into the model. This process allows the LLM to produce predetermined outputs when presented with certain inputs, effectively embedding a unique fingerprint. Our method has minimal overhead and impact on model's performance, and does not require white-box access to target model's ownership identification. Compared to existing fingerprinting methods, UTF is also more effective and robust to fine-tuning and random guess.",
      "authors": [
        "Jiacheng Cai",
        "Jiahao Yu",
        "Yangguang Shao",
        "Yuhang Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T07:36:57+00:00",
          "link": "https://arxiv.org/abs/2410.12318v1",
          "size": "182kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T01:35:14+00:00",
          "link": "https://arxiv.org/abs/2410.12318v2",
          "size": "199kb",
          "version": "v2"
        }
      ],
      "title": "UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12318",
        "HTML": "https://arxiv.org/html/2410.12318v2",
        "PDF": "https://arxiv.org/pdf/2410.12318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves using under-trained tokens for fingerprinting, it does not primarily focus on processing or creating training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.03723",
      "abstract": "Hardware design automation faces challenges in generating high-quality Verilog code efficiently. This paper introduces VFlow, an automated framework that optimizes agentic workflows for Verilog code generation. Unlike traditional approaches relying on fixed prompts or manually designed flows, VFlow treats workflow discovery as a search over graph-structured LLM invocation sequences. It introduces a multi-population cooperative evolution (CEPE-MCTS) algorithm that balances multiple hardware objectives -- functional correctness, area, power, timing and token cost -- while sharing successful patterns and avoiding repeated failures. Integrated multi-level verification ensures syntactic correctness, functional behavior, and synthesizability. Experiments on VerilogEval and RTLLM2.0 show VFlow improves pass@1 by 20--30\\% over prompting baselines and closely matches designer-level area/power. Remarkably, VFlow enables small LLMs to outperform larger models with up to 10.9$\\times$ ROI, offering a cost-effective solution for RTL design. This work paves the way for intelligent, automated hardware development, advancing LLM applications in EDA.",
      "authors": [
        "Yangbo Wei",
        "Zhen Huang",
        "Huang Li",
        "Wei W. Xing",
        "Ting-Jung Lin",
        "Lei He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-30T15:44:22+00:00",
          "link": "https://arxiv.org/abs/2504.03723v1",
          "size": "3188kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T08:44:02+00:00",
          "link": "https://arxiv.org/abs/2504.03723v2",
          "size": "675kb",
          "version": "v2"
        }
      ],
      "title": "VFlow: Discovering Optimal Agentic Workflows for Verilog Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03723",
        "HTML": "https://arxiv.org/html/2504.03723v2",
        "PDF": "https://arxiv.org/pdf/2504.03723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing workflows for Verilog code generation and does not involve any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.02178",
      "abstract": "We present a method for Sparse view reconstruction with surface element splatting that runs within 3 minutes on a consumer grade GPU. While few methods address sparse radiance field learning from noisy or unposed sparse cameras, shape recovery remains relatively underexplored in this setting. Several radiance and shape learning test-time optimization methods address the sparse posed setting by learning data priors or using combinations of external monocular geometry priors. Differently, we propose an efficient and simple pipeline harnessing a single recent 3D foundation model. We leverage its various task heads, notably point maps and camera initializations to instantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and image correspondences to guide camera optimization midst 2DGS training. Key to our contribution is a novel formulation of splatted color variance along rays, which can be computed efficiently. Reducing this moment in training leads to more accurate shape reconstructions. We demonstrate state-of-the-art performances in the sparse uncalibrated setting in reconstruction and novel view benchmarks based on established multi-view datasets.",
      "authors": [
        "Shubhendu Jena and Amine Ouasfi and Mae Younes and Adnane Boukhayma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T16:40:24+00:00",
          "link": "https://arxiv.org/abs/2505.02178v1",
          "size": "37883kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:42:51+00:00",
          "link": "https://arxiv.org/abs/2505.02178v2",
          "size": "27952kb",
          "version": "v2"
        }
      ],
      "title": "Sparfels: Fast Reconstruction from Sparse Unposed Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02178",
        "HTML": "https://arxiv.org/html/2505.02178v2",
        "PDF": "https://arxiv.org/pdf/2505.02178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses sparse view reconstruction using radiance fields and a 3D foundation model. It does not relate to LLM training data or processing methods for large language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.15634",
      "abstract": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and mathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT length, as seen in models such as DeepSeek-R1, significantly enhances this reasoning for complex problems, but requires costly and high-quality long CoT data and fine-tuning. This work, inspired by the deep thinking paradigm of DeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of an LLM without external datasets. Our method first employs Sparse Autoencoders (SAEs) to extract interpretable features from vanilla CoT. These features are then used to steer the LLM's internal states during generation. Recognizing that many LLMs do not have corresponding pre-trained SAEs, we further introduce a novel SAE-free steering algorithm, which directly computes steering directions from the residual activations of an LLM, obviating the need for an explicit SAE. Experimental results demonstrate that both our SAE-based and subsequent SAE-free steering algorithms significantly enhance the reasoning capabilities of LLMs.",
      "authors": [
        "Zihao Li",
        "Xu Wang",
        "Yuzhe Yang",
        "Ziyu Yao",
        "Haoyi Xiong",
        "Mengnan Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T15:17:59+00:00",
          "link": "https://arxiv.org/abs/2505.15634v1",
          "size": "1182kb",
          "version": "v1"
        },
        {
          "date": "2025-05-24T15:20:30+00:00",
          "link": "https://arxiv.org/abs/2505.15634v2",
          "size": "1182kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T01:29:52+00:00",
          "link": "https://arxiv.org/abs/2505.15634v3",
          "size": "1183kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T09:42:16+00:00",
          "link": "https://arxiv.org/abs/2505.15634v4",
          "size": "1182kb",
          "version": "v4"
        }
      ],
      "title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15634",
        "HTML": "https://arxiv.org/html/2505.15634v4",
        "PDF": "https://arxiv.org/pdf/2505.15634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing reasoning capabilities using steering techniques without external datasets, which minimally touches on data processing aspects related to LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.19319",
      "abstract": "White Light Imaging (WLI) and Narrow Band Imaging (NBI) are the two main colonoscopic modalities for polyp classification. While NBI, as optical chromoendoscopy, offers valuable vascular details, WLI remains the most common and often the only available modality in resource-limited settings. However, WLI-based methods typically underperform, limiting their clinical applicability. Existing approaches transfer knowledge from NBI to WLI through global feature alignment but often rely on cropped lesion regions, which are susceptible to detection errors and neglect contextual and subtle diagnostic cues. To address this, this paper proposes a novel holistic classification framework that leverages full-image diagnosis without requiring polyp localization. The key innovation lies in the Alignment-free Dense Distillation (ADD) module, which enables fine-grained cross-domain knowledge distillation regardless of misalignment between WLI and NBI images. Without resorting to explicit image alignment, ADD learns pixel-wise cross-domain affinities to establish correspondences between feature maps, guiding the distillation along the most relevant pixel connections. To further enhance distillation reliability, ADD incorporates Class Activation Mapping (CAM) to filter cross-domain affinities, ensuring the distillation path connects only those semantically consistent regions with equal contributions to polyp diagnosis. Extensive results on public and in-house datasets show that our method achieves state-of-the-art performance, relatively outperforming the other approaches by at least 2.5% and 16.2% in AUC, respectively. Code is available at: https://github.com/Huster-Hq/ADD.",
      "authors": [
        "Qiang Hu",
        "Qimei Wang",
        "Jia Chen",
        "Xuantao Ji",
        "Mei Liu",
        "Qiang Li",
        "Zhiwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T21:09:58+00:00",
          "link": "https://arxiv.org/abs/2505.19319v1",
          "size": "7843kb",
          "version": "v1"
        },
        {
          "date": "2025-06-22T18:50:46+00:00",
          "link": "https://arxiv.org/abs/2505.19319v2",
          "size": "7792kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T14:17:27+00:00",
          "link": "https://arxiv.org/abs/2505.19319v3",
          "size": "7792kb",
          "version": "v3"
        }
      ],
      "title": "Holistic White-light Polyp Classification via Alignment-free Dense Distillation of Auxiliary Optical Chromoendoscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19319",
        "HTML": "https://arxiv.org/html/2505.19319v3",
        "PDF": "https://arxiv.org/pdf/2505.19319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a polyp classification framework using distillation techniques, which does not involve any aspect of LLM training data collection or processing."
      },
      "tasks": [
        "Diagnostic",
        "Knowledge Distillation"
      ],
      "repo_urls": [
        "https://github.com/huster-hq/add"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06787",
      "abstract": "This article presents a novel stream function-based navigational control system for obstacle avoidance, where obstacles are represented as two-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The approach leverages the vortex panel method (VPM) and incorporates safety margins to control the stream function and flow properties around virtual surfaces, enabling navigation in complex, partially observed environments using real-time sensing. To address the limitations of the VPM in managing relative distance and avoiding rapidly accelerating obstacles at close proximity, the system integrates a model predictive controller (MPC) based on higher-order control barrier functions (HOCBF). This integration incorporates VPM trajectory generation, state estimation, and constraint handling into a receding-horizon optimization problem. The 2D rigid surfaces are enclosed using minimum bounding ellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts obstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid avoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone Gazebo simulator and real-time experiments involving a COEX Clover quadcopter equipped with a 360 degree LiDAR sensor.",
      "authors": [
        "Sean Smith",
        "Emmanuel Witrant",
        "Ya-Jun Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:23:30+00:00",
          "link": "https://arxiv.org/abs/2507.06787v1",
          "size": "7550kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T12:27:04+00:00",
          "link": "https://arxiv.org/abs/2507.06787v2",
          "size": "7550kb",
          "version": "v2"
        }
      ],
      "title": "Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06787",
        "HTML": "https://arxiv.org/html/2507.06787v2",
        "PDF": "https://arxiv.org/pdf/2507.06787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a navigation control system for quadcopters and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09091",
      "abstract": "We generalize the low-rank decomposition problem, such as principal and independent component analysis (PCA, ICA) for continuous-time vector-valued signals and provide a model-agnostic implicit neural signal representation framework to learn numerical approximations to solve the problem. Modeling signals as continuous-time stochastic processes, we unify the approaches to both the PCA and ICA problems in the continuous setting through a contrast function term in the network loss, enforcing the desired statistical properties of the source signals (decorrelation, independence) learned in the decomposition. This extension to a continuous domain allows the application of such decompositions to point clouds and irregularly sampled signals where standard techniques are not applicable.",
      "authors": [
        "Shayan K. Azmoodeh",
        "Krishna Subramani",
        "Paris Smaragdis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:20:16+00:00",
          "link": "https://arxiv.org/abs/2507.09091v1",
          "size": "2756kb",
          "version": "v1"
        }
      ],
      "title": "Continuous-Time Signal Decomposition: An Implicit Neural Generalization of PCA and ICA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09091",
        "HTML": "https://arxiv.org/html/2507.09091v1",
        "PDF": "https://arxiv.org/pdf/2507.09091"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on signal decomposition techniques like PCA and ICA for continuous-time vector-valued signals, without discussing LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09245",
      "abstract": "The Swa-bhasha Resource Hub provides a comprehensive collection of data resources and algorithms developed for Romanized Sinhala to Sinhala transliteration between 2020 and 2025. These resources have played a significant role in advancing research in Sinhala Natural Language Processing (NLP), particularly in training transliteration models and developing applications involving Romanized Sinhala. The current openly accessible data sets and corresponding tools are made publicly available through this hub. This paper presents a detailed overview of the resources contributed by the authors and includes a comparative analysis of existing transliteration applications in the domain.",
      "authors": [
        "Deshan Sumanathilaka",
        "Sameera Perera",
        "Sachithya Dharmasiri",
        "Maneesha Athukorala",
        "Anuja Dilrukshi Herath",
        "Rukshan Dias",
        "Pasindu Gamage",
        "Ruvan Weerasinghe",
        "Y.H.P.P. Priyadarshana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:54:30+00:00",
          "link": "https://arxiv.org/abs/2507.09245v1",
          "size": "320kb",
          "version": "v1"
        }
      ],
      "title": "Swa-bhasha Resource Hub: Romanized Sinhala to Sinhala Transliteration Systems and Data Resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09245",
        "PDF": "https://arxiv.org/pdf/2507.09245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on developing a transliteration system with clear data processing steps involved in converting Romanized Sinhala to Sinhala, emphasizing dataset creation and processing in the NLP domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09527",
      "abstract": "With the proliferation of electric vehicles (EVs), accurate charging demand and station occupancy forecasting are critical for optimizing urban energy and the profit of EVs aggregator. Existing approaches in this field usually struggle to capture the complex spatio-temporal dependencies in EV charging behaviors, and their limited model parameters hinder their ability to learn complex data distribution representations from large datasets. To this end, we propose a novel EV spatio-temporal large language model (EV-STLLM) for accurate prediction. Our proposed framework is divided into two modules. In the data processing module, we utilize variational mode decomposition (VMD) for data denoising, and improved complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN) for data multi-frequency decomposition. Fuzzy information granulation (FIG) for extracting multi-scale information. Additionally, ReliefF is used for feature selection to mitigate redundancy. In the forecasting module, the EV-STLLM is used to directly achieve EV charging and occupancy forecasting. Firstly, we fully capture the intrinsic spatio-temporal characteristics of the data by integrating adjacency matrices derived from the regional stations network and spatio-temporal-frequency embedding information. Then, the partially frozen graph attention (PFGA) module is utilized to maintain the sequential feature modeling capabilities of the pre-trained large model while incorporating EV domain knowledge. Extensive experiments using real-world data from Shenzhen, China, demonstrate that our proposed framework can achieve superior accuracy and robustness compared to the state-of-the-art benchmarks.",
      "authors": [
        "Hang Fan",
        "Yunze Chai",
        "Chenxi Liu",
        "Weican Liu",
        "Zuhan Zhang",
        "Wencai Run and Dunnan Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T07:59:13+00:00",
          "link": "https://arxiv.org/abs/2507.09527v1",
          "size": "3214kb",
          "version": "v1"
        }
      ],
      "title": "EV-STLLM: Electric vehicle charging forecasting based on spatio-temporal large language models with multi-frequency and multi-scale information fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09527",
        "HTML": "https://arxiv.org/html/2507.09527v1",
        "PDF": "https://arxiv.org/pdf/2507.09527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a data processing module where techniques such as variational mode decomposition, ICEEMDAN, and fuzzy information granulation are used for data denoising and feature extraction. However, the main focus is on leveraging these processed data for EV charging forecasting rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09664",
      "abstract": "Programming-by-prompting with generative AI offers a new paradigm for end-user programming, shifting the focus from syntactic fluency to semantic intent. This shift holds particular promise for non-programmers such as educators, who can describe instructional goals in natural language to generate interactive learning content. Yet in bypassing direct code authoring, many of programming's core affordances - such as traceability, stepwise refinement, and behavioral testing - are lost. We propose the Chain-of-Abstractions (CoA) framework as a way to recover these affordances while preserving the expressive flexibility of natural language. CoA decomposes the synthesis process into a sequence of cognitively meaningful, task-aligned representations that function as checkpoints for specification, inspection, and refinement. We instantiate this approach in SimStep, an authoring environment for teachers that scaffolds simulation creation through four intermediate abstractions: Concept Graph, Scenario Graph, Learning Goal Graph, and UI Interaction Graph. To address ambiguities and misalignments, SimStep includes an inverse correction process that surfaces in-filled model assumptions and enables targeted revision without requiring users to manipulate code. Evaluations with educators show that CoA enables greater authoring control and interpretability in programming-by-prompting workflows.",
      "authors": [
        "Zoe Kaputa",
        "Anika Rajaram",
        "Vryan Almanon Feliciano",
        "Zhuoyue Lyu",
        "Maneesh Agrawala",
        "Hari Subramonyam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:54:17+00:00",
          "link": "https://arxiv.org/abs/2507.09664v1",
          "size": "9812kb",
          "version": "v1"
        }
      ],
      "title": "SimStep: Chain-of-Abstractions for Incremental Specification and Debugging of AI-Generated Interactive Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09664",
        "HTML": "https://arxiv.org/html/2507.09664v1",
        "PDF": "https://arxiv.org/pdf/2507.09664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on using AI for end-user programming by generating interactive simulations and does not involve any contributions or methodologies related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09687",
      "abstract": "Text classification plays a pivotal role in edge computing applications like industrial monitoring, health diagnostics, and smart assistants, where low latency and high accuracy are both key requirements. Generative classifiers, in particular, have been shown to exhibit robustness to out-of-distribution and noisy data, which is an extremely critical consideration for deployment in such real-time edge environments. However, deploying such models on edge devices faces computational and memory constraints. Post Training Quantization (PTQ) reduces model size and compute costs without retraining, making it ideal for edge deployment. In this work, we present a comprehensive comparative study of generative and discriminative Long Short Term Memory (LSTM)-based text classification models with PTQ using the Brevitas quantization library. We evaluate both types of classifier models across multiple bitwidths and assess their robustness under regular and noisy input conditions. We find that while discriminative classifiers remain robust, generative ones are more sensitive to bitwidth, calibration data used during PTQ, and input noise during quantized inference. We study the influence of class imbalance in calibration data for both types of classifiers, comparing scenarios with evenly and unevenly distributed class samples including their effect on weight adjustments and activation profiles during PTQ. Using test statistics derived from nonparametric hypothesis testing, we identify that using class imbalanced data during calibration introduces insufficient weight adaptation at lower bitwidths for generative LSTM classifiers, thereby leading to degraded performance. This study underscores the role of calibration data in PTQ and when generative classifiers succeed or fail under noise, aiding deployment in edge environments.",
      "authors": [
        "Md Mushfiqur Rahaman",
        "Elliot Chang",
        "Tasmiah Haque",
        "Srinjoy Das"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:48:16+00:00",
          "link": "https://arxiv.org/abs/2507.09687v1",
          "size": "672kb",
          "version": "v1"
        }
      ],
      "title": "Post-Training Quantization of Generative and Discriminative LSTM Text Classifiers: A Study of Calibration, Class Balance, and Robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09687",
        "HTML": "https://arxiv.org/html/2507.09687v1",
        "PDF": "https://arxiv.org/pdf/2507.09687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary focus of the paper is on post-training quantization of text classifiers for deployment on edge devices, with an emphasis on model size and computation cost reduction, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09816",
      "abstract": "Neural networks are capable of superposition -- representing more features than there are dimensions. Recent work considers the analogous concept for computation instead of storage, proposing theoretical constructions. But there has been little investigation into whether these circuits can be learned in practice. In this work, we investigate a toy model for the Universal-AND problem which computes the AND of all $m\\choose 2$ pairs of $m$ sparse inputs. The hidden dimension that determines the number of non-linear activations is restricted to pressure the model to find a compute-efficient circuit, called compressed computation. We find that the training process finds a simple solution that does not correspond to theoretical constructions. It is fully dense -- every neuron contributes to every output. The solution circuit naturally scales with dimension, trading off error rates for neuron efficiency. It is similarly robust to changes in sparsity and other key parameters, and extends naturally to other boolean operations and boolean circuits. We explain the found solution in detail and compute why it is more efficient than the theoretical constructions at low sparsity. Our findings shed light on the types of circuits that models like to form and the flexibility of the superposition representation. This contributes to a broader understanding of network circuitry and interpretability.",
      "authors": [
        "Adam Newgas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T22:18:15+00:00",
          "link": "https://arxiv.org/abs/2507.09816v1",
          "size": "1736kb",
          "version": "v1"
        }
      ],
      "title": "Compressed Computation: Dense Circuits in a Toy Model of the Universal-AND Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09816",
        "HTML": "https://arxiv.org/html/2507.09816v1",
        "PDF": "https://arxiv.org/pdf/2507.09816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural network circuitry and interpretability in a toy model for the Universal-AND problem, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09961",
      "abstract": "Deep learning often struggles when training and test data distributions differ. Traditional domain generalization (DG) tackles this by including data from multiple source domains, which is impractical due to expensive data collection and annotation. Recent vision-language models like CLIP enable source-free domain generalization (SFDG) by using text prompts to simulate visual representations, reducing data demands. However, existing SFDG methods struggle with domain-specific confounders, limiting their generalization capabilities. To address this issue, we propose TDCRL (\\textbf{T}ext-\\textbf{D}riven \\textbf{C}ausal \\textbf{R}epresentation \\textbf{L}earning), the first method to integrate causal inference into the SFDG setting. TDCRL operates in two steps: first, it employs data augmentation to generate style word vectors, combining them with class information to generate text embeddings to simulate visual representations; second, it trains a causal intervention network with a confounder dictionary to extract domain-invariant features. Grounded in causal learning, our approach offers a clear and effective mechanism to achieve robust, domain-invariant features, ensuring robust generalization. Extensive experiments on PACS, VLCS, OfficeHome, and DomainNet show state-of-the-art performance, proving TDCRL effectiveness in SFDG.",
      "authors": [
        "Lihua Zhou",
        "Mao Ye",
        "Nianxin Li",
        "Shuaifeng Li",
        "Jinlin Wu",
        "Xiatian Zhu",
        "Lei Deng",
        "Hongbin Liu",
        "Jiebo Luo",
        "Zhen Lei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:20:42+00:00",
          "link": "https://arxiv.org/abs/2507.09961v1",
          "size": "737kb",
          "version": "v1"
        }
      ],
      "title": "Text-Driven Causal Representation Learning for Source-Free Domain Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09961",
        "HTML": "https://arxiv.org/html/2507.09961v1",
        "PDF": "https://arxiv.org/pdf/2507.09961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on domain generalization using text-driven causal representation learning, without focusing on processing or engineering training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10266",
      "abstract": "In 1977, Borodin and Kostochka conjectured that every graph with maximum degree $\\Delta \\geq 9$ is $(\\Delta-1)$-colourable, unless it contains a clique of size $\\Delta$. In 1999, Reed confirmed the conjecture when $\\Delta\\geq 10^{14}$.\n  We propose different generalisations of this conjecture for digraphs, and prove the analogue of Reed's result for each of them. The chromatic number and clique number are replaced respectively by the dichromatic number and the biclique number of digraphs. If $D$ is a digraph such that $\\min(\\tilde{\\Delta}(D),\\Delta^+(D)) = \\Delta \\geq 9$, we conjecture that $D$ has dichromatic number at most $\\Delta-1$, unless either (i) $D$ contains a biclique of size $\\Delta$, or (ii) $D$ contains a biclique $K$ of size $\\Delta-2$, a directed $3$-cycle $\\vec{C_3}$ disjoint from $K$, and all possible arcs in both directions between $\\vec{C_3}$ and $K$. If true, this implies the conjecture of Borodin and Kostochka. We prove it when $\\Delta$ is large enough, thereby generalising the result of Reed.\n  We finally give a sufficient condition for a digraph $D$ to have dichromatic number at most $\\Delta_{\\min}(D)-1$, assuming that $\\Delta_{\\min}(D)$ is large enough. In particular, this holds when the underlying graph of $D$ has no clique of size $\\Delta_{\\min}(D)$, thus yielding a third independent generalisation of Reed's result. We further give a hardness result witnessing that our sufficient condition is best possible.\n  To obtain these new upper bounds on the dichromatic number, we prove a dense decomposition lemma for digraphs having large maximum degree, which generalises to the directed setting the so-called dense decomposition of graphs due to Molloy and Reed. We believe this may be of independent interest, especially as a tool in various applications.",
      "authors": [
        "Ararat Harutyunyan",
        "Ken-ichi Kawarabayashi",
        "Lucas Picasarri-Arrieta",
        "Gil Puig i Surroca"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:37:44+00:00",
          "link": "https://arxiv.org/abs/2507.10266v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "$(\\Delta-1)$-dicolouring of digraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10266",
        "HTML": "https://arxiv.org/html/2507.10266v1",
        "PDF": "https://arxiv.org/pdf/2507.10266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses coloring and decomposing digraphs, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.17827",
      "abstract": "We introduce a convergent hierarchy of lower bounds on the minimum value of a real form over the unit sphere. The main practical advantage of our hierarchy over the real sum-of-squares (RSOS) hierarchy is that the lower bound at each level of our hierarchy is obtained by a minimum eigenvalue computation, as opposed to the full semidefinite program (SDP) required at each level of RSOS. In practice, this allows us to compute bounds on much larger forms than are computationally feasible for RSOS. Our hierarchy outperforms previous alternatives to RSOS, both asymptotically and in numerical experiments. We obtain our hierarchy by proving a reduction from real optimization on the sphere to Hermitian optimization on the sphere, and invoking the Hermitian sum-of-squares (HSOS) hierarchy. This opens the door to using other Hermitian optimization techniques for real optimization, and gives a path towards developing spectral hierarchies for more general constrained real optimization problems. To this end, we use our techniques to develop a hierarchy of eigencomputations for computing the real tensor spectral norm.",
      "authors": [
        "Benjamin Lovitz",
        "Nathaniel Johnston"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Data Structures and Algorithms (cs.DS)",
        "Algebraic Geometry (math.AG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-27T00:28:12+00:00",
          "link": "https://arxiv.org/abs/2310.17827v1",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "2024-11-16T18:01:30+00:00",
          "link": "https://arxiv.org/abs/2310.17827v2",
          "size": "88kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T23:22:49+00:00",
          "link": "https://arxiv.org/abs/2310.17827v3",
          "size": "95kb",
          "version": "v3"
        }
      ],
      "title": "A hierarchy of eigencomputations for polynomial optimization on the sphere",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.17827",
        "HTML": "https://arxiv.org/html/2310.17827v3",
        "PDF": "https://arxiv.org/pdf/2310.17827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on polynomial optimization and eigencomputations, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.17196",
      "abstract": "In text classification, creating an adversarial example means subtly perturbing a few words in a sentence without changing its meaning, causing it to be misclassified by a classifier. A concerning observation is that a significant portion of adversarial examples generated by existing methods change only one word. This single-word perturbation vulnerability represents a significant weakness in classifiers, which malicious users can exploit to efficiently create a multitude of adversarial examples. This paper studies this problem and makes the following key contributions: (1) We introduce a novel metric $\\rho$ to quantitatively assess a classifier's robustness against single-word perturbation. (2) We present the SP-Attack, designed to exploit the single-word perturbation vulnerability, achieving a higher attack success rate, better preserving sentence meaning, while reducing computation costs compared to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims to improve \\r{ho} by applying data augmentation in learning. Experimental results on 4 datasets and BERT and distilBERT classifiers show that SP-Defense improves $\\rho$ by 14.6% and 13.9% and decreases the attack success rate of SP-Attack by 30.4% and 21.2% on two classifiers respectively, and decreases the attack success rate of existing attack methods that involve multiple-word perturbations.",
      "authors": [
        "Lei Xu",
        "Sarah Alnegheimish",
        "Laure Berti-Equille",
        "Alfredo Cuesta-Infante",
        "Kalyan Veeramachaneni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-30T17:30:44+00:00",
          "link": "https://arxiv.org/abs/2401.17196v1",
          "size": "1328kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:02:09+00:00",
          "link": "https://arxiv.org/abs/2401.17196v2",
          "size": "1025kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T20:35:26+00:00",
          "link": "https://arxiv.org/abs/2401.17196v3",
          "size": "1025kb",
          "version": "v3"
        }
      ],
      "title": "Single Word Change is All You Need: Using LLMs to Create Synthetic Training Examples for Text Classifiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.17196",
        "HTML": "https://arxiv.org/html/2401.17196v3",
        "PDF": "https://arxiv.org/pdf/2401.17196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on generating synthetic training examples using LLMs for text classifiers, which directly pertains to processing training data."
      },
      "tasks": [
        "All",
        "Data Augmentation",
        "Sentence",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.13105",
      "abstract": "We study the Service Rate Region (SRR) of Reed-Muller (RM) codes in the context of distributed storage systems. The SRR is a convex polytope comprising all achievable data access request rates under a given coding scheme. It represents a critical metric for evaluating system efficiency and scalability. Using the geometric properties of RM codes, we characterize recovery sets for data objects, including their existence, uniqueness, and enumeration. This analysis reveals a connection between recovery sets and minimum-weight codewords in the dual RM code, providing a framework for identifying small recovery sets. Using these results, we derive explicit and tight bounds for the maximal achievable demand for individual data objects, which define the maximal simplex within the service rate region.",
      "authors": [
        "Hoang Ly",
        "Emina Soljanin",
        "V. Lalitha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T18:59:14+00:00",
          "link": "https://arxiv.org/abs/2501.13105v1",
          "size": "376kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T17:54:43+00:00",
          "link": "https://arxiv.org/abs/2501.13105v2",
          "size": "376kb",
          "version": "v2"
        },
        {
          "date": "2025-02-06T18:05:39+00:00",
          "link": "https://arxiv.org/abs/2501.13105v3",
          "size": "368kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T14:22:55+00:00",
          "link": "https://arxiv.org/abs/2501.13105v4",
          "size": "40kb",
          "version": "v4"
        }
      ],
      "title": "On the Service Rate Region of Reed-Muller Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13105",
        "HTML": "https://arxiv.org/html/2501.13105v4",
        "PDF": "https://arxiv.org/pdf/2501.13105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the service rate region of Reed-Muller codes in distributed storage systems, which does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.01297",
      "abstract": "Efficient inference is critical for deploying deep learning models on edge AI devices. Low-bit quantization (e.g., 3- and 4-bit) with fixed-point arithmetic improves efficiency, while low-power memory technologies like analog nonvolatile memory enable further gains. However, these methods introduce non-ideal hardware behavior, including bit faults and device-to-device variability. We propose a regularization-based quantization-aware training (QAT) framework that supports fixed, learnable step-size, and learnable non-uniform quantization, achieving competitive results on CIFAR-10 and ImageNet. Our method also extends to Spiking Neural Networks (SNNs), demonstrating strong performance on 4-bit networks on CIFAR10-DVS and N-Caltech 101. Beyond quantization, our framework enables fault and variability-aware fine-tuning, mitigating stuck-at faults (fixed weight bits) and device resistance variability. Compared to prior fault-aware training, our approach significantly improves performance recovery under upto 20% bit-fault rate and 40% device-to-device variability. Our results establish a generalizable framework for quantization and robustness-aware training, enhancing efficiency and reliability in low-power, non-ideal hardware.",
      "authors": [
        "Anmol Biswas",
        "Raghav Singhal",
        "Sivakumar Elangovan",
        "Shreyas Sabnis",
        "Udayan Ganguly"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T08:33:35+00:00",
          "link": "https://arxiv.org/abs/2503.01297v1",
          "size": "5247kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T08:03:39+00:00",
          "link": "https://arxiv.org/abs/2503.01297v2",
          "size": "5248kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T06:32:06+00:00",
          "link": "https://arxiv.org/abs/2503.01297v3",
          "size": "3659kb",
          "version": "v3"
        }
      ],
      "title": "Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01297",
        "HTML": "https://arxiv.org/html/2503.01297v3",
        "PDF": "https://arxiv.org/pdf/2503.01297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a regularization-based quantization-aware training framework for efficient inference in non-ideal hardware, not on processing or creating LLM training data."
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08830",
      "abstract": "We introduce Multiplicative Modular Nim (MuM), a variant of Nim in which the traditional nim-sum is replaced by heap-size multiplication modulo m. We establish a complete theory for this game, beginning with a direct, Bouton-style analysis for prime moduli. Our central result is an analogue of the Sprague-Grundy theorem, where we define a game-theoretic value, the mumber, for each position via a multiplicative mex recursion. We prove that these mumbers are equivalent to the heap-product modulo m, and show that for disjunctive sums of games, they combine via modular multiplication in contrast to the XOR-sum of classical nimbers. For composite moduli, we show that MuM decomposes via the Chinese Remainder Theorem into independent subgames corresponding to its prime-power factors. We extend the game to finite fields F(pn), motivated by the pedagogical need to make the algebra of the AES S-box more accessible. We demonstrate that a sound game in this domain requires a Canonical Heap Model to resolve the many-to-one mapping from integer heaps to field elements. To our knowledge, this is the first systematic analysis of a multiplicative modular variant of Nim and its extension into a complete, non-additive combinatorial game algebra.",
      "authors": [
        "Satyam Tyagi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T13:48:32+00:00",
          "link": "https://arxiv.org/abs/2507.08830v1",
          "size": "763kb",
          "version": "v1"
        }
      ],
      "title": "Multiplicative Modular Nim (MuM)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08830",
        "HTML": "https://arxiv.org/html/2507.08830v1",
        "PDF": "https://arxiv.org/pdf/2507.08830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is entirely about game theory, namely a Nim variant, and does not discuss LLM training data processing or any related data tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09011",
      "abstract": "A rapidly alternating red and black display known as Ganzflicker induces visual hallucinations that reflect the generative capacity of the visual system. Recent proposals regarding the imagery spectrum, that is, differences in the visual system of individuals with absent imagery, typical imagery, and vivid imagery, suggest these differences should impact the complexity of other internally generated visual experiences. Here, we used tools from natural language processing to analyze free-text descriptions of hallucinations from over 4,000 participants, asking whether people with different imagery phenotypes see different things in their mind's eye during Ganzflicker-induced hallucinations. Strong imagers described complex, naturalistic content, while weak imagers reported simple geometric patterns. Embeddings from vision language models better captured these differences than text-only language models, and participants with stronger imagery used language with richer sensorimotor associations. These findings may reflect individual variation in coordination between early visual areas and higher-order regions relevant for the imagery spectrum.",
      "authors": [
        "Ana Chkhaidze",
        "Reshanne R. Reeder",
        "Connor Gag",
        "Anastasia Kiyonaga",
        "Seana Coulson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Neurons and Cognition (q-bio.NC)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:30:29+00:00",
          "link": "https://arxiv.org/abs/2507.09011v1",
          "size": "6396kb",
          "version": "v1"
        }
      ],
      "title": "Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09011",
        "PDF": "https://arxiv.org/pdf/2507.09011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses visual hallucinations and individual differences in visual imagery, utilizing NLP tools for analysis but not focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09084",
      "abstract": "Flight delays are a significant challenge in the aviation industry, causing major financial and operational disruptions. To improve passenger experience and reduce revenue loss, flight delay prediction models must be both precise and generalizable across different networks. This paper introduces a novel approach that combines Queue-Theory with a simple attention model, referred to as the Queue-Theory SimAM (QT-SimAM). To validate our model, we used data from the US Bureau of Transportation Statistics, where our proposed QT-SimAM (Bidirectional) model outperformed existing methods with an accuracy of 0.927 and an F1 score of 0.932. To assess transferability, we tested the model on the EUROCONTROL dataset. The results demonstrated strong performance, achieving an accuracy of 0.826 and an F1 score of 0.791. Ultimately, this paper outlines an effective, end-to-end methodology for predicting flight delays. The proposed model's ability to forecast delays with high accuracy across different networks can help reduce passenger anxiety and improve operational decision-making",
      "authors": [
        "Nnamdi Daniel Aghanya",
        "Ta Duong Vu",
        "Ama\\\"elle Diop",
        "Charlotte Deville",
        "Nour Imane Kerroumi",
        "Irene Moulitsas",
        "Jun Li",
        "Desmond Bisandu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:02:40+00:00",
          "link": "https://arxiv.org/abs/2507.09084v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "Queue up for takeoff: a transferable deep learning framework for flight delay prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09084",
        "HTML": "https://arxiv.org/html/2507.09084v1",
        "PDF": "https://arxiv.org/pdf/2507.09084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a flight delay prediction model and does not discuss any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09204",
      "abstract": "Research on environmental risk modeling relies on numerous indicators to quantify the magnitude and frequency of extreme climate events, their ecological, economic, and social impacts, and the coping mechanisms that can reduce or mitigate their adverse effects. Index-based approaches significantly simplify the process of quantifying, comparing, and monitoring risks associated with other natural hazards, as a large set of indicators can be condensed into a few key performance indicators. Data fusion techniques are often used in conjunction with expert opinions to develop key performance indicators. This paper discusses alternative methods to combine data from multiple indicators, with an emphasis on their use-case scenarios, underlying assumptions, data requirements, advantages, and limitations. The paper demonstrates the application of these data fusion methods through examples from current risk and resilience models and simplified datasets. Simulations are conducted to identify their strengths and weaknesses under various scenarios. Finally, a real-life example illustrates how these data fusion techniques can be applied to inform policy recommendations in the context of drought resilience and sustainability.",
      "authors": [
        "Abdullah Konak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:53:52+00:00",
          "link": "https://arxiv.org/abs/2507.09204v1",
          "size": "378kb",
          "version": "v1"
        }
      ],
      "title": "Data Fusion and Aggregation Methods to Develop Composite Indexes for a Sustainable Future",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09204",
        "PDF": "https://arxiv.org/pdf/2507.09204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses data fusion techniques to develop composite indexes, which involves data processing but is not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09619",
      "abstract": "Anomaly inspection plays a vital role in industrial manufacturing, but the scarcity of anomaly samples significantly limits the effectiveness of existing methods in tasks such as localization and classification. While several anomaly synthesis approaches have been introduced for data augmentation, they often struggle with low realism, inaccurate mask alignment, and poor generalization. To overcome these limitations, we propose Generate Aligned Anomaly (GAA), a region-guided, few-shot anomaly image-mask pair generation framework. GAA leverages the strong priors of a pretrained latent diffusion model to generate realistic, diverse, and semantically aligned anomalies using only a small number of samples. The framework first employs Localized Concept Decomposition to jointly model the semantic features and spatial information of anomalies, enabling flexible control over the type and location of anomalies. It then utilizes Adaptive Multi-Round Anomaly Clustering to perform fine-grained semantic clustering of anomaly concepts, thereby enhancing the consistency of anomaly representations. Subsequently, a region-guided mask generation strategy ensures precise alignment between anomalies and their corresponding masks, while a low-quality sample filtering module is introduced to further improve the overall quality of the generated samples. Extensive experiments on the MVTec AD and LOCO datasets demonstrate that GAA achieves superior performance in both anomaly synthesis quality and downstream tasks such as localization and classification.",
      "authors": [
        "Yilin Lu",
        "Jianghang Lin",
        "Linhuang Xie",
        "Kai Zhao",
        "Yansong Qu",
        "Shengchuan Zhang",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:56:59+00:00",
          "link": "https://arxiv.org/abs/2507.09619v1",
          "size": "33272kb",
          "version": "v1"
        }
      ],
      "title": "Generate Aligned Anomaly: Region-Guided Few-Shot Anomaly Image-Mask Pair Synthesis for Industrial Inspection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09619",
        "HTML": "https://arxiv.org/html/2507.09619v1",
        "PDF": "https://arxiv.org/pdf/2507.09619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a framework (GAA) for anomaly image-mask pair generation with detailed data processing steps such as Localized Concept Decomposition and anomaly clustering, contributing to data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10125",
      "abstract": "In the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a (multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost $k$-edge-connected spanning subgraph of $G$. The problem admits a $2$-approximation algorithm and no better approximation ratio is known.Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria $(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected spanning subgraph of cost at most the optimal value of a standard Cut-LP for $k$-ECSS. This LP bicriteria approximation was recently improved by Cohen and Nutov [ESA 25] to $(1,k-4)$, where also was given a bicriteria approximation $(3/2,k-2)$. In this paper we improve the bicriteria approximation to $(1,k-2)$ for $k$ even and to $\\left(1-\\frac{1}{k},k-3\\right)$ for $k$ is odd, and also give another bicriteria approximation $(3/2,k-1)$.\n  The $k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost the same as $k$-ECSS, except that any edge can be selected multiple times at the same cost. The previous best approximation ratio for $k$-ECSM was $1+4/k$. Our result improves this to $1+\\frac{2}{k}$ for $k$ even and to $1+\\frac{3}{k}$ for $k$ odd, where for $k$ odd the computed subgraph is in fact $(k+1)$-edge-connected.",
      "authors": [
        "Zeev Nutov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:10:10+00:00",
          "link": "https://arxiv.org/abs/2507.10125v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "Improved bicriteria approximation for $k$-edge-connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10125",
        "HTML": "https://arxiv.org/html/2507.10125v1",
        "PDF": "https://arxiv.org/pdf/2507.10125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph algorithms for connectivity problems, offering no contribution to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10209",
      "abstract": "How much does ethnicity play its part in emotional expression? Emotional expression and micro-expression research probe into understanding human psychological responses to emotional stimuli, thereby revealing substantial hidden yet authentic emotions that can be useful in the event of diagnosis and interviews. While increased attention had been provided to micro-expression analysis, the studies were done under Ekman's assumption of emotion universality, where emotional expressions are identical across cultures and social contexts. Our computational study uncovers some of the influences of ethnic background in expression analysis, leading to an argument that the emotional universality hypothesis is an overgeneralization from the perspective of manual psychological analysis. In this research, we propose to investigate the level of influence of ethnicity in a simulated micro-expression scenario. We construct a cross-cultural micro-expression database and algorithmically annotate the ethnic labels to facilitate the investigation. With the ethnically annotated dataset, we perform a prima facie study to compare mono-ethnicity and stereo-ethnicity in a controlled environment, which uncovers a certain influence of ethnic bias via an experimental way. Building on this finding, we propose a framework that integrates ethnic context into the emotional feature learning process, yielding an ethnically aware framework that recognises ethnicity differences in micro-expression recognition. For improved understanding, qualitative analyses have been done to solidify the preliminary investigation into this new realm of research. Code is publicly available at https://github.com/IcedDoggie/ICMEW2025_EthnicMER",
      "authors": [
        "Huai-Qian Khor",
        "Yante Li",
        "Xingxun Jiang",
        "Guoying Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:27:09+00:00",
          "link": "https://arxiv.org/abs/2507.10209v1",
          "size": "3186kb",
          "version": "v1"
        }
      ],
      "title": "Is Micro-expression Ethnic Leaning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10209",
        "HTML": "https://arxiv.org/html/2507.10209v1",
        "PDF": "https://arxiv.org/pdf/2507.10209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves creating a cross-cultural micro-expression database and annotating ethnic labels, which touches on data processing. However, its primary focus is on ethnic influences in emotional expression analysis rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.09394",
      "abstract": "Test-time adaptation (TTA) is crucial in maintaining performance of Vision Language Models (VLMs) when facing distribution shifts, particularly when the source data or target labels are inaccessible. Existing TTA methods predominantly leverage the output probability distribution of CLIP for feature evaluation, resulting in biases under domain shifts, which cause misclassified features due to text priors or incorrect textual associations. To address these issues, we propose \\underline{B}idirectional Prototype-Reward co-Evolution (BPRE), a novel VLMs framework with TTA that integrates feature quality assessment with prototype evolution via a synergistic feedback loop. First, the Multi-dimensional Quality-aware Reward Module (MQRM) is designed to evaluate feature quality and guide prototype refinement precisely. The continuous refinement of prototype quality via Prototype-Reward Interactive Evolution (PRIE) enhances the computation more robust. Through this bidirectional interaction, the precision of rewards and prototype evolution mutually reinforce each other, forming a self-evolving feedback cycle. Extensive experiments conducted on 15 diverse recognition datasets demonstrate that our model consistently achieves superior performance compared to other SOTA methods, and advances VLM generalization capabilities through emphasizing comprehensive feature evaluation.",
      "authors": [
        "Xiaozhen Qiao",
        "Peng Huang",
        "Jiakang Yuan",
        "Xianda Guo",
        "Bowen Ye",
        "Chaocan Xue",
        "Ye Zheng",
        "Zhe Sun",
        "Xuelong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T13:40:33+00:00",
          "link": "https://arxiv.org/abs/2503.09394v1",
          "size": "4718kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T06:36:58+00:00",
          "link": "https://arxiv.org/abs/2503.09394v2",
          "size": "7262kb",
          "version": "v2"
        }
      ],
      "title": "Bidirectional Prototype-Reward co-Evolution for Test-Time Adaptation of Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09394",
        "HTML": "https://arxiv.org/html/2503.09394v2",
        "PDF": "https://arxiv.org/pdf/2503.09394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a framework for test-time adaptation in vision-language models. It does not discuss operations related to processing or creating LLM training data."
      },
      "tasks": [
        "Test-time Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12922",
      "abstract": "We prove a novel and general result on the asymptotic behavior of stochastic processes which conform to a certain relaxed supermartingale condition. Our result provides quantitative information in the form of an explicit and effective construction of a rate of convergence for this process, both in mean and almost surely, that is moreover highly uniform in that it only depends on very few data of the surrounding objects involved in the iteration. We then apply this result to derive new quantitative versions of well-known concepts and theorems from stochastic approximation, in particular providing effective rates for a variant of the Robbins-Siegmund theorem, Dvoretzky's convergence theorem, as well as the convergence of stochastic quasi-Fej\\'er monotone sequences, the latter of which formulated in a novel and highly general metric context. We utilize the classic and widely studied Robbins-Monro procedure as a template to evaluate our quantitative results and their applicability in greater detail. We conclude by illustrating the breadth of potential further applications with a brief discussion on a variety of other well-known iterative procedures from stochastic approximation. Throughout, we isolate and discuss special cases of our results which allow for the construction of fast, and in particular linear, rates.",
      "authors": [
        "Morenikeji Neri",
        "Nicholas Pischke",
        "Thomas Powell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Logic (math.LO)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T13:11:26+00:00",
          "link": "https://arxiv.org/abs/2504.12922v1",
          "size": "41kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:34:55+00:00",
          "link": "https://arxiv.org/abs/2504.12922v2",
          "size": "41kb",
          "version": "v2"
        }
      ],
      "title": "On the asymptotic behaviour of stochastic processes, with applications to supermartingale convergence, Dvoretzky's approximation theorem, and stochastic quasi-Fej\\'er monotonicity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12922",
        "HTML": "https://arxiv.org/html/2504.12922v2",
        "PDF": "https://arxiv.org/pdf/2504.12922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on the theoretical results of stochastic processes and their convergence, without any mention of LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.09341",
      "abstract": "AI safety systems face the dual-use dilemma. It is unclear whether to answer dual-use requests, since the same query could be either harmless or harmful depending on who made it and why. To make better decisions, such systems would need to examine requests' real-world context, but currently, they lack access to this information. Instead, they sometimes end up making arbitrary choices that result in refusing legitimate queries and allowing harmful ones, which hurts both utility and safety. To address this, we propose a conceptual framework based on access controls where only verified users can access dual-use outputs. We describe the framework's components, analyse its feasibility, and explain how it addresses both over-refusals and under-refusals. While only a high-level proposal, our work takes the first step toward giving model providers more granular tools for managing dual-use content. Such tools would enable users to access more capabilities without sacrificing safety, and offer regulators new options for targeted policies.",
      "authors": [
        "Ev\\v{z}en Wybitul"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T12:38:08+00:00",
          "link": "https://arxiv.org/abs/2505.09341v1",
          "size": "167kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:09:41+00:00",
          "link": "https://arxiv.org/abs/2505.09341v2",
          "size": "323kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T06:49:24+00:00",
          "link": "https://arxiv.org/abs/2505.09341v3",
          "size": "283kb",
          "version": "v3"
        }
      ],
      "title": "Access Controls Will Solve the Dual-Use Dilemma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09341",
        "HTML": "https://arxiv.org/html/2505.09341v3",
        "PDF": "https://arxiv.org/pdf/2505.09341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a conceptual framework for AI system access controls without discussing any aspect of LLM training data processing or engineering."
      },
      "tasks": [
        "Virology"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18589",
      "abstract": "We define base-extension semantics (Bes) using atomic systems based on sequent calculus rather than natural deduction. While traditional Bes aligns naturally with intuitionistic logic due to its constructive foundations, we show that sequent calculi with multiple conclusions yield a Bes framework more suited to classical semantics. The harmony in classical sequents leads to straightforward semantic clauses derived solely from right introduction rules. This framework enables a Sandqvist-style completeness proof that extracts a sequent calculus proof from any valid semantic consequence. Moreover, we show that the inclusion or omission of atomic cut rules meaningfully affects the semantics, yet completeness holds in both cases.",
      "authors": [
        "Victor Barroso-Nascimento",
        "Ekaterina Piotrovskaya",
        "Elaine Pimentel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T08:31:24+00:00",
          "link": "https://arxiv.org/abs/2505.18589v1",
          "size": "74kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T13:30:23+00:00",
          "link": "https://arxiv.org/abs/2505.18589v2",
          "size": "35kb",
          "version": "v2"
        }
      ],
      "title": "A Sequent Calculus Perspective on Base-Extension Semantics (Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18589",
        "HTML": "https://arxiv.org/html/2505.18589v2",
        "PDF": "https://arxiv.org/pdf/2505.18589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sequent calculus and semantics in logic, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08828",
      "abstract": "This paper introduces Recurrent Expansion (RE) as a new learning paradigm that advances beyond conventional Machine Learning (ML) and Deep Learning (DL). While DL focuses on learning from static data representations, RE proposes an additional dimension: learning from the evolving behavior of models themselves. RE emphasizes multiple mappings of data through identical deep architectures and analyzes their internal representations (i.e., feature maps) in conjunction with observed performance signals such as loss. By incorporating these behavioral traces, RE enables iterative self-improvement, allowing each model version to gain insight from its predecessors. The framework is extended through Multiverse RE (MVRE), which aggregates signals from parallel model instances, and further through Heterogeneous MVRE (HMVRE), where models of varying architectures contribute diverse perspectives. A scalable and adaptive variant, Sc-HMVRE, introduces selective mechanisms and scale diversity for real-world deployment. Altogether, RE presents a shift in DL: from purely representational learning to behavior-aware, self-evolving systems. It lays the groundwork for a new class of intelligent models capable of reasoning over their own learning dynamics, offering a path toward scalable, introspective, and adaptive artificial intelligence. A simple code example to support beginners in running their own experiments is provided in Code Availability Section of this paper.",
      "authors": [
        "Tarek Berghout"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T19:26:48+00:00",
          "link": "https://arxiv.org/abs/2507.08828v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Recurrent Expansion: A Pathway Toward the Next Generation of Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08828",
        "HTML": "https://arxiv.org/html/2507.08828v1",
        "PDF": "https://arxiv.org/pdf/2507.08828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new ML paradigm, Recurrent Expansion, focusing on learning dynamics rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08956",
      "abstract": "Diffusion models have quickly become some of the most popular and powerful generative models for high-dimensional data. The key insight that enabled their development was the realization that access to the score -- the gradient of the log-density at different noise levels -- allows for sampling from data distributions by solving a reverse-time stochastic differential equation (SDE) via forward discretization, and that popular denoisers allow for unbiased estimators of this score. In this paper, we demonstrate that an alternative, backward discretization of these SDEs, using proximal maps in place of the score, leads to theoretical and practical benefits. We leverage recent results in proximal matching to learn proximal operators of the log-density and, with them, develop Proximal Diffusion Models (ProxDM). Theoretically, we prove that $\\widetilde{O}(d/\\sqrt{\\varepsilon})$ steps suffice for the resulting discretization to generate an $\\varepsilon$-accurate distribution w.r.t. the KL divergence. Empirically, we show that two variants of ProxDM achieve significantly faster convergence within just a few sampling steps compared to conventional score-matching methods.",
      "authors": [
        "Zhenghan Fang",
        "Mateo D\\'iaz",
        "Sam Buchanan",
        "Jeremias Sulam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:30:09+00:00",
          "link": "https://arxiv.org/abs/2507.08956v1",
          "size": "3140kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Scores: Proximal Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08956",
        "HTML": "https://arxiv.org/html/2507.08956v1",
        "PDF": "https://arxiv.org/pdf/2507.08956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on diffusion models and proximal operators, which does not pertain to LLM training data processing. It is more about generative models and their theoretical improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09012",
      "abstract": "Let $k\\ge 1$ be an integer. A positive integer $n$ is $k$-\\textit{gleeful} if $n$ can be represented as the sum of $k$th powers of consecutive primes. For example, $35=2^3+3^3$ is a $3$-gleeful number, and $195=5^2+7^2+11^2$ is $2$-gleeful. In this paper, we present some new results on $k$-gleeful numbers for $k>1$.\n  First, we extend previous analytical work. For given values of $x$ and $k$, we give explicit upper and lower bounds on the number of $k$-gleeful representations of integers $n\\le x$.\n  Second, we describe and analyze two new, efficient parallel algorithms, one theoretical and one practical, to generate all $k$-gleeful representations up to a bound $x$.\n  Third, we study integers that are multiply gleeful, that is, integers with more than one representation as a sum of powers of consecutive primes, including both the same or different values of $k$. We give a simple heuristic model for estimating the density of multiply-gleeful numbers, we present empirical data in support of our heuristics, and offer some new conjectures.",
      "authors": [
        "Sara Moore and Jonathan P. Sorenson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:36:49+00:00",
          "link": "https://arxiv.org/abs/2507.09012v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "Explicit Bounds and Parallel Algorithms for Counting Multiply Gleeful Numbers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09012",
        "HTML": "https://arxiv.org/html/2507.09012v1",
        "PDF": "https://arxiv.org/pdf/2507.09012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with mathematical algorithms related to $k$-gleeful numbers and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09116",
      "abstract": "Despite substantial improvements in ASR, performance tends to degrade when faced with adverse conditions such as speaker accents. Generative error correction (GER) leverages the rich linguistic knowledge and exceptional reasoning ability of LLMs, significantly outperforming typical LM methods. However, it lacks specificity in accented speech scenarios. In this study, we leverage GER to improve the accuracy of transcription predictions by addressing the two primary features of accented speech recognition. To fully leverage pronunciation information, we propose the multi-modal GER, which integrates pronunciation information from the speech modality, and the multi-granularity GER, which incorporates fine-grained phoneme-level information related to pronunciation. These two methods enable the LLM to utilize the pronunciation information of accented speech and the semantic information from word-level hypotheses for accurate transcription predictions through LoRA fine-tuning. On the one hand, we employ a three-stage training strategy to train separate multi-modal GER models for each accent to obtain mono-accent LoRA experts. By adopting our proposed HDMoLE method, which incorporates hierarchical routing and dynamic thresholds within the mixture of LoRA experts, we effectively merge multiple mono-accent LoRA experts within a single multi-modal GER to overcome the challenges posed by accent diversity. On the other hand, multi-granularity GER leverages the N-best word-level and phoneme-level hypotheses generated by the HDMoLE model to predict the final accented speech transcriptions. Experimental results on the multi-accent English dataset demonstrate the efficacy of our proposed methods. Our methods achieve a remarkable relative WER reduction of 67.35% compared to the Whisper-large-v3 baseline.",
      "authors": [
        "Bingshen Mu",
        "Kun Wei",
        "Pengcheng Guo",
        "Lei Xie"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.09116v1",
          "size": "1770kb",
          "version": "v1"
        }
      ],
      "title": "Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09116",
        "HTML": "https://arxiv.org/html/2507.09116v1",
        "PDF": "https://arxiv.org/pdf/2507.09116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on improving transcription predictions for accented speech using generative error correction and multi-modal input in LLMs. While it involves fine-tuning methods, it does not primarily address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09474",
      "abstract": "The CoNLL-2013 shared task was devoted to grammatical error correction. In this paper, we give the task definition, present the data sets, and describe the evaluation metric and scorer used in the shared task. We also give an overview of the various approaches adopted by the participating teams, and present the evaluation results.",
      "authors": [
        "Hwee Tou Ng",
        "Siew Mei Wu",
        "Yuanbin Wu",
        "Christian Hadiwinoto",
        "Joel Tetreault"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:21:05+00:00",
          "link": "https://arxiv.org/abs/2507.09474v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "The CoNLL-2013 Shared Task on Grammatical Error Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09474",
        "HTML": "https://arxiv.org/html/2507.09474v1",
        "PDF": "https://arxiv.org/pdf/2507.09474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a shared task on grammatical error correction, which involves datasets, but does not focus on creating or processing data for LLM training specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09575",
      "abstract": "Stacked intelligent metasurfaces (SIMs), which integrate multiple programmable metasurface layers, have recently emerged as a promising technology for advanced wave-domain signal processing. SIMs benefit from flexible spatial degree-of-freedom (DoF) while reducing the requirement for costly radio-frequency (RF) chains. However, current state-of-the-art SIM designs face challenges such as complex phase shift optimization and energy attenuation from multiple layers. To address these aspects, we propose incorporating meta-fibers into SIMs, with the aim of reducing the number of layers and enhancing the energy efficiency. First, we introduce a meta-fiber-connected 2-layer SIM that exhibits the same flexible signal processing capabilities as conventional multi-layer structures, and explains the operating principle. Subsequently, we formulate and solve the optimization problem of minimizing the mean square error (MSE) between the SIM channel and the desired channel matrices. Specifically, by designing the phase shifts of the meta-atoms associated with the transmitting-SIM and receiving-SIM, a non-interference system with parallel subchannels is established. In order to reduce the computational complexity, a closed-form expression for each phase shift at each iteration of an alternating optimization (AO) algorithm is proposed. We show that the proposed algorithm is applicable to conventional multi-layer SIMs. The channel capacity bound and computational complexity are analyzed to provide design insights. Finally, numerical results are illustrated, demonstrating that the proposed two-layer SIM with meta-fiber achieves over a 25% improvement in channel capacity while reducing the total number of meta-atoms by 59% as compared with a conventional seven-layer SIM.",
      "authors": [
        "Hong Niu",
        "Jiancheng An",
        "Tuo Wu",
        "Jiangong Chen",
        "Yufei Zhao",
        "Yong Liang Guan",
        "Marco Di Renzo",
        "Merouane Debbah",
        "George K. Karagiannidis",
        "H. Vincent Poor",
        "and Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:56:33+00:00",
          "link": "https://arxiv.org/abs/2507.09575v1",
          "size": "822kb",
          "version": "v1"
        }
      ],
      "title": "Introducing Meta-Fiber into Stacked Intelligent Metasurfaces for MIMO Communications: A Low-Complexity Design with only Two Layers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09575",
        "HTML": "https://arxiv.org/html/2507.09575v1",
        "PDF": "https://arxiv.org/pdf/2507.09575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces new techniques for metasurface design in communications, which does not relate to any LLM training data processing or dataset-related discussions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10210",
      "abstract": "Proper coordination is needed to guarantee the performance of wireless networks in dense deployments. Contention-based systems suffer badly in terms of latency when multiple devices compete for the same resources. Coordinated Orthogonal Frequency Division Multiple Access (Co-OFDMA) is proposed for Wi-Fi 8 to remedy this, as it enables multiple Access Points (APs) to share spectrum more efficiently. However, fine-grained resource allocation, namely within 20MHz bandwidth, is argued to be impractical due to the over-the-air scheduling overhead and complexity in terms of physical layer signaling. A wired backhaul mitigates the need for over-the-air scheduling and synchronization, and it allows for coordination even if APs are not in each others' range. Furthermore, it forms the basis for more advanced multi-AP coordination schemes like coordinated beamforming and joint transmission. In this work we demonstrate the realization of Wi-Fi 6 compliant fine-grained Co-OFDMA using a fiber backhaul, enabled by the open-source platforms openwifi and White Rabbit. We show that the performance in terms of carrier frequency offset pre-compensation and time synchronization between two APs exceeds related wireless standard requirements. Furthermore, the quality of the received constellation of the Co-OFDMA frame as reported by a wireless connectivity tester is better than individual frames sent by the APs.",
      "authors": [
        "Thijs Havinga",
        "Xianjun Jiao",
        "Wei Liu",
        "Baiheng Chen",
        "Robbe Gaeremynck and Ingrid Moerman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:28:01+00:00",
          "link": "https://arxiv.org/abs/2507.10210v1",
          "size": "14400kb",
          "version": "v1"
        }
      ],
      "title": "Fine-Grained Coordinated OFDMA With Fiber Backhaul Enabled by openwifi and White Rabbit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10210",
        "HTML": "https://arxiv.org/html/2507.10210v1",
        "PDF": "https://arxiv.org/pdf/2507.10210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses wireless network performance issues with coordinated OFDMA and fiber backhaul, not LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10244",
      "abstract": "Software developers often have to gain an understanding of a codebase. Be it programmers getting onboarded onto a team project or, for example, developers striving to grasp an external open-source library. In either case, they frequently turn to the project's documentation. However, documentation in its traditional textual form is ill-suited for this kind of high-level exploratory analysis, since it is immutable from the readers' perspective and thus forces them to follow a predefined path. We have designed an approach bringing aspects of software architecture visualization to API reference documentation. It utilizes a highly interactive node-link diagram with expressive node glyphs and flexible filtering capabilities, providing a high-level overview of the codebase as well as details on demand. To test our design, we have implemented a prototype named Helveg, capable of automatically generating diagrams of C\\# codebases. User testing of Helveg confirmed its potential, but it also revealed problems with the readability, intuitiveness, and user experience of our tool. Therefore, in this paper, which is an extended version of our VISSOFT paper with DOI 10.1109/VISSOFT64034.2024.00012, we address many of these problems through major changes to the glyph design, means of interaction, and user interface of the tool. To assess the improvements, this new version of Helveg was evaluated again with the same group of participants as the previous version.",
      "authors": [
        "Adam \\v{S}t\\v{e}p\\'anek",
        "David Ku\\v{t}\\'ak",
        "Barbora Kozl\\'ikov\\'a",
        "Jan By\\v{s}ka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:07:50+00:00",
          "link": "https://arxiv.org/abs/2507.10244v1",
          "size": "7010kb",
          "version": "v1"
        }
      ],
      "title": "Helveg: Diagrams for Software Documentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10244",
        "HTML": "https://arxiv.org/html/2507.10244v1",
        "PDF": "https://arxiv.org/pdf/2507.10244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses software documentation and visualization, which is not related to LLM training data processing or contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10492",
      "abstract": "Retinal anomaly detection plays a pivotal role in screening ocular and systemic diseases. Despite its significance, progress in the field has been hindered by the absence of a comprehensive and publicly available benchmark, which is essential for the fair evaluation and advancement of methodologies. Due to this limitation, previous anomaly detection work related to retinal images has been constrained by (1) a limited and overly simplistic set of anomaly types, (2) test sets that are nearly saturated, and (3) a lack of generalization evaluation, resulting in less convincing experimental setups. Furthermore, existing benchmarks in medical anomaly detection predominantly focus on one-class supervised approaches (training only with negative samples), overlooking the vast amounts of labeled abnormal data and unlabeled data that are commonly available in clinical practice. To bridge these gaps, we introduce a benchmark for retinal anomaly detection, which is comprehensive and systematic in terms of data and algorithm. Through categorizing and benchmarking previous methods, we find that a fully supervised approach leveraging disentangled representations of abnormalities (DRA) achieves the best performance but suffers from significant drops in performance when encountering certain unseen anomalies. Inspired by the memory bank mechanisms in one-class supervised learning, we propose NFM-DRA, which integrates DRA with a Normal Feature Memory to mitigate the performance degradation, establishing a new SOTA. The benchmark is publicly available at https://github.com/DopamineLcy/BenchReAD.",
      "authors": [
        "Chenyu Lian",
        "Hong-Yu Zhou",
        "Zhanli Hu",
        "Jing Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:13:08+00:00",
          "link": "https://arxiv.org/abs/2507.10492v1",
          "size": "913kb",
          "version": "v1"
        }
      ],
      "title": "BenchReAD: A systematic benchmark for retinal anomaly detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10492",
        "HTML": "https://arxiv.org/html/2507.10492v1",
        "PDF": "https://arxiv.org/pdf/2507.10492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for retinal anomaly detection, which pertains to medical image processing, not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08990",
      "abstract": "Let $\\mathbb{K}$ be a field, $\\mathcal{X}$ be an infinite set (of indeterminates), and $\\mathcal{G}$ be a group acting on $\\mathcal{X}$. An ideal in the polynomial ring $\\mathbb{K}[\\mathcal{X}]$ is called equivariant if it is invariant under the action of $\\mathcal{G}$. We show Gr\\\"obner bases for equivariant ideals are computable are hence the equivariant ideal membership is decidable when $\\mathcal{G}$ and $\\mathcal{X}$ satisfies the Hilbert's basis property, that is, when every equivariant ideal in $\\mathbb{K}[\\mathcal{X}]$ is finitely generated. Moreover, we give a sufficient condition for the undecidability of the equivariant ideal membership problem. This condition is satisfied by the most common examples not satisfying the Hilbert's basis property.",
      "authors": [
        "Arka Ghosh",
        "Aliaume Lopez"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Commutative Algebra (math.AC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:48:56+00:00",
          "link": "https://arxiv.org/abs/2507.08990v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Computability of Equivariant Gr\\\"obner bases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08990",
        "PDF": "https://arxiv.org/pdf/2507.08990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the computability of equivariant Gr\\\"obner bases and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09390",
      "abstract": "In this paper, we consider an approach introduced in term rewriting for the automatic detection of non-looping non-termination from patterns of rules. We adapt it to logic programming by defining a new unfolding technique that produces patterns describing possibly infinite sets of finite rewrite sequences. We present an experimental evaluation of our contributions that we implemented in our tool NTI.",
      "authors": [
        "Etienne Payet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:16:49+00:00",
          "link": "https://arxiv.org/abs/2507.09390v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Non-Termination of Logic Programs Using Patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09390",
        "HTML": "https://arxiv.org/html/2507.09390v1",
        "PDF": "https://arxiv.org/pdf/2507.09390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses logic programming and patterns for detecting non-termination, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09591",
      "abstract": "Wire-arc directed energy deposition (DED) has emerged as a promising additive manufacturing (AM) technology for large-scale structural engineering applications. However, the complex thermal dynamics inherent to the process present challenges in ensuring structural integrity and mechanical properties of fabricated thick walls and plates. While finite element method (FEM) simulations have been conventionally employed to predict thermal history during deposition, their computational demand remains prohibitively high for actual large-scale applications. Given the necessity of multiple repetitive simulations for heat management and the determination of an optimal printing strategy, FEM simulation quickly becomes entirely infeasible. Instead, advancements have been made in using trained neural networks as surrogate models for rapid prediction. However, traditional data-driven approaches necessitate large amounts of relevant and verifiable external data, during the training and validation of the neural network. Regarding large-scale wire-arc DED, none of these data sources are readily available in quantities sufficient for an accurate surrogate. The introduction of physics-informed neural networks (PINNs) has opened up an alternative simulation strategy by leveraging the existing physical knowledge of the phenomena with advanced machine learning methods. Despite their theoretical advantages, PINNs have seen limited application in the context of large-scale wire-arc DED for structural engineering. This study investigates the scalability of PINNs, focusing on efficient collocation points sampling, a critical factor controlling both the training time and model performance. Results show PINNs can reduce computational time and effort by up to 98.6%, while maintaining the desired accuracy and offering \"super-resolution\". Future directions for enhancing PINN performance in metal AM are discussed.",
      "authors": [
        "Michael Ryan",
        "Mohammad Hassan Baqershahi",
        "Hessamoddin Moshayedi",
        "and Elyas Ghafoori"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:48:18+00:00",
          "link": "https://arxiv.org/abs/2507.09591v1",
          "size": "6506kb",
          "version": "v1"
        }
      ],
      "title": "Physics-informed machine learning surrogate for scalable simulation of thermal histories during wire-arc directed energy deposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09591",
        "HTML": "https://arxiv.org/html/2507.09591v1",
        "PDF": "https://arxiv.org/pdf/2507.09591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study uses neural networks for thermal history simulation in manufacturing, not relevant to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10325",
      "abstract": "Federated learning (FL) enables decentralized model training without centralizing raw data. However, practical FL deployments often face a key realistic challenge: Clients participate intermittently in server aggregation and with unknown, possibly biased participation probabilities. Most existing convergence results either assume full-device participation, or rely on knowledge of (in fact uniform) client availability distributions -- assumptions that rarely hold in practice. In this work, we characterize the optimization problem that consistently adheres to the stochastic dynamics of the well-known \\emph{agnostic Federated Averaging (FedAvg)} algorithm under random (and variably-sized) client availability, and rigorously establish its convergence for convex, possibly nonsmooth losses, achieving a standard rate of order $\\mathcal{O}(1/\\sqrt{T})$, where $T$ denotes the aggregation horizon. Our analysis provides the first convergence guarantees for agnostic FedAvg under general, non-uniform, stochastic client participation, without knowledge of the participation distribution. We also empirically demonstrate that agnostic FedAvg in fact outperforms common (and suboptimal) weighted aggregation FedAvg variants, even with server-side knowledge of participation weights.",
      "authors": [
        "Herlock (SeyedAbolfazl) Rahimi",
        "Dionysis Kalogerias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:32:46+00:00",
          "link": "https://arxiv.org/abs/2507.10325v1",
          "size": "649kb",
          "version": "v1"
        }
      ],
      "title": "Convergence of Agnostic Federated Averaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10325",
        "HTML": "https://arxiv.org/html/2507.10325v1",
        "PDF": "https://arxiv.org/pdf/2507.10325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents convergence results in federated learning, specifically around FedAvg, but does not cover LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01041",
      "abstract": "The movement of small but finite spherical particles in a fluid can be described by the Maxey-Riley equation (MRE) if they are too large to be considered passive tracers. The MRE contains an integral \"history term\" modeling wake effects, which causes the force acting on a particle at some given time to depend on its full past trajectory. The history term causes complications in the numerical solution of the MRE and is therefore often neglected, despite both numerical and experimental evidence that its effects are generally not negligible. By numerically computing trajectories with and without the history term of a large number of particles in different flow fields, we investigate its impact on the large-scale Lagrangian dynamics of simulated particles. We show that for moderate to large Stokes numbers, ignoring the history term leads to significant differences in clustering patterns. Furthermore, we compute finite-time Lyapunov exponents and show that, even for small particles, the differences in the resulting scalar field from ignoring the BHT can be significant, in particular if the underlying flow is turbulent.",
      "authors": [
        "Julio Urizarna-Carasa and Daniel Ruprecht and Alexandra von Kameke and Kathrin Padberg-Gehle"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T07:52:20+00:00",
          "link": "https://arxiv.org/abs/2407.01041v1",
          "size": "5529kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T06:56:22+00:00",
          "link": "https://arxiv.org/abs/2407.01041v2",
          "size": "12704kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T09:50:15+00:00",
          "link": "https://arxiv.org/abs/2407.01041v3",
          "size": "13681kb",
          "version": "v3"
        }
      ],
      "title": "Relevance of the Basset history term for Lagrangian particle dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01041",
        "HTML": "https://arxiv.org/html/2407.01041",
        "PDF": "https://arxiv.org/pdf/2407.01041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the dynamics of particles in fluid and the Maxey-Riley equation. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10701",
      "abstract": "Video Individual Counting (VIC) has received increasing attention for its importance in intelligent video surveillance. Existing works are limited in two aspects, i.e., dataset and method. Previous datasets are captured with fixed or rarely moving cameras with relatively sparse individuals, restricting evaluation for a highly varying view and time in crowded scenes. Existing methods rely on localization followed by association or classification, which struggle under dense and dynamic conditions due to inaccurate localization of small targets. To address these issues, we introduce the MovingDroneCrowd Dataset, featuring videos captured by fast-moving drones in crowded scenes under diverse illuminations, shooting heights and angles. We further propose a Shared Density map-guided Network (SDNet) using a Depth-wise Cross-Frame Attention (DCFA) module to directly estimate shared density maps between consecutive frames, from which the inflow and outflow density maps are derived by subtracting the shared density maps from the global density maps. The inflow density maps across frames are summed up to obtain the number of unique pedestrians in a video. Experiments on our datasets and publicly available ones show the superiority of our method over the state of the arts in highly dynamic and complex crowded scenes. Our dataset and codes have been released publicly.",
      "authors": [
        "Yaowu Fan and Jia Wan and Tao Han and Antoni B. Chan and Andy J. Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T07:09:33+00:00",
          "link": "https://arxiv.org/abs/2503.10701v1",
          "size": "37438kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:32:14+00:00",
          "link": "https://arxiv.org/abs/2503.10701v2",
          "size": "30722kb",
          "version": "v2"
        }
      ],
      "title": "Video Individual Counting for Moving Drones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10701",
        "HTML": "https://arxiv.org/html/2503.10701v2",
        "PDF": "https://arxiv.org/pdf/2503.10701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper introduces a new dataset (MovingDroneCrowd Dataset) for video individual counting, it does not focus on processing LLM training data but rather on video processing for surveillance tasks."
      },
      "tasks": [
        "Crowd Counting",
        "Video Individual Counting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.21771",
      "abstract": "Generative models enhance neuroimaging through data augmentation, quality improvement, and rare condition studies. Despite advances in realistic synthetic MRIs, evaluations focus on texture and perception, lacking sensitivity to crucial anatomical fidelity. This study proposes a new metric, called WASABI (Wasserstein-Based Anatomical Brain Index), to assess the anatomical realism of synthetic brain MRIs. WASABI leverages \\textit{SynthSeg}, a deep learning-based brain parcellation tool, to derive volumetric measures of brain regions in each MRI and uses the multivariate Wasserstein distance to compare distributions between real and synthetic anatomies. Based on controlled experiments on two real datasets and synthetic MRIs from five generative models, WASABI demonstrates higher sensitivity in quantifying anatomical discrepancies compared to traditional image-level metrics, even when synthetic images achieve near-perfect visual quality. Our findings advocate for shifting the evaluation paradigm beyond visual inspection and conventional metrics, emphasizing anatomical fidelity as a crucial benchmark for clinically meaningful brain MRI synthesis. Our code is available at https://github.com/BahramJafrasteh/wasabi-mri.",
      "authors": [
        "Bahram Jafrasteh",
        "Wei Peng",
        "Cheng Wan",
        "Yimin Luo",
        "Ehsan Adeli",
        "Qingyu Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T16:16:14+00:00",
          "link": "https://arxiv.org/abs/2504.21771v1",
          "size": "11891kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:59:06+00:00",
          "link": "https://arxiv.org/abs/2504.21771v2",
          "size": "11891kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T16:22:56+00:00",
          "link": "https://arxiv.org/abs/2504.21771v3",
          "size": "11892kb",
          "version": "v3"
        }
      ],
      "title": "WASABI: A Metric for Evaluating Morphometric Plausibility of Synthetic Brain MRIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21771",
        "HTML": "https://arxiv.org/html/2504.21771v3",
        "PDF": "https://arxiv.org/pdf/2504.21771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a metric (WASABI) for evaluating the anatomical fidelity of synthetic brain MRIs; it does not involve LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20564",
      "abstract": "The development of high-performing, robust, and reliable speech technologies depends on large, high-quality datasets. However, African languages -- including our focus, Igbo, Hausa, and Yoruba -- remain under-represented due to insufficient data. Popular voice-enabled technologies do not support any of the 2000+ African languages, limiting accessibility for circa one billion people. While previous dataset efforts exist for the target languages, they lack the scale and diversity needed for robust speech models. To bridge this gap, we introduce the NaijaVoices dataset, a 1,800-hour speech-text dataset with 5,000+ speakers. We outline our unique data collection approach, analyze its acoustic diversity, and demonstrate its impact through finetuning experiments on automatic speech recognition, averagely achieving 75.86% (Whisper), 52.06% (MMS), and 42.33% (XLSR) WER improvements. These results highlight NaijaVoices' potential to advance multilingual speech processing for African languages.",
      "authors": [
        "Chris Emezue and NaijaVoices Community",
        "Busayo Awobade",
        "Abraham Owodunni",
        "Handel Emezue",
        "Gloria Monica Tobechukwu Emezue",
        "Nefertiti Nneoma Emezue",
        "Sewade Ogun",
        "Bunmi Akinremi",
        "David Ifeoluwa Adelani",
        "Chris Pal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T22:53:48+00:00",
          "link": "https://arxiv.org/abs/2505.20564v1",
          "size": "2010kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T20:40:58+00:00",
          "link": "https://arxiv.org/abs/2505.20564v2",
          "size": "2010kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T04:42:21+00:00",
          "link": "https://arxiv.org/abs/2505.20564v3",
          "size": "2010kb",
          "version": "v3"
        }
      ],
      "title": "The NaijaVoices Dataset: Cultivating Large-Scale, High-Quality, Culturally-Rich Speech Data for African Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20564",
        "HTML": "https://arxiv.org/html/2505.20564v3",
        "PDF": "https://arxiv.org/pdf/2505.20564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of the NaijaVoices dataset specifically addressing data collection and processing to support speech recognition in African languages, detailing a unique approach to gather large-scale high-quality data."
      },
      "datasets": [
        {
          "dataset_name": "naijavoices/naijavoices-dataset",
          "downloads": "434",
          "likes": "11",
          "link": "https://huggingface.co/datasets/naijavoices/naijavoices-dataset"
        }
      ],
      "tasks": [
        "Automatic Speech Recognition",
        "Diversity",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08862",
      "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving external data to mitigate hallucinations and outdated knowledge issues. Benefiting from the strong ability in facilitating diverse data sources and supporting faithful reasoning, knowledge graphs (KGs) have been increasingly adopted in RAG systems, giving rise to KG-based RAG (KG-RAG) methods. Though RAG systems are widely applied in various applications, recent studies have also revealed its vulnerabilities to data poisoning attacks, where malicious information injected into external knowledge sources can mislead the system into producing incorrect or harmful responses. However, these studies focus exclusively on RAG systems using unstructured textual data sources, leaving the security risks of KG-RAG largely unexplored, despite the fact that KGs present unique vulnerabilities due to their structured and editable nature. In this work, we conduct the first systematic investigation of the security issue of KG-RAG methods through data poisoning attacks. To this end, we introduce a practical, stealthy attack setting that aligns with real-world implementation. We propose an attack strategy that first identifies adversarial target answers and then inserts perturbation triples to complete misleading inference chains in the KG, increasing the likelihood that KG-RAG methods retrieve and rely on these perturbations during generation. Through extensive experiments on two benchmarks and four recent KG-RAG methods, our attack strategy demonstrates strong effectiveness in degrading KG-RAG performance, even with minimal KG perturbations. In-depth analyses are also conducted to understand the safety threats within the internal stages of KG-RAG systems and to explore the robustness of LLMs against adversarial knowledge.",
      "authors": [
        "Tianzhe Zhao",
        "Jiaoyan Chen",
        "Yanchi Ru",
        "Haiping Zhu",
        "Nan Hu",
        "Jun Liu and Qika Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:06:58+00:00",
          "link": "https://arxiv.org/abs/2507.08862v1",
          "size": "376kb",
          "version": "v1"
        }
      ],
      "title": "RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08862",
        "HTML": "https://arxiv.org/html/2507.08862v1",
        "PDF": "https://arxiv.org/pdf/2507.08862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses knowledge poisoning attacks in RAG systems, it does not address processing or creating LLM training data or datasets, focusing instead on security aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09195",
      "abstract": "In this paper, we introduce a novel framework for spatial audio understanding of first-order ambisonic (FOA) signals through a question answering (QA) paradigm, aiming to extend the scope of sound event localization and detection (SELD) towards spatial scene understanding and reasoning. First, we curate and release fine-grained spatio-temporal textual descriptions for the STARSS23 dataset using a rule-based approach, and further enhance linguistic diversity using large language model (LLM)-based rephrasing. We also introduce a QA dataset aligned with the STARSS23 scenes, covering various aspects such as event presence, localization, spatial, and temporal relationships. To increase language variety, we again leverage LLMs to generate multiple rephrasings per question. Finally, we develop a baseline spatial audio QA model that takes FOA signals and natural language questions as input and provides answers regarding various occurrences, temporal, and spatial relationships of sound events in the scene formulated as a classification task. Despite being trained solely with scene-level question answering supervision, our model achieves performance that is comparable to a fully supervised sound event localization and detection model trained with frame-level spatiotemporal annotations. The results highlight the potential of language-guided approaches for spatial audio understanding and open new directions for integrating linguistic supervision into spatial scene analysis.",
      "authors": [
        "Parthasaarathy Sudarsanam",
        "Archontis Politis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:29:09+00:00",
          "link": "https://arxiv.org/abs/2507.09195v1",
          "size": "151kb",
          "version": "v1"
        }
      ],
      "title": "Towards Spatial Audio Understanding via Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09195",
        "HTML": "https://arxiv.org/html/2507.09195v1",
        "PDF": "https://arxiv.org/pdf/2507.09195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions generating QA datasets through LLM-based rephrasing, its primary focus is on audio scene understanding, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09618",
      "abstract": "We present the first sizeable corpus of Thai speech emotion recognition, THAI-SER, containing 41 hours and 36 minutes (27,854 utterances) from 100 recordings made in different recording environments: Zoom and two studio setups. The recordings contain both scripted and improvised sessions, acted by 200 professional actors (112 females and 88 males, aged 18 to 55) and were directed by professional directors. There are five primary emotions: neutral, angry, happy, sad, and frustrated, assigned to the actors when recording utterances. The utterances are annotated with an emotional category using crowdsourcing. To control the annotation process's quality, we also design an extensive filtering and quality control scheme to ensure that the majority agreement score remains above 0.71. We evaluate our annotated corpus using two metrics: inter-annotator reliability and human recognition accuracy. Inter-annotator reliability score was calculated using Krippendorff's alpha, where our corpus, after filtering, achieved an alpha score of 0.692, higher than a recommendation of 0.667. For human recognition accuracy, our corpus scored up to 0.772 post-filtering. We also provide the results of the model trained on the corpus evaluated on both in-corpus and cross-corpus setups. The corpus is publicly available under a Creative Commons BY-SA 4.0, as well as our codes for the experiments.",
      "authors": [
        "Jilamika Wongpithayadisai",
        "Chompakorn Chaksangchaichot",
        "Soravitt Sangnark",
        "Patawee Prakrankamanant",
        "Krit Gangwanpongpun",
        "Siwa Boonpunmongkol",
        "Premmarin Milindasuta",
        "Dangkamon Na-Pombejra",
        "Sarana Nutanong",
        "Ekapol Chuangsuwanich"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:52:31+00:00",
          "link": "https://arxiv.org/abs/2507.09618v1",
          "size": "3486kb",
          "version": "v1"
        }
      ],
      "title": "THAI Speech Emotion Recognition (THAI-SER) corpus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09618",
        "HTML": "https://arxiv.org/html/2507.09618v1",
        "PDF": "https://arxiv.org/pdf/2507.09618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the creation of the THAI-SER dataset, detailing the data collection, annotation, and filtering processes to ensure high-quality data, which is essential for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09725",
      "abstract": "Ants achieve robust visual homing with minimal sensory input and only a few learning walks, inspiring biomimetic solutions for autonomous navigation. While Mushroom Body (MB) models have been used in robotic route following, they have not yet been applied to visual homing. We present the first real-world implementation of a lateralized MB architecture for visual homing onboard a compact autonomous car-like robot. We test whether the sign of the angular path integration (PI) signal can categorize panoramic views, acquired during learning walks and encoded in the MB, into \"goal on the left\" and \"goal on the right\" memory banks, enabling robust homing in natural outdoor settings. We validate this approach through four incremental experiments: (1) simulation showing attractor-like nest dynamics; (2) real-world homing after decoupled learning walks, producing nest search behavior; (3) homing after random walks using noisy PI emulated with GPS-RTK; and (4) precise stopping-at-the-goal behavior enabled by a fifth MB Output Neuron (MBON) encoding goal-views to control velocity. This mimics the accurate homing behavior of ants and functionally resembles waypoint-based position control in robotics, despite relying solely on visual input. Operating at 8 Hz on a Raspberry Pi 4 with 32x32 pixel views and a memory footprint under 9 kB, our system offers a biologically grounded, resource-efficient solution for autonomous visual homing.",
      "authors": [
        "Gabriel G. Gattaux",
        "Julien R. Serres",
        "Franck Ruffier",
        "Antoine Wystrach"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:54:01+00:00",
          "link": "https://arxiv.org/abs/2507.09725v1",
          "size": "11665kb",
          "version": "v1"
        }
      ],
      "title": "Visual Homing in Outdoor Robots Using Mushroom Body Circuits and Learning Walks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09725",
        "HTML": "https://arxiv.org/html/2507.09725v1",
        "PDF": "https://arxiv.org/pdf/2507.09725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on autonomous navigation in outdoor robots inspired by ants, not on LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10109",
      "abstract": "While recent video-to-audio (V2A) models can generate realistic background audio from visual input, they largely overlook speech, an essential part of many video soundtracks. This paper proposes a new task, video-to-soundtrack (V2ST) generation, which aims to jointly produce synchronized background audio and speech within a unified framework. To tackle V2ST, we introduce DualDub, a unified framework built on a multimodal language model that integrates a multimodal encoder, a cross-modal aligner, and dual decoding heads for simultaneous background audio and speech generation. Specifically, our proposed cross-modal aligner employs causal and non-causal attention mechanisms to improve synchronization and acoustic harmony. Besides, to handle data scarcity, we design a curriculum learning strategy that progressively builds the multimodal capability. Finally, we introduce DualBench, the first benchmark for V2ST evaluation with a carefully curated test set and comprehensive metrics. Experimental results demonstrate that DualDub achieves state-of-the-art performance, generating high-quality and well-synchronized soundtracks with both speech and background audio.",
      "authors": [
        "Wenjie Tian",
        "Xinfa Zhu",
        "Haohe Liu",
        "Zhixian Zhao",
        "Zihao Chen",
        "Chaofan Ding",
        "Xinhan Di",
        "Junjie Zheng",
        "Lei Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:50:53+00:00",
          "link": "https://arxiv.org/abs/2507.10109v1",
          "size": "1598kb",
          "version": "v1"
        }
      ],
      "title": "DualDub: Video-to-Soundtrack Generation via Joint Speech and Background Audio Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10109",
        "HTML": "https://arxiv.org/html/2507.10109v1",
        "PDF": "https://arxiv.org/pdf/2507.10109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses video-to-soundtrack generation using multimodal language models, mentioning data scarcity and curriculum learning, but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10398",
      "abstract": "Handwritten character recognition is getting popular among researchers because of its possible applications in facilitating technological search engines, social media, recommender systems, etc. The Devanagari script is one of the oldest language scripts in India that does not have proper digitization tools. With the advancement of computing and technology, the task of this research is to extract handwritten Hindi characters from an image of Devanagari script with an automated approach to save time and obsolete data. In this paper, we present a technique to recognize handwritten Devanagari characters using two deep convolutional neural network layers. This work employs a methodology that is useful to enhance the recognition rate and configures a convolutional neural network for effective Devanagari handwritten text recognition (DHTR). This approach uses the Devanagari handwritten character dataset (DHCD), an open dataset with 36 classes of Devanagari characters. Each of these classes has 1700 images for training and testing purposes. This approach obtains promising results in terms of accuracy by achieving 96.36% accuracy in testing and 99.55% in training time.",
      "authors": [
        "Diksha Mehta",
        "Prateek Mehta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:38:42+00:00",
          "link": "https://arxiv.org/abs/2507.10398v1",
          "size": "686kb",
          "version": "v1"
        }
      ],
      "title": "Devanagari Handwritten Character Recognition using Convolutional Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10398",
        "PDF": "https://arxiv.org/pdf/2507.10398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the recognition of handwritten Devanagari characters using a CNN and does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.10873",
      "abstract": "In-context learning is a promising paradigm that utilizes in-context examples as prompts for the predictions of large language models. These prompts are crucial for achieving strong performance. However, since the prompts need to be sampled from a large volume of annotated examples, finding the right prompt may result in high annotation costs. To address this challenge, this paper introduces an influence-driven selective annotation method that aims to minimize annotation costs while improving the quality of in-context examples. The essence of our method is to select a pivotal subset from a large-scale unlabeled data pool to annotate for the subsequent sampling of prompts. Specifically, a directed graph is first constructed to represent unlabeled data. Afterward, the influence of candidate unlabeled subsets is quantified with a diffusion process. A simple yet effective greedy algorithm for unlabeled data selection is lastly introduced. It iteratively selects the data if it provides a maximum marginal gain with respect to quantified influence. Compared with previous efforts on selective annotations, our influence-driven method works in an end-to-end manner, avoids an intractable explicit balance between data diversity and representativeness, and enjoys theoretical support. Experiments confirm the superiority of the proposed method on various benchmarks, achieving better performance under lower time consumption during subset selection. The project page is available at https://skzhang1.github.io/IDEAL/.",
      "authors": [
        "Shaokun Zhang",
        "Xiaobo Xia",
        "Zhaoqing Wang",
        "Ling-Hao Chen",
        "Jiale Liu",
        "Qingyun Wu",
        "Tongliang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-16T22:53:54+00:00",
          "link": "https://arxiv.org/abs/2310.10873v1",
          "size": "470kb",
          "version": "v1"
        },
        {
          "date": "2024-01-20T03:58:10+00:00",
          "link": "https://arxiv.org/abs/2310.10873v2",
          "size": "442kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T05:18:48+00:00",
          "link": "https://arxiv.org/abs/2310.10873v3",
          "size": "423kb",
          "version": "v3"
        }
      ],
      "title": "IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.10873",
        "HTML": "https://arxiv.org/html/2310.10873v3",
        "PDF": "https://arxiv.org/pdf/2310.10873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces an influence-driven selective annotation method to improve the quality of in-context examples, which is a significant contribution to LLM training data processing."
      },
      "tasks": [
        "In-Context Learning"
      ],
      "repo_urls": [
        "https://github.com/skzhang1/ideal"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.11551",
      "abstract": "Cooperative Adaptive Cruise Control (CACC) often requires human takeover for tasks such as exiting a freeway. Direct human takeover can pose significant risks, especially given the close-following strategy employed by CACC, which might cause drivers to feel unsafe and execute hard braking, potentially leading to collisions. This research aims to develop a CACC takeover controller that ensures a smooth transition from automated to human control. The proposed CACC takeover maneuver employs an indirect human-machine shared control approach, modeled as a Stackelberg competition where the machine acts as the leader and the human as the follower. The machine guides the human to respond in a manner that aligns with the machine's expectations, aiding in maintaining following stability. Additionally, the human reaction function is integrated into the machine's predictive control system, moving beyond a simple \"prediction-planning\" pipeline to enhance planning optimality. The controller has been verified to i) enable a smooth takeover maneuver of CACC; ii) ensure string stability within a specific Operational Design Domain (ODD) when human control authority is below 32.7%; iii) enhance both perceived and actual safety through machine interventions; and iv) reduce the impact on upstream traffic by up to 60%.",
      "authors": [
        "Haoran Wang",
        "Zhenning Li",
        "Arno Eichberger",
        "Jia Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-16T09:57:50+00:00",
          "link": "https://arxiv.org/abs/2407.11551v1",
          "size": "1207kb",
          "version": "v1"
        }
      ],
      "title": "Human-Machine Shared Control Approach for the Takeover of Cooperative Adaptive Cruise Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.11551",
        "PDF": "https://arxiv.org/pdf/2407.11551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is about developing a shared control approach for Cooperative Adaptive Cruise Control and does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09145",
      "abstract": "Egocentric videos provide valuable insights into human interactions with the physical world, which has sparked growing interest in the computer vision and robotics communities. A critical challenge in fully understanding the geometry and dynamics of egocentric videos is dense scene reconstruction. However, the lack of high-quality labeled datasets in this field has hindered the effectiveness of current supervised learning methods. In this work, we aim to address this issue by exploring an self-supervised dynamic scene reconstruction approach. We introduce EgoMono4D, a novel model that unifies the estimation of multiple variables necessary for Egocentric Monocular 4D reconstruction, including camera intrinsic, camera poses, and video depth, all within a fast feed-forward framework. Starting from pretrained single-frame depth and intrinsic estimation model, we extend it with camera poses estimation and align multi-frame results on large-scale unlabeled egocentric videos. We evaluate EgoMono4D in both in-domain and zero-shot generalization settings, achieving superior performance in dense pointclouds sequence reconstruction compared to all baselines. EgoMono4D represents the first attempt to apply self-supervised learning for pointclouds sequence reconstruction to the label-scarce egocentric field, enabling fast, dense, and generalizable reconstruction. The interactable visualization, code and trained models are released https://egomono4d.github.io/",
      "authors": [
        "Chengbo Yuan",
        "Geng Chen",
        "Li Yi",
        "Yang Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T02:57:11+00:00",
          "link": "https://arxiv.org/abs/2411.09145v1",
          "size": "10332kb",
          "version": "v1"
        },
        {
          "date": "2024-11-15T12:27:39+00:00",
          "link": "https://arxiv.org/abs/2411.09145v2",
          "size": "10351kb",
          "version": "v2"
        },
        {
          "date": "2025-03-16T15:05:12+00:00",
          "link": "https://arxiv.org/abs/2411.09145v3",
          "size": "10303kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T07:00:25+00:00",
          "link": "https://arxiv.org/abs/2411.09145v4",
          "size": "10304kb",
          "version": "v4"
        }
      ],
      "title": "Self-Supervised Monocular 4D Scene Reconstruction for Egocentric Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09145",
        "HTML": "https://arxiv.org/html/2411.09145v4",
        "PDF": "https://arxiv.org/pdf/2411.09145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on self-supervised learning for scene reconstruction from egocentric videos and does not address LLM training data processing or dataset creation relevant to LLMs."
      },
      "tasks": [
        "4D reconstruction",
        "Self-Supervised Learning",
        "Zero-shot Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10454",
      "abstract": "Reliable prediction of pediatric obesity can offer a valuable resource to providers, helping them engage in timely preventive interventions before the disease is established. Many efforts have been made to develop ML-based predictive models of obesity, and some studies have reported high predictive performances. However, no commonly used clinical decision support tool based on existing ML models currently exists. This study presents a novel end-to-end pipeline specifically designed for pediatric obesity prediction, which supports the entire process of data extraction, inference, and communication via an API or a user interface. While focusing only on routinely recorded data in pediatric electronic health records (EHRs), our pipeline uses a diverse expert-curated list of medical concepts to predict the 1-3 years risk of developing obesity. Furthermore, by using the Fast Healthcare Interoperability Resources (FHIR) standard in our design procedure, we specifically target facilitating low-effort integration of our pipeline with different EHR systems. In our experiments, we report the effectiveness of the predictive model as well as its alignment with the feedback from various stakeholders, including ML scientists, providers, health IT personnel, health administration representatives, and patient group representatives.",
      "authors": [
        "Hamed Fayyaz",
        "Mehak Gupta",
        "Alejandra Perez Ramirez",
        "Claudine Jurkovitz",
        "H. Timothy Bunnell",
        "Thao-Ly T. Phan",
        "Rahmatollah Beheshti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T07:25:37+00:00",
          "link": "https://arxiv.org/abs/2412.10454v1",
          "size": "1871kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:40:57+00:00",
          "link": "https://arxiv.org/abs/2412.10454v2",
          "size": "1871kb",
          "version": "v2"
        }
      ],
      "title": "An Interoperable Machine Learning Pipeline for Pediatric Obesity Risk Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10454",
        "HTML": "https://arxiv.org/html/2412.10454v2",
        "PDF": "https://arxiv.org/pdf/2412.10454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a machine learning pipeline for pediatric obesity prediction using electronic health records, not related to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/healthylaife/fhir"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.14359",
      "abstract": "Existing detectors are often trained on biased datasets, leading to the possibility of overfitting on non-causal image attributes that are spuriously correlated with real/synthetic labels. While these biased features enhance performance on the training data, they result in substantial performance degradation when applied to unbiased datasets. One common solution is to perform dataset alignment through generative reconstruction, matching the semantic content between real and synthetic images. However, we revisit this approach and show that pixel-level alignment alone is insufficient. The reconstructed images still suffer from frequency-level misalignment, which can perpetuate spurious correlations. To illustrate, we observe that reconstruction models tend to restore the high-frequency details lost in real images (possibly due to JPEG compression), inadvertently creating a frequency-level misalignment, where synthetic images appear to have richer high-frequency content than real ones. This misalignment leads to models associating high-frequency features with synthetic labels, further reinforcing biased cues. To resolve this, we propose Dual Data Alignment (DDA), which aligns both the pixel and frequency domains. Moreover, we introduce two new test sets: DDA-COCO, containing DDA-aligned synthetic images for testing detector performance on the most aligned dataset, and EvalGEN, featuring the latest generative models for assessing detectors under new generative architectures such as visual auto-regressive generators. Finally, our extensive evaluations demonstrate that a detector trained exclusively on DDA-aligned MSCOCO could improve across 8 diverse benchmarks by a non-trivial margin, showing a +7.2% on in-the-wild benchmarks, highlighting the improved generalizability of unbiased detectors.",
      "authors": [
        "Ruoxin Chen",
        "Junwei Xi",
        "Zhiyuan Yan",
        "Ke-Yue Zhang",
        "Shuang Wu",
        "Jingyi Xie",
        "Xu Chen",
        "Lei Xu",
        "Isabel Guan",
        "Taiping Yao",
        "Shouhong Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T13:42:38+00:00",
          "link": "https://arxiv.org/abs/2505.14359v1",
          "size": "36216kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T12:59:23+00:00",
          "link": "https://arxiv.org/abs/2505.14359v2",
          "size": "30841kb",
          "version": "v2"
        },
        {
          "date": "2025-05-29T13:36:34+00:00",
          "link": "https://arxiv.org/abs/2505.14359v3",
          "size": "31335kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T04:38:47+00:00",
          "link": "https://arxiv.org/abs/2505.14359v4",
          "size": "31335kb",
          "version": "v4"
        }
      ],
      "title": "Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14359",
        "HTML": "https://arxiv.org/html/2505.14359v4",
        "PDF": "https://arxiv.org/pdf/2505.14359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a method called Dual Data Alignment to improve dataset alignment for training detectors, emphasizing improvements in data quality and processing, which are directly relevant to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.22895",
      "abstract": "Time series autoregression (AR) is a classical tool for modeling auto-correlations and periodic structures in real-world systems. We revisit this model from an interpretable machine learning perspective by introducing sparse autoregression (SAR), where $\\ell_0$-norm constraints are used to isolate dominant periodicities. We formulate exact mixed-integer optimization (MIO) approaches for both stationary and non-stationary settings and introduce two scalable extensions: a decision variable pruning (DVP) strategy for temporally-varying SAR (TV-SAR), and a two-stage optimization scheme for spatially- and temporally-varying SAR (STV-SAR). These models enable scalable inference on real-world spatiotemporal datasets. We validate our framework on large-scale mobility and climate time series. On NYC ridesharing data, TV-SAR reveals interpretable daily and weekly cycles as well as long-term shifts due to COVID-19. On climate datasets, STV-SAR uncovers the evolving spatial structure of temperature and precipitation seasonality across four decades in North America and detects global sea surface temperature dynamics, including El Ni\\~no. Together, our results demonstrate the interpretability, flexibility, and scalability of sparse autoregression for periodicity quantification in complex time series.",
      "authors": [
        "Xinyu Chen",
        "Vassilis Digalakis Jr",
        "Lijun Ding",
        "Dingyi Zhuang",
        "Jinhua Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:17:11+00:00",
          "link": "https://arxiv.org/abs/2506.22895v1",
          "size": "7486kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T21:53:21+00:00",
          "link": "https://arxiv.org/abs/2506.22895v2",
          "size": "7627kb",
          "version": "v2"
        }
      ],
      "title": "Interpretable Time Series Autoregression for Periodicity Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22895",
        "HTML": "https://arxiv.org/html/2506.22895v2",
        "PDF": "https://arxiv.org/pdf/2506.22895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an autoregression model for time series analysis, which does not relate to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10088",
      "abstract": "Tabular data synthesis for supervised learning ('SL') model training is gaining popularity in industries such as healthcare, finance, and retail. Despite the progress made in tabular data generators, models trained with synthetic data often underperform compared to those trained with original data. This low SL utility of synthetic data stems from class imbalance exaggeration and SL data relationship overlooked by tabular generator. To address these challenges, we draw inspirations from techniques in emerging data-centric artificial intelligence and elucidate Pruning and ReOrdering ('PRRO'), a novel pipeline that integrates data-centric techniques into tabular data synthesis. PRRO incorporates data pruning to guide the table generator towards observations with high signal-to-noise ratio, ensuring that the class distribution of synthetic data closely matches that of the original data. Besides, PRRO employs a column reordering algorithm to align the data modeling structure of generators with that of SL models. These two modules enable PRRO to optimize SL utility of synthetic data. Empirical experiments on 22 public datasets show that synthetic data generated using PRRO enhances predictive performance compared to data generated without PRRO. Specifically, synthetic replacement of original data yields an average improvement of 26.74% and up to 871.46% improvement using PRRO, while synthetic appendant to original data results with PRRO-generated data results in an average improvement of 6.13% and up to 200.32%. Furthermore, experiments on six highly imbalanced datasets show that PRRO enables the generator to produce synthetic data with a class distribution that resembles the original data more closely, achieving a similarity improvement of 43%. Through PRRO, we foster a seamless integration of data synthesis to subsequent SL prediction, promoting quality and accessible data analysis.",
      "authors": [
        "Tung Sum Thomas Kwok and Zeyong Zhang and Chi-Hua Wang and Guang Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:15:22+00:00",
          "link": "https://arxiv.org/abs/2507.10088v1",
          "size": "527kb",
          "version": "v1"
        }
      ],
      "title": "Towards High Supervised Learning Utility Training Data Generation: Data Pruning and Column Reordering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10088",
        "HTML": "https://arxiv.org/html/2507.10088v1",
        "PDF": "https://arxiv.org/pdf/2507.10088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the PRRO pipeline which employs data pruning and column reordering to enhance synthetic tabular data quality for supervised learning, indicating a primary focus on data processing operations that improve training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10355",
      "abstract": "Textual adapter-based tuning methods have shown significant potential in transferring knowledge from pre-trained Vision-Language Models (VLMs) to downstream tasks. Existing works generally employ the deterministic textual feature adapter to refine each category textual representation. However, due to inherent factors such as different attributes and contexts, there exists significant diversity in textual descriptions for each category. Such description diversity offers rich discriminative semantic knowledge that can benefit downstream visual learning tasks. Obviously, traditional deterministic adapter model cannot adequately capture this varied semantic information. Also, it is desirable to exploit the inter-class relationships in VLM adapter. To address these issues, we propose to exploit random graph model into VLM adapter and develop a novel Vertex Random Graph Adapter (VRGAdapter). VRGAdapter first models the inherent diverse descriptions of each category and inter-class relationships of different categories simultaneously by leveraging a Vertex Random Knowledge Graph (VRKG) model. Then, it employs probabilistic message propagation on VRKG to learn context-aware distribution representation for each class node. Finally, it adopts a reparameterized sampling function to achieve textual adapter learning. Note that, VRGAdapter provides a more general adapter solution that encompasses traditional graph-based adapter as a special case. In addition, to enable more robust performance for downstream tasks, we also introduce a new Uncertainty-guided Multi-branch Fusion (UMF) scheme that dynamically integrates multiple pre-trained models for ensemble prediction. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.",
      "authors": [
        "Bo Jiang",
        "Xueyang Ze",
        "Beibei Wang",
        "Xixi Wang",
        "Xixi Wan",
        "and Bin Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:56:49+00:00",
          "link": "https://arxiv.org/abs/2507.10355v1",
          "size": "4633kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10355",
        "HTML": "https://arxiv.org/html/2507.10355v1",
        "PDF": "https://arxiv.org/pdf/2507.10355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a Vertex Random Graph Adapter for vision-language models, focusing on adapter learning and ensemble prediction rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09020",
      "abstract": "This paper explores how AI-powered tools could be leveraged to streamline the process of identifying, screening, and analyzing relevant literature in academic research. More specifically, we examine the documented relationship between environmental, social, and governance (ESG) factors and the cost of capital (CoC). By applying an AI-assisted workflow, we identified 36 published studies, synthesized their key findings, and highlighted relevant theories, moderators, and methodological challenges. Our analyses demonstrate the value of AI tools in enhancing business research processes and also contribute to the growing literature on the importance of ESG in the field of corporate finance.",
      "authors": [
        "Ebenezer Asem",
        "Ruijie Fan",
        "Gloria Y. Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:01:09+00:00",
          "link": "https://arxiv.org/abs/2507.09020v1",
          "size": "1307kb",
          "version": "v1"
        }
      ],
      "title": "ESG and the Cost of Capital: Insights from an AI-Assisted Systematic Literature Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09020",
        "PDF": "https://arxiv.org/pdf/2507.09020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of AI tools for literature review in the context of ESG and corporate finance, not in the context of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09222",
      "abstract": "Foundation models like CLIP and SAM have transformed computer vision and medical imaging via low-shot transfer learning. However, deployment of these models hindered by two key challenges: \\textit{distribution shift} between training and test data, and \\textit{confidence misalignment} that leads to overconfident incorrect predictions. These issues manifest differently in vision-language classification and medical segmentation tasks, yet existing solutions remain domain-specific. We propose \\textit{StaRFM}, a unified framework addressing both challenges. It introduces a Fisher information penalty (FIP), extended to 3D medical data via patch-wise regularization, to reduce covariate shift in CLIP and SAM embeddings. Additionally, a confidence misalignment penalty (CMP), reformulated for voxel-level predictions, calibrates uncertainty in segmentation tasks. We theoretically derive PAC-Bayes bounds showing FIP controls generalization via the Fisher-Rao norm, while CMP minimizes calibration error through Brier score optimization. StaRFM shows consistent performance like \\texttt{+}3.5\\% accuracy and 28\\% lower ECE on 19 vision datasets (e.g., ImageNet, Office-Home), 84.7\\% DSC and 4.8mm HD95 in medical segmentation (e.g., BraTS, ATLAS), and 40\\% lower cross-domain performance gap compared to prior benchmarking methods. The framework is plug-and-play, requiring minimal architectural changes for seamless integration with foundation models. Code and models will be released at https://anonymous.4open.science/r/StaRFM-C0CD/README.md",
      "authors": [
        "Behraj Khan",
        "Tahir Syed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.09222v1",
          "size": "2974kb",
          "version": "v1"
        }
      ],
      "title": "Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09222",
        "HTML": "https://arxiv.org/html/2507.09222v1",
        "PDF": "https://arxiv.org/pdf/2507.09222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving models' robustness to distribution shifts and confidence misalignments, primarily discussing model adjustments rather than any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09269",
      "abstract": "Recently, Spiking Neural Networks (SNNs) have demonstrated rich potential in computer vision domain due to their high biological plausibility, event-driven characteristic and energy-saving efficiency. Still, limited annotated event-based datasets and immature SNN architectures result in their performance inferior to that of Artificial Neural Networks (ANNs). To enhance the performance of SNNs on their optimal data format, DVS data, we explore using RGB data and well-performing ANNs to implement knowledge distillation. In this case, solving cross-modality and cross-architecture challenges is necessary. In this paper, we propose cross knowledge distillation (CKD), which not only leverages semantic similarity and sliding replacement to mitigate the cross-modality challenge, but also uses an indirect phased knowledge distillation to mitigate the cross-architecture challenge. We validated our method on main-stream neuromorphic datasets, including N-Caltech101 and CEP-DVS. The experimental results show that our method outperforms current State-of-the-Art methods. The code will be available at https://github.com/ShawnYE618/CKD",
      "authors": [
        "Shuhan Ye",
        "Yuanbin Qian",
        "Chong Wang",
        "Sunqi Lin",
        "Jiazhen Xu",
        "Jiangbo Qian",
        "and Yuqi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T12:38:39+00:00",
          "link": "https://arxiv.org/abs/2507.09269v1",
          "size": "9965kb",
          "version": "v1"
        }
      ],
      "title": "Cross Knowledge Distillation between Artificial and Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09269",
        "HTML": "https://arxiv.org/html/2507.09269v1",
        "PDF": "https://arxiv.org/pdf/2507.09269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on cross knowledge distillation between different neural network architectures (ANNs and SNNs) and does not address LLM data processing or training data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09703",
      "abstract": "We present EPT-2, the latest iteration in our Earth Physics Transformer (EPT) family of foundation AI models for Earth system forecasting. EPT-2 delivers substantial improvements over its predecessor, EPT-1.5, and sets a new state of the art in predicting energy-relevant variables-including 10m and 100m wind speed, 2m temperature, and surface solar radiation-across the full 0-240h forecast horizon. It consistently outperforms leading AI weather models such as Microsoft Aurora, as well as the operational numerical forecast system IFS HRES from the European Centre for Medium-Range Weather Forecasts (ECMWF). In parallel, we introduce a perturbation-based ensemble model of EPT-2 for probabilistic forecasting, called EPT-2e. Remarkably, EPT-2e significantly surpasses the ECMWF ENS mean-long considered the gold standard for medium- to longrange forecasting-while operating at a fraction of the computational cost. EPT models, as well as third-party forecasts, are accessible via the app.jua.ai platform.",
      "authors": [
        "Roberto Molinaro",
        "Niall Siegenheim",
        "Niels Poulsen",
        "Jordan Dane Daubinet",
        "Henry Martin",
        "Mark Frey",
        "Kevin Thiart",
        "Alexander Jakob Dautel",
        "Andreas Schlueter",
        "Alex Grigoryev",
        "Bogdan Danciu",
        "Nikoo Ekhtiari",
        "Bas Steunebrink",
        "Leonie Wagner",
        "Marvin Vincent Gabler"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:32:13+00:00",
          "link": "https://arxiv.org/abs/2507.09703v1",
          "size": "2372kb",
          "version": "v1"
        }
      ],
      "title": "EPT-2 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09703",
        "HTML": "https://arxiv.org/html/2507.09703v1",
        "PDF": "https://arxiv.org/pdf/2507.09703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an improved Earth Physics Transformer model for weather forecasting, without relevance to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.10887",
      "abstract": "This paper presents a mini-review of the current state of research in mobile manipulators with variable levels of autonomy, emphasizing their associated challenges and application environments. The need for mobile manipulators in different environments is evident due to the unique challenges and risks each presents. Many systems deployed in these environments are not fully autonomous, requiring human-robot teaming to ensure safe and reliable operations under uncertainties. Through this analysis, we identify gaps and challenges in the literature on Variable Autonomy, including cognitive workload and communication delays, and propose future directions, including whole-body Variable Autonomy for mobile manipulators, virtual reality frameworks, and large language models to reduce operators' complexity and cognitive load in some challenging and uncertain scenarios.",
      "authors": [
        "Cesar Alan Contreras",
        "Alireza Rastegarpanah",
        "Rustam Stolkin",
        "Manolis Chiou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T14:18:35+00:00",
          "link": "https://arxiv.org/abs/2408.10887v1",
          "size": "69kb",
          "version": "v1"
        }
      ],
      "title": "A Mini-Review on Mobile Manipulators with Variable Autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10887",
        "HTML": "https://arxiv.org/html/2408.10887",
        "PDF": "https://arxiv.org/pdf/2408.10887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The mini-review explores mobile manipulators with variable autonomy, focusing on their applications and challenges, without addressing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05979",
      "abstract": "Autoregressive models (ARMs) have become the workhorse for sequence generation tasks, since many problems can be modeled as next-token prediction. While there appears to be a natural ordering for text (i.e., left-to-right), for many data types, such as graphs, the canonical ordering is less obvious. To address this problem, we introduce a variant of ARM that generates high-dimensional data using a probabilistic ordering that is sequentially inferred from data. This model incorporates a trainable probability distribution, referred to as an order-policy, that dynamically decides the autoregressive order in a state-dependent manner. To train the model, we introduce a variational lower bound on the log-likelihood, which we optimize with stochastic gradient estimation. We demonstrate experimentally that our method can learn meaningful autoregressive orderings in image and graph generation. On the challenging domain of molecular graph generation, we achieve state-of-the-art results on the QM9 and ZINC250k benchmarks, evaluated across key metrics for distribution similarity and drug-likeless.",
      "authors": [
        "Zhe Wang",
        "Jiaxin Shi",
        "Nicolas Heess",
        "Arthur Gretton",
        "Michalis K. Titsias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T23:24:24+00:00",
          "link": "https://arxiv.org/abs/2503.05979v1",
          "size": "950kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T03:58:31+00:00",
          "link": "https://arxiv.org/abs/2503.05979v2",
          "size": "1009kb",
          "version": "v2"
        }
      ],
      "title": "Learning-Order Autoregressive Models with Application to Molecular Graph Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05979",
        "HTML": "https://arxiv.org/html/2503.05979v2",
        "PDF": "https://arxiv.org/pdf/2503.05979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses autoregressive models for sequence generation, with a focus on model architecture and generation order, rather than LLM training data processing."
      },
      "tasks": [
        "Graph Generation",
        "Molecular Graph Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08916",
      "abstract": "Objectives: To evaluate the current limitations of large language models (LLMs) in medical question answering, focusing on the quality of datasets used for their evaluation. Materials and Methods: Widely-used benchmark datasets, including MedQA, MedMCQA, PubMedQA, and MMLU, were reviewed for their rigor, transparency, and relevance to clinical scenarios. Alternatives, such as challenge questions in medical journals, were also analyzed to identify their potential as unbiased evaluation tools. Results: Most existing datasets lack clinical realism, transparency, and robust validation processes. Publicly available challenge questions offer some benefits but are limited by their small size, narrow scope, and exposure to LLM training. These gaps highlight the need for secure, comprehensive, and representative datasets. Conclusion: A standardized framework is critical for evaluating LLMs in medicine. Collaborative efforts among institutions and policymakers are needed to ensure datasets and methodologies are rigorous, unbiased, and reflective of clinical complexities.",
      "authors": [
        "Mahmoud Alwakeel",
        "Aditya Nagori",
        "Vijay Krishnamoorthy",
        "Rishikesan Kamaleswaran"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:09:25+00:00",
          "link": "https://arxiv.org/abs/2507.08916v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating LLMs in Medicine: A Call for Rigor, Transparency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08916",
        "PDF": "https://arxiv.org/pdf/2507.08916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper reviews the quality of datasets for evaluating LLMs in medical contexts. While it addresses dataset quality concerns, it does not focus on training-data processing methods, but rather on evaluation rigor."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09133",
      "abstract": "With the increasing complexity of cyberattacks, the proactive and forward-looking nature of threat intelligence has become more crucial for threat detection and provenance analysis. However, translating high-level attack patterns described in Tactics, Techniques, and Procedures (TTP) intelligence into actionable security policies remains a significant challenge. This challenge arises from the semantic gap between high-level threat intelligence and low-level provenance log. To address this issue, this paper introduces CLIProv, a novel approach for detecting threat behaviors in a host system. CLIProv employs a multimodal framework that leverages contrastive learning to align the semantics of provenance logs with threat intelligence, effectively correlating system intrusion activities with attack patterns. Furthermore, CLIProv formulates threat detection as a semantic search problem, identifying attack behaviors by searching for threat intelligence that is most semantically similar to the log sequence. By leveraging attack pattern information in threat intelligence, CLIProv identifies TTPs and generates complete and concise attack scenarios. Experimental evaluations on standard datasets show that CLIProv effectively identifies attack behaviors in system provenance logs, offering valuable references for potential techniques. Compared to state-of-the-art methods, CLIProv achieves higher precision and significantly improved detection efficiency.",
      "authors": [
        "Jingwen Li",
        "Ru Zhang",
        "Jianyi Liu",
        "Wanguo Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:20:00+00:00",
          "link": "https://arxiv.org/abs/2507.09133v1",
          "size": "4891kb",
          "version": "v1"
        }
      ],
      "title": "CLIProv: A Contrastive Log-to-Intelligence Multimodal Approach for Threat Detection and Provenance Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09133",
        "HTML": "https://arxiv.org/html/2507.09133v1",
        "PDF": "https://arxiv.org/pdf/2507.09133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for threat detection and provenance analysis using contrastive learning, but does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09226",
      "abstract": "Neural speaker diarization is widely used for overlap-aware speaker diarization, but it requires large multi-speaker datasets for training. To meet this data requirement, large datasets are often constructed by combining multiple corpora, including those originally designed for multi-speaker automatic speech recognition (ASR). However, ASR datasets often feature loosely defined segment boundaries that do not align with the stricter conventions of diarization benchmarks. In this work, we show that such boundary looseness significantly impacts the diarization error rate, reducing evaluation reliability. We also reveal that models trained on data with varying boundary precision tend to learn dataset-specific looseness, leading to poor generalization across out-of-domain datasets. Training with standardized tight boundaries via forced alignment improves not only diarization performance, especially in streaming scenarios, but also ASR performance when combined with simple post-processing.",
      "authors": [
        "Shota Horiguchi",
        "Naohiro Tawara",
        "Takanori Ashihara",
        "Atsushi Ando",
        "Marc Delcroix"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:50:30+00:00",
          "link": "https://arxiv.org/abs/2507.09226v1",
          "size": "508kb",
          "version": "v1"
        }
      ],
      "title": "Can We Really Repurpose Multi-Speaker ASR Corpus for Speaker Diarization?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09226",
        "HTML": "https://arxiv.org/html/2507.09226v1",
        "PDF": "https://arxiv.org/pdf/2507.09226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper addresses the challenge of repurposing ASR datasets for speaker diarization by standardizing segment boundaries through forced alignment, significantly impacting training data quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09389",
      "abstract": "Explainability and interpretability are cornerstones of frontier and next-generation artificial intelligence (AI) systems. This is especially true in recent systems, such as large language models (LLMs), and more broadly, generative AI. On the other hand, adaptability to new domains, contexts, or scenarios is also an important aspect for a successful system. As such, we are particularly interested in how we can merge these two efforts, that is, investigating the design of transferable and interpretable neurosymbolic AI systems. Specifically, we focus on a class of systems referred to as ''Agentic Retrieval-Augmented Generation'' systems, which actively select, interpret, and query knowledge sources in response to natural language prompts. In this paper, we systematically evaluate how different conceptualizations and representations of knowledge, particularly the structure and complexity, impact an AI agent (in this case, an LLM) in effectively querying a triplestore. We report our results, which show that there are impacts from both approaches, and we discuss their impact and implications.",
      "authors": [
        "Chris Davis Jaldi",
        "Anmol Saini",
        "Elham Ghiasi",
        "O. Divine Eziolise",
        "and Cogan Shimizu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:10:26+00:00",
          "link": "https://arxiv.org/abs/2507.09389v1",
          "size": "910kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Conceptualization Impacts RAG Efficacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09389",
        "HTML": "https://arxiv.org/html/2507.09389v1",
        "PDF": "https://arxiv.org/pdf/2507.09389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates knowledge representations that may impact an LLM's querying capability, but it does not focus on processing training data for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21469",
      "abstract": "The turning movement count data is crucial for traffic signal design, intersection geometry planning, traffic flow, and congestion analysis. This work proposes three methods called dynamic, static, and hybrid configuration for TMC-based traffic signals. A vision-based tracking system is developed to estimate the TMC of six intersections in Las Vegas using traffic cameras. The intersection design, route (e.g. vehicle movement directions), and signal configuration files with compatible formats are synthesized and imported into Simulation of Urban MObility for signal evaluation with realistic data. The initial experimental results based on estimated waiting times indicate that the cycle time of 90 and 120 seconds works best for all intersections. In addition, four intersections show better performance for dynamic signal timing configuration, and the other two with lower performance have a lower ratio of total vehicle count to total lanes of the intersection leg. Since daily traffic flow often exhibits a bimodal pattern, we propose a hybrid signal method that switches between dynamic and static methods, adapting to peak and off-peak traffic conditions for improved flow management. So, a built-in traffic generator module creates vehicle routes for 4 hours, including peak hours, and a signal design module produces signal schedule cycles according to static, dynamic, and hybrid methods. Vehicle count distributions are weighted differently for each zone (i.e., West, North, East, South) to generate diverse traffic patterns. The extended experimental results for 6 intersections with 4 hours of simulation time imply that zone-based traffic pattern distributions affect signal design selection. Although the static method works great for evenly zone-based traffic distribution, the hybrid method works well for highly weighted traffic at intersection pairs of the West-East and North-South zones.",
      "authors": [
        "Mohammad Shokrolah Shirazi",
        "Hung-Fu Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:56:59+00:00",
          "link": "https://arxiv.org/abs/2506.21469v1",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of Traffic Signals for Daily Traffic Pattern",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21469",
        "HTML": "https://arxiv.org/html/2506.21469",
        "PDF": "https://arxiv.org/pdf/2506.21469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes methods for traffic signal evaluation but does not cover any LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07140",
      "abstract": "Merging parameter-efficient task experts has recently gained growing attention as a way to build modular architectures that can be rapidly adapted on the fly for specific downstream tasks, without requiring additional fine-tuning. Typically, LoRA serves as the foundational building block of such parameter-efficient modular architectures, leveraging low-rank weight structures to reduce the number of trainable parameters. In this paper, we study the properties of sparse adapters, which train only a subset of weights in the base neural network, as potential building blocks of modular architectures. First, we propose a simple method for training highly effective sparse adapters, which is conceptually simpler than existing methods in the literature and surprisingly outperforms both LoRA and full fine-tuning in our setting. Next, we investigate the merging properties of these sparse adapters by merging adapters for up to 20 natural language processing tasks, thus scaling beyond what is usually studied in the literature. Our findings demonstrate that sparse adapters yield superior in-distribution performance post-merging compared to LoRA or full model merging. Achieving strong held-out performance remains a challenge for all methods considered.",
      "authors": [
        "Samin Yeasar Arnob",
        "Zhan Su",
        "Minseon Kim",
        "Oleksiy Ostapenko",
        "Riyasat Ohib",
        "Esra'a Saleh",
        "Doina Precup",
        "Lucas Caccia",
        "Alessandro Sordoni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.07140v1",
          "size": "811kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:57:05+00:00",
          "link": "https://arxiv.org/abs/2507.07140v2",
          "size": "811kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07140",
        "HTML": "https://arxiv.org/html/2507.07140v2",
        "PDF": "https://arxiv.org/pdf/2507.07140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study focuses on sparse adapters and modular architectures, with no significant emphasis on LLM training data processing or the creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09798",
      "abstract": "Google's congestion control (GCC) has become a cornerstone for real-time video and audio communication, yet its performance remains fragile in emerging Low Earth Orbit (LEO) networks. Sparse direct-to-device constellations offer longer duration links and reduced handover frequency compared to dense deployments, presenting a unique opportunity for high-quality real-time communication (RTC) in environments with limited terrestrial network infrastructure. In this paper, we study the behavior of videoconferencing systems in sparse LEO constellations. We observe that video quality degrades due to inherent delays and network instability introduced by the high altitude and rapid movement of LEO satellites, with these effects exacerbated by WebRTC's conventional ``one-size-fits-all'' sender-side pacing queue management. To boost RTC performance, we introduce a data-driven queue management mechanism that adapts the maximum pacing queue capacity based on predicted handover activity. Specifically, our approach employs shorter queue limits during stable, no-handover phases to prioritize low latency communication, and preemptively increases pacing queue capacity when entering periods of increased handover activity to absorb disruptions. Our method yields up to $3$x improvements in video bitrate and reduces freeze rate by $62\\%$ compared to default WebRTC.",
      "authors": [
        "Aashish Gottipati and Lili Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:25:43+00:00",
          "link": "https://arxiv.org/abs/2507.09798v1",
          "size": "1439kb",
          "version": "v1"
        }
      ],
      "title": "Towards Robust RTC in Sparse LEO Constellations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09798",
        "HTML": "https://arxiv.org/html/2507.09798v1",
        "PDF": "https://arxiv.org/pdf/2507.09798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving real-time communication performance in sparse LEO constellations using a data-driven queue management mechanism, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10000",
      "abstract": "Since Searle's work deconstructing intent and intentionality in the realm of philosophy, the practical meaning of intent has received little attention in science and technology. Intentionality and context are both central to the scope of Promise Theory's model of Semantic Spacetime, used as an effective Tiny Language Model. One can identify themes and concepts from a text, on a low level (without knowledge of the specific language) by using process coherence as a guide. Any agent process can assess superficially a degree of latent `intentionality' in data by looking for anomalous multi-scale anomalies and assessing the work done to form them. Scale separation can be used to sort parts into `intended' content and `ambient context', using the spacetime coherence as a measure. This offers an elementary but pragmatic interpretation of latent intentionality for very low computational cost, and without reference to extensive training or reasoning capabilities. The process is well within the reach of basic organisms as it does not require large scale artificial probabilistic batch processing. The level of concept formation depends, however, on the memory capacity of the agent.",
      "authors": [
        "Mark Burgess"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:34:58+00:00",
          "link": "https://arxiv.org/abs/2507.10000v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10000",
        "HTML": "https://arxiv.org/html/2507.10000v1",
        "PDF": "https://arxiv.org/pdf/2507.10000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing scene context and intentionality using a Tiny Language Model, without emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10120",
      "abstract": "In this paper, we study a second-order approach to policy optimization in reinforcement learning. Existing second-order methods often suffer from suboptimal sample complexity or rely on unrealistic assumptions about importance sampling. To overcome these limitations, we propose VR-CR-PN, a variance-reduced cubic-regularized policy Newton algorithm. To the best of our knowledge, this is the first algorithm that integrates Hessian-aided variance reduction with second-order policy optimization, effectively addressing the distribution shift problem and achieving best-known sample complexity under general nonconvex conditions but without the need for importance sampling. We theoretically establish that VR-CR-PN achieves a sample complexity of $\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ to reach an $\\epsilon$-second-order stationary point, significantly improving upon the previous best result of $\\tilde{\\mathcal{O}}(\\epsilon^{-3.5})$ under comparable assumptions. As an additional contribution, we introduce a novel Hessian estimator for the expected return function, which admits a uniform upper bound independent of the horizon length $H$, allowing the algorithm to achieve horizon-independent sample complexity.",
      "authors": [
        "Cheng Sun and Zhen Zhang and Shaofu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:04:02+00:00",
          "link": "https://arxiv.org/abs/2507.10120v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "A Variance-Reduced Cubic-Regularized Newton for Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10120",
        "HTML": "https://arxiv.org/html/2507.10120v1",
        "PDF": "https://arxiv.org/pdf/2507.10120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an optimization algorithm for policy optimization in reinforcement learning, focusing on algorithmic improvements rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10225",
      "abstract": "Pre-trained vision-language models have exhibited remarkable abilities in detecting out-of-distribution (OOD) samples. However, some challenging OOD samples, which lie close to in-distribution (InD) data in image feature space, can still lead to misclassification. The emergence of foundation models like diffusion models and multimodal large language models (MLLMs) offers a potential solution to this issue. In this work, we propose SynOOD, a novel approach that harnesses foundation models to generate synthetic, challenging OOD data for fine-tuning CLIP models, thereby enhancing boundary-level discrimination between InD and OOD samples. Our method uses an iterative in-painting process guided by contextual prompts from MLLMs to produce nuanced, boundary-aligned OOD samples. These samples are refined through noise adjustments based on gradients from OOD scores like the energy score, effectively sampling from the InD/OOD boundary. With these carefully synthesized images, we fine-tune the CLIP image encoder and negative label features derived from the text encoder to strengthen connections between near-boundary OOD samples and a set of negative labels. Finally, SynOOD achieves state-of-the-art performance on the large-scale ImageNet benchmark, with minimal increases in parameters and runtime. Our approach significantly surpasses existing methods, improving AUROC by 2.80% and reducing FPR95 by 11.13%. Codes are available in https://github.com/Jarvisgivemeasuit/SynOOD.",
      "authors": [
        "Jinglun Li and Kaixun Jiang and Zhaoyu Chen and Bo Lin and Yao Tang and Weifeng Ge and Wenqiang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:43:50+00:00",
          "link": "https://arxiv.org/abs/2507.10225v1",
          "size": "1823kb",
          "version": "v1"
        }
      ],
      "title": "Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10225",
        "HTML": "https://arxiv.org/html/2507.10225v1",
        "PDF": "https://arxiv.org/pdf/2507.10225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel method (SynOOD) to generate synthetic OOD data for fine-tuning CLIP models, which is a direct contribution to LLM training data processing by creating a dataset with detailed data processing steps to improve boundary-level discrimination."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.14477",
      "abstract": "Aligning language models with human preferences through reinforcement learning from human feedback is crucial for their safe and effective deployment. The human preference is typically represented through comparison where one response is chosen over another for a given prompt. However, standard preference datasets often lack explicit information on why a particular choice was made, presenting an ambiguity that can hinder efficient learning and robust alignment, especially given the high cost of acquiring extensive human annotations. While many studies focus on algorithmic improvements, this work adopts a data-centric perspective, exploring how to enhance learning from existing preference data. We propose augmenting standard preference pairs with rationales that explain the reasoning behind the human preference. Specifically, we introduce a simple and principled framework that leverages machine-generated rationales to enrich preference data for preference optimization algorithms. Our comprehensive analysis demonstrates that incorporating rationales improves learning efficiency. Extensive experiments reveal some advantages: rationale-augmented learning accelerates convergence and can achieve higher final model performance. Furthermore, this approach is versatile and compatible with various direct preference optimization algorithms. Our findings showcase the potential of thoughtful data design in preference learning, demonstrating that enriching existing datasets with explanatory rationales can help unlock improvements in model alignment and annotation efficiency.",
      "authors": [
        "Hoang Anh Just",
        "Ming Jin",
        "Anit Sahu",
        "Huy Phan",
        "Ruoxi Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-19T17:27:52+00:00",
          "link": "https://arxiv.org/abs/2407.14477v1",
          "size": "3974kb",
          "version": "v1"
        },
        {
          "date": "2024-07-23T02:10:12+00:00",
          "link": "https://arxiv.org/abs/2407.14477v2",
          "size": "3974kb",
          "version": "v2"
        },
        {
          "date": "2024-08-03T17:32:08+00:00",
          "link": "https://arxiv.org/abs/2407.14477v3",
          "size": "3967kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T19:41:48+00:00",
          "link": "https://arxiv.org/abs/2407.14477v4",
          "size": "1018kb",
          "version": "v4"
        }
      ],
      "title": "Data-Centric Human Preference with Rationales for Direct Preference Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.14477",
        "HTML": "https://arxiv.org/html/2407.14477v4",
        "PDF": "https://arxiv.org/pdf/2407.14477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a framework to enrich preference datasets with machine-generated rationales, enhancing the quality and utility of existing training data. This is a direct contribution to LLM training data processing by focusing on data augmentation to improve model alignment."
      },
      "datasets": [
        {
          "dataset_name": "redsgnaoh/orcaratgen",
          "downloads": "43",
          "likes": "2",
          "link": "https://huggingface.co/datasets/redsgnaoh/orcaratgen"
        },
        {
          "dataset_name": "redsgnaoh/orcaratspec",
          "downloads": "31",
          "likes": "2",
          "link": "https://huggingface.co/datasets/redsgnaoh/orcaratspec"
        }
      ],
      "tasks": [
        "Hallucination"
      ],
      "repo_urls": [
        "https://github.com/reds-lab/preference-learning-with-rationales"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08736",
      "abstract": "We present Holoview, an augmented reality (AR) system designed to support immersive and interactive learning of human anatomy. Holoview enables users to dynamically explore volumetric anatomical data through intuitive hand gestures in a 3D AR environment, allowing inspection of individual organs and cross-sectional views via clipping and bioscope features. The system adopts a lightweight client-server architecture optimized for real-time performance on the HoloLens through hybrid and foveated rendering. Our user study demonstrated Holoview's educational effectiveness, with participants showing a 135 percent improvement in task-specific knowledge and reporting increased confidence in understanding anatomical structures. The system was perceived as engaging and intuitive, particularly for organ selection and cross-sectional exploration, with low cognitive load and increasing ease of use over time. These findings highlight Holoview's potential to enhance anatomy learning through immersive, user-centered AR experiences.",
      "authors": [
        "Anshul Goswami and Ojaswa Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T11:29:26+00:00",
          "link": "https://arxiv.org/abs/2501.08736v1",
          "size": "23617kb",
          "version": "v1"
        },
        {
          "date": "2025-01-16T02:24:48+00:00",
          "link": "https://arxiv.org/abs/2501.08736v2",
          "size": "23618kb",
          "version": "v2"
        },
        {
          "date": "2025-04-05T11:26:44+00:00",
          "link": "https://arxiv.org/abs/2501.08736v3",
          "size": "23518kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T07:35:39+00:00",
          "link": "https://arxiv.org/abs/2501.08736v4",
          "size": "35679kb",
          "version": "v4"
        }
      ],
      "title": "Holoview: An Immersive Mixed-Reality Visualization System for Anatomical Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08736",
        "HTML": "https://arxiv.org/html/2501.08736v4",
        "PDF": "https://arxiv.org/pdf/2501.08736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Holoview is an augmented reality system for anatomical education with no focus on LLM training data processing or related dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09850",
      "abstract": "Reasoning-capable language models achieve state-of-the-art performance in diverse complex tasks by generating long, explicit Chain-of-Thought (CoT) traces. While recent works show that base models can acquire such reasoning traces via reinforcement learning or distillation from stronger models like DeepSeek-R1, previous works demonstrate that even short CoT prompting without fine-tuning is able to improve reasoning. We ask whether long CoT can be induced in a base model using only prompting or minimal tuning. Using just 20 long CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly fine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms the much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of high-quality examples can unlock strong reasoning capabilities. We further explore using CoT data from non-reasoning models and human annotators, enhanced with prompt engineering, multi-pass editing, and structural guidance. However, neither matches the performance of reasoning model traces, suggesting that certain latent qualities of expert CoT are difficult to replicate. We analyze key properties of reasoning data, such as problem difficulty, diversity, and answer length, that influence reasoning distillation. While challenges remain, we are optimistic that carefully curated human-written CoT, even in small quantities, can activate reasoning behaviors in base models. We release our human-authored dataset across refinement stages and invite further investigation into what makes small-scale reasoning supervision so effective.",
      "authors": [
        "Wei Du",
        "Branislav Kisacanin",
        "George Armstrong",
        "Shubham Toshniwal",
        "Ivan Moshkov",
        "Alexan Ayrapetyan",
        "Sadegh Mahdavi",
        "Dan Zhao",
        "Shizhe Diao",
        "Dragan Masulovic",
        "Marius Stanean",
        "Advaith Avadhanam",
        "Max Wang",
        "Ashmit Dutta",
        "Shitij Govil",
        "Sri Yanamandara",
        "Mihir Tandon",
        "Sriram Ananthakrishnan",
        "Vedant Rathi",
        "David Zhang",
        "Joonseok Kang",
        "Leon Luo",
        "Titu Andreescu",
        "Boris Ginsburg",
        "and Igor Gitman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.09850v1",
          "size": "120kb",
          "version": "v1"
        }
      ],
      "title": "Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09850",
        "PDF": "https://arxiv.org/pdf/2507.09850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper explores human-written data and CoT data used for fine-tuning LLMs, tackling data challenges such as problem difficulty, diversity, and reasoning distillation, which are central to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09888",
      "abstract": "Time series forecasting is a fundamental task with broad applications, yet conventional methods often treat data as discrete sequences, overlooking their origin as noisy samples of continuous processes. Crucially, discrete noisy observations cannot uniquely determine a continuous function; instead, they correspond to a family of plausible functions. Mathematically, time series can be viewed as noisy observations of a continuous function family governed by a shared probability measure. Thus, the forecasting task can be framed as learning the transition from the historical function family to the future function family. This reframing introduces two key challenges: (1) How can we leverage discrete historical and future observations to learn the relationships between their underlying continuous functions? (2) How can we model the transition path in function space from the historical function family to the future function family? To address these challenges, we propose NeuTSFlow, a novel framework that leverages Neural Operators to facilitate flow matching for learning path of measure between historical and future function families. By parameterizing the velocity field of the flow in infinite-dimensional function spaces, NeuTSFlow moves beyond traditional methods that focus on dependencies at discrete points, directly modeling function-level features instead. Experiments on diverse forecasting tasks demonstrate NeuTSFlow's superior accuracy and robustness, validating the effectiveness of the function-family perspective.",
      "authors": [
        "Huibo Xu and Likang Wu and Xianquan Wang and Haoning Dang and Chun-Wun Cheng and Angelica I Aviles-Rivero and Qi Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:48:48+00:00",
          "link": "https://arxiv.org/abs/2507.09888v1",
          "size": "502kb",
          "version": "v1"
        }
      ],
      "title": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09888",
        "HTML": "https://arxiv.org/html/2507.09888v1",
        "PDF": "https://arxiv.org/pdf/2507.09888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for time series forecasting using views of continuous functions; it is unrelated to LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.06161",
      "abstract": "Despite their simple and robust structure, low cost, and simple cooling system, switched reluctance motors (SRMs) face the challenge of low mean torque. A possible solution is to change the structure of SRMs. This article introduces an innovative combination of the number of rotor teeth and stator teeth of a two-phase switch reluctance motor (TPSRM) with eight teeth for the stator and fourteen teeth for the rotor. As a result of its unique design, which has a short path for passing the main flux, it requires less magnetomotive force. This leads to less core and copper loss, resulting in increased efficiency. Each tooth of the stator in a phase develops a positive torque during the rotation of the rotor, which increases the torque and consequently increases the mean torque of the proposed TPSRM. A current hysteresis control (CHC) is simulated by 2D FEM for the proposed 8/14 TPSRM and the conventional 8/12 TPSRM under the same mechanical load on the shaft to get a current hysteresis reference of 15A at the nominal speed of 600 rpm. To verify the novelty and advantages of the suggested TPSRM, it is compared with the conventional 8/12 TPSRM in terms of mean and peak torque, torque density, and core and copper losses were compared. Lastly, the proposed 8/14 TPSRM is shown to have better performance than the conventional 8/12 TPSRM.",
      "authors": [
        "Gholamreza Davarpanah",
        "Hossein Shirzad",
        "Jawad Faiz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-09T12:11:05+00:00",
          "link": "https://arxiv.org/abs/2411.06161v1",
          "size": "3262kb",
          "version": "v1"
        },
        {
          "date": "2025-04-28T19:47:35+00:00",
          "link": "https://arxiv.org/abs/2411.06161v2",
          "size": "3273kb",
          "version": "v2"
        },
        {
          "date": "2025-04-30T07:43:55+00:00",
          "link": "https://arxiv.org/abs/2411.06161v3",
          "size": "3262kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T07:26:10+00:00",
          "link": "https://arxiv.org/abs/2411.06161v4",
          "size": "3262kb",
          "version": "v4"
        }
      ],
      "title": "A New 8/14 Two-Phase Switched Reluctance Motor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06161",
        "PDF": "https://arxiv.org/pdf/2411.06161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This article introduces an innovation in motor design for switched reluctance motors. It is not related to LLM training data processing or any associated data engineering methods."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.02342",
      "abstract": "This study proposes DeltaSHAP, a novel explainable artificial intelligence (XAI) algorithm specifically designed for online patient monitoring systems. In clinical environments, discovering the causes driving patient risk evolution is critical for timely intervention, yet existing XAI methods fail to address the unique requirements of clinical time series explanation tasks. To this end, DeltaSHAP addresses three key clinical needs: explaining the changes in the consecutive predictions rather than isolated prediction scores, providing both magnitude and direction of feature attributions, and delivering these insights in real time. By adapting Shapley values to temporal settings, our approach accurately captures feature coalition effects. It further attributes prediction changes using only the actually observed feature combinations, making it efficient and practical for time-sensitive clinical applications. We also introduce new evaluation metrics to evaluate the faithfulness of the attributions for online time series, and demonstrate through experiments on online patient monitoring tasks that DeltaSHAP outperforms state-of-the-art XAI methods in both explanation quality as 62% and computational efficiency as 33% time reduction on the MIMIC-III decompensation benchmark. We release our code at https://github.com/AITRICS/DeltaSHAP.",
      "authors": [
        "Changhun Kim",
        "Yechan Mun",
        "Sangchul Hahn",
        "and Eunho Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:08:07+00:00",
          "link": "https://arxiv.org/abs/2507.02342v1",
          "size": "3511kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T07:51:21+00:00",
          "link": "https://arxiv.org/abs/2507.02342v2",
          "size": "3511kb",
          "version": "v2"
        }
      ],
      "title": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02342",
        "HTML": "https://arxiv.org/html/2507.02342v2",
        "PDF": "https://arxiv.org/pdf/2507.02342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents an XAI algorithm for patient monitoring systems and focuses on prediction explanations without involving LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03280",
      "abstract": "Existing solutions for bundle recommendation(BR) have achieved remarkable effectiveness for predicting the user's preference for prebuilt bundles. However, bundle-item(B-I) affiliation will vary dynamically in real scenarios. For example, a bundle themed as 'casual outfit', may add 'hat' or remove 'watch' due to factors such as seasonal variations, changes in user pes or inventory adjustments. Our empirical study demonstrates that the performance of mainstream BR models will fluctuate or even decline regarding item-level variability. This paper makes the first attempt to referencaddress the above problem and proposes a novel Residual Diffusion for Bundle Recommendation(RDiffBR) as a model-agnostic generative framework which can assist a BR model in adapting this scenario. During the initial training of the BR model, RDiffBR employs a residual diffusion model to process the item-level bundle embeddings which are generated by BR model to represent bundle theme via a forward-reverse process. In the inference stage, RDiffBR reverses item-level bundle embeddings obtained by the well-trained bundle model under B-I variability scenarios to generate the effective item-level bundle embeddings. In particular, the residual connection in our residual approximator significantly enhances item-level bundle embeddings generation ability of BR models. Experiments on six BR models and four public datasets from different domains show that RDiffBR improves the performance of Recall and NDCG of backbone BR models by up to 23%, while only increased training time about 4%.Codes and datasets are available at https://anonymous.4open.science/r/RDiffBR.",
      "authors": [
        "Dong Zhang",
        "Lin Li",
        "Ming Li",
        "Xiaohui Tao",
        "Meng Sun",
        "Jimmy Xiangji Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T03:56:04+00:00",
          "link": "https://arxiv.org/abs/2507.03280v1",
          "size": "8941kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.03280v2",
          "size": "8941kb",
          "version": "v2"
        }
      ],
      "title": "Modeling Item-Level Dynamic Variability with Residual Diffusion for Bundle Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03280",
        "HTML": "https://arxiv.org/html/2507.03280v2",
        "PDF": "https://arxiv.org/pdf/2507.03280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for handling item-level variability in bundle recommendation systems, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08908",
      "abstract": "Despite the widespread interest in machine learning (ML), the engineering industry has not yet fully adopted ML-based methods, which has left engineers and stakeholders uncertain about the legal and regulatory frameworks that govern their decisions. This gap remains unaddressed as an engineer's decision-making process, typically governed by professional ethics and practical guidelines, now intersects with complex algorithmic outputs. To bridge this gap, this paper explores how engineers can navigate legal principles and legislative justifications that support and/or contest the deployment of ML technologies. Drawing on recent precedents and experiences gained from other fields, this paper argues that analogical reasoning can provide a basis for embedding ML within existing engineering codes while maintaining professional accountability and meeting safety requirements. In exploring these issues, the discussion focuses on established liability doctrines, such as negligence and product liability, and highlights how courts have evaluated the use of predictive models. We further analyze how legislative bodies and standard-setting organizations can furnish explicit guidance equivalent to prior endorsements of emergent technologies. This exploration stresses the vitality of understanding the interplay between technical justifications and legal precedents for shaping an informed stance on ML's legitimacy in engineering practice. Finally, our analysis catalyzes a legal framework for integrating ML through which stakeholders can critically assess the responsibilities, liabilities, and benefits inherent in ML-driven engineering solutions.",
      "authors": [
        "M.Z. Naser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:28:32+00:00",
          "link": "https://arxiv.org/abs/2507.08908v1",
          "size": "818kb",
          "version": "v1"
        }
      ],
      "title": "The Engineer's Dilemma: A Review of Establishing a Legal Framework for Integrating Machine Learning in Construction by Navigating Precedents and Industry Expectations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08908",
        "PDF": "https://arxiv.org/pdf/2507.08908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the legal frameworks for integrating machine learning in engineering, focusing on legal principles and industry expectations. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09166",
      "abstract": "The coarse spatial resolution of gridded climate models, such as general circulation models, limits their direct use in projecting socially relevant variables like extreme precipitation. Most downscaling methods estimate the conditional distributions of extremes by generating large ensembles, complicating the assessment of robustness under distributional shifts, such as those induced by climate change. To better understand and potentially improve robustness, we propose super-resolving the parameters of the target variable's probability distribution directly using analytically tractable mappings. Within a perfect-model framework over Switzerland, we demonstrate that vector generalized linear and additive models can super-resolve the generalized extreme value distribution of summer hourly precipitation extremes from coarse precipitation fields and topography. We introduce the notion of a \"robustness gap\", defined as the difference in predictive error between present-trained and future-trained models, and use it to diagnose how model structure affects the generalization of each quantile to a pseudo-global warming scenario. By evaluating multiple model configurations, we also identify an upper limit on the super-resolution factor based on the spatial auto- and cross-correlation of precipitation and elevation, beyond which coarse precipitation loses predictive value. Our framework is broadly applicable to variables governed by parametric distributions and offers a model-agnostic diagnostic for understanding when and why empirical downscaling generalizes to climate change and extremes.",
      "authors": [
        "Louise Largeau",
        "Erwan Koch",
        "David Leutwyler",
        "Gregoire Mariethoz",
        "Valerie Chavez-Demoulin",
        "Tom Beucler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:04:07+00:00",
          "link": "https://arxiv.org/abs/2507.09166v1",
          "size": "38344kb",
          "version": "v1"
        }
      ],
      "title": "Investigating the Robustness of Extreme Precipitation Super-Resolution Across Climates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09166",
        "HTML": "https://arxiv.org/html/2507.09166v1",
        "PDF": "https://arxiv.org/pdf/2507.09166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses climate model robustness and super-resolution of climate data, focusing on generalized extreme value distribution. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09701",
      "abstract": "Large language models exhibit cultural biases and limited cross-cultural understanding capabilities, particularly when serving diverse global user populations. We propose MCEval, a novel multilingual evaluation framework that employs dynamic cultural question construction and enables causal analysis through Counterfactual Rephrasing and Confounder Rephrasing. Our comprehensive evaluation spans 13 cultures and 13 languages, systematically assessing both cultural awareness and cultural bias across different linguistic scenarios. The framework provides 39,897 cultural awareness instances and 17,940 cultural bias instances. Experimental results reveal performance disparities across different linguistic scenarios, demonstrating that optimal cultural performance is not only linked to training data distribution, but also is related to language-culture alignment. The evaluation results also expose the fairness issue, where approaches appearing successful in the English scenario create substantial disadvantages. MCEval represents the first comprehensive multilingual cultural evaluation framework that provides deeper insights into LLMs' cultural understanding.",
      "authors": [
        "Shulin Huang",
        "Linyi Yang",
        "Yue Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:24:35+00:00",
          "link": "https://arxiv.org/abs/2507.09701v1",
          "size": "7119kb",
          "version": "v1"
        }
      ],
      "title": "MCEval: A Dynamic Framework for Fair Multilingual Cultural Evaluation of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09701",
        "HTML": "https://arxiv.org/html/2507.09701v1",
        "PDF": "https://arxiv.org/pdf/2507.09701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes an evaluation framework for cultural biases in multilingual LLMs, focusing on evaluation techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10239",
      "abstract": "Recent research has investigated the shape and texture biases of deep neural networks (DNNs) in image classification which influence their generalization capabilities and robustness. It has been shown that, in comparison to regular DNN training, training with stylized images reduces texture biases in image classification and improves robustness with respect to image corruptions. In an effort to advance this line of research, we examine whether style transfer can likewise deliver these two effects in semantic segmentation. To this end, we perform style transfer with style varying across artificial image areas. Those random areas are formed by a chosen number of Voronoi cells. The resulting style-transferred data is then used to train semantic segmentation DNNs with the objective of reducing their dependence on texture cues while enhancing their reliance on shape-based features. In our experiments, it turns out that in semantic segmentation, style transfer augmentation reduces texture bias and strongly increases robustness with respect to common image corruptions as well as adversarial attacks. These observations hold for convolutional neural networks and transformer architectures on the Cityscapes dataset as well as on PASCAL Context, showing the generality of the proposed method.",
      "authors": [
        "Ben Hamscher",
        "Edgar Heinert",
        "Annika M\\\"utze",
        "Kira Maag",
        "Matthias Rottmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:02:19+00:00",
          "link": "https://arxiv.org/abs/2507.10239v1",
          "size": "11391kb",
          "version": "v1"
        }
      ],
      "title": "Transferring Styles for Reduced Texture Bias and Improved Robustness in Semantic Segmentation Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10239",
        "HTML": "https://arxiv.org/html/2507.10239v1",
        "PDF": "https://arxiv.org/pdf/2507.10239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses mainly on the effect of style transfer on biases and robustness in semantic segmentation networks rather than LLM training data processing or creation of new LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.14718",
      "abstract": "Future Frame Synthesis (FFS), the task of generating subsequent video frames from context, represents a core challenge in machine intelligence and a cornerstone for developing predictive world models. This survey provides a comprehensive analysis of the FFS landscape, charting its critical evolution from deterministic algorithms focused on pixel-level accuracy to modern generative paradigms that prioritize semantic coherence and dynamic plausibility. We introduce a novel taxonomy organized by algorithmic stochasticity, which not only categorizes existing methods but also reveals the fundamental drivers--advances in architectures, datasets, and computational scale--behind this paradigm shift. Critically, our analysis identifies a bifurcation in the field's trajectory: one path toward efficient, real-time prediction, and another toward large-scale, generative world simulation. By pinpointing key challenges and proposing concrete research questions for both frontiers, this survey serves as an essential guide for researchers aiming to advance the frontiers of visual dynamic modeling.",
      "authors": [
        "Ruibo Ming",
        "Zhewei Huang",
        "Jingwei Wu",
        "Zhuoxuan Ju",
        "Daxin Jiang",
        "Jianming Hu",
        "Lihui Peng",
        "Shuchang Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-26T08:59:38+00:00",
          "link": "https://arxiv.org/abs/2401.14718v1",
          "size": "227kb",
          "version": "v1"
        },
        {
          "date": "2024-01-31T05:09:44+00:00",
          "link": "https://arxiv.org/abs/2401.14718v2",
          "size": "175kb",
          "version": "v2"
        },
        {
          "date": "2024-07-22T10:18:26+00:00",
          "link": "https://arxiv.org/abs/2401.14718v3",
          "size": "181kb",
          "version": "v3"
        },
        {
          "date": "2024-09-12T02:25:47+00:00",
          "link": "https://arxiv.org/abs/2401.14718v4",
          "size": "197kb",
          "version": "v4"
        },
        {
          "date": "2024-11-08T10:51:47+00:00",
          "link": "https://arxiv.org/abs/2401.14718v5",
          "size": "82kb",
          "version": "v5"
        },
        {
          "date": "2025-05-20T10:34:20+00:00",
          "link": "https://arxiv.org/abs/2401.14718v6",
          "size": "6020kb",
          "version": "v6"
        },
        {
          "date": "2025-06-19T03:21:06+00:00",
          "link": "https://arxiv.org/abs/2401.14718v7",
          "size": "4086kb",
          "version": "v7"
        },
        {
          "date": "2025-07-14T09:44:08+00:00",
          "link": "https://arxiv.org/abs/2401.14718v8",
          "size": "6237kb",
          "version": "v8"
        }
      ],
      "title": "A Survey on Future Frame Synthesis: Bridging Deterministic and Generative Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.14718",
        "HTML": "https://arxiv.org/html/2401.14718",
        "PDF": "https://arxiv.org/pdf/2401.14718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys Future Frame Synthesis (FFS) techniques and does not discuss LLM training data processing."
      },
      "tasks": [
        "Survey",
        "Video Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.04963",
      "abstract": "Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliability. To address these problems, this study provides in-depth insights into LLMs' performance while ensuring the reliability of the evaluation. We design an error-based human annotation framework to assess the LLMs' simplification capabilities. We select both closed-source and open-source LLMs, including GPT-4, Qwen2.5-72B, and Llama-3.2-3B. We believe that these models offer a representative selection across large, medium, and small sizes of LLMs. Results show that LLMs generally generate fewer erroneous simplification outputs compared to the previous state-of-the-art. However, LLMs have their limitations, as seen in GPT-4's and Qwen2.5-72B's struggle with lexical paraphrasing. Furthermore, we conduct meta-evaluations on widely used automatic metrics using our human annotations. We find that these metrics lack sufficient sensitivity to assess the overall high-quality simplifications, particularly those generated by high-performance LLMs.",
      "authors": [
        "Xuanxin Wu and Yuki Arase"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-08T00:19:24+00:00",
          "link": "https://arxiv.org/abs/2403.04963v1",
          "size": "2430kb",
          "version": "v1"
        },
        {
          "date": "2025-04-08T02:31:31+00:00",
          "link": "https://arxiv.org/abs/2403.04963v2",
          "size": "2586kb",
          "version": "v2"
        },
        {
          "date": "2025-05-27T03:36:23+00:00",
          "link": "https://arxiv.org/abs/2403.04963v3",
          "size": "2252kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T08:30:39+00:00",
          "link": "https://arxiv.org/abs/2403.04963v4",
          "size": "1300kb",
          "version": "v4"
        }
      ],
      "title": "An In-depth Evaluation of Large Language Models in Sentence Simplification with Error-based Human Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.04963",
        "HTML": "https://arxiv.org/html/2403.04963v4",
        "PDF": "https://arxiv.org/pdf/2403.04963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses evaluation methodologies for LLMs' sentence simplification and does not focus on processing or creating LLM training data."
      },
      "tasks": [
        "Sentence"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06799",
      "abstract": "Recent advances in artificial intelligence have highlighted the remarkable capabilities of neural network (NN)-powered systems on classical computers. However, these systems face significant computational challenges that limit scalability and efficiency. Quantum computers hold the potential to overcome these limitations and increase processing power beyond classical systems. Despite this, integrating quantum computing with NNs remains largely unrealized due to challenges posed by noise, decoherence, and high error rates in current quantum hardware. Here, we propose a novel quantum echo-state network (QESN) design and implementation algorithm that can operate within the presence of noise on current IBM hardware. We apply classical control-theoretic response analysis to characterize the QESN, emphasizing its rich nonlinear dynamics and memory, as well as its ability to be fine-tuned with sparsity and re-uploading blocks. We validate our approach through a comprehensive demonstration of QESNs functioning as quantum observers, applied in both high-fidelity simulations and hardware experiments utilizing data from a prototypical chaotic Lorenz system. Our results show that the QESN can predict long time-series with persistent memory, running over 100 times longer than the median T1 and T2 of the IBM Marrakesh QPU, achieving state-of-the-art time-series performance on superconducting hardware.",
      "authors": [
        "Erik L. Connerty",
        "Ethan N. Evans",
        "Gerasimos Angelatos",
        "Vignesh Narayanan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-11T00:40:44+00:00",
          "link": "https://arxiv.org/abs/2505.06799v1",
          "size": "13927kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:53:10+00:00",
          "link": "https://arxiv.org/abs/2505.06799v2",
          "size": "13927kb",
          "version": "v2"
        }
      ],
      "title": "Quantum Observers: A NISQ Hardware Demonstration of Chaotic State Prediction Using Quantum Echo-state Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06799",
        "HTML": "https://arxiv.org/html/2505.06799v2",
        "PDF": "https://arxiv.org/pdf/2505.06799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a quantum echo-state network design for chaotic state prediction, focusing on quantum computing challenges. There is no mention of LLM training data processing or data-centric methodologies for language models."
      },
      "tasks": [
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/econnerty/QESN-Code"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08858",
      "abstract": "The zero-shot capabilities of foundation models (FMs) for time series forecasting offer promising potentials in conformal prediction, as most of the available data can be allocated to calibration. This study compares the performance of Time Series Foundation Models (TSFMs) with traditional methods, including statistical models and gradient boosting, within a conformal prediction setting. Our findings highlight two key advantages of TSFMs. First, when the volume of data is limited, TSFMs provide more reliable conformalized prediction intervals than classic models, thanks to their superior predictive accuracy. Second, the calibration process is more stable because more data are used for calibration. Morever, the fewer data available, the more pronounced these benefits become, as classic models require a substantial amount of data for effective training. These results underscore the potential of foundation models in improving conformal prediction reliability in time series applications, particularly in data-constrained cases. All the code to reproduce the experiments is available.",
      "authors": [
        "Sami Achour",
        "Yassine Bouher",
        "Duong Nguyen",
        "Nicolas Chesneau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:41:54+00:00",
          "link": "https://arxiv.org/abs/2507.08858v1",
          "size": "2439kb",
          "version": "v1"
        }
      ],
      "title": "Foundation models for time series forecasting: Application in conformal prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08858",
        "HTML": "https://arxiv.org/html/2507.08858v1",
        "PDF": "https://arxiv.org/pdf/2507.08858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores foundational models for time series forecasting in conformal prediction scenarios and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09068",
      "abstract": "The rapid advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have ushered in remarkable progress in video understanding. However, a fundamental challenge persists: effectively processing and comprehending video content that extends beyond minutes or hours. While recent efforts like Video-XL-2 have demonstrated novel architectural solutions for extreme efficiency, and advancements in positional encoding such as HoPE and VideoRoPE++ aim to improve spatio-temporal understanding over extensive contexts, current state-of-the-art models still encounter significant computational and memory constraints when faced with the sheer volume of visual tokens from lengthy sequences. Furthermore, maintaining temporal coherence, tracking complex events, and preserving fine-grained details over extended periods remain formidable hurdles, despite progress in agentic reasoning systems like Deep Video Discovery. This position paper posits that a logical, albeit ambitious, next frontier for multimedia research is Infinite Video Understanding -- the capability for models to continuously process, understand, and reason about video data of arbitrary, potentially never-ending duration. We argue that framing Infinite Video Understanding as a blue-sky research objective provides a vital north star for the multimedia, and the wider AI, research communities, driving innovation in areas such as streaming architectures, persistent memory mechanisms, hierarchical and adaptive representations, event-centric reasoning, and novel evaluation paradigms. Drawing inspiration from recent work on long/ultra-long video understanding and several closely related fields, we outline the core challenges and key research directions towards achieving this transformative capability.",
      "authors": [
        "Dell Zhang",
        "Xiangyu Chen",
        "Jixiang Luo",
        "Mengxi Jia",
        "Changzhi Sun",
        "Ruilong Ren",
        "Jingren Liu",
        "Hao Sun",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:07:04+00:00",
          "link": "https://arxiv.org/abs/2507.09068v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Infinite Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09068",
        "HTML": "https://arxiv.org/html/2507.09068v1",
        "PDF": "https://arxiv.org/pdf/2507.09068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses advancements in video understanding and proposes a future research direction called Infinite Video Understanding, focusing on processing video data. It does not involve LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09473",
      "abstract": "Motivated by applications such as cloud platforms allocating GPUs to users or governments deploying mobile health units across competing regions, we study the dynamic allocation of a reusable resource to strategic agents with private valuations. Our objective is to simultaneously (i) maximize social welfare, (ii) satisfy multi-dimensional long-term cost constraints, and (iii) incentivize truthful reporting. We begin by numerically evaluating primal-dual methods widely used in constrained online optimization and find them to be highly fragile in strategic settings -- agents can easily manipulate their reports to distort future dual updates for future gain.\n  To address this vulnerability, we develop an incentive-aware framework that makes primal-dual methods robust to strategic behavior. Our design combines epoch-based lazy updates -- where dual variables remain fixed within each epoch -- with randomized exploration rounds that extract approximately truthful signals for learning. Leveraging carefully designed online learning subroutines that can be of independent interest for dual updates, our mechanism achieves $\\tilde{\\mathcal{O}}(\\sqrt{T})$ social welfare regret, satisfies all cost constraints, and ensures incentive alignment. This matches the performance of non-strategic allocation approaches while being robust to strategic agents.",
      "authors": [
        "Yan Dai",
        "Negin Golrezaei",
        "Patrick Jaillet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:18:02+00:00",
          "link": "https://arxiv.org/abs/2507.09473v1",
          "size": "347kb",
          "version": "v1"
        }
      ],
      "title": "Incentive-Aware Dynamic Resource Allocation under Long-Term Cost Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09473",
        "HTML": "https://arxiv.org/html/2507.09473v1",
        "PDF": "https://arxiv.org/pdf/2507.09473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses dynamic resource allocation under cost constraints and is not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09833",
      "abstract": "In this study, we consider a problem of remote safety monitoring, where a monitor pulls status updates from multiple sensors monitoring several safety-critical situations. Based on the received updates, multiple estimators determine the current safety-critical situations. Due to transmission errors and limited channel resources, the received status updates may not be fresh, resulting in the possibility of misunderstanding the current safety situation. In particular, if a dangerous situation is misinterpreted as safe, the safety risk is high. We study the joint design of transmission scheduling and estimation for multi-sensor, multi-channel remote safety monitoring, aiming to minimize the loss due to the unawareness of potential danger. We show that the joint design of transmission scheduling and estimation can be reduced to a sequential optimization of estimation and scheduling. The scheduling problem can be formulated as a Restless Multi-armed Bandit (RMAB) , for which it is difficult to establish indexability. We propose a low-complexity Maximum Gain First (MGF) policy and prove it is asymptotically optimal as the numbers of sources and channels scale up proportionally, without requiring the indexability condition. We also provide an information-theoretic interpretation of the transmission scheduling problem. Numerical results show that our estimation and scheduling policies achieves higher performance gain over periodic updating, randomized policy, and Maximum Age First (MAF) policy.",
      "authors": [
        "Tasmeen Zaman Ornee",
        "Md Kamran Chowdhury Shisher",
        "Clement Kam",
        "Yin Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:04:38+00:00",
          "link": "https://arxiv.org/abs/2507.09833v1",
          "size": "887kb",
          "version": "v1"
        }
      ],
      "title": "Remote Safety Monitoring: Significance-Aware Status Updating for Situational Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09833",
        "HTML": "https://arxiv.org/html/2507.09833v1",
        "PDF": "https://arxiv.org/pdf/2507.09833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses remote safety monitoring with a focus on transmission scheduling and estimation, without discussing any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09859",
      "abstract": "Self-Sovereign Identity (SSI) offers significant potential for managing identities in the Internet of Things (IoT), enabling decentralized authentication and credential management without reliance on centralized entities. However, existing SSI frameworks often limit credential issuance and revocation to trusted entities, such as IoT manufacturers, which restricts flexibility in dynamic IoT ecosystems. In this paper, we propose a blockchain-based SSI framework that allows any individual with a verifiable trust linkage to act as a credential issuer, ensuring decentralized and scalable identity management. Our framework incorporates a layered architecture, where trust is dynamically established through endorsement-based calculations and maintained via a hierarchical chain-of-trust mechanism. Blockchain serves as the Verifiable Data Registry, ensuring transparency and immutability of identity operations, while smart contracts automate critical processes such as credential issuance, verification, and revocation. A proof-of-concept implementation demonstrates that the proposed framework is feasible and incurs minimal overheads compared to the baseline, making it well-suited for dynamic and resource-constrained IoT environments.",
      "authors": [
        "Guntur Dharma Putra",
        "Bagus Rakadyanto Oktavianto Putra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:03:14+00:00",
          "link": "https://arxiv.org/abs/2507.09859v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Endorsement-Driven Blockchain SSI Framework for Dynamic IoT Ecosystems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09859",
        "HTML": "https://arxiv.org/html/2507.09859v1",
        "PDF": "https://arxiv.org/pdf/2507.09859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for managing identities in IoT systems using blockchain technology, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10543",
      "abstract": "In robot manipulation, robot learning has become a prevailing approach. However, generative models within this field face a fundamental trade-off between the slow, iterative sampling of diffusion models and the architectural constraints of faster Flow-based methods, which often rely on explicit consistency losses. To address these limitations, we introduce MP1, which pairs 3D point-cloud inputs with the MeanFlow paradigm to generate action trajectories in one network function evaluation (1-NFE). By directly learning the interval-averaged velocity via the MeanFlow Identity, our policy avoids any additional consistency constraints. This formulation eliminates numerical ODE-solver errors during inference, yielding more precise trajectories. MP1 further incorporates CFG for improved trajectory controllability while retaining 1-NFE inference without reintroducing structural constraints. Because subtle scene-context variations are critical for robot learning, especially in few-shot learning, we introduce a lightweight Dispersive Loss that repels state embeddings during training, boosting generalization without slowing inference. We validate our method on the Adroit and Meta-World benchmarks, as well as in real-world scenarios. Experimental results show MP1 achieves superior average task success rates, outperforming DP3 by 10.2% and FlowPolicy by 7.3%. Its average inference time is only 6.8 ms-19x faster than DP3 and nearly 2x faster than FlowPolicy. Our code is available at https://mp1-2254.github.io/.",
      "authors": [
        "Juyi Sheng",
        "Ziyi Wang",
        "Peiming Li",
        "Mengyuan Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:08+00:00",
          "link": "https://arxiv.org/abs/2507.10543v1",
          "size": "451kb",
          "version": "v1"
        }
      ],
      "title": "MP1: Mean Flow Tames Policy Learning in 1-step for Robotic Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10543",
        "HTML": "https://arxiv.org/html/2507.10543v1",
        "PDF": "https://arxiv.org/pdf/2507.10543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about robot learning and policy generation for robotic manipulation, with no mention of LLM training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.02487",
      "abstract": "We investigate the real-time voltage regulation problem in distribution systems employing online feedback optimization (OFO) with short-range communication between physical neighbours. OFO does not need an accurate grid model nor estimated consumption of non-controllable loads, affords fast calculations, and demonstrates robustness to uncertainties and disturbances, which render it particularly suitable for real-time distribution system applications. However, many OFO controllers require centralized communication, making them susceptible to single-point failures. This paper proposes a distributed OFO design based on a nested feedback optimization strategy and analyzes its convergence. The strategy preserves end-users' privacy by keeping voltage data local. Numerical study results demonstrate that the proposed design achieves effective voltage regulation and outperforms other distributed and local approaches.",
      "authors": [
        "Sen Zhan",
        "Nikolaos G. Paterakis",
        "Wouter van den Akker",
        "Anne van der Molen",
        "Johan Morren and Han Slootweg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-03T21:29:40+00:00",
          "link": "https://arxiv.org/abs/2405.02487v1",
          "size": "420kb",
          "version": "v1"
        },
        {
          "date": "2024-08-22T13:51:42+00:00",
          "link": "https://arxiv.org/abs/2405.02487v2",
          "size": "1007kb",
          "version": "v2"
        },
        {
          "date": "2024-10-11T07:16:37+00:00",
          "link": "https://arxiv.org/abs/2405.02487v3",
          "size": "3500kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T22:09:33+00:00",
          "link": "https://arxiv.org/abs/2405.02487v4",
          "size": "3799kb",
          "version": "v4"
        }
      ],
      "title": "Distributed Online Feedback Optimization for Real-time Distribution System Voltage Regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.02487",
        "HTML": "https://arxiv.org/html/2405.02487v4",
        "PDF": "https://arxiv.org/pdf/2405.02487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing real-time voltage regulation in distribution systems and does not involve any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.08373",
      "abstract": "Retrieval over knowledge graphs is usually performed using dedicated, complex query languages like SPARQL. We propose a novel system, Ontology and Semantic Exploration Toolkit (OnSET) that allows non-expert users to easily build queries with visual user guidance provided by topic modelling and semantic search throughout the application. OnSET allows users without any prior information about the ontology or networked knowledge to start exploring topics of interest over knowledge graphs, including the retrieval and detailed exploration of prototypical sub-graphs and their instances. Existing systems either focus on direct graph explorations or do not foster further exploration of the result set. We, however, provide a node-based editor that can extend on these missing properties of existing systems to support the search over big ontologies with sub-graph instances. Furthermore, OnSET combines efficient and open platforms to deploy the system on commodity hardware.",
      "authors": [
        "Benedikt Kantz",
        "Kevin Innerebner",
        "Peter Waldert",
        "Stefan Lengauer",
        "Elisabeth Lex",
        "Tobias Schreck"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T09:18:06+00:00",
          "link": "https://arxiv.org/abs/2504.08373v1",
          "size": "7448kb",
          "version": "v1"
        }
      ],
      "title": "OnSET: Ontology and Semantic Exploration Toolkit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08373",
        "PDF": "https://arxiv.org/pdf/2504.08373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes OnSET, a toolkit for exploring knowledge graphs, which is unrelated to LLM training data processing or engineering."
      },
      "tasks": [
        "Knowledge Graphs",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08864",
      "abstract": "Location-based vehicular traffic management faces significant challenges in protecting sensitive geographical data while maintaining utility for traffic management and fairness across regions. Existing state-of-the-art solutions often fail to meet the required level of protection against linkage attacks and demographic biases, leading to privacy leakage and inequity in data analysis. In this paper, we propose a novel algorithm designed to address the challenges regarding the balance of privacy, utility, and fairness in location-based vehicular traffic management systems. In this context, utility means providing reliable and meaningful traffic information, while fairness ensures that all regions and individuals are treated equitably in data use and decision-making. Employing differential privacy techniques, we enhance data security by integrating query-based data access with iterative shuffling and calibrated noise injection, ensuring that sensitive geographical data remains protected. We ensure adherence to epsilon-differential privacy standards by implementing the Laplace mechanism. We implemented our algorithm on vehicular location-based data from Norway, demonstrating its ability to maintain data utility for traffic management and urban planning while ensuring fair representation of all geographical areas without being overrepresented or underrepresented. Additionally, we have created a heatmap of Norway based on our model, illustrating the privatized and fair representation of the traffic conditions across various cities. Our algorithm provides privacy in vehicular traffic",
      "authors": [
        "Poushali Sengupta",
        "Sabita Maharjan",
        "frank Eliassen",
        "Yan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:49:13+00:00",
          "link": "https://arxiv.org/abs/2507.08864v1",
          "size": "668kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Utility-Fairness: A Balanced Approach to Vehicular-Traffic Management System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08864",
        "HTML": "https://arxiv.org/html/2507.08864v1",
        "PDF": "https://arxiv.org/pdf/2507.08864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses privacy, utility, and fairness in vehicular traffic data management, with no relevance to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08923",
      "abstract": "The rapid expansion of data centers (DCs) to support large-scale AI and scientific workloads is driving unsustainable growth in energy consumption and greenhouse gas emissions. While successive generations of hardware platforms have improved performance and energy efficiency, the question remains whether new, more efficient platforms can realistically offset the rising emissions associated with increasing demand. Prior studies often overlook the complex trade-offs in such transitions by failing to account for both the economic incentives and the projected compute demand growth over the operational lifetime of the devices. In response, we present CEO-DC, an integrated model and decision-making methodology for Carbon and Economy Optimization in Data Centers. CEO-DC models the competing forces of cost, carbon, and compute demand to guide optimal platform procurement and replacement strategies. We propose metrics to steer procurement, platform design, and policy decisions toward sustainable DC technologies. Given current platform trends, our AI case study using CEO-DC shows that upgrading legacy devices on a 4-year cycle reduces total emissions. However, these upgrades fail to scale with DC demand growth trends without increasing total emissions in over 44% of cases, and require economic incentives for adoption in over 72%. Furthermore, current carbon prices are insufficient to motivate upgrades in 9 out of the 14 countries with the highest number of DCs globally. We also find that optimizing platforms for energy efficiency at the expense of latency can increase the carbon price required to justify their adoption. In summary, CEO-DC provides actionable insights for DC architects, platform designers, and policymakers by timing legacy platform upgrades, constraining DC growth to sustainable levels, optimizing platform performance-to-cost ratios, and increasing incentives.",
      "authors": [
        "Rub\\'en Rodr\\'iguez \\'Alvarez",
        "Denisa-Andreea Constantinescu",
        "Miguel Pe\\'on-Quir\\'os",
        "David Atienza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Computers and Society (cs.CY)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:36:14+00:00",
          "link": "https://arxiv.org/abs/2507.08923v1",
          "size": "2123kb",
          "version": "v1"
        }
      ],
      "title": "CEO-DC: An Actionable Framework to Close the Carbon Gap in HPC Data Centers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08923",
        "HTML": "https://arxiv.org/html/2507.08923v1",
        "PDF": "https://arxiv.org/pdf/2507.08923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses carbon and economy optimization in data centers, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09403",
      "abstract": "Related video recommendations commonly use collaborative filtering (CF) driven by co-engagement signals, often resulting in recommendations lacking semantic coherence and exhibiting strong popularity bias. This paper introduces a novel multi-objective retrieval framework, enhancing standard two-tower models to explicitly balance semantic relevance and user engagement. Our approach uniquely combines: (a) multi-task learning (MTL) to jointly optimize co-engagement and semantic relevance, explicitly prioritizing topical coherence; (b) fusion of multimodal content features (textual and visual embeddings) for richer semantic understanding; and (c) off-policy correction (OPC) via inverse propensity weighting to effectively mitigate popularity bias. Evaluation on industrial-scale data and a two-week live A/B test reveals our framework's efficacy. We observed significant improvements in semantic relevance (from 51% to 63% topic match rate), a reduction in popular item distribution (-13.8% popular video recommendations), and a +0.04% improvement in our topline user engagement metric. Our method successfully achieves better semantic coherence, balanced engagement, and practical scalability for real-world deployment.",
      "authors": [
        "Amit Jaspal",
        "Feng Zhang",
        "Wei Chang",
        "Sumit Kumar",
        "Yubo Wang",
        "Roni Mittleman",
        "Qifan Wang",
        "Weize Mao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T21:04:25+00:00",
          "link": "https://arxiv.org/abs/2507.09403v1",
          "size": "330kb",
          "version": "v1"
        }
      ],
      "title": "Balancing Semantic Relevance and Engagement in Related Video Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09403",
        "PDF": "https://arxiv.org/pdf/2507.09403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving video recommendation systems and does not discuss LLM training data processing, collection, or any relevant data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.14127",
      "abstract": "Shock waves in gas dynamics feature jump discontinuities that hinder numerical simulations. Viscous regularizations are prone to excessive dissipation of fine-scale structures. In this work, we propose the first inviscid regularization of the multidimensional Euler equation based on ideas from semidefinite programming, information geometry, geometric hydrodynamics, and nonlinear elasticity. The Lagrangian flow maps of Euler solutions are a dynamical system on the manifold of diffeomorphisms. We observe that shock formation arises from the manifold's geodesic incompleteness. Our regularization embeds it into an ambient space equipped with the information geometry of the logarithmic barrier function. Thus, the diffeomorphism manifold inherits a geodesically complete geometry. The resulting regularized conservation law replaces shocks with smooth profiles without affecting oscillatory structures. One and two-dimensional numerical experiments show its practical potential to enable higher-order methods without explicit shock capturing. While we focus on the barotropic Euler equations for concreteness and simplicity of exposition, our regularization easily extends to more general Euler and Navier-Stokes-type equations. Our approach regularizes the Wasserstein geometry of the mass density with its information geometry. The former captures the natural trajectories of physical particles and the latter that of statistical estimators. Information geometric regularization accounts for the mass density's dual nature as a statistical/computational tool summarizing the motion of physical particles. Thus, our work is a starting point for information geometric mechanics that views solutions of continuum mechanical PDEs as parameters of statistical models for unresolved scales and uses their information geometry to evolve them in time.",
      "authors": [
        "Ruijia Cao and Florian Sch\\\"afer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-27T15:03:32+00:00",
          "link": "https://arxiv.org/abs/2308.14127v1",
          "size": "4939kb",
          "version": "v1"
        },
        {
          "date": "2023-12-12T18:39:57+00:00",
          "link": "https://arxiv.org/abs/2308.14127v2",
          "size": "6621kb",
          "version": "v2"
        },
        {
          "date": "2024-03-18T17:58:12+00:00",
          "link": "https://arxiv.org/abs/2308.14127v3",
          "size": "8148kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T15:37:52+00:00",
          "link": "https://arxiv.org/abs/2308.14127v4",
          "size": "7257kb",
          "version": "v4"
        }
      ],
      "title": "Information geometric regularization of the barotropic Euler equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.14127",
        "PDF": "https://arxiv.org/pdf/2308.14127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with inviscid regularization of the Euler equation and is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10086",
      "abstract": "Open-vocabulary semantic segmentation aims to assign semantic labels to each pixel without being constrained by a predefined set of categories. While Contrastive Language-Image Pre-training (CLIP) excels in zero-shot classification, it struggles to align image patches with category embeddings because of its incoherent patch correlations. This study reveals that inter-class correlations are the main reason for impairing CLIP's segmentation performance. Accordingly, we propose CorrCLIP, which reconstructs the scope and value of patch correlations. Specifically, CorrCLIP leverages the Segment Anything Model (SAM) to define the scope of patch interactions, reducing inter-class correlations. To mitigate the problem that SAM-generated masks may contain patches belonging to different classes, CorrCLIP incorporates self-supervised models to compute coherent similarity values, suppressing the weight of inter-class correlations. Additionally, we introduce two additional branches to strengthen patch features' spatial details and semantic representation. Finally, we update segmentation maps with SAM-generated masks to improve spatial consistency. Based on the improvement across patch correlations, feature representations, and segmentation maps, CorrCLIP achieves superior performance across eight benchmarks. Codes are available at: https://github.com/zdk258/CorrCLIP.",
      "authors": [
        "Dengke Zhang",
        "Fagui Liu",
        "Quan Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T10:14:55+00:00",
          "link": "https://arxiv.org/abs/2411.10086v1",
          "size": "5204kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T05:11:22+00:00",
          "link": "https://arxiv.org/abs/2411.10086v2",
          "size": "7754kb",
          "version": "v2"
        }
      ],
      "title": "CorrCLIP: Reconstructing Patch Correlations in CLIP for Open-Vocabulary Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10086",
        "HTML": "https://arxiv.org/html/2411.10086v2",
        "PDF": "https://arxiv.org/pdf/2411.10086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper improves segmentation by adjusting patch correlations in CLIP, it primarily addresses algorithmic enhancement rather than LLM data processing or dataset creation."
      },
      "tasks": [
        "Open Vocabulary Semantic Segmentation",
        "Open-Vocabulary Semantic Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Zero-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/zdk258/CorrCLIP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08959",
      "abstract": "In order to improve the accuracy of cross-platform advertisement recommendation, a graph neural network (GNN)- based advertisement recommendation method is analyzed. Through multi-dimensional modeling, user behavior data (e.g., click frequency, active duration) reveal temporal patterns of interest evolution, ad content (e.g., type, tag, duration) influences semantic preferences, and platform features (e.g., device type, usage context) shape the environment where interest transitions occur. These factors jointly enable the GNN to capture the latent pathways of user interest migration across platforms. The experimental results are based on the datasets of three platforms, and Platform B reaches 0.937 in AUC value, which is the best performance. Platform A and Platform C showed a slight decrease in precision and recall with uneven distribution of ad labels. By adjusting the hyperparameters such as learning rate, batch size and embedding dimension, the adaptability and robustness of the model in heterogeneous data are further improved.",
      "authors": [
        "Xiang Li",
        "Xinyu Wang",
        "Yifan Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:34:02+00:00",
          "link": "https://arxiv.org/abs/2507.08959v1",
          "size": "1203kb",
          "version": "v1"
        }
      ],
      "title": "Graph Neural Network Enhanced Sequential Recommendation Method for Cross-Platform Ad Campaign",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08959",
        "PDF": "https://arxiv.org/pdf/2507.08959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing advertisement recommendations using graph neural networks, with no focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09230",
      "abstract": "An ideal digital telepresence experience requires accurate replication of a person's body, clothing, and movements. To capture and transfer these movements into virtual reality, the egocentric (first-person) perspective can be adopted, which enables the use of a portable and cost-effective device without front-view cameras. However, this viewpoint introduces challenges such as occlusions and distorted body proportions.\n  There are few works reconstructing human appearance from egocentric views, and none use a generative prior-based approach. Some methods create avatars from a single egocentric image during inference, but still rely on multi-view datasets during training. To our knowledge, this is the first study using a generative backbone to reconstruct animatable avatars from egocentric inputs. Based on Stable Diffusion, our method reduces training burden and improves generalizability.\n  Inspired by methods such as SiTH and MagicMan, which perform 360-degree reconstruction from a frontal image, we introduce a pipeline that generates realistic frontal views from occluded top-down images using ControlNet and a Stable Diffusion backbone.\n  Our goal is to convert a single top-down egocentric image into a realistic frontal representation and feed it into an image-to-motion model. This enables generation of avatar motions from minimal input, paving the way for more accessible and generalizable telepresence systems.",
      "authors": [
        "G. Kutay T\\\"urkoglu",
        "Julian Tanke",
        "Iheb Belgacem",
        "Lev Markhasin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:59:31+00:00",
          "link": "https://arxiv.org/abs/2507.09230v1",
          "size": "4235kb",
          "version": "v1"
        }
      ],
      "title": "EgoAnimate: Generating Human Animations from Egocentric top-down Views",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09230",
        "HTML": "https://arxiv.org/html/2507.09230v1",
        "PDF": "https://arxiv.org/pdf/2507.09230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating human animations from egocentric views using a generative approach and visual data, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.15595",
      "abstract": "With the rapid advancement of large language models (LLMs), aligning policy models with human preferences has become increasingly critical. Direct Preference Optimization (DPO) has emerged as a promising approach for alignment, acting as an RL-free alternative to Reinforcement Learning from Human Feedback (RLHF). Despite DPO's various advancements and inherent limitations, an in-depth review of these aspects is currently lacking in the literature. In this work, we present a comprehensive review of the challenges and opportunities in DPO, covering theoretical analyses, variants, relevant preference datasets, and applications. Specifically, we categorize recent studies on DPO based on key research questions to provide a thorough understanding of DPO's current landscape. Additionally, we propose several future research directions to offer insights on model alignment for the research community. An updated collection of relevant papers can be found on https://github.com/Mr-Loevan/DPO-Survey.",
      "authors": [
        "Wenyi Xiao",
        "Zechuan Wang",
        "Leilei Gan",
        "Shuai Zhao",
        "Zongrui Li",
        "Ruirui Lei",
        "Wanggui He",
        "Luu Anh Tuan",
        "Long Chen",
        "Hao Jiang",
        "Zhou Zhao",
        "Fei Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T02:27:24+00:00",
          "link": "https://arxiv.org/abs/2410.15595v1",
          "size": "142kb",
          "version": "v1"
        },
        {
          "date": "2024-11-10T13:46:15+00:00",
          "link": "https://arxiv.org/abs/2410.15595v2",
          "size": "142kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T09:25:43+00:00",
          "link": "https://arxiv.org/abs/2410.15595v3",
          "size": "6530kb",
          "version": "v3"
        }
      ],
      "title": "A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15595",
        "HTML": "https://arxiv.org/html/2410.15595v3",
        "PDF": "https://arxiv.org/pdf/2410.15595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper provides a survey about Direct Preference Optimization, discussing datasets and alignment in context of LLM alignment with human preferences. However, it is more focused on model alignment theories and applications rather than direct contributions to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.18076",
      "abstract": "Unsupervised pretraining has been transformative in many supervised domains. However, applying such ideas to reinforcement learning (RL) presents a unique challenge in that fine-tuning does not involve mimicking task-specific data, but rather exploring and locating the solution through iterative self-improvement. In this work, we study how unlabeled offline trajectory data can be leveraged to learn efficient exploration strategies. While prior data can be used to pretrain a set of low-level skills, or as additional off-policy data for online RL, it has been unclear how to combine these ideas effectively for online exploration. Our method SUPE (Skills from Unlabeled Prior data for Exploration) demonstrates that a careful combination of these ideas compounds their benefits. Our method first extracts low-level skills using a variational autoencoder (VAE), and then pseudo-labels unlabeled trajectories with optimistic rewards and high-level action labels, transforming prior data into high-level, task-relevant examples that encourage novelty-seeking behavior. Finally, SUPE uses these transformed examples as additional off-policy data for online RL to learn a high-level policy that composes pretrained low-level skills to explore efficiently. In our experiments, SUPE consistently outperforms prior strategies across a suite of 42 long-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.",
      "authors": [
        "Max Wilcoxson",
        "Qiyang Li",
        "Kevin Frans",
        "Sergey Levine"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T17:58:45+00:00",
          "link": "https://arxiv.org/abs/2410.18076v1",
          "size": "6129kb",
          "version": "v1"
        },
        {
          "date": "2024-12-06T16:57:15+00:00",
          "link": "https://arxiv.org/abs/2410.18076v2",
          "size": "7955kb",
          "version": "v2"
        },
        {
          "date": "2025-02-23T18:58:48+00:00",
          "link": "https://arxiv.org/abs/2410.18076v3",
          "size": "8718kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T20:30:30+00:00",
          "link": "https://arxiv.org/abs/2410.18076v4",
          "size": "7226kb",
          "version": "v4"
        }
      ],
      "title": "Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18076",
        "HTML": "https://arxiv.org/html/2410.18076v4",
        "PDF": "https://arxiv.org/pdf/2410.18076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using unlabeled prior data for reinforcement learning to develop exploration strategies, and does not discuss any aspect of LLM training data processing or improvements."
      },
      "tasks": [
        "Efficient Exploration",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/rail-berkeley/supe"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.10687",
      "abstract": "Integrated sensing and communication (ISAC) has garnered substantial research interest owing to its pivotal role in advancing the development of next-generation (6G) wireless networks. However, achieving a performance balance between communication and sensing in the dual-function radar communication (DFRC)-based ISAC system remains a significant challenge. In this paper, a low-altitude intelligent reflecting surface (IRS)-assisted ISAC system is explored, where a base station (BS) supports dual-functional operations, enabling both data transmission for multiple users and sensing for a blocked target, with the channel quality enhanced by an IRS mounted on the unmanned aerial vehicle (UAV). Moreover, we formulate an integrated communication, sensing, and energy efficiency multi-objective optimization problem (CSEMOP), which aims to maximize the communication rate of the users and the sensing rate of the target, while minimizing UAV propulsion energy consumption by jointly optimizing the BS beamforming matrix, IRS phase shifts, the flight velocity and angle of the UAV. Considering the non-convexity, trade-off, and dynamic nature of the formulated CSEMOP, we propose a generative diffusion model-based deep deterministic policy gradient (GDMDDPG) algorithm to solve the problem. Specifically, the diffusion model is incorporated into the actor network of DDPG to improve the action quality, with noise perturbation mechanism for better exploration and recent prioritized experience replay (RPER) sampling mechanism for enhanced training efficiency. Simulation results indicate that the GDMDDPG algorithm delivers superior performance compared to the existing methods.",
      "authors": [
        "Wenwen Xie",
        "Geng Sun",
        "Jiacheng Wang",
        "Hongyang Du",
        "Jiawen Kang",
        "Dusit Niyato",
        "Kaibin Huang",
        "Victor C. M. Leung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-15T06:16:26+00:00",
          "link": "https://arxiv.org/abs/2502.10687v1",
          "size": "2721kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T08:16:42+00:00",
          "link": "https://arxiv.org/abs/2502.10687v2",
          "size": "4145kb",
          "version": "v2"
        }
      ],
      "title": "Multi-objective Low-altitude IRS-assisted ISAC Optimization via Generative AI-enhanced Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10687",
        "HTML": "https://arxiv.org/html/2502.10687v2",
        "PDF": "https://arxiv.org/pdf/2502.10687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it applies generative AI techniques, the focus is on optimizing wireless network performance, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.00735",
      "abstract": "Dynamic metabolic control allows key metabolic fluxes to be modulated in real time, enhancing bioprocess flexibility and expanding available optimization degrees of freedom. This is achieved, e.g., via targeted modulation of metabolic enzyme expression. However, identifying optimal dynamic control policies is challenging due to the generally high-dimensional solution space and the need to manage metabolic burden and cytotoxic effects arising from inducible enzyme expression. The task is further complicated by stochastic dynamics, which reduce bioprocess reproducibility. We propose a reinforcement learning framework} to derive optimal policies by allowing an agent (the controller) to interact with a surrogate dynamic model. To promote robustness, we apply domain randomization, enabling the controller to generalize across uncertainties. When transferred to an experimental system, the agent can in principle continue fine-tuning the policy. Our framework provides an alternative to conventional model-based control such as model predictive control, which requires model differentiation with respect to decision variables; often impractical for complex stochastic, nonlinear, stiff, and piecewise-defined dynamics. In contrast, our approach relies on forward integration of the model, thereby simplifying the task. We demonstrate the framework in two $\\textit{Escherichia coli}$ bioprocesses: dynamic control of acetyl-CoA carboxylase for fatty-acid synthesis and of adenosine triphosphatase for lactate synthesis.",
      "authors": [
        "Sebasti\\'an Espinel-R\\'ios",
        "River Walser",
        "Dongda Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T12:47:05+00:00",
          "link": "https://arxiv.org/abs/2504.00735v1",
          "size": "2004kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T13:20:48+00:00",
          "link": "https://arxiv.org/abs/2504.00735v2",
          "size": "4182kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T06:08:07+00:00",
          "link": "https://arxiv.org/abs/2504.00735v3",
          "size": "4187kb",
          "version": "v3"
        }
      ],
      "title": "Reinforcement learning for robust dynamic metabolic control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00735",
        "PDF": "https://arxiv.org/pdf/2504.00735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a reinforcement learning framework for dynamic metabolic control, making no contribution to the processing or creation of LLM training data."
      },
      "tasks": [
        "Model Predictive Control",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09128",
      "abstract": "A modern paradigm for generalization in machine learning and AI consists of pre-training a task-agnostic foundation model, generally obtained using self-supervised and multimodal contrastive learning. The resulting representations can be used for prediction on a downstream task for which no labeled data is available. We present a theoretical framework to better understand this approach, called zero-shot prediction. We identify the target quantities that zero-shot prediction aims to learn, or learns in passing, and the key conditional independence relationships that enable its generalization ability.",
      "authors": [
        "Ronak Mehta",
        "Zaid Harchaoui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T03:37:57+00:00",
          "link": "https://arxiv.org/abs/2507.09128v1",
          "size": "3461kb",
          "version": "v1"
        }
      ],
      "title": "A Generalization Theory for Zero-Shot Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09128",
        "PDF": "https://arxiv.org/pdf/2507.09128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a theoretical framework for zero-shot prediction, dealing with generalization theory in machine learning without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09753",
      "abstract": "Deep generative models are increasingly used for molecular discovery, with most recent approaches relying on equivariant graph neural networks (GNNs) under the assumption that explicit equivariance is essential for generating high-quality 3D molecules. However, these models are complex, difficult to train, and scale poorly.\n  We investigate whether non-equivariant convolutional neural networks (CNNs) trained with rotation augmentations can learn equivariance and match the performance of equivariant models. We derive a loss decomposition that separates prediction error from equivariance error, and evaluate how model size, dataset size, and training duration affect performance across denoising, molecule generation, and property prediction. To our knowledge, this is the first study to analyze learned equivariance in generative tasks.",
      "authors": [
        "Ewa M. Nowara",
        "Joshua Rackers",
        "Patricia Suriana",
        "Pan Kessel",
        "Max Shen",
        "Andrew Martin Watkins",
        "Michael Maser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:16:11+00:00",
          "link": "https://arxiv.org/abs/2507.09753v1",
          "size": "5725kb",
          "version": "v1"
        }
      ],
      "title": "Do we need equivariant models for molecule generation?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09753",
        "HTML": "https://arxiv.org/html/2507.09753v1",
        "PDF": "https://arxiv.org/pdf/2507.09753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes equivariant models in molecule generation and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10250",
      "abstract": "Accurate and timely cancer diagnosis from histopathological slides is vital for effective clinical decision-making. This paper introduces DepViT-CAD, a deployable AI system for multi-class cancer diagnosis in histopathology. At its core is MAViT, a novel Multi-Attention Vision Transformer designed to capture fine-grained morphological patterns across diverse tumor types. MAViT was trained on expert-annotated patches from 1008 whole-slide images, covering 11 diagnostic categories, including 10 major cancers and non-tumor tissue. DepViT-CAD was validated on two independent cohorts: 275 WSIs from The Cancer Genome Atlas and 50 routine clinical cases from pathology labs, achieving diagnostic sensitivities of 94.11% and 92%, respectively. By combining state-of-the-art transformer architecture with large-scale real-world validation, DepViT-CAD offers a robust and scalable approach for AI-assisted cancer diagnostics. To support transparency and reproducibility, software and code will be made publicly available at GitHub.",
      "authors": [
        "Ashkan Shakarami",
        "Lorenzo Nicole",
        "Rocco Cappellesso",
        "Angelo Paolo Dei Tos",
        "and Stefano Ghidoni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:17:46+00:00",
          "link": "https://arxiv.org/abs/2507.10250v1",
          "size": "9930kb",
          "version": "v1"
        }
      ],
      "title": "DepViT-CAD: Deployable Vision Transformer-Based Cancer Diagnosis in Histopathology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10250",
        "HTML": "https://arxiv.org/html/2507.10250v1",
        "PDF": "https://arxiv.org/pdf/2507.10250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a Vision Transformer-based cancer diagnosis system and does not include methods for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10479",
      "abstract": "People with vision impairments (VIPs) often rely on their remaining vision when interacting with user interfaces. Simulating visual impairments is an effective tool for designers, fostering awareness of the challenges faced by VIPs. While previous research has introduced various vision impairment simulators, none have yet been developed with the direct involvement of VIPs or thoroughly evaluated from their perspective. To address this gap, we developed VIP-Sim. This symptom-based vision simulator was created through a participatory design process tailored explicitly for this purpose, involving N=7 VIPs. 21 symptoms, like field loss or light sensitivity, can be overlaid on desktop design tools. Most participants felt VIP-Sim could replicate their symptoms. VIP-Sim was received positively, but concerns about exclusion in design and comprehensiveness of the simulation remain, mainly whether it represents the experiences of other VIPs.",
      "authors": [
        "Max R\\\"adler",
        "Mark Colley",
        "and Enrico Rukzio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:57:29+00:00",
          "link": "https://arxiv.org/abs/2507.10479v1",
          "size": "20659kb",
          "version": "v1"
        }
      ],
      "title": "VIP-Sim: A User-Centered Approach to Vision Impairment Simulation for Accessible Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10479",
        "HTML": "https://arxiv.org/html/2507.10479v1",
        "PDF": "https://arxiv.org/pdf/2507.10479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores a simulator for vision impairments for interface design, developed with involvement from visually impaired people. It does not involve any processes related to LLM training data or its enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2110.14842",
      "abstract": "Distinguishability is fundamental to information theory and extends naturally to quantum systems. While quantum state discrimination is well understood, quantum channel discrimination remains challenging due to the dynamic nature of channels and the variety of discrimination strategies. This work advances the understanding of quantum channel discrimination and its fundamental limits. We develop new tools for quantum divergences, including sharper bounds on the quantum hypothesis testing relative entropy and additivity results for channel divergences. We establish a quantum Stein's lemma for memoryless channel discrimination, and link the strong converse property to the asymptotic equipartition property and continuity of divergences. Notably, we prove the equivalence of exponentially strong converse properties under coherent and sequential strategies. We further explore the interplay among operational regimes, discrimination strategies, and channel divergences, deriving exponents in various settings and contributing to a unified framework for channel discrimination. Finally, we recast quantum communication tasks as discrimination problems, uncovering deep connections between channel capacities, channel discrimination, and the mathematical structure of channel divergences. These results bridge two core areas of quantum information theory and offer new insights for future exploration.",
      "authors": [
        "Kun Fang",
        "Gilad Gour",
        "and Xin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2021-10-28T01:48:13+00:00",
          "link": "https://arxiv.org/abs/2110.14842v1",
          "size": "623kb",
          "version": "v1"
        },
        {
          "date": "2022-03-01T08:34:30+00:00",
          "link": "https://arxiv.org/abs/2110.14842v2",
          "size": "1353kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T21:40:44+00:00",
          "link": "https://arxiv.org/abs/2110.14842v3",
          "size": "1309kb",
          "version": "v3"
        }
      ],
      "title": "Towards the ultimate limits of quantum channel discrimination and quantum communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.14842",
        "HTML": "https://arxiv.org/html/2110.14842v3",
        "PDF": "https://arxiv.org/pdf/2110.14842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses quantum channel discrimination and quantum communication, with no focus on LLM training data processing or dataset creation processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07611",
      "abstract": "Interpretation is critical for disease diagnosis, but existing models struggle to balance predictive accuracy with human-understandable rationales. While large language models (LLMs) offer strong reasoning abilities, their clinical use is limited by high computational costs and restricted multimodal reasoning ability. Small language models (SLMs) are efficient but lack advanced reasoning for integrating multimodal medical data. In addition, both LLMs and SLMs lack domain knowledge for trustworthy reasoning. Therefore, we propose ClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via rationale distillation and domain knowledge injection for trustworthy multimodal rationale generation. Key innovations include a sequential rationale distillation framework that equips SLMs with LLM-comparable multimodal reasoning abilities, and a knowledge-augmented attention mechanism that jointly unifies multimodal representation from time series and textual data in the same encoding space, enabling it to be naturally interpreted by SLMs while incorporating domain knowledge for reliable rationale generation. Experiments on real-world medical datasets show that ClinRaGen achieves state-of-the-art performance in disease diagnosis and rationale generation, demonstrating the effectiveness of combining LLM-driven reasoning with knowledge augmentation for improved interpretability.",
      "authors": [
        "Shuai Niu",
        "Jing Ma",
        "Hongzhan Lin",
        "Liang Bai",
        "Zhihua Wang",
        "Yida Xu",
        "Yunya Song",
        "and Xian Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T07:34:56+00:00",
          "link": "https://arxiv.org/abs/2411.07611v1",
          "size": "4905kb",
          "version": "v1"
        },
        {
          "date": "2025-04-25T03:53:34+00:00",
          "link": "https://arxiv.org/abs/2411.07611v2",
          "size": "5357kb",
          "version": "v2"
        },
        {
          "date": "2025-04-28T03:28:51+00:00",
          "link": "https://arxiv.org/abs/2411.07611v3",
          "size": "5357kb",
          "version": "v3"
        },
        {
          "date": "2025-06-15T10:21:01+00:00",
          "link": "https://arxiv.org/abs/2411.07611v4",
          "size": "2600kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T10:35:58+00:00",
          "link": "https://arxiv.org/abs/2411.07611v5",
          "size": "2600kb",
          "version": "v5"
        }
      ],
      "title": "Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07611",
        "HTML": "https://arxiv.org/html/2411.07611v5",
        "PDF": "https://arxiv.org/pdf/2411.07611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on developing a model for clinical rationale generation using existing techniques like rationale distillation and attention mechanisms, with no emphasis on the processing of LLM training data."
      },
      "tasks": [
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09093",
      "abstract": "We study convergence in high-probability of SGD-type methods in non-convex optimization and the presence of heavy-tailed noise. To combat the heavy-tailed noise, a general black-box nonlinear framework is considered, subsuming nonlinearities like sign, clipping, normalization and their smooth counterparts. Our first result shows that nonlinear SGD (N-SGD) achieves the rate $\\widetilde{\\mathcal{O}}(t^{-1/2})$, for any noise with unbounded moments and a symmetric probability density function (PDF). Crucially, N-SGD has exponentially decaying tails, matching the performance of linear SGD under light-tailed noise. To handle non-symmetric noise, we propose two novel estimators, based on the idea of noise symmetrization. The first, dubbed Symmetrized Gradient Estimator (SGE), assumes a noiseless gradient at any reference point is available at the start of training, while the second, dubbed Mini-batch SGE (MSGE), uses mini-batches to estimate the noiseless gradient. Combined with the nonlinear framework, we get N-SGE and N-MSGE methods, respectively, both achieving the same convergence rate and exponentially decaying tails as N-SGD, while allowing for non-symmetric noise with unbounded moments and PDF satisfying a mild technical condition, with N-MSGE additionally requiring bounded noise moment of order $p \\in (1,2]$. Compared to works assuming noise with bounded $p$-th moment, our results: 1) are based on a novel symmetrization approach; 2) provide a unified framework and relaxed moment conditions; 3) imply optimal oracle complexity of N-SGD and N-SGE, strictly better than existing works when $p < 2$, while the complexity of N-MSGE is close to existing works. Compared to works assuming symmetric noise with unbounded moments, we: 1) provide a sharper analysis and improved rates; 2) facilitate state-dependent symmetric noise; 3) extend the strong guarantees to non-symmetric noise.",
      "authors": [
        "Aleksandar Armacki",
        "Dragana Bajovic",
        "Dusan Jakovetic",
        "Soummya Kar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:31:13+00:00",
          "link": "https://arxiv.org/abs/2507.09093v1",
          "size": "243kb",
          "version": "v1"
        }
      ],
      "title": "Optimal High-probability Convergence of Nonlinear SGD under Heavy-tailed Noise via Symmetrization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09093",
        "HTML": "https://arxiv.org/html/2507.09093v1",
        "PDF": "https://arxiv.org/pdf/2507.09093"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses convergence issues in non-convex optimization scenarios with heavy-tailed noise in SGD methods, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09185",
      "abstract": "Large language models (LLMs) often develop learned mechanisms specialized to specific datasets, such as reliance on domain-specific correlations, which yield high-confidence predictions without generalizable reasoning. While beneficial in one setting, these dataset-specific mechanisms typically degrade performance when models encounter novel tasks or distributions. In this work, we introduce a fine-tuning approach designed to enhance generalization by identifying and pruning neurons associated with dataset-specific mechanisms in transformer-based LLMs. Our method employs Integrated Gradients to quantify each neuron's influence on high-confidence predictions, pinpointing those that disproportionately contribute to dataset-specific performance without supporting robust, transferable reasoning. Selectively pruning these neurons compels the model to depend on generalizable representations. Evaluated across multiple-choice benchmarks, our pruning-based fine-tuning significantly enhances performance, surpassing prior (non-pruning) adaptation methods.",
      "authors": [
        "Ameen Ali",
        "Shahar Katz",
        "Lior Wolf and Ivan Titov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:10:10+00:00",
          "link": "https://arxiv.org/abs/2507.09185v1",
          "size": "98kb",
          "version": "v1"
        }
      ],
      "title": "Detecting and Pruning Prominent but Detrimental Neurons in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09185",
        "PDF": "https://arxiv.org/pdf/2507.09185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a neuron pruning technique in LLMs to enhance generalization. Although it involves fine-tuning, it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09266",
      "abstract": "Gloss-free Sign Language Translation (SLT) has advanced rapidly, achieving strong performances without relying on gloss annotations. However, these gains have often come with increased model complexity and high computational demands, raising concerns about scalability, especially as large-scale sign language datasets become more common. We propose a segment-aware visual tokenization framework that leverages sign segmentation to convert continuous video into discrete, sign-informed visual tokens. This reduces input sequence length by up to 50% compared to prior methods, resulting in up to 2.67x lower memory usage and better scalability on larger datasets. To bridge the visual and linguistic modalities, we introduce a token-to-token contrastive alignment objective, along with a dual-level supervision that aligns both language embeddings and intermediate hidden states. This improves fine-grained cross-modal alignment without relying on gloss-level supervision. Our approach notably exceeds the performance of state-of-the-art methods on the PHOENIX14T benchmark, while significantly reducing sequence length. Further experiments also demonstrate our improved performance over prior work under comparable sequence-lengths, validating the potential of our tokenization and alignment strategies.",
      "authors": [
        "JianHe Low",
        "Ozge Mercanoglu Sincan",
        "Richard Bowden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T12:18:34+00:00",
          "link": "https://arxiv.org/abs/2507.09266v1",
          "size": "9566kb",
          "version": "v1"
        }
      ],
      "title": "SAGE: Segment-Aware Gloss-Free Encoding for Token-Efficient Sign Language Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09266",
        "HTML": "https://arxiv.org/html/2507.09266v1",
        "PDF": "https://arxiv.org/pdf/2507.09266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a segment-aware visual tokenization framework for sign language translation, which reduces input sequence length, but the primary focus is on improving computational efficiency and cross-modal alignment rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09274",
      "abstract": "We consider a test problem for Navier-Stokes solvers based on the flow around a cylinder at Reynolds numbers 500 and 1000, where the solution is observed to be periodic when the problem is sufficiently resolved. Computing the resulting flow is a challenge, even for exactly divergence-free discretization methods, when the scheme does not include sufficient numerical dissipation. We examine the performance of the energy, momentum and angular momentum conserving (EMAC) formulation of the Navier-Stokes equations. This incorporates more physical conservation into the finite element method even when the numerical solution is not exactly divergence-free. Consequently, it has a chance to outperform standard methods, especially for long-time simulations. We find that for lowest-order Taylor-Hood elements, EMAC outperforms the standard convective formulations. However, for higher-order elements, EMAC can become unstable on under-resolved meshes.",
      "authors": [
        "Henry von Wahl and Leo G. Rebholz and L. Ridgway Scott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:03:25+00:00",
          "link": "https://arxiv.org/abs/2507.09274v1",
          "size": "4548kb",
          "version": "v1"
        }
      ],
      "title": "Benchmark stress tests for flow past a cylinder at higher Reynolds numbers using EMAC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09274",
        "HTML": "https://arxiv.org/html/2507.09274v1",
        "PDF": "https://arxiv.org/pdf/2507.09274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines numerical methods for Navier-Stokes equations and does not address LLM training data processing, collection, or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09367",
      "abstract": "As cities evolve toward more complex and multimodal transportation systems, the need for human-centered multi-agent simulation tools has never been more urgent. Yet most existing platforms remain limited - they often separate different types of road users, rely on scripted or pre-defined behaviors, overlook public transit users as active participants, and are rarely designed with accessibility in mind for non-technical users. To address this gap, this paper presents the specifications of a multi-agent simulation platform designed to support real-time, human-centered, and immersive studies of all road users, accompanied by open-source scripts for replication. Using high-fidelity immersive virtual environments, our platform enables interaction across public transit users, pedestrians, cyclists, automated vehicles, and drivers. The architecture is modular, extensible, and designed for accessibility. The system integrates hardware-specific modules - including an omnidirectional treadmill, a seating arrangement, a smart trainer, and an actuated cockpit. Additionally, the platform collects multimodal physiological, neurological, and behavioral data through embedded sensing devices such as functional near-infrared spectroscopy (fNIRS), eye tracking, and wrist-based biosensors. To show the usability of this system, we present three use cases. Simulation for All aims to lower the barrier to entry for high-fidelity transportation simulation, support experimentation across disciplines, and advance our understanding of multimodal mobility in complex urban environments.",
      "authors": [
        "Shiva Azimi (1)",
        "Arash Tavakoli (1) ((1) Villanova University",
        "USA)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:07:19+00:00",
          "link": "https://arxiv.org/abs/2507.09367v1",
          "size": "36246kb",
          "version": "v1"
        }
      ],
      "title": "Simulation for All: A Step-by-Step Cookbook for Developing Human-Centered Multi-Agent Transportation Simulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09367",
        "HTML": "https://arxiv.org/html/2507.09367v1",
        "PDF": "https://arxiv.org/pdf/2507.09367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a multi-agent transportation simulator platform, focusing on simulation and data collection, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09624",
      "abstract": "Driving trajectory data remains vulnerable to privacy breaches despite existing mitigation measures. Traditional methods for detecting driving trajectories typically rely on map-matching the path using Global Positioning System (GPS) data, which is susceptible to GPS data outage. This paper introduces CAN-Trace, a novel privacy attack mechanism that leverages Controller Area Network (CAN) messages to uncover driving trajectories, posing a significant risk to drivers' long-term privacy. A new trajectory reconstruction algorithm is proposed to transform the CAN messages, specifically vehicle speed and accelerator pedal position, into weighted graphs accommodating various driving statuses. CAN-Trace identifies driving trajectories using graph-matching algorithms applied to the created graphs in comparison to road networks. We also design a new metric to evaluate matched candidates, which allows for potential data gaps and matching inaccuracies. Empirical validation under various real-world conditions, encompassing different vehicles and driving regions, demonstrates the efficacy of CAN-Trace: it achieves an attack success rate of up to 90.59% in the urban region, and 99.41% in the suburban region.",
      "authors": [
        "Xiaojie Lin",
        "Baihe Ma",
        "Xu Wang",
        "Guangsheng Yu",
        "Ying He",
        "Wei Ni and Ren Ping Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T13:31:07+00:00",
          "link": "https://arxiv.org/abs/2507.09624v1",
          "size": "17045kb",
          "version": "v1"
        }
      ],
      "title": "CAN-Trace Attack: Exploit CAN Messages to Uncover Driving Trajectories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09624",
        "HTML": "https://arxiv.org/html/2507.09624v1",
        "PDF": "https://arxiv.org/pdf/2507.09624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy attacks using CAN messages in the context of driving trajectories, with no mention of LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09880",
      "abstract": "Understanding dynamic 3D human representation has become increasingly critical in virtual and extended reality applications. However, existing human part segmentation methods are constrained by reliance on closed-set datasets and prolonged inference times, which significantly restrict their applicability. In this paper, we introduce the first 4D human parsing framework that simultaneously addresses these challenges by reducing the inference time and introducing open-vocabulary capabilities. Building upon state-of-the-art open-vocabulary 3D human parsing techniques, our approach extends the support to 4D human-centric video with three key innovations: 1) We adopt mask-based video object tracking to efficiently establish spatial and temporal correspondences, avoiding the necessity of segmenting all frames. 2) A novel Mask Validation module is designed to manage new target identification and mitigate tracking failures. 3) We propose a 4D Mask Fusion module, integrating memory-conditioned attention and logits equalization for robust embedding fusion. Extensive experiments demonstrate the effectiveness and flexibility of the proposed method on 4D human-centric parsing tasks, achieving up to 93.3% acceleration compared to the previous state-of-the-art method, which was limited to parsing fixed classes.",
      "authors": [
        "Keito Suzuki",
        "Bang Du",
        "Runfa Blark Li",
        "Kunyao Chen",
        "Lei Wang",
        "Peng Liu",
        "Ning Bi",
        "Truong Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:35:06+00:00",
          "link": "https://arxiv.org/abs/2507.09880v1",
          "size": "9792kb",
          "version": "v1"
        }
      ],
      "title": "OpenHuman4D: Open-Vocabulary 4D Human Parsing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09880",
        "HTML": "https://arxiv.org/html/2507.09880v1",
        "PDF": "https://arxiv.org/pdf/2507.09880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a 4D human parsing framework with new techniques for video processing, but does not primarily focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10329",
      "abstract": "Let $\\Omega_1, \\ldots, \\Omega_m$ be probability spaces, let $\\Omega=\\Omega_1 \\times \\cdots \\times \\Omega_m$ be their product and let $A_1, \\ldots, A_n \\subset \\Omega$ be events. Suppose that each event $A_i$ depends on $r_i$ coordinates of a point $x \\in \\Omega$, $x=\\left(\\xi_1, \\ldots, \\xi_m\\right)$, and that for each event $A_i$ there are $\\Delta_i$ of other events $A_j$ that depend on some of the coordinates that $A_i$ depends on. Let $\\Delta=\\max\\{5,\\ \\Delta_i: i=1, \\ldots, n\\}$ and let $\\mu_i=\\min\\{r_i,\\ \\Delta_i+1\\}$ for $i=1, \\ldots, n$. We prove that if $P(A_i) < (3\\Delta)^{-3\\mu_i}$ for all $I$, then for any $0 < \\epsilon < 1$, the probability $P\\left( \\bigcap_{i=1}^n \\overline{A}_i\\right)$ of the intersection of the complements of all $A_i$ can be computed within relative error $\\epsilon$ in polynomial time from the probabilities $P\\left(A_{i_1} \\cap \\ldots \\cap A_{i_k}\\right)$ of $k$-wise intersections of the events $A_i$ for $k = e^{O(\\Delta)} \\ln (n/\\epsilon)$.",
      "authors": [
        "Alexander Barvinok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:38:31+00:00",
          "link": "https://arxiv.org/abs/2507.10329v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Computing the probability of intersection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10329",
        "HTML": "https://arxiv.org/html/2507.10329v1",
        "PDF": "https://arxiv.org/pdf/2507.10329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the computation of intersection probabilities in probability spaces, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10463",
      "abstract": "Escalating artificial intelligence (AI) demands expose a critical \"compute crisis\" characterized by unsustainable energy consumption, prohibitive training costs, and the approaching limits of conventional CMOS scaling. Physics-based Application-Specific Integrated Circuits (ASICs) present a transformative paradigm by directly harnessing intrinsic physical dynamics for computation rather than expending resources to enforce idealized digital abstractions. By relaxing the constraints needed for traditional ASICs, like enforced statelessness, unidirectionality, determinism, and synchronization, these devices aim to operate as exact realizations of physical processes, offering substantial gains in energy efficiency and computational throughput. This approach enables novel co-design strategies, aligning algorithmic requirements with the inherent computational primitives of physical systems. Physics-based ASICs could accelerate critical AI applications like diffusion models, sampling, optimization, and neural network inference as well as traditional computational workloads like scientific simulation of materials and molecules. Ultimately, this vision points towards a future of heterogeneous, highly-specialized computing platforms capable of overcoming current scaling bottlenecks and unlocking new frontiers in computational power and efficiency.",
      "authors": [
        "Maxwell Aifer",
        "Zach Belateche",
        "Suraj Bramhavar",
        "Kerem Y. Camsari",
        "Patrick J. Coles",
        "Gavin Crooks",
        "Douglas J. Durian",
        "Andrea J. Liu",
        "Anastasia Marchenkova",
        "Antonio J. Martinez",
        "Peter L. McMahon",
        "Faris Sbahi",
        "Benjamin Weiner",
        "Logan G. Wright"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:40:37+00:00",
          "link": "https://arxiv.org/abs/2507.10463v1",
          "size": "1945kb",
          "version": "v1"
        }
      ],
      "title": "Solving the compute crisis with physics-based ASICs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10463",
        "HTML": "https://arxiv.org/html/2507.10463v1",
        "PDF": "https://arxiv.org/pdf/2507.10463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of physics-based ASICs for compute efficiency and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.10502",
      "abstract": "The fitness level method is a widely used technique for estimating the mean hitting time of elitist evolutionary algorithms on level-based fitness functions. However, this paper identifies its main limitation: the linear lower bound derived from traditional fitness level partitioning is not tight when applied to many non-level-based fitness functions. A new subset level method is introduced to address this limitation. It selects a subset of non-optimal solutions, partitions them into levels, and then estimates linear bound coefficients based on drift analysis. Explicit expressions are proposed to compute the lower bound on the mean hitting time of elitist evolutionary algorithms. The proposed method is validated using six instances of the knapsack problem. Results show that the new method can be used to quickly estimate the lower bound on the mean hitting time of elitist evolutionary algorithms. This expands the application scope of the fitness level method to non-level-based functions.",
      "authors": [
        "Jun He",
        "Siang Yew Chong and Xin Yao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-17T13:04:42+00:00",
          "link": "https://arxiv.org/abs/2311.10502v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2024-05-16T15:41:44+00:00",
          "link": "https://arxiv.org/abs/2311.10502v2",
          "size": "55kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T20:59:57+00:00",
          "link": "https://arxiv.org/abs/2311.10502v3",
          "size": "123kb",
          "version": "v3"
        }
      ],
      "title": "Fast Estimations of Hitting Time of Elitist Evolutionary Algorithms from Fitness Levels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.10502",
        "HTML": "https://arxiv.org/html/2311.10502v3",
        "PDF": "https://arxiv.org/pdf/2311.10502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with evaluating hitting times of evolutionary algorithms, with no focus on LLM training data processing or dataset engineering."
      },
      "tasks": [
        "Evolutionary Algorithms"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13355",
      "abstract": "Measurements acquired from distributed physical systems are often sparse and noisy. Therefore, signal processing and system identification tools are required to mitigate noise effects and reconstruct unobserved dynamics from limited sensor data. However, this process is particularly challenging because the fundamental equations governing the dynamics are largely unavailable in practice. Reservoir Computing (RC) techniques have shown promise in efficiently simulating dynamical systems through an unstructured and efficient computation graph comprising a set of neurons with random connectivity. However, the potential of RC to operate in noisy regimes and distinguish noise from the primary smooth or non-smooth deterministic dynamics of the system has not been fully explored. This paper presents a novel RC method for noise filtering and reconstructing unobserved nonlinear dynamics, offering a novel learning protocol associated with hyperparameter optimization. The performance of the RC in terms of noise intensity, noise frequency content, and drastic shifts in dynamical parameters is studied in two illustrative examples involving the nonlinear dynamics of the Lorenz attractor and the adaptive exponential integrate-and-fire system. It is demonstrated that denoising performance improves by truncating redundant nodes and edges of the reservoir, as well as by properly optimizing hyperparameters, such as the leakage rate, spectral radius, input connectivity, and ridge regression parameter. Furthermore, the presented framework shows good generalization behavior when tested for reconstructing unseen and qualitatively different attractors. Compared to the extended Kalman filter, the presented RC framework yields competitive accuracy at low signal-to-noise ratios and high-frequency ranges.",
      "authors": [
        "Omid Sedehi",
        "Manish Yadav",
        "Merten Stender",
        "Sebastian Oberst"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T21:47:13+00:00",
          "link": "https://arxiv.org/abs/2504.13355v1",
          "size": "7367kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T10:44:18+00:00",
          "link": "https://arxiv.org/abs/2504.13355v2",
          "size": "4866kb",
          "version": "v2"
        }
      ],
      "title": "Denoising and Reconstruction of Nonlinear Dynamics using Truncated Reservoir Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13355",
        "HTML": "https://arxiv.org/html/2504.13355v2",
        "PDF": "https://arxiv.org/pdf/2504.13355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reservoir computing techniques for noise filtering and dynamic reconstruction in nonlinear systems, with no mention of LLM training data processing or dataset creation."
      },
      "tasks": [
        "Denoising",
        "Hyperparameter Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16790",
      "abstract": "Masked diffusion models (MDMs) have achieved notable progress in modeling discrete data, while their potential in molecular generation remains underexplored. In this work, we explore their potential and introduce the surprising result that naively applying standards MDMs severely degrades the performance. We identify the critical cause of this issue as a state-clashing problem-where the forward diffusion of distinct molecules collapse into a common state, resulting in a mixture of reconstruction targets that cannot be learned using typical reverse diffusion process with unimodal predictions. To mitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that orchestrates per-element corruption trajectories to avoid collision between distinct molecular graphs. This is achieved through a parameterized noise scheduling network that assigns distinct corruption rates to individual graph elements, i.e., atoms and bonds. Extensive experiments on diverse molecular benchmarks reveal that MELD markedly enhances overall generation quality compared to element-agnostic noise scheduling, increasing the chemical validity of vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves state-of-the-art property alignment in conditional generation tasks.",
      "authors": [
        "Hyunjin Seo",
        "Taewon Kim",
        "Sihyun Yu",
        "SungSoo Ahn"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T15:30:17+00:00",
          "link": "https://arxiv.org/abs/2505.16790v1",
          "size": "1956kb",
          "version": "v1"
        },
        {
          "date": "2025-05-25T16:59:38+00:00",
          "link": "https://arxiv.org/abs/2505.16790v2",
          "size": "1956kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T14:11:54+00:00",
          "link": "https://arxiv.org/abs/2505.16790v3",
          "size": "1956kb",
          "version": "v3"
        }
      ],
      "title": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16790",
        "HTML": "https://arxiv.org/html/2505.16790v3",
        "PDF": "https://arxiv.org/pdf/2505.16790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with molecular diffusion models and their performance, unrelated to LLM training data processing or datasets creation."
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04462",
      "abstract": "Watermarking techniques for large language models (LLMs) can significantly impact output quality, yet their effects on truthfulness, safety, and helpfulness remain critically underexamined. This paper presents a systematic analysis of how two popular watermarking approaches-Gumbel and KGW-affect these core alignment properties across four aligned LLMs. Our experiments reveal two distinct degradation patterns: guard attenuation, where enhanced helpfulness undermines model safety, and guard amplification, where excessive caution reduces model helpfulness. These patterns emerge from watermark-induced shifts in token distribution, surfacing the fundamental tension that exists between alignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an inference-time sampling method that uses an external reward model to restore alignment. We establish a theoretical lower bound on the improvement in expected reward score as the sample size is increased and empirically demonstrate that sampling just 2-4 watermarked generations effectively recovers or surpasses baseline (unwatermarked) alignment scores. To overcome the limited response diversity of standard Gumbel watermarking, our modified implementation sacrifices strict distortion-freeness while maintaining robust detectability, ensuring compatibility with AR. Experimental results confirm that AR successfully recovers baseline alignment in both watermarking approaches, while maintaining strong watermark detectability. This work reveals the critical balance between watermark strength and model alignment, providing a simple inference-time solution to responsibly deploy watermarked LLMs in practice.",
      "authors": [
        "Apurv Verma",
        "NhatHai Phan",
        "Shubhendu Trivedi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T21:29:07+00:00",
          "link": "https://arxiv.org/abs/2506.04462v1",
          "size": "4654kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:50:21+00:00",
          "link": "https://arxiv.org/abs/2506.04462v2",
          "size": "4848kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T16:50:20+00:00",
          "link": "https://arxiv.org/abs/2506.04462v3",
          "size": "4654kb",
          "version": "v3"
        }
      ],
      "title": "Watermarking Degrades Alignment in Language Models: Analysis and Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04462",
        "PDF": "https://arxiv.org/pdf/2506.04462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the impact of watermarking on alignment in language models and introduces a method to address alignment issues at inference time, without focusing on processing, creating, or enhancing training data for LLMs."
      },
      "tasks": [
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/dapurv5/alignmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08952",
      "abstract": "Introduction: Chest CT scans are increasingly used in dyspneic patients where acute heart failure (AHF) is a key differential diagnosis. Interpretation remains challenging and radiology reports are frequently delayed due to a radiologist shortage, although flagging such information for emergency physicians would have therapeutic implication. Artificial intelligence (AI) can be a complementary tool to enhance the diagnostic precision. We aim to develop an explainable AI model to detect radiological signs of AHF in chest CT with an accuracy comparable to thoracic radiologists.\n  Methods: A single-center, retrospective study during 2016-2021 at Copenhagen University Hospital - Bispebjerg and Frederiksberg, Denmark. A Boosted Trees model was trained to predict AHF based on measurements of segmented cardiac and pulmonary structures from acute thoracic CT scans. Diagnostic labels for training and testing were extracted from radiology reports. Structures were segmented with TotalSegmentator. Shapley Additive explanations values were used to explain the impact of each measurement on the final prediction.\n  Results: Of the 4,672 subjects, 49% were female. The final model incorporated twelve key features of AHF and achieved an area under the ROC of 0.87 on the independent test set. Expert radiologist review of model misclassifications found that 24 out of 64 (38%) false positives and 24 out of 61 (39%) false negatives were actually correct model predictions, with the errors originating from inaccuracies in the initial radiology reports.\n  Conclusion: We developed an explainable AI model with strong discriminatory performance, comparable to thoracic radiologists. The AI model's stepwise, transparent predictions may support decision-making.",
      "authors": [
        "Silas Nyboe {\\O}rting",
        "Kristina Miger",
        "Anne Sophie Overgaard Olesen",
        "Mikael Ploug Boesen",
        "Michael Brun Andersen",
        "Jens Petersen",
        "Olav W. Nielsen and Marleen de Bruijne"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:25:34+00:00",
          "link": "https://arxiv.org/abs/2507.08952v1",
          "size": "1774kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable Artificial Intelligence for Detecting Acute Heart Failure on Acute Chest CT Scans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08952",
        "PDF": "https://arxiv.org/pdf/2507.08952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about developing an AI model for detecting heart failure from CT scans and does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10324",
      "abstract": "Interaction-Oriented Programming (IOP) is an approach to building a multiagent system by modeling the interactions between its roles via a flexible interaction protocol and implementing agents to realize the interactions of the roles they play in the protocol.\n  In recent years, we have developed an extensive suite of software that enables multiagent system developers to apply IOP. These include tools for efficiently verifying protocols for properties such as liveness and safety and middleware that simplifies the implementation of agents. This paper presents some of that software suite.",
      "authors": [
        "Amit K. Chopra and Samuel H. Christie V and Munindar P. Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:32:09+00:00",
          "link": "https://arxiv.org/abs/2507.10324v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Toolsuite for Implementing Multiagent Systems Based on Communication Protocols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10324",
        "HTML": "https://arxiv.org/html/2507.10324v1",
        "PDF": "https://arxiv.org/pdf/2507.10324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on software and tool development for multiagent systems with regard to communication protocols, not on LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10425",
      "abstract": "Conformal prediction is a distribution-free uncertainty quantification method that has gained popularity in the machine learning community due to its finite-sample guarantees and ease of use. Its most common variant, dubbed split conformal prediction, is also computationally efficient as it boils down to collecting statistics of the model predictions on some calibration data not yet seen by the model. Nonetheless, these guarantees only hold if the calibration and test data are exchangeable, a condition that is difficult to verify and often violated in practice due to so-called distribution shifts. The literature is rife with methods to mitigate the loss in coverage in this non-exchangeable setting, but these methods require some prior information on the type of distribution shift to be expected at test time. In this work, we study this problem via a new perspective, through the lens of optimal transport, and show that it is possible to estimate the loss in coverage and mitigate it in case of distribution shift.",
      "authors": [
        "Alvaro H.C. Correia",
        "Christos Louizos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:10:55+00:00",
          "link": "https://arxiv.org/abs/2507.10425v1",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "title": "Non-exchangeable Conformal Prediction with Optimal Transport: Tackling Distribution Shifts with Unlabeled Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10425",
        "HTML": "https://arxiv.org/html/2507.10425v1",
        "PDF": "https://arxiv.org/pdf/2507.10425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses non-exchangeable conformal prediction and distribution shifts, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.00574",
      "abstract": "Long-context video modeling is critical for multimodal large language models (MLLMs), enabling them to process movies, online video streams, and so on. Despite its advances, handling long videos remains challenging due to the difficulty in efficiently understanding the extremely long video context. This paper aims to address this issue from aspects of model architecture, training data, training strategy and evaluation benchmark. First, we propose a novel Hierarchical video token Compression (HiCo) method, which leverages visual redundancy in long videos to compress long video context from Clip-level to Video-level, reducing the computation significantly while preserving essential details, achieving an extreme compression ratio of approximately 1/50 with almost no performance loss. Second, we introduce a multi-stage short-to-long learning scheme, a large-scale dataset of real-world long videos named LongVid, and a challenging ``Multi-Hop Needle-In-A-Video-Haystack'' benchmark. Finally, we build a powerful video MLLM named VideoChat-Flash, which shows a leading performance on both mainstream long and short video benchmarks at the 2B and 7B model scale. It first gets 99.1% accuracy over 10,000 frames in NIAH among open-source models.",
      "authors": [
        "Xinhao Li",
        "Yi Wang",
        "Jiashuo Yu",
        "Xiangyu Zeng",
        "Yuhan Zhu",
        "Haian Huang",
        "Jianfei Gao",
        "Kunchang Li",
        "Yinan He",
        "Chenting Wang",
        "Yu Qiao",
        "Yali Wang",
        "Limin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T18:01:23+00:00",
          "link": "https://arxiv.org/abs/2501.00574v1",
          "size": "1070kb",
          "version": "v1"
        },
        {
          "date": "2025-01-10T12:00:51+00:00",
          "link": "https://arxiv.org/abs/2501.00574v2",
          "size": "1490kb",
          "version": "v2"
        },
        {
          "date": "2025-03-09T07:32:35+00:00",
          "link": "https://arxiv.org/abs/2501.00574v3",
          "size": "5034kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T16:21:16+00:00",
          "link": "https://arxiv.org/abs/2501.00574v4",
          "size": "5034kb",
          "version": "v4"
        }
      ],
      "title": "VideoChat-Flash: Hierarchical Compression for Long-Context Video Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00574",
        "HTML": "https://arxiv.org/html/2501.00574v4",
        "PDF": "https://arxiv.org/pdf/2501.00574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on video token compression and improving model architecture and evaluation for long-context video modeling, without substantial focus on LLM training data processing or new dataset creation."
      },
      "models": [
        {
          "model_path": "OpenGVLab/VideoChat-Flash-Qwen2_5-2B_res448",
          "downloads": "1235",
          "likes": "23",
          "trending_score": "1.0",
          "link": "https://huggingface.co/OpenGVLab/VideoChat-Flash-Qwen2_5-2B_res448"
        },
        {
          "model_path": "OpenGVLab/VideoChat-Flash-Qwen2-7B_res224",
          "downloads": "59",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/VideoChat-Flash-Qwen2-7B_res224"
        },
        {
          "model_path": "OpenGVLab/VideoChat-Flash-Qwen2-7B_res448",
          "downloads": "2242",
          "likes": "12",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/VideoChat-Flash-Qwen2-7B_res448"
        },
        {
          "model_path": "OpenGVLab/InternVL_2_5_HiCo_R16",
          "downloads": "4433",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/InternVL_2_5_HiCo_R16"
        },
        {
          "model_path": "OpenGVLab/InternVL_2_5_HiCo_R64",
          "downloads": "581",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/InternVL_2_5_HiCo_R64"
        },
        {
          "model_path": "OpenGVLab/VideoChat-Flash-Qwen2_5-7B_InternVideo2-1B",
          "downloads": "168",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/VideoChat-Flash-Qwen2_5-7B_InternVideo2-1B"
        },
        {
          "model_path": "OpenGVLab/VideoChat-Flash-Qwen2_5-7B-1M_res224",
          "downloads": "58",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/VideoChat-Flash-Qwen2_5-7B-1M_res224"
        },
        {
          "model_path": "FriendliAI/InternVL_2_5_HiCo_R16",
          "downloads": "24",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/FriendliAI/InternVL_2_5_HiCo_R16"
        },
        {
          "model_path": "MInference/videochat",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/MInference/videochat"
        }
      ],
      "datasets": [
        {
          "dataset_name": "OpenGVLab/VideoChat-Flash-Training-Data",
          "downloads": "129287",
          "likes": "10",
          "link": "https://huggingface.co/datasets/OpenGVLab/VideoChat-Flash-Training-Data"
        }
      ],
      "tasks": [
        "Memorization"
      ],
      "repo_urls": [
        "https://github.com/opengvlab/videochat-flash",
        "https://github.com/opengvlab/internvideo2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.21291",
      "abstract": "Despite significant progress in diffusion-based image generation, subject-driven generation and instruction-based editing remain challenging. Existing methods typically treat them separately, struggling with limited high-quality data and poor generalization. However, both tasks require capturing complex visual variations while maintaining consistency between inputs and outputs. Inspired by this, we propose MIGE, a unified framework that standardizes task representations using multimodal instructions. It first treats subject-driven generation as creation on a blank canvas and instruction-based editing as modification of an existing image, establishing a shared input-output formulation, then introduces a novel multimodal encoder that maps free-form multimodal instructions into a unified vision-language space, integrating visual and semantic features through a feature fusion mechanism. This unification enables joint training of both tasks, providing two key advantages: (1) Cross-Task Enhancement: by leveraging shared visual and semantic representations, joint training improves instruction adherence and visual consistency in both subject-driven generation and instruction-based editing. (2) Generalization: learning in a unified format facilitates cross-task knowledge transfer, enabling MIGE to generalize to novel compositional tasks, including instruction-based subject-driven editing. Experiments show that MIGE excels in both subject-driven generation and instruction-based editing while setting a SOTA in the new task of instruction-based subject-driven editing. Code and model have been publicly available at https://github.com/Eureka-Maggie/MIGE/tree/main.",
      "authors": [
        "Xueyun Tian",
        "Wei Li",
        "Bingbing Xu",
        "Yige Yuan",
        "Yuanzhuo Wang",
        "Huawei Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T18:21:08+00:00",
          "link": "https://arxiv.org/abs/2502.21291v1",
          "size": "22429kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T11:33:31+00:00",
          "link": "https://arxiv.org/abs/2502.21291v2",
          "size": "22429kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T13:33:09+00:00",
          "link": "https://arxiv.org/abs/2502.21291v3",
          "size": "19137kb",
          "version": "v3"
        }
      ],
      "title": "MIGE: Mutually Enhanced Multimodal Instruction-Based Image Generation and Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.21291",
        "HTML": "https://arxiv.org/html/2502.21291v3",
        "PDF": "https://arxiv.org/pdf/2502.21291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for image generation and editing, with no focus on LLM training data processing or dataset creation."
      },
      "models": [
        {
          "model_path": "EurekaTian/MIGE",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/EurekaTian/MIGE"
        }
      ],
      "datasets": [
        {
          "dataset_name": "EurekaTian/MIGEBench",
          "downloads": "10",
          "likes": "0",
          "link": "https://huggingface.co/datasets/EurekaTian/MIGEBench"
        },
        {
          "dataset_name": "EurekaTian/MIGE_train_sub_edit",
          "downloads": "23",
          "likes": "0",
          "link": "https://huggingface.co/datasets/EurekaTian/MIGE_train_sub_edit"
        }
      ],
      "tasks": [
        "Image Generation",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/eureka-maggie/mige"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07426",
      "abstract": "Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery.",
      "authors": [
        "Zerui Yang and Yuwei Wan and Yinqiao Li and Yudai Matsuda and Tong Xie and Linqi Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:39:55+00:00",
          "link": "https://arxiv.org/abs/2507.07426v1",
          "size": "950kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:20:44+00:00",
          "link": "https://arxiv.org/abs/2507.07426v2",
          "size": "950kb",
          "version": "v2"
        }
      ],
      "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07426",
        "HTML": "https://arxiv.org/html/2507.07426v2",
        "PDF": "https://arxiv.org/pdf/2507.07426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for drug repurposing using LLMs but does not involve LLM training data processing or creation activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09024",
      "abstract": "Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets. CNeuroMod-THINGS meets this need by capturing neural representations for a wide set of semantic concepts using well-characterized stimuli in a new densely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS exploits synergies between two existing projects: the THINGS initiative (THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has developed a common set of thoroughly annotated images broadly sampling natural and man-made objects which is used to acquire a growing collection of large-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring hundreds of hours of fMRI data from a core set of participants during controlled and naturalistic tasks, including visual tasks like movie watching and videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each completed 33-36 sessions of a continuous recognition paradigm using approximately 4000 images from the THINGS stimulus set spanning 720 categories. We report behavioural and neuroimaging metrics that showcase the quality of the data. By bridging together large existing resources, CNeuroMod-THINGS expands our capacity to model broad slices of the human visual experience.",
      "authors": [
        "Marie St-Laurent",
        "Basile Pinsard",
        "Oliver Contier",
        "Elizabeth DuPre",
        "Katja Seeliger",
        "Valentina Borghesani",
        "Julie A. Boyle",
        "Lune Bellec",
        "Martin N. Hebart"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:16:59+00:00",
          "link": "https://arxiv.org/abs/2507.09024v1",
          "size": "17450kb",
          "version": "v1"
        }
      ],
      "title": "CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09024",
        "PDF": "https://arxiv.org/pdf/2507.09024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a neuroimaging dataset for visual neuroscience and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09599",
      "abstract": "This paper provides a precise and scientific definition of complexity and coupling, grounded in the functional domain, particularly within industrial control and automation systems (iCAS). We highlight the widespread ambiguity in defining complexity and coupling, emphasizing that many existing definitions rooted in physical attributes lead to confusion and inconsistencies. Furthermore, we re-exhibit why coupled design inherently increases complexity and how potentially this complexity could be reduced. Drawing on examples from various disciplines, such as software engineering, industrial automation, and mechanical design, we demonstrate that complexity does not necessarily correlate with system size or the number of components, and coupling, unlike common belief in software engineering, actually does not occur in the physical domain but in the functional domain. We conclude that effective design necessitates addressing coupling and complexity within the functional domain.",
      "authors": [
        "Aydin Homay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:07:53+00:00",
          "link": "https://arxiv.org/abs/2507.09599v1",
          "size": "985kb",
          "version": "v1"
        }
      ],
      "title": "Complexity and Coupling: A Functional Domain Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09599",
        "HTML": "https://arxiv.org/html/2507.09599v1",
        "PDF": "https://arxiv.org/pdf/2507.09599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on defining complexity and coupling in industrial systems, not on LLM training data or processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09660",
      "abstract": "System-level design, once the province of board designers, has now become a central concern for chip designers. Because chip design is a less forgiving design medium -- design cycles are longer and mistakes are harder to correct -- system-on-chip designers need a more extensive tool suite than may be used by board designers and a variety of tools and methodologies have been developed for system-level design of systems-on-chips (SoCs). System-level design is less amenable to synthesis than are logic or physical design. As a result, system-level tools concentrate on modeling, simulation, design space exploration, and design verification. The goal of modeling is to correctly capture the system's operational semantics, which helps with both implementation and verification. The study of models of computation provides a framework for the description of digital systems. Not only do we need to understand a particular style of computation, such as dataflow, but we also need to understand how different models of computation can reliably communicate with each other. Design space exploration tools, such as hardware/software co-design, develop candidate designs to understand trade-offs. Simulation can be used not only to verify functional correctness but also to supply performance and power/energy information for design analysis. This chapter employs two applications -- video and neural networks -- as examples. Both are leading-edge applications that illustrate many important aspects of system-level design.",
      "authors": [
        "Shuvra S. Bhattacharyya and Marilyn Wolf"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:49:13+00:00",
          "link": "https://arxiv.org/abs/2507.09660v1",
          "size": "743kb",
          "version": "v1"
        }
      ],
      "title": "Tools and Methodologies for System-Level Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09660",
        "HTML": "https://arxiv.org/html/2507.09660v1",
        "PDF": "https://arxiv.org/pdf/2507.09660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on system-level design for chips and SoCs, not related to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10326",
      "abstract": "Prompt engineering has proven to be a crucial step in leveraging pretrained large language models (LLMs) in solving various real-world tasks. Numerous solutions have been proposed that seek to automate prompt engineering by using the model itself to edit prompts. However, the majority of state-of-the-art approaches are evaluated on tasks that require minimal prompt templates and on very large and highly capable LLMs. In contrast, solving complex tasks that require detailed information to be included in the prompt increases the amount of text that needs to be optimised. Furthermore, smaller models have been shown to be more sensitive to prompt design. To address these challenges, we propose an evolutionary search approach to automated discrete prompt optimisation consisting of two phases. In the first phase, grammar-guided genetic programming is invoked to synthesise prompt-creating programmes by searching the space of programmes populated by function compositions of syntactic, dictionary-based and LLM-based prompt-editing functions. In the second phase, local search is applied to explore the neighbourhoods of best-performing programmes in an attempt to further fine-tune their performance. Our approach outperforms three state-of-the-art prompt optimisation approaches, PromptWizard, OPRO, and RL-Prompt, on three relatively small general-purpose LLMs in four domain-specific challenging tasks. We also illustrate several examples where these benchmark methods suffer relatively severe performance degradation, while our approach improves performance in almost all task-model combinations, only incurring minimal degradation when it does not.",
      "authors": [
        "Muzhaffar Hazman",
        "Minh-Khoi Pham",
        "Shweta Soundararajan",
        "Goncalo Mordido",
        "Leonardo Custode",
        "David Lynch",
        "Giorgio Cruciata",
        "Yucheng Shi",
        "Hongmeng Song",
        "Wang Chao",
        "Pan Yue",
        "Aleksandar Milenovic",
        "Alexandros Agapitos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:34:15+00:00",
          "link": "https://arxiv.org/abs/2507.10326v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "Grammar-Guided Evolutionary Search for Discrete Prompt Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10326",
        "HTML": "https://arxiv.org/html/2507.10326v1",
        "PDF": "https://arxiv.org/pdf/2507.10326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on prompt optimization techniques to improve performance with LLMs, but does not address the processing or creation of training data directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.05815",
      "abstract": "This paper introduces a novel nonlinear model predictive control (NMPC) framework that incorporates a lifting technique to enhance control performance for nonlinear systems. While the lifting technique has been widely employed in linear systems to capture intersample behaviour, their application to nonlinear systems remains unexplored. We address this gap by formulating an NMPC scheme that combines fast-sample fast-hold (FSFH) approximations and numerical methods to approximate system dynamics and cost functions. The proposed approach is validated through two case studies: the Van der Pol oscillator and the inverted pendulum on a cart. Simulation results demonstrate that the lifted NMPC outperforms conventional NMPC in terms of reduced settling time and improved control accuracy. These findings underscore the potential of the lifting-based NMPC for efficient control of nonlinear systems, offering a practical solution for real-time applications.",
      "authors": [
        "Nuthasith Gerdpratoom",
        "Fumiya Matsuzaki",
        "Yutaka Yamamoto",
        "Kaoru Yamamoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T09:38:42+00:00",
          "link": "https://arxiv.org/abs/2501.05815v1",
          "size": "8658kb",
          "version": "v1"
        }
      ],
      "title": "Enhanced sampled-data model predictive control via nonlinear lifting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05815",
        "HTML": "https://arxiv.org/html/2501.05815",
        "PDF": "https://arxiv.org/pdf/2501.05815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a model predictive control framework for nonlinear systems, and does not address any aspects related to LLM training data processing."
      },
      "tasks": [
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12851",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. \"Normal\" evaluates tool usage in basic scenarios; \"Special\" evaluates tool usage in situations with ambiguous or incomplete instructions; \"Agent\" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.",
      "authors": [
        "Chen Chen",
        "Xinlong Hao",
        "Weiwen Liu",
        "Xu Huang",
        "Xingshan Zeng",
        "Shuai Yu",
        "Dexun Li",
        "Shuai Wang",
        "Weinan Gan",
        "Yuefeng Huang",
        "Wulong Liu",
        "Xinzhi Wang",
        "Defu Lian",
        "Baoqun Yin",
        "Yasheng Wang",
        "Wu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T12:59:08+00:00",
          "link": "https://arxiv.org/abs/2501.12851v1",
          "size": "1669kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T14:36:52+00:00",
          "link": "https://arxiv.org/abs/2501.12851v2",
          "size": "1669kb",
          "version": "v2"
        },
        {
          "date": "2025-02-13T12:43:59+00:00",
          "link": "https://arxiv.org/abs/2501.12851v3",
          "size": "1052kb",
          "version": "v3"
        },
        {
          "date": "2025-02-26T09:54:28+00:00",
          "link": "https://arxiv.org/abs/2501.12851v4",
          "size": "915kb",
          "version": "v4"
        },
        {
          "date": "2025-07-14T05:06:20+00:00",
          "link": "https://arxiv.org/abs/2501.12851v5",
          "size": "910kb",
          "version": "v5"
        }
      ],
      "title": "ACEBench: Who Wins the Match Point in Tool Usage?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12851",
        "HTML": "https://arxiv.org/html/2501.12851v5",
        "PDF": "https://arxiv.org/pdf/2501.12851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces ACEBench, a benchmark for assessing LLM tool usage. It does not focus on LLM training data collection, processing, or engineering, which is the required criterion."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02704",
      "abstract": "Monocular depth estimation can be broadly categorized into two directions: relative depth estimation, which predicts normalized or inverse depth without absolute scale, and metric depth estimation, which aims to recover depth with real-world scale. While relative methods are flexible and data-efficient, their lack of metric scale limits their utility in downstream tasks. A promising solution is to infer absolute scale from textual descriptions. However, such language-based recovery is highly sensitive to natural language ambiguity, as the same image may be described differently across perspectives and styles. To address this, we introduce VGLD (Visually-Guided Linguistic Disambiguation), a framework that incorporates high-level visual semantics to resolve ambiguity in textual inputs. By jointly encoding both image and text, VGLD predicts a set of global linear transformation parameters that align relative depth maps with metric scale. This visually grounded disambiguation improves the stability and accuracy of scale estimation. We evaluate VGLD on representative models, including MiDaS and DepthAnything, using standard indoor (NYUv2) and outdoor (KITTI) benchmarks. Results show that VGLD significantly mitigates scale estimation bias caused by inconsistent or ambiguous language, achieving robust and accurate metric predictions. Moreover, when trained on multiple datasets, VGLD functions as a universal and lightweight alignment module, maintaining strong performance even in zero-shot settings. Code will be released upon acceptance.",
      "authors": [
        "Bojin Wu",
        "Jing Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T14:57:16+00:00",
          "link": "https://arxiv.org/abs/2505.02704v1",
          "size": "13584kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T03:06:28+00:00",
          "link": "https://arxiv.org/abs/2505.02704v2",
          "size": "13584kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T06:16:51+00:00",
          "link": "https://arxiv.org/abs/2505.02704v3",
          "size": "8443kb",
          "version": "v3"
        }
      ],
      "title": "VGLD: Visually-Guided Linguistic Disambiguation for Monocular Depth Scale Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02704",
        "HTML": "https://arxiv.org/html/2505.02704v3",
        "PDF": "https://arxiv.org/pdf/2505.02704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework (VGLD) for linguistic disambiguation by integrating visual semantics for depth estimation. It focuses on depth scale recovery and does not discuss LLM training data processing."
      },
      "tasks": [
        "Depth Estimation",
        "Monocular Depth Estimation"
      ],
      "repo_urls": [
        "https://github.com/pakinwu/vgld"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07028",
      "abstract": "It is known that real Mutually Unbiased Bases (MUBs) do not exist for any dimension $d > 2$ which is not divisible by 4. Thus, the next combinatorial question is how one can construct Approximate Real MUBs (ARMUBs) in this direction with encouraging parameters. In this paper, for the first time, we show that it is possible to construct $> \\lceil \\sqrt{d} \\rceil$ many ARMUBs for certain odd dimensions $d$ of the form $d = (4n-t)s$, $t = 1, 2, 3$, where $n$ is a natural number and $s$ is an odd prime power. Our method exploits any available $4n \\times 4n$ real Hadamard matrix $H_{4n}$ (conjectured to be true) and uses this to construct an orthogonal matrix ${Y}_{4n-t}$ of size $(4n - t) \\times (4n - t)$, such that the absolute value of each entry varies a little from $\\frac{1}{\\sqrt{4n-t}}$. In our construction, the absolute value of the inner product between any pair of basis vectors from two different ARMUBs will be $\\leq \\frac{1}{\\sqrt{d}}(1 + O(d^{-\\frac{1}{4}})) < 2$, for proper choices of parameters, the class of dimensions $d$ being infinitely large.",
      "authors": [
        "Ajeet Kumar",
        "Rakesh Kumar",
        "Subhamoy Maitra",
        "Uddipto Mandal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:58:56+00:00",
          "link": "https://arxiv.org/abs/2507.07028v1",
          "size": "31kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T18:11:24+00:00",
          "link": "https://arxiv.org/abs/2507.07028v2",
          "size": "32kb",
          "version": "v2"
        }
      ],
      "title": "On Construction of Approximate Real Mutually Unbiased Bases for an infinite class of dimensions $d \\not\\equiv 0 \\bmod 4$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07028",
        "HTML": "https://arxiv.org/html/2507.07028v2",
        "PDF": "https://arxiv.org/pdf/2507.07028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with constructing Approximate Real Mutually Unbiased Bases in certain dimensions and does not pertain to any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08841",
      "abstract": "Neural architecture search (NAS) is a promising approach for automatically designing neural network architectures. However, the architecture estimation of NAS is computationally expensive and time-consuming because of training multiple architectures from scratch. Although existing zero-shot NAS methods use training-free proxies to accelerate the architecture estimation, their effectiveness, stability, and generality are still lacking. We present a novel training-free estimation proxy called weighted response correlation (WRCor). WRCor utilizes correlation coefficient matrices of responses across different input samples to calculate the proxy scores of estimated architectures, which can measure their expressivity and generalizability. Experimental results on proxy evaluation demonstrate that WRCor and its voting proxies are more efficient estimation strategies than existing proxies. We also apply them with different search strategies in architecture search. Experimental results on architecture search show that our zero-shot NAS algorithm outperforms most existing NAS algorithms in different search spaces. Our NAS algorithm can discover an architecture with a 22.1% test error on the ImageNet-1k dataset within 4 GPU hours. All codes are publicly available at https://github.com/kunjing96/ZSNAS-WRCor.git.",
      "authors": [
        "Kun Jing",
        "Luoyu Chen",
        "Jungang Xu",
        "Jianwei Tai",
        "Yiyu Wang",
        "Shuaimin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T02:19:29+00:00",
          "link": "https://arxiv.org/abs/2507.08841v1",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "title": "Zero-Shot Neural Architecture Search with Weighted Response Correlation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08841",
        "HTML": "https://arxiv.org/html/2507.08841v1",
        "PDF": "https://arxiv.org/pdf/2507.08841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Neural Architecture Search (NAS) using a new proxy but does not discuss any LLM training data processing, engineering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08878",
      "abstract": "Large Language Models (LLMs) have showcased remarkable generalizability in language comprehension and hold significant potential to revolutionize human-computer interaction in smart homes. Existing LLM-based smart home assistants typically transmit user commands, along with user profiles and home configurations, to remote servers to obtain personalized services. However, users are increasingly concerned about the potential privacy leaks to the remote servers. To address this issue, we develop HomeLLaMA, an on-device assistant for privacy-preserving and personalized smart home serving with a tailored small language model (SLM). HomeLLaMA learns from cloud LLMs to deliver satisfactory responses and enable user-friendly interactions. Once deployed, HomeLLaMA facilitates proactive interactions by continuously updating local SLMs and user profiles. To further enhance user experience while protecting their privacy, we develop PrivShield to offer an optional privacy-preserving LLM-based smart home serving for those users, who are unsatisfied with local responses and willing to send less-sensitive queries to remote servers. For evaluation, we build a comprehensive benchmark DevFinder to assess the service quality. Extensive experiments and user studies (M=100) demonstrate that HomeLLaMA can provide personalized services while significantly enhancing user privacy.",
      "authors": [
        "Xinyu Huang",
        "Leming Shen",
        "Zijing Ma",
        "Yuanqing Zheng"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:36:32+00:00",
          "link": "https://arxiv.org/abs/2507.08878v1",
          "size": "1020kb",
          "version": "v1"
        }
      ],
      "title": "Towards Privacy-Preserving and Personalized Smart Homes via Tailored Small Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08878",
        "HTML": "https://arxiv.org/html/2507.08878v1",
        "PDF": "https://arxiv.org/pdf/2507.08878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a privacy-preserving approach for smart homes using tailored small language models but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09074",
      "abstract": "This paper presents a novel method of executable steganography using the alpha transparency layer of ICO image files to embed and deliver self-decompressing JavaScript payloads within web browsers. By targeting the least significant bit (LSB) of non-transparent alpha layer image values, the proposed method successfully conceals compressed JavaScript code inside a favicon image without affecting visual fidelity. Global web traffic loads 294 billion favicons daily and consume 0.9 petabytes of network bandwidth. A proof-of-concept implementation demonstrates that a 64x64 ICO image can embed up to 512 bytes uncompressed, or 0.8 kilobyte when using lightweight two-fold compression. On page load, a browser fetches the favicon as part of standard behavior, allowing an embedded loader script to extract and execute the payload entirely in memory using native JavaScript APIs and canvas pixel access. This creates a two-stage covert channel requiring no additional network or user requests. Testing across multiple browsers in both desktop and mobile environments confirms successful and silent execution of the embedded script. We evaluate the threat model, relate it to polymorphic phishing attacks that evade favicon-based detection, and analyze evasion of content security policies and antivirus scanners. We map nine example MITRE ATT&CK Framework objectives to single line JavaScript to execute arbitrarily in ICO files. Existing steganalysis and sanitization defenses are discussed, highlighting limitations in detecting or neutralizing alpha-channel exploits. The results demonstrate a stealthy and reusable attack surface that blurs traditional boundaries between static images and executable content. Because modern browsers report silent errors when developers specifically fail to load ICO files, this attack surface offers an interesting example of required web behaviors that in turn compromise security.",
      "authors": [
        "David Noever",
        "Forrest McKee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:29:04+00:00",
          "link": "https://arxiv.org/abs/2507.09074v1",
          "size": "457kb",
          "version": "v1"
        }
      ],
      "title": "Favicon Trojans: Executable Steganography Via Ico Alpha Channel Exploitation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09074",
        "PDF": "https://arxiv.org/pdf/2507.09074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for executable steganography using image files, which is related to cybersecurity rather than LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10003",
      "abstract": "This work presents a vision-based underwater exploration and inspection autonomy solution integrated into Ariel, a custom vision-driven underwater robot. Ariel carries a $5$ camera and IMU based sensing suite, enabling a refraction-aware multi-camera visual-inertial state estimation method aided by a learning-based proprioceptive robot velocity prediction method that enhances robustness against visual degradation. Furthermore, our previously developed and extensively field-verified autonomous exploration and general visual inspection solution is integrated on Ariel, providing aerial drone-level autonomy underwater. The proposed system is field-tested in a submarine dry dock in Trondheim under challenging visual conditions. The field demonstration shows the robustness of the state estimation solution and the generalizability of the path planning techniques across robot embodiments.",
      "authors": [
        "Mohit Singh",
        "Mihir Dharmadhikari and Kostas Alexis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:36:25+00:00",
          "link": "https://arxiv.org/abs/2507.10003v1",
          "size": "4114kb",
          "version": "v1"
        }
      ],
      "title": "Ariel Explores: Vision-based underwater exploration and inspection via generalist drone-level autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10003",
        "HTML": "https://arxiv.org/html/2507.10003v1",
        "PDF": "https://arxiv.org/pdf/2507.10003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on vision-based underwater exploration and inspection autonomy for a robotic system and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10078",
      "abstract": "Deep learning models incorporating linear SSMs have gained attention for capturing long-range dependencies in sequential data. However, their large parameter sizes pose challenges for deployment on resource-constrained devices. In this study, we propose an efficient parameter reduction method for these models by applying $H^{2}$ model order reduction techniques from control theory to their linear SSM components. In experiments, the LRA benchmark results show that the model compression based on our proposed method outperforms an existing method using the Balanced Truncation, while successfully reducing the number of parameters in the SSMs to $1/32$ without sacrificing the performance of the original models.",
      "authors": [
        "Hiroki Sakamoto and Kazuhiro Sato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:03:44+00:00",
          "link": "https://arxiv.org/abs/2507.10078v1",
          "size": "564kb",
          "version": "v1"
        }
      ],
      "title": "Compression Method for Deep Diagonal State Space Model Based on $H^2$ Optimal Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10078",
        "HTML": "https://arxiv.org/html/2507.10078v1",
        "PDF": "https://arxiv.org/pdf/2507.10078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a compression method for deep learning models, specifically linear SSMs, not related to processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10343",
      "abstract": "We introduce FGSSNet, a novel multi-headed feature-guided semantic segmentation (FGSS) architecture designed to improve the generalization ability of wall segmentation on floorplans. FGSSNet features a U-Net segmentation backbone with a multi-headed dedicated feature extractor used to extract domain-specific feature maps which are injected into the latent space of U-Net to guide the segmentation process. This dedicated feature extractor is trained as an encoder-decoder with selected wall patches, representative of the walls present in the input floorplan, to produce a compressed latent representation of wall patches while jointly trained to predict the wall width. In doing so, we expect that the feature extractor encodes texture and width features of wall patches that are useful to guide the wall segmentation process. Our experiments show increased performance by the use of such injected features in comparison to the vanilla U-Net, highlighting the validity of the proposed approach.",
      "authors": [
        "Hugo Norrby",
        "Gabriel F\\\"arm",
        "Kevin Hernandez-Diaz",
        "and Fernando Alonso-Fernandez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:47:11+00:00",
          "link": "https://arxiv.org/abs/2507.10343v1",
          "size": "12625kb",
          "version": "v1"
        }
      ],
      "title": "FGSSNet: Feature-Guided Semantic Segmentation of Real World Floorplans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10343",
        "HTML": "https://arxiv.org/html/2507.10343v1",
        "PDF": "https://arxiv.org/pdf/2507.10343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a segmentation architecture for floorplans and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.11447",
      "abstract": "We introduce GaussianOcc, a systematic method that investigates the two usages of Gaussian splatting for fully self-supervised and efficient 3D occupancy estimation in surround views. First, traditional methods for self-supervised 3D occupancy estimation still require ground truth 6D poses from sensors during training. To address this limitation, we propose Gaussian Splatting for Projection (GSP) module to provide accurate scale information for fully self-supervised training from adjacent view projection. Additionally, existing methods rely on volume rendering for final 3D voxel representation learning using 2D signals (depth maps, semantic maps), which is both time-consuming and less effective. We propose Gaussian Splatting from Voxel space (GSV) to leverage the fast rendering properties of Gaussian splatting. As a result, the proposed GaussianOcc method enables fully self-supervised (no ground truth pose) 3D occupancy estimation in competitive performance with low computational cost (2.7 times faster in training and 5 times faster in rendering). The relevant code is available in https://github.com/GANWANSHUI/GaussianOcc.git.",
      "authors": [
        "Wanshui Gan",
        "Fang Liu",
        "Hongbin Xu",
        "Ningkai Mo",
        "Naoto Yokoya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-21T09:06:30+00:00",
          "link": "https://arxiv.org/abs/2408.11447v1",
          "size": "39648kb",
          "version": "v1"
        },
        {
          "date": "2024-09-13T06:09:25+00:00",
          "link": "https://arxiv.org/abs/2408.11447v2",
          "size": "39648kb",
          "version": "v2"
        },
        {
          "date": "2024-12-12T14:42:30+00:00",
          "link": "https://arxiv.org/abs/2408.11447v3",
          "size": "45724kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T17:20:25+00:00",
          "link": "https://arxiv.org/abs/2408.11447v4",
          "size": "48470kb",
          "version": "v4"
        }
      ],
      "title": "GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation with Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.11447",
        "HTML": "https://arxiv.org/html/2408.11447v4",
        "PDF": "https://arxiv.org/pdf/2408.11447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving 3D occupancy estimation techniques using Gaussian splatting, but does not address or make contributions to processing LLM training data."
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/ganwanshui/gaussianocc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01132",
      "abstract": "Graph-structured data is ubiquitous in scientific domains, where models often face imbalanced learning settings. In imbalanced regression, domain preferences focus on specific target value ranges that represent the most scientifically valuable cases; however, we observe a significant lack of research regarding this challenge. In this paper, we present Spectral Manifold Harmonization (SMH), a novel approach to address imbalanced regression challenges on graph-structured data by generating synthetic graph samples that preserve topological properties while focusing on the most relevant target distribution regions. Conventional methods fail in this context because they either ignore graph topology in case generation or do not target specific domain ranges, resulting in models biased toward average target values. Experimental results demonstrate the potential of SMH on chemistry and drug discovery benchmark datasets, showing consistent improvements in predictive performance for target domain ranges. Code is available at https://github.com/brendacnogueira/smh-graph-imbalance.git.",
      "authors": [
        "Brenda Nogueira",
        "Gabe Gomes",
        "Meng Jiang",
        "Nitesh V. Chawla",
        "Nuno Moniz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Molecular Networks (q-bio.MN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T18:48:43+00:00",
          "link": "https://arxiv.org/abs/2507.01132v1",
          "size": "1632kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:22:33+00:00",
          "link": "https://arxiv.org/abs/2507.01132v2",
          "size": "2024kb",
          "version": "v2"
        }
      ],
      "title": "Spectral Manifold Harmonization for Graph Imbalanced Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01132",
        "HTML": "https://arxiv.org/html/2507.01132v2",
        "PDF": "https://arxiv.org/pdf/2507.01132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on imbalanced regression on graph-structured data, specifically addressing challenges related to generating synthetic graph samples. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09039",
      "abstract": "Mobile app reviews are a large-scale data source for software improvements. A key task in this context is effectively extracting requirements from app reviews to analyze the users' needs and support the software's evolution. Recent studies show that existing methods fail at this task since app reviews usually contain informal language, grammatical and spelling errors, and a large amount of irrelevant information that might not have direct practical value for developers. To address this, we propose a novel reformulation of requirements extraction as a Named Entity Recognition (NER) task based on the sequence-to-sequence (Seq2seq) generation approach. With this aim, we propose a Seq2seq framework, incorporating a BiLSTM encoder and an LSTM decoder, enhanced with a self-attention mechanism, GloVe embeddings, and a CRF model. We evaluated our framework on two datasets: a manually annotated set of 1,000 reviews (Dataset 1) and a crowdsourced set of 23,816 reviews (Dataset 2). The quantitative evaluation of our framework showed that it outperformed existing state-of-the-art methods with an F1 score of 0.96 on Dataset 2, and achieved comparable performance on Dataset 1 with an F1 score of 0.47.",
      "authors": [
        "Aakash Sorathiya and Gouri Ginde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:35:14+00:00",
          "link": "https://arxiv.org/abs/2507.09039v1",
          "size": "892kb",
          "version": "v1"
        }
      ],
      "title": "Towards Extracting Software Requirements from App Reviews using Seq2seq Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09039",
        "HTML": "https://arxiv.org/html/2507.09039v1",
        "PDF": "https://arxiv.org/pdf/2507.09039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about extracting software requirements from app reviews using a Seq2seq framework, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09300",
      "abstract": "A precise domain triangulation is recognized as indispensable for the accurate numerical approximation of differential operators within collocation methods, leading to a substantial reduction in discretization errors. An efficient finite element method (FEM) is presented in this paper, meticulously developed to solve a complex mathematical model. This model governs the behavior of thermoelastic solids containing both a V-notch and inclusions. The system of partial differential equations underlying this model consists of two primary components: a linear elliptic equation, which is used to describe the temperature distribution, and a quasilinear equation, which governs the mechanical behavior of the body. Through the application of this specifically tailored FEM, accurate and efficient solutions are able to be obtained for these intricate thermoelastic problems. The algebraically nonlinear constitutive equation, alongside the balance of linear momentum, is effectively reduced to a second-order quasi-linear elliptic partial differential equation. Complex curved boundaries are represented through the application of a smooth, distinctive point transformation. Furthermore, higher-order shape functions are employed to ensure the accurate computation of entries within the FEM matrices and vectors, from which a highly precise approximate solution to the BVP is subsequently obtained. The inherent nonlinearities in the governing differential equation are addressed through the implementation of a Picard-type linearization scheme. Numerical results, derived from a series of test cases, have consistently demonstrated a significant enhancement in accuracy, a crucial achievement for the nuanced analysis of thermoelastic solids.",
      "authors": [
        "G. Shylaja",
        "V. Kesavulu Naidu",
        "B. Venkatesh",
        "S. M. Mallikarjunaiah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:28:16+00:00",
          "link": "https://arxiv.org/abs/2507.09300v1",
          "size": "695kb",
          "version": "v1"
        }
      ],
      "title": "Finite element modeling of V-notched thermoelastic strain-limiting solids containing inclusions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09300",
        "HTML": "https://arxiv.org/html/2507.09300v1",
        "PDF": "https://arxiv.org/pdf/2507.09300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a finite element method for modeling thermoelastic solids and does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09626",
      "abstract": "Artificial intelligence (AI) systems often interact with multiple agents. The regulation of such AI systems often requires that {\\em a priori\\/} guarantees of fairness and robustness be satisfied. With stochastic models of agents' responses to the outputs of AI systems, such {\\em a priori\\/} guarantees require non-trivial reasoning about the corresponding stochastic systems. Here, we present an open-source PyTorch-based toolkit for the use of stochastic control techniques in modelling interconnections of AI systems and properties of their repeated uses. It models robustness and fairness desiderata in a closed-loop fashion, and provides {\\em a priori\\/} guarantees for these interconnections. The PyTorch-based toolkit removes much of the complexity associated with the provision of fairness guarantees for closed-loop models of multi-agent systems.",
      "authors": [
        "Rodion Nazarov",
        "Anthony Quinn",
        "Robert Shorten",
        "Jakub Marecek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T13:35:15+00:00",
          "link": "https://arxiv.org/abs/2507.09626v1",
          "size": "559kb",
          "version": "v1"
        }
      ],
      "title": "humancompatible.interconnect: Testing Properties of Repeated Uses of Interconnections of AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09626",
        "HTML": "https://arxiv.org/html/2507.09626v1",
        "PDF": "https://arxiv.org/pdf/2507.09626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a toolkit for stochastic control in AI systems, emphasizing fairness and robustness guarantees, without addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23553",
      "abstract": "Contrastive language-audio pretraining (CLAP) is widely used for audio generation and recognition tasks. For example, CLAPScore, which utilizes the similarity of CLAP embeddings, has been a major metric for the evaluation of the relevance between audio and text in text-to-audio. However, the relationship between CLAPScore and human subjective evaluation scores is still unclarified. We show that CLAPScore has a low correlation with human subjective evaluation scores. Additionally, we propose a human-perception-based CLAP called Human-CLAP by training a contrastive language-audio model using the subjective evaluation score. In our experiments, the results indicate that our Human-CLAP improved the Spearman's rank correlation coefficient (SRCC) between the CLAPScore and the subjective evaluation scores by more than 0.25 compared with the conventional CLAP.",
      "authors": [
        "Taisei Takano",
        "Yuki Okamoto",
        "Yusuke Kanamori",
        "Yuki Saito",
        "Ryotaro Nagase",
        "Hiroshi Saruwatari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:57:57+00:00",
          "link": "https://arxiv.org/abs/2506.23553v1",
          "size": "3587kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T13:00:45+00:00",
          "link": "https://arxiv.org/abs/2506.23553v2",
          "size": "12770kb",
          "version": "v2"
        }
      ],
      "title": "Human-CLAP: Human-perception-based contrastive language-audio pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23553",
        "HTML": "https://arxiv.org/html/2506.23553v2",
        "PDF": "https://arxiv.org/pdf/2506.23553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a human-perception-based contrastive language-audio pretraining model but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07910",
      "abstract": "The explosive growth of textual data over time presents a significant challenge in uncovering evolving themes and trends. Existing dynamic topic modeling techniques, while powerful, often exist in fragmented pipelines that lack robust support for interpretation and user-friendly exploration. We introduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end system that bridges the gap between raw textual data and meaningful temporal insights. DTECT provides a unified workflow that supports data preprocessing, multiple model architectures, and dedicated evaluation metrics to analyze the topic quality of temporal topic models. It significantly enhances interpretability by introducing LLM-driven automatic topic labeling, trend analysis via temporally salient words, interactive visualizations with document-level summarization, and a natural language chat interface for intuitive data querying. By integrating these features into a single, cohesive platform, DTECT empowers users to more effectively track and understand thematic dynamics. DTECT is open-source and available at https://github.com/AdhyaSuman/DTECT.",
      "authors": [
        "Suman Adhya and Debarshi Kumar Sanyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:44:33+00:00",
          "link": "https://arxiv.org/abs/2507.07910v1",
          "size": "949kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T05:41:16+00:00",
          "link": "https://arxiv.org/abs/2507.07910v2",
          "size": "951kb",
          "version": "v2"
        }
      ],
      "title": "DTECT: Dynamic Topic Explorer & Context Tracker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07910",
        "HTML": "https://arxiv.org/html/2507.07910v2",
        "PDF": "https://arxiv.org/pdf/2507.07910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a topic modeling system that involves data preprocessing but does not primarily focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08821",
      "abstract": "Fluid antenna systems represent an innovative approach in wireless communication, recently applied in multiple access to optimize the signal-to-interference-plus-noise ratio through port selection. This letter frames the port selection problem as a multi-label classification task for the first time, improving best-port selection with limited port observations. We address this challenge by leveraging liquid neural networks (LNNs) to predict the optimal port under emerging fluid antenna multiple access scenarios alongside a more general $\\alpha$-$\\mu$ fading model. We also apply hyperparameter optimization to refine LNN architectures for different observation scenarios. Our approach yields lower outage probability values than existing methods.",
      "authors": [
        "Pedro D. Alvim",
        "Hugerles S. Silva",
        "Ugo S. Dias",
        "Osamah S. Badarneh",
        "Felipe A. P. Figueiredo and Rausley A. A. de Souza"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:31:02+00:00",
          "link": "https://arxiv.org/abs/2507.08821v1",
          "size": "399kb",
          "version": "v1"
        }
      ],
      "title": "LNN-powered Fluid Antenna Multiple Access",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08821",
        "HTML": "https://arxiv.org/html/2507.08821v1",
        "PDF": "https://arxiv.org/pdf/2507.08821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on wireless communication and not on LLM training data. It involves liquid neural networks for signal prediction rather than data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08881",
      "abstract": "The integration of large language model (LLM) technology into judicial systems is fundamentally transforming legal practice worldwide. However, this global transformation has revealed an urgent paradox requiring immediate attention. This study introduces the concept of ``consistency-acceptability divergence'' for the first time, referring to the gap between technical consistency and social acceptance. While LLMs achieve high consistency at the technical level, this consistency demonstrates both positive and negative effects. Through comprehensive analysis of recent data on LLM judicial applications from 2023--2025, this study finds that addressing this challenge requires understanding both task and stakeholder dimensions. This study proposes the Dual-Track Deliberative Multi-Role LLM Judicial Governance Framework (DTDMR-LJGF), which enables intelligent task classification and meaningful interaction among diverse stakeholders. This framework offers both theoretical insights and practical guidance for building an LLM judicial ecosystem that balances technical efficiency with social legitimacy.",
      "authors": [
        "Zhang MingDa",
        "Xu Qing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.08881v1",
          "size": "3425kb",
          "version": "v1"
        }
      ],
      "title": "The Consistency-Acceptability Divergence of LLMs in Judicial Decision-Making: Task and Stakeholder Dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08881",
        "HTML": "https://arxiv.org/html/2507.08881v1",
        "PDF": "https://arxiv.org/pdf/2507.08881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on LLMs in judicial decision-making and proposes a governance framework. It does not involve processing or engineering training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08954",
      "abstract": "Hardware accelerators like GPUs are now ubiquitous in data centers, but are not fully supported by common cloud abstractions such as Functions as a Service (FaaS). Many popular and emerging FaaS applications such as machine learning and scientific computing can benefit from GPU acceleration. However, FaaS frameworks (such as OpenWhisk) are not capable of providing this acceleration because of the impedance mismatch between GPUs and the FaaS programming model, which requires virtualization and sandboxing of each function. The challenges are amplified due to the highly dynamic and heterogeneous FaaS workloads. This paper presents the design and implementation of a FaaS system for providing GPU acceleration in a black-box manner (without modifying function code). Running small functions in containerized sandboxes is challenging due to limited GPU concurrency and high cold-start overheads, resulting in heavy queueing of function invocations. We show how principles from I/O scheduling, such as fair queuing and anticipatory scheduling, can be translated to function scheduling on GPUs. We develop MQFQ-Sticky, an integrated fair queueing and GPU memory management approach, which balances the tradeoffs between locality, fairness, and latency. Empirical evaluation on a range of workloads shows that it reduces function latency by 2x to 20x compared to existing GPU and CPU queueing policies.",
      "authors": [
        "Alexander Fuerst",
        "Siddharth Anil",
        "Vishakha Dixit",
        "Purushottam (Puru) Kulkarni",
        "Prateek Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:28:25+00:00",
          "link": "https://arxiv.org/abs/2507.08954v1",
          "size": "474kb",
          "version": "v1"
        }
      ],
      "title": "MQFQ-Sticky: Fair Queueing For Serverless GPU Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08954",
        "HTML": "https://arxiv.org/html/2507.08954v1",
        "PDF": "https://arxiv.org/pdf/2507.08954"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a system for GPU acceleration in serverless functions and does not mention LLM training data or data engineering processes relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09376",
      "abstract": "Accurate sound propagation simulation is essential for delivering immersive experiences in virtual applications, yet industry methods for acoustic modeling often do not account for the full breadth of acoustic wave phenomena. This paper proposes a novel two-dimensional (2D) finite-difference time-domain (FDTD) framework that simulates sound propagation as a wave-based model in Unreal Engine, with an emphasis on capturing lower frequency wave phenomena, embedding occlusion, diffraction, reflection and interference in generated impulse responses. The process begins by discretizing the scene geometry into a 2D grid via a top-down projection from which obstacle masks and boundary conditions are derived. A Python-based FDTD solver injects a sine sweep at a source position, and virtual quadraphonic microphone arrays record pressure field responses at pre-defined listener positions. De-convolution of the pressure responses yields multi-channel impulse responses that retain spatial directionality which are then integrated into Unreal Engine's audio pipeline for dynamic playback. Benchmark tests confirm agreement with analytical expectations, and the paper outlines hybrid extensions aimed at commercial viability.",
      "authors": [
        "Bilkent Samsurya"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:46:26+00:00",
          "link": "https://arxiv.org/abs/2507.09376v1",
          "size": "2181kb",
          "version": "v1"
        }
      ],
      "title": "Acoustic Wave Modeling Using 2D FDTD: Applications in Unreal Engine For Dynamic Sound Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09376",
        "HTML": "https://arxiv.org/html/2507.09376v1",
        "PDF": "https://arxiv.org/pdf/2507.09376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a model for acoustic wave modeling in Unreal Engine, focusing on sound propagation rather than any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10075",
      "abstract": "Automated vehicles (AVs) face a critical need to adopt socially compatible behaviors and cooperate effectively with human-driven vehicles (HVs) in heterogeneous traffic environment. However, most existing lane-changing frameworks overlook HVs' dynamic trust levels, limiting their ability to accurately predict human driver behaviors. To address this gap, this study proposes a trust-aware game-theoretic lane-changing decision (TGLD) framework. First, we formulate a multi-vehicle coalition game, incorporating fully cooperative interactions among AVs and partially cooperative behaviors from HVs informed by real-time trust evaluations. Second, we develop an online trust evaluation method to dynamically estimate HVs' trust levels during lane-changing interactions, guiding AVs to select context-appropriate cooperative maneuvers. Lastly, social compatibility objectives are considered by minimizing disruption to surrounding vehicles and enhancing the predictability of AV behaviors, thereby ensuring human-friendly and context-adaptive lane-changing strategies. A human-in-the-loop experiment conducted in a highway on-ramp merging scenario validates our TGLD approach. Results show that AVs can effectively adjust strategies according to different HVs' trust levels and driving styles. Moreover, incorporating a trust mechanism significantly improves lane-changing efficiency, maintains safety, and contributes to transparent and adaptive AV-HV interactions.",
      "authors": [
        "Jie Pan",
        "Tianyi Wang",
        "Yangyang Wang",
        "Junfeng Jiao",
        "Christian Claudel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:01:00+00:00",
          "link": "https://arxiv.org/abs/2507.10075v1",
          "size": "3590kb",
          "version": "v1"
        }
      ],
      "title": "TGLD: A Trust-Aware Game-Theoretic Lane-Changing Decision Framework for Automated Vehicles in Heterogeneous Traffic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10075",
        "PDF": "https://arxiv.org/pdf/2507.10075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The main contribution is a trust-aware decision framework for lane-changing in automated vehicles, not processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.01062",
      "abstract": "Model Inversion (MI) attacks pose a significant privacy threat by reconstructing private training data from machine learning models. While existing defenses primarily concentrate on model-centric approaches, the impact of data on MI robustness remains largely unexplored. In this work, we explore Random Erasing (RE), a technique traditionally used for improving model generalization under occlusion, and uncover its surprising effectiveness as a defense against MI attacks. Specifically, our novel feature space analysis shows that models trained with RE-images introduce a significant discrepancy between the features of MI-reconstructed images and those of the private data. At the same time, features of private images remain distinct from other classes and well-separated from different classification regions. These effects collectively degrade MI reconstruction quality and attack accuracy while maintaining reasonable natural accuracy. Furthermore, we explore two critical properties of RE including Partial Erasure and Random Location. Partial Erasure prevents the model from observing entire objects during training. We find this has a significant impact on MI, which aims to reconstruct the entire objects. Random Location of erasure plays a crucial role in achieving a strong privacy-utility trade-off. Our findings highlight RE as a simple yet effective defense mechanism that can be easily integrated with existing privacy-preserving techniques. Extensive experiments across 37 setups demonstrate that our method achieves state-of-the-art (SOTA) performance in the privacy-utility trade-off. The results consistently demonstrate the superiority of our defense over existing methods across different MI attacks, network architectures, and attack configurations. For the first time, we achieve a significant degradation in attack accuracy without a decrease in utility for some configurations.",
      "authors": [
        "Viet-Hung Tran",
        "Ngoc-Bao Nguyen",
        "Son T. Mai",
        "Hans Vandierendonck",
        "Ira Assent",
        "Alex Kot",
        "Ngai-Man Cheung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T08:37:17+00:00",
          "link": "https://arxiv.org/abs/2409.01062v1",
          "size": "13382kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:55:10+00:00",
          "link": "https://arxiv.org/abs/2409.01062v2",
          "size": "18255kb",
          "version": "v2"
        }
      ],
      "title": "Random Erasing vs. Model Inversion: A Promising Defense or a False Hope?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01062",
        "HTML": "https://arxiv.org/html/2409.01062v2",
        "PDF": "https://arxiv.org/pdf/2409.01062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper primarily investigates a defense against Model Inversion attacks and does not make contributions to LLM training data processing or dataset engineering."
      },
      "tasks": [
        "Data Augmentation",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.24085",
      "abstract": "Blending visual and textual concepts into a new visual concept is a unique and powerful trait of human beings that can fuel creativity. However, in practice, cross-modal conceptual blending for humans is prone to cognitive biases, like design fixation, which leads to local minima in the design space. In this paper, we propose a T2I diffusion adapter \"IT-Blender\" that can automate the blending process to enhance human creativity. Prior works related to cross-modal conceptual blending are limited in encoding a real image without loss of details or in disentangling the image and text inputs. To address these gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend the latent representations of a clean reference image with those of the noisy generated image. Combined with our novel blended attention, IT-Blender encodes the real reference image without loss of details and blends the visual concept with the object specified by the text in a disentangled way. Our experiment results show that IT-Blender outperforms the baselines by a large margin in blending visual and textual concepts, shedding light on the new application of image generative models to augment human creativity.",
      "authors": [
        "Wonwoong Cho",
        "Yanxia Zhang",
        "Yan-Ying Chen",
        "David I. Inouye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:41:25+00:00",
          "link": "https://arxiv.org/abs/2506.24085v1",
          "size": "47161kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:42:45+00:00",
          "link": "https://arxiv.org/abs/2506.24085v2",
          "size": "47168kb",
          "version": "v2"
        }
      ],
      "title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24085",
        "HTML": "https://arxiv.org/html/2506.24085v2",
        "PDF": "https://arxiv.org/pdf/2506.24085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on blending visual and textual concepts using existing pretrained diffusion models and does not discuss processing LLM training data or dataset creation."
      },
      "models": [
        {
          "model_path": "WonwoongCho/IT-Blender",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WonwoongCho/IT-Blender"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04225",
      "abstract": "Cyclic peptides, characterized by geometric constraints absent in linear peptides, offer enhanced biochemical properties, presenting new opportunities to address unmet medical needs. However, designing target-specific cyclic peptides remains underexplored due to limited training data. To bridge the gap, we propose CP-Composer, a novel generative framework that enables zero-shot cyclic peptide generation via composable geometric constraints. Our approach decomposes complex cyclization patterns into unit constraints, which are incorporated into a diffusion model through geometric conditioning on nodes and edges. During training, the model learns from unit constraints and their random combinations in linear peptides, while at inference, novel constraint combinations required for cyclization are imposed as input. Experiments show that our model, despite trained with linear peptides, is capable of generating diverse target-binding cyclic peptides, reaching success rates from 38% to 84% on different cyclization strategies.",
      "authors": [
        "Dapeng Jiang",
        "Xiangzhe Kong",
        "Jiaqi Han",
        "Mingyu Li",
        "Rui Jiao",
        "Wenbing Huang",
        "Stefano Ermon",
        "Jianzhu Ma",
        "Yang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T03:30:45+00:00",
          "link": "https://arxiv.org/abs/2507.04225v1",
          "size": "3897kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:33:47+00:00",
          "link": "https://arxiv.org/abs/2507.04225v2",
          "size": "3897kb",
          "version": "v2"
        }
      ],
      "title": "Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04225",
        "HTML": "https://arxiv.org/html/2507.04225v2",
        "PDF": "https://arxiv.org/pdf/2507.04225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a framework for cyclic peptide generation using geometric constraints. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08382",
      "abstract": "Cluster analysis is a fundamental research issue in statistics and machine learning. In many modern clustering methods, we need to determine whether two subsets of samples come from the same cluster. Since these subsets are usually generated by certain clustering procedures, the deployment of classic two-sample tests in this context would yield extremely smaller p-values, leading to inflated Type-I error rate. To overcome this bias, we formally introduce the two-cluster test issue and argue that it is a totally different significance testing issue from conventional two-sample test. Meanwhile, we present a new method based on the boundary points between two subsets to derive an analytical p-value for the purpose of significance quantification. Experiments on both synthetic and real data sets show that the proposed test is able to significantly reduce the Type-I error rate, in comparison with several classic two-sample testing methods. More importantly, the practical usage of such two-cluster test is further verified through its applications in tree-based interpretable clustering and significance-based hierarchical clustering.",
      "authors": [
        "Xinying Liu",
        "Lianyu Hu",
        "Mudi Jiang",
        "Simeng Zhang",
        "Jun Lou",
        "and Zengyou He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:54:16+00:00",
          "link": "https://arxiv.org/abs/2507.08382v1",
          "size": "1068kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T06:58:33+00:00",
          "link": "https://arxiv.org/abs/2507.08382v2",
          "size": "1067kb",
          "version": "v2"
        }
      ],
      "title": "Two-cluster test",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08382",
        "HTML": "https://arxiv.org/html/2507.08382v2",
        "PDF": "https://arxiv.org/pdf/2507.08382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on cluster analysis and significance testing, unrelated to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08917",
      "abstract": "The combination of highly realistic voice cloning, along with visually compelling avatar, face-swap, or lip-sync deepfake video generation, makes it relatively easy to create a video of anyone saying anything. Today, such deepfake impersonations are often used to power frauds, scams, and political disinformation. We propose a novel forensic machine learning technique for the detection of deepfake video impersonations that leverages unnatural patterns in facial biometrics. We evaluate this technique across a large dataset of deepfake techniques and impersonations, as well as assess its reliability to video laundering and its generalization to previously unseen video deepfake generators.",
      "authors": [
        "Justin D. Norman and Hany Farid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:29:25+00:00",
          "link": "https://arxiv.org/abs/2507.08917v1",
          "size": "1014kb",
          "version": "v1"
        }
      ],
      "title": "Detecting Deepfake Talking Heads from Facial Biometric Anomalies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08917",
        "HTML": "https://arxiv.org/html/2507.08917v1",
        "PDF": "https://arxiv.org/pdf/2507.08917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a technique for detecting deepfake videos based on facial biometrics and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09211",
      "abstract": "Observed records of climate extremes provide an incomplete picture of risk, missing \"unseen\" extremes that exceed historical bounds. In parallel, neglecting spatial dependence undervalues the risk of synchronized hazards that amplify impacts. To address these challenges, we develop DeepX-GAN (Dependence-Enhanced Embedding for Physical eXtremes - Generative Adversarial Network), a knowledge-informed deep generative model designed to better capture the spatial structure of rare extremes. The zero-shot generalizability of DeepX-GAN enables simulation of unseen extremes that fall outside historical experience yet remain statistically plausible. We define two types of unseen extremes: \"checkmate\" extremes that directly hit targets, and \"stalemate\" extremes that narrowly miss. These unrealized scenarios expose latent risks in fragile systems and may reinforce a false sense of resilience if overlooked. Near misses, in particular, can prompt either proactive adaptation or dangerous complacency, depending on how they are interpreted. Applying DeepX-GAN to the Middle East and North Africa (MENA), we find that these unseen extremes disproportionately affect regions with high vulnerability and low socioeconomic readiness, but differ in urgency and interpretation. Future warming could expand and redistribute these unseen extremes, with emerging exposure hotspots in Indo-Pakistan and Central Africa. This distributional shift highlights critical blind spots in conventional hazard planning and underscores the need to develop spatially adaptive policies that anticipate emergent risk hotspots rather than simply extrapolating from historical patterns.",
      "authors": [
        "Xinyue Liu",
        "Xiao Peng",
        "Shuyue Yan",
        "Yuntian Chen",
        "Dongxiao Zhang",
        "Zhixiao Niu",
        "Hui-Min Wang",
        "Xiaogang He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Geophysics (physics.geo-ph)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:06:45+00:00",
          "link": "https://arxiv.org/abs/2507.09211v1",
          "size": "16033kb",
          "version": "v1"
        }
      ],
      "title": "Capturing Unseen Spatial Extremes Through Knowledge-Informed Generative Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09211",
        "PDF": "https://arxiv.org/pdf/2507.09211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on climate modeling using a GAN framework and does not involve processing or creation of LLM training data or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09950",
      "abstract": "The fashion retail business is centered around the capacity to comprehend products. Product attribution helps in comprehending products depending on the business process. Quality attribution improves the customer experience as they navigate through millions of products offered by a retail website. It leads to well-organized product catalogs. In the end, product attribution directly impacts the 'discovery experience' of the customer. Although large language models (LLMs) have shown remarkable capabilities in understanding multimodal data, their performance on fine-grained fashion attribute recognition remains under-explored. This paper presents a zero-shot evaluation of state-of-the-art LLMs that balance performance with speed and cost efficiency, mainly GPT-4o-mini and Gemini 2.0 Flash. We have used the dataset DeepFashion-MultiModal (https://github.com/yumingj/DeepFashion-MultiModal) to evaluate these models in the attribution tasks of fashion products. Our study evaluates these models across 18 categories of fashion attributes, offering insight into where these models excel. We only use images as the sole input for product information to create a constrained environment. Our analysis shows that Gemini 2.0 Flash demonstrates the strongest overall performance with a macro F1 score of 56.79% across all attributes, while GPT-4o-mini scored a macro F1 score of 43.28%. Through detailed error analysis, our findings provide practical insights for deploying these LLMs in production e-commerce product attribution-related tasks and highlight the need for domain-specific fine-tuning approaches. This work also lays the groundwork for future research in fashion AI and multimodal attribute extraction.",
      "authors": [
        "Shubham Shukla",
        "Kunal Sonalkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:59:50+00:00",
          "link": "https://arxiv.org/abs/2507.09950v1",
          "size": "543kb",
          "version": "v1"
        }
      ],
      "title": "Can GPT-4o mini and Gemini 2.0 Flash Predict Fine-Grained Fashion Product Attributes? A Zero-Shot Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09950",
        "HTML": "https://arxiv.org/html/2507.09950v1",
        "PDF": "https://arxiv.org/pdf/2507.09950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper evaluates LLMs' performance on fashion product attribution tasks using existing datasets and does not focus on training data processing or new dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10183",
      "abstract": "Dynamic graph learning methods have recently emerged as powerful tools for modelling relational data evolving through time. However, despite extensive benchmarking efforts, it remains unclear whether current Temporal Graph Neural Networks (TGNNs) effectively capture core temporal patterns such as periodicity, cause-and-effect, and long-range dependencies. In this work, we introduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive set of synthetic tasks designed to systematically probe the capabilities of TGNNs to reason across time. T-GRAB provides controlled, interpretable tasks that isolate key temporal skills: counting/memorizing periodic repetitions, inferring delayed causal effects, and capturing long-range dependencies over both spatial and temporal dimensions. We evaluate 11 temporal graph learning methods on these tasks, revealing fundamental shortcomings in their ability to generalize temporal patterns. Our findings offer actionable insights into the limitations of current models, highlight challenges hidden by traditional real-world benchmarks, and motivate the development of architectures with stronger temporal reasoning abilities. The code for T-GRAB can be found at: https://github.com/alirezadizaji/T-GRAB.",
      "authors": [
        "Alireza Dizaji",
        "Benedict Aaron Tjandra",
        "Mehrab Hamidi",
        "Shenyang Huang",
        "Guillaume Rabusseau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:47:43+00:00",
          "link": "https://arxiv.org/abs/2507.10183v1",
          "size": "16346kb",
          "version": "v1"
        }
      ],
      "title": "T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10183",
        "HTML": "https://arxiv.org/html/2507.10183v1",
        "PDF": "https://arxiv.org/pdf/2507.10183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a synthetic benchmarking dataset (T-GRAB) for evaluating temporal graph models but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.14890",
      "abstract": "This paper tackles the problem of the worst-class error rate, instead of the standard error rate averaged over all classes. For example, a three-class classification task with class-wise error rates of 10%, 10%, and 40% has a worst-class error rate of 40%, whereas the average is 20% under the class-balanced condition. The worst-class error is important in many applications. For example, in a medical image classification task, it would not be acceptable for the malignant tumor class to have a 40% error rate, while the benign and healthy classes have a 10% error rates. To avoid overfitting in worst-class error minimization using Deep Neural Networks (DNNs), we design a problem formulation for bounding the worst-class error instead of achieving zero worst-class error. Moreover, to correctly bound the worst-class error, we propose a boosting approach which ensembles DNNs. We give training and generalization worst-class-error bound. Experimental results show that the algorithm lowers worst-class test error rates while avoiding overfitting to the training set.",
      "authors": [
        "Yuya Saito",
        "Shinnosuke Matsuo",
        "Seiichi Uchida",
        "Daiki Suehiro"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-20T07:49:10+00:00",
          "link": "https://arxiv.org/abs/2310.14890v1",
          "size": "6436kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:13:38+00:00",
          "link": "https://arxiv.org/abs/2310.14890v2",
          "size": "12931kb",
          "version": "v2"
        }
      ],
      "title": "Bounding the Worst-class Error: A Boosting Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.14890",
        "HTML": "https://arxiv.org/html/2310.14890v2",
        "PDF": "https://arxiv.org/pdf/2310.14890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a classification problem focusing on error rates and does not discuss any aspect of LLM training data collection or processing."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Medical Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.12079",
      "abstract": "PhoenixOS (PhOS) is the first OS service that can concurrently checkpoint and restore (C/R) GPU processes -- a fundamental capability for critical tasks such as fault tolerance, process migration, and fast startup. While concurrent C/R is well-established on CPUs, it poses unique challenges on GPUs due to their lack of essential features for efficiently tracing concurrent memory reads and writes, such as specific hardware capabilities (e.g., dirty bits) and OS-mediated data paths (e.g., copy-on-write). To ensure correct concurrent C/R, PhOS proactively detects GPU memory reads and writes through a two-step process: first, it speculates about GPU memory accesses based on the arguments used when launching GPU kernels; then, it validates these accesses efficiently at runtime using binary instrumentation. With this validated speculation, PhOS retrofits CPU-based concurrent C/R for GPUs through software-based approaches, including soft copy-on-write, soft recopy, and soft on-demand restore. PhOS further proposes several GPU-aware techniques for efficient GPU C/R, including coordinated checkpoint data transfer and execution context pool. For downstream tasks that use C/R for tolerating failures, migrating processes live, and accelerating cold starts in serverless computing, PHOS achieves orders of magnitude higher performance than state-of-the-art OS-level GPU C/R systems like NVIDIA cuda-checkpoint.",
      "authors": [
        "Xingda Wei",
        "Zhuobin Huang",
        "Tianle Sun",
        "Yingyi Hao",
        "Rong Chen",
        "Mingcong Han",
        "Jinyu Gu and Haibo Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T14:49:45+00:00",
          "link": "https://arxiv.org/abs/2405.12079v1",
          "size": "2290kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:24:02+00:00",
          "link": "https://arxiv.org/abs/2405.12079v2",
          "size": "3265kb",
          "version": "v2"
        }
      ],
      "title": "PhoenixOS: Concurrent OS-level GPU Checkpoint and Restore with Validated Speculation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.12079",
        "HTML": "https://arxiv.org/html/2405.12079v2",
        "PDF": "https://arxiv.org/pdf/2405.12079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses GPU checkpoint and restore systems for improved performance but does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.10268",
      "abstract": "In mathematical proof education, there remains a need for interventions that help students learn to write mathematical proofs. Research has shown that timely feedback can be very helpful to students learning new skills. While for many years natural language processing models have struggled to perform well on tasks related to mathematical texts, recent developments in natural language processing have created the opportunity to complete the task of giving students instant feedback on their mathematical proofs. In this paper, we present a set of training methods and models capable of autograding freeform mathematical proofs by leveraging existing large language models and other machine learning techniques. The models are trained using proof data collected from four different proof by induction problems. We use four different robust large language models to compare their performances, and all achieve satisfactory performances to various degrees. Additionally, we recruit human graders to grade the same proofs as the training data, and find that the best grading model is also more accurate than most human graders. With the development of these grading models, we create and deploy an autograder for proof by induction problems and perform a user study with students. Results from the study shows that students are able to make significant improvements to their proofs using the feedback from the autograder, but students still do not trust the AI autograders as much as they trust human graders. Future work can improve on the autograder feedback and figure out ways to help students trust AI autograders.",
      "authors": [
        "Chenyan Zhao",
        "Mariana Silva",
        "and Seth Poulsen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-11T15:30:26+00:00",
          "link": "https://arxiv.org/abs/2406.10268v1",
          "size": "885kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T06:18:20+00:00",
          "link": "https://arxiv.org/abs/2406.10268v2",
          "size": "894kb",
          "version": "v2"
        }
      ],
      "title": "Autograding Mathematical Induction Proofs with Natural Language Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10268",
        "HTML": "https://arxiv.org/html/2406.10268",
        "PDF": "https://arxiv.org/pdf/2406.10268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions training methods using proof data but primarily focuses on NLP models for autograding mathematical proofs rather than LLM training data processing techniques."
      },
      "tasks": [
        "Mathematical Induction",
        "Mathematical Proofs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07533",
      "abstract": "This study investigates the linguistic understanding of Large Language Models (LLMs) regarding signifier (form) and signified (meaning) by distinguishing two LLM assessment paradigms: psycholinguistic and neurolinguistic. Traditional psycholinguistic evaluations often reflect statistical rules that may not accurately represent LLMs' true linguistic competence. We introduce a neurolinguistic approach, utilizing a novel method that combines minimal pair and diagnostic probing to analyze activation patterns across model layers. This method allows for a detailed examination of how LLMs represent form and meaning, and whether these representations are consistent across languages. We found: (1) Psycholinguistic and neurolinguistic methods reveal that language performance and competence are distinct; (2) Direct probability measurement may not accurately assess linguistic competence; (3) Instruction tuning won't change much competence but improve performance; (4) LLMs exhibit higher competence and performance in form compared to meaning. Additionally, we introduce new conceptual minimal pair datasets for Chinese (COMPS-ZH) and German (COMPS-DE), complementing existing English datasets.",
      "authors": [
        "Linyang He",
        "Ercong Nie",
        "Helmut Schmid",
        "Hinrich Sch\\\"utze",
        "Nima Mesgarani",
        "Jonathan Brennan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T04:16:44+00:00",
          "link": "https://arxiv.org/abs/2411.07533v1",
          "size": "10156kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T20:08:00+00:00",
          "link": "https://arxiv.org/abs/2411.07533v2",
          "size": "40725kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T22:46:18+00:00",
          "link": "https://arxiv.org/abs/2411.07533v3",
          "size": "8160kb",
          "version": "v3"
        }
      ],
      "title": "Large Language Models as Neurolinguistic Subjects: Discrepancy between Performance and Competence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07533",
        "HTML": "https://arxiv.org/html/2411.07533v3",
        "PDF": "https://arxiv.org/pdf/2411.07533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces new datasets (COMPS-ZH, COMPS-DE) for evaluating linguistic competence of LLMs but doesn't focus on training data processing or improvements in data quality for model training."
      },
      "tasks": [
        "Diagnostic",
        "Form"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12642",
      "abstract": "SARS-CoV-2, the causative agent of COVID-19, remains a global health concern due to its high transmissibility and evolving variants. Although vaccination efforts and therapeutic advancements have mitigated disease severity, emerging mutations continue to challenge diagnostics and containment strategies. As of mid-February 2025, global test positivity has risen to 11%, marking the highest level in over six months despite widespread immunization efforts. Newer variants demonstrate enhanced host cell binding, increasing both infectivity and diagnostic complexity. This study evaluates the effectiveness of deep transfer learning in delivering rapid, accurate, and mutation-resilient COVID-19 diagnosis from medical imaging, with a focus on scalability and accessibility. We developed an automated detection system using state-of-the-art CNNs, including VGG16, ResNet50, ConvNetXtTiny, MobileNet, NASNetMobile, and DenseNet121 among others, to detect COVID-19 from chest X-ray and CT images. Among all the models evaluated, DenseNet121 emerged as the best-performing architecture for COVID-19 diagnosis using CT and X-ray images. It achieved an impressive accuracy of 98%, with 96.9% precision, 98.9% recall, 97.9% F1-score and 99.8% AUC score, indicating a high degree of consistency and reliability in both detecting positive and negative cases. The confusion matrix showed minimal false positives and false negatives, underscoring the model's robustness in real-world diagnostic scenarios.",
      "authors": [
        "Anjali Dharmik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T20:33:39+00:00",
          "link": "https://arxiv.org/abs/2503.12642v1",
          "size": "804kb",
          "version": "v1"
        },
        {
          "date": "2025-03-23T17:38:40+00:00",
          "link": "https://arxiv.org/abs/2503.12642v2",
          "size": "721kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T23:28:48+00:00",
          "link": "https://arxiv.org/abs/2503.12642v3",
          "size": "268kb",
          "version": "v3"
        }
      ],
      "title": "COVID-19 Pneumonia Diagnosis Using Medical Images: Deep Learning-Based Transfer Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12642",
        "HTML": "https://arxiv.org/html/2503.12642v3",
        "PDF": "https://arxiv.org/pdf/2503.12642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using transfer learning for COVID-19 diagnosis from medical images but does not discuss LLM training data processing."
      },
      "tasks": [
        "COVID-19 Diagnosis",
        "Diagnostic",
        "Specificity",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08835",
      "abstract": "The present work tackles the money laundering detection problem. A new procedure is introduced which exploits structured time series of both qualitative and quantitative data by means of a transformer neural network. The first step of this procedure aims at learning representations of time series through contrastive learning (without any labels). The second step leverages these representations to generate a money laundering scoring of all observations. A two-thresholds approach is then introduced, which ensures a controlled false-positive rate by means of the Benjamini-Hochberg (BH) procedure. Experiments confirm that the transformer is able to produce general representations that succeed in exploiting money laundering patterns with minimal supervision from domain experts. It also illustrates the higher ability of the new procedure for detecting nonfraudsters as well as fraudsters, while keeping the false positive rate under control. This greatly contrasts with rule-based procedures or the ones based on LSTM architectures.",
      "authors": [
        "Harold Gu\\'eneau (SAMM)",
        "Alain Celisse (LPP",
        "MODAL)",
        "Pascal Delange"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Statistics Theory (math.ST)",
        "Risk Management (q-fin.RM)",
        "Statistical Finance (q-fin.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T08:16:11+00:00",
          "link": "https://arxiv.org/abs/2507.08835v1",
          "size": "4576kb",
          "version": "v1"
        }
      ],
      "title": "Representation learning with a transformer by contrastive learning for money laundering detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08835",
        "PDF": "https://arxiv.org/pdf/2507.08835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of transformers for money laundering detection using contrastive learning, but it does not address the creation or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09580",
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across a variety of domains. However, their applications in cryptography, which serves as a foundational pillar of cybersecurity, remain largely unexplored. To address this gap, we propose \\textbf{AICrypto}, the first comprehensive benchmark designed to evaluate the cryptographic capabilities of LLMs. The benchmark comprises 135 multiple-choice questions, 150 capture-the-flag (CTF) challenges, and 18 proof problems, covering a broad range of skills from factual memorization to vulnerability exploitation and formal reasoning. All tasks are carefully reviewed or constructed by cryptography experts to ensure correctness and rigor. To support automated evaluation of CTF challenges, we design an agent-based framework. To gain deeper insight into the current state of cryptographic proficiency in LLMs, we introduce human expert performance baselines for comparison across all task types. Our evaluation of 17 leading LLMs reveals that state-of-the-art models match or even surpass human experts in memorizing cryptographic concepts, exploiting common vulnerabilities, and routine proofs. However, they still lack a deep understanding of abstract mathematical concepts and struggle with tasks that require multi-step reasoning and dynamic analysis. We hope this work could provide insights for future research on LLMs in cryptographic applications. Our code and dataset are available at https://aicryptobench.github.io.",
      "authors": [
        "Yu Wang",
        "Yijian Liu",
        "Liheng Ji",
        "Han Luo",
        "Wenjie Li",
        "Xiaofei Zhou",
        "Chiyun Feng",
        "Puji Wang",
        "Yuhan Cao",
        "Geyuan Zhang",
        "Xiaojian Li",
        "Rongwu Xu",
        "Yilei Chen",
        "Tianxing He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:11:01+00:00",
          "link": "https://arxiv.org/abs/2507.09580v1",
          "size": "756kb",
          "version": "v1"
        }
      ],
      "title": "AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09580",
        "PDF": "https://arxiv.org/pdf/2507.09580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating cryptographic capabilities of LLMs, focusing on model evaluation and task performance rather than training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09726",
      "abstract": "Public electric vehicle (EV) charging infrastructure is crucial for accelerating EV adoption and reducing transportation emissions; however, disparities in infrastructure access have raised significant equity concerns. This systematic review synthesizes existing knowledge and identifies gaps regarding equity in EV public charging research. Following structured review protocols, 91 peer-reviewed studies from Scopus and Google Scholar were analyzed, focusing explicitly on equity considerations. The findings indicate that current research on EV public charging equity mainly adopted geographic information systems (GIS), network optimization, behavioral modeling, and hybrid analytical frameworks, yet lacks consistent normative frameworks for assessing equity outcomes. Equity assessments highlight four key dimensions: spatial accessibility, cost burdens, reliability and usability, and user awareness and trust. Socio-economic disparities, particularly income, housing tenure, and ethnicity, frequently exacerbate inequitable access, disproportionately disadvantaging low-income, renter, and minority populations. Additionally, infrastructure-specific choices, including charger reliability, strategic location, and pricing strategies, significantly influence adoption patterns and equity outcomes. However, existing literature primarily reflects North American, European, and Chinese contexts, revealing substantial geographical and methodological limitations. This review suggests the need for more robust normative evaluations of equity, comprehensive demographic data integration, and advanced methodological frameworks, thereby guiding targeted, inclusive, and context-sensitive infrastructure planning and policy interventions.",
      "authors": [
        "Boyou Chen",
        "Kaihan Zhang",
        "Austin Moore",
        "Bochen Jia",
        "Mengqiu Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:57:06+00:00",
          "link": "https://arxiv.org/abs/2507.09726v1",
          "size": "1448kb",
          "version": "v1"
        }
      ],
      "title": "Electric Vehicle Public Charging Equity Considerations: A Systematic Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09726",
        "PDF": "https://arxiv.org/pdf/2507.09726"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews equity in electric vehicle charging infrastructure and does not discuss LLM training data processing or related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10062",
      "abstract": "Snapshot testing has emerged as a critical technique for UI validation in modern software development, yet it suffers from substantial maintenance overhead due to frequent UI changes causing test failures that require manual inspection to distinguish between genuine regressions and intentional design changes. This manual triage process becomes increasingly burdensome as applications evolve, creating a need for automated analysis solutions. This paper introduces LLMShot, a novel framework that leverages vision-based Large Language Models to automatically analyze snapshot test failures through hierarchical classification of UI changes. To evaluate LLMShot's effectiveness, we developed a comprehensive dataset using a feature-rich iOS application with configurable feature flags, creating realistic scenarios that produce authentic snapshot differences representative of real development workflows. Our evaluation using Gemma3 models demonstrates strong classification performance, with the 12B variant achieving over 84% recall in identifying failure root causes while the 4B model offers practical deployment advantages with acceptable performance for continuous integration environments. However, our exploration of selective ignore mechanisms revealed significant limitations in current prompting-based approaches for controllable visual reasoning. LLMShot represents the first automated approach to semantic snapshot test analysis, offering developers structured insights that can substantially reduce manual triage effort and advance toward more intelligent UI testing paradigms.",
      "authors": [
        "Erg\\\"un Batuhan Kaynak",
        "Mayasah Lami",
        "Sahand Moslemi",
        "Anil Koyuncu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.10062v1",
          "size": "1041kb",
          "version": "v1"
        }
      ],
      "title": "LLMShot: Reducing snapshot testing maintenance via LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10062",
        "HTML": "https://arxiv.org/html/2507.10062v1",
        "PDF": "https://arxiv.org/pdf/2507.10062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for snapshot test analysis using LLMs for UI validation and maintenance, without dealing with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10456",
      "abstract": "Non-metric music forms the core of the repertoire in Iranian classical music. Dastgahi music serves as the underlying theoretical system for both Iranian art music and certain folk traditions. At the heart of Iranian classical music lies the radif, a foundational repertoire that organizes melodic material central to performance and pedagogy.\n  In this study, we introduce the first digital corpus representing the complete non-metrical radif repertoire, covering all 13 existing components of this repertoire. We provide MIDI files (about 281 minutes in total) and data spreadsheets describing notes, note durations, intervals, and hierarchical structures for 228 pieces of music. We faithfully represent the tonality including quarter-tones, and the non-metric aspect. Furthermore, we provide supporting basic statistics, and measures of complexity and similarity over the corpus.\n  Our corpus provides a platform for computational studies of Iranian classical music. Researchers might employ it in studying melodic patterns, investigating improvisational styles, or for other tasks in music information retrieval, music theory, and computational (ethno)musicology.",
      "authors": [
        "Maziar Kanani",
        "Sean O Leary",
        "James McDermott"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:35:09+00:00",
          "link": "https://arxiv.org/abs/2507.10456v1",
          "size": "463kb",
          "version": "v1"
        }
      ],
      "title": "Radif corpus: a symbolic dataset for non-metric iranian classical music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10456",
        "HTML": "https://arxiv.org/html/2507.10456v1",
        "PDF": "https://arxiv.org/pdf/2507.10456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the creation of a symbolic dataset for non-metric Iranian classical music, with no relation to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06848",
      "abstract": "Diffusion models produce impressive results in modalities ranging from images and video to protein design and text. However, generating samples with user-specified properties remains a challenge. Recent research proposes fine-tuning models to maximize rewards that capture desired properties, but these methods require expensive training and are prone to mode collapse. In this work, we present Feynman-Kac (FK) steering, an inference-time framework for steering diffusion models with reward functions. FK steering works by sampling a system of multiple interacting diffusion processes, called particles, and resampling particles at intermediate steps based on scores computed using functions called potentials. Potentials are defined using rewards for intermediate states and are selected such that a high value indicates that the particle will yield a high-reward sample. We explore various choices of potentials, intermediate rewards, and samplers. We evaluate FK steering on text-to-image and text diffusion models. For steering text-to-image models with a human preference reward, we find that FK steering a 0.8B parameter model outperforms a 2.6B parameter fine-tuned model on prompt fidelity, with faster sampling and no training. For steering text diffusion models with rewards for text quality and specific text attributes, we find that FK steering generates lower perplexity, more linguistically acceptable outputs and enables gradient-free control of attributes like toxicity. Our results demonstrate that inference-time scaling and steering of diffusion models - even with off-the-shelf rewards - can provide significant sample quality gains and controllability benefits. Code is available at https://github.com/zacharyhorvitz/Fk-Diffusion-Steering .",
      "authors": [
        "Raghav Singhal",
        "Zachary Horvitz",
        "Ryan Teehan",
        "Mengye Ren",
        "Zhou Yu",
        "Kathleen McKeown",
        "Rajesh Ranganath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T15:34:24+00:00",
          "link": "https://arxiv.org/abs/2501.06848v1",
          "size": "21362kb",
          "version": "v1"
        },
        {
          "date": "2025-01-15T18:28:37+00:00",
          "link": "https://arxiv.org/abs/2501.06848v2",
          "size": "21363kb",
          "version": "v2"
        },
        {
          "date": "2025-01-16T03:18:14+00:00",
          "link": "https://arxiv.org/abs/2501.06848v3",
          "size": "25224kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T01:12:12+00:00",
          "link": "https://arxiv.org/abs/2501.06848v4",
          "size": "21364kb",
          "version": "v4"
        }
      ],
      "title": "A General Framework for Inference-time Scaling and Steering of Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06848",
        "HTML": "https://arxiv.org/html/2501.06848v4",
        "PDF": "https://arxiv.org/pdf/2501.06848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on inference-time steering of diffusion models rather than training data processing or dataset creation."
      },
      "tasks": [
        "Protein Design"
      ],
      "repo_urls": [
        "https://github.com/zacharyhorvitz/fk-diffusion-steering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09470",
      "abstract": "This study explores the optimization of the DRAGON Longformer base model for clinical text classification, specifically targeting the binary classification of medical case descriptions. A dataset of 500 clinical cases containing structured medical observations was used, with 400 cases for training and 100 for validation. Enhancements to the pre-trained joeranbosma/dragon-longformer-base-mixed-domain model included hyperparameter tuning, domain-specific preprocessing, and architectural adjustments. Key modifications involved increasing sequence length from 512 to 1024 tokens, adjusting learning rates from 1e-05 to 5e-06, extending training epochs from 5 to 8, and incorporating specialized medical terminology. The optimized model achieved notable performance gains: accuracy improved from 72.0% to 85.2%, precision from 68.0% to 84.1%, recall from 75.0% to 86.3%, and F1-score from 71.0% to 85.2%. Statistical analysis confirmed the significance of these improvements (p < .001). The model demonstrated enhanced capability in interpreting medical terminology, anatomical measurements, and clinical observations. These findings contribute to domain-specific language model research and offer practical implications for clinical natural language processing applications. The optimized model's strong performance across diverse medical conditions underscores its potential for broad use in healthcare settings.",
      "authors": [
        "Mingchuan Yang",
        "Ziyuan Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:10:19+00:00",
          "link": "https://arxiv.org/abs/2507.09470v1",
          "size": "256kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09470",
        "PDF": "https://arxiv.org/pdf/2507.09470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on optimizing model performance through fine-tuning, including some domain-specific preprocessing, but it does not contribute new techniques or insights specifically on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09546",
      "abstract": "With the exponential growth of smart devices connected to wireless networks, data production is increasing rapidly, requiring machine learning (ML) techniques to unlock its value. However, the centralized ML paradigm raises concerns over communication overhead and privacy. Federated learning (FL) offers an alternative at the network edge, but practical deployment in wireless networks remains challenging. This paper proposes a lightweight FL (LTFL) framework integrating wireless transmission power control, model pruning, and gradient quantization. We derive a closed-form expression of the FL convergence gap, considering transmission error, model pruning error, and gradient quantization error. Based on these insights, we formulate an optimization problem to minimize the convergence gap while meeting delay and energy constraints. To solve the non-convex problem efficiently, we derive closed-form solutions for the optimal model pruning ratio and gradient quantization level, and employ Bayesian optimization for transmission power control. Extensive experiments on real-world datasets show that LTFL outperforms state-of-the-art schemes.",
      "authors": [
        "Xiangwang Hou",
        "Jingjing Wang",
        "Jun Du",
        "Chunxiao Jiang",
        "Yong Ren",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T09:14:17+00:00",
          "link": "https://arxiv.org/abs/2507.09546v1",
          "size": "603kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Federated Learning over Wireless Edge Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09546",
        "HTML": "https://arxiv.org/html/2507.09546v1",
        "PDF": "https://arxiv.org/pdf/2507.09546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper explores federated learning, it focuses on model optimization techniques within wireless networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10068",
      "abstract": "We introduce Berman-intersection-dual Berman (BiD) codes. These are abelian codes of length $3^m$ that can be constructed using Kronecker products of a $3 \\times 3$ kernel matrix. BiD codes offer minimum distance close to that of Reed-Muller (RM) codes at practical blocklengths, and larger distance than RM codes asymptotically in the blocklength. Simulations of BiD codes of length $3^5=243$ in the erasure and Gaussian channels show that their block error rates under maximum-likelihood decoding are similar to, and sometimes better, than RM, RM-Polar, and CRC-aided Polar codes.",
      "authors": [
        "Anirudh Dash and K. R. Nandakishore and Lakshmi Prasad Natarajan and Prasad Krishnan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:52:58+00:00",
          "link": "https://arxiv.org/abs/2507.10068v1",
          "size": "256kb",
          "version": "v1"
        }
      ],
      "title": "BiD Codes: Algebraic Codes from $3 \\times 3$ Kernel",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10068",
        "HTML": "https://arxiv.org/html/2507.10068v1",
        "PDF": "https://arxiv.org/pdf/2507.10068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new type of algebraic code, which is unrelated to LLM training data processing or dataset management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10136",
      "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ``hit-and-run\" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.",
      "authors": [
        "Zhonglin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.10136v1",
          "size": "674kb",
          "version": "v1"
        }
      ],
      "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run'' Therapeutic Strategy in Melanoma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10136",
        "HTML": "https://arxiv.org/html/2507.10136v1",
        "PDF": "https://arxiv.org/pdf/2507.10136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a probabilistic model to discover therapeutic strategies in melanoma and employs reinforcement learning for intervention protocols, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10202",
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding, reasoning, and generation. However, they struggle with tasks requiring fine-grained localization and reasoning in high-resolution images. This constraint stems from the fact that MLLMs are fine-tuned with fixed image resolution to align with the pre-trained image encoder used in MLLM. Consequently, feeding high-resolution images directly into MLLMs leads to poor generalization due to a train-test resolution discrepancy, while downsampling these images-although ensuring consistency-compromises fine-grained visual details and ultimately degrades performance. To address this challenge, we propose Extract Candidate then Predict (ECP), a novel training-free, task-agnostic two-stage framework designed to enhance MLLM performance on high-resolution images. The key intuition behind ECP is that while MLLMs struggle with high-resolution images, their predictions on downsampled images still contain implicit localization cues. By first identifying candidate region using the coarse prediction and then predicting the final output based on candidate region, ECP effectively preserves fine-grained details while mitigating the challenges posed by high-resolution data. We validate our framework on 4K GUI grounding and 4K, 8K MLLM perception, achieving +21.3%, +5.8%, +5.2% absolute improvement compared to baseline respectively, demonstrating its effectiveness. Code is available at https://github.com/yenncye/ECP.",
      "authors": [
        "Jaeseong Lee",
        "Yeeun Choi",
        "Heechan Choi",
        "Hanjung Kim",
        "Seonjoo Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:14:53+00:00",
          "link": "https://arxiv.org/abs/2507.10202v1",
          "size": "2111kb",
          "version": "v1"
        }
      ],
      "title": "A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10202",
        "HTML": "https://arxiv.org/html/2507.10202v1",
        "PDF": "https://arxiv.org/pdf/2507.10202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving multimodal large language model performance on high-resolution images through a framework called Extract Candidate then Predict (ECP). It does not address training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08914",
      "abstract": "Adolescents increasingly rely on online technologies to explore their identities, form social connections, and access information and entertainment. However, their growing digital engagement exposes them to significant online risks, particularly in underrepresented contexts like West Africa. This study investigates the online experiences of 409 secondary school adolescents in Nigeria's Federal Capital Territory (FCT), focusing on their access to technology, exposure to risks, coping strategies, key stakeholders influencing their online interactions, and recommendations for improving online safety. Using self-administered surveys, we found that while most adolescents reported moderate access to online technology and connectivity, those who encountered risks frequently reported exposure to inappropriate content and online scams. Blocking and reporting tools were the most commonly used strategies, though some adolescents responded with inaction due to limited resources or awareness. Parents emerged as the primary support network, though monitoring practices and communication varied widely. Guided by Protection Motivation Theory (PMT), our analysis interprets adolescents' online safety behaviors as shaped by both their threat perceptions and their confidence in available coping strategies. A thematic analysis of their recommendations highlights the need for greater awareness and education, parental mediation, enhanced safety tools, stricter age restrictions, improved content moderation, government accountability, and resilience-building initiatives. Our findings underscore the importance of culturally and contextually relevant interventions to empower adolescents in navigating the digital world, with implications for parents, educators, designers, and policymakers.",
      "authors": [
        "Munachimso B. Oguine and Ozioma C. Oguine and Karla Badillo-Urquiola and Oluwasogo Adekunle Okunade"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:39:01+00:00",
          "link": "https://arxiv.org/abs/2507.08914v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "'Teens Need to Be Educated on the Danger': Digital Access, Online Risks, and Safety Practices Among Nigerian Adolescents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08914",
        "PDF": "https://arxiv.org/pdf/2507.08914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the online experiences of adolescents in Nigeria and recommendations for improving online safety, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09019",
      "abstract": "The rapid evolution of Large Language Model (LLM) inference systems has yielded significant efficiency improvements. However, our systematic analysis reveals that current evaluation methodologies frequently exhibit fundamental flaws, often manifesting as common evaluation anti-patterns that obscure true performance characteristics and impede scientific progress. Through a comprehensive examination of recent systems, we identify recurring anti-patterns across three key dimensions: Baseline Fairness, Evaluation Setup, and Metric Design. These anti-patterns are uniquely problematic for LLM inference due to its dual-phase nature combining distinct prefill and decode operations, its handling of highly heterogeneous workloads, and its strict temporal requirements for interactive use. We demonstrate how common anti-patterns -- such as inadequate baseline comparisons that conflate engineering effort with algorithmic novelty, workload selections that fail to represent production scenarios, and metric normalizations that hide substantial performance variability like generation stalls-lead to misleading conclusions. To address these challenges, we provide a comprehensive checklist derived from our analysis, establishing a framework for recognizing and avoiding these anti-patterns in favor of robust LLM inference evaluation. To demonstrate the practical application of our framework, we present a case study analyzing speculative decoding, a technique whose bursty, non-uniform token generation is easily misinterpreted when evaluated using approaches characteristic of these anti-patterns. Our work establishes a rigorous foundation for evaluation methodology, enabling meaningful comparisons, ensuring reproducible results, and ultimately accelerating genuine progress in LLM inference systems by moving beyond common anti-patterns to align evaluation with real-world requirements.",
      "authors": [
        "Amey Agrawal",
        "Nitin Kedia",
        "Anmol Agarwal",
        "Jayashree Mohan",
        "Nipun Kwatra",
        "Souvik Kundu",
        "Ramachandran Ramjee",
        "Alexey Tumanov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:58:21+00:00",
          "link": "https://arxiv.org/abs/2507.09019v1",
          "size": "597kb",
          "version": "v1"
        }
      ],
      "title": "On Evaluating Performance of LLM Inference Serving Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09019",
        "HTML": "https://arxiv.org/html/2507.09019v1",
        "PDF": "https://arxiv.org/pdf/2507.09019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLM inference systems and their performance, without discussing any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09167",
      "abstract": "We present a novel approach for the procedural construction of multi-step contact-rich manipulation tasks in robotics. Our generator takes as input user-defined sets of atomic actions, objects, and spatial predicates and outputs solvable tasks of a given length for the selected robotic environment. The generator produces solvable tasks by constraining all possible (nonsolvable) combinations by symbolic and physical validation. The symbolic validation checks each generated sequence for logical and operational consistency, and also the suitability of object-predicate relations. Physical validation checks whether tasks can be solved in the selected robotic environment. Only the tasks that passed both validators are retained. The output from the generator can be directly interfaced with any existing framework for training robotic manipulation tasks, or it can be stored as a dataset of curated robotic tasks with detailed information about each task. This is beneficial for RL training as there are dense reward functions and initial and goal states paired with each subgoal. It allows the user to measure the semantic similarity of all generated tasks. We tested our generator on sequences of up to 15 actions resulting in millions of unique solvable multi-step tasks.",
      "authors": [
        "Michal Vavrecka",
        "Radoslav Skoviera",
        "Gabriela Sejnova",
        "Karla Stepanova"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:07:10+00:00",
          "link": "https://arxiv.org/abs/2507.09167v1",
          "size": "1533kb",
          "version": "v1"
        }
      ],
      "title": "PRAG: Procedural Action Generator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09167",
        "HTML": "https://arxiv.org/html/2507.09167v1",
        "PDF": "https://arxiv.org/pdf/2507.09167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a generator for creating datasets of procedural robotic tasks with symbolic and physical validation, focusing on dataset creation and data generation processes relevant to training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09231",
      "abstract": "Transparency is one of the key benefits of public blockchains. However, the public visibility of transactions potentially compromises users' privacy. The fundamental challenge is to balance the intrinsic benefits of blockchain openness with the vital need for individual confidentiality. The proposal suggests creating a confidential version of wrapped Ethereum (cWETH) fully within the application layer. The solution combines the Elliptic Curve (EC) Twisted ElGamal-based commitment scheme to preserve confidentiality and the EC Diffie-Hellman (DH) protocol to introduce accessibility limited by the commitment scheme. To enforce the correct generation of commitments, encryption, and decryption, zk-SNARKs are utilized.",
      "authors": [
        "Artem Chystiakov",
        "Mariia Zhvanko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:00:50+00:00",
          "link": "https://arxiv.org/abs/2507.09231v1",
          "size": "943kb",
          "version": "v1"
        }
      ],
      "title": "Confidential Wrapped Ethereum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09231",
        "HTML": "https://arxiv.org/html/2507.09231v1",
        "PDF": "https://arxiv.org/pdf/2507.09231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses blockchain technology and privacy mechanisms for Ethereum, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09515",
      "abstract": "We give new lower bounds for the fragments of the Ideal Proof System (IPS) introduced by Grochow and Pitassi (JACM 2018). The Ideal Proof System is a central topic in algebraic proof complexity developed in the context of Nullstellensatz refutation (Beame, Impagliazzo, Krajicek, Pitassi, Pudlak, FOCS 1994) and simulates Extended Frege efficiently. Our main results are as follows.\n  1. mult-IPS_{Lin'}: We prove nearly quadratic-size formula lower bound for multilinear refutation (over the Boolean hypercube) of a variant of the subset-sum axiom polynomial. Extending this, we obtain a nearly matching qualitative statement for a constant degree target polynomial.\n  2. IPS_{Lin'}: Over the fields of characteristic zero, we prove exponential-size sum-of-ROABPs lower bound for the refutation of a variant of the subset-sum axiom polynomial. The result also extends over the fields of positive characteristics when the target polynomial is suitably modified. The modification is inspired by the recent results (Hakoniemi, Limaye, Tzameret, STOC 2024 and Behera, Limaye, Ramanathan, Srinivasan, ICALP 2025).\n  The mult-IPS_{Lin'} lower bound result is obtained by combining the quadratic-size formula lower bound technique of Kalorkoti (SICOMP 1985) with some additional ideas. The proof technique of IPS_{Lin'} lower bound result is inspired by the recent lower bound result of Chatterjee, Kush, Saraf and Shpilka (CCC 2024).",
      "authors": [
        "Prerona Chatterjee",
        "Utsab Ghosal",
        "Partha Mukhopadhyay",
        "Amit Sinhababu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.09515v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "IPS Lower Bounds for Formulas and Sum of ROABPs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09515",
        "HTML": "https://arxiv.org/html/2507.09515v1",
        "PDF": "https://arxiv.org/pdf/2507.09515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents new lower bounds related to the Ideal Proof System, which involves algebraic proof complexity rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09788",
      "abstract": "Recent advances in Large Language Models (LLM) have led to a new class of autonomous agents, renewing and expanding interest in the area. LLM-powered Multiagent Systems (MAS) have thus emerged, both for assistive and simulation purposes, yet tools for realistic human behavior simulation -- with its distinctive challenges and opportunities -- remain underdeveloped. Existing MAS libraries and tools lack fine-grained persona specifications, population sampling facilities, experimentation support, and integrated validation, among other key capabilities, limiting their utility for behavioral studies, social simulation, and related applications. To address these deficiencies, in this work we introduce TinyTroupe, a simulation toolkit enabling detailed persona definitions (e.g., nationality, age, occupation, personality, beliefs, behaviors) and programmatic control via numerous LLM-driven mechanisms. This allows for the concise formulation of behavioral problems of practical interest, either at the individual or group level, and provides effective means for their solution. TinyTroupe's components are presented using representative working examples, such as brainstorming and market research sessions, thereby simultaneously clarifying their purpose and demonstrating their usefulness. Quantitative and qualitative evaluations of selected aspects are also provided, highlighting possibilities, limitations, and trade-offs. The approach, though realized as a specific Python implementation, is meant as a novel conceptual contribution, which can be partially or fully incorporated in other contexts. The library is available as open source at https://github.com/microsoft/tinytroupe.",
      "authors": [
        "Paulo Salem",
        "Robert Sim",
        "Christopher Olsen",
        "Prerit Saxena",
        "Rafael Barcelos",
        "Yi Ding"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:00:27+00:00",
          "link": "https://arxiv.org/abs/2507.09788v1",
          "size": "1685kb",
          "version": "v1"
        }
      ],
      "title": "TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09788",
        "HTML": "https://arxiv.org/html/2507.09788v1",
        "PDF": "https://arxiv.org/pdf/2507.09788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a toolkit for simulating personas with LLMs but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10007",
      "abstract": "Chain of Thought (CoT) reasoning has demonstrated remarkable deep reasoning capabilities in both large language models (LLMs) and multimodal large language models (MLLMs). However, its reliability is often undermined by the accumulation of errors in intermediate steps. This paper introduces an novel approach to calibrate the CoT reasoning accuracy by leveraging the model's intrinsic veracity encoding. We discover that specific attention head activations reliably reflect the truthfulness of reasoning steps in CoT. Based on this insight, we train a confidence predictor to evaluate the correctness of each reasoning step using these truthfulness-sensitive activations, dynamically selecting the most plausible reasoning path via beam search. Experimental results demonstrate that our method significantly outperforms the state-of-the-art baselines (e.g., Few-Shot CoT, Self-Consistency, and Self-Evaluation Guided Beam Search) across the mathematical, symbolic, and commonsense reasoning tasks, exhibiting superior accuracy and reliability in both unimodal and multimodal settings. We further validate the approach on large reasoning models, confirming its applicability to specialized reasoning models. Additionally, we explore the role of the model's self-correction ability in CoT reasoning. This work provides a novel reliability improvement path for CoT reasoning with broad application potential.",
      "authors": [
        "Zijun Chen",
        "Wenbo Hu",
        "Richang Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:41:35+00:00",
          "link": "https://arxiv.org/abs/2507.10007v1",
          "size": "918kb",
          "version": "v1"
        }
      ],
      "title": "Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10007",
        "HTML": "https://arxiv.org/html/2507.10007v1",
        "PDF": "https://arxiv.org/pdf/2507.10007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method to improve CoT reasoning in LLMs but does not focus on the processing or modification of training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2211.05031",
      "abstract": "Automatic keyword extraction (AKE) has gained more importance with the increasing amount of digital textual data that modern computing systems process. It has various applications in information retrieval (IR) and natural language processing (NLP), including text summarisation, topic analysis and document indexing. This paper proposes a simple but effective post-processing-based universal approach to improve the performance of any AKE methods, via an enhanced level of semantic-awareness supported by PoS-tagging. To demonstrate the performance of the proposed approach, we considered word types retrieved from a PoS-tagging step and two representative sources of semantic information - specialised terms defined in one or more context-dependent thesauri, and named entities in Wikipedia. The above three steps can be simply added to the end of any AKE methods as part of a post-processor, which simply re-evaluate all candidate keywords following some context-specific and semantic-aware criteria. For five state-of-the-art (SOTA) AKE methods, our experimental results with 17 selected datasets showed that the proposed approach improved their performances both consistently (up to 100% in terms of improved cases) and significantly (between 10.2% and 53.8%, with an average of 25.8%, in terms of F1-score and across all five methods), especially when all the three enhancement steps are used. Our results have profound implications considering the ease to apply our proposed approach to any AKE methods and to further extend it.",
      "authors": [
        "Enes Altuncu",
        "Jason R.C. Nurse",
        "Yang Xu",
        "Jie Guo",
        "Shujun Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-09T17:04:13+00:00",
          "link": "https://arxiv.org/abs/2211.05031v1",
          "size": "311kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T14:42:31+00:00",
          "link": "https://arxiv.org/abs/2211.05031v2",
          "size": "360kb",
          "version": "v2"
        }
      ],
      "title": "Improving Performance of Automatic Keyword Extraction (AKE) Methods Using PoS-Tagging and Enhanced Semantic-Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.05031",
        "HTML": "https://arxiv.org/html/2211.05031",
        "PDF": "https://arxiv.org/pdf/2211.05031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements to automatic keyword extraction methods but does not contribute to LLM training data processing."
      },
      "tasks": [
        "Information Retrieval",
        "Keyword Extraction",
        "POS",
        "POS Tagging",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06793",
      "abstract": "This paper proposes a differentially private gradient-tracking-based distributed stochastic optimization algorithm over directed graphs. In particular, privacy noises are incorporated into each agent's state and tracking variable to mitigate information leakage, after which the perturbed states and tracking variables are transmitted to neighbors. We design two novel schemes for the step-sizes and the sampling number within the algorithm. The sampling parameter-controlled subsampling method employed by both schemes enhances the differential privacy level, and ensures a finite cumulative privacy budget even over infinite iterations. The algorithm achieves both almost sure and mean square convergence for nonconvex objectives. Furthermore, when nonconvex objectives satisfy the Polyak-Lojasiewicz condition, Scheme (S1) achieves a polynomial mean square convergence rate, and Scheme (S2) achieves an exponential mean square convergence rate. The trade-off between privacy and convergence is presented. The effectiveness of the algorithm and its superior performance compared to existing works are illustrated through numerical examples of distributed training on the benchmark datasets \"MNIST\" and \"CIFAR-10\".",
      "authors": [
        "Jialong Chen",
        "Jimin Wang",
        "Ji-Feng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T12:10:42+00:00",
          "link": "https://arxiv.org/abs/2501.06793v1",
          "size": "433kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T12:17:06+00:00",
          "link": "https://arxiv.org/abs/2501.06793v2",
          "size": "462kb",
          "version": "v2"
        }
      ],
      "title": "Differentially Private Gradient-Tracking-Based Distributed Stochastic Optimization over Directed Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06793",
        "HTML": "https://arxiv.org/html/2501.06793v2",
        "PDF": "https://arxiv.org/pdf/2501.06793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses distributed training with privacy considerations using known datasets, MNIST and CIFAR-10, without focusing on new data processing methods or dataset creation."
      },
      "tasks": [
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12992",
      "abstract": "Post-hoc explanation methods for black-box models often struggle with faithfulness and human interpretability due to the lack of explainability in current neural architectures. Meanwhile, B-cos networks have been introduced to improve model explainability by proposing an architecture that removes bias terms and promotes input-weight alignment. Although B-cos networks have shown success in building explainable systems, their application has so far been limited to computer vision models and their associated training pipelines. In this work, we introduce B-cos LMs, i.e., B-cos language models (LMs) empowered for natural language processing (NLP) tasks. Our approach directly transforms pre-trained language models into B-cos LMs by combining B-cos conversion and task fine-tuning, improving efficiency compared to previous methods. Our automatic and human evaluation results demonstrate that B-cos LMs produce more faithful and human interpretable explanations than post-hoc methods, while maintaining task performance comparable to conventional fine-tuning. Our in-depth analysis explores how B-cos LMs differ from conventionally fine-tuned models in their learning processes and explanation patterns. Finally, we are also the first to explore the transformation of decoder-only models to B-cos LMs for generation tasks.",
      "authors": [
        "Yifan Wang",
        "Sukrut Rao",
        "Ji-Ung Lee",
        "Mayank Jobanputra and Vera Demberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T16:13:08+00:00",
          "link": "https://arxiv.org/abs/2502.12992v1",
          "size": "9468kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:11:13+00:00",
          "link": "https://arxiv.org/abs/2502.12992v2",
          "size": "8839kb",
          "version": "v2"
        }
      ],
      "title": "B-cos LM: Efficiently Transforming Pre-trained Language Models for Improved Explainability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12992",
        "HTML": "https://arxiv.org/html/2502.12992v2",
        "PDF": "https://arxiv.org/pdf/2502.12992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses transforming pre-trained language models to improve explainability but does not focus on LLM training data processing or creating datasets, hence it does not align with core processing tasks."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.01248",
      "abstract": "Diabetic retinopathy (DR) is a leading cause of vision loss, requiring early and accurate assessment to prevent irreversible damage. Spectral Domain Optical Coherence Tomography (SD-OCT) enables high-resolution retinal imaging, but automated segmentation performance varies, especially in cases with complex fluid and hyperreflective foci (HRF) patterns. This study proposes an active-learning-based deep learning pipeline for automated segmentation of retinal layers, fluid, and HRF, using four state-of-the-art models: U-Net, SegFormer, SwinUNETR, and VM-UNet, trained on expert-annotated SD-OCT volumes. Segmentation accuracy was evaluated with five-fold cross-validation, and retinal thickness was quantified using a K-nearest neighbors algorithm and visualized with Early Treatment Diabetic Retinopathy Study (ETDRS) maps. SwinUNETR achieved the highest overall accuracy (DSC = 0.7719; NSD = 0.8149), while VM-UNet excelled in specific layers. Structural differences were observed between non-proliferative and proliferative DR, with layer-specific thickening correlating with visual acuity impairment. The proposed framework enables robust, clinically relevant DR assessment while reducing the need for manual annotation, supporting improved disease monitoring and treatment planning.",
      "authors": [
        "S. Chen",
        "D. Ma",
        "M. Raviselvan",
        "S. Sundaramoorthy",
        "K. Popuri",
        "M. J. Ju",
        "M. V. Sarunic",
        "D. Ratra and M. F. Beg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Tissues and Organs (q-bio.TO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T07:23:56+00:00",
          "link": "https://arxiv.org/abs/2503.01248v1",
          "size": "33716kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T19:32:18+00:00",
          "link": "https://arxiv.org/abs/2503.01248v2",
          "size": "14639kb",
          "version": "v2"
        },
        {
          "date": "2025-04-11T03:23:52+00:00",
          "link": "https://arxiv.org/abs/2503.01248v3",
          "size": "17471kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T15:52:05+00:00",
          "link": "https://arxiv.org/abs/2503.01248v4",
          "size": "17310kb",
          "version": "v4"
        }
      ],
      "title": "Comprehensive Evaluation of OCT-based Automated Segmentation of Retinal Layer, Fluid and Hyper-Reflective Foci: Impact on Clinical Assessment of Diabetic Retinopathy Severity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01248",
        "HTML": "https://arxiv.org/html/2503.01248v4",
        "PDF": "https://arxiv.org/pdf/2503.01248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with automated segmentation in retinal images for medical diagnostics, not involving language model training data processing."
      },
      "tasks": [
        "Active Learning",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01410",
      "abstract": "The ontological and epistemic complexities inherent in the moral domain make it challenging to establish clear standards for evaluating the performance of a moral machine. In this paper, we present a formal method to describe Ethical Decision Making models based on ethical risk assessment. Then, we show how these models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets. A case study from the medical field is considered to illustrate the proposed approach.",
      "authors": [
        "Abeer Dyoub and Francesca A. Lisi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T07:05:11+00:00",
          "link": "https://arxiv.org/abs/2507.01410v1",
          "size": "304kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:38:44+00:00",
          "link": "https://arxiv.org/abs/2507.01410v2",
          "size": "301kb",
          "version": "v2"
        }
      ],
      "title": "A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01410",
        "HTML": "https://arxiv.org/html/2507.01410v2",
        "PDF": "https://arxiv.org/pdf/2507.01410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ethical decision-making models using fuzzy logic, with no mention of LLM training data or data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07911",
      "abstract": "Immersive virtual reality (VR) is a promising tool for stress reduction and relaxation, traditionally relying on visual and auditory stimuli. This study examines the role of olfactory stimuli in enhancing these effects, using a randomized within-subject design. Thirty participants aged 18-60 experienced VR scenarios simulating a calming seaside environment, with sessions lasting 45 minutes, in two conditions: with and without a \"Beach\" essential oil scent (Yankee Candle) administered via diffuser. Stress and relaxation were assessed through self-reported surveys and physiological measures, specifically ECG-based heart rate variability (HRV). Results showed no significant difference in self-reported relaxation scores (p=0.371) between conditions, but HRV analysis revealed a significant stress reduction (p=0.002) with olfactory input, with HF increasing 108% from the Math Stress Test to the scented relaxation condition, compared to 44% without scent. Additionally, 71.4% of participants expressed willingness to use olfactory-enhanced VR for relaxation, suggesting practical appeal. These findings indicate that olfactory stimuli may enhance relaxation subconsciously, underscoring the importance of multisensory integration in VR. Future work could explore personalized scents and long-term effects to optimize VR- based interventions for emotional and physical well-being.",
      "authors": [
        "Yasmin Elsaddik Valdivieso",
        "Mohd Faisal",
        "Karim Alghoul",
        "Monireh (Monica) Vahdati",
        "Kamran Gholizadeh Hamlabadi",
        "Fedwa Laamarti",
        "Hussein Al Osman",
        "Abdulmotaleb El Saddik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:45:10+00:00",
          "link": "https://arxiv.org/abs/2507.07911v1",
          "size": "602kb",
          "version": "v1"
        }
      ],
      "title": "The Potential of Olfactory Stimuli in Stress Reduction through Virtual Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07911",
        "PDF": "https://arxiv.org/pdf/2507.07911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about the use of olfactory stimuli in virtual reality for stress reduction and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09602",
      "abstract": "Federated learning enables collaborative machine learning while preserving data privacy. However, the rise of federated unlearning, designed to allow clients to erase their data from the global model, introduces new privacy concerns. Specifically, the gradient exchanges during the unlearning process can leak sensitive information about deleted data. In this paper, we introduce DRAGD, a novel attack that exploits gradient discrepancies before and after unlearning to reconstruct forgotten data. We also present DRAGDP, an enhanced version of DRAGD that leverages publicly available prior data to improve reconstruction accuracy, particularly for complex datasets like facial images. Extensive experiments across multiple datasets demonstrate that DRAGD and DRAGDP significantly outperform existing methods in data reconstruction.Our work highlights a critical privacy vulnerability in federated unlearning and offers a practical solution, advancing the security of federated unlearning systems in real-world applications.",
      "authors": [
        "Bocheng Ju",
        "Junchao Fan",
        "Jiaqi Liu",
        "Xiaolin Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:16:43+00:00",
          "link": "https://arxiv.org/abs/2507.09602v1",
          "size": "1265kb",
          "version": "v1"
        }
      ],
      "title": "DRAGD: A Federated Unlearning Data Reconstruction Attack Based on Gradient Differences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09602",
        "PDF": "https://arxiv.org/pdf/2507.09602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses federated learning and federated unlearning data reconstruction attacks, but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09929",
      "abstract": "This work investigates speech enhancement (SE) from the perspective of language models (LMs). We propose a novel method that leverages Direct Preference Optimization (DPO) to improve the perceptual quality of enhanced speech. Using UTMOS, a neural MOS prediction model, as a proxy for human ratings, our approach guides optimization toward perceptually preferred outputs. This differs from existing LM-based SE methods that focus on maximizing the likelihood of clean speech tokens, which may misalign with human perception and degrade quality despite low prediction error. Experiments on the 2020 Deep Noise Suppression Challenge test sets demonstrate that applying DPO to a pretrained LM-based SE model yields consistent improvements across various speech quality metrics, with relative gains of up to 56%. To our knowledge, this is the first application of DPO to SE and the first to incorporate proxy perceptual feedback into LM-based SE training, pointing to a promising direction for perceptually aligned SE.",
      "authors": [
        "Haoyang Li",
        "Nana Hou",
        "Yuchen Hu",
        "Jixun Yao",
        "Sabato Marco Siniscalchi",
        "Eng Siong Chng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:15:39+00:00",
          "link": "https://arxiv.org/abs/2507.09929v1",
          "size": "144kb",
          "version": "v1"
        }
      ],
      "title": "Aligning Generative Speech Enhancement with Human Preferences via Direct Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09929",
        "HTML": "https://arxiv.org/html/2507.09929v1",
        "PDF": "https://arxiv.org/pdf/2507.09929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on speech enhancement using Direct Preference Optimization, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.09750",
      "abstract": "Large language models (LLMs) are increasingly integrated into creative coding, yet how users reflect, and how different co-creation conditions influence reflective behavior, remains underexplored. This study investigates situated, moment-to-moment reflection in creative coding under two prompting strategies: the entire task invocation (T1) and decomposed subtask invocation (T2), to examine their effects on reflective behavior. Our mixed-method results reveal three distinct reflection types and show that T2 encourages more frequent, strategic, and generative reflection, fostering diagnostic reasoning and goal redefinition. These findings offer insights into how LLM-based tools foster deeper creative engagement through structured, behaviorally grounded reflection support.",
      "authors": [
        "Anqi Wang",
        "Zhizhuo Yin",
        "Yulu Hu",
        "Yuanyuan Mao",
        "Lei Han",
        "Xin Tong",
        "Keqin Jiao",
        "Pan Hui"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-15T07:00:06+00:00",
          "link": "https://arxiv.org/abs/2402.09750v1",
          "size": "1816kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:54:14+00:00",
          "link": "https://arxiv.org/abs/2402.09750v2",
          "size": "1130kb",
          "version": "v2"
        }
      ],
      "title": "Pinning \"Reflection\" on the Agenda: Investigating Reflection in Human-LLM Co-Creation for Creative Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09750",
        "HTML": "https://arxiv.org/html/2402.09750v2",
        "PDF": "https://arxiv.org/pdf/2402.09750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human-LLM interaction and reflection in creative coding rather than on processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08875",
      "abstract": "Modern methods for multi-criteria assessment (MCA), such as Data Envelopment Analysis (DEA), Stochastic Frontier Analysis (SFA), and Multiple Criteria Decision-Making (MCDM), are utilized to appraise a collection of Decision-Making Units (DMUs), also known as alternatives, based on several criteria. These methodologies inherently rely on assumptions and can be influenced by subjective judgment to effectively tackle the complex evaluation challenges in various fields. In real-world scenarios, it is essential to incorporate both quantitative and qualitative criteria as they consist of cardinal and ordinal data. Despite the inherent variability in the criterion values of different alternatives, the homogeneity assumption is often employed, significantly affecting evaluations. To tackle these challenges and determine the most appropriate alternative, we propose a novel MCA approach that combines two Virtual Gap Analysis (VGA) models. The VGA framework, rooted in linear programming, is pivotal in the MCA methodology. This approach improves efficiency and fairness, ensuring that evaluations are both comprehensive and dependable, thus offering a strong and adaptive solution. Two comprehensive numerical examples demonstrate the accuracy and transparency of our proposed method. The goal is to encourage continued advancement and stimulate progress in automated decision systems and decision support systems.",
      "authors": [
        "Fuh-Hwa Franklin Liu and Su-Chuan Shih"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:00:48+00:00",
          "link": "https://arxiv.org/abs/2507.08875v1",
          "size": "1410kb",
          "version": "v1"
        }
      ],
      "title": "A New Approach for Multicriteria Assessment in the Ranking of Alternatives Using Cardinal and Ordinal Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08875",
        "HTML": "https://arxiv.org/html/2507.08875v1",
        "PDF": "https://arxiv.org/pdf/2507.08875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel approach for multicriteria assessment using cardinal and ordinal data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08943",
      "abstract": "Git has become one of the most widely used version control systems today. Among its distinguishing features, its ability to easily and quickly create branches stands out, allowing teams to customize their workflows. In this context, various formats of collaborative development workflows using Git have emerged and gained popularity among software engineers. We can categorize such workflows into two main types: branch-based workflows and trunk-based workflows. Branch-based workflows typically define a set of remote branches with well-defined objectives, such as feature branches, a branch for feature integration, and a main branch. The goal is to migrate changes from the most isolated branch to the main one shared by all as the code matures. In this category, GitFlow stands out as the most popular example. In contrast, trunk-based workflows have a single remote branch where developers integrate their changes directly. In this range of options, choosing a workflow that maximizes team productivity while promoting software quality becomes a non-trivial task. Despite discussions on forums, social networks, and blogs, few scientific articles have explored this topic. In this work, we provide evidence on how Brazilian developers work with Git workflows and what factors favor or hinder the use of each model. To this end, we conducted semi-structured interviews and a survey with software developers. Our results indicate that trunk-based development favors fast-paced projects with experienced and smaller teams, while branch-based development suits less experienced and larger teams better, despite posing management challenges.",
      "authors": [
        "Pedro Lopes",
        "Paola Accioly",
        "Paulo Borba and Vitor Menezes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:06:00+00:00",
          "link": "https://arxiv.org/abs/2507.08943v1",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "title": "Choosing the Right Git Workflow: A Comparative Analysis of Trunk-based vs. Branch-based Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08943",
        "HTML": "https://arxiv.org/html/2507.08943v1",
        "PDF": "https://arxiv.org/pdf/2507.08943"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Git workflows for software development teams and does not cover any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09140",
      "abstract": "Creating high-quality anime illustrations presents notable challenges, particularly for beginners, due to the intricate styles and fine details inherent in anime art. We present an interactive drawing guidance system specifically designed for anime illustrations to address this issue. It offers real-time guidance to help users refine their work and streamline the creative process. Our system is built upon the StreamDiffusion pipeline to deliver real-time drawing assistance. We fine-tune Stable Diffusion with LoRA to synthesize anime style RGB images from user-provided hand-drawn sketches and prompts. Leveraging the Informative Drawings model, we transform these RGB images into rough sketches, which are further refined into structured guidance sketches using a custom-designed optimizer. The proposed system offers precise, real-time guidance aligned with the creative intent of the user, significantly enhancing both the efficiency and accuracy of the drawing process. To assess the effectiveness of our approach, we conducted a user study, gathering empirical feedback on both system performance and interface usability.",
      "authors": [
        "Chuang Chen",
        "Xiaoxuan Xie",
        "Yongming Zhang",
        "Tianyu Zhang",
        "Haoran Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T05:03:09+00:00",
          "link": "https://arxiv.org/abs/2507.09140v1",
          "size": "1018kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Drawing Guidance for Anime Illustrations with Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09140",
        "HTML": "https://arxiv.org/html/2507.09140v1",
        "PDF": "https://arxiv.org/pdf/2507.09140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily discusses an interactive drawing guidance system for anime illustrations using a diffusion model, but it does involve fine-tuning Stable Diffusion models which indirectly relates to data preprocessing for model adaptation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09186",
      "abstract": "We introduce OpenCAMS (Open-Source Connected and Automated Mobility Co-Simulation Platform), an open-source, synchronized, and extensible co-simulation framework that tightly couples three best-in-class simulation tools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support advanced research in transportation safety, mobility, and cybersecurity by combining the strengths of each simulation domain. Specifically, SUMO provides large-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D perception, vehicle dynamics, and control simulation; and OMNeT++ enables modular, event-driven network communication, such as cellular vehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized, bidirectional coupling architecture that ensures coherent simulation progression across traffic, perception, and communication domains while preserving modularity and reproducibility. For example, CARLA can simulate and render a subset of vehicles that require detailed sensor emulation and control logic; SUMO orchestrates network-wide traffic flow, vehicle routing, and traffic signal management; and OMNeT++ dynamically maps communication nodes to both mobile entities (e.g., vehicles) and static entities (e.g., roadside units) to enable C-V2X communication. While these three simulators form the foundational core of OpenCAMS, the platform is designed to be expandable and future-proof, allowing additional simulators to be integrated on top of this core without requiring fundamental changes to the system architecture. The OpenCAMS platform is fully open-source and publicly available through its GitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim, providing the research community with an accessible, flexible, and collaborative environment for advancing next-generation intelligent transportation systems.",
      "authors": [
        "Minhaj Uddin Ahmad",
        "Akid Abrar",
        "Sagar Dasgupta",
        "Mizanur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:10:37+00:00",
          "link": "https://arxiv.org/abs/2507.09186v1",
          "size": "3296kb",
          "version": "v1"
        }
      ],
      "title": "OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advanced Transportation Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09186",
        "HTML": "https://arxiv.org/html/2507.09186v1",
        "PDF": "https://arxiv.org/pdf/2507.09186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a simulation platform for transportation research and does not involve processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09352",
      "abstract": "Mobile Edge Computing (MEC) enables low-latency applications by bringing computation closer to the user, but dynamic task arrivals and communication threats like jamming complicate reliable task offloading and resource allocation. In this paper, we formulate a dynamic MEC framework considering the transmission diversity that jointly addresses task scheduling and resource block (RB) assignment in the presence of jamming. First, we define and evaluate key network metrics-including dropped task ratio and bandwidth utilization-while maintaining service continuity by accounting for the existing commitments of the edge server to previously offloaded tasks. Then, we propose a jamming-aware offloading and RB allocation framework that leverages transmission diversity and optimal scheduling across distributed gNBs. The proposed solution is compared to a similar scenario without transmission diversity and two baseline strategies of first-come-first-served (FCFS) and shortest task first (STF). The proposed algorithm effectively mitigates the impact of jamming while enhancing resource utilization and minimizing task drop rates, making it highly suitable for mission-critical MEC applications. At signal-to-jamming-and-noise ratio (SJNR) of 4 dB, the proposed method achieves a $0.26$ task drop rate, outperforming the scenario without transmission diversity with a task drop rate of 0.50 and STF and FCFS strategies with 0.52 and 0.63 task drop rates, respectively.",
      "authors": [
        "Ghazal Asemian",
        "Mohammadreza Amini",
        "Burak Kantarci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T17:08:27+00:00",
          "link": "https://arxiv.org/abs/2507.09352v1",
          "size": "513kb",
          "version": "v1"
        }
      ],
      "title": "Reliable Task Offloading in MEC through Transmission Diversity and Jamming-Aware Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09352",
        "HTML": "https://arxiv.org/html/2507.09352v1",
        "PDF": "https://arxiv.org/pdf/2507.09352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses task offloading in MEC and resource allocation involving transmission diversity and jamming-aware scheduling without relevance to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09508",
      "abstract": "Large language models (LLMs) have become proficient at sophisticated code-generation tasks, yet remain ineffective at reliably detecting or avoiding code vulnerabilities. Does this deficiency stem from insufficient learning about code vulnerabilities, or is it merely a result of ineffective prompting? Using representation engineering techniques, we investigate whether LLMs internally encode the concepts necessary to identify code vulnerabilities. We find that current LLMs encode precise internal representations that distinguish vulnerable from secure code--achieving greater accuracy than standard prompting approaches. Leveraging these vulnerability-sensitive representations, we develop an inference-time steering technique that subtly modulates the model's token-generation probabilities through a mixture of corrections (MoC). Our method effectively guides LLMs to produce less vulnerable code without compromising functionality, demonstrating a practical approach to controlled vulnerability management in generated code. Notably, MoC enhances the security ratio of Qwen2.5-Coder-7B by 8.9\\%, while simultaneously improving functionality on HumanEval pass@1 by 2.1\\%.",
      "authors": [
        "Weichen Yu",
        "Ravi Mangal",
        "Terry Zhuo",
        "Matt Fredrikson",
        "Corina S. Pasareanu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:27:33+00:00",
          "link": "https://arxiv.org/abs/2507.09508v1",
          "size": "237kb",
          "version": "v1"
        }
      ],
      "title": "A Mixture of Linear Corrections Generates Secure Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09508",
        "HTML": "https://arxiv.org/html/2507.09508v1",
        "PDF": "https://arxiv.org/pdf/2507.09508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on representation engineering and inference-time techniques to improve code security, without addressing data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09729",
      "abstract": "We obtain faster expander decomposition algorithms for directed graphs, matching the guarantees of Saranurak and Wang (SODA 2019) for expander decomposition on undirected graphs. Our algorithms are faster than prior work and also generalize almost losslessly to capacitated graphs. In particular, we obtain the first directed expander decomposition algorithm for capacitated graphs in near-linear time with optimal dependence on $\\phi$.\n  To obtain our result, we provide the first implementation and analysis of the non-stop cut-matching game for directed, capacitated graphs. All existing directed expander decomposition algorithms instead temporarily add ''fake edges'' before pruning them away in a final cleanup step. Our result shows that the natural undirected approach applies even to directed graphs. The difficulty is in its analysis, which is technical and requires significant modifications from the original setting of undirected graphs.",
      "authors": [
        "Henry Fleischmann",
        "George Z. Li",
        "and Jason Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:01:02+00:00",
          "link": "https://arxiv.org/abs/2507.09729v1",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "title": "Improved Directed Expander Decompositions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09729",
        "HTML": "https://arxiv.org/html/2507.09729v1",
        "PDF": "https://arxiv.org/pdf/2507.09729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses algorithms for expander decomposition in directed graphs, with no focus on LLM training data processing or the creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09839",
      "abstract": "An increasing number of NLP applications interact with large language models (LLMs) through black-box APIs, making prompt engineering critical for controlling model outputs. While recent Automatic Prompt Optimization (APO) methods iteratively refine prompts using model-generated feedback, textual gradients, they primarily focus on error correction and neglect valuable insights from correct predictions. This limits both their effectiveness and efficiency. In this paper, we propose a novel APO framework centered on enhancing the feedback mechanism. We reinterpret the textual gradient as a form of negative reinforcement and introduce the complementary positive reinforcement to explicitly preserve beneficial prompt components identified through successful predictions. To mitigate the noise inherent in LLM-generated feedback, we introduce a technique called feedback diversification, which aggregates multiple feedback signals, emphasizing consistent, actionable advice while filtering out outliers. Motivated by the rapid evolution and diversity of available LLMs, we also formalize Continual Prompt Optimization (CPO), addressing the practical challenge of efficiently migrating optimized prompts between different model versions or API providers. Our experiments reveal that naive prompt migration often degrades performance due to loss of critical instructions. In contrast, our approach consistently outperforms strong baselines, achieving significant accuracy improvements, faster convergence, and lower computational costs in both standard and migration scenarios.",
      "authors": [
        "MohammadReza Davari and Utkarsh Garg and Weixin Cai and Eugene Belilovsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:20:14+00:00",
          "link": "https://arxiv.org/abs/2507.09839v1",
          "size": "160kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Prompt Optimization: Reinforcement, Diversification, and Migration in Blackbox LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09839",
        "HTML": "https://arxiv.org/html/2507.09839v1",
        "PDF": "https://arxiv.org/pdf/2507.09839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily centers on prompt optimization for LLMs and improving feedback mechanisms, not on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.07577",
      "abstract": "Recent representation learning approaches enhance neural topic models by optimizing the weighted linear combination of the evidence lower bound (ELBO) of the log-likelihood and the contrastive learning objective that contrasts pairs of input documents. However, document-level contrastive learning might capture low-level mutual information, such as word ratio, which disturbs topic modeling. Moreover, there is a potential conflict between the ELBO loss that memorizes input details for better reconstruction quality, and the contrastive loss which attempts to learn topic representations that generalize among input documents. To address these issues, we first introduce a novel contrastive learning method oriented towards sets of topic vectors to capture useful semantics that are shared among a set of input documents. Secondly, we explicitly cast contrastive topic modeling as a gradient-based multi-objective optimization problem, with the goal of achieving a Pareto stationary solution that balances the trade-off between the ELBO and the contrastive objective. Extensive experiments demonstrate that our framework consistently produces higher-performing neural topic models in terms of topic coherence, topic diversity, and downstream performance.",
      "authors": [
        "Thong Nguyen",
        "Xiaobao Wu",
        "Xinshuai Dong",
        "Cong-Duy T Nguyen",
        "See-Kiong Ng",
        "Anh Tuan Luu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-12T11:18:32+00:00",
          "link": "https://arxiv.org/abs/2402.07577v1",
          "size": "406kb",
          "version": "v1"
        },
        {
          "date": "2024-03-09T05:35:21+00:00",
          "link": "https://arxiv.org/abs/2402.07577v2",
          "size": "407kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T05:00:42+00:00",
          "link": "https://arxiv.org/abs/2402.07577v3",
          "size": "281kb",
          "version": "v3"
        }
      ],
      "title": "Topic Modeling as Multi-Objective Contrastive Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.07577",
        "HTML": "https://arxiv.org/html/2402.07577v3",
        "PDF": "https://arxiv.org/pdf/2402.07577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper touches on document processing and contrastive learning but primarily focuses on topic modeling rather than LLM training data processing."
      },
      "tasks": [
        "Contrastive Learning",
        "Diversity",
        "Representation Learning",
        "Topic Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.08553",
      "abstract": "Recent advancement in online optimization and control has provided novel tools to study online linear quadratic regulator (LQR) problems, where cost matrices are time-varying and unknown in advance. In this work, we study the online linear quadratic Gaussian (LQG) problem over the manifold of stabilizing controllers that are linearly constrained to impose physical conditions such as sparsity. By adopting a Riemannian perspective, we propose the online Newton on manifold (ONM) algorithm, which generates an online controller on-the-fly based on the second-order information of the cost function sequence. To quantify the algorithm performance, we use the notion of regret, defined as the sub-optimality of the algorithm cumulative cost against a (locally) minimizing controller sequence. We establish a regret bound in terms of the path-length of the benchmark minimizer sequence, and we further verify the effectiveness of ONM via simulations.",
      "authors": [
        "Ting-Jui Chang and Shahin Shahrampour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-13T14:06:18+00:00",
          "link": "https://arxiv.org/abs/2403.08553v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T13:06:40+00:00",
          "link": "https://arxiv.org/abs/2403.08553v2",
          "size": "141kb",
          "version": "v2"
        }
      ],
      "title": "Regret Analysis of Policy Optimization over Submanifolds for Linearly Constrained Online LQG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08553",
        "HTML": "https://arxiv.org/html/2403.08553v2",
        "PDF": "https://arxiv.org/pdf/2403.08553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses an online optimization algorithm for control problems in LQG systems, not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.10484",
      "abstract": "The application of the Universal Design for Learning framework favors the creation of virtual educational environments for all. It requires developing accessible content, having a usable platform, and the use of flexible didactics and evaluations that promote constant student motivation. The present study aims to design a methodology to evaluate the usability of the Moodle platform based on the principles of Universal Design for Learning, recognizing the importance of accessibility, usability and the availability of Assistive Technologies. We developed and applied a methodology to assess the usability level of Moodle platforms, taking into consideration that they integrate Assistive Technologies or are used for MOOC contexts. We provide the results of a use case that assesses two instances for the respective Moodle v.2.x and v.3.x family versions. We employed the framework of mixed design research in order to assess a MOOC-type educational program devised under the principles of Universal Design for Learning. As a result of the assessment of Moodle v.2.x and v.3.x, we conclude that the platforms must improve some key elements (e.g. contrasting colors, incorporation of alternative text and links) in order to comply with international accessibility standards. With respect to usability, we can confirm that the principles and guidelines of Universal Design for Learning are applicable to MOOC-type Virtual Learning Environments, are positively valued by students, and have a positive impact on certification rates.",
      "authors": [
        "Rosana Montes and Liliana Herrera and Emilio Crisol"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-15T17:19:04+00:00",
          "link": "https://arxiv.org/abs/2403.10484v1",
          "size": "218kb",
          "version": "v1"
        },
        {
          "date": "2024-04-02T15:25:51+00:00",
          "link": "https://arxiv.org/abs/2403.10484v2",
          "size": "210kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T11:35:25+00:00",
          "link": "https://arxiv.org/abs/2403.10484v3",
          "size": "214kb",
          "version": "v3"
        }
      ],
      "title": "Moodle Usability Assessment Methodology using the Universal Design for Learning perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.10484",
        "HTML": "https://arxiv.org/html/2403.10484v3",
        "PDF": "https://arxiv.org/pdf/2403.10484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on assessing the usability of the Moodle platform using the Universal Design for Learning framework, with no discussion of LLM training data processing or data engineering techniques relevant to LLM development."
      },
      "repo_urls": [
        "https://github.com/ari-dasci/od-moodle-usability-assessment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.24391",
      "abstract": "Recent advances in DUSt3R have enabled robust estimation of dense point clouds and camera parameters of static scenes, leveraging Transformer network architectures and direct supervision on large-scale 3D datasets. In contrast, the limited scale and diversity of available 4D datasets present a major bottleneck for training a highly generalizable 4D model. This constraint has driven conventional 4D methods to fine-tune 3D models on scalable dynamic video data with additional geometric priors such as optical flow and depths. In this work, we take an opposite path and introduce Easi3R, a simple yet efficient training-free method for 4D reconstruction. Our approach applies attention adaptation during inference, eliminating the need for from-scratch pre-training or network fine-tuning. We find that the attention layers in DUSt3R inherently encode rich information about camera and object motion. By carefully disentangling these attention maps, we achieve accurate dynamic region segmentation, camera pose estimation, and 4D dense point map reconstruction. Extensive experiments on real-world dynamic videos demonstrate that our lightweight attention adaptation significantly outperforms previous state-of-the-art methods that are trained or finetuned on extensive dynamic datasets. Our code is publicly available for research purpose at https://easi3r.github.io/",
      "authors": [
        "Xingyu Chen",
        "Yue Chen",
        "Yuliang Xiu",
        "Andreas Geiger",
        "Anpei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T17:59:58+00:00",
          "link": "https://arxiv.org/abs/2503.24391v1",
          "size": "17375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T12:35:53+00:00",
          "link": "https://arxiv.org/abs/2503.24391v2",
          "size": "17661kb",
          "version": "v2"
        }
      ],
      "title": "Easi3R: Estimating Disentangled Motion from DUSt3R Without Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.24391",
        "HTML": "https://arxiv.org/html/2503.24391v2",
        "PDF": "https://arxiv.org/pdf/2503.24391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for 4D reconstruction without training, focusing on attention adaptation in the context of 3D and 4D dynamic data, with no relation to LLM training data processing."
      },
      "tasks": [
        "4D reconstruction",
        "Camera Pose Estimation",
        "Dynamic Region Segmentation",
        "Optical Flow Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/inception3d/easi3r"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07094",
      "abstract": "Bridges, which are stochastic processes with pinned initial and terminal conditions, have recently been applied to various problems. We show that a bridge based on the Cox-Ingersoll-Ross process, called a CIR bridge in this paper, reasonably models the intraday number of migrating fish at an observation point in a river. The studied fish migrates between sunrise and sunset each day, which are considered the initial and terminal times, respectively. The CIR bridge is well-defined as a unique pathwise continuous solution to a stochastic differential equation with unbounded drift and diffusion coefficients and potentially represents the on-off intermittency of the fish count data. Our bridge is theoretically novel in that it admits closed-form time-dependent averages and variances, with which the model parameters can be identified efficiently, and is computable by a recently-developed one-step numerical method. The CIR bridge is applied to the sub-hourly migration data of the diadromous fish Plecoglossus altivelis altivelis in the Nagara River, Japan, from February to June.",
      "authors": [
        "Hidekazu Yoshioka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T11:35:34+00:00",
          "link": "https://arxiv.org/abs/2506.07094v1",
          "size": "2294kb",
          "version": "v1"
        },
        {
          "date": "2025-07-06T00:46:52+00:00",
          "link": "https://arxiv.org/abs/2506.07094v2",
          "size": "2283kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T11:48:02+00:00",
          "link": "https://arxiv.org/abs/2506.07094v3",
          "size": "2326kb",
          "version": "v3"
        }
      ],
      "title": "CIR bridge for modeling of fish migration on sub-hourly scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07094",
        "PDF": "https://arxiv.org/pdf/2506.07094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a bridge model for fish migration data without any connection to LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05171",
      "abstract": "We formulate a vector cost alternative to the scalarization method for weighting and combining multi-objective costs. The algorithm produces solutions to bimatrix games that are simultaneously pure, unique Nash equilibria and Pareto optimal with guarantees for avoiding worst case outcomes. We achieve this by enforcing exact potential game constraints to guide cost adjustments towards equilibrium, while minimizing the deviation from the original cost structure. The magnitude of this adjustment serves as a metric for differentiating between Pareto optimal solutions. We implement this approach in a racing competition between agents with heterogeneous cost structures, resulting in fewer collision incidents with a minimal decrease in performance. Code is available at https://github.com/toazbenj/race_simulation.",
      "authors": [
        "Benjamin R. Toaz",
        "Shaunak D. Bopardikar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:24:23+00:00",
          "link": "https://arxiv.org/abs/2507.05171v1",
          "size": "216kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:49:26+00:00",
          "link": "https://arxiv.org/abs/2507.05171v2",
          "size": "216kb",
          "version": "v2"
        }
      ],
      "title": "Vector Cost Bimatrix Games with Applications to Autonomous Racing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05171",
        "HTML": "https://arxiv.org/html/2507.05171v2",
        "PDF": "https://arxiv.org/pdf/2507.05171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents methods for vector cost bimatrix games in autonomous racing, unrelated to any LLM training data processes or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08992",
      "abstract": "Source code segmentation, dividing code into functionally coherent segments, is crucial for knowledge retrieval and maintenance in software development. While enabling efficient navigation and comprehension of large codebases, manual and syntactic analysis approaches have become impractical as repositories grow, especially for low-resource languages like R and their research domains (e.g., social sciences, psychology).This paper introduces an automated, domain-specific approach for research R code segmentation using Large and Small Language Models (LLMs/SLMs). It presents two novel approaches and a human-annotated dataset, StatCodeSeg. We explore two distinct approaches: line-by-line analysis with context and range-based segment determination. We experiment with LLMs and fine-tuned SLMs. To support the generalizability of our approaches, we also include experiments on Python code from the computer science domain.Our results show that context-based line-by-line analysis is superior over range-based segmentation.Using smaller language models like CodeBERT and an encoder-only version of CodeT5+ are better than their LLM counterparts. Most notably, these two best-performing models did not see R code during pre-training versus the LLMs but were only fine-tuned on 4,130 lines of manually annotated code.",
      "authors": [
        "Abdelhalim Dahou",
        "Ansgar Scherp",
        "Sebastian Kurten",
        "Brigitte Mathiak",
        "Madhu Chauhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:49:59+00:00",
          "link": "https://arxiv.org/abs/2507.08992v1",
          "size": "804kb",
          "version": "v1"
        }
      ],
      "title": "Semantic Source Code Segmentation using Small and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08992",
        "PDF": "https://arxiv.org/pdf/2507.08992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces an automated source code segmentation approach using LLMs and SLMs, but focuses on new approaches to code segmentation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09083",
      "abstract": "This paper investigates the behavior of simulated AI agents (large language models, or LLMs) in auctions, introducing a novel synthetic data-generating process to help facilitate the study and design of auctions. We find that LLMs -- when endowed with chain of thought reasoning capacity -- agree with the experimental literature in auctions across a variety of classic auction formats. In particular, we find that LLM bidders produce results consistent with risk-averse human bidders; that they perform closer to theoretical predictions in obviously strategy-proof auctions; and, that they succumb to the winner's curse in common value settings. On prompting, we find that LLMs are not very sensitive to naive changes in prompts (e.g., language, currency) but can improve dramatically towards theoretical predictions with the right mental model (i.e., the language of Nash deviations). We run 1,000$+$ auctions for less than $\\$$400 with GPT-4 models (three orders of magnitude cheaper than modern auction experiments) and develop a framework flexible enough to run auction experiments with any LLM model and a wide range of auction design specifications, facilitating further experimental study by decreasing costs and serving as a proof-of-concept for the use of LLM proxies.",
      "authors": [
        "Anand Shah",
        "Kehang Zhu",
        "Yanchen Jiang",
        "Jeffrey G. Wang",
        "Arif K. Dayi",
        "John J. Horton",
        "David C. Parkes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:00:30+00:00",
          "link": "https://arxiv.org/abs/2507.09083v1",
          "size": "6354kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Synthetic Labs: Language Models as Auction Participants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09083",
        "HTML": "https://arxiv.org/html/2507.09083v1",
        "PDF": "https://arxiv.org/pdf/2507.09083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel synthetic data-generating process for LLMs in auctions, which constitutes a significant contribution to data processing by generating training data for these models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09483",
      "abstract": "We reproduce the UMBRELA LLM Judge evaluation framework across a range of large language models (LLMs) to assess its generalizability beyond the original study. Our investigation evaluates how LLM choice affects relevance assessment accuracy, focusing on leaderboard rank correlation and per-label agreement metrics. Results demonstrate that UMBRELA with DeepSeek V3 obtains very comparable performance to GPT-4o (used in original work). For LLaMA-3.3-70B we obtain slightly lower performance, which further degrades with smaller LLMs.",
      "authors": [
        "Naghmeh Farzi",
        "Laura Dietz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:05:25+00:00",
          "link": "https://arxiv.org/abs/2507.09483v1",
          "size": "105kb",
          "version": "v1"
        }
      ],
      "title": "Does UMBRELA Work on Other LLMs?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09483",
        "HTML": "https://arxiv.org/html/2507.09483v1",
        "PDF": "https://arxiv.org/pdf/2507.09483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the evaluation of LLMs with the UMBRELA framework, focusing on model evaluation rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09505",
      "abstract": "Autonomous trucking offers significant benefits, such as improved safety and reduced costs, but faces unique perception challenges due to trucks' large size and dynamic trailer movements. These challenges include extensive blind spots and occlusions that hinder the truck's perception and the capabilities of other road users. To address these limitations, cooperative perception emerges as a promising solution. However, existing datasets predominantly feature light vehicle interactions or lack multi-agent configurations for heavy-duty vehicle scenarios. To bridge this gap, we introduce TruckV2X, the first large-scale truck-centered cooperative perception dataset featuring multi-modal sensing (LiDAR and cameras) and multi-agent cooperation (tractors, trailers, CAVs, and RSUs). We further investigate how trucks influence collaborative perception needs, establishing performance benchmarks while suggesting research priorities for heavy vehicle perception. The dataset provides a foundation for developing cooperative perception systems with enhanced occlusion handling capabilities, and accelerates the deployment of multi-agent autonomous trucking systems. The TruckV2X dataset is available at https://huggingface.co/datasets/XieTenghu1/TruckV2X.",
      "authors": [
        "Tenghui Xie",
        "Zhiying Song",
        "Fuxi Wen",
        "Jun Li",
        "Guangzhao Liu",
        "Zijian Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:16:13+00:00",
          "link": "https://arxiv.org/abs/2507.09505v1",
          "size": "9059kb",
          "version": "v1"
        }
      ],
      "title": "TruckV2X: A Truck-Centered Perception Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09505",
        "PDF": "https://arxiv.org/pdf/2507.09505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces TruckV2X, a new truck-centered perception dataset, with detailed data processing steps for multi-modal sensing and multi-agent cooperation, thereby contributing directly to data set creation and data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10262",
      "abstract": "Retrieving cohesive subgraphs in networks is a fundamental problem in social network analysis and graph data management. These subgraphs can be used for marketing strategies or recommendation systems. Despite the introduction of numerous models over the years, a systematic comparison of their performance, especially across varied network configurations, remains unexplored. In this study, we evaluated various cohesive subgraph models using task-based evaluations and conducted extensive experimental studies on both synthetic and real-world networks. Thus, we unveil the characteristics of cohesive subgraph models, highlighting their efficiency and applicability. Our findings not only provide a detailed evaluation of current models but also lay the groundwork for future research by shedding light on the balance between the interpretability and cohesion of the subgraphs. This research guides the selection of suitable models for specific analytical needs and applications, providing valuable insights.",
      "authors": [
        "Dahee Kim",
        "Song Kim",
        "Jeongseon Kim",
        "Junghoon Kim",
        "Kaiyu Feng",
        "Sungsu Lim",
        "and Jungeun Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.10262v1",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "title": "Experimental Analysis and Evaluation of Cohesive Subgraph Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10262",
        "HTML": "https://arxiv.org/html/2507.10262v1",
        "PDF": "https://arxiv.org/pdf/2507.10262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cohesive subgraph discovery in networks, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10376",
      "abstract": "Autonomous driving systems are highly dependent on sensors like cameras, LiDAR, and inertial measurement units (IMU) to perceive the environment and estimate their motion. Among these sensors, perception-based sensors are not protected from harsh weather and technical failures. Although existing methods show robustness against common technical issues like rotational misalignment and disconnection, they often degrade when faced with dynamic environmental factors like weather conditions. To address these problems, this research introduces a novel deep learning-based motion estimator that integrates visual, inertial, and millimeter-wave radar data, utilizing each sensor strengths to improve odometry estimation accuracy and reliability under adverse environmental conditions such as snow, rain, and varying light. The proposed model uses advanced sensor fusion techniques that dynamically adjust the contributions of each sensor based on the current environmental condition, with radar compensating for visual sensor limitations in poor visibility. This work explores recent advancements in radar-based odometry and highlights that radar robustness in different weather conditions makes it a valuable component for pose estimation systems, specifically when visual sensors are degraded. Experimental results, conducted on the Boreas dataset, showcase the robustness and effectiveness of the model in both clear and degraded environments.",
      "authors": [
        "Mohammadhossein Talebi",
        "Pragyan Dahal",
        "Davide Possenti",
        "Stefano Arrigoni and Francesco Braghin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:16:20+00:00",
          "link": "https://arxiv.org/abs/2507.10376v1",
          "size": "774kb",
          "version": "v1"
        }
      ],
      "title": "Raci-Net: Ego-vehicle Odometry Estimation in Adverse Weather Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10376",
        "HTML": "https://arxiv.org/html/2507.10376v1",
        "PDF": "https://arxiv.org/pdf/2507.10376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving odometry estimation in autonomous vehicles using sensor fusion under adverse weather conditions, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.00027",
      "abstract": "Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs for personalization-related downstream applications, such as recommendation systems. In this work, we bridge the gap between these two separate main directions for the first time by introducing a taxonomy for personalized LLM usage and summarizing the key differences and challenges. We provide a formalization of the foundations of personalized LLMs that consolidates and expands notions of personalization of LLMs, defining and discussing novel facets of personalization, usage, and desiderata of personalized LLMs. We then unify the literature across these diverse fields and usage scenarios by proposing systematic taxonomies for the granularity of personalization, personalization techniques, datasets, evaluation methods, and applications of personalized LLMs. Finally, we highlight challenges and important open problems that remain to be addressed. By unifying and surveying recent research using the proposed taxonomies, we aim to provide a clear guide to the existing literature and different facets of personalization in LLMs, empowering both researchers and practitioners.",
      "authors": [
        "Zhehao Zhang",
        "Ryan A. Rossi",
        "Branislav Kveton",
        "Yijia Shao",
        "Diyi Yang",
        "Hamed Zamani",
        "Franck Dernoncourt",
        "Joe Barrow",
        "Tong Yu",
        "Sungchul Kim",
        "Ruiyi Zhang",
        "Jiuxiang Gu",
        "Tyler Derr",
        "Hongjie Chen",
        "Junda Wu",
        "Xiang Chen",
        "Zichao Wang",
        "Subrata Mitra",
        "Nedim Lipka",
        "Nesreen Ahmed",
        "Yu Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T04:01:11+00:00",
          "link": "https://arxiv.org/abs/2411.00027v1",
          "size": "4783kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T03:03:35+00:00",
          "link": "https://arxiv.org/abs/2411.00027v2",
          "size": "5365kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T02:13:14+00:00",
          "link": "https://arxiv.org/abs/2411.00027v3",
          "size": "4142kb",
          "version": "v3"
        }
      ],
      "title": "Personalization of Large Language Models: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00027",
        "HTML": "https://arxiv.org/html/2411.00027v3",
        "PDF": "https://arxiv.org/pdf/2411.00027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on personalization of LLMs and discusses taxonomies and challenges but does not contribute to LLM training data processing."
      },
      "tasks": [
        "Recommendation Systems",
        "Survey",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05319",
      "abstract": "The adoption of Building Information Modeling (BIM) and model-based design within the Architecture, Engineering, and Construction (AEC) industry has been hindered by the perception that using BIM authoring tools demands more effort than conventional 2D drafting. To enhance design efficiency, this paper proposes a BIM command recommendation framework that predicts the optimal next actions in real-time based on users' historical interactions. We propose a comprehensive filtering and enhancement method for large-scale raw BIM log data and introduce a novel command recommendation model. Our model builds upon the state-of-the-art Transformer backbones originally developed for large language models (LLMs), incorporating a custom feature fusion module, dedicated loss function, and targeted learning strategy. In a case study, the proposed method is applied to over 32 billion rows of real-world log data collected globally from the BIM authoring software Vectorworks. Experimental results demonstrate that our method can learn universal and generalizable modeling patterns from anonymous user interaction sequences across different countries, disciplines, and projects. When generating recommendations for the next command, our approach achieves a Recall@10 of approximately 84%. The code is available at: https://github.com/dcy0577/BIM-Command-Recommendation.git",
      "authors": [
        "Changyu Du",
        "Zihan Deng",
        "Stavros Nousias",
        "Andr\\'e Borrmann"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-23T11:47:57+00:00",
          "link": "https://arxiv.org/abs/2504.05319v1",
          "size": "2758kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T17:14:34+00:00",
          "link": "https://arxiv.org/abs/2504.05319v2",
          "size": "2794kb",
          "version": "v2"
        }
      ],
      "title": "Predictive Modeling: BIM Command Recommendation Based on Large-scale Usage Logs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05319",
        "HTML": "https://arxiv.org/html/2504.05319v2",
        "PDF": "https://arxiv.org/pdf/2504.05319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a method for filtering and enhancing large-scale raw BIM log data for a command recommendation framework, but it does not primarily focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21628",
      "abstract": "Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics Challenges to the first humanoid-robot kickboxing tournament-yet commercial autonomy still lags behind progress in machine learning. A major bottleneck is software: current robot stacks demand steep learning curves, low-level C/C++ expertise, fragmented tooling, and intricate hardware integration, in stark contrast to the Python-centric, well-documented ecosystems that propelled modern AI. We introduce ARK, an open-source, Python-first robotics framework designed to close that gap. ARK presents a Gym-style environment interface that allows users to collect data, preprocess it, and train policies using state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy) while seamlessly toggling between high-fidelity simulation and physical robots. A lightweight client-server architecture provides networked publisher-subscriber communication, and optional C/C++ bindings ensure real-time performance when needed. ARK ships with reusable modules for control, SLAM, motion planning, system identification, and visualization, along with native ROS interoperability. Comprehensive documentation and case studies-from manipulation to mobile navigation-demonstrate rapid prototyping, effortless hardware swapping, and end-to-end pipelines that rival the convenience of mainstream machine-learning workflows. By unifying robotics and AI practices under a common Python umbrella, ARK lowers entry barriers and accelerates research and commercial deployment of autonomous robots.",
      "authors": [
        "Magnus Dierking",
        "Christopher E. Mower",
        "Sarthak Das",
        "Huang Helong",
        "Jiacheng Qiu",
        "Cody Reading",
        "Wei Chen",
        "Huidong Liang",
        "Huang Guowei",
        "Jan Peters",
        "Quan Xingyue",
        "Jun Wang",
        "Haitham Bou-Ammar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T20:23:39+00:00",
          "link": "https://arxiv.org/abs/2506.21628v1",
          "size": "24617kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:46:29+00:00",
          "link": "https://arxiv.org/abs/2506.21628v2",
          "size": "24617kb",
          "version": "v2"
        }
      ],
      "title": "Ark: An Open-source Python-based Framework for Robot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21628",
        "HTML": "https://arxiv.org/html/2506.21628v2",
        "PDF": "https://arxiv.org/pdf/2506.21628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract mentions data collection and preprocessing in a robotics framework but does not primarily focus on LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00348",
      "abstract": "Machine learning is increasingly vital in cybersecurity, especially in malware detection. However, concept drift, where the characteristics of malware change over time, poses a challenge for maintaining the efficacy of these detection systems. Concept drift can occur in two forms: the emergence of entirely new malware families and the evolution of existing ones. This paper proposes an innovative method to address the former, focusing on effectively identifying new malware families. Our approach leverages a supervised autoencoder combined with triplet loss to differentiate between known and new malware families. We create clear and robust clusters that enhance the accuracy and resilience of malware family classification by utilizing this metric learning technique and the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm. The effectiveness of our method is validated using an Android malware dataset and a Windows portable executable (PE) malware dataset, showcasing its capability to sustain model performance within the dynamic landscape of emerging malware threats. Our results demonstrate a significant improvement in detecting new malware families, offering a reliable solution for ongoing cybersecurity challenges.",
      "authors": [
        "Numan Halit Guldemir",
        "Oluwafemi Olukoya",
        "Jes\\'us Mart\\'inez-del-Rinc\\'on"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T00:55:00+00:00",
          "link": "https://arxiv.org/abs/2507.00348v1",
          "size": "2023kb",
          "version": "v1"
        }
      ],
      "title": "Addressing malware family concept drift with triplet autoencoder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00348",
        "HTML": "https://arxiv.org/html/2507.00348",
        "PDF": "https://arxiv.org/pdf/2507.00348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with concept drift in malware detection using triplet autoencoders, without any focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09049",
      "abstract": "With the increasing proliferation of mobile applications in our daily lives, the concerns surrounding ethics have surged significantly. Users communicate their feedback in app reviews, frequently emphasizing ethical concerns, such as privacy and security. Incorporating these reviews has proved to be useful for many areas of software engineering (e.g., requirement engineering, testing, etc.). However, app reviews related to ethical concerns generally use domain-specific language and are typically overshadowed by more generic categories of user feedback, such as app reliability and usability. Thus, making automated extraction a challenging and time-consuming effort.\n  This study proposes CMER (A \\underline{C}ontext-Aware Approach for \\underline{M}ining \\underline{E}thical Concern-related App \\underline{R}eviews), a novel approach that combines Natural Language Inference (NLI) and a decoder-only (LLaMA-like) Large Language Model (LLM) to extract ethical concern-related app reviews at scale. In CMER, NLI provides domain-specific context awareness by using domain-specific hypotheses, and the Llama-like LLM eliminates the need for labeled data in the classification task. We evaluated the validity of CMER by mining privacy and security-related reviews (PSRs) from the dataset of more than 382K app reviews of mobile investment apps. First, we evaluated four NLI models and compared the results of domain-specific hypotheses with generic hypotheses. Next, we evaluated three LLMs for the classification task. Finally, we combined the best NLI and LLM models (CMER) and extracted 2,178 additional PSRs overlooked by the previous study using a keyword-based approach, thus demonstrating the effectiveness of CMER. These reviews can be further refined into actionable requirement artifacts.",
      "authors": [
        "Aakash Sorathiya and Gouri Ginde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:46:04+00:00",
          "link": "https://arxiv.org/abs/2507.09049v1",
          "size": "231kb",
          "version": "v1"
        }
      ],
      "title": "CMER: A Context-Aware Approach for Mining Ethical Concern-related App Reviews",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09049",
        "HTML": "https://arxiv.org/html/2507.09049v1",
        "PDF": "https://arxiv.org/pdf/2507.09049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on extracting ethical concern-related app reviews using an LLM without contributing to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09751",
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, but they exhibit problems with logical consistency in the output they generate. How can we harness LLMs' broad-coverage parametric knowledge in formal reasoning despite their inconsistency? We present a method for directly integrating an LLM into the interpretation function of the formal semantics for a paraconsistent logic. We provide experimental evidence for the feasibility of the method by evaluating the function using datasets created from several short-form factuality benchmarks. Unlike prior work, our method offers a theoretical framework for neuro-symbolic reasoning that leverages an LLM's knowledge while preserving the underlying logic's soundness and completeness properties.",
      "authors": [
        "Bradley P. Allen",
        "Prateek Chhikara",
        "Thomas Macaulay Ferguson",
        "Filip Ilievski",
        "and Paul Groth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:05:43+00:00",
          "link": "https://arxiv.org/abs/2507.09751v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09751",
        "HTML": "https://arxiv.org/html/2507.09751v1",
        "PDF": "https://arxiv.org/pdf/2507.09751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses integrating LLMs into formal reasoning systems without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.12399",
      "abstract": "Visuospatial Neglect (VSN) affects spatial awareness, leading to functional and motor challenges. This study explores virtual reality (VR) as a potential complementary tool for VSN rehabilitation, offering a novel environment that intends to support therapy outcomes. Specifically, we aim to explore the initial experiences of patients and physiotherapists engaging with the protocol. VSN occurs in approximately 30% of stroke survivors, often presenting as inattention to one side of space. While conventional therapies rely on repetitive motor tasks, VR has emerged as a promising alternative for targeted and patient-centered rehabilitation. However, evidence on the integration of audio-visual cues in VR for VSN is limited. A preliminary VR task integrating audio-visual cues was co-designed with two physiotherapists. The task was then tested with two VSN patients over 12 sessions. Preliminary findings suggest potential benefits in patient experience, with one patient reporting increased confidence in mobility. However, outcomes varied, and the results are exploratory.",
      "authors": [
        "Andrew Danso",
        "Patti Nijhuis",
        "Alessandro Ansani",
        "Martin Hartmann",
        "Gulnara Minkkinen",
        "Geoff Luck",
        "Joshua S. Bamford",
        "Sarah Faber",
        "Kat Agres",
        "Solange Glasser",
        "Teppo S\\\"ark\\\"am\\\"o",
        "Rebekah Rousi",
        "Marc R. Thompson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-19T18:35:01+00:00",
          "link": "https://arxiv.org/abs/2312.12399v1",
          "size": "1009kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T16:55:03+00:00",
          "link": "https://arxiv.org/abs/2312.12399v2",
          "size": "3841kb",
          "version": "v2"
        }
      ],
      "title": "Development and User Experiences of a Novel Virtual Reality Task for Post-stroke Visuospatial Neglect: An Exploratory Pilot Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.12399",
        "PDF": "https://arxiv.org/pdf/2312.12399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates virtual reality for rehabilitation in post-stroke patients and does not address LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13367",
      "abstract": "Mobile robots exploring indoor environments increasingly rely on vision-language models to perceive high-level semantic cues in camera images, such as object categories. Such models offer the potential to substantially advance robot behaviour for tasks such as object-goal navigation (ObjectNav), where the robot must locate objects specified in natural language by exploring the environment. Current ObjectNav methods heavily depend on prompt engineering for perception and do not address the semantic uncertainty induced by variations in prompt phrasing. Ignoring semantic uncertainty can lead to suboptimal exploration, which in turn limits performance. Hence, we propose a semantic uncertainty-informed active perception pipeline for ObjectNav in indoor environments. We introduce a novel probabilistic sensor model for quantifying semantic uncertainty in vision-language models and incorporate it into a probabilistic geometric-semantic map to enhance spatial understanding. Based on this map, we develop a frontier exploration planner with an uncertainty-informed multi-armed bandit objective to guide efficient object search. Experimental results demonstrate that our method achieves ObjectNav success rates comparable to those of state-of-the-art approaches, without requiring extensive prompt engineering.",
      "authors": [
        "Utkarsh Bajpai",
        "Julius R\\\"uckin",
        "Cyrill Stachniss",
        "Marija Popovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T11:17:15+00:00",
          "link": "https://arxiv.org/abs/2506.13367v1",
          "size": "5332kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T00:15:15+00:00",
          "link": "https://arxiv.org/abs/2506.13367v2",
          "size": "5333kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13367",
        "HTML": "https://arxiv.org/html/2506.13367v2",
        "PDF": "https://arxiv.org/pdf/2506.13367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses uncertainty-informed active perception for object navigation in robots and does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09001",
      "abstract": "Machine Learning (ML) models for electronic structure rely on large datasets generated through expensive Kohn-Sham Density Functional Theory simulations. This study reveals a surprisingly high level of redundancy in such datasets across various material systems, including molecules, simple metals, and complex alloys. Our findings challenge the prevailing assumption that large, exhaustive datasets are necessary for accurate ML predictions of electronic structure. We demonstrate that even random pruning can substantially reduce dataset size with minimal loss in predictive accuracy, while a state-of-the-art coverage-based pruning strategy retains chemical accuracy and model generalizability using up to 100-fold less data and reducing training time by threefold or more. By contrast, widely used importance-based pruning methods, which eliminate seemingly redundant data, can catastrophically fail at higher pruning factors, possibly due to the significant reduction in data coverage. This heretofore unexplored high degree of redundancy in electronic structure data holds the potential to identify a minimal, essential dataset representative of each material class.",
      "authors": [
        "Sazzad Hossain",
        "Ponkrshnan Thiagarajan",
        "Shashank Pathrudkar",
        "Stephanie Taylor",
        "Abhijeet S. Gangan",
        "Amartya S. Banerjee",
        "and Susanta Ghosh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:08:07+00:00",
          "link": "https://arxiv.org/abs/2507.09001v1",
          "size": "16978kb",
          "version": "v1"
        }
      ],
      "title": "Surprisingly High Redundancy in Electronic Structure Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09001",
        "HTML": "https://arxiv.org/html/2507.09001v1",
        "PDF": "https://arxiv.org/pdf/2507.09001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper addresses redundancy in large electronic structure datasets and explores efficient pruning strategies, which significantly contribute to data processing for improving data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09642",
      "abstract": "LSM-tree is a widely adopted data structure in modern key-value store systems that optimizes write performance in write-heavy applications by using append writes to achieve sequential writes. However, the unpredictability of LSM-tree compaction introduces significant challenges, including performance variability during peak workloads and in resource-constrained environments, write amplification caused by data rewriting during compactions, read amplification from multi-level queries, trade-off between read and write performance, as well as efficient space utilization to mitigate space amplification. Prior studies on LSM-tree optimizations have addressed the above challenges; however, in recent years, research on LSM-tree optimization has continued to propose. The goal of this survey is to review LSM-tree optimization, focusing on representative works in the past five years. This survey first studies existing solutions on how to mitigate the performance impact of LSM-tree flush and compaction and how to improve basic key-value operations. In addition, distributed key-value stores serve multi-tenants, ranging from tens of thousands to millions of users with diverse requirements. We then analyze the new challenges and opportunities in these modern architectures and across various application scenarios. Unlike the existing survey papers, this survey provides a detailed discussion of the state-of-the-art work on LSM-tree optimizations and gives future research directions.",
      "authors": [
        "Yina Lv and Qiao Li and Quanqing Xu and Congming Gao and Chuanhui Yang and Xiaoli Wang and Chun Jason Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:15:01+00:00",
          "link": "https://arxiv.org/abs/2507.09642v1",
          "size": "817kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking LSM-tree based Key-Value Stores: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09642",
        "HTML": "https://arxiv.org/html/2507.09642v1",
        "PDF": "https://arxiv.org/pdf/2507.09642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey reviews LSM-tree optimizations in key-value stores, focusing on data structure and database performance, not on LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09710",
      "abstract": "In this paper, we consider two ways of breaking a graph's symmetry: distinguishing labelings and fixing sets. A distinguishing labeling $\\phi$ of $G$ colors the vertices of $G$ so that the only automorphism of the labeled graph $(G, \\phi)$ is the identity map. The distinguishing number of $G$, $D(G)$, is the fewest number of colors needed to create a distinguishing labeling of $G$. A subset $S$ of vertices is a fixing set of $G$ if the only automorphism of $G$ that fixes every element in $S$ is the identity map. The fixing number of $G$, $Fix(G)$, is the size of a smallest fixing set. A fixing set $S$ of $G$ can be translated into a distinguishing labeling $\\phi_S$ by assigning distinct colors to the vertices in $S$ and assigning another color (e.g., the ``null\" color) to the vertices not in $S$.\n  Color refinement is a well-known efficient heuristic for graph isomorphism. A graph $G$ is amenable if, for any graph $H$, color refinement correctly determines whether $G$ and $H$ are isomorphic or not. Using the characterization of amenable graphs by Arvind et al. as a starting point, we show that both $D(G)$ and $Fix(G)$ can be computed in $O((|V(G)|+|E(G)|) \\log |V(G)|)$ time when $G$ is an amenable graph.",
      "authors": [
        "Christine T. Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:06:55+00:00",
          "link": "https://arxiv.org/abs/2507.09710v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "Breaking the Symmetries of Amenable Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09710",
        "PDF": "https://arxiv.org/pdf/2507.09710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses breaking graph symmetries and does not focus on LLM training data processing or the creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09921",
      "abstract": "This work studies a stabilization technique for first-order hyperbolic differential equations used in DNA transcription modeling. Specifically we use the Lighthill-Whitham-Richards Model with a nonlinear Greenshield's velocity proposed in [1]. Standard finite element methods are known to produce spurious oscillations when applied to nonsmooth solutions. To address this, we incorporate stabilization terms involving spatial and temporal filtering into the system. We present numerical stability and prove convergence results for both the backwards Euler and time filtered formulations. We also present several computational results to demonstrate the rates in space and in time as well as for selected biological scenarios.",
      "authors": [
        "Ali Balooch",
        "Faranak Courtney-Pahlevani",
        "Lisa Davis",
        "Adrian Dunca",
        "Monika Neda",
        "Jorge Reyes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:59:58+00:00",
          "link": "https://arxiv.org/abs/2507.09921v1",
          "size": "2561kb",
          "version": "v1"
        }
      ],
      "title": "Numerical Analysis of a Bio-Polymerization Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09921",
        "HTML": "https://arxiv.org/html/2507.09921v1",
        "PDF": "https://arxiv.org/pdf/2507.09921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with numerical analysis of bio-polymerization models and stabilization techniques, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09995",
      "abstract": "Brain tumor segmentation plays a critical role in clinical diagnosis and treatment planning, yet the variability in imaging quality across different MRI scanners presents significant challenges to model generalization. To address this, we propose the Edge Iterative MRI Lesion Localization System (EdgeIMLocSys), which integrates Continuous Learning from Human Feedback to adaptively fine-tune segmentation models based on clinician feedback, thereby enhancing robustness to scanner-specific imaging characteristics. Central to this system is the Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS), which employs a Modality-Aware Adaptive Encoder (M2AE) to extract multi-scale semantic features efficiently, and a Graph-based Multi-Modal Collaborative Interaction Module (G2MCIM) to model complementary cross-modal relationships via graph structures. Additionally, we introduce a novel Voxel Refinement UpSampling Module (VRUM) that synergistically combines linear interpolation and multi-scale transposed convolutions to suppress artifacts while preserving high-frequency details, improving segmentation boundary accuracy. Our proposed GMLN-BTS model achieves a Dice score of 85.1% on the BraTS2017 dataset with only 4.58 million parameters, representing a 98% reduction compared to mainstream 3D Transformer models, and significantly outperforms existing lightweight approaches. This work demonstrates a synergistic breakthrough in achieving high-accuracy, resource-efficient brain tumor segmentation suitable for deployment in resource-constrained clinical environments.",
      "authors": [
        "Guohao Huo",
        "Ruiting Dai",
        "Hao Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:29:49+00:00",
          "link": "https://arxiv.org/abs/2507.09995v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09995",
        "HTML": "https://arxiv.org/html/2507.09995v1",
        "PDF": "https://arxiv.org/pdf/2507.09995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on brain tumor segmentation and model adaptation for MRI data, without any mention of LLM training data processing or data engineering methods applicable to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09997",
      "abstract": "This paper presents a trust-based predictive multi-agent consensus protocol that analyses neighbours' anticipation data and makes coordination decisions. Agents in the network share their future predicted data over a finite look-ahead horizon with their neighbours and update their predictions in a rolling-horizon fashion. The prediction data is then used by agents to learn both the trust and the commitment traits exhibited by their neighbours over time. The proposed protocol is named as the Anticipatory Distributed Coordination (ADC) protocol. Lyapunov theory-based agreement convergence between agents is provided, followed by demonstrations using numerical simulations.",
      "authors": [
        "Venkatraman Renganathan",
        "Sabyasachi Mondal",
        "Antonios Tsourdos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:32:05+00:00",
          "link": "https://arxiv.org/abs/2507.09997v1",
          "size": "477kb",
          "version": "v1"
        }
      ],
      "title": "Predictive & Trust-based Multi-Agent Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09997",
        "HTML": "https://arxiv.org/html/2507.09997v1",
        "PDF": "https://arxiv.org/pdf/2507.09997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a trust-based predictive multi-agent consensus protocol, but does not address any aspects of LLM training data collection, processing, or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10174",
      "abstract": "In recent years, extensive work has explored the application of the Transformer architecture to reinforcement learning problems. Among these, Decision Transformer (DT) has gained particular attention in the context of offline reinforcement learning due to its ability to frame return-conditioned policy learning as a sequence modeling task. Most recently, Bhargava et al. (2024) provided a systematic comparison of DT with more conventional MLP-based offline RL algorithms, including Behavior Cloning (BC) and Conservative Q-Learning (CQL), and claimed that DT exhibits superior performance in sparse-reward and low-quality data settings.\n  In this paper, through experimentation on robotic manipulation tasks (Robomimic) and locomotion benchmarks (D4RL), we show that MLP-based Filtered Behavior Cloning (FBC) achieves competitive or superior performance compared to DT in sparse-reward environments. FBC simply filters out low-performing trajectories from the dataset and then performs ordinary behavior cloning on the filtered dataset. FBC is not only very straightforward, but it also requires less training data and is computationally more efficient. The results therefore suggest that DT is not preferable for sparse-reward environments. From prior work, arguably, DT is also not preferable for dense-reward environments. Thus, we pose the question: Is DT ever preferable?",
      "authors": [
        "Yumi Omori",
        "Zixuan Dong",
        "Keith Ross"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:36:31+00:00",
          "link": "https://arxiv.org/abs/2507.10174v1",
          "size": "3518kb",
          "version": "v1"
        }
      ],
      "title": "Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10174",
        "HTML": "https://arxiv.org/html/2507.10174v1",
        "PDF": "https://arxiv.org/pdf/2507.10174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The methodology involves filtering low-performing data, an aspect of data processing, but the core focus is on improving reinforcement learning algorithms rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.05373",
      "abstract": "The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks (GNNs) is gradually attracting attention due to the low power consumption and high efficiency in processing the non-Euclidean data represented by graphs. However, as a common problem, dynamic graph representation learning faces challenges such as high complexity and large memory overheads. Current work often uses SNNs instead of Recurrent Neural Networks (RNNs) by using binary features instead of continuous ones for efficient training, which would overlooks graph structure information and leads to the loss of details during propagation. Additionally, optimizing dynamic spiking models typically requires propagation of information across time steps, which increases memory requirements. To address these challenges, we present a framework named \\underline{Dy}namic \\underline{S}p\\underline{i}king \\underline{G}raph \\underline{N}eural Networks (\\method{}). To mitigate the information loss problem, \\method{} propagates early-layer information directly to the last layer for information compensation. To accommodate the memory requirements, we apply the implicit differentiation on the equilibrium state, which does not rely on the exact reverse of the forward computation. While traditional implicit differentiation methods are usually used for static situations, \\method{} extends it to the dynamic graph setting. Extensive experiments on three large-scale real-world dynamic graph datasets validate the effectiveness of \\method{} on dynamic node classification tasks with lower computational costs.",
      "authors": [
        "Nan Yin",
        "Mengzhu Wang",
        "Zhenghan Chen",
        "Giulia De Masi",
        "Bin Gu",
        "Huan Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-15T12:45:47+00:00",
          "link": "https://arxiv.org/abs/2401.05373v1",
          "size": "482kb",
          "version": "v1"
        },
        {
          "date": "2024-07-29T14:33:02+00:00",
          "link": "https://arxiv.org/abs/2401.05373v2",
          "size": "482kb",
          "version": "v2"
        },
        {
          "date": "2024-07-30T09:05:05+00:00",
          "link": "https://arxiv.org/abs/2401.05373v3",
          "size": "482kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T04:36:52+00:00",
          "link": "https://arxiv.org/abs/2401.05373v4",
          "size": "392kb",
          "version": "v4"
        }
      ],
      "title": "Dynamic Spiking Framework for Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.05373",
        "HTML": "https://arxiv.org/html/2401.05373v4",
        "PDF": "https://arxiv.org/pdf/2401.05373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for integrating spiking neural networks with graph neural networks, focusing on reducing computational costs, without discussing LLM training data processing or creation."
      },
      "tasks": [
        "Dynamic Node Classification",
        "Graph Representation Learning",
        "Node Classification",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.09446",
      "abstract": "Understanding cooperation in social dilemmas requires models that capture the complexity of real-world interactions. While network frameworks have provided valuable insights to model the evolution of cooperation, they are unable to encode group interactions properly. Here, we introduce a general higher-order network framework for multi-player games on structured populations. Our model considers multi-dimensional strategies, based on the observation that social behaviours are affected by the size of the group interaction. We investigate dynamical and structural coupling between different orders of interactions, revealing the crucial role of nested multilevel interactions, and showing how such features can enhance cooperation beyond the limit of traditional models with uni-dimensional strategies. Our work identifies the key drivers promoting cooperative behaviour commonly observed in real-world group social dilemmas.",
      "authors": [
        "Onkar Sadekar",
        "Andrea Civilini",
        "Vito Latora",
        "and Federico Battiston"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computer Science and Game Theory (cs.GT)",
        "Social and Information Networks (cs.SI)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T16:15:45+00:00",
          "link": "https://arxiv.org/abs/2502.09446v1",
          "size": "1150kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T09:42:21+00:00",
          "link": "https://arxiv.org/abs/2502.09446v2",
          "size": "1570kb",
          "version": "v2"
        }
      ],
      "title": "Drivers of cooperation in social dilemmas on higher-order networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09446",
        "HTML": "https://arxiv.org/html/2502.09446",
        "PDF": "https://arxiv.org/pdf/2502.09446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores cooperation in social dilemmas using network frameworks, which do not involve any LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.10059",
      "abstract": "Recent advancements in camera-trajectory-guided image-to-video generation offer higher precision and better support for complex camera control compared to text-based approaches. However, they also introduce significant usability challenges, as users often struggle to provide precise camera parameters when working with arbitrary real-world images without knowledge of their depth nor scene scale. To address these real-world application issues, we propose RealCam-I2V, a novel diffusion-based video generation framework that integrates monocular metric depth estimation to establish 3D scene reconstruction in a preprocessing step. During training, the reconstructed 3D scene enables scaling camera parameters from relative to metric scales, ensuring compatibility and scale consistency across diverse real-world images. In inference, RealCam-I2V offers an intuitive interface where users can precisely draw camera trajectories by dragging within the 3D scene. To further enhance precise camera control and scene consistency, we propose scene-constrained noise shaping, which shapes high-level noise and also allows the framework to maintain dynamic and coherent video generation in lower noise stages. RealCam-I2V achieves significant improvements in controllability and video quality on the RealEstate10K and out-of-domain images. We further enables applications like camera-controlled looping video generation and generative frame interpolation. Project page: https://zgctroy.github.io/RealCam-I2V.",
      "authors": [
        "Teng Li",
        "Guangcong Zheng",
        "Rui Jiang",
        "Shuigen Zhan",
        "Tao Wu",
        "Yehao Lu",
        "Yining Lin",
        "Chuanyun Deng",
        "Yepan Xiong",
        "Min Chen",
        "Lin Cheng",
        "Xi Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T10:21:49+00:00",
          "link": "https://arxiv.org/abs/2502.10059v1",
          "size": "38285kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T08:12:15+00:00",
          "link": "https://arxiv.org/abs/2502.10059v2",
          "size": "6495kb",
          "version": "v2"
        }
      ],
      "title": "RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10059",
        "HTML": "https://arxiv.org/html/2502.10059v2",
        "PDF": "https://arxiv.org/pdf/2502.10059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on video generation from images and camera control improvements, without discussing LLM training data processing or dataset creation."
      },
      "models": [
        {
          "model_path": "MuteApo/CamI2V",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/MuteApo/CamI2V"
        }
      ],
      "datasets": [
        {
          "dataset_name": "MuteApo/RealCam-Vid",
          "downloads": "1191",
          "likes": "2",
          "link": "https://huggingface.co/datasets/MuteApo/RealCam-Vid"
        }
      ],
      "tasks": [
        "3D Scene Reconstruction",
        "Depth Estimation",
        "Image to Video Generation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10551",
      "abstract": "Empirical Risk Minimization (ERM) models often rely on spurious correlations between features and labels during the learning process, leading to shortcut learning behavior that undermines robustness generalization performance. Current research mainly targets identifying or mitigating a single shortcut; however, in real-world scenarios, cues within the data are diverse and unknown. In empirical studies, we reveal that the models rely to varying extents on different shortcuts. Compared to weak shortcuts, models depend more heavily on strong shortcuts, resulting in their poor generalization ability. To address these challenges, we propose MiMu, a novel method integrated with Transformer-based ERMs designed to Mitigate Multiple shortcut learning behavior, which incorporates self-calibration strategy and self-improvement strategy. In the source model, we preliminarily propose the self-calibration strategy to prevent the model from relying on shortcuts and make overconfident predictions. Then, we further design self-improvement strategy in target model to reduce the reliance on multiple shortcuts. The random mask strategy involves randomly masking partial attention positions to diversify the focus of target model other than concentrating on a fixed region. Meanwhile, the adaptive attention alignment module facilitates the alignment of attention weights to the calibrated source model, without the need for post-hoc attention maps or supervision. Finally, extensive experiments conducted on Natural Language Processing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu in improving robustness generalization abilities.",
      "authors": [
        "Lili Zhao",
        "Qi Liu",
        "Wei Chen",
        "Liyi Chen",
        "Ruijun Sun",
        "Min Hou",
        "Yang Wang",
        "Shijin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T08:11:09+00:00",
          "link": "https://arxiv.org/abs/2504.10551v1",
          "size": "10230kb",
          "version": "v1"
        }
      ],
      "title": "MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10551",
        "HTML": "https://arxiv.org/html/2504.10551",
        "PDF": "https://arxiv.org/pdf/2504.10551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a model architecture and mitigation strategies for shortcut learning in transformers, but does not focus on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08994",
      "abstract": "Piecewise constant functions describe a variety of real-world phenomena in domains ranging from chemistry to manufacturing. In practice, it is often required to confidently identify the locations of the abrupt changes in these functions as quickly as possible. For this, we introduce a fixed-confidence piecewise constant bandit problem. Here, we sequentially query points in the domain and receive noisy evaluations of the function under bandit feedback. We provide instance-dependent lower bounds for the complexity of change point identification in this problem. These lower bounds illustrate that an optimal method should focus its sampling efforts adjacent to each of the change points, and the number of samples around each change point should be inversely proportional to the magnitude of the change. Building on this, we devise a simple and computationally efficient variant of Track-and-Stop and prove that it is asymptotically optimal in many regimes. We support our theoretical findings with experimental results in synthetic environments demonstrating the efficiency of our method.",
      "authors": [
        "Joseph Lazzaro and Ciara Pike-Burke"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:52:11+00:00",
          "link": "https://arxiv.org/abs/2507.08994v1",
          "size": "140kb",
          "version": "v1"
        }
      ],
      "title": "Fixed-Confidence Multiple Change Point Identification under Bandit Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08994",
        "HTML": "https://arxiv.org/html/2507.08994v1",
        "PDF": "https://arxiv.org/pdf/2507.08994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses change point identification in piecewise constant bandit problems and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09018",
      "abstract": "In this paper, we critically examine Deng's \"P=NP\" [Den24]. The paper claims that there is a polynomial-time algorithm that decides 3-coloring for graphs with vertices of degree at most 4, which is known to be an NP-complete problem. Deng presents a semidefinite program with an objective function that is unboundedly negative if the graph is not 3-colorable, and a minimum of 0 if the graph is 3-colorable. Through detailed analysis, we find that Deng conflates subgraphs with induced subgraphs, leading to a critical error which thereby invalidates Deng's proof that $\\text{P}=\\text{NP}$.",
      "authors": [
        "Isabel Humphreys",
        "Matthew Iceland",
        "Harry Liuson",
        "Dylan McKellips",
        "and Leo Sciortino"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:57:34+00:00",
          "link": "https://arxiv.org/abs/2507.09018v1",
          "size": "11kb",
          "version": "v1"
        }
      ],
      "title": "A Critique of Deng's \"P=NP\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09018",
        "HTML": "https://arxiv.org/html/2507.09018v1",
        "PDF": "https://arxiv.org/pdf/2507.09018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This critique paper analyzes a theoretical claim about P=NP and does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09214",
      "abstract": "3D detection technology is widely used in the field of autonomous driving, with its application scenarios gradually expanding from enclosed highways to open conventional roads. For rare anomaly categories that appear on the road, 3D detection models trained on closed sets often misdetect or fail to detect anomaly objects. To address this risk, it is necessary to enhance the generalization ability of 3D detection models for targets of arbitrary shapes and to possess the capability to filter out anomalies. The generalization of 3D detection is limited by two factors: the coupled training of 2D and 3D, and the insufficient diversity in the scale distribution of training samples. This paper proposes a Stereo-based 3D Anomaly object Detection (S3AD) algorithm, which decouples the training strategy of 3D and 2D to release the generalization ability for arbitrary 3D foreground detection, and proposes an anomaly scoring algorithm based on foreground confidence prediction, achieving target-level anomaly scoring. In order to further verify and enhance the generalization of anomaly detection, we use a 3D rendering method to synthesize two augmented reality binocular stereo 3D detection datasets which named KITTI-AR. KITTI-AR extends upon KITTI by adding 97 new categories, totaling 6k pairs of stereo images. The KITTI-AR-ExD subset includes 39 common categories as extra training data to address the sparse sample distribution issue. Additionally, 58 rare categories form the KITTI-AR-OoD subset, which are not used in training to simulate zero-shot scenarios in real-world settings, solely for evaluating 3D anomaly detection. Finally, the performance of the algorithm and the dataset is verified in the experiments. (Code and dataset can be obtained at https://github.com/xxxx/xxx).",
      "authors": [
        "Shiyi Mu",
        "Zichong Gu",
        "Hanqi Lyu",
        "Yilin Gao and Shugong Xu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:10:29+00:00",
          "link": "https://arxiv.org/abs/2507.09214v1",
          "size": "30279kb",
          "version": "v1"
        }
      ],
      "title": "Stereo-based 3D Anomaly Object Detection for Autonomous Driving: A New Dataset and Baseline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09214",
        "HTML": "https://arxiv.org/html/2507.09214v1",
        "PDF": "https://arxiv.org/pdf/2507.09214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a new dataset with clear data processing steps, specifically KITTI-AR, which augments existing data with new categories for 3D anomaly detection, making a core contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09404",
      "abstract": "Large foundation models are typically trained on data from multiple domains, with the data mixture--the proportion of each domain used--playing a critical role in model performance. The standard approach to selecting this mixture relies on trial and error, which becomes impractical for large-scale pretraining. We propose a systematic method to determine the optimal data mixture for any target domain using scaling laws. Our approach accurately predicts the loss of a model of size $N$ trained with $D$ tokens and a specific domain weight vector $h$. We validate the universality of these scaling laws by demonstrating their predictive power in three distinct and large-scale settings: large language model (LLM), native multimodal model (NMM), and large vision models (LVM) pretraining. We further show that these scaling laws can extrapolate to new data mixtures and across scales: their parameters can be accurately estimated using a few small-scale training runs, and used to estimate the performance at larger scales and unseen domain weights. The scaling laws allow to derive the optimal domain weights for any target domain under a given training budget ($N$,$D$), providing a principled alternative to costly trial-and-error methods.",
      "authors": [
        "Mustafa Shukor",
        "Louis Bethune",
        "Dan Busbridge",
        "David Grangier",
        "Enrico Fini",
        "Alaaeldin El-Nouby",
        "Pierre Ablin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T21:16:08+00:00",
          "link": "https://arxiv.org/abs/2507.09404v1",
          "size": "2828kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Laws for Optimal Data Mixtures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09404",
        "HTML": "https://arxiv.org/html/2507.09404v1",
        "PDF": "https://arxiv.org/pdf/2507.09404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses a systematic method for determining optimal data mixtures for training large models, which indirectly relates to LLM training data processing in terms of data mixture optimization."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09460",
      "abstract": "Clinical monitoring of functional decline in ALS relies on periodic assessments that may miss critical changes occurring between visits. To address this gap, semi-supervised regression models were developed to estimate rates of decline in a case series cohort by targeting ALSFRS- R scale trajectories with continuous in-home sensor monitoring data. Our analysis compared three model paradigms (individual batch learning and cohort-level batch versus incremental fine-tuned transfer learning) across linear slope, cubic polynomial, and ensembled self-attention pseudo-label interpolations. Results revealed cohort homogeneity across functional domains responding to learning methods, with transfer learning improving prediction error for ALSFRS-R subscales in 28 of 32 contrasts (mean RMSE=0.20(0.04)), and individual batch learning for predicting the composite scale (mean RMSE=3.15(1.25)) in 2 of 3. Self-attention interpolation achieved the lowest prediction error for subscale-level models (mean RMSE=0.19(0.06)), capturing complex nonlinear progression patterns, outperforming linear and cubic interpolations in 20 of 32 contrasts, though linear interpolation proved more stable in all ALSFRS-R composite scale models (mean RMSE=0.23(0.10)). We identified distinct homogeneity-heterogeneity profiles across functional domains with respiratory and speech exhibiting patient-specific patterns benefiting from personalized incremental adaptation, while swallowing and dressing functions followed cohort-level trajectories suitable for transfer models. These findings suggest that matching learning and pseudo-labeling techniques to functional domain-specific homogeneity-heterogeneity profiles enhances predictive accuracy in ALS progression tracking. Integrating adaptive model selection within sensor monitoring platforms could enable timely interventions and scalable deployment in future multi-center studies.",
      "authors": [
        "Noah Marchal",
        "William E. Janes",
        "Mihail Popescu",
        "Xing Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:56:40+00:00",
          "link": "https://arxiv.org/abs/2507.09460v1",
          "size": "2862kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing ALS Progression Tracking with Semi-Supervised ALSFRS-R Scores Estimated from Ambient Home Health Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09460",
        "HTML": "https://arxiv.org/html/2507.09460v1",
        "PDF": "https://arxiv.org/pdf/2507.09460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses ALS progression tracking using semi-supervised models and sensor data but doesn't involve any LLM training data processing or create datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09672",
      "abstract": "WiFi-based human pose estimation has emerged as a promising non-visual alternative approaches due to its pene-trability and privacy advantages. This paper presents VST-Pose, a novel deep learning framework for accurate and continuous pose estimation using WiFi channel state information. The proposed method introduces ViSTA-Former, a spatiotemporal attention backbone with dual-stream architecture that adopts a dual-stream architecture to separately capture temporal dependencies and structural relationships among body joints. To enhance sensitivity to subtle human motions, a velocity modeling branch is integrated into the framework, which learns short-term keypoint dis-placement patterns and improves fine-grained motion representation. We construct a 2D pose dataset specifically designed for smart home care scenarios and demonstrate that our method achieves 92.2% accuracy on the PCK@50 metric, outperforming existing methods by 8.3% in PCK@50 on the self-collected dataset. Further evaluation on the public MMFi dataset confirms the model's robustness and effectiveness in 3D pose estimation tasks. The proposed system provides a reliable and privacy-aware solution for continuous human motion analysis in indoor environments. Our codes are available in https://github.com/CarmenQing/VST-Pose.",
      "authors": [
        "Xinyu Zhang",
        "Zhonghao Ye",
        "Jingwei Zhang",
        "Xiang Tian",
        "Zhisheng Liang",
        "and Shipeng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:11:18+00:00",
          "link": "https://arxiv.org/abs/2507.09672v1",
          "size": "1083kb",
          "version": "v1"
        }
      ],
      "title": "VST-Pose: A Velocity-Integrated Spatiotem-poral Attention Network for Human WiFi Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09672",
        "PDF": "https://arxiv.org/pdf/2507.09672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the focus is on a deep learning framework for WiFi-based human pose estimation, the paper mentions the creation of a 2D pose dataset but lacks detailed data processing contributions directly related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09871",
      "abstract": "The grand goal of AI research, and particularly Self Supervised Learning (SSL), is to produce systems that can successfully solve any possible task. In contrast, current evaluation methods available to AI researchers typically rely on a fixed collection of hand-picked downstream benchmarks. Hence, a large amount of effort is put into designing and searching for large collection of evaluation tasks that can serve as a proxy of our grand goal. We argue that such a rigid evaluation protocol creates a silent bottleneck in AI research. To remedy that, we define a probabilistic space of downstream tasks obtained by adopting a distribution of tasks and by defining Task Priors. Under this view, one can evaluate a model's performance over the set of all possible downstream tasks. Our framework is the first to provide answers to key questions such as (i) what is the average performance of my model over all possible downstream tasks weighted by the probability to encounter each task? or (ii) what is the variance of my model's performance across all downstream tasks under the defined Task Priors? Beyond establishing a new standard for evaluation, we believe that Task Priors will accelerate the pace of research in SSL - where downstream task evaluation is the sole qualitative signal that researchers have access to.",
      "authors": [
        "Niket Patel",
        "Randall Balestriero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:53:14+00:00",
          "link": "https://arxiv.org/abs/2507.09871v1",
          "size": "1155kb",
          "version": "v1"
        }
      ],
      "title": "Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09871",
        "HTML": "https://arxiv.org/html/2507.09871v1",
        "PDF": "https://arxiv.org/pdf/2507.09871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses evaluation of models over a probabilistic space of downstream tasks, but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10421",
      "abstract": "School dropout is a serious problem in distance learning, where early detection is crucial for effective intervention and student perseverance. Predicting student dropout using available educational data is a widely researched topic in learning analytics. Our partner's distance learning platform highlights the importance of integrating diverse data sources, including socio-demographic data, behavioral data, and sentiment analysis, to accurately predict dropout risks. In this paper, we introduce a novel model that combines sentiment analysis of student comments using the Bidirectional Encoder Representations from Transformers (BERT) model with socio-demographic and behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We fine-tuned BERT on student comments to capture nuanced sentiments, which were then merged with key features selected using feature importance techniques in XGBoost. Our model was tested on unseen data from the next academic year, achieving an accuracy of 84\\%, compared to 82\\% for the baseline model. Additionally, the model demonstrated superior performance in other metrics, such as precision and F1-score. The proposed method could be a vital tool in developing personalized strategies to reduce dropout rates and encourage student perseverance",
      "authors": [
        "Meriem Zerkouk",
        "Miloud Mihoubi",
        "Belkacem Chikhaoui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:04:34+00:00",
          "link": "https://arxiv.org/abs/2507.10421v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10421",
        "HTML": "https://arxiv.org/html/2507.10421v1",
        "PDF": "https://arxiv.org/pdf/2507.10421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a machine learning model for dropout prediction using sentiment analysis and other data types. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.07320",
      "abstract": "Neural compression has brought tremendous progress in designing lossy compressors with good rate-distortion (RD) performance at low complexity. Thus far, neural compression design involves transforming the source to a latent vector, which is then rounded to integers and entropy coded. While this approach has been shown to be optimal on a few specific sources, we show that it can be highly sub-optimal on synthetic sources whose intrinsic dimensionality is greater than one. With integer rounding in the latent space, the quantization regions induced by neural transformations, remain square-like and fail to match those of optimal vector quantization. We demonstrate that this phenomenon is due to the choice of scalar quantization in the latent space, and not the transform design. By employing lattice quantization instead, we propose Lattice Transform Coding (LTC) and show that it approximately recovers optimal vector quantization at reasonable complexity. On real-world sources, LTC improves upon standard neural compressors. LTC also provides a framework that can integrate structurally (near) optimal information-theoretic designs into lossy compression; examples include block coding, which yields coding gain over optimal one-shot coding and approaches the asymptotically-achievable rate-distortion function, as well as nested lattice quantization for low complexity fixed-rate coding.",
      "authors": [
        "Eric Lei",
        "Hamed Hassani",
        "Shirin Saeedi Bidokhti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-12T05:09:25+00:00",
          "link": "https://arxiv.org/abs/2403.07320v1",
          "size": "45314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T23:09:51+00:00",
          "link": "https://arxiv.org/abs/2403.07320v2",
          "size": "22090kb",
          "version": "v2"
        }
      ],
      "title": "Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.07320",
        "HTML": "https://arxiv.org/html/2403.07320v2",
        "PDF": "https://arxiv.org/pdf/2403.07320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on neural compression and doesn't involve contributions to LLM training data processing or creation."
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05602",
      "abstract": "As Large Language Models (LLMs) and other AI systems evolve, robustly estimating their capabilities from inherently stochastic outputs while systematically quantifying uncertainty in these estimates becomes increasingly important. Further, advanced AI evaluations often have a nested hierarchical structure, exhibit high levels of complexity, and come with high costs in testing the most advanced AI systems. To address these challenges, we introduce HiBayES, a generalizable Hierarchical Bayesian modeling framework for AI Evaluation Statistics. HiBayES supports robust inferences in classical question-answer benchmarks and advanced agentic evaluations, particularly in low-data scenarios (e.g., < 20 data points per evaluation). Built on Generalized Linear Models (GLMs), Bayesian data analysis, and formal model comparison, HiBayES provides principled uncertainty quantification and robust parameter estimation. This paper offers a comprehensive introduction to HiBayES, including illustrative examples, comparisons to conventional statistical methods, and practical guidance for implementing multilevel Bayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta version) for out-of-the-box implementation.",
      "authors": [
        "Lennart Luettgau",
        "Harry Coppock",
        "Magda Dubois",
        "Christopher Summerfield",
        "Cozmin Ududec"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T19:05:02+00:00",
          "link": "https://arxiv.org/abs/2505.05602v1",
          "size": "5098kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T11:06:22+00:00",
          "link": "https://arxiv.org/abs/2505.05602v2",
          "size": "5124kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T12:48:23+00:00",
          "link": "https://arxiv.org/abs/2505.05602v3",
          "size": "5125kb",
          "version": "v3"
        }
      ],
      "title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05602",
        "HTML": "https://arxiv.org/html/2505.05602v3",
        "PDF": "https://arxiv.org/pdf/2505.05602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a hierarchical Bayesian modeling framework (HiBayES) for AI evaluation statistics and does not discuss LLM training data processing, data engineering, or dataset creation methods."
      },
      "tasks": [
        "parameter estimation",
        "Uncertainty Quantification"
      ],
      "repo_urls": [
        "https://github.com/ukgovernmentbeis/hibayes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09008",
      "abstract": "The advances in multi-modal foundation models (FMs) (e.g., CLIP and LLaVA) have facilitated the auto-labeling of large-scale datasets, enhancing model performance in challenging downstream tasks such as open-vocabulary object detection and segmentation. However, the quality of FM-generated labels is less studied as existing approaches focus more on data quantity over quality. This is because validating large volumes of data without ground truth presents a considerable challenge in practice. Existing methods typically rely on limited metrics to identify problematic data, lacking a comprehensive perspective, or apply human validation to only a small data fraction, failing to address the full spectrum of potential issues. To overcome these challenges, we introduce VISTA, a visual analytics framework that improves data quality to enhance the performance of multi-modal models. Targeting the complex and demanding domain of open-vocabulary image segmentation, VISTA integrates multi-phased data validation strategies with human expertise, enabling humans to identify, understand, and correct hidden issues within FM-generated labels. Through detailed use cases on two benchmark datasets and expert reviews, we demonstrate VISTA's effectiveness from both quantitative and qualitative perspectives.",
      "authors": [
        "Xiwei Xuan",
        "Xiaoqi Wang",
        "Wenbin He",
        "Jorge Piazentin Ono",
        "Liang Gou",
        "Kwan-Liu Ma",
        "Liu Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:17:23+00:00",
          "link": "https://arxiv.org/abs/2507.09008v1",
          "size": "8305kb",
          "version": "v1"
        }
      ],
      "title": "VISTA: A Visual Analytics Framework to Enhance Foundation Model-Generated Data Labels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09008",
        "HTML": "https://arxiv.org/html/2507.09008v1",
        "PDF": "https://arxiv.org/pdf/2507.09008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on improving the quality of foundation model-generated data labels through a visual analytics framework, which directly involves data processing to enhance the performance of multi-modal models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09131",
      "abstract": "Nonlinearly stable flux reconstruction (NSFR) combines the key properties of provable nonlinear stability with the increased time step from energy-stable flux reconstruction. The NSFR scheme has been successfully applied to unsteady compressible flows. Through the use of a bound-preserving limiter, positivity of thermodynamic quantities is preserved, and this enables the extension of NSFR to hyperbolic conservation laws. We extend the limiter of Zhang and Shu [1] to ensure robustness for the proposed scheme. The limiter is modified to consider the minimum density and pressure at the solution nodes when determining the value to scale the solution. The modifications are thoroughly tested with a suite of test cases. In addition to these modifications, this paper conducts a thorough investigation into the shock-capturing capabilities of the NSFR scheme and the advantages it presents over standard discontinuous Galerkin (DG) methods, where, on select variants of the flux reconstruction (FR) scheme, essentially oscillation-free solutions are demonstrated. Various parameters of the scheme are extensively tested and analyzed through several 1D and 2D compressible Euler tests that verify the high-order accuracy, entropy stability, time step advantage and shock-capturing capabilities of the NSFR scheme. These parameters include the two-point flux, quadrature nodes and the strength of the FR parameter. In addition to investigating the impact of the various two-point fluxes, this paper also presents numerical studies to determine the CFL condition required to maintain positivity for the two-point flux of choice. The investigation yields insightful results for all parameters, with the results pertaining to the type of FR scheme being of special interest. The tests showcase increased robustness, time step advantages and oscillation/overshoot mitigation when employing a stronger FR parameter.",
      "authors": [
        "Sai Shruthi Srinivasan",
        "Siva Nadarajah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:05:36+00:00",
          "link": "https://arxiv.org/abs/2507.09131v1",
          "size": "9958kb",
          "version": "v1"
        }
      ],
      "title": "Investigation of Shock-Capturing with Bound-Preserving Limiters for the Nonlinearly Stable Flux Reconstruction Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09131",
        "HTML": "https://arxiv.org/html/2507.09131v1",
        "PDF": "https://arxiv.org/pdf/2507.09131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on shock-capturing and numerical methods in compressible fluid dynamics, not on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09135",
      "abstract": "Large Language Models have demonstrated remarkable capabilities in automated code generation, yet their statistical nature and black-box characteristics create significant semantic gaps manifested through syntax errors, semantic hallucinations, and reliability concerns. This position paper argues that principled integration of Programming Language (PL) techniques is essential for bridging these gaps. Through structured program representations, formal correctness guarantees, and robust verification mechanisms, PL techniques can elevate LLM-generated code from statistical pattern matching to truly reliable and trustworthy levels. This integration is crucial for developing systems that generate code that is not only functionally correct but also interpretable, verifiable, and ultimately trustworthy.",
      "authors": [
        "Yalong Du",
        "Chaozheng Wang",
        "Huaijin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:32:15+00:00",
          "link": "https://arxiv.org/abs/2507.09135v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Position Paper: Programming Language Techniques for Bridging LLM Code Generation Semantic Gaps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09135",
        "HTML": "https://arxiv.org/html/2507.09135v1",
        "PDF": "https://arxiv.org/pdf/2507.09135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the integration of programming language techniques to address semantic gaps in LLM code generation but does not focus on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09766",
      "abstract": "Accurate estimation of Remaining Useful Life (RUL) and State of Health (SOH) is essential for Prognostics and Health Management (PHM) across a wide range of industrial applications. We propose a novel framework -- Reinforced Graph-Based Physics-Informed Neural Networks Enhanced with Dynamic Weights (RGPD) -- that combines physics-based supervision with advanced spatio-temporal learning. Graph Convolutional Recurrent Networks (GCRNs) embed graph-convolutional filters within recurrent units to capture how node representations evolve over time. Graph Attention Convolution (GATConv) leverages a self-attention mechanism to compute learnable, edge-wise attention coefficients, dynamically weighting neighbor contributions for adaptive spatial aggregation. A Soft Actor-Critic (SAC) module is positioned between the Temporal Attention Unit (TAU) and GCRN to further improve the spatio-temporal learning. This module improves attention and prediction accuracy by dynamically scaling hidden representations to minimize noise and highlight informative features. To identify the most relevant physical constraints in each area, Q-learning agents dynamically assign weights to physics-informed loss terms, improving generalization across real-time industrial systems and reducing the need for manual tuning. In both RUL and SOH estimation tasks, the proposed method consistently outperforms state-of-the-art models, demonstrating strong robustness and predictive accuracy across varied degradation patterns across three diverse industrial benchmark datasets.",
      "authors": [
        "Mohamadreza Akbari Pour",
        "Ali Ghasemzadeh",
        "MohamadAli Bijarchi",
        "Mohammad Behshad Shafii"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:49:12+00:00",
          "link": "https://arxiv.org/abs/2507.09766v1",
          "size": "19362kb",
          "version": "v1"
        }
      ],
      "title": "Toward accurate RUL and SOH estimation using reinforced graph-based PINNs enhanced with dynamic weights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09766",
        "HTML": "https://arxiv.org/html/2507.09766v1",
        "PDF": "https://arxiv.org/pdf/2507.09766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on improving RUL and SOH estimation in industrial systems and does not cover LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18608",
      "abstract": "Spiking Transformers offer an energy-efficient alternative to conventional deep learning by transmitting information solely through binary (0/1) spikes. However, there remains a substantial performance gap compared to artificial neural networks. A common belief is that their binary and sparse activation transmission leads to information loss, thus degrading feature representation and accuracy. In this work, however, we reveal for the first time that spiking neurons preferentially propagate low-frequency information. We hypothesize that the rapid dissipation of high-frequency components is the primary cause of performance degradation. For example, on Cifar-100, adopting Avg-Pooling (low-pass) for token mixing lowers performance to 76.73%; interestingly, replacing it with Max-Pooling (high-pass) pushes the top-1 accuracy to 79.12%, surpassing the well-tuned Spikformer baseline by 0.97%. Accordingly, we introduce Max-Former that restores high-frequency signals through two frequency-enhancing operators: extra Max-Pooling in patch embedding and Depth-Wise Convolution in place of self-attention. Notably, our Max-Former (63.99 M) hits the top-1 accuracy of 82.39% on ImageNet, showing a +7.58% improvement over Spikformer with comparable model size (74.81%, 66.34 M). We hope this simple yet effective solution inspires future research to explore the distinctive nature of spiking neural networks, beyond the established practice in standard deep learning. \\href{https://github.com/bic-L/Spiking-Transformers-Need-High-Frequency-Information}{Code} is available.",
      "authors": [
        "Yuetong Fang",
        "Deming Zhou",
        "Ziqing Wang",
        "Hongwei Ren",
        "ZeCui Zeng",
        "Lusong Li",
        "Shibo Zhou",
        "Renjing Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T09:15:59+00:00",
          "link": "https://arxiv.org/abs/2505.18608v1",
          "size": "1008kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T11:40:40+00:00",
          "link": "https://arxiv.org/abs/2505.18608v2",
          "size": "914kb",
          "version": "v2"
        }
      ],
      "title": "Spiking Transformers Need High Frequency Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18608",
        "HTML": "https://arxiv.org/html/2505.18608v2",
        "PDF": "https://arxiv.org/pdf/2505.18608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements to Spiking Transformers in terms of frequency information propagation, not involving LLM training data processing or creation."
      },
      "tasks": [
        "Avg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04712",
      "abstract": "In this paper, we formulate a mutual information optimal control problem (MIOCP) for discrete-time linear systems. This problem can be regarded as an extension of a maximum entropy optimal control problem (MEOCP). Differently from the MEOCP where the prior is fixed to the uniform distribution, the MIOCP optimizes the policy and prior simultaneously. As analytical results, under the policy and prior classes consisting of Gaussian distributions, we derive the optimal policy and prior of the MIOCP with the prior and policy fixed, respectively. Using the results, we propose an alternating minimization algorithm for the MIOCP. Through numerical experiments, we discuss how our proposed algorithm works.",
      "authors": [
        "Shoju Enami and Kenji Kashima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T07:04:27+00:00",
          "link": "https://arxiv.org/abs/2507.04712v1",
          "size": "453kb",
          "version": "v1"
        }
      ],
      "title": "Mutual Information Optimal Control of Discrete-Time Linear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04712",
        "HTML": "https://arxiv.org/html/2507.04712",
        "PDF": "https://arxiv.org/pdf/2507.04712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a mutual information optimal control problem for discrete-time linear systems without any mention of LLM training data processing or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08924",
      "abstract": "The development of Large Language Models (LLMs) requires robust benchmarks that encompass not only academic domains but also industrial fields to effectively evaluate their applicability in real-world scenarios. In this paper, we introduce two Korean expert-level benchmarks. KMMLU-Redux, reconstructed from the existing KMMLU, consists of questions from the Korean National Technical Qualification exams, with critical errors removed to enhance reliability. KMMLU-Pro is based on Korean National Professional Licensure exams to reflect professional knowledge in Korea. Our experiments demonstrate that these benchmarks comprehensively represent industrial knowledge in Korea. We release our dataset publicly available.",
      "authors": [
        "Seokhee Hong",
        "Sunkyoung Kim",
        "Guijin Son",
        "Soyeon Kim",
        "Yeonjung Hong",
        "Jinsik Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:56:32+00:00",
          "link": "https://arxiv.org/abs/2507.08924v1",
          "size": "805kb",
          "version": "v1"
        }
      ],
      "title": "From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08924",
        "HTML": "https://arxiv.org/html/2507.08924v1",
        "PDF": "https://arxiv.org/pdf/2507.08924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces two Korean benchmarks with detailed data processing steps to remove errors and improve reliability, focusing on creating a specialized dataset for LLM evaluation."
      },
      "datasets": [
        {
          "dataset_name": "LGAI-EXAONE/KMMLU-Redux",
          "downloads": "0",
          "likes": "4",
          "link": "https://huggingface.co/datasets/LGAI-EXAONE/KMMLU-Redux"
        },
        {
          "dataset_name": "LGAI-EXAONE/KMMLU-Pro",
          "downloads": "0",
          "likes": "3",
          "link": "https://huggingface.co/datasets/LGAI-EXAONE/KMMLU-Pro"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09148",
      "abstract": "Sparse Principal Component Analysis (SPCA) is a fundamental technique for dimensionality reduction, and is NP-hard. In this paper, we introduce a randomized approximation algorithm for SPCA, which is based on the basic SDP relaxation. Our algorithm has an approximation ratio of at most the sparsity constant with high probability, if called enough times. Under a technical assumption, which is consistently satisfied in our numerical tests, the average approximation ratio is also bounded by $\\mathcal{O}(\\log{d})$, where $d$ is the number of features. We show that this technical assumption is satisfied if the SDP solution is low-rank, or has exponentially decaying eigenvalues. We then present a broad class of instances for which this technical assumption holds. We also demonstrate that in a covariance model, which generalizes the spiked Wishart model, our proposed algorithm achieves a near-optimal approximation ratio. We demonstrate the efficacy of our algorithm through numerical results on real-world datasets.",
      "authors": [
        "Alberto Del Pia and Dekun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T05:43:56+00:00",
          "link": "https://arxiv.org/abs/2507.09148v1",
          "size": "123kb",
          "version": "v1"
        }
      ],
      "title": "A Randomized Algorithm for Sparse PCA based on the Basic SDP Relaxation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09148",
        "HTML": "https://arxiv.org/html/2507.09148v1",
        "PDF": "https://arxiv.org/pdf/2507.09148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a randomized algorithm for Sparse PCA, focusing on mathematical optimization techniques rather than any LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09201",
      "abstract": "Large language models (LLMs) have demonstrated exceptional proficiency in understanding and generating human language, but efficient inference on resource-constrained embedded devices remains challenging due to large model sizes and memory-intensive operations in feedforward network (FFN) and multi-head attention (MHA) layers. While existing accelerators offload LLM inference to expensive heterogeneous computing systems, they fail to exploit the significant sparsity inherent in LLM operations, leaving hardware resources underutilized. We propose SLIM, an algorithm-hardware co-design optimized for sparse LLM serving on edge devices. SLIM exploits LLM sparsity through an adaptive thresholding algorithm that enables runtime-configurable sparsity with negligible accuracy loss, fetching only activated neurons to dramatically reduce data movement. Our heterogeneous hardware architecture strategically combines near-storage processing (NSP) and processing-in-memory (PIM): FFN weights are stored in high-density 3D NAND and computed using NSP units, while memory-intensive MHA operations are processed in PIM modules. This design significantly reduces memory footprint, data movement, and energy consumption. Our comprehensive evaluation demonstrates SLIM's effectiveness, achieving 13-18x throughput improvements over SSD-GPU systems and 9-10x better energy efficiency over DRAM-GPU systems while maintaining low latency, making cost-effective LLM deployment viable for edge computing environments.",
      "authors": [
        "Weihong Xu",
        "Haein Choi",
        "Po-kai Hsu",
        "Shimeng Yu",
        "and Tajana Rosing"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:44:38+00:00",
          "link": "https://arxiv.org/abs/2507.09201v1",
          "size": "702kb",
          "version": "v1"
        }
      ],
      "title": "SLIM: A Heterogeneous Accelerator for Edge Inference of Sparse Large Language Model via Adaptive Thresholding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09201",
        "HTML": "https://arxiv.org/html/2507.09201v1",
        "PDF": "https://arxiv.org/pdf/2507.09201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on hardware acceleration and efficient inference for sparse LLMs on edge devices, rather than data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09247",
      "abstract": "We consider algorithmic determination of the $n$-dimensional Sherrington-Kirkpatrick (SK) spin glass model ground state free energy. It corresponds to a binary maximization of an indefinite quadratic form and under the \\emph{worst case} principles of the classical NP complexity theory it is hard to approximate within a $\\log(n)^{const.}$ factor. On the other hand, the SK's random nature allows (polynomial) spectral methods to \\emph{typically} approach the optimum within a constant factor. Naturally one is left with the fundamental question: can the residual (constant) \\emph{computational gap} be erased?\n  Following the success of \\emph{Controlled Loosening-up} (CLuP) algorithms in planted models, we here devise a simple practical CLuP-SK algorithmic procedure for (non-planted) SK models. To analyze the \\emph{typical} success of the algorithm we associate to it (random) CLuP-SK models. Further connecting to recent random processes studies [94,97], we characterize the models and CLuP-SK algorithm via fully lifted random duality theory (fl RDT) [98]. Moreover, running the algorithm we demonstrate that its performance is in an excellent agrement with theoretical predictions. In particular, already for $n$ on the order of a few thousands CLuP-SK achieves $\\sim 0.76$ ground state free energy and remarkably closely approaches theoretical $n\\rightarrow\\infty$ limit $\\approx 0.763$. For all practical purposes, this renders computing SK model's near ground state free energy as a \\emph{typically} easy problem.",
      "authors": [
        "Mihailo Stojnic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:58:50+00:00",
          "link": "https://arxiv.org/abs/2507.09247v1",
          "size": "2471kb",
          "version": "v1"
        }
      ],
      "title": "A CLuP algorithm to practically achieve $\\sim 0.76$ SK--model ground state free energy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09247",
        "HTML": "https://arxiv.org/html/2507.09247v1",
        "PDF": "https://arxiv.org/pdf/2507.09247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithmic approaches to the Sherrington-Kirkpatrick model and does not involve any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09309",
      "abstract": "Optimal path planning in nonconvex free spaces is notoriously challenging, as formulating such problems as mixed-integer linear programs (MILPs) is NP-hard. We propose HZ-MP, an informed Hybrid Zonotope-based Motion Planner, as an alternative approach that decomposes the obstacle-free space and performs low-dimensional face sampling guided by an ellipsotope heuristic, enabling focused exploration along promising transit regions. This structured exploration eliminates the excessive, unreachable sampling that degrades existing informed planners such as AIT* and EIT* in narrow gaps or boxed-goal scenarios. We prove that HZ-MP is probabilistically complete and asymptotically optimal. It converges to near-optimal trajectories in finite time and scales to high-dimensional cluttered scenes.",
      "authors": [
        "Peng Xie",
        "Johannes Betz",
        "Amr Alanwar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:54:46+00:00",
          "link": "https://arxiv.org/abs/2507.09309v1",
          "size": "366kb",
          "version": "v1"
        }
      ],
      "title": "Informed Hybrid Zonotope-based Motion Planning Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09309",
        "HTML": "https://arxiv.org/html/2507.09309v1",
        "PDF": "https://arxiv.org/pdf/2507.09309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses motion planning using Hybrid Zonotope-based approaches, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09776",
      "abstract": "Analog in-memory computing (AIMC) is an energy-efficient alternative to digital architectures for accelerating machine learning and signal processing workloads. However, its energy efficiency is limited by the high energy cost of the column analog-to-digital converters (ADCs). Reducing the ADC precision is an effective approach to lowering its energy cost. However, doing so also reduces the AIMC's computational accuracy thereby making it critical to identify the minimum precision required to meet a target accuracy. Prior works overestimate the ADC precision requirements by modeling quantization error as input-independent noise, maximizing the signal-to-quantization-noise ratio (SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address these limitations by developing analytical expressions for estimating the compute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and propose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a circuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we show that for a 256-dimensional binary dot product, CACTUS reduces the ADC precision requirements by 3b while achieving 6dB higher CSNR over prior methods. We also delineate operating conditions under which our proposed CSNR-optimal ADCs outperform conventional SQNR-optimal ADCs.",
      "authors": [
        "Mihir Kavishwar and Naresh Shanbhag"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:13:20+00:00",
          "link": "https://arxiv.org/abs/2507.09776v1",
          "size": "4481kb",
          "version": "v1"
        }
      ],
      "title": "Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09776",
        "HTML": "https://arxiv.org/html/2507.09776v1",
        "PDF": "https://arxiv.org/pdf/2507.09776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with analog-to-digital converter optimization within analog in-memory computing, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09852",
      "abstract": "In unmanned aerial vehicle (UAV) networks, communication protocols and algorithms are essential for cooperation and collaboration between UAVs. Simulation provides a cost-effective solution for prototyping, debugging, and analyzing protocols and algorithms, avoiding the prohibitive expenses of field experiments. In this paper, we present ``UavNetSim-v1'', an open-source Python-based simulation platform designed for rapid development, testing, and evaluating the protocols and algorithms in UAV networks. ``UavNetSim-v1'' provides most of the functionalities developers may need, including routing/medium access control (MAC) protocols, topology control algorithms and mobility/energy models, while maintaining ease of use. Furthermore, the platform supports comprehensive performance evaluation and features an interactive visualization interface for in-depth algorithm analysis. In short, ``UavNetSim-v1'' lends itself to both rapid prototyping and educational purposes, and can serve as a lightweight yet powerful alternative to mature network simulators for UAV communication research.",
      "authors": [
        "Zihao Zhou",
        "Zipeng Dai",
        "Linyi Huang",
        "Cui Yang",
        "Youjun Xiang",
        "Jie Tang and Kai-kit Wong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:22:57+00:00",
          "link": "https://arxiv.org/abs/2507.09852v1",
          "size": "2891kb",
          "version": "v1"
        }
      ],
      "title": "UavNetSim-v1: A Python-based Simulation Platform for UAV Communication Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09852",
        "HTML": "https://arxiv.org/html/2507.09852v1",
        "PDF": "https://arxiv.org/pdf/2507.09852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a simulation platform for UAV communication networks and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09855",
      "abstract": "Designing satellite constellation systems involves complex multidisciplinary optimization in which coverage serves as a primary driver of overall system cost and performance. Among the various design considerations, constellation configuration -- how satellites are placed and distributed in space relative to each other -- predominantly determines the resulting coverage. In constellation configuration design, coverage can be considered either as an objective or a constraint, driven by mission objectives. State-of-the-art literature addresses each situation on a case-by-case basis, applying a unique set of assumptions, modeling, and solution methods. Although such a problem-based methodology is valuable, users often face implementation challenges when performing trade-off studies across different mission scenarios, as each scenario must be handled distinctly. In response, we propose a unifying framework consisting of five mixed-integer linear program formulations that are of practical significance, extensible to more complex mission narratives using additional constraints, and capable of obtaining provably optimal constellation configurations. It can handle various metrics and mission scenarios, such as percent coverage, average or maximum revisit times, fixed number of satellites, spatiotemporally varying coverage requirements, and ground-, aerial-, or space-based, static or mobile targets. The paper presents several add-ons, case studies, and comparative analyses to demonstrate the versatility of the proposed framework.",
      "authors": [
        "David O. Williams Rogers",
        "Dongshik Won",
        "Dongwook Koh",
        "Kyungwoo Hong",
        "Hang Woon Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:37:40+00:00",
          "link": "https://arxiv.org/abs/2507.09855v1",
          "size": "11961kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Design of Satellite Constellation Configurations with Mixed Integer Linear Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09855",
        "HTML": "https://arxiv.org/html/2507.09855v1",
        "PDF": "https://arxiv.org/pdf/2507.09855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing satellite constellation systems using optimization techniques, without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09890",
      "abstract": "Clustering analysis is fundamental in single-cell RNA sequencing (scRNA-seq) data analysis for elucidating cellular heterogeneity and diversity. Recent graph-based scRNA-seq clustering methods, particularly graph neural networks (GNNs), have significantly improved in tackling the challenges of high-dimension, high-sparsity, and frequent dropout events that lead to ambiguous cell population boundaries. However, their reliance on hard graph constructions derived from thresholded similarity matrices presents challenges:(i) The simplification of intercellular relationships into binary edges (0 or 1) by applying thresholds, which restricts the capture of continuous similarity features among cells and leads to significant information loss.(ii) The presence of significant inter-cluster connections within hard graphs, which can confuse GNN methods that rely heavily on graph structures, potentially causing erroneous message propagation and biased clustering outcomes. To tackle these challenges, we introduce scSGC, a Soft Graph Clustering for single-cell RNA sequencing data, which aims to more accurately characterize continuous similarities among cells through non-binary edge weights, thereby mitigating the limitations of rigid data structures. The scSGC framework comprises three core components: (i) a zero-inflated negative binomial (ZINB)-based feature autoencoder; (ii) a dual-channel cut-informed soft graph embedding module; and (iii) an optimal transport-based clustering optimization module. Extensive experiments across ten datasets demonstrate that scSGC outperforms 13 state-of-the-art clustering models in clustering accuracy, cell type annotation, and computational efficiency. These results highlight its substantial potential to advance scRNA-seq data analysis and deepen our understanding of cellular heterogeneity.",
      "authors": [
        "Ping Xu",
        "Pengfei Wang",
        "Zhiyuan Ning",
        "Meng Xiao",
        "Min Wu and Yuanchun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:49:12+00:00",
          "link": "https://arxiv.org/abs/2507.09890v1",
          "size": "16686kb",
          "version": "v1"
        }
      ],
      "title": "Soft Graph Clustering for single-cell RNA Sequencing Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09890",
        "HTML": "https://arxiv.org/html/2507.09890v1",
        "PDF": "https://arxiv.org/pdf/2507.09890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on clustering in single-cell RNA sequencing data using a soft graph clustering approach. It does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10016",
      "abstract": "Our research uncovers a novel privacy risk associated with multimodal large language models (MLLMs): the ability to infer sensitive personal attributes from audio data -- a technique we term audio private attribute profiling. This capability poses a significant threat, as audio can be covertly captured without direct interaction or visibility. Moreover, compared to images and text, audio carries unique characteristics, such as tone and pitch, which can be exploited for more detailed profiling. However, two key challenges exist in understanding MLLM-employed private attribute profiling from audio: (1) the lack of audio benchmark datasets with sensitive attribute annotations and (2) the limited ability of current MLLMs to infer such attributes directly from audio. To address these challenges, we introduce AP^2, an audio benchmark dataset that consists of two subsets collected and composed from real-world data, and both are annotated with sensitive attribute labels. Additionally, we propose Gifts, a hybrid multi-agent framework that leverages the complementary strengths of audio-language models (ALMs) and large language models (LLMs) to enhance inference capabilities. Gifts employs an LLM to guide the ALM in inferring sensitive attributes, then forensically analyzes and consolidates the ALM's inferences, overcoming severe hallucinations of existing ALMs in generating long-context responses. Our evaluations demonstrate that Gifts significantly outperforms baseline approaches in inferring sensitive attributes. Finally, we investigate model-level and data-level defense strategies to mitigate the risks of audio private attribute profiling. Our work validates the feasibility of audio-based privacy attacks using MLLMs, highlighting the need for robust defenses, and provides a dataset and framework to facilitate future research.",
      "authors": [
        "Lixu Wang",
        "Kaixiang Yao",
        "Xinfeng Li",
        "Dong Yang",
        "Haoyang Li",
        "Xiaofeng Wang",
        "Wei Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:51:56+00:00",
          "link": "https://arxiv.org/abs/2507.10016v1",
          "size": "592kb",
          "version": "v1"
        }
      ],
      "title": "The Man Behind the Sound: Demystifying Audio Private Attribute Profiling via Multimodal Large Language Model Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10016",
        "HTML": "https://arxiv.org/html/2507.10016v1",
        "PDF": "https://arxiv.org/pdf/2507.10016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces an audio benchmark dataset annotated with sensitive attribute labels and a framework for processing audio data with multimodal LLMs, indicating substantial efforts in data creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10074",
      "abstract": "The superimposed pilot transmission scheme offers substantial potential for improving spectral efficiency in MIMO-OFDM systems, but it presents significant challenges for receiver design due to pilot contamination and data interference. To address these issues, we propose an advanced iterative receiver based on joint channel estimation, detection, and decoding, which refines the receiver outputs through iterative feedback. The proposed receiver incorporates two adaptive channel estimation strategies to enhance robustness under time-varying and mismatched channel conditions. First, a variational message passing (VMP) method and its low-complexity variant (VMP-L) are introduced to perform inference without relying on time-domain correlation. Second, a deep learning (DL) based estimator is developed, featuring a convolutional neural network with a despreading module and an attention mechanism to extract and fuse relevant channel features. Extensive simulations under multi-stream and high-mobility scenarios demonstrate that the proposed receiver consistently outperforms conventional orthogonal pilot baselines in both throughput and block error rate. Moreover, over-the-air experiments validate the practical effectiveness of the proposed design. Among the methods, the DL based estimator achieves a favorable trade-off between performance and complexity, highlighting its suitability for real-world deployment in dynamic wireless environments.",
      "authors": [
        "Xinjie Li",
        "Xingyu Zhou",
        "Yixiao Cao",
        "Jing Zhang",
        "Chao-Kai Wen",
        "Xiao Li",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:00:27+00:00",
          "link": "https://arxiv.org/abs/2507.10074v1",
          "size": "1815kb",
          "version": "v1"
        }
      ],
      "title": "Learning-Aided Iterative Receiver for Superimposed Pilots: Design and Experimental Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10074",
        "HTML": "https://arxiv.org/html/2507.10074v1",
        "PDF": "https://arxiv.org/pdf/2507.10074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the design and evaluation of a receiver for MIMO-OFDM systems focusing on channel estimation and decoding, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.02595",
      "abstract": "This study introduces the Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine Learning (QML) and quantum computing with Federated Learning (FL) for financial fraud detection. Using quantum technologies' computational power and the robust data privacy protections offered by FL, QFNN-FFD emerges as a secure and efficient method for identifying fraudulent transactions within the financial sector. Implementing a dual-phase training model across distributed clients enhances data integrity and enables superior performance metrics, achieving precision rates consistently above 95%. Additionally, QFNN-FFD demonstrates exceptional resilience by maintaining an impressive 80% accuracy, highlighting its robustness and readiness for real-world applications. This combination of high performance, security, and robustness against noise positions QFNN-FFD as a transformative advancement in financial technology solutions and establishes it as a new benchmark for privacy-focused fraud detection systems. This framework facilitates the broader adoption of secure, quantum-enhanced financial services and inspires future innovations that could use QML to tackle complex challenges in other areas requiring high confidentiality and accuracy.",
      "authors": [
        "Nouhaila Innan",
        "Alberto Marchisio",
        "Mohamed Bennai",
        "and Muhammad Shafique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-03T09:19:46+00:00",
          "link": "https://arxiv.org/abs/2404.02595v1",
          "size": "466kb",
          "version": "v1"
        },
        {
          "date": "2024-05-01T10:04:21+00:00",
          "link": "https://arxiv.org/abs/2404.02595v2",
          "size": "691kb",
          "version": "v2"
        },
        {
          "date": "2024-12-02T10:36:05+00:00",
          "link": "https://arxiv.org/abs/2404.02595v3",
          "size": "838kb",
          "version": "v3"
        },
        {
          "date": "2025-05-22T09:43:50+00:00",
          "link": "https://arxiv.org/abs/2404.02595v4",
          "size": "839kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T04:24:08+00:00",
          "link": "https://arxiv.org/abs/2404.02595v5",
          "size": "839kb",
          "version": "v5"
        }
      ],
      "title": "QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.02595",
        "HTML": "https://arxiv.org/html/2404.02595v5",
        "PDF": "https://arxiv.org/pdf/2404.02595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development of a Quantum Federated Neural Network for financial fraud detection and does not discuss any processing of LLM training data."
      },
      "tasks": [
        "Federated Learning",
        "Fraud Detection",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12795",
      "abstract": "Building up competencies in working with data and tools of Artificial Intelligence (AI) is becoming more relevant across disciplinary engineering fields. While the adoption of tools for teaching and learning, such as ChatGPT, is garnering significant attention, integration of AI knowledge, competencies, and skills within engineering education is lacking. Building upon existing curriculum change research, this practice paper introduces a systems perspective on integrating AI education within engineering through the lens of a change model. In particular, it identifies core aspects that shape AI adoption on a program level as well as internal and external influences using existing literature and a practical case study. Overall, the paper provides an analysis frame to enhance the understanding of change initiatives and builds the basis for generalizing insights from different initiatives in the adoption of AI in engineering education.",
      "authors": [
        "Johannes Schleiss",
        "Aditya Johri",
        "Sebastian Stober"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-28T18:02:17+00:00",
          "link": "https://arxiv.org/abs/2410.12795v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Integrating AI Education in Disciplinary Engineering Fields: Towards a System and Change Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12795",
        "PDF": "https://arxiv.org/pdf/2410.12795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about integrating AI education in engineering fields, with no relevance to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08960",
      "abstract": "Large Language Models (LLMs) have achieved strong performance on a wide range of complex reasoning tasks, yet further gains are often possible by leveraging the complementary strengths of multiple models. While multi-agent frameworks can improve solution quality by leveraging multiple LLMs, existing methods are often computationally expensive, both at training and inference time. In this work, we introduce a hierarchical multi-agent framework that addresses these challenges by training only a single leader LLM to coordinate a team of untrained peer agents. To this end, we propose Multi-agent guided Leader Policy \\textbf{O}ptimization (MLPO), a novel approach which trains the leader to evaluate and synthesize agent responses without auxiliary value networks or explicit agent feedback. Leaders trained with MLPO exhibit improved performance not only when interacting with the agent team at inference time, but also enjoy improved performance when deployed in single-agent settings without the team. Empirical results on Big-Bench Hard (BBH), MATH, and MMLU demonstrate that our framework achieves substantial performance improvements over both single-agent and multi-agent baselines. Our results highlight the effectiveness and efficiency of training a single, flexible leader for collaborative reasoning in multi-agent LLM systems.",
      "authors": [
        "Andrew Estornell",
        "Jean-Francois Ton",
        "Muhammad Faaiz Taufiq",
        "Hang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:34:07+00:00",
          "link": "https://arxiv.org/abs/2507.08960v1",
          "size": "5933kb",
          "version": "v1"
        }
      ],
      "title": "How to Train a Leader: Hierarchical Reasoning in Multi-Agent LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08960",
        "PDF": "https://arxiv.org/pdf/2507.08960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a multi-agent framework for LLMs, focusing on optimizing reasoning tasks, but it does not address LLM training data processing or creation directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09709",
      "abstract": "Understanding the latent space geometry of large language models (LLMs) is key to interpreting their behavior and improving alignment. \\baturay{However, it remains unclear to what extent LLMs internally organize representations related to semantic understanding. To investigate this, we conduct a large-scale empirical study of hidden states in transformer-based LLMs, analyzing 11 decoder-only models across 6 scientific topics and 12 layers each. We find that high-level semantic information consistently lies in low-dimensional subspaces that form linearly separable representations across distinct domains. This separability becomes more pronounced in deeper layers and under prompts that trigger structured reasoning or alignment behaviors$\\unicode{x2013}$even when surface content is unchanged. This geometry enables simple yet effective causal interventions in hidden space; for example, reasoning patterns like chain-of-thought can be captured by a single vector direction. Together, these findings support the development of geometry-aware tools that operate directly on latent representations to detect and mitigate harmful or adversarial content, using methods such as transport-based defenses that leverage this separability. As a proof of concept, we demonstrate this potential by training a simple MLP classifier as a lightweight latent-space guardrail, which detects adversarial and malicious prompts with high precision.",
      "authors": [
        "Baturay Saglam",
        "Paul Kassianik",
        "Blaine Nelson",
        "Sajana Weerawardhena",
        "Yaron Singer",
        "Amin Karbasi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:03:25+00:00",
          "link": "https://arxiv.org/abs/2507.09709v1",
          "size": "3741kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models Encode Semantics in Low-Dimensional Linear Subspaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09709",
        "HTML": "https://arxiv.org/html/2507.09709v1",
        "PDF": "https://arxiv.org/pdf/2507.09709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the latent space geometry of LLMs for semantic understanding but does not address training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10043",
      "abstract": "Immersive analytics is gaining attention across multiple domains due to its capability to facilitate intuitive data analysis in expansive environments through user interaction with data. However, creating immersive analytics systems for specific tasks is challenging due to the need for programming expertise and significant development effort. Despite the introduction of various immersive visualization authoring toolkits, domain experts still face hurdles in adopting immersive analytics into their workflow, particularly when faced with dynamically changing tasks and data in real time. To lower such technical barriers, we introduce XROps, a web-based authoring system that allows users to create immersive analytics applications through interactive visual programming, without the need for low-level scripting or coding. XROps enables dynamic immersive analytics authoring by allowing users to modify each step of the data visualization process with immediate feedback, enabling them to build visualizations on-the-fly and adapt to changing environments. It also supports the integration and visualization of real-time sensor data from XR devices, a key feature of immersive analytics, facilitating the creation of various analysis scenarios. We evaluated the usability of XROps through a user study and demonstrate its efficacy and usefulness in several example scenarios. We have released a web platform (https://vience.io/xrops) to demonstrate various examples to supplement our findings.",
      "authors": [
        "Suemin Jeon",
        "JunYoung Choi",
        "Haejin Jeong",
        "Won-Ki Jeong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:19:32+00:00",
          "link": "https://arxiv.org/abs/2507.10043v1",
          "size": "13623kb",
          "version": "v1"
        }
      ],
      "title": "XROps: A Visual Workflow Management System for Dynamic Immersive Analytics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10043",
        "HTML": "https://arxiv.org/html/2507.10043v1",
        "PDF": "https://arxiv.org/pdf/2507.10043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses immersive analytics and a visual workflow management system, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2008.07292",
      "abstract": "This paper is concerned with the paraconsistent first-order logic LPQ$^{\\supset,\\mathsf{F}}$, Priest's LPQ enriched with an implication connective and a falsity constant. A sequent-style natural deduction proof system for this logic is presented and, for this proof system, both a model-theoretic justification and a logical justification by means of an embedding into first-order classical logic is given. The given embedding provides in addition a classical-logic explanation of this paraconsistent logic. As a further matter, its use in decidability issues concerning this paraconsistent logic is discussed. The major properties of LPQ$^{\\supset,\\mathsf{F}}$ concerning its logical consequence relation and its logical equivalence relation are also treated. The paper emphasizes how closely LPQ$^{\\supset,\\mathsf{F}}$ is related to classical logic.",
      "authors": [
        "C. A. Middelburg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2020-08-17T13:17:25+00:00",
          "link": "https://arxiv.org/abs/2008.07292v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2021-01-08T13:31:18+00:00",
          "link": "https://arxiv.org/abs/2008.07292v2",
          "size": "33kb",
          "version": "v2"
        },
        {
          "date": "2022-07-06T15:10:20+00:00",
          "link": "https://arxiv.org/abs/2008.07292v3",
          "size": "26kb",
          "version": "v3"
        },
        {
          "date": "2022-08-27T11:46:24+00:00",
          "link": "https://arxiv.org/abs/2008.07292v4",
          "size": "26kb",
          "version": "v4"
        },
        {
          "date": "2022-10-23T09:05:13+00:00",
          "link": "https://arxiv.org/abs/2008.07292v5",
          "size": "26kb",
          "version": "v5"
        },
        {
          "date": "2023-01-12T21:14:59+00:00",
          "link": "https://arxiv.org/abs/2008.07292v6",
          "size": "26kb",
          "version": "v6"
        },
        {
          "date": "2025-06-21T08:21:54+00:00",
          "link": "https://arxiv.org/abs/2008.07292v7",
          "size": "27kb",
          "version": "v7"
        },
        {
          "date": "2025-07-13T17:44:33+00:00",
          "link": "https://arxiv.org/abs/2008.07292v8",
          "size": "30kb",
          "version": "v8"
        }
      ],
      "title": "A classical-logic view on a paraconsistent logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2008.07292",
        "PDF": "https://arxiv.org/pdf/2008.07292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with paraconsistent logic and its classical logic embedding, with no mention of LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.05709",
      "abstract": "The capacity of a discrete-time channel with correlated phase noises is investigated. In particular, the electro-optic frequency comb system is considered, where the phase noise of each subchannel is a combination of two independent Wiener phase-noise sources. Capacity upper and lower bounds are derived for this channel and are compared with lower bounds obtained by numerically evaluating the achievable information rates using quadrature amplitude modulation constellations. Capacity upper and lower bounds are provided for the high signal-to-noise ratio (SNR) regime. The multiplexing gain (pre-log) is shown to be $M-1$, where $M$ represents the number of subchannels. A constant gap between the asymptotic upper and lower bounds is observed, which depends on the number of subchannels $M$. For the specific case of $M=2$, capacity is characterized up to a term that vanishes as the SNR grows large.",
      "authors": [
        "Mohammad Farsi",
        "Hamdi Joudeh",
        "Gabriele Liga",
        "Alex Alvarado",
        "Magnus Karlsson",
        "and Erik Agrell"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-09T12:10:18+00:00",
          "link": "https://arxiv.org/abs/2405.05709v1",
          "size": "223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:39:26+00:00",
          "link": "https://arxiv.org/abs/2405.05709v2",
          "size": "225kb",
          "version": "v2"
        }
      ],
      "title": "On the Capacity of Correlated Phase-Noise Channels: An Electro-Optic Frequency Comb Example",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.05709",
        "PDF": "https://arxiv.org/pdf/2405.05709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates channel capacity in electro-optic systems and does not involve LLM training data processing or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.17739",
      "abstract": "Extending the context length of Language Models (LMs) by improving Rotary Position Embedding (RoPE) has become a trend. While prior works mainly address RoPE's limitations within attention, this paper uncovers the adverse effects on length generalization from nearly all parts of LMs. Using Discrete Signal Processing theory, we show that RoPE enables periodic attention by implicitly achieving Non-Uniform Discrete Fourier Transform. However, this periodicity is undermined by the spectrum damage caused by: 1) linear layers and activation functions; 2) insufficiently trained frequency components brought by time-domain truncation. Building on our observations, we propose Fourier Position Embedding (FoPE), which enhances attention's frequency-domain properties to improve both its periodic extension and length generalization. FoPE constructs \\textit{Fourier Series} and zero-outs the destructive frequency components, increasing model robustness against the spectrum damage. Experiments across various model scales and benchmarks show that, within varying context windows, FoPE maintains a more stable performance compared to other baselines. Several analyses and ablations bring further support to our method and theoretical modeling.",
      "authors": [
        "Ermo Hua",
        "Che Jiang",
        "Xingtai Lv",
        "Kaiyan Zhang",
        "Youbang Sun",
        "Yuchen Fan",
        "Xuekai Zhu",
        "Biqing Qi",
        "Ning Ding",
        "and Bowen Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T17:44:01+00:00",
          "link": "https://arxiv.org/abs/2412.17739v1",
          "size": "526kb",
          "version": "v1"
        },
        {
          "date": "2025-01-02T08:58:38+00:00",
          "link": "https://arxiv.org/abs/2412.17739v2",
          "size": "526kb",
          "version": "v2"
        },
        {
          "date": "2025-05-06T07:47:40+00:00",
          "link": "https://arxiv.org/abs/2412.17739v3",
          "size": "558kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T04:23:36+00:00",
          "link": "https://arxiv.org/abs/2412.17739v4",
          "size": "450kb",
          "version": "v4"
        }
      ],
      "title": "Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17739",
        "HTML": "https://arxiv.org/html/2412.17739v4",
        "PDF": "https://arxiv.org/pdf/2412.17739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes Fourier Position Embedding to improve length generalization in language models but focuses on enhancements to model architecture rather than data processing itself."
      },
      "tasks": [
        "Position"
      ],
      "repo_urls": [
        "https://github.com/tsinghuac3i/fourier-position-embedding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09094",
      "abstract": "In this paper, a novel Three dimensional (3D) positioning framework of fluid antenna system (FAS)-enabled unmanned aerial vehicles (UAVs) is developed. In the proposed framework, a set of controlled UAVs cooperatively estimate the real-time 3D position of a target UAV. Here, the active UAV transmits a measurement signal to the passive UAVs via the reflection from the target UAV. Each passive UAV estimates the distance of the active-target-passive UAV link and selects an antenna port to share the distance information with the base station (BS) that calculates the real-time position of the target UAV. As the target UAV is moving due to its task operation, the controlled UAVs must optimize their trajectories and select optimal antenna port, aiming to estimate the real-time position of the target UAV. We formulate this problem as an optimization problem to minimize the target UAV positioning error via optimizing the trajectories of all controlled UAVs and antenna port selection of passive UAVs. Here, an attention-based recurrent multi-agent reinforcement learning (AR-MARL) scheme is proposed, which enables each controlled UAV to use the local Q function to determine its trajectory and antenna port while optimizing the target UAV positioning performance without knowing the trajectories and antenna port selections of other controlled UAVs. Different from current MARL methods, the proposed method uses a recurrent neural network (RNN) that incorporates historical state-action pairs of each controlled UAV, and an attention mechanism to analyze the importance of these historical state-action pairs, thus improving the global Q function approximation accuracy and the target UAV positioning accuracy. Simulation results show that the proposed AR-MARL scheme can reduce the average positioning error by up to 17.5% and 58.5% compared to the VD-MARL scheme and the proposed method without FAS.",
      "authors": [
        "Xiaoren Xu",
        "Hao Xu",
        "Dongyu Wei",
        "Walid Saad",
        "Mehdi Bennis",
        "and Mingzhe Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:31:15+00:00",
          "link": "https://arxiv.org/abs/2507.09094v1",
          "size": "415kb",
          "version": "v1"
        }
      ],
      "title": "Transformer based Collaborative Reinforcement Learning for Fluid Antenna System (FAS)-enabled 3D UAV Positioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09094",
        "HTML": "https://arxiv.org/html/2507.09094v1",
        "PDF": "https://arxiv.org/pdf/2507.09094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on UAV positioning using reinforcement learning and does not involve LLM training data processing or improvements therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10440",
      "abstract": "Large language models have demonstrated substantial advancements in reasoning capabilities. However, current Vision-Language Models (VLMs) often struggle to perform systematic and structured reasoning, especially when handling complex visual question-answering tasks. In this work, we introduce LLaVA-CoT, a large VLM designed to conduct autonomous multistage reasoning. Unlike chain-of-thought prompting, LLaVA-CoT independently engages in sequential stages of summarization, visual interpretation, logical reasoning, and conclusion generation. This structured approach enables LLaVA-CoT to achieve marked improvements on reasoning-intensive tasks. To accomplish this, we construct the LLaVA-CoT-100k dataset, integrating samples from various visual question answering sources and providing structured reasoning annotations. Besides, we propose a test-time stage-wise retracing search method (SWIRES), which enables effective and efficient test-time scaling. Remarkably, with only 100k training samples and test-time scaling, LLaVA-CoT not only outperforms its base model by 9.4% on a wide range of multimodal reasoning benchmarks, but also surpasses the performance of larger and even closed-source models, such as Gemini-1.5-pro, GPT-4o-mini, and Llama-3.2-90B-Vision-Instruct. The code, dataset, and pre-trained weights are publicly available at https://github.com/PKU-YuanGroup/LLaVA-CoT.",
      "authors": [
        "Guowei Xu",
        "Peng Jin",
        "Ziang Wu",
        "Hao Li",
        "Yibing Song",
        "Lichao Sun",
        "Li Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T18:58:31+00:00",
          "link": "https://arxiv.org/abs/2411.10440v1",
          "size": "700kb",
          "version": "v1"
        },
        {
          "date": "2024-11-25T07:42:20+00:00",
          "link": "https://arxiv.org/abs/2411.10440v2",
          "size": "3492kb",
          "version": "v2"
        },
        {
          "date": "2025-01-09T07:58:20+00:00",
          "link": "https://arxiv.org/abs/2411.10440v3",
          "size": "3474kb",
          "version": "v3"
        },
        {
          "date": "2025-02-16T08:24:42+00:00",
          "link": "https://arxiv.org/abs/2411.10440v4",
          "size": "3476kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T06:36:59+00:00",
          "link": "https://arxiv.org/abs/2411.10440v5",
          "size": "3604kb",
          "version": "v5"
        }
      ],
      "title": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10440",
        "PDF": "https://arxiv.org/pdf/2411.10440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces LLaVA-CoT, focusing on multistage reasoning for visual question answering and dataset creation for reasoning tasks, but lacks focus on LLM training data processing or general LLM dataset engineering."
      },
      "models": [
        {
          "model_path": "Xkev/Llama-3.2V-11B-cot",
          "downloads": "3654",
          "likes": "153",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Xkev/Llama-3.2V-11B-cot"
        },
        {
          "model_path": "BarraHome/Mistroll-3.0-CoT-Llama-3.2-11B-Vision-Instruct",
          "downloads": "7",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BarraHome/Mistroll-3.0-CoT-Llama-3.2-11B-Vision-Instruct"
        }
      ],
      "datasets": [
        {
          "dataset_name": "berhaan/clevr-tr",
          "downloads": "28",
          "likes": "2",
          "link": "https://huggingface.co/datasets/berhaan/clevr-tr"
        },
        {
          "dataset_name": "Xkev/LLaVA-CoT-100k",
          "downloads": "1732",
          "likes": "95",
          "link": "https://huggingface.co/datasets/Xkev/LLaVA-CoT-100k"
        },
        {
          "dataset_name": "berhaan/pisc-tr",
          "downloads": "12",
          "likes": "1",
          "link": "https://huggingface.co/datasets/berhaan/pisc-tr"
        },
        {
          "dataset_name": "Nagase-Kotono/LLaVA-CoT-ko",
          "downloads": "15",
          "likes": "2",
          "link": "https://huggingface.co/datasets/Nagase-Kotono/LLaVA-CoT-ko"
        },
        {
          "dataset_name": "di-zhang-fdu/llava-cot-100k-r1-format",
          "downloads": "53",
          "likes": "2",
          "link": "https://huggingface.co/datasets/di-zhang-fdu/llava-cot-100k-r1-format"
        }
      ],
      "tasks": [
        "Logical Reasoning",
        "Multimodal Reasoning",
        "Question Answering",
        "Visual Question Answering"
      ],
      "repo_urls": [
        "https://github.com/PKU-YuanGroup/LLaVA-CoT",
        "https://github.com/zhaoolee/garss"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.21774",
      "abstract": "Collaborative perception enhances environmental awareness through inter-agent communication and is regarded as a promising solution to intelligent transportation systems. However, existing collaborative methods for Unmanned Aerial Vehicles (UAVs) overlook the unique characteristics of the UAV perspective, resulting in substantial communication overhead. To address this issue, we propose a novel communication-efficient collaborative perception framework based on late-intermediate fusion, dubbed LIF. The core concept is to exchange informative and compact detection results and shift the fusion stage to the feature representation level. In particular, we leverage vision-guided positional embedding (VPE) and box-based virtual augmented feature (BoBEV) to effectively integrate complementary information from various agents. Additionally, we innovatively introduce an uncertainty-driven communication mechanism that uses uncertainty evaluation to select high-quality and reliable shared areas. Experimental results demonstrate that our LIF achieves superior performance with minimal communication bandwidth, proving its effectiveness and practicality. Code and models are available at https://github.com/uestchjw/LIF.",
      "authors": [
        "Jiuwu Hao",
        "Liguo Sun",
        "Yuting Wan",
        "Yueyang Wu",
        "Ti Xiang",
        "Haolin Song and Pin Lv"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T16:22:14+00:00",
          "link": "https://arxiv.org/abs/2504.21774v1",
          "size": "3192kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:42:11+00:00",
          "link": "https://arxiv.org/abs/2504.21774v2",
          "size": "3192kb",
          "version": "v2"
        }
      ],
      "title": "Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21774",
        "HTML": "https://arxiv.org/html/2504.21774v2",
        "PDF": "https://arxiv.org/pdf/2504.21774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a communication-efficient collaborative perception framework for UAVs, which does not pertain to processing or creating LLM training data."
      },
      "tasks": [
        "All"
      ],
      "repo_urls": [
        "https://github.com/uestchjw/lif"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23978",
      "abstract": "While the Internet's core infrastructure was designed to be open and universal, today's application layer is dominated by closed, proprietary platforms. Open and interoperable APIs require significant investment, and market leaders have little incentive to enable data exchange that could erode their user lock-in. We argue that LLM-based agents fundamentally disrupt this status quo. Agents can automatically translate between data formats and interact with interfaces designed for humans: this makes interoperability dramatically cheaper and effectively unavoidable. We name this shift universal interoperability: the ability for any two digital services to exchange data seamlessly using AI-mediated adapters. Universal interoperability undermines monopolistic behaviours and promotes data portability. However, it can also lead to new security risks and technical debt. Our position is that the ML community should embrace this development while building the appropriate frameworks to mitigate the downsides. By acting now, we can harness AI to restore user freedom and competitive markets without sacrificing security.",
      "authors": [
        "Samuele Marro",
        "Philip Torr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:45:17+00:00",
          "link": "https://arxiv.org/abs/2506.23978v1",
          "size": "83kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T15:26:07+00:00",
          "link": "https://arxiv.org/abs/2506.23978v2",
          "size": "83kb",
          "version": "v2"
        }
      ],
      "title": "LLM Agents Are the Antidote to Walled Gardens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23978",
        "HTML": "https://arxiv.org/html/2506.23978v2",
        "PDF": "https://arxiv.org/pdf/2506.23978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses LLM-based agents for universal interoperability across digital services, which is about data translation and interaction rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09184",
      "abstract": "Hallucinations pose a significant challenge in Large Vision Language Models (LVLMs), with misalignment between multimodal features identified as a key contributing factor. This paper reveals the negative impact of the long-term decay in Rotary Position Encoding (RoPE), used for positional modeling in LVLMs, on multimodal alignment. Concretely, under long-term decay, instruction tokens exhibit uneven perception of image tokens located at different positions within the two-dimensional space: prioritizing image tokens from the bottom-right region since in the one-dimensional sequence, these tokens are positionally closer to the instruction tokens. This biased perception leads to insufficient image-instruction interaction and suboptimal multimodal alignment. We refer to this phenomenon as image alignment bias. To enhance instruction's perception of image tokens at different spatial locations, we propose MCA-LLaVA, based on Manhattan distance, which extends the long-term decay to a two-dimensional, multi-directional spatial decay. MCA-LLaVA integrates the one-dimensional sequence order and two-dimensional spatial position of image tokens for positional modeling, mitigating hallucinations by alleviating image alignment bias. Experimental results of MCA-LLaVA across various hallucination and general benchmarks demonstrate its effectiveness and generality. The code can be accessed in https://github.com/ErikZ719/MCA-LLaVA.",
      "authors": [
        "Qiyan Zhao",
        "Xiaofeng Zhang",
        "Yiheng Li",
        "Yun Xing",
        "Xiaosong Yuan",
        "Feilong Tang",
        "Sinan Fan",
        "Xuhang Chen",
        "Xuyao Zhang",
        "Dahan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:09:35+00:00",
          "link": "https://arxiv.org/abs/2507.09184v1",
          "size": "1832kb",
          "version": "v1"
        }
      ],
      "title": "MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09184",
        "HTML": "https://arxiv.org/html/2507.09184v1",
        "PDF": "https://arxiv.org/pdf/2507.09184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concentrates on improving multimodal alignment in large vision-language models, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09311",
      "abstract": "This study introduces a novel multi-objective reinforcement learning (MORL) approach for autonomous intersection management, aiming to balance traffic efficiency and environmental sustainability across electric and internal combustion vehicles. The proposed method utilizes MORL to identify Pareto-optimal policies, with a post-hoc fairness criterion guiding the selection of the final policy. Simulation results in a complex intersection scenario demonstrate the approach's effectiveness in optimizing traffic efficiency and emissions reduction while ensuring fairness across vehicle categories. We believe that this criterion can lay the foundation for ensuring equitable service, while fostering safe, efficient, and sustainable practices in smart urban mobility.",
      "authors": [
        "Matteo Cederle",
        "Marco Fabris",
        "Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:58:13+00:00",
          "link": "https://arxiv.org/abs/2507.09311v1",
          "size": "112kb",
          "version": "v1"
        }
      ],
      "title": "A Fairness-Oriented Multi-Objective Reinforcement Learning approach for Autonomous Intersection Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09311",
        "HTML": "https://arxiv.org/html/2507.09311v1",
        "PDF": "https://arxiv.org/pdf/2507.09311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a reinforcement learning approach for traffic management. It does not relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09507",
      "abstract": "Due to their numerous applications, in particular in Mechanism Design, Prophet Inequalities have experienced a surge of interest. They describe competitive ratios for basic stopping time problems where random variables get revealed sequentially. A key drawback in the classical setting is the assumption of full distributional knowledge of the involved random variables, which is often unrealistic. A natural way to address this is via sample-based approaches, where only a limited number of samples from the distribution of each random variable is available. Recently, Fu, Lu, Gavin Tang, Wu, Wu, and Zhang (2024) showed that sample-based Online Contention Resolution Schemes (OCRS) are a powerful tool to obtain sample-based Prophet Inequalities. They presented the first sample-based OCRS for matroid constraints, which is a heavily studied constraint family in this context, as it captures many interesting settings. This allowed them to get the first sample-based Matroid Prophet Inequality, using $O(\\log^4 n)$ many samples (per random variable), where $n$ is the number of random variables, while obtaining a constant competitiveness of $\\frac{1}{4}-\\varepsilon$.\n  We present a nearly optimal sample-based OCRS for matroid constraints, which uses only $O(\\log \\rho \\cdot \\log^2\\log\\rho)$ many samples, almost matching a known lower bound of $\\Omega(\\log \\rho)$, where $\\rho \\leq n$ is the rank of the matroid. Through the above-mentioned connection to Prophet Inequalities, this yields a sample-based Matroid Prophet Inequality using only $O(\\log n + \\log\\rho \\cdot \\log^2\\log\\rho)$ many samples, and matching the competitiveness of $\\frac{1}{4}-\\varepsilon$, which is the best known competitiveness for the considered almighty adversary setting even when the distributions are fully known.",
      "authors": [
        "Moran Feldman",
        "Ola Svensson",
        "Rico Zenklusen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:18:48+00:00",
          "link": "https://arxiv.org/abs/2507.09507v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "Nearly Tight Sample Complexity for Matroid Online Contention Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09507",
        "HTML": "https://arxiv.org/html/2507.09507v1",
        "PDF": "https://arxiv.org/pdf/2507.09507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sample complexity in the context of online contention resolution and Prophet Inequalities, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09786",
      "abstract": "Approximate machine unlearning (AMU) enables models to `forget' specific training data through specialized fine-tuning on a retained dataset subset. However, processing this retained subset still dominates computational runtime, while reductions of epochs also remain a challenge. We propose two complementary methods to accelerate classification-oriented AMU. First, \\textbf{Blend}, a novel distribution-matching dataset condensation (DC), merges visually similar images with shared blend-weights to significantly reduce the retained set size. It operates with minimal pre-processing overhead and is orders of magnitude faster than state-of-the-art DC methods. Second, our loss-centric method, \\textbf{Accelerated-AMU (A-AMU)}, augments the unlearning objective to quicken convergence. A-AMU achieves this by combining a steepened primary loss to expedite forgetting with a novel, differentiable regularizer that matches the loss distributions of forgotten and in-distribution unseen data. Our extensive experiments demonstrate that this dual approach of data and loss-centric optimization dramatically reduces end-to-end unlearning latency across both single and multi-round scenarios, all while preserving model utility and privacy. To our knowledge, this is the first work to systematically tackle unlearning efficiency by jointly designing a specialized dataset condensation technique with a dedicated accelerated loss function. Code is available at https://github.com/algebraicdianuj/DC_Unlearning.",
      "authors": [
        "Junaid Iqbal Khan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:57:31+00:00",
          "link": "https://arxiv.org/abs/2507.09786v1",
          "size": "2629kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Distribution Matching to Make Approximate Machine Unlearning Faster",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09786",
        "HTML": "https://arxiv.org/html/2507.09786v1",
        "PDF": "https://arxiv.org/pdf/2507.09786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a dataset condensation technique for efficient training in the context of machine unlearning, which relates to data processing but not explicitly to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10026",
      "abstract": "The growth of Artificial Intelligence (AI) and large language models has enabled the use of Generative AI (GenAI) in cloud data centers for diverse AI-Generated Content (AIGC) tasks. Models like Stable Diffusion introduce unavoidable delays and substantial resource overhead, which are unsuitable for users at the network edge with high QoS demands. Deploying AIGC services on edge servers reduces transmission times but often leads to underutilized resources and fails to optimally balance inference latency and quality. To address these issues, this paper introduces a QoS-aware \\underline{E}dge-collaborative \\underline{A}IGC \\underline{T}ask scheduling (EAT) algorithm. Specifically: 1) We segment AIGC tasks and schedule patches to various edge servers, formulating it as a gang scheduling problem that balances inference latency and quality while considering server heterogeneity, such as differing model distributions and cold start issues. 2) We propose a reinforcement learning-based EAT algorithm that uses an attention layer to extract load and task queue information from edge servers and employs a diffusion-based policy network for scheduling, efficiently enabling model reuse. 3) We develop an AIGC task scheduling system that uses our EAT algorithm to divide tasks and distribute them across multiple edge servers for processing. Experimental results based on our system and large-scale simulations show that our EAT algorithm can reduce inference latency by up to 56\\% compared to baselines. We release our open-source code at https://github.com/zzf1955/EAT.",
      "authors": [
        "Zhifei Xu",
        "Zhiqing Tang",
        "Jiong Lou",
        "Zhi Yao",
        "Xuan Xie",
        "Tian Wang",
        "Yinglong Wang",
        "Weijia Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:06:58+00:00",
          "link": "https://arxiv.org/abs/2507.10026v1",
          "size": "5776kb",
          "version": "v1"
        }
      ],
      "title": "EAT: QoS-Aware Edge-Collaborative AIGC Task Scheduling via Attention-Guided Diffusion Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10026",
        "HTML": "https://arxiv.org/html/2507.10026v1",
        "PDF": "https://arxiv.org/pdf/2507.10026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces task scheduling for AI-generated content tasks using LLMs but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10087",
      "abstract": "The rapid emergence of foundation models, particularly Large Language Models (LLMs) and Vision-Language Models (VLMs), has introduced a transformative paradigm in robotics. These models offer powerful capabilities in semantic understanding, high-level reasoning, and cross-modal generalization, enabling significant advances in perception, planning, control, and human-robot interaction. This critical review provides a structured synthesis of recent developments, categorizing applications across simulation-driven design, open-world execution, sim-to-real transfer, and adaptable robotics. Unlike existing surveys that emphasize isolated capabilities, this work highlights integrated, system-level strategies and evaluates their practical feasibility in real-world environments. Key enabling trends such as procedural scene generation, policy generalization, and multimodal reasoning are discussed alongside core bottlenecks, including limited embodiment, lack of multimodal data, safety risks, and computational constraints. Through this lens, this paper identifies both the architectural strengths and critical limitations of foundation model-based robotics, highlighting open challenges in real-time operation, grounding, resilience, and trust. The review concludes with a roadmap for future research aimed at bridging semantic reasoning and physical intelligence through more robust, interpretable, and embodied models.",
      "authors": [
        "Muhammad Tayyab Khan",
        "Ammar Waheed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:13:07+00:00",
          "link": "https://arxiv.org/abs/2507.10087v1",
          "size": "21439kb",
          "version": "v1"
        }
      ],
      "title": "Foundation Model Driven Robotics: A Comprehensive Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10087",
        "HTML": "https://arxiv.org/html/2507.10087v1",
        "PDF": "https://arxiv.org/pdf/2507.10087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a review of foundation models for robotics applications, focusing on model capabilities and real-world integration challenges, not on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10284",
      "abstract": "Visual coverage path planning with unmanned aerial vehicles (UAVs) requires agents to strategically coordinate UAV motion and camera control to maximize coverage, minimize redundancy, and maintain battery efficiency. Traditional reinforcement learning (RL) methods rely on environment-specific reward formulations that lack semantic adaptability. This study proposes Prompt-Informed Reinforcement Learning (PIRL), a novel approach that integrates the zero-shot reasoning ability and in-context learning capability of large language models with curiosity-driven RL. PIRL leverages semantic feedback from an LLM, GPT-3.5, to dynamically shape the reward function of the Proximal Policy Optimization (PPO) RL policy guiding the agent in position and camera adjustments for optimal visual coverage. The PIRL agent is trained using OpenAI Gym and evaluated in various environments. Furthermore, the sim-to-real-like ability and zero-shot generalization of the agent are tested by operating the agent in Webots simulator which introduces realistic physical dynamics. Results show that PIRL outperforms multiple learning-based baselines such as PPO with static rewards, PPO with exploratory weight initialization, imitation learning, and an LLM-only controller. Across different environments, PIRL outperforms the best-performing baseline by achieving up to 14% higher visual coverage in OpenAI Gym and 27% higher in Webots, up to 25% higher battery efficiency, and up to 18\\% lower redundancy, depending on the environment. The results highlight the effectiveness of LLM-guided reward shaping in complex spatial exploration tasks and suggest a promising direction for integrating natural language priors into RL for robotics.",
      "authors": [
        "Venkat Margapuri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:51:28+00:00",
          "link": "https://arxiv.org/abs/2507.10284v1",
          "size": "2531kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Informed Reinforcement Learning for Visual Coverage Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10284",
        "HTML": "https://arxiv.org/html/2507.10284v1",
        "PDF": "https://arxiv.org/pdf/2507.10284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper improves reinforcement learning in camera and UAV control using LLM-based semantic feedback for reward shaping, focusing on robotics rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.02718",
      "abstract": "Pan-sharpening algorithm utilizes panchromatic image and multispectral image to obtain a high spatial and high spectral image. However, the optimizations of the algorithms are designed with different standards. We adopt the simple matrix equation to describe the Pan-sharpening problem. The solution existence condition and the acquirement of spectral and spatial resolution are discussed. A down-sampling enhancement method was introduced for better acquiring the spatial and spectral down-sample matrices. By the generalized inverse theory, we derived two forms of general inverse matrix formulations that can correspond to the two prominent classes of Pan-sharpening methods, that is, component substitution and multi-resolution analysis methods. Specifically, the Gram Schmidt Adaptive(GSA) was proved to follow the general inverse matrix formulation of component substitution. A model prior to the general inverse matrix of the spectral function was rendered. The theoretical errors are analyzed. Synthetic experiments and real data experiments are implemented. The proposed methods are better and sharper than other methods qualitatively in both synthetic and real experiments. The down-sample enhancement effect is shown of better results both quantitatively and qualitatively in real experiments. The generalized inverse matrix theory help us better understand the Pan-sharpening.",
      "authors": [
        "Shiqi Liu",
        "Yutong Bai",
        "Xinyang Han",
        "Alan Yuille"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-04T10:41:21+00:00",
          "link": "https://arxiv.org/abs/2310.02718v1",
          "size": "2537kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:52:35+00:00",
          "link": "https://arxiv.org/abs/2310.02718v2",
          "size": "22535kb",
          "version": "v2"
        }
      ],
      "title": "Understanding Pan-Sharpening via Generalized Inverse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.02718",
        "HTML": "https://arxiv.org/html/2310.02718v2",
        "PDF": "https://arxiv.org/pdf/2310.02718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pan-sharpening algorithms and image processing, which are unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.13693",
      "abstract": "Photovoltaic (PV) systems allow us to tap into all abundant solar energy, however they require regular maintenance for high efficiency and to prevent degradation. Traditional manual health check, using Electroluminescence (EL) imaging, is expensive and logistically challenging which makes automated defect detection essential. Current automation approaches require extensive manual expert labeling, which is time-consuming, expensive, and prone to errors. We propose PV-S3 (Photovoltaic-Semi-supervised Semantic Segmentation), a Semi-Supervised Learning approach for semantic segmentation of defects in EL images that reduces reliance on extensive labeling. PV-S3 is an artificial intelligence (AI) model trained using a few labeled images along with numerous unlabeled images. We introduce a novel Semi Cross-Entropy loss function to deal with class imbalance. We evaluate PV-S3 on multiple datasets and demonstrate its effectiveness and adaptability. With merely 20% labeled samples, we achieve an absolute improvement of 9.7% in mean Intersection-over-Union (mIoU), 13.5% in Precision, 29.15% in Recall, and 20.42% in F1-Score over prior state-of-the-art supervised method (which uses 100% labeled samples) on University of Central Florida-Electroluminescence (UCF-EL) dataset (largest dataset available for semantic segmentation of EL images) showing improvement in performance while reducing the annotation costs by 80%. For more details, visit our GitHub repository: https://github.com/abj247/PV-S3.",
      "authors": [
        "Abhishek Jha",
        "Yogesh Rawat",
        "Shruti Vyas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-21T15:42:56+00:00",
          "link": "https://arxiv.org/abs/2404.13693v1",
          "size": "8729kb",
          "version": "v1"
        },
        {
          "date": "2024-07-17T16:33:03+00:00",
          "link": "https://arxiv.org/abs/2404.13693v2",
          "size": "8903kb",
          "version": "v2"
        },
        {
          "date": "2025-01-30T15:08:17+00:00",
          "link": "https://arxiv.org/abs/2404.13693v3",
          "size": "9382kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T10:18:07+00:00",
          "link": "https://arxiv.org/abs/2404.13693v4",
          "size": "2005kb",
          "version": "v4"
        }
      ],
      "title": "Advancing Automatic Photovoltaic Defect Detection using Semi-Supervised Semantic Segmentation of Electroluminescence Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.13693",
        "HTML": "https://arxiv.org/html/2404.13693v4",
        "PDF": "https://arxiv.org/pdf/2404.13693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using semi-supervised semantic segmentation for photovoltaic defect detection in electroluminescence images, which is not related to LLM training data processing."
      },
      "tasks": [
        "Defect Detection",
        "Segmentation",
        "Semantic Segmentation",
        "Semi-Supervised Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/abj247/pv-s3"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01389",
      "abstract": "How do vision-language (VL) transformer models ground verb phrases and do they integrate contextual and world knowledge in this process? We introduce the CV-Probes dataset, containing image-caption pairs involving verb phrases that require both social knowledge and visual context to interpret (e.g., \"beg\"), as well as pairs involving verb phrases that can be grounded based on information directly available in the image (e.g., \"sit\"). We show that VL models struggle to ground VPs that are strongly context-dependent. Further analysis using explainable AI techniques shows that such models may not pay sufficient attention to the verb token in the captions. Our results suggest a need for improved methodologies in VL model training and evaluation. The code and dataset will be available https://github.com/ivana-13/CV-Probes.",
      "authors": [
        "Ivana Be\\v{n}ov\\'a",
        "Michal Gregor",
        "Albert Gatt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T17:39:26+00:00",
          "link": "https://arxiv.org/abs/2409.01389v1",
          "size": "7144kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:48:47+00:00",
          "link": "https://arxiv.org/abs/2409.01389v2",
          "size": "1091kb",
          "version": "v2"
        }
      ],
      "title": "CV-Probes: Studying the interplay of lexical and world knowledge in visually grounded verb understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01389",
        "HTML": "https://arxiv.org/html/2409.01389v2",
        "PDF": "https://arxiv.org/pdf/2409.01389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although it introduces a dataset (CV-Probes) for verb phrase grounding, the focus is more on model evaluation rather than detailed LLM training data processing or dataset creation methodologies."
      },
      "tasks": [
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15684",
      "abstract": "Data-Independent Acquisition (DIA) was introduced to improve sensitivity to cover all peptides in a range rather than only sampling high-intensity peaks as in Data-Dependent Acquisition (DDA) mass spectrometry. However, it is not very clear how useful DIA data is for de novo peptide sequencing as the DIA data are marred with coeluted peptides, high noises, and varying data quality. We present a new deep learning method DIANovo, and address each of these difficulties, and improves the previous established system DeepNovo-DIA by from 34% to 108%, averaging 50%, for amino acid recall, and by from 32% to 83%, averaging 57%, for peptide recall, by equipping the model with a deeper understanding of coeluted DIA spectra. This paper also provides criteria about when DIA data could be used for de novo peptide sequencing and when not to by providing a comparison between DDA and DIA, in both de novo and database search mode. We find that while DIA excels with narrow isolation windows on older-generation instruments, it loses its advantage with wider windows. However, with Orbitrap Astral, DIA consistently outperforms DDA due to narrow window mode enabled. We also provide a theoretical explanation of this phenomenon, emphasizing the critical role of the signal-to-noise profile in the successful application of de novo sequencing.",
      "authors": [
        "Zheng Ma",
        "Zeping Mao",
        "Ruixue Zhang",
        "Jiazhen Chen",
        "Lei Xin",
        "Paul Shan",
        "Ali Ghodsi",
        "Ming Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-24T02:10:29+00:00",
          "link": "https://arxiv.org/abs/2411.15684v1",
          "size": "2934kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T00:46:26+00:00",
          "link": "https://arxiv.org/abs/2411.15684v2",
          "size": "3080kb",
          "version": "v2"
        },
        {
          "date": "2025-03-06T05:15:54+00:00",
          "link": "https://arxiv.org/abs/2411.15684v3",
          "size": "3080kb",
          "version": "v3"
        },
        {
          "date": "2025-06-13T00:56:44+00:00",
          "link": "https://arxiv.org/abs/2411.15684v4",
          "size": "3244kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T22:38:02+00:00",
          "link": "https://arxiv.org/abs/2411.15684v5",
          "size": "3040kb",
          "version": "v5"
        }
      ],
      "title": "Disentangling the Complex Multiplexed DIA Spectra in De Novo Peptide Sequencing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15684",
        "HTML": "https://arxiv.org/html/2411.15684v5",
        "PDF": "https://arxiv.org/pdf/2411.15684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving de novo peptide sequencing using a deep learning method for processing mass spectrometry data, and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "tasks": [
        "de novo peptide sequencing"
      ],
      "repo_urls": [
        "https://github.com/hearthewind/dianovo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03468",
      "abstract": "Partial audio deepfake localization pose unique challenges and remain underexplored compared to full-utterance spoofing detection. While recent methods report strong in-domain performance, their real-world utility remains unclear. In this analysis, we critically examine the limitations of current evaluation practices, particularly the widespread use of Equal Error Rate (EER), which often obscures generalization and deployment readiness. We propose reframing the localization task as a sequential anomaly detection problem and advocate for the use of threshold-dependent metrics such as accuracy, precision, recall, and F1-score, which better reflect real-world behavior. Specifically, we analyze the performance of the open-source Coarse-to-Fine Proposal Refinement Framework (CFPRF), which achieves a 20-ms EER of 7.61% on the in-domain PartialSpoof evaluation set, but 43.25% and 27.59% on the LlamaPartialSpoof and Half-Truth out-of-domain test sets. Interestingly, our reproduced version of the same model performs worse on in-domain data (9.84%) but better on the out-of-domain sets (41.72% and 14.98%, respectively). This highlights the risks of over-optimizing for in-domain EER, which can lead to models that perform poorly in real-world scenarios. It also suggests that while deep learning models can be effective on in-domain data, they generalize poorly to out-of-domain scenarios, failing to detect novel synthetic samples and misclassifying unfamiliar bona fide audio. Finally, we observe that adding more bona fide or fully synthetic utterances to the training data often degrades performance, whereas adding partially fake utterances improves it.",
      "authors": [
        "Hieu-Thi Luong",
        "Inbal Rimon",
        "Haim Permuter",
        "Kong Aik Lee",
        "Eng Siong Chng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T10:46:11+00:00",
          "link": "https://arxiv.org/abs/2507.03468v1",
          "size": "1081kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T03:58:43+00:00",
          "link": "https://arxiv.org/abs/2507.03468v2",
          "size": "1081kb",
          "version": "v2"
        }
      ],
      "title": "Robust Localization of Partially Fake Speech: Metrics, Models, and Out-of-Domain Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03468",
        "HTML": "https://arxiv.org/html/2507.03468v2",
        "PDF": "https://arxiv.org/pdf/2507.03468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the robustness and evaluation of speech deepfake detection models, analyzing performance metrics and challenges in detection tasks. It does not discuss any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08832",
      "abstract": "Farmers in developing regions like Karnataka, India, face a dual challenge: navigating extreme market and climate volatility while being excluded from the digital revolution due to literacy barriers. This paper presents a novel decision support system that addresses both challenges through a unique synthesis of machine learning and human-computer interaction. We propose a hybrid recommendation engine that integrates two predictive models: a Random Forest classifier to assess agronomic suitability based on soil, climate, and real-time weather data, and a Long Short-Term Memory (LSTM) network to forecast market prices for agronomically viable crops. This integrated approach shifts the paradigm from \"what can grow?\" to \"what is most profitable to grow?\", providing a significant advantage in mitigating economic risk. The system is delivered through an end-to-end, voice-based interface in the local Kannada language, leveraging fine-tuned speech recognition and high-fidelity speech synthesis models to ensure accessibility for low-literacy users. Our results show that the Random Forest model achieves 98.5% accuracy in suitability prediction, while the LSTM model forecasts harvest-time prices with a low margin of error. By providing data-driven, economically optimized recommendations through an inclusive interface, this work offers a scalable and impactful solution to enhance the financial resilience of marginalized farming communities.",
      "authors": [
        "Niranjan Mallikarjun Sindhur",
        "Pavithra C",
        "Nivya Muchikel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T06:18:41+00:00",
          "link": "https://arxiv.org/abs/2507.08832v1",
          "size": "280kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid Machine Learning Framework for Optimizing Crop Selection via Agronomic and Economic Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08832",
        "HTML": "https://arxiv.org/html/2507.08832v1",
        "PDF": "https://arxiv.org/pdf/2507.08832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on optimizing crop selection through machine learning, without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09318",
      "abstract": "Generating spoken dialogue is more challenging than monologue text-to-speech (TTS) due to the need for realistic turn-taking and distinct speaker timbres. Existing spoken dialogue generation models, being auto-regressive, suffer from slow and unstable inference. To overcome these limitations, we introduce ZipVoice-Dialog, a non-autoregressive zero-shot spoken dialogue generation model built upon flow matching. Key designs include: 1) speaker-turn embeddings for precise speaker turn-taking; 2) a curriculum learning strategy for stable speech-text alignment; 3) specialized strategies to enable stereo dialogue generation. Additionally, recognizing the lack of open-source large-scale spoken dialogue datasets, we curated OpenDialog, a 6.8k-hour spoken dialogue dataset from in-the-wild speech data. Furthermore, we established a benchmark to comprehensively evaluate various models. Experimental results demonstrate that ZipVoice-Dialog achieves superior performance in intelligibility, speaker turn-taking accuracy, speaker similarity, and inference speed. Our codes, model checkpoints, demo samples, and the OpenDialog dataset are all publicly available at https://github.com/k2-fsa/ZipVoice.",
      "authors": [
        "Han Zhu",
        "Wei Kang",
        "Liyong Guo",
        "Zengwei Yao",
        "Fangjun Kuang",
        "Weiji Zhuang",
        "Zhaoqing Li",
        "Zhifeng Han",
        "Dong Zhang",
        "Xin Zhang",
        "Xingchen Song",
        "Long Lin",
        "Daniel Povey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:18:47+00:00",
          "link": "https://arxiv.org/abs/2507.09318v1",
          "size": "747kb",
          "version": "v1"
        }
      ],
      "title": "ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09318",
        "HTML": "https://arxiv.org/html/2507.09318v1",
        "PDF": "https://arxiv.org/pdf/2507.09318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a new dataset, OpenDialog, for spoken dialogue generation, including its processing from in-the-wild speech data, which is directly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09523",
      "abstract": "The hallmark feature of temporal-difference (TD) learning is bootstrapping: using value predictions to generate new value predictions. The vast majority of TD methods for control learn a policy by bootstrapping from a single action-value function (e.g., Q-learning and Sarsa). Significantly less attention has been given to methods that bootstrap from two asymmetric value functions: i.e., methods that learn state values as an intermediate step in learning action values. Existing algorithms in this vein can be categorized as either QV-learning or AV-learning. Though these algorithms have been investigated to some degree in prior work, it remains unclear if and when it is advantageous to learn two value functions instead of just one -- and whether such approaches are theoretically sound in general. In this paper, we analyze these algorithmic families in terms of convergence and sample efficiency. We find that while both families are more efficient than Expected Sarsa in the prediction setting, only AV-learning methods offer any major benefit over Q-learning in the control setting. Finally, we introduce a new AV-learning algorithm called Regularized Dueling Q-learning (RDQ), which significantly outperforms Dueling DQN in the MinAtar benchmark.",
      "authors": [
        "Brett Daley",
        "Prabhat Nagarajan",
        "Martha White",
        "Marlos C. Machado"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T07:34:33+00:00",
          "link": "https://arxiv.org/abs/2507.09523v1",
          "size": "650kb",
          "version": "v1"
        }
      ],
      "title": "An Analysis of Action-Value Temporal-Difference Methods That Learn State Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09523",
        "HTML": "https://arxiv.org/html/2507.09523v1",
        "PDF": "https://arxiv.org/pdf/2507.09523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on temporal-difference learning methods for state-action value functions, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09601",
      "abstract": "General-purpose sentence embedding models often struggle to capture specialized financial semantics, especially in low-resource languages like Korean, due to domain-specific jargon, temporal meaning shifts, and misaligned bilingual vocabularies. To address these gaps, we introduce NMIXX (Neural eMbeddings for Cross-lingual eXploration of Finance), a suite of cross-lingual embedding models fine-tuned with 18.8K high-confidence triplets that pair in-domain paraphrases, hard negatives derived from a semantic-shift typology, and exact Korean-English translations. Concurrently, we release KorFinSTS, a 1,921-pair Korean financial STS benchmark spanning news, disclosures, research reports, and regulations, designed to expose nuances that general benchmarks miss.\n  When evaluated against seven open-license baselines, NMIXX's multilingual bge-m3 variant achieves Spearman's rho gains of +0.10 on English FinSTS and +0.22 on KorFinSTS, outperforming its pre-adaptation checkpoint and surpassing other models by the largest margin, while revealing a modest trade-off in general STS performance. Our analysis further shows that models with richer Korean token coverage adapt more effectively, underscoring the importance of tokenizer design in low-resource, cross-lingual settings. By making both models and the benchmark publicly available, we provide the community with robust tools for domain-adapted, multilingual representation learning in finance.",
      "authors": [
        "Hanwool Lee",
        "Sara Yu",
        "Yewon Hwang",
        "Jonghyun Choi",
        "Heejae Ahn",
        "Sungbum Jung",
        "Youngjae Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computational Finance (q-fin.CP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.09601v1",
          "size": "171kb",
          "version": "v1"
        }
      ],
      "title": "NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09601",
        "HTML": "https://arxiv.org/html/2507.09601v1",
        "PDF": "https://arxiv.org/pdf/2507.09601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on domain-adapted neural embeddings and cross-lingual embedding models in the financial domain. It does not primarily address LLM training data processing."
      },
      "models": [
        {
          "model_path": "nmixx-fin/nmixx-bge-m3",
          "downloads": "133",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nmixx-fin/nmixx-bge-m3"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09982",
      "abstract": "Hit-like molecular generation with therapeutic potential is essential for target-specific drug discovery. However, the field lacks heterogeneous data and unified frameworks for integrating diverse molecular representations. To bridge this gap, we introduce TextOmics, a pioneering benchmark that establishes one-to-one correspondences between omics expressions and molecular textual descriptions. TextOmics provides a heterogeneous dataset that facilitates molecular generation through representations alignment. Built upon this foundation, we propose ToDi, a generative framework that jointly conditions on omics expressions and molecular textual descriptions to produce biologically relevant, chemically valid, hit-like molecules. ToDi leverages two encoders (OmicsEn and TextEn) to capture multi-level biological and semantic associations, and develops conditional diffusion (DiffGen) for controllable generation. Extensive experiments confirm the effectiveness of TextOmics and demonstrate ToDi outperforms existing state-of-the-art approaches, while also showcasing remarkable potential in zero-shot therapeutic molecular generation. Sources are available at: https://github.com/hala-ToDi.",
      "authors": [
        "Hang Yuan",
        "Chen Li",
        "Wenjun Ma",
        "Yuncheng Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.09982v1",
          "size": "2183kb",
          "version": "v1"
        }
      ],
      "title": "TextOmics-Guided Diffusion for Hit-like Molecular Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09982",
        "HTML": "https://arxiv.org/html/2507.09982v1",
        "PDF": "https://arxiv.org/pdf/2507.09982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces TextOmics, providing a heterogeneous dataset aligning omics expressions with molecular descriptions, facilitating novel data processing methods for molecule generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2210.06419",
      "abstract": "The divide-and-conquer framework, used extensively in classical algorithm design, recursively breaks a problem of size $n$ into smaller subproblems (say, $a$ copies of size $n/b$ each), along with some auxiliary work of cost $C^{\\textrm{aux}}(n)$, to give a recurrence relation $$C(n) \\leq a \\, C(n/b) + C^{\\textrm{aux}}(n)$$ for the classical complexity $C(n)$. We describe a quantum divide-and-conquer framework that, in certain cases, yields an analogous recurrence relation $$C_Q(n) \\leq \\sqrt{a} \\, C_Q(n/b) + O(C^{\\textrm{aux}}_Q(n))$$ that characterizes the quantum query complexity. We apply this framework to obtain near-optimal quantum query complexities for various string problems, such as (i) recognizing regular languages; (ii) decision versions of String Rotation and String Suffix; and natural parameterized versions of (iii) Longest Increasing Subsequence and (iv) Longest Common Subsequence.",
      "authors": [
        "Andrew M. Childs",
        "Robin Kothari",
        "Matt Kovacs-Deak",
        "Aarthi Sundaram",
        "Daochen Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-12T17:14:28+00:00",
          "link": "https://arxiv.org/abs/2210.06419v1",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "title": "Quantum divide and conquer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.06419",
        "PDF": "https://arxiv.org/pdf/2210.06419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It discusses a quantum divide-and-conquer framework for solving algorithmic problems and does not involve any processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.17494",
      "abstract": "Ads recommendation is a prominent service of online advertising systems and has been actively studied. Recent studies indicate that scaling-up and advanced design of the recommendation model can bring significant performance improvement. However, with a larger model scale, such prior studies have a significantly increasing gap from industry as they often neglect two fundamental challenges in industrial-scale applications. First, training and inference budgets are restricted for the model to be served, exceeding which may incur latency and impair user experience. Second, large-volume data arrive in a streaming mode with data distributions dynamically shifting, as new users/ads join and existing users/ads leave the system. We propose the External Large Foundation Model (ExFM) framework to address the overlooked challenges. Specifically, we develop external distillation and a data augmentation system (DAS) to control the computational cost of training/inference while maintaining high performance. We design the teacher in a way like a foundation model (FM) that can serve multiple students as vertical models (VMs) to amortize its building cost. We propose Auxiliary Head and Student Adapter to mitigate the data distribution gap between FM and VMs caused by the streaming data issue. Comprehensive experiments on internal industrial-scale applications and public datasets demonstrate significant performance gain by ExFM.",
      "authors": [
        "Mingfu Liang",
        "Xi Liu",
        "Rong Jin",
        "Boyang Liu",
        "Qiuling Suo",
        "Qinghai Zhou",
        "Song Zhou",
        "Laming Chen",
        "Hua Zheng",
        "Zhiyuan Li",
        "Shali Jiang",
        "Jiyan Yang",
        "Xiaozhen Xia",
        "Fan Yang",
        "Yasmine Badr",
        "Ellie Wen",
        "Shuyu Xu",
        "Hansey Chen",
        "Zhengyu Zhang",
        "Jade Nie",
        "Chunzhi Yang",
        "Zhichen Zeng",
        "Weilin Zhang",
        "Xingliang Huang",
        "Qianru Li",
        "Shiquan Wang",
        "Evelyn Lyu",
        "Wenjing Lu",
        "Rui Zhang",
        "Wenjun Wang",
        "Jason Rudy",
        "Mengyue Hang",
        "Kai Wang",
        "Yinbin Ma",
        "Shuaiwen Wang",
        "Sihan Zeng",
        "Tongyi Tang",
        "Xiaohan Wei",
        "Longhao Jin",
        "Jamey Zhang",
        "Marcus Chen",
        "Jiayi Xu",
        "Angie Huang",
        "Xihuan Zeng",
        "Chi Zhang",
        "Zhengli Zhao",
        "Jared Yang",
        "Qiang Jin",
        "Xian Chen",
        "Amit Anand Amlesahwaram",
        "Lexi Song",
        "Liang Luo",
        "Yuchen Hao",
        "Nan Xiao",
        "Yavuz Yetim",
        "Luoshang Pan",
        "Gaoxiang Liu",
        "Yuxi Hu",
        "Yuzhen Huang",
        "Jackie Xu",
        "Rich Zhu",
        "Xin Zhang",
        "Yiqun Liu",
        "Hang Yin",
        "Yuxin Chen",
        "Buyun Zhang",
        "Xiaoyi Liu",
        "Xingyuan Wang",
        "Wenguang Mao",
        "Zhijing Li",
        "Zhehui Zhou",
        "Feifan Gu",
        "Qin Huang",
        "Chonglin Sun",
        "Nancy Yu",
        "Shuo Gu",
        "Shupin Mao",
        "Benjamin Au",
        "Jingzheng Qin",
        "Peggy Yao",
        "Jae-Woo Choi",
        "Bin Gao",
        "Ernest Wang",
        "Lei Zhang",
        "Wen-Yen Chen",
        "Ted Lee",
        "Yujie Zha",
        "Yi Meng",
        "Alex Gong",
        "Edison Gao",
        "Jack Hsueh",
        "Jie Zheng",
        "Alireza Vahdatpour",
        "Yiping Han",
        "Yantao Yao",
        "Toshinari Kureha",
        "Shuo Chang",
        "Musharaf Sultan",
        "John Bocharov",
        "Sagar Chordia",
        "Xiaorui Gan",
        "Peng Sun",
        "Rocky Liu",
        "Bo Long",
        "Wenlin Chen",
        "Santanu Kolay",
        "Huayu Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T22:35:52+00:00",
          "link": "https://arxiv.org/abs/2502.17494v1",
          "size": "1057kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T05:29:28+00:00",
          "link": "https://arxiv.org/abs/2502.17494v2",
          "size": "1057kb",
          "version": "v2"
        },
        {
          "date": "2025-02-27T23:32:37+00:00",
          "link": "https://arxiv.org/abs/2502.17494v3",
          "size": "1057kb",
          "version": "v3"
        },
        {
          "date": "2025-03-03T22:21:09+00:00",
          "link": "https://arxiv.org/abs/2502.17494v4",
          "size": "1057kb",
          "version": "v4"
        },
        {
          "date": "2025-04-14T07:39:56+00:00",
          "link": "https://arxiv.org/abs/2502.17494v5",
          "size": "1057kb",
          "version": "v5"
        },
        {
          "date": "2025-04-23T06:47:38+00:00",
          "link": "https://arxiv.org/abs/2502.17494v6",
          "size": "1057kb",
          "version": "v6"
        },
        {
          "date": "2025-07-14T03:01:53+00:00",
          "link": "https://arxiv.org/abs/2502.17494v7",
          "size": "1057kb",
          "version": "v7"
        }
      ],
      "title": "External Large Foundation Model: How to Efficiently Serve Trillions of Parameters for Online Ads Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17494",
        "HTML": "https://arxiv.org/html/2502.17494",
        "PDF": "https://arxiv.org/pdf/2502.17494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper provides some insights into data augmentation and model distillation, which could slightly influence data handling strategies, but the primary focus is on serving models in ads recommendation, not on LLM training data processing."
      },
      "tasks": [
        "Data Augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19537",
      "abstract": "Leading language model (LM) providers like OpenAI and Anthropic allow customers to fine-tune frontier LMs for specific use cases. To prevent abuse, these providers apply filters to block fine-tuning on overtly harmful data. In this setting, we make three contributions: First, while past work has shown that safety alignment is \"shallow\", we correspondingly demonstrate that existing fine-tuning attacks are shallow -- attacks target only the first several tokens of the model response, and consequently can be blocked by generating the first several response tokens with an aligned model. Second, we conceptually illustrate how to make attacks deeper by introducing a new fine-tuning attack that trains models to first refuse harmful requests before answering them; this \"refuse-then-comply\" strategy bypasses shallow defenses and produces harmful responses that evade output filters. Third, we demonstrate the potency of our new fine-tuning attack by jailbreaking both open-source models equipped with defenses and production models, achieving attack success rates of 57% and 72% against GPT-4o and Claude Haiku, respectively. Our attack received a $2000 bug bounty from OpenAI and was acknowledged as a vulnerability by Anthropic. Our work undermines the notion that models are safe because they initially refuse harmful requests and broadens awareness of the scope of attacks that face production fine-tuning APIs.",
      "authors": [
        "Joshua Kazdan",
        "Abhay Puri",
        "Rylan Schaeffer",
        "Lisa Yu",
        "Chris Cundy",
        "Jason Stanley",
        "Sanmi Koyejo",
        "Krishnamurthy Dvijotham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T20:20:01+00:00",
          "link": "https://arxiv.org/abs/2502.19537v1",
          "size": "2456kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T17:50:21+00:00",
          "link": "https://arxiv.org/abs/2502.19537v2",
          "size": "2456kb",
          "version": "v2"
        },
        {
          "date": "2025-04-01T18:57:07+00:00",
          "link": "https://arxiv.org/abs/2502.19537v3",
          "size": "2463kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T22:09:54+00:00",
          "link": "https://arxiv.org/abs/2502.19537v4",
          "size": "3149kb",
          "version": "v4"
        },
        {
          "date": "2025-07-12T21:20:09+00:00",
          "link": "https://arxiv.org/abs/2502.19537v5",
          "size": "3149kb",
          "version": "v5"
        }
      ],
      "title": "No, of Course I Can! Deeper Fine-Tuning Attacks That Bypass Token-Level Safety Mechanisms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19537",
        "HTML": "https://arxiv.org/html/2502.19537v5",
        "PDF": "https://arxiv.org/pdf/2502.19537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning attacks on language models and implies work on training-data filtering to prevent abuse, but its main focus is on model vulnerabilities rather than on advancing training data processing techniques."
      },
      "tasks": [
        "Data Poisoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23377",
      "abstract": "Large language models (LLMs) are used in a variety of mission-critical roles. Due to the rapidly developing nature of LLMs, there is a lack of quantifiable understanding of the bias and perspective associated with LLM output. Inspired by this need, this paper considers the broader issue of perspective or viewpoint of general text and perspective control of large-language model (LLM) output. Perspective-Dial consists of two main components: a (1) metric space, dubbed Perspective Space, that enables quantitative measurements of different perspectives regarding a topic, and the use of (2) Systematic Prompt Engineering that utilizes greedy-coordinate descent to control LLM output perspective based on measurement feedback from the Perspective Space. The empirical nature of the approach allows progress to side step a principled understanding of perspective or bias -- effectively quantifying and adjusting outputs for a variety of topics. Potential applications include detection, tracking and mitigation of LLM bias, narrative detection, sense making and tracking in public discourse, and debate bot advocating given perspective.",
      "authors": [
        "Taejin Kim and Siun-Chuon Mau and Konrad Vesey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:26:37+00:00",
          "link": "https://arxiv.org/abs/2506.23377v1",
          "size": "416kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T17:57:39+00:00",
          "link": "https://arxiv.org/abs/2506.23377v2",
          "size": "416kb",
          "version": "v2"
        }
      ],
      "title": "Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23377",
        "HTML": "https://arxiv.org/html/2506.23377v2",
        "PDF": "https://arxiv.org/pdf/2506.23377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses perspective control in LLM outputs and mentions systematic prompt engineering, but it does not primarily focus on the process of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08333",
      "abstract": "Audio inpainting refers to the task of reconstructing missing segments in corrupted audio recordings. While prior approaches-including waveform and spectrogram-based diffusion models-have shown promising results for short gaps, they often degrade in quality when gaps exceed 100 milliseconds (ms). In this work, we introduce a novel inpainting method based on discrete diffusion modeling, which operates over tokenized audio representations produced by a pre-trained audio tokenizer. Our approach models the generative process directly in the discrete latent space, enabling stable and semantically coherent reconstruction of missing audio. We evaluate the method on the MusicNet dataset using both objective and perceptual metrics across gap durations up to 300 ms. We further evaluated our approach on the MTG dataset, extending the gap duration to 500 ms. Experimental results demonstrate that our method achieves competitive or superior performance compared to existing baselines, particularly for longer gaps, offering a robust solution for restoring degraded musical recordings. Audio examples of our proposed method can be found at https://iftach21.github.io/",
      "authors": [
        "Tali Dror",
        "Iftach Shoham",
        "Moshe Buchris",
        "Oren Gal",
        "Haim Permuter",
        "Gilad Katz",
        "Eliya Nachmani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:25:49+00:00",
          "link": "https://arxiv.org/abs/2507.08333v1",
          "size": "1036kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:38:36+00:00",
          "link": "https://arxiv.org/abs/2507.08333v2",
          "size": "1036kb",
          "version": "v2"
        }
      ],
      "title": "Token-based Audio Inpainting via Discrete Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08333",
        "HTML": "https://arxiv.org/html/2507.08333v2",
        "PDF": "https://arxiv.org/pdf/2507.08333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audio inpainting using a discrete diffusion model on tokenized audio, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09857",
      "abstract": "Adversarial attacks on robotic grasping provide valuable insights into evaluating and improving the robustness of these systems. Unlike studies that focus solely on neural network predictions while overlooking the physical principles of grasping, this paper introduces AdvGrasp, a framework for adversarial attacks on robotic grasping from a physical perspective. Specifically, AdvGrasp targets two core aspects: lift capability, which evaluates the ability to lift objects against gravity, and grasp stability, which assesses resistance to external disturbances. By deforming the object's shape to increase gravitational torque and reduce stability margin in the wrench space, our method systematically degrades these two key grasping metrics, generating adversarial objects that compromise grasp performance. Extensive experiments across diverse scenarios validate the effectiveness of AdvGrasp, while real-world validations demonstrate its robustness and practical applicability",
      "authors": [
        "Xiaofei Wang",
        "Mingliang Han",
        "Tianyu Hao",
        "Cegang Li",
        "Yunbo Zhao and Keke Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:48:42+00:00",
          "link": "https://arxiv.org/abs/2507.09857v1",
          "size": "9844kb",
          "version": "v1"
        }
      ],
      "title": "AdvGrasp: Adversarial Attacks on Robotic Grasping from a Physical Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09857",
        "HTML": "https://arxiv.org/html/2507.09857v1",
        "PDF": "https://arxiv.org/pdf/2507.09857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on adversarial attacks in robotic grasping, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.08147",
      "abstract": "We study mathematical models of binary direct collinear collisions of convex viscoplastic bodies based on two incremental collision laws that employ the Bouc-Wen differential model of hysteresis to represent the elastoplastic behavior of the materials of the colliding bodies. These collision laws are the Bouc-Wen-Simon-Hunt-Crossley Collision Law (BWSHCCL) and the Bouc-Wen-Maxwell Collision Law (BWMCL). The BWSHCCL comprises of the Bouc-Wen model amended with a nonlinear Hertzian elastic spring element and connected in parallel to a nonlinear displacement-dependent and velocity-dependent energy dissipation element. The BWMCL comprises of the Bouc-Wen model amended with a nonlinear Hertzian elastic spring element and connected in series to a linear velocity-dependent energy dissipation element. The mathematical models of the collision process are presented in the form of finite-dimensional initial value problems. We show that the models possess favorable analytical properties (e.g., global existence, uniqueness, and boundedness of the solutions) under suitable restrictions on the values of their parameters. Furthermore, based on the results of two model parameter identification studies, we demonstrate that good agreement can be attained between experimental data and numerical approximations of the behavior of the mathematical models across a wide range of initial relative velocities of the colliding bodies while using parameterizations of the models that are independent of the initial relative velocity.",
      "authors": [
        "Mihails Milehins and Dan B. Marghitu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Classical Physics (physics.class-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T17:31:36+00:00",
          "link": "https://arxiv.org/abs/2410.08147v1",
          "size": "163kb",
          "version": "v1"
        },
        {
          "date": "2024-10-14T05:19:37+00:00",
          "link": "https://arxiv.org/abs/2410.08147v2",
          "size": "163kb",
          "version": "v2"
        },
        {
          "date": "2024-10-28T04:41:50+00:00",
          "link": "https://arxiv.org/abs/2410.08147v3",
          "size": "135kb",
          "version": "v3"
        },
        {
          "date": "2024-11-06T09:12:56+00:00",
          "link": "https://arxiv.org/abs/2410.08147v4",
          "size": "136kb",
          "version": "v4"
        },
        {
          "date": "2024-11-11T02:57:09+00:00",
          "link": "https://arxiv.org/abs/2410.08147v5",
          "size": "137kb",
          "version": "v5"
        },
        {
          "date": "2025-01-13T05:29:14+00:00",
          "link": "https://arxiv.org/abs/2410.08147v6",
          "size": "139kb",
          "version": "v6"
        },
        {
          "date": "2025-01-20T05:17:05+00:00",
          "link": "https://arxiv.org/abs/2410.08147v7",
          "size": "139kb",
          "version": "v7"
        },
        {
          "date": "2025-03-03T07:52:06+00:00",
          "link": "https://arxiv.org/abs/2410.08147v8",
          "size": "139kb",
          "version": "v8"
        }
      ],
      "title": "The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08147",
        "PDF": "https://arxiv.org/pdf/2410.08147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on mathematical models for collisions of viscoplastic bodies, with no mention of LLM training data processing."
      },
      "repo_urls": [
        "https://gitlab.com/user9716869/bwbcl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04653",
      "abstract": "Developing advanced medical imaging retrieval systems is challenging due to the varying definitions of `similar images' across different medical contexts. This challenge is compounded by the lack of large-scale, high-quality medical imaging retrieval datasets and benchmarks. In this paper, we propose a novel methodology that leverages dense radiology reports to define image-wise similarity ordering at multiple granularities in a scalable and fully automatic manner. Using this approach, we construct two comprehensive medical imaging retrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans, providing detailed image-image ranking annotations conditioned on diverse anatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR and model-ChestCT, which demonstrate superior performance in traditional image-image and image-report retrieval tasks. These systems also enable flexible, effective image retrieval conditioned on specific anatomical structures described in text, achieving state-of-the-art results on 77 out of 78 metrics.",
      "authors": [
        "Tengfei Zhang",
        "Ziheng Zhao",
        "Chaoyi Wu",
        "Xiao Zhou",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T17:43:03+00:00",
          "link": "https://arxiv.org/abs/2503.04653v1",
          "size": "2587kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T04:07:11+00:00",
          "link": "https://arxiv.org/abs/2503.04653v2",
          "size": "2399kb",
          "version": "v2"
        }
      ],
      "title": "RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval via Radiology Report Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04653",
        "HTML": "https://arxiv.org/html/2503.04653v2",
        "PDF": "https://arxiv.org/pdf/2503.04653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes to creating new datasets by leveraging radiology reports to define similarity in medical images, involving detailed data processing steps for dataset construction."
      },
      "datasets": [
        {
          "dataset_name": "zzh99/RadIR",
          "downloads": "106",
          "likes": "0",
          "link": "https://huggingface.co/datasets/zzh99/RadIR"
        }
      ],
      "tasks": [
        "Image Retrieval",
        "Medical Image Retrieval",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10992",
      "abstract": "Process automation is a crucial strategy for improving business processes, but little attention has been paid to the effects that automation has once it is operational. This paper addresses this research problem by reviewing the literature on human-automation interaction. Although many of the studies in this field have been conducted in different domains, they provide a foundation for developing propositions about process automation effects. Our analysis focuses on how humans perceive automation technology when working within a process, allowing us to propose an effective engagement model between technology, process participants, process managers, and software developers. This paper offers insights and recommendations that can help organizations optimize their use of process automation. We further derive novel research questions for a discourse within the process automation community.",
      "authors": [
        "Hoang Vu",
        "Jennifer Haase",
        "Henrik Leopold",
        "and Jan Mendling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T12:09:07+00:00",
          "link": "https://arxiv.org/abs/2506.10992v1",
          "size": "411kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:07:58+00:00",
          "link": "https://arxiv.org/abs/2506.10992v2",
          "size": "108kb",
          "version": "v2"
        }
      ],
      "title": "Towards a Theory on Process Automation Effects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10992",
        "HTML": "https://arxiv.org/html/2506.10992v2",
        "PDF": "https://arxiv.org/pdf/2506.10992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses process automation effects and human-automation interaction, which do not pertain to LLM training data processing or data-engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09887",
      "abstract": "The electrocardiogram (ECG) is an essential and effective tool for diagnosing heart diseases. However, its effectiveness can be compromised by noise or unavailability of one or more leads of the standard 12-lead recordings, resulting in diagnostic errors or uncertainty. To address these challenges, we propose TolerantECG, a foundation model for ECG signals that is robust to noise and capable of functioning with arbitrary subsets of the standard 12-lead ECG. TolerantECG training combines contrastive and self-supervised learning frameworks to jointly learn ECG signal representations alongside their corresponding knowledge-retrieval-based text report descriptions and corrupted or lead-missing signals. Comprehensive benchmarking results demonstrate that TolerantECG consistently ranks as the best or second-best performer across various ECG signal conditions and class levels in the PTB-XL dataset, and achieves the highest performance on the MIT-BIH Arrhythmia Database.",
      "authors": [
        "Huynh Nguyen Dang",
        "Thang Pham",
        "Ngan Le",
        "Van Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:48:35+00:00",
          "link": "https://arxiv.org/abs/2507.09887v1",
          "size": "1049kb",
          "version": "v1"
        }
      ],
      "title": "TolerantECG: A Foundation Model for Imperfect Electrocardiogram",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09887",
        "HTML": "https://arxiv.org/html/2507.09887v1",
        "PDF": "https://arxiv.org/pdf/2507.09887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for ECG signal processing robust to imperfections, focusing on representation learning, without discussing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09945",
      "abstract": "Dense audio-visual event localization (DAVE) aims to identify event categories and locate the temporal boundaries in untrimmed videos. Most studies only employ event-related semantic constraints on the final outputs, lacking cross-modal semantic bridging in intermediate layers. This causes modality semantic gap for further fusion, making it difficult to distinguish between event-related content and irrelevant background content. Moreover, they rarely consider the correlations between events, which limits the model to infer concurrent events among complex scenarios. In this paper, we incorporate multi-stage semantic guidance and multi-event relationship modeling, which respectively enable hierarchical semantic understanding of audio-visual events and adaptive extraction of event dependencies, thereby better focusing on event-related information. Specifically, our eventaware semantic guided network (ESG-Net) includes a early semantics interaction (ESI) module and a mixture of dependency experts (MoDE) module. ESI applys multi-stage semantic guidance to explicitly constrain the model in learning semantic information through multi-modal early fusion and several classification loss functions, ensuring hierarchical understanding of event-related content. MoDE promotes the extraction of multi-event dependencies through multiple serial mixture of experts with adaptive weight allocation. Extensive experiments demonstrate that our method significantly surpasses the state-of-the-art methods, while greatly reducing parameters and computational load. Our code will be released on https://github.com/uchiha99999/ESG-Net.",
      "authors": [
        "Huilai Li",
        "Yonghao Dang",
        "Ying Xing",
        "Yiming Wang",
        "Jianqin Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:42:00+00:00",
          "link": "https://arxiv.org/abs/2507.09945v1",
          "size": "14510kb",
          "version": "v1"
        }
      ],
      "title": "ESG-Net: Event-Aware Semantic Guided Network for Dense Audio-Visual Event Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09945",
        "HTML": "https://arxiv.org/html/2507.09945v1",
        "PDF": "https://arxiv.org/pdf/2507.09945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses semantic guidance in audio-visual event localization, focusing on network architecture and fusion techniques rather than on any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10135",
      "abstract": "Carousels have become the de-facto interface in online services. However, there is a lack of research in carousels, particularly examining how recommender systems may be designed differently than the traditional single-list interfaces. One of the key elements for understanding how to design a system for a particular interface is understanding how users browse. For carousels, users may browse in a number of different ways due to the added complexity of multiple topic defined-lists and swiping to see more items.\n  Eye tracking is the key to understanding user behavior by providing valuable, direct information on how users see and navigate. In this work, we provide the first extensive analysis of the eye tracking behavior in carousel recommenders under the free-browsing setting. To understand how users browse, we examine the following research questions : 1) where do users start browsing, 2) how do users transition from item to item within the same carousel and across carousels, and 3) how does genre preference impact transitions?\n  This work addresses a gap in the field and provides the first extensive empirical results of eye tracked browsing behavior in carousels for improving recommenders. Taking into account the insights learned from the above questions, our final contribution is to provide suggestions to help carousel recommender system designers optimize their systems for user browsing behavior. The most important suggestion being to reorder the ranked item positions to account for browsing after swiping.These contributions aim not only to help improve current systems, but also to encourage and allow the design of new user models, systems, and metrics that are better suited to the complexity of carousel interfaces.",
      "authors": [
        "Santiago de Leon-Martinez",
        "Robert Moro",
        "Branislav Kveton",
        "Maria Bielikova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:26:27+00:00",
          "link": "https://arxiv.org/abs/2507.10135v1",
          "size": "12104kb",
          "version": "v1"
        }
      ],
      "title": "Riding the Carousel: The First Extensive Eye Tracking Analysis of Browsing Behavior in Carousel Recommenders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10135",
        "HTML": "https://arxiv.org/html/2507.10135v1",
        "PDF": "https://arxiv.org/pdf/2507.10135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies eye-tracking in carousel recommenders to understand browsing behavior, without mentioning any processing or creation of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.05236",
      "abstract": "Recently, a surge of 3D style transfer methods has been proposed that leverage the scene reconstruction power of a pre-trained neural radiance field (NeRF). To successfully stylize a scene this way, one must first reconstruct a photo-realistic radiance field from collected images of the scene. However, when only sparse input views are available, pre-trained few-shot NeRFs often suffer from high-frequency artifacts, which are generated as a by-product of high-frequency details for improving reconstruction quality. Is it possible to generate more faithful stylized scenes from sparse inputs by directly optimizing encoding-based scene representation with target style? In this paper, we consider the stylization of sparse-view scenes in terms of disentangling content semantics and style textures. We propose a coarse-to-fine sparse-view scene stylization framework, where a novel hierarchical encoding-based neural representation is designed to generate high-quality stylized scenes directly from implicit scene representations. We also propose a new optimization strategy with content strength annealing to achieve realistic stylization and better content preservation. Extensive experiments demonstrate that our method can achieve high-quality stylization of sparse-view scenes and outperforms fine-tuning-based baselines in terms of stylization quality and efficiency.",
      "authors": [
        "Y. Wang",
        "A. Gao",
        "Y. Gong and Y. Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-08T07:01:42+00:00",
          "link": "https://arxiv.org/abs/2404.05236v1",
          "size": "20511kb",
          "version": "v1"
        }
      ],
      "title": "Stylizing Sparse-View 3D Scenes with Hierarchical Neural Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.05236",
        "HTML": "https://arxiv.org/html/2404.05236",
        "PDF": "https://arxiv.org/pdf/2404.05236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses methods for 3D scene stylization and neural representations without addressing LLM training data processing."
      },
      "tasks": [
        "NeRF",
        "Style Transfer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16430",
      "abstract": "There are various methods for modeling phase transformations in materials science, including general classes of phase-field methods and reactive diffusion methodologies, which most importantly differ in their treatment of interface energy. These methodologies appear mutually exclusive since the respective numerical schemes only allow for their primary use case. To address this issue, a novel methodology for modeling phase transformations in multi-phase, multi-component systems, with particular emphasis on applications in materials science and the study of substitutional alloys is introduced. The fundamental role of interface energy in the evolution of a material's morphology will be studied by example of binary and ternary systems. Allowing full control over the interface energy quantity enables more detailed investigations and bridges the gaps between known methods. We prove the thermodynamic consistency of the derived method and discuss several use cases, such as vacancy-mediated diffusion. Furthermore a scheme for relating Onsager and Diffusion coefficients is proposed, which allows us to study the intricate coupling that is observed in multicomponent systems. We hope to contribute to the development of new mathematical tools for modeling complex phase transformations in materials science.",
      "authors": [
        "Wolfgang Flachberger",
        "Thomas Antretter",
        "Swaroop Gaddikere-Nagaraja",
        "Silvia Leitner",
        "Manuel Petersmann",
        "Jiri Svoboda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Numerical Analysis (cs.NA)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T14:33:21+00:00",
          "link": "https://arxiv.org/abs/2411.16430v1",
          "size": "372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:09:00+00:00",
          "link": "https://arxiv.org/abs/2411.16430v2",
          "size": "496kb",
          "version": "v2"
        }
      ],
      "title": "Interface Energy and Phase Transformations: A Comparative Analysis of Cahn-Hilliard and CALPHAD-based Models in Ternary Substitutional Alloys",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16430",
        "HTML": "https://arxiv.org/html/2411.16430v2",
        "PDF": "https://arxiv.org/pdf/2411.16430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling phase transformations in materials science and does not address LLM training data collection, processing, or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03668",
      "abstract": "Large Foundation Models (LFMs), including multi-modal and generative models, promise to unlock new capabilities for next-generation Edge AI applications. However, performing inference with LFMs in resource-constrained and heterogeneous edge environments, such as Multi-access Edge Computing (MEC), presents significant challenges for workload orchestration due to time-varying network, compute, and storage conditions. In particular, current split inference strategies, which partition LFM layers across nodes, are not designed to adapt to fluctuating workloads, dynamic bandwidth conditions, or evolving privacy constraints in high-utilization MEC environments. In this work, we propose a novel adaptive split inference orchestration framework that elevates both the placement and partitioning of LFM layers to runtime-tunable variables. Specifically, our framework enables real-time, quality-of-service (QoS)-aware management of inference workloads by extending conventional orchestrators with three key services: (1) Capacity-aware workload distribution, which continuously profiles node resources and selects an optimal subset of MEC nodes; (2) Dynamic partition migration, which transparently relocates pre-cut LFM segments in response to changes in utilization or network conditions; (3) Real-time reconfiguration, which dynamically re-splits LFM layers to balance latency, throughput, and privacy. We formalize the joint placement-partitioning problem, outline a reference architecture and algorithmic workflow, and discuss applicability in representative smart city, V2X, and industrial edge scenarios.",
      "authors": [
        "Fernando Koch and Aladin Djuhera and Alecio Binotto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T15:35:56+00:00",
          "link": "https://arxiv.org/abs/2504.03668v1",
          "size": "639kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:26:30+00:00",
          "link": "https://arxiv.org/abs/2504.03668v2",
          "size": "673kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T22:37:25+00:00",
          "link": "https://arxiv.org/abs/2504.03668v3",
          "size": "674kb",
          "version": "v3"
        }
      ],
      "title": "Intelligent Orchestration of Distributed Large Foundation Model Inference at the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03668",
        "HTML": "https://arxiv.org/html/2504.03668v3",
        "PDF": "https://arxiv.org/pdf/2504.03668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses orchestration of inference at the edge for large models and does not focus on the processing of LLM training data."
      },
      "tasks": [
        "Edge-computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18392",
      "abstract": "The Peterson hit problem in algebraic topology is to explicitly determine the dimension of the quotient space $Q\\mathcal P_k = \\mathbb F_2\\otimes_{\\mathcal A}\\mathcal P_k$ in positive degrees, where $\\mathcal{P}_k$ denotes the polynomial algebra in $k$ variables over the field $\\mathbb{F}_2$, considered as an unstable module over the Steenrod algebra $\\mathcal{A}$. Current approaches to this problem still rely heavily on manual computations, which are highly prone to errors due to the intricate nature of the underlying calculations. To date, no efficient algorithm implemented in any computer algebra system has been made publicly available to tackle this problem in a systematic manner.\n  Motivated by the above, in this work, which is considered as Part I of our project, we first establish a criterion based entirely on linear algebra for determining whether a given homogeneous polynomial is \"hit\". Accordingly, we describe the dimensions of the hit spaces. This leads to a practical and reliable computational method for determining the dimension of $Q\\mathcal{P}_k$ for arbitrary $k$ and any positive degrees, with the support of a computer algebra system. We then give a concrete implementation of the obtained results as novel algorithms in \\textsc{SageMath}. As an application, our algorithm demonstrates that the manually computed result presented in the recent work of Sum and Tai [15] for the dimension of $Q\\mathcal{P}_5$ in degree $2^{6}$ is not correct. Furthermore, our algorithm determines that $\\dim(Q\\mathcal{P}_5)_{2^{7}} = 1985,$ which falls within the range $1984 \\leq \\dim(Q\\mathcal{P}_5)_{2^{7}} \\leq 1990$ as estimated in [15].",
      "authors": [
        "Dang Vo Phuc"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Algebraic Topology (math.AT)",
        "Symbolic Computation (cs.SC)",
        "Geometric Topology (math.GT)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T08:27:44+00:00",
          "link": "https://arxiv.org/abs/2506.18392v1",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T12:27:38+00:00",
          "link": "https://arxiv.org/abs/2506.18392v2",
          "size": "59kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T08:45:47+00:00",
          "link": "https://arxiv.org/abs/2506.18392v3",
          "size": "94kb",
          "version": "v3"
        }
      ],
      "title": "A matrix criterion and algorithmic approach for the Peterson hit problem: Part I",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18392",
        "HTML": "https://arxiv.org/html/2506.18392v3",
        "PDF": "https://arxiv.org/pdf/2506.18392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an algorithmic approach to the Peterson hit problem in algebraic topology, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08869",
      "abstract": "Construction zones are inherently hazardous, posing significant risks to construction workers and motorists. Despite existing safety measures, construction zones continue to witness fatalities and serious injuries, imposing economic burdens. Addressing these issues requires understanding root causes and implementing preventive strategies centered around the 4Es (Engineering, Education, Enforcement, Emergency Response) and 4Is (Information Intelligence, Innovation, Insight into communities, Investment, and Policies). Proper safety management, integrating these strategic initiatives, aims to reduce and potentially eliminate fatalities and serious injuries in work zones. In Florida, road construction work zone fatalities and serious injuries remain a critical concern, especially in urban counties. Despite a 12 billion dollars infrastructure investment in 2022, Florida ranks eighth nationally for fatal work zone crashes involving commercial motor vehicles (CMVs). Analysis from 2019 to 2023 shows an average of 71 fatalities and 309 serious injuries annually in Florida work zones, reflecting a persistent safety challenge. High-risk counties include Orange, Broward, Duval, Hillsborough, Pasco, Miami-Dade, Seminole, Manatee, Palm Beach, and Lake. This study presents a preliminary analysis of work zone crashes in Broward, Duval, Hillsborough, and Orange counties. A multilogit model assessed attributes contributing to fatalities and serious injuries, such as crash type, weather and light conditions, work zone type, type of shoulder, presence of workers, and law enforcement. Results indicate significant contributing factors, highlighting opportunities to use machine learning for alerting drivers and construction managers, ultimately enhancing safety protocols and reducing fatalities.",
      "authors": [
        "Tatiana Deslouches",
        "Doreen Kobelo Regalado",
        "Mohamed Khalafalla",
        "Tejal Mulay"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:52:28+00:00",
          "link": "https://arxiv.org/abs/2507.08869v1",
          "size": "357kb",
          "version": "v1"
        }
      ],
      "title": "Preliminary Analysis of Construction Work Zone on Roadways in Florida by Crash Severity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08869",
        "PDF": "https://arxiv.org/pdf/2507.08869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is on crash analysis and safety in construction zones using variables like crash type and weather, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09755",
      "abstract": "Optimal power management of battery energy storage systems (BESS) is crucial for their safe and efficient operation. Numerical optimization techniques are frequently utilized to solve the optimal power management problems. However, these techniques often fall short of delivering real-time solutions for large-scale BESS due to their computational complexity. To address this issue, this paper proposes a computationally efficient approach. We introduce a new set of decision variables called power-sharing ratios corresponding to each cell, indicating their allocated power share from the output power demand. We then formulate an optimal power management problem to minimize the system-wide power losses while ensuring compliance with safety, balancing, and power supply-demand match constraints. To efficiently solve this problem, a parameterized control policy is designed and leveraged to transform the optimal power management problem into a parameter estimation problem. We then implement the ensemble Kalman inversion to estimate the optimal parameter set. The proposed approach significantly reduces computational requirements due to 1) the much lower dimensionality of the decision parameters and 2) the estimation treatment of the optimal power management problem. Finally, we conduct extensive simulations to validate the effectiveness of the proposed approach. The results show promise in accuracy and computation time compared with explored numerical optimization techniques.",
      "authors": [
        "Amir Farakhor",
        "Iman Askari",
        "Di Wu",
        "Huazhen Fang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:30:33+00:00",
          "link": "https://arxiv.org/abs/2507.09755v1",
          "size": "2374kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Power Management of Battery Energy Storage Systems via Ensemble Kalman Inversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09755",
        "HTML": "https://arxiv.org/html/2507.09755v1",
        "PDF": "https://arxiv.org/pdf/2507.09755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses optimal power management for battery energy storage systems using ensemble Kalman inversion, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09881",
      "abstract": "Recent work on counterfactual visual explanations has contributed to making artificial intelligence models more explainable by providing visual perturbation to flip the prediction. However, these approaches neglect the causal relationships and the spurious correlations behind the image generation process, which often leads to unintended alterations in the counterfactual images and renders the explanations with limited quality. To address this challenge, we introduce a novel framework CECAS, which first leverages a causally-guided adversarial method to generate counterfactual explanations. It innovatively integrates a causal perspective to avoid unwanted perturbations on spurious factors in the counterfactuals. Extensive experiments demonstrate that our method outperforms existing state-of-the-art approaches across multiple benchmark datasets and ultimately achieves a balanced trade-off among various aspects of validity, sparsity, proximity, and realism.",
      "authors": [
        "Yiran Qiao",
        "Disheng Liu",
        "Yiren Lu",
        "Yu Yin",
        "Mengnan Du",
        "Jing Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:36:36+00:00",
          "link": "https://arxiv.org/abs/2507.09881v1",
          "size": "705kb",
          "version": "v1"
        }
      ],
      "title": "Counterfactual Visual Explanation via Causally-Guided Adversarial Steering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09881",
        "HTML": "https://arxiv.org/html/2507.09881v1",
        "PDF": "https://arxiv.org/pdf/2507.09881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on counterfactual explanations in visual data processing rather than on processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10179",
      "abstract": "We identify a second machine turn in the process of mathematical discovery: after automating proof-checking, AI is now poised to automate the *creation* of mathematical concepts themselves. We discuss the current state of the art, obstacles and potential solutions as well as a preliminary attempt at mathematizing the creation of concepts itself. The paper ends with an assessment of how these capabilities could reshape mathematics and human-machine collaboration, and a few different futures we might find ourselves in.",
      "authors": [
        "Asvin G"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "History and Overview (math.HO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:42:01+00:00",
          "link": "https://arxiv.org/abs/2507.10179v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "The Second Machine Turn: From Checking Proofs to Creating Concepts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10179",
        "HTML": "https://arxiv.org/html/2507.10179v1",
        "PDF": "https://arxiv.org/pdf/2507.10179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automating the creation of mathematical concepts and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10400",
      "abstract": "Reaction mechanism search tools have demonstrated the ability to provide insights into likely products and rate-limiting steps of reacting systems. However, reactions involving several concerted bond changes - as can be found in many key steps of natural product synthesis - can complicate the search process. To mitigate these complications, we present a mechanism search strategy particularly suited to help expedite exploration of an exemplary family of such complex reactions, cyclizations. We provide a cost-effective strategy for identifying relevant elementary reaction steps by combining graph-based enumeration schemes and machine learning techniques for intermediate filtering. Key to this approach is our use of a neural network potential (NNP), AIMNet2-rxn, for computational evaluation of each candidate reaction pathway. In this article, we evaluate the NNP's ability to estimate activation energies, demonstrate the correct anticipation of stereoselectivity, and recapitulate complex enabling steps in natural product synthesis.",
      "authors": [
        "Nicholas Casetti",
        "Dylan Anstine",
        "Olexandr Isayev",
        "Connor W. Coley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:43:59+00:00",
          "link": "https://arxiv.org/abs/2507.10400v1",
          "size": "6446kb",
          "version": "v1"
        }
      ],
      "title": "Anticipating the Selectivity of Cyclization Reaction Pathways with Neural Network Potentials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10400",
        "HTML": "https://arxiv.org/html/2507.10400v1",
        "PDF": "https://arxiv.org/pdf/2507.10400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a mechanism search strategy for cyclization reactions using neural network potentials and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10510",
      "abstract": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC), where one peer is not a human, but a Multimodal Large Language Model (MLLM). This makes interaction between humans and AI more intuitive, as if chatting face-to-face with a real person. However, this poses significant challenges to latency, because the MLLM inference takes up most of the response time, leaving very little time for video streaming. Due to network uncertainty and instability, transmission latency becomes a critical bottleneck preventing AI from being like a real person. To address this, we propose Artic, an AI-oriented Real-time Communication framework, exploring the network requirement shift from \"humans watching video\" to \"AI understanding video\". To reduce bitrate dramatically while maintaining MLLM accuracy, we propose Context-Aware Video Streaming that recognizes the importance of each video region for chat and allocates bitrate almost exclusively to chat-important regions. To avoid packet retransmission, we propose Loss-Resilient Adaptive Frame Rate that leverages previous frames to substitute for lost/delayed frames while avoiding bitrate waste. To evaluate the impact of video streaming quality on MLLM accuracy, we build the first benchmark, named Degraded Video Understanding Benchmark (DeViBench). Finally, we discuss some open questions and ongoing solutions for AI Video Chat.",
      "authors": [
        "Jiangkai Wu",
        "Zhiyuan Ren",
        "Liming Liu",
        "Xinggong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:34:49+00:00",
          "link": "https://arxiv.org/abs/2507.10510v1",
          "size": "5360kb",
          "version": "v1"
        }
      ],
      "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10510",
        "HTML": "https://arxiv.org/html/2507.10510v1",
        "PDF": "https://arxiv.org/pdf/2507.10510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about video streaming in AI communication and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07776",
      "abstract": "Unrestricted adversarial attacks aim to fool computer vision models without being constrained by $\\ell_p$-norm bounds to remain imperceptible to humans, for example, by changing an object's color. This allows attackers to circumvent traditional, norm-bounded defense strategies such as adversarial training or certified defense strategies. However, due to their unrestricted nature, there are also no guarantees of norm-based imperceptibility, necessitating human evaluations to verify just how authentic these adversarial examples look. While some related work assesses this vital quality of adversarial attacks, none provide statistically significant insights. This issue necessitates a unified framework that supports and streamlines such an assessment for evaluating and comparing unrestricted attacks. To close this gap, we introduce SCOOTER - an open-source, statistically powered framework for evaluating unrestricted adversarial examples. Our contributions are: $(i)$ best-practice guidelines for crowd-study power, compensation, and Likert equivalence bounds to measure imperceptibility; $(ii)$ the first large-scale human vs. model comparison across 346 human participants showing that three color-space attacks and three diffusion-based attacks fail to produce imperceptible images. Furthermore, we found that GPT-4o can serve as a preliminary test for imperceptibility, but it only consistently detects adversarial examples for four out of six tested attacks; $(iii)$ open-source software tools, including a browser-based task template to collect annotations and analysis scripts in Python and R; $(iv)$ an ImageNet-derived benchmark dataset containing 3K real images, 7K adversarial examples, and over 34K human ratings. Our findings demonstrate that automated vision systems do not align with human perception, reinforcing the need for a ground-truth SCOOTER benchmark.",
      "authors": [
        "Dren Fazlija",
        "Monty-Maximilian Z\\\"uhlke",
        "Johanna Schrader",
        "Arkadij Orlov",
        "Clara Stein",
        "Iyiola E. Olatunji",
        "Daniel Kudenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:56:32+00:00",
          "link": "https://arxiv.org/abs/2507.07776v1",
          "size": "9676kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:01:42+00:00",
          "link": "https://arxiv.org/abs/2507.07776v2",
          "size": "9675kb",
          "version": "v2"
        }
      ],
      "title": "SCOOTER: A Human Evaluation Framework for Unrestricted Adversarial Examples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07776",
        "HTML": "https://arxiv.org/html/2507.07776v2",
        "PDF": "https://arxiv.org/pdf/2507.07776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a human evaluation framework for adversarial attacks in computer vision, not on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09193",
      "abstract": "The problem of bistatic integrated sensing and communications over memoryless relay channels is considered, where destination concurrently decodes the message sent by the source and estimates unknown parameters from received signals with the help of a relay. A state-dependent discrete memoryless relay channel is considered to model this setup, and the fundamental limits of the communication-sensing performance tradeoff are characterized by the capacity-distortion function. An upper bound on the capacity-distortion function is derived, extending the cut-set bound results to address the sensing operation at the destination. A hybrid-partial-decode-and-compress-forward coding scheme is also proposed to facilitate source-relay cooperation for both message transmission and sensing, establishing a lower bound on the capacity-distortion function. It is found that the hybrid-partial-decode-and-compress-forward scheme achieves optimal sensing performance when the communication task is ignored. Furthermore, the upper and lower bounds are shown to coincide for three specific classes of relay channels. Numerical examples are provided to illustrate the communication-sensing tradeoff and demonstrate the benefits of integrated design.",
      "authors": [
        "Yao Liu",
        "Min Li",
        "Lawrence Ong",
        "Aylin Yener"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:27:09+00:00",
          "link": "https://arxiv.org/abs/2507.09193v1",
          "size": "426kb",
          "version": "v1"
        }
      ],
      "title": "Fundamental Limits of Bistatic Integrated Sensing and Communications over Memoryless Relay Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09193",
        "HTML": "https://arxiv.org/html/2507.09193v1",
        "PDF": "https://arxiv.org/pdf/2507.09193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about sensing and communication over relay channels, not relevant to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09255",
      "abstract": "We present StockSim, an open-source simulation platform for systematic evaluation of large language models (LLMs) in realistic financial decision-making scenarios. Unlike previous toolkits that offer limited scope, StockSim delivers a comprehensive system that fully models market dynamics and supports diverse simulation modes of varying granularity. It incorporates critical real-world factors, such as latency, slippage, and order-book microstructure, that were previously neglected, enabling more faithful and insightful assessment of LLM-based trading agents. An extensible, role-based agent framework supports heterogeneous trading strategies and multi-agent coordination, making StockSim a uniquely capable testbed for NLP research on reasoning under uncertainty and sequential decision-making. We open-source all our code at https: //github.com/harrypapa2002/StockSim.",
      "authors": [
        "Charidimos Papadakis",
        "Giorgos Filandrianos",
        "Angeliki Dimitriou",
        "Maria Lymperaiou",
        "Konstantinos Thomas",
        "Giorgos Stamou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:29:44+00:00",
          "link": "https://arxiv.org/abs/2507.09255v1",
          "size": "950kb",
          "version": "v1"
        }
      ],
      "title": "StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09255",
        "PDF": "https://arxiv.org/pdf/2507.09255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a simulation platform for evaluating LLMs in financial markets but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09487",
      "abstract": "Visual and semantic concepts are often structured in a hierarchical manner. For instance, textual concept `cat' entails all images of cats. A recent study, MERU, successfully adapts multimodal learning techniques from Euclidean space to hyperbolic space, effectively capturing the visual-semantic hierarchy. However, a critical question remains: how can we more efficiently train a model to capture and leverage this hierarchy? In this paper, we propose the \\textit{Hyperbolic Masked Image and Distillation Network} (HMID-Net), a novel and efficient method that integrates Masked Image Modeling (MIM) and knowledge distillation techniques within hyperbolic space. To the best of our knowledge, this is the first approach to leverage MIM and knowledge distillation in hyperbolic space to train highly efficient models. In addition, we introduce a distillation loss function specifically designed to facilitate effective knowledge transfer in hyperbolic space. Our experiments demonstrate that MIM and knowledge distillation techniques in hyperbolic space can achieve the same remarkable success as in Euclidean space. Extensive evaluations show that our method excels across a wide range of downstream tasks, significantly outperforming existing models like MERU and CLIP in both image classification and retrieval.",
      "authors": [
        "Changli Wang",
        "Fang Yin",
        "Jiafeng Liu",
        "Rui Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.09487v1",
          "size": "2787kb",
          "version": "v1"
        }
      ],
      "title": "HMID-Net: An Exploration of Masked Image Modeling and Knowledge Distillation in Hyperbolic Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09487",
        "HTML": "https://arxiv.org/html/2507.09487v1",
        "PDF": "https://arxiv.org/pdf/2507.09487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model architecture for masked image modeling and knowledge distillation in hyperbolic space, with no emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10337",
      "abstract": "Log data is a vital resource for capturing system events and states. With the increasing complexity and widespread adoption ofmodern software systems and IoT devices, the daily volume of log generation has surged to tens of petabytes, leading to significant collection and storage costs. To address this challenge, lossless log compression has emerged as an effective solution, enabling substantial resource savings without compromising log information. In this paper, we first conduct a characterization study on extensive public log datasets and identify four key observations. Building on these insights, we propose LogLite, a lightweight, plug-and-play, streaming lossless compression algorithm designed to handle both TEXT and JSON logs throughout their life cycle. LogLite requires no predefined rules or pre-training and is inherently adaptable to evolving log structures. Our evaluation shows that, compared to state-of-the-art baselines, LogLite achieves Pareto optimality in most scenarios, delivering an average improvement of up to 67.8% in compression ratio and up to 2.7 $\\times$ in compression speed.",
      "authors": [
        "Benzhao Tang",
        "Shiyu Yang",
        "Zhitao Shen",
        "Wenjie Zhang",
        "Xuemin Lin",
        "Zhihong Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:43:10+00:00",
          "link": "https://arxiv.org/abs/2507.10337v1",
          "size": "504kb",
          "version": "v1"
        }
      ],
      "title": "LogLite: Lightweight Plug-and-Play Streaming Log Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10337",
        "HTML": "https://arxiv.org/html/2507.10337v1",
        "PDF": "https://arxiv.org/pdf/2507.10337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with log compression strategies, which does not pertain to the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.03309",
      "abstract": "Visual recognition of materials and their states is essential for understanding the physical world, from identifying wet regions on surfaces or stains on fabrics to detecting infected areas on plants or minerals in rocks. Collecting data that captures this vast variability is complex due to the scattered and gradual nature of material states. Manually annotating real-world images is constrained by cost and precision, while synthetic data, although accurate and inexpensive, lacks real-world diversity. This work aims to bridge this gap by infusing patterns automatically extracted from real-world images into synthetic data. Hence, patterns collected from natural images are used to generate and map materials into synthetic scenes. This unsupervised approach captures the complexity of the real world while maintaining the precision and scalability of synthetic data. We also present the first comprehensive benchmark for zero-shot material state segmentation, utilizing real-world images across a diverse range of domains, including food, soils, construction, plants, liquids, and more, each appears in various states such as wet, dry, infected, cooked, burned, and many others. The annotation includes partial similarity between regions with similar but not identical materials and hard segmentation of only identical material states. This benchmark eluded top foundation models, exposing the limitations of existing data collection methods. Meanwhile, nets trained on the infused data performed significantly better on this and related tasks. The dataset, code, and trained model are available. We also share 300,000 extracted textures and SVBRDF/PBR materials to facilitate future datasets generation.",
      "authors": [
        "Sagi Eppel",
        "Jolina Li",
        "Manuel Drehwald",
        "Alan Aspuru-Guzik"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-05T20:21:49+00:00",
          "link": "https://arxiv.org/abs/2403.03309v1",
          "size": "5118kb",
          "version": "v1"
        },
        {
          "date": "2024-03-07T17:43:54+00:00",
          "link": "https://arxiv.org/abs/2403.03309v2",
          "size": "4533kb",
          "version": "v2"
        },
        {
          "date": "2024-03-14T23:14:16+00:00",
          "link": "https://arxiv.org/abs/2403.03309v3",
          "size": "4786kb",
          "version": "v3"
        },
        {
          "date": "2024-04-09T13:44:54+00:00",
          "link": "https://arxiv.org/abs/2403.03309v4",
          "size": "4512kb",
          "version": "v4"
        },
        {
          "date": "2024-06-10T01:13:22+00:00",
          "link": "https://arxiv.org/abs/2403.03309v5",
          "size": "11628kb",
          "version": "v5"
        }
      ],
      "title": "Learning Zero-Shot Material States Segmentation, by Implanting Natural Image Patterns in Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.03309",
        "HTML": "https://arxiv.org/html/2403.03309",
        "PDF": "https://arxiv.org/pdf/2403.03309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper outlines a method to augment synthetic data with real-world patterns for material state recognition, involving a detailed data processing approach to create a new dataset."
      },
      "tasks": [
        "Material Recognition",
        "Segmentation",
        "Zero-Shot Learning",
        "Zero Shot Segmentation"
      ],
      "repo_urls": [
        "https://github.com/sagieppel/matseg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18738",
      "abstract": "Visual augmentation has become a crucial technique for enhancing the visual robustness of imitation learning. However, existing methods are often limited by prerequisites such as camera calibration or the need for controlled environments (e.g., green screen setups). In this work, we introduce RoboEngine, the first plug-and-play visual robot data augmentation toolkit. For the first time, users can effortlessly generate physics- and task-aware robot scenes with just a few lines of code. To achieve this, we present a novel robot scene segmentation dataset, a generalizable high-quality robot segmentation model, and a fine-tuned background generation model, which together form the core components of the out-of-the-box toolkit. Using RoboEngine, we demonstrate the ability to generalize robot manipulation tasks across six entirely new scenes, based solely on demonstrations collected from a single scene, achieving a more than 200% performance improvement compared to the no-augmentation baseline. All datasets, model weights, and the toolkit are released https://roboengine.github.io/",
      "authors": [
        "Chengbo Yuan",
        "Suraj Joshi",
        "Shaoting Zhu",
        "Hang Su",
        "Hang Zhao",
        "Yang Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T14:46:14+00:00",
          "link": "https://arxiv.org/abs/2503.18738v1",
          "size": "2586kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T02:18:02+00:00",
          "link": "https://arxiv.org/abs/2503.18738v2",
          "size": "1911kb",
          "version": "v2"
        }
      ],
      "title": "RoboEngine: Plug-and-Play Robot Data Augmentation with Semantic Robot Segmentation and Background Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18738",
        "HTML": "https://arxiv.org/html/2503.18738v2",
        "PDF": "https://arxiv.org/pdf/2503.18738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel robot scene segmentation dataset and provides detailed data processing steps for generating augmented training data specific to the domain of robot operations."
      },
      "models": [
        {
          "model_path": "michaelyuanqwq/roboengine-sam",
          "downloads": "57194",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/michaelyuanqwq/roboengine-sam"
        },
        {
          "model_path": "michaelyuanqwq/roboengine-bg-diffusion",
          "downloads": "22",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/michaelyuanqwq/roboengine-bg-diffusion"
        }
      ],
      "datasets": [
        {
          "dataset_name": "michaelyuanqwq/roboseg",
          "downloads": "119",
          "likes": "2",
          "link": "https://huggingface.co/datasets/michaelyuanqwq/roboseg"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22566",
      "abstract": "Exploration remains a fundamental challenge in reinforcement learning (RL), particularly in environments with sparse or adversarial reward structures. In this work, we study how the architecture of deep neural policies implicitly shapes exploration before training. We theoretically and empirically demonstrate strategies for generating ballistic or diffusive trajectories from untrained policies in a toy model. Using the theory of infinite-width networks and a continuous-time limit, we show that untrained policies return correlated actions and result in non-trivial state-visitation distributions. We discuss the distributions of the corresponding trajectories for a standard architecture, revealing insights into inductive biases for tackling exploration. Our results establish a theoretical and experimental framework for using policy initialization as a design tool to understand exploration behavior in early training.",
      "authors": [
        "Jacob Adamczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:28:41+00:00",
          "link": "https://arxiv.org/abs/2506.22566v1",
          "size": "433kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T19:21:29+00:00",
          "link": "https://arxiv.org/abs/2506.22566v2",
          "size": "433kb",
          "version": "v2"
        }
      ],
      "title": "Exploration Behavior of Untrained Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22566",
        "HTML": "https://arxiv.org/html/2506.22566v2",
        "PDF": "https://arxiv.org/pdf/2506.22566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on how the architecture of deep neural policies shapes exploration behavior in reinforcement learning, with no mention of LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22777",
      "abstract": "Language models trained with reinforcement learning (RL) can engage in reward hacking--the exploitation of unintended strategies for high reward--without revealing this behavior in their chain-of-thought reasoning. This makes the detection of reward hacking difficult, posing risks for high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL fine-tuning intervention that trains models to explicitly acknowledge when they are influenced by prompt cues--hints which point to incorrect answers (e.g., \"a Stanford professor thinks the answer is A\"). To evaluate VFT, we subsequently train models with RL on environments where held-out prompt cues signal which incorrect answers will receive high reward, incentivizing models to exploit these cues instead of reasoning correctly. We measure how often models exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained model's responses consist of undetected reward hacks. In comparison, when we perform RL without VFT, the rate of undetected reward hacks goes up to 88%; with a debiasing baseline intervention, this increases further to 99%. VFT achieves this by substantially increasing how often models verbalize the influence of cues, from 8% to 43% after VFT, and up to 94% after RL. Baselines remain low even after RL (11% and 1%). Our results show that teaching models to explicitly verbalize reward hacking behavior before RL significantly improves their detection, offering a practical path toward more transparent and safe AI systems.",
      "authors": [
        "Miles Turpin",
        "Andy Arditi",
        "Marvin Li",
        "Joe Benton",
        "Julian Michael"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:37:10+00:00",
          "link": "https://arxiv.org/abs/2506.22777v1",
          "size": "3360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T15:36:35+00:00",
          "link": "https://arxiv.org/abs/2506.22777v2",
          "size": "4079kb",
          "version": "v2"
        }
      ],
      "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22777",
        "HTML": "https://arxiv.org/html/2506.22777v2",
        "PDF": "https://arxiv.org/pdf/2506.22777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses verbalization fine-tuning (VFT) as a pre-RL intervention but does not make a substantive contribution to processing or modifying training data specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09540",
      "abstract": "Spiking Neural Networks (SNNs) offer biologically inspired, energy-efficient alternatives to traditional Deep Neural Networks (DNNs) for real-time control systems. However, their training presents several challenges, particularly for reinforcement learning (RL) tasks, due to the non-differentiable nature of spike-based communication. In this work, we introduce what is, to our knowledge, the first framework that employs Metropolis-Hastings (MH) sampling, a Bayesian inference technique, to train SNNs for dynamical agent control in RL environments without relying on gradient-based methods. Our approach iteratively proposes and probabilistically accepts network parameter updates based on accumulated reward signals, effectively circumventing the limitations of backpropagation while enabling direct optimization on neuromorphic platforms. We evaluated this framework on two standard control benchmarks: AcroBot and CartPole. The results demonstrate that our MH-based approach outperforms conventional Deep Q-Learning (DQL) baselines and prior SNN-based RL approaches in terms of maximizing the accumulated reward while minimizing network resources and training episodes.",
      "authors": [
        "Ali Safa",
        "Farida Mohsen",
        "Ali Al-Zawqari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:50:00+00:00",
          "link": "https://arxiv.org/abs/2507.09540v1",
          "size": "1899kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09540",
        "HTML": "https://arxiv.org/html/2507.09540v1",
        "PDF": "https://arxiv.org/pdf/2507.09540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on training Spiking Neural Networks using Metropolis-Hastings sampling for control tasks, not on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10248",
      "abstract": "Submodular functions and their optimization have found applications in diverse settings ranging from machine learning and data mining to game theory and economics. In this work, we consider the constrained maximization of a submodular function, for which we conduct a principled study of bicriteria approximation algorithms -- algorithms which can violate the constraint, but only up to a bounded factor. Bicrteria optimization allows constrained submodular maximization to capture additional important settings, such as the well-studied submodular cover problem and optimization under soft constraints. We provide results that span both multiple types of constraints (cardinality, knapsack, matroid and convex set) and multiple classes of submodular functions (monotone, symmetric and general). For many of the cases considered, we provide optimal results. In other cases, our results improve over the state-of-the-art, sometimes even over the state-of-the-art for the special case of single-criterion (standard) optimization. Results of the last kind demonstrate that relaxing the feasibility constraint may give a perspective about the problem that is useful even if one only desires feasible solutions.",
      "authors": [
        "Moran Feldman and Alan Kuhnle"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.10248v1",
          "size": "123kb",
          "version": "v1"
        }
      ],
      "title": "Bicriteria Submodular Maximization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10248",
        "HTML": "https://arxiv.org/html/2507.10248v1",
        "PDF": "https://arxiv.org/pdf/2507.10248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on bicriteria submodular maximization which is related to optimization algorithms and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.02068",
      "abstract": "The elapsed time equation is an age-structured model that describes the dynamics of interconnected spiking neurons through the elapsed time since the last discharge, leading to many interesting questions on the evolution of the system from a mathematical and biological point of view. In this work, we deal with the case when the transmission after a spike is instantaneous and the case with a distributed delay that depends on the previous history of the system, which is a more realistic assumption. Since the instantaneous transmission case is known to be ill-posed due to non-uniqueness or jump discontinuities, we establish a criterion for well-posedness to determine when the solution remains continuous in time, through an invertibility condition that improves the existence theory under more relaxed hypothesis on the nonlinearity, including the strongly excitatory case. Inspired in the existence theory, we adapt the classical explicit upwind scheme through a robust fixed-point approach and we prove that the approximation given by this scheme converges to the solution of the nonlinear problem through BV-estimates and we extend the idea to the case with distributed delay. We also show some numerical simulations to compare the behavior of the system in the case of instantaneous transmission with the case of distributed delay under different parameters, leading to solutions with different asymptotic profiles.",
      "authors": [
        "Mauricio Sepulveda",
        "Nicolas Torres",
        "Luis Miguel Villada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-03T14:10:50+00:00",
          "link": "https://arxiv.org/abs/2310.02068v1",
          "size": "2477kb",
          "version": "v1"
        },
        {
          "date": "2024-04-09T19:16:10+00:00",
          "link": "https://arxiv.org/abs/2310.02068v2",
          "size": "2477kb",
          "version": "v2"
        },
        {
          "date": "2024-12-04T21:01:39+00:00",
          "link": "https://arxiv.org/abs/2310.02068v3",
          "size": "2503kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T16:25:38+00:00",
          "link": "https://arxiv.org/abs/2310.02068v4",
          "size": "2480kb",
          "version": "v4"
        }
      ],
      "title": "Well-posedness and numerical analysis of an elapsed time model with strongly coupled neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.02068",
        "HTML": "https://arxiv.org/html/2310.02068v4",
        "PDF": "https://arxiv.org/pdf/2310.02068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the mathematical and numerical analysis of neural network models and does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.12796",
      "abstract": "In this practice paper, we propose a framework for integrating AI into disciplinary engineering courses and curricula. The use of AI within engineering is an emerging but growing area and the knowledge, skills, and abilities (KSAs) associated with it are novel and dynamic. This makes it challenging for faculty who are looking to incorporate AI within their courses to create a mental map of how to tackle this challenge. In this paper, we advance a role-based conception of competencies to assist disciplinary faculty with identifying and implementing AI competencies within engineering curricula. We draw on prior work related to AI literacy and competencies and on emerging research on the use of AI in engineering. To illustrate the use of the framework, we provide two exemplary cases. We discuss the challenges in implementing the framework and emphasize the need for an embedded approach where AI concerns are integrated across multiple courses throughout the degree program, especially for teaching responsible and ethical AI development and use.",
      "authors": [
        "Johannes Schleiss",
        "Aditya Johri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-28T19:13:14+00:00",
          "link": "https://arxiv.org/abs/2410.12796v1",
          "size": "170kb",
          "version": "v1"
        }
      ],
      "title": "A Roles-based Competency Framework for Integrating Artificial Intelligence (AI) in Engineering Courses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12796",
        "PDF": "https://arxiv.org/pdf/2410.12796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a roles-based competency framework for integrating AI in engineering courses and curricula, without addressing any aspects of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07803",
      "abstract": "Streaming speech translation (StreamST) requires determining appropriate timing, known as policy, to generate translations while continuously receiving source speech inputs, balancing low latency with high translation quality. However, existing StreamST methods typically operate on sentence-level speech segments, referred to as simultaneous speech translation (SimulST). In practice, they require collaboration with segmentation models to accomplish StreamST, where the truncated speech segments constrain SimulST models to make policy decisions and generate translations based on limited contextual information. Moreover, SimulST models struggle to learn effective policies due to the complexity of speech inputs and cross-lingual generation. To address these challenges, we propose StreamUni, which achieves StreamST through a unified Large Speech-Language Model (LSLM). Specifically, StreamUni incorporates speech Chain-of-Thought (CoT) in guiding the LSLM to generate multi-stage outputs. Leveraging these multi-stage outputs, StreamUni simultaneously accomplishes speech segmentation, policy decision, and translation generation, completing StreamST without requiring massive policy-specific training. Additionally, we propose a streaming CoT training method that enhances low-latency policy decisions and generation capabilities using limited CoT data. Experiments demonstrate that our approach achieves state-of-the-art performance on StreamST tasks.",
      "authors": [
        "Shoutao Guo",
        "Xiang Li",
        "Mengge Liu",
        "Wei Chen",
        "Yang Feng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:28:39+00:00",
          "link": "https://arxiv.org/abs/2507.07803v1",
          "size": "132kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T01:40:13+00:00",
          "link": "https://arxiv.org/abs/2507.07803v2",
          "size": "132kb",
          "version": "v2"
        }
      ],
      "title": "StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07803",
        "HTML": "https://arxiv.org/html/2507.07803v2",
        "PDF": "https://arxiv.org/pdf/2507.07803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mainly discusses streaming speech translation using a unified speech-language model and enhanced policy decisions, with limited focus on LLM training data processing."
      },
      "models": [
        {
          "model_path": "ICTNLP/StreamUni-Phi4",
          "downloads": "0",
          "likes": "4",
          "trending_score": "4.0",
          "link": "https://huggingface.co/ICTNLP/StreamUni-Phi4"
        }
      ],
      "datasets": [
        {
          "dataset_name": "ICTNLP/StreamUni",
          "downloads": "1740",
          "likes": "1",
          "link": "https://huggingface.co/datasets/ICTNLP/StreamUni"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08967",
      "abstract": "Model steering represents a powerful technique that dynamically aligns large language models (LLMs) with human preferences during inference. However, conventional model-steering methods rely heavily on externally annotated data, not only limiting their adaptability to varying contexts but also tethering their effectiveness to annotation quality. In this paper, we present SIMS, the first self-improving model-steering framework that operates without relying on external supervision. At its core, SIMS autonomously generates and refines contrastive samples through iterative self-improvement cycles, enabling adaptive, context-specific steering. Additionally, SIMS employs novel strategies, including prompt ranking and contrast sampling, to further enhance steering efficacy. Extensive evaluation across diverse LLMs and benchmarks demonstrates that SIMS substantially outperforms existing methods in steering effectiveness and adaptability, highlighting self-improving model steering as a promising direction for future research on inference-time LLM alignment.",
      "authors": [
        "Rongyi Zhu",
        "Yuhui Wang",
        "Tanqiu Jiang",
        "Jiacheng Liang",
        "Ting Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:52:32+00:00",
          "link": "https://arxiv.org/abs/2507.08967v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "Self-Improving Model Steering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08967",
        "PDF": "https://arxiv.org/pdf/2507.08967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses a method for model steering that generates contrastive samples, it primarily focuses on inference time alignment rather than the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10368",
      "abstract": "Deep Operator Networks (DeepONets) have emerged as a powerful surrogate modeling framework for learning solution operators in PDE-governed systems. While their use is expanding across engineering disciplines, applications in geotechnical engineering remain limited. This study systematically evaluates several DeepONet architectures for the one-dimensional consolidation problem. We initially consider three architectures: a standard DeepONet with the coefficient of consolidation embedded in the branch net (Models 1 and 2), and a physics-inspired architecture with the coefficient embedded in the trunk net (Model 3). Results show that Model 3 outperforms the standard configurations (Models 1 and 2) but still has limitations when the target solution (excess pore pressures) exhibits significant variation. To overcome this limitation, we propose a Trunknet Fourier feature-enhanced DeepONet (Model 4) that addresses the identified limitations by capturing rapidly varying functions. All proposed architectures achieve speedups ranging from 1.5 to 100 times over traditional explicit and implicit solvers, with Model 4 being the most efficient. Larger computational savings are expected for more complex systems than the explored 1D case, which is promising. Overall, the study highlights the potential of DeepONets to enable efficient, generalizable surrogate modeling in geotechnical applications, advancing the integration of scientific machine learning in geotechnics, which is at an early stage.",
      "authors": [
        "Yongjin Choi",
        "Chenying Liu",
        "Jorge Macedo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:09:58+00:00",
          "link": "https://arxiv.org/abs/2507.10368v1",
          "size": "7742kb",
          "version": "v1"
        }
      ],
      "title": "Enhanced DeepONet for 1-D consolidation operator learning: an architectural investigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10368",
        "HTML": "https://arxiv.org/html/2507.10368v1",
        "PDF": "https://arxiv.org/pdf/2507.10368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on Deep Operator Networks for modeling PDE-governed systems in geotechnical engineering and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10475",
      "abstract": "The rapid advancement of large language models (LLMs) has raised concerns about reliably detecting AI-generated text. Stylometric metrics work well on autoregressive (AR) outputs, but their effectiveness on diffusion-based models is unknown. We present the first systematic comparison of diffusion-generated text (LLaDA) and AR-generated text (LLaMA) using 2 000 samples. Perplexity, burstiness, lexical diversity, readability, and BLEU/ROUGE scores show that LLaDA closely mimics human text in perplexity and burstiness, yielding high false-negative rates for AR-oriented detectors. LLaMA shows much lower perplexity but reduced lexical fidelity. Relying on any single metric fails to separate diffusion outputs from human writing. We highlight the need for diffusion-aware detectors and outline directions such as hybrid models, diffusion-specific stylometric signatures, and robust watermarking.",
      "authors": [
        "\\.Ismail Tar{\\i}m",
        "Aytu\\u{g} Onan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:55:57+00:00",
          "link": "https://arxiv.org/abs/2507.10475v1",
          "size": "3006kb",
          "version": "v1"
        }
      ],
      "title": "Can You Detect the Difference?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10475",
        "HTML": "https://arxiv.org/html/2507.10475v1",
        "PDF": "https://arxiv.org/pdf/2507.10475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper addresses the detection of AI-generated text, comparing diffusion-generated and AR-generated text. Although it involves textual analysis, it doesn't focus on processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10491",
      "abstract": "Backdoor unlearning aims to remove backdoor-related information while preserving the model's original functionality. However, existing unlearning methods mainly focus on recovering trigger patterns but fail to restore the correct semantic labels of poison samples. This limitation prevents them from fully eliminating the false correlation between the trigger pattern and the target label. To address this, we leverage boundary adversarial attack techniques, revealing two key observations. First, poison samples exhibit significantly greater distances from decision boundaries compared to clean samples, indicating they require larger adversarial perturbations to change their predictions. Second, while adversarial predicted labels for clean samples are uniformly distributed, those for poison samples tend to revert to their original correct labels. Moreover, the features of poison samples restore to closely resemble those of corresponding clean samples after adding adversarial perturbations. Building upon these insights, we propose Backdoor Unlearning via adversaRial bouNdary analysis (BURN), a novel defense framework that integrates false correlation decoupling, progressive data refinement, and model purification. In the first phase, BURN employs adversarial boundary analysis to detect poisoned samples based on their abnormal adversarial boundary distances, then restores their correct semantic labels for fine-tuning. In the second phase, it employs a feedback mechanism that tracks prediction discrepancies between the original backdoored model and progressively sanitized models, guiding both dataset refinement and model purification. Extensive evaluations across multiple datasets, architectures, and seven diverse backdoor attack types confirm that BURN effectively removes backdoor threats while maintaining the model's original performance.",
      "authors": [
        "Yanghao Su",
        "Jie Zhang",
        "Yiming Li",
        "Tianwei Zhang",
        "Qing Guo",
        "Weiming Zhang",
        "Nenghai Yu",
        "Nils Lukas",
        "Wenbo Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:13:06+00:00",
          "link": "https://arxiv.org/abs/2507.10491v1",
          "size": "1444kb",
          "version": "v1"
        }
      ],
      "title": "BURN: Backdoor Unlearning via Adversarial Boundary Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10491",
        "HTML": "https://arxiv.org/html/2507.10491v1",
        "PDF": "https://arxiv.org/pdf/2507.10491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for backdoor unlearning in machine learning models, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.17530",
      "abstract": "Millimeter-wave (mmWave) communication enables high data rates for cellular-connected Unmanned Aerial Vehicles (UAVs). However, a robust beam management remains challenging due to significant path loss and the dynamic mobility of UAVs, which can destabilize the UAV-base station (BS) link. This research presents a GPS-aided deep learning (DL) model that simultaneously predicts current and future optimal beams for UAV mmWave communications, maintaining a Top-1 prediction accuracy exceeding 70% and an average power loss below 0.6 dB across all prediction steps. These outcomes stem from a proposed data set splitting method ensuring balanced label distribution, paired with a GPS preprocessing technique that extracts key positional features, and a DL architecture that maps sequential position data to beam index predictions. The model reduces overhead by approximately 93% (requiring the training of 2 ~ 3 beams instead of 32 beams) with 95% beam prediction accuracy guarantees, and ensures 94% to 96% of predictions exhibit mean power loss not exceeding 1 dB.",
      "authors": [
        "Vendi Ardianto Nugroho and Byung Moo Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T06:38:00+00:00",
          "link": "https://arxiv.org/abs/2505.17530v1",
          "size": "478kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T21:49:26+00:00",
          "link": "https://arxiv.org/abs/2505.17530v2",
          "size": "479kb",
          "version": "v2"
        }
      ],
      "title": "GPS-Aided Deep Learning for Beam Prediction and Tracking in UAV mmWave Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17530",
        "HTML": "https://arxiv.org/html/2505.17530v2",
        "PDF": "https://arxiv.org/pdf/2505.17530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a GPS-aided deep learning model and data set splitting methods for beam prediction, mentioning data preprocessing techniques. However, it largely focuses on communication systems rather than elaborating on LLM training data processing."
      },
      "tasks": [
        "Beam Prediction",
        "Prediction"
      ],
      "repo_urls": [
        "https://github.com/ardiantovn/gpsbeam"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17826",
      "abstract": "Trinity-RFT is a general-purpose, unified and easy-to-use framework designed for reinforcement fine-tuning (RFT) of large language models. It is built with a modular and decoupled design, consisting of (1) an RFT-core that unifies and generalizes synchronous/asynchronous, on-policy/off-policy, and online/offline modes of RFT; (2) seamless integration for agent-environment interaction with high efficiency and robustness; and (3) systematic data pipelines optimized for RFT. Trinity-RFT can be easily adapted for diverse application scenarios, and serves as a unified platform for development and research of advanced reinforcement learning paradigms at both macroscopic and microscopic levels. This technical report outlines the vision, features, design and implementations of Trinity-RFT, accompanied by extensive examples, applications and experiments that demonstrate its functionalities and user-friendliness.",
      "authors": [
        "Xuchen Pan",
        "Yanxi Chen",
        "Yushuo Chen",
        "Yuchang Sun",
        "Daoyuan Chen",
        "Wenhao Zhang",
        "Yuexiang Xie",
        "Yilun Huang",
        "Yilei Zhang",
        "Dawei Gao",
        "Weijie Shi",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T12:41:09+00:00",
          "link": "https://arxiv.org/abs/2505.17826v1",
          "size": "5221kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T12:02:28+00:00",
          "link": "https://arxiv.org/abs/2505.17826v2",
          "size": "7103kb",
          "version": "v2"
        }
      ],
      "title": "Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17826",
        "HTML": "https://arxiv.org/html/2505.17826v2",
        "PDF": "https://arxiv.org/pdf/2505.17826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "Trinity-RFT discusses systematic data pipelines optimized for RFT of LLMs, highlighting the design and processing of data pipelines that enhance data quality for reinforcement fine-tuning, which aligns with improving LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/modelscope/trinity-rft"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.06955",
      "abstract": "We present BIS Reasoning 1.0, the first large-scale Japanese dataset of syllogistic reasoning problems explicitly designed to evaluate belief-inconsistent reasoning in large language models (LLMs). Unlike prior datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent syllogisms to uncover reasoning biases in LLMs trained on human-aligned corpora. We benchmark state-of-the-art models - including GPT models, Claude models, and leading Japanese LLMs - revealing significant variance in performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies critical weaknesses in current LLMs when handling logically valid but belief-conflicting inputs. These findings have important implications for deploying LLMs in high-stakes domains such as law, healthcare, and scientific literature, where truth must override intuitive belief to ensure integrity and safety.",
      "authors": [
        "Ha-Thanh Nguyen",
        "Chaoran Liu",
        "Qianying Liu",
        "Hideyuki Tachibana",
        "Su Myat Noe",
        "Yusuke Miyao",
        "Koichi Takeda",
        "Sadao Kurohashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T00:38:18+00:00",
          "link": "https://arxiv.org/abs/2506.06955v1",
          "size": "3136kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T07:39:43+00:00",
          "link": "https://arxiv.org/abs/2506.06955v2",
          "size": "3139kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T08:15:13+00:00",
          "link": "https://arxiv.org/abs/2506.06955v3",
          "size": "3313kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T02:22:42+00:00",
          "link": "https://arxiv.org/abs/2506.06955v4",
          "size": "3649kb",
          "version": "v4"
        }
      ],
      "title": "BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06955",
        "HTML": "https://arxiv.org/html/2506.06955v4",
        "PDF": "https://arxiv.org/pdf/2506.06955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a new dataset for evaluating belief-inconsistent reasoning in LLMs, but it focuses on evaluation rather than detailing data processing methods aimed at improving LLM training data."
      },
      "tasks": [
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02083",
      "abstract": "Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.",
      "authors": [
        "Haonan Duan",
        "Stephen Zhewen Lu",
        "Caitlin Fiona Harrigan",
        "Nishkrit Desai",
        "Jiarui Lu",
        "Micha{\\l} Koziarski",
        "Leonardo Cotta",
        "Chris J. Maddison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:41:44+00:00",
          "link": "https://arxiv.org/abs/2507.02083v1",
          "size": "3246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:17:16+00:00",
          "link": "https://arxiv.org/abs/2507.02083v2",
          "size": "2349kb",
          "version": "v2"
        }
      ],
      "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02083",
        "HTML": "https://arxiv.org/html/2507.02083v2",
        "PDF": "https://arxiv.org/pdf/2507.02083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating the scientific capabilities of LLMs in systems biology but does not involve any LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08849",
      "abstract": "Machine Learning models are increasingly used in businesses to detect faults and anomalies in complex systems. In this work, we take this approach a step further: beyond merely detecting anomalies, we aim to identify the optimal control strategy that restores the system to a safe state with minimal disruption. We frame this challenge as a counterfactual problem: given a Machine Learning model that classifies system states as either good or anomalous, our goal is to determine the minimal adjustment to the system's control variables (i.e., its current status) that is necessary to return it to the good state. To achieve this, we leverage a mathematical model that finds the optimal counterfactual solution while respecting system specific constraints. Notably, most counterfactual analysis in the literature focuses on individual cases where a person seeks to alter their status relative to a decision made by a classifier, such as for loan approval or medical diagnosis. Our work addresses a fundamentally different challenge: optimizing counterfactuals for a complex energy system, specifically an offshore wind turbine oil type transformer. This application not only advances counterfactual optimization in a new domain but also opens avenues for broader research in this area. Our tests on real world data provided by our industrial partner show that our methodology easily adapts to user preferences and brings savings in the order of 3 million euros per year in a typical farm.",
      "authors": [
        "Emilio Carrizosa",
        "Martina Fischetti",
        "Roshell Haaker",
        "Juan Miguel Morales"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:10:25+00:00",
          "link": "https://arxiv.org/abs/2507.08849v1",
          "size": "2396kb",
          "version": "v1"
        }
      ],
      "title": "Counterfactual optimization for fault prevention in complex wind energy systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08849",
        "HTML": "https://arxiv.org/html/2507.08849v1",
        "PDF": "https://arxiv.org/pdf/2507.08849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on counterfactual optimization for fault prevention in wind energy systems without addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09022",
      "abstract": "We propose a method for using Web Authentication APIs for SSH authentication, enabling passwordless remote server login with passkeys. These are credentials that are managed throughout the key lifecycle by an authenticator on behalf of the user and offer strong security guarantees.\n  Passwords remain the dominant mode of SSH authentication, despite their well known flaws such as phishing and reuse. SSH's custom key-based authentication protocol can alleviate these issues but remains vulnerable to key theft. Additionally, it has poor usability, with even knowledgeable users leaking key material and failing to verify fingerprints. Hence, effective key management remains a critical open area in SSH security. In contrast, WebAuthn is a modern authentication standard designed to replace passwords, managing keys on behalf of the user. As a web API, this standard cannot integrate with SSH directly.\n  We propose a framework to integrate WebAuthn with SSH servers, by using UNIX pluggable authentication modules (PAM). Our approach is backwards-compatible, supports stock SSH servers and requires no new software client-side. It offers protection for cryptographic material at rest, resistance to key leaks, phishing protection, privacy protection and attestation capability. None of these properties are offered by passwords nor traditional SSH keys. We validate these advantages with a structured, conceptual security analysis.\n  We develop a prototype implementation and conduct a user study to quantify the security advantages of our proposal, testing our prototype with 40 SSH users. The study confirms the security problems of SSH-keys, including 20% of the cohort leaking their private keys. Our SSH-passkeys effectively address these problems: we find a 90% reduction in critical security errors, while reducing authentication time by 4x on average.",
      "authors": [
        "Moe Kayali and Jonas Schmitt and Franziska Roesner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:13:09+00:00",
          "link": "https://arxiv.org/abs/2507.09022v1",
          "size": "566kb",
          "version": "v1"
        }
      ],
      "title": "SSH-Passkeys: Leveraging Web Authentication for Passwordless SSH",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09022",
        "HTML": "https://arxiv.org/html/2507.09022v1",
        "PDF": "https://arxiv.org/pdf/2507.09022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses SSH authentication with WebAuthn and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09111",
      "abstract": "Human-Object Interaction (HOI) detection is crucial for robot-human assistance, enabling context-aware support. However, models trained on clean datasets degrade in real-world conditions due to unforeseen corruptions, leading to inaccurate prediction. To address this, we introduce the first robustness benchmark for HOI detection, evaluating model resilience under diverse challenges. Despite advances, current models struggle with environmental variability, occlusion, and noise. Our benchmark, RoHOI, includes 20 corruption types based on HICO-DET and V-COCO datasets and a new robustness-focused metric. We systematically analyze existing models in the related field, revealing significant performance drops under corruptions. To improve robustness, we propose a Semantic-Aware Masking-based Progressive Learning (SAMPL) strategy to guide the model to be optimized based on holistic and partial cues, dynamically adjusting the model's optimization to enhance robust feature learning. Extensive experiments show our approach outperforms state-of-the-art methods, setting a new standard for robust HOI detection. Benchmarks, datasets, and code will be made publicly available at https://github.com/Kratos-Wen/RoHOI.",
      "authors": [
        "Di Wen",
        "Kunyu Peng",
        "Kailun Yang",
        "Yufan Chen",
        "Ruiping Liu",
        "Junwei Zheng",
        "Alina Roitberg",
        "Rainer Stiefelhagen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:58:04+00:00",
          "link": "https://arxiv.org/abs/2507.09111v1",
          "size": "12813kb",
          "version": "v1"
        }
      ],
      "title": "RoHOI: Robustness Benchmark for Human-Object Interaction Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09111",
        "HTML": "https://arxiv.org/html/2507.09111v1",
        "PDF": "https://arxiv.org/pdf/2507.09111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a robustness benchmark for human-object interaction detection, focusing on model evaluation rather than LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09242",
      "abstract": "Artistic image assessment has become a prominent research area in computer vision. In recent years, the field has witnessed a proliferation of datasets and methods designed to evaluate the aesthetic quality of paintings. However, most existing approaches focus solely on static final images, overlooking the dynamic and multi-stage nature of the artistic painting process. To address this gap, we propose a novel framework for human-aligned assessment of painting processes. Specifically, we introduce the Painting Process Assessment Dataset (PPAD), the first large-scale dataset comprising real and synthetic painting process images, annotated by domain experts across eight detailed attributes. Furthermore, we present PPJudge (Painting Process Judge), a Transformer-based model enhanced with temporally-aware positional encoding and a heterogeneous mixture-of-experts architecture, enabling effective assessment of the painting process. Experimental results demonstrate that our method outperforms existing baselines in accuracy, robustness, and alignment with human judgment, offering new insights into computational creativity and art education.",
      "authors": [
        "Shiqi Jiang",
        "Xinpeng Li",
        "Xi Mao",
        "Changbo Wang",
        "Chenhui Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:30:44+00:00",
          "link": "https://arxiv.org/abs/2507.09242v1",
          "size": "2743kb",
          "version": "v1"
        }
      ],
      "title": "PPJudge: Towards Human-Aligned Assessment of Artistic Painting Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09242",
        "HTML": "https://arxiv.org/html/2507.09242v1",
        "PDF": "https://arxiv.org/pdf/2507.09242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset (PPAD) with detailed descriptions and annotations, relevant for data creation, but it does not focus on LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09353",
      "abstract": "Time series data with missing values is common across many domains. Healthcare presents special challenges due to prolonged periods of sensor disconnection. In such cases, having a confidence measure for imputed values is critical. Most existing methods either overlook model uncertainty or lack mechanisms to estimate it. To address this gap, we introduce a general framework that quantifies and leverages uncertainty for selective imputation. By focusing on values the model is most confident in, highly unreliable imputations are avoided. Our experiments on multiple EHR datasets, covering diverse types of missingness, demonstrate that selectively imputing less-uncertain values not only reduces imputation errors but also improves downstream tasks. Specifically, we show performance gains in a 24-hour mortality prediction task, underscoring the practical benefit of incorporating uncertainty into time series imputation.",
      "authors": [
        "Addison Weatherhead",
        "Anna Goldenberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T17:11:00+00:00",
          "link": "https://arxiv.org/abs/2507.09353v1",
          "size": "3976kb",
          "version": "v1"
        }
      ],
      "title": "Impute With Confidence: A Framework for Uncertainty Aware Multivariate Time Series Imputation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09353",
        "HTML": "https://arxiv.org/html/2507.09353v1",
        "PDF": "https://arxiv.org/pdf/2507.09353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for multivariate time series imputation focusing on uncertainty awareness which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09892",
      "abstract": "Estimating worst-case resource consumption is a critical task in software development. The worst-case analysis (WCA) problem is an optimization-based abstraction of this task. Fuzzing and symbolic execution are widely used techniques for addressing the WCA problem. However, improving code coverage in fuzzing or managing path explosion in symbolic execution within the context of WCA poses significant challenges. In this paper, we propose PathFuzzing, aiming to combine the strengths of both techniques to design a WCA method. The key idea is to transform a program into a symbolic one that takes an execution path (encoded as a binary string) and interprets the bits as branch decisions. PathFuzzing then applies evolutionary fuzzing techniques to the transformed program to search for binary strings that represent satisfiable path conditions and lead to high resource consumption. We evaluate the performance of PathFuzzing experimentally on a benchmark suite that consists of prior work's benchmarks and some added by us. Results show that PathFuzzing generally outperforms a fuzzing and a symbolic-execution baseline.",
      "authors": [
        "Zimu Chen",
        "Di Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:51:50+00:00",
          "link": "https://arxiv.org/abs/2507.09892v1",
          "size": "454kb",
          "version": "v1"
        }
      ],
      "title": "PathFuzzing: Worst Case Analysis by Fuzzing Symbolic-Execution Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09892",
        "HTML": "https://arxiv.org/html/2507.09892v1",
        "PDF": "https://arxiv.org/pdf/2507.09892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method called PathFuzzing for worst-case analysis in software development, focusing on code coverage and path explosion challenges. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10095",
      "abstract": "CLIP has shown promising performance across many short-text tasks in a zero-shot manner. However, limited by the input length of the text encoder, CLIP struggles on under-stream tasks with long-text inputs (>77 tokens). To remedy this issue, we propose FIX-CLIP which includes three novel modules: (1) A dual-branch training pipeline that aligns short and long texts with masked and raw images respectively, which boosts the long-text representation while preserving the short-text ability. (2) Multiple learnable regional prompts with unidirectional masks in Transformer layers for regional information extraction. (3) A hierarchical feature alignment module in the intermediate encoder layers to promote the consistency of multi-scale features. Furthermore, we collect 30M images and utilize existing MLLMs to synthesize long-text captions for training. Extensive experiments show that FIX-CLIP achieves state-of-the-art performance on both long-text and short-text retrieval benchmarks. For downstream applications, we reveal that FIX-CLIP's text encoder delivers promising performance in a plug-and-play manner for diffusion models with long-text input.",
      "authors": [
        "Bingchao Wang",
        "Zhiwei Ning",
        "Jianyu Ding",
        "Xuanang Gao",
        "Yin Li",
        "Dongsheng Jiang",
        "Jie Yang",
        "Wei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:31:34+00:00",
          "link": "https://arxiv.org/abs/2507.10095v1",
          "size": "6533kb",
          "version": "v1"
        }
      ],
      "title": "FIX-CLIP: Dual-Branch Hierarchical Contrastive Learning via Synthetic Captions for Better Understanding of Long Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10095",
        "HTML": "https://arxiv.org/html/2507.10095v1",
        "PDF": "https://arxiv.org/pdf/2507.10095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses generating synthetic long-text captions for training, the main focus is on improving model performance (FIX-CLIP), rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10203",
      "abstract": "Multimodal learning often encounters the under-optimized problem and may perform worse than unimodal learning. Existing approaches attribute this issue to imbalanced learning across modalities and tend to address it through gradient balancing. However, this paper argues that balanced learning is not the optimal setting for multimodal learning. With bias-variance analysis, we prove that imbalanced dependency on each modality obeying the inverse ratio of their variances contributes to optimal performance. To this end, we propose the Asymmetric Representation Learning(ARL) strategy to assist multimodal learning via imbalanced optimization. ARL introduces auxiliary regularizers for each modality encoder to calculate their prediction variance. ARL then calculates coefficients via the unimodal variance to re-weight the optimization of each modality, forcing the modality dependence ratio to be inversely proportional to the modality variance ratio. Moreover, to minimize the generalization error, ARL further introduces the prediction bias of each modality and jointly optimizes them with multimodal loss. Notably, all auxiliary regularizers share parameters with the multimodal model and rely only on the modality representation. Thus the proposed ARL strategy introduces no extra parameters and is independent of the structures and fusion methods of the multimodal model. Finally, extensive experiments on various datasets validate the effectiveness and versatility of ARL. Code is available at \\href{https://github.com/shicaiwei123/ICCV2025-ARL}{https://github.com/shicaiwei123/ICCV2025-ARL}",
      "authors": [
        "Shicai Wei",
        "Chunbo Luo",
        "Yang Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.10203v1",
          "size": "1128kb",
          "version": "v1"
        }
      ],
      "title": "Improving Multimodal Learning via Imbalanced Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10203",
        "HTML": "https://arxiv.org/html/2507.10203v1",
        "PDF": "https://arxiv.org/pdf/2507.10203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving multimodal learning through imbalanced optimization strategies (ARL) but does not involve LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10215",
      "abstract": "This paper analyzes neural networks through graph variables and statistical sufficiency. We interpret neural network layers as graph-based transformations, where neurons act as pairwise functions between inputs and learned anchor points. Within this formulation, we establish conditions under which layer outputs are sufficient for the layer inputs, that is, each layer preserves the conditional distribution of the target variable given the input variable. Under dense anchor point assumptions, we prove that asymptotic sufficiency holds in the infinite-width limit and is preserved throughout training. To align more closely with practical architectures, we further show that sufficiency can be achieved with finite-width networks by assuming region-separated input distributions and constructing appropriate anchor points. Our framework covers fully connected layers, general pairwise functions, ReLU and sigmoid activations, and convolutional neural networks. This work bridges statistical sufficiency, graph-theoretic representations, and deep learning, providing a new statistical understanding of neural networks.",
      "authors": [
        "Cencheng Shen",
        "Yuexiao Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:31:47+00:00",
          "link": "https://arxiv.org/abs/2507.10215v1",
          "size": "165kb",
          "version": "v1"
        }
      ],
      "title": "A Graph Sufficiency Perspective for Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10215",
        "HTML": "https://arxiv.org/html/2507.10215v1",
        "PDF": "https://arxiv.org/pdf/2507.10215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes neural networks using graph sufficiency and statistical methods but does not discuss processing or managing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10367",
      "abstract": "Client-side metadata caching has long been considered an effective method for accelerating metadata operations in distributed file systems (DFSs). However, we have found that client-side state (e.g., caching) is not only ineffective but also consumes valuable memory resources in the deep learning pipelines. We thus propose FalconFS, a DFS optimized for deep learning pipelines with the stateless-client architecture. Specifically, instead of performing client-side path resolution and caching, FalconFS efficiently resolves paths on the server side using hybrid metadata indexing and lazy namespace replication. FalconFS also boosts server concurrency with concurrent request merging and provides easy deployment with VFS shortcut. Evaluations against CephFS and Lustre show that FalconFS achieves up to 5.72$\\times$ throughput for small file read/write and up to 12.81$\\times$ throughput for deep learning model training. FalconFS has been running in Huawei autonomous driving system's production environment with 10,000 NPUs for one year.",
      "authors": [
        "Jingwei Xu",
        "Junbin Kang",
        "Mingkai Dong",
        "Mingyu Liu",
        "Lu Zhang",
        "Shaohong Guo",
        "Ziyan Qiu",
        "Mingzhen You",
        "Ziyi Tian",
        "Anqi Yu",
        "Tianhong Ding",
        "Xinwei Hu",
        "and Haibo Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:09:01+00:00",
          "link": "https://arxiv.org/abs/2507.10367v1",
          "size": "457kb",
          "version": "v1"
        }
      ],
      "title": "FalconFS: Distributed File System for Large-Scale Deep Learning Pipeline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10367",
        "HTML": "https://arxiv.org/html/2507.10367v1",
        "PDF": "https://arxiv.org/pdf/2507.10367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a Distributed File System (FalconFS) for deep learning pipelines, which optimizes metadata operations, but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1107.3279",
      "abstract": "The ideas here are a continuation of a previous article. Some of the applications of the main ideas in the previous article are explained, along with some limitations of the general ideas. There are situations where additional hypotheses allow the use of the main ideas in problems that are not immediately accessible.",
      "authors": [
        "Jesse Gilbert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2011-07-17T06:23:00+00:00",
          "link": "https://arxiv.org/abs/1107.3279v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2011-10-12T01:39:45+00:00",
          "link": "https://arxiv.org/abs/1107.3279v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2011-10-18T03:46:24+00:00",
          "link": "https://arxiv.org/abs/1107.3279v3",
          "size": "1kb",
          "version": "v3"
        },
        {
          "date": "2011-10-22T02:40:48+00:00",
          "link": "https://arxiv.org/abs/1107.3279v4",
          "size": "4kb",
          "version": "v4"
        },
        {
          "date": "2012-11-22T00:12:46+00:00",
          "link": "https://arxiv.org/abs/1107.3279v5",
          "size": "13kb",
          "version": "v5"
        },
        {
          "date": "2013-01-28T06:14:35+00:00",
          "link": "https://arxiv.org/abs/1107.3279v6",
          "size": "6kb",
          "version": "v6"
        },
        {
          "date": "2013-02-11T11:05:50+00:00",
          "link": "https://arxiv.org/abs/1107.3279v7",
          "size": "1kb",
          "version": "v7"
        },
        {
          "date": "2013-02-14T21:10:43+00:00",
          "link": "https://arxiv.org/abs/1107.3279v8",
          "size": "0kb",
          "version": "v8"
        },
        {
          "date": "2013-02-25T15:47:49+00:00",
          "link": "https://arxiv.org/abs/1107.3279v9",
          "size": "6kb",
          "version": "v9"
        },
        {
          "date": "2013-04-07T09:29:25+00:00",
          "link": "https://arxiv.org/abs/1107.3279v10",
          "size": "4kb",
          "version": "v10"
        },
        {
          "date": "2013-04-13T21:24:17+00:00",
          "link": "https://arxiv.org/abs/1107.3279v11",
          "size": "8kb",
          "version": "v11"
        },
        {
          "date": "2013-05-07T00:56:12+00:00",
          "link": "https://arxiv.org/abs/1107.3279v12",
          "size": "8kb",
          "version": "v12"
        },
        {
          "date": "2013-06-23T00:19:01+00:00",
          "link": "https://arxiv.org/abs/1107.3279v13",
          "size": "1kb",
          "version": "v13"
        },
        {
          "date": "2013-11-07T22:39:29+00:00",
          "link": "https://arxiv.org/abs/1107.3279v14",
          "size": "3kb",
          "version": "v14"
        },
        {
          "date": "2013-11-19T14:50:16+00:00",
          "link": "https://arxiv.org/abs/1107.3279v15",
          "size": "1kb",
          "version": "v15"
        },
        {
          "date": "2023-12-27T14:57:27+00:00",
          "link": "https://arxiv.org/abs/1107.3279v16",
          "size": "14kb",
          "version": "v16"
        },
        {
          "date": "2024-01-03T23:50:47+00:00",
          "link": "https://arxiv.org/abs/1107.3279v17",
          "size": "0kb",
          "version": "v17"
        },
        {
          "date": "2024-07-03T17:37:20+00:00",
          "link": "https://arxiv.org/abs/1107.3279v18",
          "size": "17kb",
          "version": "v18"
        },
        {
          "date": "2025-07-14T15:58:08+00:00",
          "link": "https://arxiv.org/abs/1107.3279v19",
          "size": "16kb",
          "version": "v19"
        }
      ],
      "title": "Probabilistic Methods on Erdos Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/1107.3279",
        "HTML": "https://arxiv.org/html/1107.3279",
        "PDF": "https://arxiv.org/pdf/1107.3279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses probabilistic methods applied to Erdos problems and does not mention LLM training data or any aspect of data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2110.00905",
      "abstract": "The max-flow min-cut theorem is a cornerstone result in combinatorial optimization. Calegari et al. (arXiv:0802.3208) initialized the study of quantum max-flow min-cut conjecture, which connects the rank of a tensor network and the min-cut. Cui et al. (arXiv:1508.04644) showed that this conjecture is false generally. In this paper, we establish a quantum max-flow min-cut theorem for a new definition of quantum maximum flow. In particular, we show that for any quantum tensor network, there are infinitely many $n$, such that quantum max-flow equals quantum min-cut, after attaching dimension $n$ maximally entangled state to each edge as ancilla. Our result implies that the ratio of the quantum max-flow to the quantum min-cut converges to $1$ as the dimension $n$ tends to infinity. As a direct application, we prove the validity of the asymptotical version of the open problem about the quantum max-flow and the min-cut, proposed in Cui et al. (arXiv:1508.04644 ).",
      "authors": [
        "Nengkun Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2021-10-03T02:11:39+00:00",
          "link": "https://arxiv.org/abs/2110.00905v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Max-Flow Min-Cut theorem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.00905",
        "PDF": "https://arxiv.org/pdf/2110.00905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses the quantum max-flow min-cut theorem without addressing any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.04525",
      "abstract": "Recent research reveals that machine learning (ML) models are highly sensitive to minor changes in their training procedure, such as the inclusion or exclusion of a single data point, leading to conflicting predictions on individual data points; a property termed as arbitrariness or instability in ML pipelines in prior work. Drawing from the uncertainty literature, we show that stability decomposes into epistemic and aleatoric components, capturing the consistency and confidence in prediction, respectively. We use this decomposition to provide two main contributions. Our first contribution is an extensive empirical evaluation. We find that (i) epistemic instability can be reduced with more training data whereas aleatoric instability cannot; (ii) state-of-the-art ML models have aleatoric instability as high as 79% and aleatoric instability disparities among demographic groups as high as 29% in popular fairness benchmarks; and (iii) fairness pre-processing interventions generally increase aleatoric instability more than in-processing interventions, and both epistemic and aleatoric instability are highly sensitive to data-processing interventions and model architecture. Our second contribution is a practical solution to the problem of systematic arbitrariness. We propose a model selection procedure that includes epistemic and aleatoric criteria alongside existing accuracy and fairness criteria, and show that it successfully narrows down a large set of good models (50-100 on our datasets) to a handful of stable, fair and accurate ones. We built and publicly released a python library to measure epistemic and aleatoric multiplicity in any ML pipeline alongside existing confusion-matrix-based metrics, providing practitioners with a rich suite of evaluation metrics to use to define a more precise criterion during model selection.",
      "authors": [
        "Falaah Arif Khan",
        "Denys Herasymuk",
        "Nazar Protsiv",
        "Julia Stoyanovich"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-09T09:35:36+00:00",
          "link": "https://arxiv.org/abs/2302.04525v1",
          "size": "1947kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T07:10:35+00:00",
          "link": "https://arxiv.org/abs/2302.04525v2",
          "size": "1831kb",
          "version": "v2"
        }
      ],
      "title": "An Epistemic and Aleatoric Decomposition of Arbitrariness to Constrain the Set of Good Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.04525",
        "HTML": "https://arxiv.org/html/2302.04525v2",
        "PDF": "https://arxiv.org/pdf/2302.04525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses data-processing interventions impacting model instability, it does not primarily focus on LLM training data processing."
      },
      "tasks": [
        "Fairness",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.00235",
      "abstract": "Convex relaxation methods are powerful tools for studying the lowest energy of many-body problems. By relaxing the representability conditions for marginals to a set of local constraints, along with a global semidefinite constraint, a polynomial-time solvable semidefinite program (SDP) that provides a lower bound for the energy can be derived. In this paper, we propose accelerating the solution of such an SDP relaxation by imposing a hierarchical structure on the positive semidefinite (PSD) primal and dual variables. Furthermore, these matrices can be updated efficiently using the algebra of the compressed representations within an augmented Lagrangian method. We achieve quadratic and even near-linear time per-iteration complexity. Through experimentation on the quantum transverse field Ising model, we showcase the capability of our approach to provide a sufficiently accurate lower bound for the exact ground-state energy.",
      "authors": [
        "Yi Wang",
        "Rizheng Huang",
        "Yuehaw Khoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T02:09:39+00:00",
          "link": "https://arxiv.org/abs/2408.00235v1",
          "size": "403kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:48:41+00:00",
          "link": "https://arxiv.org/abs/2408.00235v2",
          "size": "347kb",
          "version": "v2"
        }
      ],
      "title": "Solving cluster moment relaxation with hierarchical matrix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00235",
        "HTML": "https://arxiv.org/html/2408.00235v2",
        "PDF": "https://arxiv.org/pdf/2408.00235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on methods for accelerating the solution of semidefinite program relaxations rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.18353",
      "abstract": "This review explores recent advancements in data fusion techniques and Transformer-based remote sensing applications in precision agriculture. Using a systematic, data-driven approach, we analyze research trends from 1994 to 2024, identifying key developments in data fusion, remote sensing, and AI-driven agricultural monitoring. While traditional machine learning and deep learning approaches have demonstrated effectiveness in agricultural decision-making, challenges such as limited scalability, suboptimal feature extraction, and reliance on extensive labeled data persist. This study examines the comparative advantages of Transformer-based fusion methods, particularly their ability to model spatiotemporal dependencies and integrate heterogeneous datasets for applications in soil analysis, crop classification, yield prediction, and disease detection. A comparative analysis of multimodal data fusion approaches is conducted, evaluating data types, fusion techniques, and remote sensing platforms. We demonstrate how Transformers outperform conventional models by enhancing prediction accuracy, mitigating feature redundancy, and optimizing large-scale data integration. Furthermore, we propose a structured roadmap for implementing data fusion in agricultural remote sensing, outlining best practices for ground-truth data selection, platform integration, and fusion model design. By addressing key research gaps and providing a strategic framework, this review offers valuable insights for advancing precision agriculture through AI-driven data fusion techniques.",
      "authors": [
        "Mahdi Saki",
        "Rasool Keshavarz",
        "Daniel Franklin",
        "Mehran Abolhasan",
        "Justin Lipman",
        "Negin Shariati"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T01:26:21+00:00",
          "link": "https://arxiv.org/abs/2410.18353v1",
          "size": "695kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T01:10:32+00:00",
          "link": "https://arxiv.org/abs/2410.18353v2",
          "size": "1914kb",
          "version": "v2"
        }
      ],
      "title": "A Data-Driven Review of Remote Sensing-Based Data Fusion in Precision Agriculture from Foundational to Transformer-Based Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18353",
        "PDF": "https://arxiv.org/pdf/2410.18353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a review focused on data fusion in precision agriculture, with no mention of processing training data for LLMs or contributing to LLM data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.04845",
      "abstract": "We provide abstract, general and highly uniform rates of asymptotic regularity for a generalized stochastic Halpern-style iteration, which incorporates a second mapping in the style of a Krasnoselskii-Mann iteration. This iteration is general in two ways: First, it incorporates stochasticity in a completely abstract way rather than fixing a sampling method; secondly, it includes as special cases stochastic versions of various schemes from the optimization literature, including Halpern's iteration as well as a Krasnoselskii-Mann iteration with Tikhonov regularization terms in the sense of Bo\\c{t}, Csetnek and Meier. For these specific cases, we in particular obtain linear rates of asymptotic regularity, matching (or improving) the currently best known rates for these iterations in stochastic optimization, and quadratic rates of asymptotic regularity are obtained in the context of inner product spaces for the general iteration. At the end, we briefly sketch how the schemes presented here can be instantiated in the context of reinforcement learning to yield novel methods for Q-learning.",
      "authors": [
        "Nicholas Pischke and Thomas Powell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T16:32:50+00:00",
          "link": "https://arxiv.org/abs/2411.04845v1",
          "size": "28kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:38:10+00:00",
          "link": "https://arxiv.org/abs/2411.04845v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Asymptotic regularity of a generalised stochastic Halpern scheme",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04845",
        "HTML": "https://arxiv.org/html/2411.04845v2",
        "PDF": "https://arxiv.org/pdf/2411.04845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses stochastic Halpern schemes and their regularity in optimization contexts. It does not mention any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Q-Learning",
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.02799",
      "abstract": "Error-bounded lossy compression has been widely adopted in many scientific domains because it can address the challenges in storing, transferring, and analyzing unprecedented amounts of scientific data. Although error-bounded lossy compression offers general data distortion control by enforcing strict error bounds on raw data, it may fail to meet the quality requirements on the results of downstream analysis, a.k.a. Quantities of Interest (QoIs), derived from raw data. This may lead to uncertainties and even misinterpretations in scientific discoveries, significantly limiting the use of lossy compression in practice. In this paper, we propose QPET, a novel, versatile, and portable framework for QoI-preserving error-bounded lossy compression, which overcomes the challenges of modeling diverse QoIs by leveraging numerical strategies. QPET features (1) high portability to multiple existing lossy compressors, (2) versatile preservation to most differentiable univariate and multivariate QoIs, and (3) significant compression improvements in QoI-preservation tasks. Experiments with six real-world datasets demonstrate that integrating QPET into state-of-the-art error-bounded lossy compressors can gain 2x to 10x compression speedups of existing QoI-preserving error-bounded lossy compression solutions, up to 1000% compression ratio improvements to general-purpose compressors, and up to 133% compression ratio improvements to existing QoI-integrated scientific compressors.",
      "authors": [
        "Jinyang Liu",
        "Pu Jiao",
        "Kai Zhao",
        "Xin Liang",
        "Sheng Di",
        "Franck Cappello"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T20:01:23+00:00",
          "link": "https://arxiv.org/abs/2412.02799v1",
          "size": "3189kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T00:49:38+00:00",
          "link": "https://arxiv.org/abs/2412.02799v2",
          "size": "3868kb",
          "version": "v2"
        },
        {
          "date": "2025-04-15T22:19:10+00:00",
          "link": "https://arxiv.org/abs/2412.02799v3",
          "size": "3868kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T04:41:54+00:00",
          "link": "https://arxiv.org/abs/2412.02799v4",
          "size": "638kb",
          "version": "v4"
        }
      ],
      "title": "QPET: A Versatile and Portable Quantity-of-Interest-Preservation Framework for Error-Bounded Lossy Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02799",
        "HTML": "https://arxiv.org/html/2412.02799v4",
        "PDF": "https://arxiv.org/pdf/2412.02799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "QPET focuses on lossy data compression techniques for scientific data and does not discuss or make contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08966",
      "abstract": "Protein-ligand binding affinity prediction is essential for drug discovery and toxicity assessment. While machine learning (ML) promises fast and accurate predictions, its progress is constrained by the availability of reliable data. In contrast, physics-based methods such as absolute binding free energy perturbation (AB-FEP) deliver high accuracy but are computationally prohibitive for high-throughput applications. To bridge this gap, we introduce ToxBench, the first large-scale AB-FEP dataset designed for ML development and focused on a single pharmaceutically critical target, Human Estrogen Receptor Alpha (ER$\\alpha$). ToxBench contains 8,770 ER$\\alpha$-ligand complex structures with binding free energies computed via AB-FEP with a subset validated against experimental affinities at 1.75 kcal/mol RMSE, along with non-overlapping ligand splits to assess model generalizability. Using ToxBench, we further benchmark state-of-the-art ML methods, and notably, our proposed DualBind model, which employs a dual-loss framework to effectively learn the binding energy function. The benchmark results demonstrate the superior performance of DualBind and the potential of ML to approximate AB-FEP at a fraction of the computational cost.",
      "authors": [
        "Meng Liu",
        "Karl Leswing",
        "Simon K. S. Chu",
        "Farhad Ramezanghorbani",
        "Griffin Young",
        "Gabriel Marques",
        "Prerna Das",
        "Anjali Panikar",
        "Esther Jamir",
        "Mohammed Sulaiman Shamsudeen",
        "K. Shawn Watts",
        "Ananya Sen",
        "Hari Priya Devannagari",
        "Edward B. Miller",
        "Muyun Lihan",
        "Howook Hwang",
        "Janet Paulsen",
        "Xin Yu",
        "Kyle Gion",
        "Timur Rvachov",
        "Emine Kucukbenli",
        "Saee Gopal Paliwal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:50:43+00:00",
          "link": "https://arxiv.org/abs/2507.08966v1",
          "size": "1220kb",
          "version": "v1"
        }
      ],
      "title": "ToxBench: A Binding Affinity Prediction Benchmark with AB-FEP-Calculated Labels for Human Estrogen Receptor Alpha",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08966",
        "HTML": "https://arxiv.org/html/2507.08966v1",
        "PDF": "https://arxiv.org/pdf/2507.08966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new dataset (ToxBench) for binding affinity prediction and benchmarks ML methods but does not involve any processes related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09117",
      "abstract": "Dexterous intelligence - the ability to perform complex interactions with multi-fingered hands - is a pinnacle of human physical intelligence and emergent higher-order cognitive skills. However, contrary to Moravec's paradox, dexterous intelligence in humans appears simple only superficially. Many million years were spent co-evolving the human brain and hands including rich tactile sensing. Achieving human-level dexterity with robotic hands has long been a fundamental goal in robotics and represents a critical milestone toward general embodied intelligence. In this pursuit, computational sensorimotor learning has made significant progress, enabling feats such as arbitrary in-hand object reorientation. However, we observe that achieving higher levels of dexterity requires overcoming very fundamental limitations of computational sensorimotor learning.\n  I develop robot learning methods for highly dexterous multi-fingered manipulation by directly addressing these limitations at their root cause. Chiefly, through key studies, this disseration progressively builds an effective framework for reinforcement learning of dexterous multi-fingered manipulation skills. These methods adopt structured exploration, effectively overcoming the limitations of random exploration in reinforcement learning. The insights gained culminate in a highly effective reinforcement learning that incorporates sampling-based planning for direct exploration. Additionally, this thesis explores a new paradigm of using visuo-tactile human demonstrations for dexterity, introducing corresponding imitation learning techniques.",
      "authors": [
        "Gagan Khandate"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:22:55+00:00",
          "link": "https://arxiv.org/abs/2507.09117v1",
          "size": "12705kb",
          "version": "v1"
        }
      ],
      "title": "Towards Human-level Dexterity via Robot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09117",
        "HTML": "https://arxiv.org/html/2507.09117v1",
        "PDF": "https://arxiv.org/pdf/2507.09117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about developing robot learning methods for dexterous manipulation and does not discuss any aspects of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09157",
      "abstract": "Detecting deception in strategic dialogues is a complex and high-stakes task due to the subtlety of language and extreme class imbalance between deceptive and truthful communications. In this work, we revisit deception detection in the Diplomacy dataset, where less than 5% of messages are labeled deceptive. We introduce a lightweight yet effective model combining frozen BERT embeddings, interpretable linguistic and game-specific features, and a Positive-Unlabeled (PU) learning objective. Unlike traditional binary classifiers, PU-Lie is tailored for situations where only a small portion of deceptive messages are labeled, and the majority are unlabeled. Our model achieves a new best macro F1 of 0.60 while reducing trainable parameters by over 650x. Through comprehensive evaluations and ablation studies across seven models, we demonstrate the value of PU learning, linguistic interpretability, and speaker-aware representations. Notably, we emphasize that in this problem setting, accurately detecting deception is more critical than identifying truthful messages. This priority guides our choice of PU learning, which explicitly models the rare but vital deceptive class.",
      "authors": [
        "Bhavinkumar Vinodbhai Kuwar",
        "Bikrant Bikram Pratap Maurya",
        "Priyanshu Gupta",
        "Nitin Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T06:27:46+00:00",
          "link": "https://arxiv.org/abs/2507.09157v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "PU-Lie: Lightweight Deception Detection in Imbalanced Diplomatic Dialogues via Positive-Unlabeled Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09157",
        "HTML": "https://arxiv.org/html/2507.09157v1",
        "PDF": "https://arxiv.org/pdf/2507.09157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper deals with deception detection in dialogues using BERT embeddings and PU learning. There is a focus on model architecture rather than LLM training data processing, but mention of embeddings slightly links to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09288",
      "abstract": "Quantum Key Distribution (QKD) offers information-theoretic security against quantum computing threats, but integrating QKD into existing security protocols remains an unsolved challenge due to fundamental mismatches between pre-distributed quantum keys and computational key exchange paradigms. This paper presents the first systematic comparison of sequential versus parallel hybrid QKD-PQC key establishment strategies for IPsec, revealing fundamental protocol design principles that extend beyond specific implementations. We introduce two novel approaches for incorporating QKD into Internet Key Exchange version 2 (IKEv2) with support for both ETSI GS QKD 004 stateful and ETSI GS QKD 014 stateless API specifications: (1) a pure QKD approach that replaces computational key derivation with identifier-based quantum key coordination, and (2) a unified QKD-KEM abstraction that enables parallel composition of quantum and post-quantum cryptographic methods within existing protocol frameworks. Our key insight is that parallel hybrid approaches eliminate the multiplicative latency penalties inherent in sequential methods mandated by RFC 9370, achieving significant performance improvements under realistic network conditions. Performance evaluation using a Docker-based testing framework with IDQuantique QKD hardware demonstrates that the parallel hybrid approach significantly outperforms sequential methods under network latency conditions, while pure QKD achieves minimal bandwidth overhead through identifier-based key coordination. Our implementations provide practical quantum-enhanced IPsec solutions suitable for critical infrastructure deployments requiring defense-in-depth security.",
      "authors": [
        "Javier Blanco-Romero",
        "Pedro Otero Garc\\'ia",
        "Daniel Sobral-Blanco",
        "Florina Almenares Mendoza",
        "Ana Fern\\'andez Vilas",
        "Manuel Fern\\'andez-Veiga"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:54:04+00:00",
          "link": "https://arxiv.org/abs/2507.09288v1",
          "size": "410kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Quantum Security for IPsec",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09288",
        "HTML": "https://arxiv.org/html/2507.09288v1",
        "PDF": "https://arxiv.org/pdf/2507.09288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with quantum key distribution and its integration into IPsec protocols, which is unrelated to LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09538",
      "abstract": "Using neuromorphic computing for robotics applications has gained much attention in recent year due to the remarkable ability of Spiking Neural Networks (SNNs) for high-precision yet low memory and compute complexity inference when implemented in neuromorphic hardware. This ability makes SNNs well-suited for autonomous robot applications (such as in drones and rovers) where battery resources and payload are typically limited. Within this context, this paper studies the use of SNNs for performing direct robot navigation and obstacle avoidance from LIDAR data. A custom robot platform equipped with a LIDAR is set up for collecting a labeled dataset of LIDAR sensing data together with the human-operated robot control commands used for obstacle avoidance. Crucially, this paper provides what is, to the best of our knowledge, a first focused study about the importance of neuron membrane leakage on the SNN precision when processing LIDAR data for obstacle avoidance. It is shown that by carefully tuning the membrane potential leakage constant of the spiking Leaky Integrate-and-Fire (LIF) neurons used within our SNN, it is possible to achieve on-par robot control precision compared to the use of a non-spiking Convolutional Neural Network (CNN). Finally, the LIDAR dataset collected during this work is released as open-source with the hope of benefiting future research.",
      "authors": [
        "Zainab Ali",
        "Lujayn Al-Amir",
        "Ali Safa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:43:31+00:00",
          "link": "https://arxiv.org/abs/2507.09538v1",
          "size": "5554kb",
          "version": "v1"
        }
      ],
      "title": "On the Importance of Neural Membrane Potential Leakage for LIDAR-based Robot Obstacle Avoidance using Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09538",
        "HTML": "https://arxiv.org/html/2507.09538v1",
        "PDF": "https://arxiv.org/pdf/2507.09538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the creation of a labeled LIDAR dataset for neuromorphic computing and SNNs but does not provide detailed data processing steps relevant to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09698",
      "abstract": "The metric complexity (sometimes called Leinster--Cobbold maximum diversity) of a compact metric space is a recently introduced isometry-invariant of compact metric spaces which generalizes the notion of cardinality, and can be thought of as a metric-sensitive analogue of maximum entropy. On the other hand, the notion of diversity introduced by Bryant and Tupper is an assignment of a real number to every finite subset of a fixed set, which generalizes the notion of a metric. We establish a connection between these concepts by showing that the former quantity naturally produces an example of the latter. Moreover, in contrast to several examples in the literature, the diversity that arises from metric complexity is Minkowski-superlinear for compact subsets of the real line.",
      "authors": [
        "Gautam Aishwarya",
        "Dongbin Li",
        "Mokshay Madiman",
        "Mark Meckes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:16:14+00:00",
          "link": "https://arxiv.org/abs/2507.09698v1",
          "size": "335kb",
          "version": "v1"
        }
      ],
      "title": "Metric complexity is a Bryant--Tupper diversity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09698",
        "HTML": "https://arxiv.org/html/2507.09698v1",
        "PDF": "https://arxiv.org/pdf/2507.09698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses concepts in metric complexity and diversity for metric spaces, with no mention of LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09865",
      "abstract": "This paper considers the problem of estimating a matrix that encodes pairwise distances in a finite metric space (or, more generally, the edge weight matrix of a network) under the barycentric coding model (BCM) with respect to the Gromov-Wasserstein (GW) distance function. We frame this task as estimating the unknown barycentric coordinates with respect to the GW distance, assuming that the target matrix (or kernel) belongs to the set of GW barycenters of a finite collection of known templates. In the language of harmonic analysis, if computing GW barycenters can be viewed as a synthesis problem, this paper aims to solve the corresponding analysis problem. We propose two methods: one utilizing fixed-point iteration for computing GW barycenters, and another employing a differentiation-based approach to the GW structure using a blow-up technique. Finally, we demonstrate the application of the proposed GW analysis approach in a series of numerical experiments and applications to machine learning.",
      "authors": [
        "Roc\\'io D\\'iaz Mart\\'in",
        "Ivan V. Medri",
        "James M. Murphy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Functional Analysis (math.FA)",
        "Metric Geometry (math.MG)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:34:31+00:00",
          "link": "https://arxiv.org/abs/2507.09865v1",
          "size": "5453kb",
          "version": "v1"
        }
      ],
      "title": "Gromov-Wasserstein Barycenters: The Analysis Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09865",
        "HTML": "https://arxiv.org/html/2507.09865v1",
        "PDF": "https://arxiv.org/pdf/2507.09865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the analysis problem of Gromov-Wasserstein barycenters related to matrix estimation, which is unrelated to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09942",
      "abstract": "This letter investigates the optimal allocation of large language model (LLM) inference workloads across heterogeneous edge data centers (DCs) over time. Each DC features on-site renewable generation and faces dynamic electricity prices and spatiotemporal variability in renewable availability. The central question is: how can inference workloads be optimally distributed to the DCs to minimize energy consumption, carbon emissions, and water usage while enhancing user experience? This letter proposes a novel optimization model for LLM service providers to reduce operational costs and environmental impacts. Numerical results validate the efficacy of the proposed approach.",
      "authors": [
        "Jiaming Cheng and Duong Tung Nguyen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:32:32+00:00",
          "link": "https://arxiv.org/abs/2507.09942v1",
          "size": "2075kb",
          "version": "v1"
        }
      ],
      "title": "Green-LLM: Optimal Workload Allocation for Environmentally-Aware Distributed Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09942",
        "HTML": "https://arxiv.org/html/2507.09942v1",
        "PDF": "https://arxiv.org/pdf/2507.09942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the optimization of inference workloads in data centers, which is not related to LLM training data processing or any related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09998",
      "abstract": "Knowledge graphs (KGs) and multimodal item information, which respectively capture relational and attribute features, play a crucial role in improving recommender system accuracy. Recent studies have attempted to integrate them via multimodal knowledge graphs (MKGs) to further enhance recommendation performance. However, existing methods typically freeze the MKG structure during training, which limits the full integration of structural information from heterogeneous graphs (e.g., KG and user-item interaction graph), and results in sub-optimal performance. To address this challenge, we propose a novel framework, termed Self-loop Iterative Fusion of Heterogeneous Auxiliary Information for Multimodal Recommendation (SLIF-MR), which leverages item representations from previous training epoch as feedback signals to dynamically optimize the heterogeneous graph structures composed of KG, multimodal item feature graph, and user-item interaction graph. Through this iterative fusion mechanism, both user and item representations are refined, thus improving the final recommendation performance. Specifically, based on the feedback item representations, SLIF-MR constructs an item-item correlation graph, then integrated into the establishment process of heterogeneous graphs as additional new structural information in a self-loop manner. Consequently, the internal structures of heterogeneous graphs are updated with the feedback item representations during training. Moreover, a semantic consistency learning strategy is proposed to align heterogeneous item representations across modalities. The experimental results show that SLIF-MR significantly outperforms existing methods, particularly in terms of accuracy and robustness.",
      "authors": [
        "Jie Guo",
        "Jiahao Jiang",
        "Ziyuan Guo",
        "Bin Song and Yue Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:32:16+00:00",
          "link": "https://arxiv.org/abs/2507.09998v1",
          "size": "1643kb",
          "version": "v1"
        }
      ],
      "title": "SLIF-MR: Self-loop Iterative Fusion of Heterogeneous Auxiliary Information for Multimodal Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09998",
        "HTML": "https://arxiv.org/html/2507.09998v1",
        "PDF": "https://arxiv.org/pdf/2507.09998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a system for improving recommendation systems using knowledge graphs and multimodal data integration, which involves data processing but is not primarily focused on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10158",
      "abstract": "Federated Learning (FL) is a promising machine learning paradigm that enables participating devices to train privacy-preserved and collaborative models. FL has proven its benefits for robotic manipulation tasks. However, grasping tasks lack exploration in such settings where robots train a global model without moving data and ensuring data privacy. The main challenge is that each robot learns from data that is nonindependent and identically distributed (non-IID) and of low quantity. This exhibits performance degradation, particularly in robotic grasping. Thus, in this work, we propose MTF-Grasp, a multi-tier FL approach for robotic grasping, acknowledging the unique challenges posed by the non-IID data distribution across robots, including quantitative skewness. MTF-Grasp harnesses data quality and quantity across robots to select a set of \"top-level\" robots with better data distribution and higher sample count. It then utilizes top-level robots to train initial seed models and distribute them to the remaining \"low-level\" robots, reducing the risk of model performance degradation in low-level robots. Our approach outperforms the conventional FL setup by up to 8% on the quantity-skewed Cornell and Jacquard grasping datasets.",
      "authors": [
        "Obaidullah Zaland",
        "Erik Elmroth and Monowar Bhuyan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:17:28+00:00",
          "link": "https://arxiv.org/abs/2507.10158v1",
          "size": "3917kb",
          "version": "v1"
        }
      ],
      "title": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10158",
        "HTML": "https://arxiv.org/html/2507.10158v1",
        "PDF": "https://arxiv.org/pdf/2507.10158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Federated Learning and improving performance in robotic grasping tasks, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06759",
      "abstract": "Deep neural networks for medical image segmentation often produce overconfident results misaligned with empirical observations. Such miscalibration, challenges their clinical translation. We propose to use marginal L1 average calibration error (mL1-ACE) as a novel auxiliary loss function to improve pixel-wise calibration without compromising segmentation quality. We show that this loss, despite using hard binning, is directly differentiable, bypassing the need for approximate but differentiable surrogate or soft binning approaches. Our work also introduces the concept of dataset reliability histograms which generalises standard reliability diagrams for refined visual assessment of calibration in semantic segmentation aggregated at the dataset level. Using mL1-ACE, we reduce average and maximum calibration error by 45% and 55% respectively, maintaining a Dice score of 87% on the BraTS 2021 dataset. We share our code here: https://github.com/cai4cai/ACE-DLIRIS",
      "authors": [
        "Theodore Barfoot and Luis Garcia-Peraza-Herrera and Ben Glocker and Tom Vercauteren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T14:31:03+00:00",
          "link": "https://arxiv.org/abs/2403.06759v1",
          "size": "238kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T14:15:56+00:00",
          "link": "https://arxiv.org/abs/2403.06759v2",
          "size": "441kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T09:36:10+00:00",
          "link": "https://arxiv.org/abs/2403.06759v3",
          "size": "0kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T14:53:56+00:00",
          "link": "https://arxiv.org/abs/2403.06759v4",
          "size": "205kb",
          "version": "v4"
        }
      ],
      "title": "Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06759",
        "HTML": "https://arxiv.org/html/2403.06759v4",
        "PDF": "https://arxiv.org/pdf/2403.06759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses improved reliability in image segmentation using a novel loss function, without focusing on LLM training data processing."
      },
      "tasks": [
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/cai4cai/ace-dliris"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07006",
      "abstract": "Let $G$ be a finite abelian group and $A$ be a subset of $G \\times G$ which is corner--free, meaning that there are no $x, y \\in G$ and $d \\in G \\setminus \\{0\\}$ such that $(x, y)$, $(x+d, y)$, $(x, y+d) \\in A$. We prove that \\[|A| \\le |G|^2 \\cdot \\exp(-(\\log |G|)^{\\Omega(1)}).\\] As a consequence, we obtain polynomial (in the input length) lower bounds on the nondeterministic communication complexity of Exactly-N in the 3-player Number-on-Forehead model. We also obtain the first \"reasonable'' lower bounds on the coloring version of the $3$-dimensional corners problem, as well as on the nondeterministic communication complexity of Exactly-N in the 4-player Number-on-Forehead model.",
      "authors": [
        "Michael Jaber",
        "Yang P. Liu",
        "Shachar Lovett",
        "Anthony Ostuni",
        "Mehtaab Sawhney"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Complexity (cs.CC)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T16:26:06+00:00",
          "link": "https://arxiv.org/abs/2504.07006v1",
          "size": "78kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:57:37+00:00",
          "link": "https://arxiv.org/abs/2504.07006v2",
          "size": "69kb",
          "version": "v2"
        }
      ],
      "title": "Quasipolynomial bounds for the corners theorem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07006",
        "PDF": "https://arxiv.org/pdf/2504.07006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves mathematical bounds related to nondeterministic communication complexity problems and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18912",
      "abstract": "This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes parametric uncertainty but also the nonlinear sector bound is unknown. We investigate tools from positive linear systems to effectively solve the problems in complicated and uncertain nonlinear systems. By leveraging the positivity characteristic of the system, we derive an explicit formula for the stability radius of Lur'e systems. Furthermore, we extend our analysis to systems with neural network (NN) feedback loops. Building on this approach, we also propose a refinement method for sector bounds of NNs. This study introduces a scalable and efficient approach for robustness analysis of both Lur'e and NN-controlled systems. Finally, the proposed results are supported by illustrative examples.",
      "authors": [
        "Hamidreza Montazeri Hedesh",
        "Moh. Kamalul Wafi",
        "Bahram Shafai",
        "and Milad Siami"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T00:37:28+00:00",
          "link": "https://arxiv.org/abs/2505.18912v1",
          "size": "3645kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:47:32+00:00",
          "link": "https://arxiv.org/abs/2505.18912v2",
          "size": "8216kb",
          "version": "v2"
        }
      ],
      "title": "Robust Stability Analysis of Positive Lure System with Neural Network Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18912",
        "HTML": "https://arxiv.org/html/2505.18912v2",
        "PDF": "https://arxiv.org/pdf/2505.18912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with robustness analysis of control systems with neural network feedback, with no focus on LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06071",
      "abstract": "Audio-driven emotional 3D facial animation aims to generate synchronized lip movements and vivid facial expressions. However, most existing approaches focus on static and predefined emotion labels, limiting their diversity and naturalness. To address these challenges, we propose MEDTalk, a novel framework for fine-grained and dynamic emotional talking head generation. Our approach first disentangles content and emotion embedding spaces from motion sequences using a carefully designed cross-reconstruction process, enabling independent control over lip movements and facial expressions. Beyond conventional audio-driven lip synchronization, we integrate audio and speech text, predicting frame-wise intensity variations and dynamically adjusting static emotion features to generate realistic emotional expressions. Furthermore, to enhance control and personalization, we incorporate multimodal inputs-including text descriptions and reference expression images-to guide the generation of user-specified facial expressions. With MetaHuman as the priority, our generated results can be conveniently integrated into the industrial production pipeline.",
      "authors": [
        "Chang Liu",
        "Ye Pan",
        "Chenyang Ding",
        "Susanto Rahardja",
        "Xiaokang Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:14:27+00:00",
          "link": "https://arxiv.org/abs/2507.06071v1",
          "size": "19598kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T06:17:30+00:00",
          "link": "https://arxiv.org/abs/2507.06071v2",
          "size": "19598kb",
          "version": "v2"
        }
      ],
      "title": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06071",
        "HTML": "https://arxiv.org/html/2507.06071v2",
        "PDF": "https://arxiv.org/pdf/2507.06071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for 3D facial animation driven by audio inputs, focusing on emotion embedding and synchronization, with no involvement in LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09061",
      "abstract": "We study the problem of imitating an expert demonstrator in a continuous state-and-action dynamical system. While imitation learning in discrete settings such as autoregressive language modeling has seen immense success and popularity in recent years, imitation in physical settings such as autonomous driving and robot learning has proven comparably more complex due to the compounding errors problem, often requiring elaborate set-ups to perform stably. Recent work has demonstrated that even in benign settings, exponential compounding errors are unavoidable when learning solely from expert-controlled trajectories, suggesting the need for more advanced policy parameterizations or data augmentation. To this end, we present minimal interventions that provably mitigate compounding errors in continuous state-and-action imitation learning. When the system is open-loop stable, we prescribe \"action chunking,\" i.e., predicting and playing sequences of actions in open-loop; when the system is possibly unstable, we prescribe \"noise injection,\" i.e., adding noise during expert demonstrations. These interventions align with popular choices in modern robot learning, though the benefits we derive are distinct from the effects they were designed to target. Our results draw insights and tools from both control theory and reinforcement learning; however, our analysis reveals novel considerations that do not naturally arise when either literature is considered in isolation.",
      "authors": [
        "Thomas T. Zhang",
        "Daniel Pfrommer",
        "Nikolai Matni",
        "Max Simchowitz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T22:36:39+00:00",
          "link": "https://arxiv.org/abs/2507.09061v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09061",
        "HTML": "https://arxiv.org/html/2507.09061v1",
        "PDF": "https://arxiv.org/pdf/2507.09061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses imitation learning in continuous action spaces and presents methods to mitigate compounding error, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09785",
      "abstract": "Fast and accurate generation of molecular conformers is desired for downstream computational chemistry and drug discovery tasks. Currently, training and sampling state-of-the-art diffusion or flow-based models for conformer generation require significant computational resources. In this work, we build upon flow-matching and propose two mechanisms for accelerating training and inference of generative models for 3D molecular conformer generation. For fast training, we introduce the SO(3)-Averaged Flow training objective, which leads to faster convergence to better generation quality compared to conditional optimal transport flow or Kabsch-aligned flow. We demonstrate that models trained using SO(3)-Averaged Flow can reach state-of-the-art conformer generation quality. For fast inference, we show that the reflow and distillation methods of flow-based models enable few-steps or even one-step molecular conformer generation with high quality. The training techniques proposed in this work show a path towards highly efficient molecular conformer generation with flow-based models.",
      "authors": [
        "Zhonglin Cao",
        "Mario Geiger",
        "Allan dos Santos Costa",
        "Danny Reidenbach",
        "Karsten Kreis",
        "Tomas Geffner",
        "Franco Pellegrini",
        "Guoqing Zhou",
        "Emine Kucukbenli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:48:21+00:00",
          "link": "https://arxiv.org/abs/2507.09785v1",
          "size": "2622kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Molecular Conformer Generation with SO(3)-Averaged Flow Matching and Reflow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09785",
        "HTML": "https://arxiv.org/html/2507.09785v1",
        "PDF": "https://arxiv.org/pdf/2507.09785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary focus of this paper is on generative models for molecular conformer generation and efficiency improvements, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09080",
      "abstract": "The accelerating loss of biodiversity presents critical challenges for ecological research and conservation strategies. The preservation of biodiversity is paramount for maintaining ecological balance and ensuring the sustainability of ecosystems. However, biodiversity faces numerous threats, including habitat loss, climate change, and the proliferation of invasive species. Addressing these and other ecology-related challenges, both at local and global scales, requires comprehensive monitoring, predictive and conservation planning capabilities. Artificial Intelligence (AI) Foundation Models (FMs) have gained significant momentum in numerous scientific domains by leveraging vast datasets to learn general-purpose representations adaptable to various downstream tasks. This paradigm holds immense promise for biodiversity conservation. In response, we introduce BioAnalyst, the first Foundation Model tailored for biodiversity analysis and conservation planning. BioAnalyst employs a transformer-based architecture, pre-trained on extensive multi-modal datasets encompassing species occurrence records, remote sensing indicators, climate and environmental variables. BioAnalyst is designed for adaptability, allowing for fine-tuning of a range of downstream tasks, such as species distribution modelling, habitat suitability assessments, invasive species detection, and population trend forecasting. We evaluate the model's performance on two downstream use cases, demonstrating its generalisability compared to existing methods, particularly in data-scarce scenarios for two distinct use-cases, establishing a new accuracy baseline for ecological forecasting. By openly releasing BioAnalyst and its fine-tuning workflows to the scientific community, we aim to foster collaborative efforts in biodiversity modelling and advance AI-driven solutions to pressing ecological challenges.",
      "authors": [
        "Athanasios Trantas",
        "Martino Mensio",
        "Stylianos Stasinos",
        "Sebastian Gribincea",
        "Taimur Khan",
        "Damian Podareanu",
        "Aliene van der Veen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:56:08+00:00",
          "link": "https://arxiv.org/abs/2507.09080v1",
          "size": "15297kb",
          "version": "v1"
        }
      ],
      "title": "BioAnalyst: A Foundation Model for Biodiversity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09080",
        "HTML": "https://arxiv.org/html/2507.09080v1",
        "PDF": "https://arxiv.org/pdf/2507.09080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces BioAnalyst, a foundation model for biodiversity analysis, it does not focus on LLM training data processing; rather, it discusses model adaptability and fine-tuning for biodiversity tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09149",
      "abstract": "Health misinformation during the COVID-19 pandemic has significantly challenged public health efforts globally. This study applies the Elaboration Likelihood Model (ELM) to enhance misinformation detection on social media using a hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) model. The model aims to enhance the detection accuracy and reliability of misinformation classification by integrating ELM-based features such as text readability, sentiment polarity, and heuristic cues (e.g., punctuation frequency). The enhanced model achieved an accuracy of 97.37%, precision of 96.88%, recall of 98.50%, F1-score of 97.41%, and ROC-AUC of 99.50%. A combined model incorporating feature engineering further improved performance, achieving a precision of 98.88%, recall of 99.80%, F1-score of 99.41%, and ROC-AUC of 99.80%. These findings highlight the value of ELM features in improving detection performance, offering valuable contextual information. This study demonstrates the practical application of psychological theories in developing advanced machine learning algorithms to address health misinformation effectively.",
      "authors": [
        "Mkululi Sikosana",
        "Sean Maudsley-Barton",
        "Oluwaseun Ajao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T05:44:06+00:00",
          "link": "https://arxiv.org/abs/2507.09149v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Advanced Health Misinformation Detection Through Hybrid CNN-LSTM Models Informed by the Elaboration Likelihood Model (ELM)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09149",
        "PDF": "https://arxiv.org/pdf/2507.09149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing misinformation detection using CNN-LSTM models and ELM features. It does not discuss processing LLM training data or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09301",
      "abstract": "The emergence of quantum computers poses a significant threat to current secure service, application and/or protocol implementations that rely on RSA and ECDSA algorithms, for instance DNSSEC, because public-key cryptography based on number factorization or discrete logarithm is vulnerable to quantum attacks. This paper presents the integration of post-quantum cryptographic (PQC) algorithms into CoreDNS to enable quantum-resistant DNSSEC functionality. We have developed a plugin that extends CoreDNS with support for five PQC signature algorithm families: ML-DSA, FALCON, SPHINCS+, MAYO, and SNOVA. Our implementation maintains compatibility with existing DNS resolution flows while providing on-the-fly signing using quantum-resistant signatures. A benchmark has been performed and performance evaluation results reveal significant trade-offs between security and efficiency. The results indicate that while PQC algorithms introduce operational overhead, several candidates offer viable compromises for transitioning DNSSEC to quantum-resistant cryptography.",
      "authors": [
        "Julio Gento Suela",
        "Javier Blanco-Romero",
        "Florina Almenares Mendoza",
        "Daniel D\\'iaz-S\\'anchez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:34:17+00:00",
          "link": "https://arxiv.org/abs/2507.09301v1",
          "size": "1631kb",
          "version": "v1"
        }
      ],
      "title": "Implementing and Evaluating Post-Quantum DNSSEC in CoreDNS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09301",
        "HTML": "https://arxiv.org/html/2507.09301v1",
        "PDF": "https://arxiv.org/pdf/2507.09301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on implementing post-quantum cryptographic algorithms in DNSSEC and does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09748",
      "abstract": "Text-to-3D generation based on score distillation of pre-trained 2D diffusion models has gained increasing interest, with variational score distillation (VSD) as a remarkable example. VSD proves that vanilla score distillation can be improved by introducing an extra score-based model, which characterizes the distribution of images rendered from 3D models, to correct the distillation gradient. Despite the theoretical foundations, VSD, in practice, is likely to suffer from slow and sometimes ill-posed convergence. In this paper, we perform an in-depth investigation of the interplay between the introduced score model and the 3D model, and find that there exists a mismatching problem between LoRA and 3D distributions in practical implementation. We can simply adjust their optimization order to improve the generation quality. By doing so, the score model looks ahead to the current 3D state and hence yields more reasonable corrections. Nevertheless, naive lookahead VSD may suffer from unstable training in practice due to the potential over-fitting. To address this, we propose to use a linearized variant of the model for score distillation, giving rise to the Linearized Lookahead Variational Score Distillation ($L^2$-VSD). $L^2$-VSD can be realized efficiently with forward-mode autodiff functionalities of existing deep learning libraries. Extensive experiments validate the efficacy of $L^2$-VSD, revealing its clear superiority over prior score distillation-based methods. We also show that our method can be seamlessly incorporated into any other VSD-based text-to-3D framework.",
      "authors": [
        "Yu Lei",
        "Bingde Liu",
        "Qingsong Xie",
        "Haonan Lu and Zhijie Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.09748v1",
          "size": "37948kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Text-to-3D Generation with Linearized Lookahead Variational Score Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09748",
        "HTML": "https://arxiv.org/html/2507.09748v1",
        "PDF": "https://arxiv.org/pdf/2507.09748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores text-to-3D generation using score distillation and does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09935",
      "abstract": "Retrieval-Augmented Generation (RAG) systems commonly use chunking strategies for retrieval, which enhance large language models (LLMs) by enabling them to access external knowledge, ensuring that the retrieved information is up-to-date and domain-specific. However, traditional methods often fail to create chunks that capture sufficient semantic meaning, as they do not account for the underlying textual structure. This paper proposes a novel framework that enhances RAG by integrating hierarchical text segmentation and clustering to generate more meaningful and semantically coherent chunks. During inference, the framework retrieves information by leveraging both segment-level and cluster-level vector representations, thereby increasing the likelihood of retrieving more precise and contextually relevant information. Evaluations on the NarrativeQA, QuALITY, and QASPER datasets indicate that the proposed method achieved improved results compared to traditional chunking techniques.",
      "authors": [
        "Hai Toan Nguyen",
        "Tien Dat Nguyen and Viet Ha Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:21:58+00:00",
          "link": "https://arxiv.org/abs/2507.09935v1",
          "size": "313kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Retrieval Augmented Generation with Hierarchical Text Segmentation Chunking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09935",
        "HTML": "https://arxiv.org/html/2507.09935v1",
        "PDF": "https://arxiv.org/pdf/2507.09935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a novel framework for constructing semantically coherent data chunks for Retrieval-Augmented Generation, directly involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.06333",
      "abstract": "Quasi two-dimensional Coulomb systems have drawn widespread interest. The reduced symmetry of these systems leads to complex collective behaviors, yet simultaneously poses significant challenges for particle-based simulations. In this paper, a novel method is presented for efficiently simulate a collection of charges confined in doubly-periodic slabs, with the extension to scenarios involving dielectric jumps at slab boundaries. Unlike existing methods, the method is insensitive to the aspect ratio of simulation box, and it achieves optimal O(N) complexity and strong scalability, thanks to the random batch Ewald (RBE) approach. Moreover, the additional cost for polarization contributions, represented as image reflection series, is reduced to a negligible cost via combining the RBE with an efficient structure factor coefficient re-calibration technique in k-space. Explicit formulas for optimal parameter choices of the algorithm are provided through error estimates, together with a rigorous proof. Finally, we demonstrate the accuracy, efficiency and scalability of our method, called RBE2D, via numerical tests across a variety of prototype systems. An excellent agreement between the RBE2D and the PPPM method is observed, with a significant reduction in the computational cost and strong scalability, demonstrating that it is a promising method for a broad range of charged systems under quasi-2D confinement.",
      "authors": [
        "Zecheng Gan",
        "Xuanzhao Gao",
        "Jiuyang Liang",
        "and Zhenli Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-10T09:08:15+00:00",
          "link": "https://arxiv.org/abs/2405.06333v1",
          "size": "6226kb",
          "version": "v1"
        }
      ],
      "title": "Random Batch Ewald Method for Dielectrically Confined Coulomb Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.06333",
        "HTML": "https://arxiv.org/html/2405.06333",
        "PDF": "https://arxiv.org/pdf/2405.06333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel computational method for simulating charges in quasi-2D systems, with no mention of LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12185",
      "abstract": "Assessing the programming capabilities of Large Language Models (LLMs) is crucial for their effective use in software engineering. Current evaluations, however, predominantly measure the accuracy of generated code on static benchmarks, neglecting the critical aspect of model robustness during programming tasks. While adversarial attacks offer insights on model robustness, their effectiveness is limited and evaluation could be constrained. Current adversarial attack methods for robustness evaluation yield inconsistent results, struggling to provide a unified evaluation across different LLMs. We introduce EVALOOP, a novel assessment framework that evaluate the robustness from a self-consistency perspective, i.e., leveraging the natural duality inherent in popular software engineering tasks, e.g., code generation and code summarization. EVALOOP initiates a self-contained feedback loop: an LLM generates output (e.g., code) from an input (e.g., natural language specification), and then use the generated output as the input to produce a new output (e.g., summarizes that code into a new specification). EVALOOP repeats the process to assess the effectiveness of EVALOOP in each loop. This cyclical strategy intrinsically evaluates robustness without rely on any external attack setups, providing a unified metric to evaluate LLMs' robustness in programming. We evaluate 16 prominent LLMs (e.g., GPT-4.1, O4-mini) on EVALOOP and found that EVALOOP typically induces a 5.01%-19.31% absolute drop in pass@1 performance within ten loops. Intriguingly, robustness does not always align with initial performance (i.e., one-time query); for instance, GPT-3.5-Turbo, despite superior initial code generation compared to DeepSeek-V2, demonstrated lower robustness over repeated evaluation loop.",
      "authors": [
        "Sen Fang",
        "Weiyuan Ding",
        "Bowen Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-18T01:02:33+00:00",
          "link": "https://arxiv.org/abs/2505.12185v1",
          "size": "4484kb",
          "version": "v1"
        },
        {
          "date": "2025-06-01T21:54:31+00:00",
          "link": "https://arxiv.org/abs/2505.12185v2",
          "size": "4609kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T05:28:08+00:00",
          "link": "https://arxiv.org/abs/2505.12185v3",
          "size": "4878kb",
          "version": "v3"
        }
      ],
      "title": "EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12185",
        "HTML": "https://arxiv.org/html/2505.12185v3",
        "PDF": "https://arxiv.org/pdf/2505.12185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although EVALOOP involves LLMs, it is primarily concerned with evaluating programming robustness rather than focusing on the processing or creation of LLM training data."
      },
      "tasks": [
        "Adversarial Attack",
        "Code Generation",
        "Code Summarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06269",
      "abstract": "Quantifying uncertainty in neural implicit 3D representations, particularly those utilizing Signed Distance Functions (SDFs), remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. Existing methods typically neglect direct geometric integration, leading to poorly calibrated uncertainty maps. We introduce BayesSDF, a novel probabilistic framework for uncertainty quantification in neural implicit SDF models, motivated by scientific simulation applications with 3D environments (e.g., forests) such as modeling fluid flow through forests, where precise surface geometry and reliable uncertainty estimates are essential. Unlike radiance-based models such as Neural Radiance Fields (NeRF) or 3D Gaussian splatting, which lack explicit surface formulations, Signed Distance Functions (SDFs) define continuous and differentiable geometry, making them better suited for physical modeling and analysis. BayesSDF leverages a Laplace approximation to quantify local surface instability using Hessian-based metrics, enabling efficient, surfaceaware uncertainty estimation. Our method shows that uncertainty predictions correspond closely with poorly reconstructed geometry, providing actionable confidence measures for downstream use. Extensive evaluations on synthetic and real-world datasets demonstrate that BayesSDF outperforms existing methods in both calibration and geometric consistency, establishing a strong foundation for uncertainty-aware 3D scene reconstruction, simulation, and robotic decision-making.",
      "authors": [
        "Rushil Desai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:21:12+00:00",
          "link": "https://arxiv.org/abs/2507.06269v1",
          "size": "13273kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:52:55+00:00",
          "link": "https://arxiv.org/abs/2507.06269v2",
          "size": "13277kb",
          "version": "v2"
        }
      ],
      "title": "BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06269",
        "HTML": "https://arxiv.org/html/2507.06269v2",
        "PDF": "https://arxiv.org/pdf/2507.06269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for uncertainty estimation in 3D geometry using neural implicit SDF models, focusing on uncertainty quantification rather than any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09654",
      "abstract": "We prove that Ranked Pairs orders candidates in such a way as to minimize the $p$-norm, in the limit as $p \\to \\infty$, of those head-to-head margins of victory which go against its ordering.",
      "authors": [
        "Amir Babak Aazami",
        "Hubert L. Bray"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:40:15+00:00",
          "link": "https://arxiv.org/abs/2507.09654v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Ranked Pairs minimizes the $p$-norm as $p \\to \\infty$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09654",
        "HTML": "https://arxiv.org/html/2507.09654v1",
        "PDF": "https://arxiv.org/pdf/2507.09654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about minimizing the p-norm of margins of victory in a voting method, with no mention of LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09822",
      "abstract": "Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at https://darshangm.github.io/papers/active-probing-multimodal-predictions/.",
      "authors": [
        "Darshan Gadginmath",
        "Farhad Nawaz",
        "Minjun Sung",
        "Faizan M Tariq",
        "Sangjae Bae",
        "David Isele",
        "Fabio Pasqualetti",
        "Jovin Dsa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:06:46+00:00",
          "link": "https://arxiv.org/abs/2507.09822v1",
          "size": "653kb",
          "version": "v1"
        }
      ],
      "title": "Active Probing with Multimodal Predictions for Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09822",
        "HTML": "https://arxiv.org/html/2507.09822v1",
        "PDF": "https://arxiv.org/pdf/2507.09822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores autonomous navigation in dynamic environments, focusing on multimodal predictions and decision-making under uncertainty, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10403",
      "abstract": "Retrieving relevant imagery from vast satellite archives is crucial for applications like disaster response and long-term climate monitoring. However, most text-to-image retrieval systems are limited to RGB data, failing to exploit the unique physical information captured by other sensors, such as the all-weather structural sensitivity of Synthetic Aperture Radar (SAR) or the spectral signatures in optical multispectral data. To bridge this gap, we introduce CrisisLandMark, a new large-scale corpus of over 647,000 Sentinel-1 SAR and Sentinel-2 multispectral images paired with structured textual annotations for land cover, land use, and crisis events harmonized from authoritative land cover systems (CORINE and Dynamic World) and crisis-specific sources. We then present CLOSP (Contrastive Language Optical SAR Pretraining), a novel framework that uses text as a bridge to align unpaired optical and SAR images into a unified embedding space. Our experiments show that CLOSP achieves a new state-of-the-art, improving retrieval nDGC by 54% over existing models. Additionally, we find that the unified training strategy overcomes the inherent difficulty of interpreting SAR imagery by transferring rich semantic knowledge from the optical domain with indirect interaction. Furthermore, GeoCLOSP, which integrates geographic coordinates into our framework, creates a powerful trade-off between generality and specificity: while the CLOSP excels at general semantic tasks, the GeoCLOSP becomes a specialized expert for retrieving location-dependent crisis events and rare geographic features. This work highlights that the integration of diverse sensor data and geographic context is essential for unlocking the full potential of remote sensing archives.",
      "authors": [
        "Daniele Rege Cambrin",
        "Lorenzo Vaiani",
        "Giuseppe Gallipoli",
        "Luca Cagliero",
        "Paolo Garza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:46:56+00:00",
          "link": "https://arxiv.org/abs/2507.10403v1",
          "size": "7226kb",
          "version": "v1"
        }
      ],
      "title": "Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10403",
        "HTML": "https://arxiv.org/html/2507.10403v1",
        "PDF": "https://arxiv.org/pdf/2507.10403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces CrisisLandMark, a new corpus with structured textual annotations and details the creation and processing steps involved in aligning unpaired optical and SAR images with text, which is directly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03262",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. While state-of-the-art applications like ChatGPT/GPT-4 commonly employ Proximal Policy Optimization (PPO), the inclusion of a critic network introduces significant computational overhead. REINFORCE-based methods, such as REINFORCE Leave One-Out (RLOO), ReMax, and Group Relative Policy Optimization (GRPO), address this limitation by eliminating the critic network. However, these approaches face challenges in accurate advantage estimation. Specifically, they estimate advantages independently for responses to each prompt, which can lead to overfitting on simpler prompts and vulnerability to reward hacking. To address these challenges, we introduce REINFORCE++, a novel approach that removes the critic model while using the normalized reward of a batch as the baseline. Our empirical evaluation demonstrates that REINFORCE++ exhibits robust performance across various reward models without requiring prompt set truncation. Furthermore, it achieves superior generalization in both RLHF and long chain-of-thought (CoT) settings compared to existing REINFORCE-based methods. The implementation is available at https://github.com/OpenRLHF/OpenRLHF.",
      "authors": [
        "Jian Hu",
        "Jason Klein Liu",
        "Wei Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-04T02:08:06+00:00",
          "link": "https://arxiv.org/abs/2501.03262v1",
          "size": "1283kb",
          "version": "v1"
        },
        {
          "date": "2025-04-03T03:20:56+00:00",
          "link": "https://arxiv.org/abs/2501.03262v2",
          "size": "2387kb",
          "version": "v2"
        },
        {
          "date": "2025-04-06T02:23:29+00:00",
          "link": "https://arxiv.org/abs/2501.03262v3",
          "size": "2387kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T04:17:04+00:00",
          "link": "https://arxiv.org/abs/2501.03262v4",
          "size": "2596kb",
          "version": "v4"
        },
        {
          "date": "2025-07-04T03:51:01+00:00",
          "link": "https://arxiv.org/abs/2501.03262v5",
          "size": "2229kb",
          "version": "v5"
        },
        {
          "date": "2025-07-14T02:04:47+00:00",
          "link": "https://arxiv.org/abs/2501.03262v6",
          "size": "2237kb",
          "version": "v6"
        }
      ],
      "title": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03262",
        "HTML": "https://arxiv.org/html/2501.03262",
        "PDF": "https://arxiv.org/pdf/2501.03262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel RLHF algorithm for LLMs, emphasizing reinforcement learning methodologies rather than training-data processing or dataset creation."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/theeighthday/seekworld",
        "https://github.com/gair-nlp/maye",
        "https://github.com/openrlhf/openrlhf",
        "https://github.com/OpenLLMAI/OpenLLaMA2",
        "https://github.com/OpenLLMAI/OpenRLHF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17229",
      "abstract": "Evidence is presented that the accuracy of Nonextensive Statistical Mechanics framework is improved using the coupled entropy, which carefully establishes the physical measures of complex systems. While Nonextensive Statistical Mechanics (NSM) has developed into a powerful toolset, questions have persisted as to how to evaluate whether its proposed solutions properly characterize the uncertainty of heavy-tailed distributions. The entropy of the generalized Pareto distribution (GPD) is $1+\\kappa+\\ln\\sigma$, where $\\kappa$ is the shape or nonlinear coupling and $\\sigma$ is the scale. A generalized entropy should retain the uncertainty due to the scale, while minimizing the dependence of the nonlinear coupling. The Tsallis entropy of the GPD instead subtracts a function of the inverse-scale and converges to one as $\\kappa\\rightarrow\\infty$. Colloquially, the Tsallis entropy is too cold. The normalized Tsallis entropy (NTE) rectifies the positive dependence on the scale but introduces a nonlinear term multiplying the scale and the coupling, making it too hot. The coupled entropy measures the uncertainty of the GPD to be $1+\\ln_\\frac{\\kappa}{1+\\kappa}\\sigma=1+\\frac{1+\\kappa}{\\kappa}(\\sigma^\\frac{\\kappa}{1+\\kappa}-1)$, which converges to $\\sigma$ as $\\kappa\\rightarrow\\infty$. One could say, the coupled entropy allows scientists, engineers, and analysts to eat their porridge, confident that its measure of uncertainty reflects the mathematical physics of the scale of non-exponential distributions while minimizing the dependence on the shape or nonlinear coupling. The training of the coupled variational autoencoder is an example of the unique ability of the coupled entropy to improve the performance of complex systems.",
      "authors": [
        "Kenric P. Nelson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-17T19:00:25+00:00",
          "link": "https://arxiv.org/abs/2506.17229v1",
          "size": "12kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T22:29:23+00:00",
          "link": "https://arxiv.org/abs/2506.17229v2",
          "size": "50kb",
          "version": "v2"
        }
      ],
      "title": "Coupled Entropy: A Goldilocks Generalization for Nonextensive Statistical Mechanics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17229",
        "HTML": "https://arxiv.org/html/2506.17229v2",
        "PDF": "https://arxiv.org/pdf/2506.17229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on statistical mechanics and entropy in complex systems. There is no discussion on processing LLM training data or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21278",
      "abstract": "We propose a novel variational autoencoder (VAE) architecture that employs a spherical Cauchy (spCauchy) latent distribution. Unlike traditional Gaussian latent spaces or the widely used von Mises-Fisher (vMF) distribution, spCauchy provides a more natural hyperspherical representation of latent variables, better capturing directional data while maintaining flexibility. Its heavy-tailed nature prevents over-regularization, ensuring efficient latent space utilization while offering a more expressive representation. Additionally, spCauchy circumvents the numerical instabilities inherent to vMF, which arise from computing normalization constants involving Bessel functions. Instead, it enables a fully differentiable and efficient reparameterization trick via M\\\"obius transformations, allowing for stable and scalable training. The KL divergence can be computed through a rapidly converging power series, eliminating concerns of underflow or overflow associated with evaluation of ratios of hypergeometric functions. These properties make spCauchy a compelling alternative for VAEs, offering both theoretical advantages and practical efficiency in high-dimensional generative modeling.",
      "authors": [
        "Lukas Sablica",
        "Kurt Hornik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:01:51+00:00",
          "link": "https://arxiv.org/abs/2506.21278v1",
          "size": "785kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T10:06:29+00:00",
          "link": "https://arxiv.org/abs/2506.21278v2",
          "size": "785kb",
          "version": "v2"
        }
      ],
      "title": "Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21278",
        "HTML": "https://arxiv.org/html/2506.21278v2",
        "PDF": "https://arxiv.org/pdf/2506.21278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel variational autoencoder architecture and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23121",
      "abstract": "Multi-organ medical segmentation is a crucial component of medical image processing, essential for doctors to make accurate diagnoses and develop effective treatment plans. Despite significant progress in this field, current multi-organ segmentation models often suffer from inaccurate details, dependence on geometric prompts and loss of spatial information. Addressing these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal Interaction and Semantic Prompting based on SAM2. This model represents a promising approach to multi-organ medical segmentation guided by textual descriptions of organs. Our method begins by converting visual and textual inputs into cross-modal contextualized semantics using a progressive cross-attention interaction mechanism. These semantics are then injected into the image encoder to enhance the detailed understanding of visual information. To eliminate reliance on geometric prompts, we use a semantic prompting strategy, replacing the original prompt encoder to sharpen the perception of challenging targets. In addition, a similarity-sorting self-updating strategy for memory and a mask-refining process is applied to further adapt to medical imaging and enhance localized details. Comparative experiments conducted on seven public datasets indicate that CRISP-SAM2 outperforms existing models. Extensive analysis also demonstrates the effectiveness of our method, thereby confirming its superior performance, especially in addressing the limitations mentioned earlier. Our code is available at: https://github.com/YU-deep/CRISP_SAM2.git.",
      "authors": [
        "Xinlei Yu",
        "Changmiao Wang",
        "Hui Jin",
        "Ahmed Elazab",
        "Gangyong Jia",
        "Xiang Wan",
        "Changqing Zou",
        "Ruiquan Ge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:05:27+00:00",
          "link": "https://arxiv.org/abs/2506.23121v1",
          "size": "3210kb",
          "version": "v1"
        },
        {
          "date": "2025-07-06T02:53:08+00:00",
          "link": "https://arxiv.org/abs/2506.23121v2",
          "size": "3211kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T02:03:48+00:00",
          "link": "https://arxiv.org/abs/2506.23121v3",
          "size": "3213kb",
          "version": "v3"
        }
      ],
      "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23121",
        "HTML": "https://arxiv.org/html/2506.23121v3",
        "PDF": "https://arxiv.org/pdf/2506.23121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for multi-organ segmentation, focusing on improving model architecture and segmentation techniques, not on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08973",
      "abstract": "As we move towards a future of autonomous vehicles, questions regarding their method of communication have arisen. One of the common questions concerns the placement of the signaling used to communicate with pedestrians and road users, but little work has been published fully dedicated to exploring this. This paper uses a simulation made in the Unity game engine to record the visibility of fifteen different vehicles, specifically regarding the visibility of frontal elements by a pedestrian on the sidewalk. Variables include the vehicle position, number of vehicles on the road, and minimum and maximum distance of the recorded points. It was concluded that the areas of the vehicle most often seen by pedestrians on the sidewalk attempting to cross the road were the frontal frontal fenders and the headlights, with the frontal wheels, frontal doors, bumper, and side mirrors are less visible alternatives. These findings are valuable in the future design of signaling for autonomous vehicles, in order to ensure pedestrians are able to see them on approaching vehicles. The software used provides a platform for similar works in the future to be conducted.",
      "authors": [
        "Jose Gonzalez-Belmonte and Jaerock Kwon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:04:23+00:00",
          "link": "https://arxiv.org/abs/2507.08973v1",
          "size": "9716kb",
          "version": "v1"
        }
      ],
      "title": "Analytical Study on the Visibility of Potential Positions for External Human-Machine Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08973",
        "HTML": "https://arxiv.org/html/2507.08973v1",
        "PDF": "https://arxiv.org/pdf/2507.08973"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses signaling methods for autonomous vehicles and does not focus on any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09092",
      "abstract": "With the intervention of machine vision in our crucial day to day necessities including healthcare and automated power plants, attention has been drawn to the internal mechanisms of convolutional neural networks, and the reason why the network provides specific inferences. This paper proposes a novel post-hoc visual explanation method called MI CAM based on activation mapping. Differing from previous class activation mapping based approaches, MI CAM produces saliency visualizations by weighing each feature map through its mutual information with the input image and the final result is generated by a linear combination of weights and activation maps. It also adheres to producing causal interpretations as validated with the help of counterfactual analysis. We aim to exhibit the visual performance and unbiased justifications for the model inferencing procedure achieved by MI CAM. Our approach works at par with all state-of-the-art methods but particularly outperforms some in terms of qualitative and quantitative measures. The implementation of proposed method can be found on https://anonymous.4open.science/r/MI-CAM-4D27",
      "authors": [
        "Ram S Iyer",
        "Narayan S Iyer",
        "Rugmini Ammal P"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:20:32+00:00",
          "link": "https://arxiv.org/abs/2507.09092v1",
          "size": "10639kb",
          "version": "v1"
        }
      ],
      "title": "MI CAM: Mutual Information Weighted Activation Mapping for Causal Visual Explanations of Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09092",
        "HTML": "https://arxiv.org/html/2507.09092v1",
        "PDF": "https://arxiv.org/pdf/2507.09092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for visual explanations of convolutional neural networks and does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09545",
      "abstract": "The usage of eXplainable Artificial Intelligence (XAI) methods has become essential in practical applications, given the increasing deployment of Artificial Intelligence (AI) models and the legislative requirements put forward in the latest years. A fundamental but often underestimated aspect of the explanations is their robustness, a key property that should be satisfied in order to trust the explanations. In this study, we provide some preliminary insights on evaluating the reliability of explanations in the specific case of unbalanced datasets, which are very frequent in high-risk use-cases, but at the same time considerably challenging for both AI models and XAI methods. We propose a simple evaluation focused on the minority class (i.e. the less frequent one) that leverages on-manifold generation of neighbours, explanation aggregation and a metric to test explanation consistency. We present a use-case based on a tabular dataset with numerical features focusing on the occurrence of frost events.",
      "authors": [
        "Ilaria Vascotto",
        "Valentina Blasone",
        "Alex Rodriguez",
        "Alessandro Bonaita",
        "Luca Bortolussi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T09:12:38+00:00",
          "link": "https://arxiv.org/abs/2507.09545v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Assessing reliability of explanations in unbalanced datasets: a use-case on the occurrence of frost events",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09545",
        "PDF": "https://arxiv.org/pdf/2507.09545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses explainable AI and robustness of explanations in unbalanced datasets, which does not relate to LLM training data processing or involve modifications to LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10352",
      "abstract": "This work presents several improvements to the closed-loop stability verification framework using semialgebraic sets and convex semidefinite programming to examine neural-network-based control systems regulating nonlinear dynamical systems. First, the utility of the framework is greatly expanded: two semialgebraic functions mimicking common, smooth activation functions are presented and compatibility with control systems incorporating Recurrent Equilibrium Networks (RENs) and thereby Recurrent Neural Networks (RNNs) is established. Second, the validity of the framework's state-of-the-art stability analyses is established via an alternate proof. Third, based on this proof, two new optimization problems simplifying the analysis of local stability properties are presented. To simplify the analysis of a closed-loop system's Region of Attraction (RoA), the first problem explicitly parameterizes a class of candidate Lyapunov functions larger than in previous works. The second problem utilizes the unique guarantees available under the condition of invariance to further expand the set of candidate Lyapunov functions and directly determine whether an invariant set forms part of the system's RoA. These contributions are successfully demonstrated in two numerical examples and suggestions for future research are provided.",
      "authors": [
        "Alvaro Detailleur",
        "Guillaume Ducard",
        "Christopher Onder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:54:19+00:00",
          "link": "https://arxiv.org/abs/2507.10352v1",
          "size": "157kb",
          "version": "v1"
        }
      ],
      "title": "Improved Sum-of-Squares Stability Verification of Neural-Network-Based Controllers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10352",
        "PDF": "https://arxiv.org/pdf/2507.10352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on stability verification of neural network-based controllers, which does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.19919",
      "abstract": "We study infinite-horizon average-reward reinforcement learning (RL) for Lipschitz MDPs, a broad class that subsumes several important classes such as linear and RKHS MDPs, function approximation frameworks, and develop an adaptive algorithm $\\text{ZoRL}$ with regret bounded as $\\mathcal{O}\\big(T^{1 - d_{\\text{eff.}}^{-1}}\\big)$, where $d_{\\text{eff.}}= 2d_\\mathcal{S} + d_z + 3$, $d_\\mathcal{S}$ is the dimension of the state space and $d_z$ is the zooming dimension. In contrast, algorithms with fixed discretization yield $d_{\\text{eff.}} = 2(d_\\mathcal{S} + d_\\mathcal{A}) + 2$, $d_\\mathcal{A}$ being the dimension of action space. $\\text{ZoRL}$ achieves this by discretizing the state-action space adaptively and zooming into ''promising regions'' of the state-action space. $d_z$, a problem-dependent quantity bounded by the state-action space's dimension, allows us to conclude that if an MDP is benign, then the regret of $\\text{ZoRL}$ will be small. The zooming dimension and $\\text{ZoRL}$ are truly adaptive, i.e., the current work shows how to capture adaptivity gains for infinite-horizon average-reward RL. $\\text{ZoRL}$ outperforms other state-of-the-art algorithms in experiments, thereby demonstrating the gains arising due to adaptivity.",
      "authors": [
        "Avik Kar",
        "Rahul Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T18:14:42+00:00",
          "link": "https://arxiv.org/abs/2410.19919v1",
          "size": "7046kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T20:29:21+00:00",
          "link": "https://arxiv.org/abs/2410.19919v2",
          "size": "2418kb",
          "version": "v2"
        }
      ],
      "title": "Provably Adaptive Average Reward Reinforcement Learning for Metric Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19919",
        "HTML": "https://arxiv.org/html/2410.19919v2",
        "PDF": "https://arxiv.org/pdf/2410.19919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses reinforcement learning in metric spaces and adaptive algorithms without involving LLM training data processing, engineering, or creation."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23146",
      "abstract": "In-context learning (ICL) has emerged as an effective approach to enhance the performance of large language models (LLMs). However, its effectiveness varies significantly across models and tasks, posing challenges for practitioners to determine when ICL reliably improves performance. Current evaluation approaches, reliant on performance change after applying ICL, suffer from low reliability, poor attribution, and impracticality in data-insufficient scenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that quantifies ICL effectiveness by modeling the slope between learning gain (loss decrease from demonstrations) and contextual relevance (demonstration-input relevance). LCS addresses key limitations of performance-based metrics: (1) it captures continuous loss changes even when outputs are incorrect, improving reliability; (2) its formulation attributes ICL failures to weak contextual alignment (inability to adapt inputs to demonstrations) or strong output calibration (self-verification of correctness); and (3) it minimizes reliance on labeled data via synthetic evaluation. Extensive experiments demonstrate that LCS strongly correlates with performance improvements in labeled settings and reliably reflects true effectiveness in biased or data-scarce scenarios. Further analysis reveals actionable thresholds for LCS and identifies model capabilities critical to ICL success.",
      "authors": [
        "Dingzriui Wang",
        "Xuanliang Zhang",
        "Keyan Xu",
        "Qingfu Zhu",
        "Wanxiang Che",
        "Yang Deng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:55:37+00:00",
          "link": "https://arxiv.org/abs/2506.23146v1",
          "size": "4679kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T07:03:17+00:00",
          "link": "https://arxiv.org/abs/2506.23146v2",
          "size": "4673kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T15:01:01+00:00",
          "link": "https://arxiv.org/abs/2506.23146v3",
          "size": "4673kb",
          "version": "v3"
        }
      ],
      "title": "Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23146",
        "PDF": "https://arxiv.org/pdf/2506.23146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper focuses on a novel evaluation metric for in-context learning, it mentions synthetic evaluation data, but does not primarily address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08850",
      "abstract": "Communities worldwide increasingly confront flood hazards intensified by climate change, urban expansion, and environmental degradation. Addressing these challenges requires real-time flood analysis, precise flood forecasting, and robust risk communications with stakeholders to implement efficient mitigation strategies. Recent advances in hydrodynamic modeling and digital twins afford new opportunities for high-resolution flood modeling and visualization at the street and basement levels. Focusing on Galveston City, a barrier island in Texas, U.S., this study created a geospatial digital twin (GDT) supported by 1D-2D coupled hydrodynamic models to strengthen urban resilience to pluvial and fluvial flooding. The objectives include: (1) developing a GDT (FlowsDT-Galveston) incorporating topography, hydrography, and infrastructure; (2) validating the twin using historical flood events and social sensing; (3) modeling hyperlocal flood conditions under 2-, 10-, 25-, 50-, and 100-year return period rainfall scenarios; and (4) identifying at-risk zones under different scenarios. This study employs the PCSWMM to create dynamic virtual replicas of urban landscapes and accurate flood modeling. By integrating LiDAR data, land cover, and storm sewer geometries, the model can simulate flood depth, extent, duration, and velocity in a 4-D environment across different historical and design storms. Results show buildings inundated over one foot increased by 5.7% from 2- to 100-year flood. Road inundations above 1 foot increased by 6.7% from 2- to 100-year floods. The proposed model can support proactive flood management and urban planning in Galveston; and inform disaster resilience efforts and guide sustainable infrastructure development. The framework can be extended to other communities facing similar challenges.",
      "authors": [
        "Debayan Mandal",
        "Lei Zou",
        "Abhinav Wadhwa",
        "Rohan Singh Wilkho",
        "Zhenhang Cai",
        "Bing Zhou",
        "Xinyue Ye",
        "Galen Newman",
        "Nasir Gharaibeh",
        "Burak G\\\"uneralp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:41:10+00:00",
          "link": "https://arxiv.org/abs/2507.08850v1",
          "size": "5163kb",
          "version": "v1"
        }
      ],
      "title": "FlowsDT: A Geospatial Digital Twin for Navigating Urban Flood Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08850",
        "PDF": "https://arxiv.org/pdf/2507.08850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details flood modeling using a geospatial digital twin, unrelated to any LLM training data processing or dataset creation methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08861",
      "abstract": "This paper proposes sharp lower bounds for the number of message passing iterations required in graph neural networks (GNNs) when solving partial differential equations (PDE). This significantly reduces the need for exhaustive hyperparameter tuning. Bounds are derived for the three fundamental classes of PDEs (hyperbolic, parabolic and elliptic) by relating the physical characteristics of the problem in question to the message-passing requirement of GNNs. In particular, we investigate the relationship between the physical constants of the equations governing the problem, the spatial and temporal discretisation and the message passing mechanisms in GNNs.\n  When the number of message passing iterations is below these proposed limits, information does not propagate efficiently through the network, resulting in poor solutions, even for deep GNN architectures. In contrast, when the suggested lower bound is satisfied, the GNN parameterisation allows the model to accurately capture the underlying phenomenology, resulting in solvers of adequate accuracy.\n  Examples are provided for four different examples of equations that show the sharpness of the proposed lower bounds.",
      "authors": [
        "Lucas Tesan and Mikel M. Iparraguirre and David Gonzalez and Pedro Martins and Elias Cueto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:50:10+00:00",
          "link": "https://arxiv.org/abs/2507.08861v1",
          "size": "11634kb",
          "version": "v1"
        }
      ],
      "title": "On the under-reaching phenomenon in message-passing neural PDE solvers: revisiting the CFL condition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08861",
        "HTML": "https://arxiv.org/html/2507.08861v1",
        "PDF": "https://arxiv.org/pdf/2507.08861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on message-passing iterations in graph neural networks for solving PDEs, without any mention of processing or creating LLM training data or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09263",
      "abstract": "This paper introduces a three-dimensional (3-D) mathematical and computational framework for the characterization of crack-tip fields in star-shaped cracks within porous elastic solids. A core emphasis of this model is its direct integration of density-dependent elastic moduli, offering a more physically realistic representation of engineering materials where intrinsic porosity and density profoundly influence mechanical behavior. The governing boundary value problem, formulated for the static equilibrium of a 3-D, homogeneous, and isotropic material, manifests as a system of second-order, quasilinear partial differential equations. This system is meticulously coupled with classical traction-free boundary conditions imposed at the complex crack surface. For the robust numerical solution of this intricate nonlinear problem, we employ a continuous trilinear Galerkin-type finite element discretization. The inherent strong nonlinearities arising within the discrete system are effectively managed through a powerful and stable {Picard-type linearization scheme}. The proposed model demonstrates a remarkable ability to accurately describe the full stress and strain states in a diverse range of materials, crucially recovering the well-established classical singularities observed in linearized elastic fracture mechanics. A comprehensive numerical examination of tensile stress, strain, and strain energy density fields consistently reveals that these quantities attain their peak values in the immediate vicinity of the crack tip, an observation that remarkably aligns with established findings in standard linearized elastic fracture mechanics.",
      "authors": [
        "S. M. Mallikarjunaiah and Kun Gou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T12:00:13+00:00",
          "link": "https://arxiv.org/abs/2507.09263v1",
          "size": "1440kb",
          "version": "v1"
        }
      ],
      "title": "Crack-tip field characterization in nonlinearly constituted and geometrically linear elastoporous solid containing a star-shaped crack: A finite element study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09263",
        "HTML": "https://arxiv.org/html/2507.09263v1",
        "PDF": "https://arxiv.org/pdf/2507.09263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a study on crack-tip fields in materials using finite element analysis, unrelated to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09524",
      "abstract": "Recent advancements in unpaired dehazing, particularly those using GANs, show promising performance in processing real-world hazy images. However, these methods tend to face limitations due to the generator's limited transport mapping capability, which hinders the full exploitation of their effectiveness in unpaired training paradigms. To address these challenges, we propose DehazeSB, a novel unpaired dehazing framework based on the Schr\\\"odinger Bridge. By leveraging optimal transport (OT) theory, DehazeSB directly bridges the distributions between hazy and clear images. This enables optimal transport mappings from hazy to clear images in fewer steps, thereby generating high-quality results. To ensure the consistency of structural information and details in the restored images, we introduce detail-preserving regularization, which enforces pixel-level alignment between hazy inputs and dehazed outputs. Furthermore, we propose a novel prompt learning to leverage pre-trained CLIP models in distinguishing hazy images and clear ones, by learning a haze-aware vision-language alignment. Extensive experiments on multiple real-world datasets demonstrate our method's superiority. Code: https://github.com/ywxjm/DehazeSB.",
      "authors": [
        "Yunwei Lan",
        "Zhigao Cui",
        "Xin Luo",
        "Chang Liu",
        "Nian Wang",
        "Menglin Zhang",
        "Yanzhao Su",
        "Dong Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T07:39:44+00:00",
          "link": "https://arxiv.org/abs/2507.09524v1",
          "size": "8529kb",
          "version": "v1"
        }
      ],
      "title": "When Schr\\\"odinger Bridge Meets Real-World Image Dehazing with Unpaired Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09524",
        "HTML": "https://arxiv.org/html/2507.09524v1",
        "PDF": "https://arxiv.org/pdf/2507.09524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel framework for unpaired image dehazing with optimal transport, which does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09741",
      "abstract": "In this article, we consider the decoding problem of affine Grassmann codes over nonbinary fields. We use matrices of different ranks to construct a large set consisting of parity checks of affine Grassmann codes, which are orthogonal with respect to a fixed coordinate. By leveraging the automorphism groups of these codes, we generate a set of orthogonal parity checks for each coordinate. Using these parity checks, we perform majority logic decoding to correct a large number of errors in affine Grassmann codes. The order of error correction capability and the complexity of this decoder for affine Grassmann codes are the same as those of the majority logic decoder for Grassmann codes proposed in [BS21].",
      "authors": [
        "Fernando Pi\\~nero Gonz\\'alez",
        "Prasant Singh",
        "and Rohit Yadav"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:37:54+00:00",
          "link": "https://arxiv.org/abs/2507.09741v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Majority Logic Decoding of Affine Grassmann Codes Over Nonbinary Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09741",
        "HTML": "https://arxiv.org/html/2507.09741v1",
        "PDF": "https://arxiv.org/pdf/2507.09741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses error correction in affine Grassmann codes, utilizing parity checks and majority logic decoding. It does not cover LLM training data processing or involve any dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10313",
      "abstract": "We present a demo of DQLoRA, an Adapter-Guided Distillation framework for robust speech recognition under low-resource and noisy conditions. Our method employs a frozen Whisper model as the teacher to provide semantic supervision, and a lightweight Wav2Vec2 student equipped with QLoRA-based Adapters. Training is conducted on the FLEURS dataset augmented with DNS-style noise. The student is optimized by jointly minimizing CTC loss and KL-based distillation loss, enabling efficient adaptation while preserving recognition accuracy.",
      "authors": [
        "Yiru Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:16:40+00:00",
          "link": "https://arxiv.org/abs/2507.10313v1",
          "size": "789kb",
          "version": "v1"
        }
      ],
      "title": "DQLoRA: A Lightweight Domain-Aware Denoising ASR via Adapter-guided Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10313",
        "PDF": "https://arxiv.org/pdf/2507.10313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for robust speech recognition using a frozen Whisper model and lightweight Wav2Vec2 student with QLoRA-based Adapters. It does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10427",
      "abstract": "Socially Assistive Robotics (SAR) has shown promise in supporting emotion regulation for neurodivergent children. Recently, there has been increasing interest in leveraging advanced technologies to assist parents in co-regulating emotions with their children. However, limited research has explored the integration of large language models (LLMs) with SAR to facilitate emotion co-regulation between parents and children with neurodevelopmental disorders. To address this gap, we developed an LLM-powered social robot by deploying a speech communication module on the MiRo-E robotic platform. This supervised autonomous system integrates LLM prompts and robotic behaviors to deliver tailored interventions for both parents and neurodivergent children. Pilot tests were conducted with two parent-child dyads, followed by a qualitative analysis. The findings reveal MiRo-E's positive impacts on interaction dynamics and its potential to facilitate emotion regulation, along with identified design and technical challenges. Based on these insights, we provide design implications to advance the future development of LLM-powered SAR for mental health applications.",
      "authors": [
        "Jing Li and Felix Schijve and Sheng Li and Yuye Yang and Jun Hu and Emilia Barakova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:16:12+00:00",
          "link": "https://arxiv.org/abs/2507.10427v1",
          "size": "2054kb",
          "version": "v1"
        }
      ],
      "title": "Towards Emotion Co-regulation with LLM-powered Socially Assistive Robots: Integrating LLM Prompts and Robotic Behaviors to Support Parent-Neurodivergent Child Dyads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10427",
        "HTML": "https://arxiv.org/html/2507.10427v1",
        "PDF": "https://arxiv.org/pdf/2507.10427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating large language models with socially assistive robots for emotion co-regulation, which is a specific application of LLMs. It does not discuss data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.01876",
      "abstract": "This paper focuses on finding approximate solutions to stochastic optimal control problems with control domains being not necessarily convex, where the state trajectory is subject to controlled stochastic differential equations. The control-dependent diffusions make the traditional method of successive approximations (MSA) insufficient to reduce the value of cost functional in each iteration. Without adding extra terms over which to perform the Hamiltonian minimization, the MSA becomes sufficient by our novel error estimate involving a higher order backward adjoint equation. Under certain convexity assumptions on the coefficients (no convexity assumptions on the control domains), the value of the cost functional descends to the global minimum as the number of iterations tends to infinity. In particular, a convergence rate is available for a class of generalized linear-quadratic systems.",
      "authors": [
        "Shaolin Ji",
        "Rundong Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-05T08:15:33+00:00",
          "link": "https://arxiv.org/abs/2207.01876v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:32:19+00:00",
          "link": "https://arxiv.org/abs/2207.01876v2",
          "size": "42kb",
          "version": "v2"
        }
      ],
      "title": "Global Convergence of Successive Approximations for Non-convex Stochastic Optimal Control Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.01876",
        "HTML": "https://arxiv.org/html/2207.01876v2",
        "PDF": "https://arxiv.org/pdf/2207.01876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses mathematical solutions to non-convex stochastic optimal control problems and does not pertain to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09466",
      "abstract": "Recently, many generative models for de novo protein structure design have emerged. Yet, only few tackle the difficult task of directly generating fully atomistic structures jointly with the underlying amino acid sequence. This is challenging, for instance, because the model must reason over side chains that change in length during generation. We introduce La-Proteina for atomistic protein design based on a novel partially latent protein representation: coarse backbone structure is modeled explicitly, while sequence and atomistic details are captured via per-residue latent variables of fixed dimensionality, thereby effectively side-stepping challenges of explicit side-chain representations. Flow matching in this partially latent space then models the joint distribution over sequences and full-atom structures. La-Proteina achieves state-of-the-art performance on multiple generation benchmarks, including all-atom co-designability, diversity, and structural validity, as confirmed through detailed structural analyses and evaluations. Notably, La-Proteina also surpasses previous models in atomistic motif scaffolding performance, unlocking critical atomistic structure-conditioned protein design tasks. Moreover, La-Proteina is able to generate co-designable proteins of up to 800 residues, a regime where most baselines collapse and fail to produce valid samples, demonstrating La-Proteina's scalability and robustness.",
      "authors": [
        "Tomas Geffner",
        "Kieran Didi",
        "Zhonglin Cao",
        "Danny Reidenbach",
        "Zuobai Zhang",
        "Christian Dallago",
        "Emine Kucukbenli",
        "Karsten Kreis",
        "Arash Vahdat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:01:50+00:00",
          "link": "https://arxiv.org/abs/2507.09466v1",
          "size": "9946kb",
          "version": "v1"
        }
      ],
      "title": "La-Proteina: Atomistic Protein Generation via Partially Latent Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09466",
        "HTML": "https://arxiv.org/html/2507.09466v1",
        "PDF": "https://arxiv.org/pdf/2507.09466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about generative models for protein structure design, specifically La-Proteina, and does not cover LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09646",
      "abstract": "This paper presents a novel identification approach of Koopman models of nonlinear systems with inputs under rather general noise conditions. The method uses deep state-space encoders based on the concept of state reconstructability and an efficient multiple-shooting formulation of the squared loss of the prediction error to estimate the dynamics and the lifted state from input-output data. Furthermore, the Koopman model structure includes an innovation noise term that is used to handle process and measurement noise. It is shown that the proposed approach is statistically consistent and computationally efficient due to the multiple-shooting formulation where, on subsections of the data, multi-step prediction errors can be calculated in parallel. The latter allows for efficient batch optimization of the network parameters and, at the same time, excellent long-term prediction capabilities of the obtained models. The performance of the approach is illustrated by nonlinear benchmark examples.",
      "authors": [
        "Lucian Cristian Iacob",
        "M\\'at\\'e Sz\\'ecsi",
        "Gerben Izaak Beintema",
        "Maarten Schoukens",
        "Roland T\\'oth"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:20:19+00:00",
          "link": "https://arxiv.org/abs/2507.09646v1",
          "size": "2753kb",
          "version": "v1"
        }
      ],
      "title": "Learning Koopman Models From Data Under General Noise Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09646",
        "HTML": "https://arxiv.org/html/2507.09646v1",
        "PDF": "https://arxiv.org/pdf/2507.09646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on identifying Koopman models for nonlinear systems with noise conditions, primarily dealing with state-space encoders and prediction errors, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10011",
      "abstract": "Components of electrical power systems are susceptible to failures caused by lightning strikes, aging or human errors. These faults can cause equipment damage, affect system reliability, and results in expensive repair costs. As electric power systems are becoming more complex, traditional protection methods face limitations and shortcomings. Faults in power systems can occur at anytime and anywhere, can be caused by a natural disaster or an accident, and their occurrence can be hardly predicted or avoided; therefore, it is crucial to accurately estimate the fault location and quickly restore service. The development of methods capable of accurately detecting, locating and removing faults is essential (i.e. fast isolation of faults is necessary to maintain the system stability at transmission levels; accurate and fast detection and location of faults are essential for increasing reliability and customer satisfaction at distribution levels). This has motivated the development of new and more efficient methods. Methods developed to detect and locate faults in power systems can be divided into two categories, conventional and artificial intelligence-based techniques. Although the utilization of artificial intelligence (AI) techniques offer tremendous potential, they are challenging and time consuming (i.e. many AI techniques require training data for processing). This paper presents a survey of the application of AI techniques to fault diagnosis (detection, classification and location of faults) of lines and cables of power systems at both transmission and distribution levels. The paper provides a short introduction to AI concepts, a brief summary of the application of AI techniques to power system analysis and design, and a discussion on AI-based fault diagnosis methods.",
      "authors": [
        "Juan A. Martinez-Velasco",
        "Alexandre Serrano-Fontova",
        "Ricard Bosch-Tous",
        "Pau Casals-Torrens"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:46:56+00:00",
          "link": "https://arxiv.org/abs/2507.10011v1",
          "size": "1916kb",
          "version": "v1"
        }
      ],
      "title": "Survey on Methods for Detection, Classification and Location of Faults in Power Systems Using Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10011",
        "PDF": "https://arxiv.org/pdf/2507.10011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey examines AI methods for fault detection in power systems, which involves AI technique applications and not LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10381",
      "abstract": "Topological data analysis (TDA) is a relatively new field that is gaining rapid adoption due to its robustness and ability to effectively describe complex datasets by quantifying geometric information. In imaging contexts, TDA typically models data as filtered cubical complexes from which we can extract discriminative features using persistence homology. Meanwhile, convolutional neural networks (CNNs) have been shown to be biased towards texture based local features. To address this limitation, we propose a TDA feature engineering pipeline and a simple method to integrate topological features with deep learning models on remote sensing classification. Our method improves the performance of a ResNet18 model on the EuroSAT dataset by 1.44% achieving 99.33% accuracy, which surpasses all previously reported single-model accuracies, including those with larger architectures, such as ResNet50 (2x larger) and XL Vision Transformers (197x larger). We additionally show that our method's accuracy is 1.82% higher than our ResNet18 baseline on the RESISC45 dataset. To our knowledge, this is the first application of TDA features in satellite scene classification with deep learning. This demonstrates that TDA features can be integrated with deep learning models, even on datasets without explicit topological structures, thereby increasing the applicability of TDA. A clean implementation of our method will be made publicly available upon publication.",
      "authors": [
        "Aaryam Sharma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:22:29+00:00",
          "link": "https://arxiv.org/abs/2507.10381v1",
          "size": "504kb",
          "version": "v1"
        }
      ],
      "title": "Improving Remote Sensing Classification using Topological Data Analysis and Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10381",
        "HTML": "https://arxiv.org/html/2507.10381v1",
        "PDF": "https://arxiv.org/pdf/2507.10381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses feature engineering with topological data analysis and CNNs, it does not involve LLM training data processing or related data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04607",
      "abstract": "Large language model (LLM) personalization aims to align model outputs with individuals' unique preferences and opinions. While recent efforts have implemented various personalization methods, a unified theoretical framework that can systematically understand the drivers of effective personalization is still lacking. In this work, we integrate the well-established cognitive dual-memory model into LLM personalization, by mirroring episodic memory to historical user engagements and semantic memory to long-term, evolving user beliefs. Specifically, we systematically investigate memory instantiations and introduce a unified framework, PRIME, using episodic and semantic memory mechanisms. We further augment PRIME with a novel personalized thinking capability inspired by the slow thinking strategy. Moreover, recognizing the absence of suitable benchmarks, we introduce a dataset using Change My View (CMV) from Reddit, specifically designed to evaluate long-context personalization. Extensive experiments validate PRIME's effectiveness across both long- and short-context scenarios. Further analysis confirms that PRIME effectively captures dynamic personalization beyond mere popularity biases.",
      "authors": [
        "Xinliang Frederick Zhang",
        "Nick Beauchamp",
        "Lu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T01:54:34+00:00",
          "link": "https://arxiv.org/abs/2507.04607v1",
          "size": "863kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:54:45+00:00",
          "link": "https://arxiv.org/abs/2507.04607v2",
          "size": "847kb",
          "version": "v2"
        }
      ],
      "title": "PRIME: Large Language Model Personalization with Cognitive Memory and Thought Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04607",
        "HTML": "https://arxiv.org/html/2507.04607v2",
        "PDF": "https://arxiv.org/pdf/2507.04607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a personalization framework for LLMs, which includes a dataset for evaluation. It touches on data handling for personalization but doesn't focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09216",
      "abstract": "Due to the current lack of large-scale datasets at the million-scale level, tasks involving panoramic images predominantly rely on existing two-dimensional pre-trained image benchmark models as backbone networks. However, these networks are not equipped to recognize the distortions and discontinuities inherent in panoramic images, which adversely affects their performance in such tasks. In this paper, we introduce a novel spherical sampling method for panoramic images that enables the direct utilization of existing pre-trained models developed for two-dimensional images. Our method employs spherical discrete sampling based on the weights of the pre-trained models, effectively mitigating distortions while achieving favorable initial training values. Additionally, we apply the proposed sampling method to panoramic image segmentation, utilizing features obtained from the spherical model as masks for specific channel attentions, which yields commendable results on commonly used indoor datasets, Stanford2D3D.",
      "authors": [
        "Jingguo Liu and Han Yu and Shigang Li and Jianfeng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:18:30+00:00",
          "link": "https://arxiv.org/abs/2507.09216v1",
          "size": "4721kb",
          "version": "v1"
        }
      ],
      "title": "360-Degree Full-view Image Segmentation by Spherical Convolution compatible with Large-scale Planar Pre-trained Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09216",
        "HTML": "https://arxiv.org/html/2507.09216v1",
        "PDF": "https://arxiv.org/pdf/2507.09216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on spherical convolution and image segmentation improvements, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09491",
      "abstract": "Existing video benchmarks often resemble image-based benchmarks, with question types like \"What actions does the person perform throughout the video?\" or \"What color is the woman's dress in the video?\" For these, models can often answer by scanning just a few key frames, without deep temporal reasoning. This limits our ability to assess whether large vision-language models (LVLMs) can truly think with videos rather than perform superficial frame-level analysis. To address this, we introduce GLIMPSE, a benchmark specifically designed to evaluate whether LVLMs can genuinely think with videos. Unlike prior benchmarks, GLIMPSE emphasizes comprehensive video understanding beyond static image cues. It consists of 3,269 videos and over 4,342 highly visual-centric questions across 11 categories, including Trajectory Analysis, Temporal Reasoning, and Forensics Detection. All questions are carefully crafted by human annotators and require watching the entire video and reasoning over full video context-this is what we mean by thinking with video. These questions cannot be answered by scanning selected frames or relying on text alone. In human evaluations, GLIMPSE achieves 94.82% accuracy, but current LVLMs face significant challenges. Even the best-performing model, GPT-o3, reaches only 66.43%, highlighting that LVLMs still struggle to move beyond surface-level reasoning to truly think with videos.",
      "authors": [
        "Yiyang Zhou",
        "Linjie Li",
        "Shi Qiu",
        "Zhengyuan Yang",
        "Yuyang Zhao",
        "Siwei Han",
        "Yangfan He",
        "Kangqi Li",
        "Haonian Ji",
        "Zihao Zhao",
        "Haibo Tong",
        "Lijuan Wang",
        "Huaxiu Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:44:57+00:00",
          "link": "https://arxiv.org/abs/2507.09491v1",
          "size": "37287kb",
          "version": "v1"
        }
      ],
      "title": "GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09491",
        "PDF": "https://arxiv.org/pdf/2507.09491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a video benchmark, GLIMPSE, focusing on large vision-language models and their temporal reasoning capabilities. It does not involve any LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09564",
      "abstract": "Phishing is a prevalent cyberattack that uses look-alike websites to deceive users into revealing sensitive information. Numerous efforts have been made by the Internet community and security organizations to detect, prevent, or train users to avoid falling victim to phishing attacks. Most of this research over the years has been highly diverse and application-oriented, often serving as standalone solutions for HTTP clients, servers, or third parties. However, limited work has been done to develop a comprehensive or proactive protocol-oriented solution to effectively counter phishing attacks. Inspired by the concept of certificate transparency, which allows certificates issued by Certificate Authorities (CAs) to be publicly verified by clients, thereby enhancing transparency, we propose a concept called Page Transparency (PT) for the web. The proposed PT requires login pages that capture users' sensitive information to be publicly logged via PLS and made available to web clients for verification. The pages are verified to be logged using cryptographic proofs. Since all pages are logged on a PLS and visually compared with existing pages through a comprehensive visual page-matching algorithm, it becomes impossible for an attacker to register a deceptive look-alike page on the PLS and receive the cryptographic proof required for client verification. All implementations occur on the client side, facilitated by the introduction of a new HTTP PT header, eliminating the need for platform-specific changes or the installation of third-party solutions for phishing prevention.",
      "authors": [
        "Gaurav Varshney",
        "Akanksha Raj",
        "Divya Sangwan",
        "Sharif Abuadbba",
        "Rina Mishra and Yansong Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:15:36+00:00",
          "link": "https://arxiv.org/abs/2507.09564v1",
          "size": "7705kb",
          "version": "v1"
        }
      ],
      "title": "A Login Page Transparency and Visual Similarity Based Zero Day Phishing Defense Protocol",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09564",
        "HTML": "https://arxiv.org/html/2507.09564v1",
        "PDF": "https://arxiv.org/pdf/2507.09564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses phishing defense through a web security protocol. It does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09980",
      "abstract": "Existing multi-view classification and clustering methods typically improve task accuracy by leveraging and fusing information from different views. However, ensuring the reliability of multi-view integration and final decisions is crucial, particularly when dealing with noisy or corrupted data. Current methods often rely on Kullback-Leibler (KL) divergence to estimate uncertainty of network predictions, ignoring domain gaps between different modalities. To address this issue, KPHD-Net, based on H\\\"older divergence, is proposed for multi-view classification and clustering tasks. Generally, our KPHD-Net employs a variational Dirichlet distribution to represent class probability distributions, models evidences from different views, and then integrates it with Dempster-Shafer evidence theory (DST) to improve uncertainty estimation effects. Our theoretical analysis demonstrates that Proper H\\\"older divergence offers a more effective measure of distribution discrepancies, ensuring enhanced performance in multi-view learning. Moreover, Dempster-Shafer evidence theory, recognized for its superior performance in multi-view fusion tasks, is introduced and combined with the Kalman filter to provide future state estimations. This integration further enhances the reliability of the final fusion results. Extensive experiments show that the proposed KPHD-Net outperforms the current state-of-the-art methods in both classification and clustering tasks regarding accuracy, robustness, and reliability, with theoretical guarantees.",
      "authors": [
        "Zhipeng Xue",
        "Yan Zhang",
        "Ming Li",
        "Chun Li",
        "Yue Liu",
        "and Fei Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:55:32+00:00",
          "link": "https://arxiv.org/abs/2507.09980v1",
          "size": "21363kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Quantification for Incomplete Multi-View Data Using Divergence Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09980",
        "HTML": "https://arxiv.org/html/2507.09980v1",
        "PDF": "https://arxiv.org/pdf/2507.09980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on uncertainty quantification in multi-view data using divergence measures, without any mention of processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10072",
      "abstract": "Diffusion models exhibit impressive generative capabilities but are significantly impacted by exposure bias. In this paper, we make a key observation: the energy of the predicted noisy images decreases during the diffusion process. Building on this, we identify two important findings: 1) The reduction in energy follows distinct patterns in the low-frequency and high-frequency subbands; 2) This energy reduction results in amplitude variations between the network-reconstructed clean data and the real clean data. Based on the first finding, we introduce a frequency-domain regulation mechanism utilizing wavelet transforms, which separately adjusts the low- and high-frequency subbands. Leveraging the second insight, we provide a more accurate analysis of exposure bias in the two subbands. Our method is training-free and plug-and-play, significantly improving the generative quality of various diffusion models and providing a robust solution to exposure bias across different model architectures. The source code is available at https://github.com/kunzhan/wpp.",
      "authors": [
        "Meng Yu",
        "Kun Zhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:58:38+00:00",
          "link": "https://arxiv.org/abs/2507.10072v1",
          "size": "11137kb",
          "version": "v1"
        }
      ],
      "title": "Frequency Regulation for Exposure Bias Mitigation in Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10072",
        "HTML": "https://arxiv.org/html/2507.10072v1",
        "PDF": "https://arxiv.org/pdf/2507.10072"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work improves exposure bias in diffusion models via frequency-domain regulation, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10195",
      "abstract": "In this work, we focus on text-based person retrieval, which aims to identify individuals based on textual descriptions. Given the significant privacy issues and the high cost associated with manual annotation, synthetic data has become a popular choice for pretraining models, leading to notable advancements. However, the considerable domain gap between synthetic pretraining datasets and real-world target datasets, characterized by differences in lighting, color, and viewpoint, remains a critical obstacle that hinders the effectiveness of the pretrain-finetune paradigm. To bridge this gap, we introduce a unified text-based person retrieval pipeline considering domain adaptation at both image and region levels. In particular, it contains two primary components, i.e., Domain-aware Diffusion (DaD) for image-level adaptation and Multi-granularity Relation Alignment (MRA) for region-level adaptation. As the name implies, Domain-aware Diffusion is to migrate the distribution of images from the pretraining dataset domain to the target real-world dataset domain, e.g., CUHK-PEDES. Subsequently, MRA performs a meticulous region-level alignment by establishing correspondences between visual regions and their descriptive sentences, thereby addressing disparities at a finer granularity. Extensive experiments show that our dual-level adaptation method has achieved state-of-the-art results on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets, outperforming existing methodologies. The dataset, model, and code are available at https://github.com/Shuyu-XJTU/MRA.",
      "authors": [
        "Shuyu Yang",
        "Yaxiong Wang",
        "Yongrui Li",
        "Li Zhu",
        "Zhedong Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:03:04+00:00",
          "link": "https://arxiv.org/abs/2507.10195v1",
          "size": "2655kb",
          "version": "v1"
        }
      ],
      "title": "Minimizing the Pretraining Gap: Domain-aligned Text-Based Person Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10195",
        "HTML": "https://arxiv.org/html/2507.10195v1",
        "PDF": "https://arxiv.org/pdf/2507.10195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves data adaptation techniques for bridging domain gaps in pretraining and fine-tuning, it primarily focuses on model architecture and text-based person retrieval, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.02070",
      "abstract": "Diffusion and flow-based models have become the state of the art for generative AI across a wide range of data modalities, including images, videos, shapes, molecules, music, and more. This tutorial provides a self-contained introduction to diffusion and flow-based generative models from first principles. We systematically develop the necessary mathematical background in ordinary and stochastic differential equations and derive the core algorithms of flow matching and denoising diffusion models. We then provide a step-by-step guide to building image and video generators, including training methods, guidance, and architectural design. This tutorial is ideal for machine learning researchers who want to develop a principled understanding of the theory and practice of generative AI.",
      "authors": [
        "Peter Holderrieth",
        "Ezra Erives"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T05:07:25+00:00",
          "link": "https://arxiv.org/abs/2506.02070v1",
          "size": "13432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T16:37:24+00:00",
          "link": "https://arxiv.org/abs/2506.02070v2",
          "size": "13432kb",
          "version": "v2"
        }
      ],
      "title": "An Introduction to Flow Matching and Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02070",
        "HTML": "https://arxiv.org/html/2506.02070v2",
        "PDF": "https://arxiv.org/pdf/2506.02070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The tutorial provides an introduction to diffusion and flow-based models, which is unrelated to the explicit processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09041",
      "abstract": "Developing autonomous agents that quickly explore an environment and adapt their behavior online is a canonical challenge in robotics and machine learning. While humans are able to achieve such fast online exploration and adaptation, often acquiring new information and skills in only a handful of interactions, existing algorithmic approaches tend to rely on random exploration and slow, gradient-based behavior updates. How can we endow autonomous agents with such capabilities on par with humans? Taking inspiration from recent progress on both in-context learning and large-scale behavioral cloning, in this work we propose behavioral exploration: training agents to internalize what it means to explore and adapt in-context over the space of ``expert'' behaviors. To achieve this, given access to a dataset of expert demonstrations, we train a long-context generative model to predict expert actions conditioned on a context of past observations and a measure of how ``exploratory'' the expert's behaviors are relative to this context. This enables the model to not only mimic the behavior of an expert, but also, by feeding its past history of interactions into its context, to select different expert behaviors than what have been previously selected, thereby allowing for fast online adaptation and targeted, ``expert-like'' exploration. We demonstrate the effectiveness of our method in both simulated locomotion and manipulation settings, as well as on real-world robotic manipulation tasks, illustrating its ability to learn adaptive, exploratory behavior.",
      "authors": [
        "Andrew Wagenmaker and Zhiyuan Zhou and Sergey Levine"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:36:19+00:00",
          "link": "https://arxiv.org/abs/2507.09041v1",
          "size": "38980kb",
          "version": "v1"
        }
      ],
      "title": "Behavioral Exploration: Learning to Explore via In-Context Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09041",
        "PDF": "https://arxiv.org/pdf/2507.09041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is focused on training autonomous agents for exploration and adaptation, which does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09285",
      "abstract": "Deep prior-based approaches have demonstrated remarkable success in blind motion deblurring (BMD) recently. These methods, however, are often limited by the high non-convexity of the underlying optimization process in BMD, which leads to extreme sensitivity to the initial blur kernel. To address this issue, we propose a novel framework for BMD that leverages a deep generative model to encode the kernel prior and induce a better initialization for the blur kernel. Specifically, we pre-train a kernel generator based on a generative adversarial network (GAN) to aptly characterize the kernel's prior distribution, as well as a kernel initializer to provide a well-informed and high-quality starting point for kernel estimation. By combining these two components, we constrain the BMD solution within a compact latent kernel manifold, thus alleviating the aforementioned sensitivity for kernel initialization. Notably, the kernel generator and initializer are designed to be easily integrated with existing BMD methods in a plug-and-play manner, enhancing their overall performance. Furthermore, we extend our approach to tackle blind non-uniform motion deblurring without the need for additional priors, achieving state-of-the-art performance on challenging benchmark datasets. The source code is available at https://github.com/dch0319/GLKM-Deblur.",
      "authors": [
        "Chenhao Ding",
        "Jiangtao Zhang",
        "Zongsheng Yue",
        "Hui Wang",
        "Qian Zhao",
        "and Deyu Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:48:10+00:00",
          "link": "https://arxiv.org/abs/2507.09285v1",
          "size": "42262kb",
          "version": "v1"
        }
      ],
      "title": "Generative Latent Kernel Modeling for Blind Motion Deblurring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09285",
        "HTML": "https://arxiv.org/html/2507.09285v1",
        "PDF": "https://arxiv.org/pdf/2507.09285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion deblurring techniques using generative models and does not discuss any aspect of LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09394",
      "abstract": "In this work, we study how multi-head latent attention (MLA), a popular strategy for compressing key/value memory, affects a transformer's internal capacity during pretraining. Using a lightweight suite of Marchenko-Pastur (MP) diagnostics, we analyze the spectrum of the $W_{Q}W_{K}^\\top$ gram matrix throughout training, comparing three variants: the standard multi-head attention (MHA) baseline, MLA-PreRoPE with rotary applied before compression, and MLA-Decoupled, which shares a single rotary sub-vector across all heads. Our random matrix analysis reveals \\textbf{three key findings:} \\textbf{ i)} capacity bottlenecks emerge locally: both MHA and MLA-PreRoPE exhibit sharp, early spikes in specific layers that persist and propagate, disrupting the balance between bulk and outlier directions; \\textbf{ ii)} these spikes coincide with rank collapse, concentrating the model's expressivity into narrow subspaces; \\textbf{ iii)} only the decoupled variant prevents this cascade, maintaining broad spectral support and suppressing outlier formation across layers. These results underscore that \\emph{how} rotary embeddings are applied is just as critical as \\emph{where} compression occurs. Sharing rotary components across heads mitigates spectral fragmentation and preserves representational capacity.",
      "authors": [
        "Nandan Kumar Jha and Brandon Reagen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:31:07+00:00",
          "link": "https://arxiv.org/abs/2507.09394v1",
          "size": "353kb",
          "version": "v1"
        }
      ],
      "title": "A Random Matrix Theory Perspective on the Learning Dynamics of Multi-head Latent Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09394",
        "HTML": "https://arxiv.org/html/2507.09394v1",
        "PDF": "https://arxiv.org/pdf/2507.09394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work analyzes learning dynamics in transformers, specifically multi-head latent attention during pretraining, but it does not discuss any data processing related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09464",
      "abstract": "Unmanned Aerial Vehicles (UAV) have emerged as versatile platforms, driving the demand for accurate modeling to support developmental testing. This paper proposes data-driven modeling software for UAV. Emphasizes the utilization of cost-effective sensors to obtain orientation and location data subsequently processed through the application of data filtering algorithms and sensor fusion techniques to improve the data quality to make a precise model visualization on the software. UAV's orientation is obtained using processed Inertial Measurement Unit (IMU) data and represented using Quaternion Representation to avoid the gimbal lock problem. The UAV's location is determined by combining data from the Global Positioning System (GPS), which provides stable geographic coordinates but slower data update frequency, and the accelerometer, which has higher data update frequency but integrating it to get position data is unstable due to its accumulative error. By combining data from these two sensors, the software is able to calculate and continuously update the UAV's real-time position during its flight operations. The result shows that the software effectively renders UAV orientation and position with high degree of accuracy and fluidity",
      "authors": [
        "Azfar Azdi Arfakhsyad",
        "Aufa Nasywa Rahman",
        "Larasati Kinanti",
        "Ahmad Ataka Awwalur Rizqi",
        "Hannan Nur Muhammad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:00:31+00:00",
          "link": "https://arxiv.org/abs/2507.09464v1",
          "size": "795kb",
          "version": "v1"
        }
      ],
      "title": "Unmanned Aerial Vehicle (UAV) Data-Driven Modeling Software with Integrated 9-Axis IMUGPS Sensor Fusion and Data Filtering Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09464",
        "PDF": "https://arxiv.org/pdf/2507.09464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on UAV data modeling with sensor fusion and data filtering for improved UAV modeling, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.17749",
      "abstract": "This paper presents a novel approach to learning free terminal time closed-loop control for robotic manipulation tasks, enabling dynamic adjustment of task duration and control inputs to enhance performance. We extend the supervised learning approach, namely solving selected optimal open-loop problems and utilizing them as training data for a policy network, to the free terminal time scenario. Three main challenges are addressed in this extension. First, we introduce a marching scheme that enhances the solution quality and increases the success rate of the open-loop solver by gradually refining time discretization. Second, we extend the QRnet in Nakamura-Zimmerer et al. (2021b) to the free terminal time setting to address discontinuity and improve stability at the terminal state. Third, we present a more automated version of the initial value problem (IVP) enhanced sampling method from previous work (Zhang et al., 2022) to adaptively update the training dataset, significantly improving its quality. By integrating these techniques, we develop a closed-loop policy that operates effectively over a broad domain with varying optimal time durations, achieving near globally optimal total costs.",
      "authors": [
        "Wei Hu",
        "Yue Zhao",
        "Weinan E",
        "Jiequn Han",
        "Jihao Long"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-29T15:53:43+00:00",
          "link": "https://arxiv.org/abs/2311.17749v1",
          "size": "4922kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T07:53:44+00:00",
          "link": "https://arxiv.org/abs/2311.17749v2",
          "size": "4254kb",
          "version": "v2"
        }
      ],
      "title": "Learning Free Terminal Time Optimal Closed-loop Control of Manipulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.17749",
        "HTML": "https://arxiv.org/html/2311.17749v2",
        "PDF": "https://arxiv.org/pdf/2311.17749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions improving the quality of the training dataset through automated sampling methods but focuses primarily on robotic manipulation task control rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.00486",
      "abstract": "Dynamic jumping on high platforms and over gaps differentiates legged robots from wheeled counterparts. Dynamic locomotion on abrupt surfaces, as opposed to walking on rough terrains, demands the integration of proprioceptive and exteroceptive perception to enable explosive movements. In this paper, we propose SF-TIM (Simple Framework combining Terrain Imagination and Measurement), a single-policy method that enhances quadrupedal robot jumping agility, while preserving their fundamental blind walking capabilities. In addition, we introduce a terrain-guided reward design specifically to assist quadrupedal robots in high jumping, improving their performance in this task. To narrow the simulation-to-reality gap in quadrupedal robot learning, we introduce a stable and high-speed elevation map generation framework, enabling zero-shot simulation-to-reality transfer of locomotion ability. Our algorithm has been deployed and validated on both the small-/large-size quadrupedal robots, demonstrating its effectiveness in real-world applications: the robot has successfully traversed various high platforms and gaps, showing the robustness of our proposed approach. A demo video has been made available at https://flysoaryun.github.io/SF-TIM.",
      "authors": [
        "Ze Wang",
        "Yang Li",
        "Long Xu",
        "Hao Shi",
        "Zunwang Ma",
        "Zhen Chu",
        "Chao Li",
        "Fei Gao",
        "Kailun Yang",
        "Kaiwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T11:45:26+00:00",
          "link": "https://arxiv.org/abs/2408.00486v1",
          "size": "6744kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:41:57+00:00",
          "link": "https://arxiv.org/abs/2408.00486v2",
          "size": "5739kb",
          "version": "v2"
        }
      ],
      "title": "SF-TIM: A Simple Framework for Enhancing Quadrupedal Robot Jumping Agility by Combining Terrain Imagination and Measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00486",
        "HTML": "https://arxiv.org/html/2408.00486v2",
        "PDF": "https://arxiv.org/pdf/2408.00486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses enhancing quadrupedal robot jumping agility and real-world applications rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09122",
      "abstract": "Text-to-motion generation has experienced remarkable progress in recent years. However, current approaches remain limited to synthesizing motion from short or general text prompts, primarily due to dataset constraints. This limitation undermines fine-grained controllability and generalization to unseen prompts. In this paper, we introduce SnapMoGen, a new text-motion dataset featuring high-quality motion capture data paired with accurate, expressive textual annotations. The dataset comprises 20K motion clips totaling 44 hours, accompanied by 122K detailed textual descriptions averaging 48 words per description (vs. 12 words of HumanML3D). Importantly, these motion clips preserve original temporal continuity as they were in long sequences, facilitating research in long-term motion generation and blending. We also improve upon previous generative masked modeling approaches. Our model, MoMask++, transforms motion into multi-scale token sequences that better exploit the token capacity, and learns to generate all tokens using a single generative masked transformer. MoMask++ achieves state-of-the-art performance on both HumanML3D and SnapMoGen benchmarks. Additionally, we demonstrate the ability to process casual user prompts by employing an LLM to reformat inputs to align with the expressivity and narration style of SnapMoGen. Project webpage: https://snap-research.github.io/SnapMoGen/",
      "authors": [
        "Chuan Guo",
        "Inwoo Hwang",
        "Jian Wang",
        "Bing Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:54:59+00:00",
          "link": "https://arxiv.org/abs/2507.09122v1",
          "size": "10543kb",
          "version": "v1"
        }
      ],
      "title": "SnapMoGen: Human Motion Generation from Expressive Texts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09122",
        "HTML": "https://arxiv.org/html/2507.09122v1",
        "PDF": "https://arxiv.org/pdf/2507.09122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "SnapMoGen introduces a new text-to-motion dataset with detailed data processing steps. This creation of a new dataset with an emphasis on high-quality data and extensive annotations aligns with LLM training data processing contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09347",
      "abstract": "Purpose: This study introduces a novel framework for identifying and exploiting predictive lead-lag relationships in financial markets. We propose an integrated approach that combines advanced statistical methodologies with machine learning models to enhance the identification and exploitation of predictive relationships between equities. Methods: We employed a Gaussian Mixture Model (GMM) to cluster nine prominent stocks based on their mid-range historical volatility profiles over a three-year period. From the resulting clusters, we constructed a multi-stage causal inference pipeline, incorporating the Granger Causality Test (GCT), a customised Peter-Clark Momentary Conditional Independence (PCMCI) test, and Effective Transfer Entropy (ETE) to identify robust, predictive linkages. Subsequently, Dynamic Time Warping (DTW) and a K-Nearest Neighbours (KNN) classifier were utilised to determine the optimal time lag for trade execution. The resulting strategy was rigorously backtested. Results: The proposed volatility-based trading strategy, tested from 8 June 2023 to 12 August 2023, demonstrated substantial efficacy. The portfolio yielded a total return of 15.38%, significantly outperforming the 10.39% return of a comparative Buy-and-Hold strategy. Key performance metrics, including a Sharpe Ratio up to 2.17 and a win rate up to 100% for certain pairs, confirmed the strategy's viability. Conclusion: This research contributes a systematic and robust methodology for identifying profitable trading opportunities derived from volatility-based causal relationships. The findings have significant implications for both academic research in financial modelling and the practical application of algorithmic trading, offering a structured approach to developing resilient, data-driven strategies.",
      "authors": [
        "Ivan Letteri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:53:32+00:00",
          "link": "https://arxiv.org/abs/2507.09347v1",
          "size": "880kb",
          "version": "v1"
        }
      ],
      "title": "A Framework for Predictive Directional Trading Based on Volatility and Causal Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09347",
        "HTML": "https://arxiv.org/html/2507.09347v1",
        "PDF": "https://arxiv.org/pdf/2507.09347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is on predictive trading using financial data, emphasizing statistical methods and causal inference, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10008",
      "abstract": "Suicide is a critical global health issue that requires urgent attention. Even though prior work has revealed valuable insights into detecting current suicide risk on social media, little attention has been paid to developing models that can predict subsequent suicide risk over time, limiting their ability to capture rapid fluctuations in individuals' mental state transitions. In addition, existing work ignores protective factors that play a crucial role in suicide risk prediction, focusing predominantly on risk factors alone. Protective factors such as social support and coping strategies can mitigate suicide risk by moderating the impact of risk factors. Therefore, this study proposes a novel framework for predicting subsequent suicide risk by jointly learning the dynamic influence of both risk factors and protective factors on users' suicide risk transitions. We propose a novel Protective Factor-Aware Dataset, which is built from 12 years of Reddit posts along with comprehensive annotations of suicide risk and both risk and protective factors. We also introduce a Dynamic Factors Influence Learning approach that captures the varying impact of risk and protective factors on suicide risk transitions, recognizing that suicide risk fluctuates over time according to established psychological theories. Our thorough experiments demonstrate that the proposed model significantly outperforms state-of-the-art models and large language models across three datasets. In addition, the proposed Dynamic Factors Influence Learning provides interpretable weights, helping clinicians better understand suicidal patterns and enabling more targeted intervention strategies.",
      "authors": [
        "Jun Li",
        "Xiangmeng Wang",
        "Haoyang Li",
        "Yifei Yan",
        "Hong Va Leong",
        "Ling Feng",
        "Nancy Xiaonan Yu",
        "Qing Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:41:54+00:00",
          "link": "https://arxiv.org/abs/2507.10008v1",
          "size": "5802kb",
          "version": "v1"
        }
      ],
      "title": "Protective Factor-Aware Dynamic Influence Learning for Suicide Risk Prediction on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10008",
        "HTML": "https://arxiv.org/html/2507.10008v1",
        "PDF": "https://arxiv.org/pdf/2507.10008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on predicting suicide risk using a dataset from Reddit, but it does not cover LLM training data processing or creation of LLM-specific training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01326",
      "abstract": "A polycube is an orthogonal polyhedron composed of unit cubes glued together along entire faces, and homeomorphic to a sphere. A layer of a polycube refers to the portion lying between two horizontal cross-sections spaced one unit apart. We present an unfolding algorithm that flattens any polycube with orthogonally convex layers into a single, non-overlapping planar piece. The algorithm makes cuts only along cube edges-that is, it is an edge unfolding.",
      "authors": [
        "Mirela Damian and Henk Meijer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T14:33:26+00:00",
          "link": "https://arxiv.org/abs/2407.01326v1",
          "size": "379kb",
          "version": "v1"
        },
        {
          "date": "2024-07-16T14:47:58+00:00",
          "link": "https://arxiv.org/abs/2407.01326v2",
          "size": "380kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T18:44:51+00:00",
          "link": "https://arxiv.org/abs/2407.01326v3",
          "size": "392kb",
          "version": "v3"
        }
      ],
      "title": "Unfolding Polycubes with Orthogonally Convex Layers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01326",
        "HTML": "https://arxiv.org/html/2407.01326v3",
        "PDF": "https://arxiv.org/pdf/2407.01326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an algorithm for unfolding polycubes, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10925",
      "abstract": "Visual localization refers to the process of determining camera poses and orientation within a known scene representation. This task is often complicated by factors such as changes in illumination and variations in viewing angles. In this paper, we propose HGSLoc, a novel lightweight plug-and-play pose optimization framework, which integrates 3D reconstruction with a heuristic refinement strategy to achieve higher pose estimation accuracy. Specifically, we introduce an explicit geometric map for 3D representation and high-fidelity rendering, allowing the generation of high-quality synthesized views to support accurate visual localization. Our method demonstrates higher localization accuracy compared to NeRF-based neural rendering localization approaches. We introduce a heuristic refinement strategy, its efficient optimization capability can quickly locate the target node, while we set the step level optimization step to enhance the pose accuracy in the scenarios with small errors. With carefully designed heuristic functions, it offers efficient optimization capabilities, enabling rapid error reduction in rough localization estimations. Our method mitigates the dependence on complex neural network models while demonstrating improved robustness against noise and higher localization accuracy in challenging environments, as compared to neural network joint optimization strategies. The optimization framework proposed in this paper introduces novel approaches to visual localization by integrating the advantages of 3D reconstruction and the heuristic refinement strategy, which demonstrates strong performance across multiple benchmark datasets, including 7Scenes and Deep Blending dataset. The implementation of our method has been released at https://github.com/anchang699/HGSLoc.",
      "authors": [
        "Zhongyan Niu",
        "Zhen Tan",
        "Jinpu Zhang",
        "Xueliang Yang",
        "Dewen Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-17T06:48:48+00:00",
          "link": "https://arxiv.org/abs/2409.10925v1",
          "size": "3587kb",
          "version": "v1"
        },
        {
          "date": "2024-09-21T03:32:37+00:00",
          "link": "https://arxiv.org/abs/2409.10925v2",
          "size": "3587kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T09:19:29+00:00",
          "link": "https://arxiv.org/abs/2409.10925v3",
          "size": "5545kb",
          "version": "v3"
        }
      ],
      "title": "HGSLoc: 3DGS-based Heuristic Camera Pose Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10925",
        "HTML": "https://arxiv.org/html/2409.10925v3",
        "PDF": "https://arxiv.org/pdf/2409.10925"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about visual localization and pose refinement, which does not involve LLM training data processing or engineering."
      },
      "tasks": [
        "3DGS",
        "3D Reconstruction",
        "NeRF",
        "Neural Rendering",
        "Pose Estimation",
        "Visual Localization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06842",
      "abstract": "Healthcare systems are struggling to meet the growing demand for neurological care, particularly in Alzheimer's disease and related dementias (ADRD). We propose that LLM-based generative AI systems can enhance clinician capabilities to approach specialist-level assessment and decision-making in ADRD care at scale. This article presents a comprehensive six-phase roadmap for responsible design and integration of such systems into ADRD care: (1) high-quality standardized data collection across modalities; (2) decision support; (3) clinical integration enhancing workflows; (4) rigorous validation and monitoring protocols; (5) continuous learning through clinical feedback; and (6) robust ethics and risk management frameworks. This human centered approach optimizes clinicians' capabilities in comprehensive data collection, interpretation of complex clinical information, and timely application of relevant medical knowledge while prioritizing patient safety, healthcare equity, and transparency. Though focused on ADRD, these principles offer broad applicability across medical specialties facing similar systemic challenges.",
      "authors": [
        "Andrew G. Breithaupt",
        "Michael Weiner",
        "Alice Tang",
        "Katherine L. Possin",
        "Marina Sirota",
        "James Lah",
        "Allan I. Levey",
        "Pascal Van Hentenryck",
        "Reza Zandehshahvar",
        "Marilu Luisa Gorno-Tempini",
        "Joseph Giorgio",
        "Jingshen Wang",
        "Andreas M. Rauschecker",
        "Howard J. Rosen",
        "Rachel L. Nosheny",
        "Bruce L. Miller",
        "Pedro Pinheiro-Chagas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T19:09:11+00:00",
          "link": "https://arxiv.org/abs/2502.06842v1",
          "size": "330kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:30:52+00:00",
          "link": "https://arxiv.org/abs/2502.06842v2",
          "size": "758kb",
          "version": "v2"
        }
      ],
      "title": "Integrating Generative Artificial Intelligence in ADRD: A Roadmap for Streamlining Diagnosis and Care in Neurodegenerative Diseases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06842",
        "PDF": "https://arxiv.org/pdf/2502.06842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper outlines a roadmap for integrating LLM-based AI into healthcare, mentioning data collection as part of its process. However, it does not focus on LLM training data processing specifically."
      },
      "tasks": [
        "Clinical Knowledge",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03334",
      "abstract": "Detecting deepfakes involving face-swaps presents a significant challenge, particularly in real-world scenarios where anyone can perform face-swapping with freely available tools and apps without any technical knowledge. Existing deepfake detection methods rely on facial landmarks or inconsistencies in pixel-level features and often struggle with face-swap deepfakes, where the source face is seamlessly blended into the target image or video. The prevalence of face-swap is evident in everyday life, where it is used to spread false information, damage reputations, manipulate political opinions, create non-consensual intimate deepfakes (NCID), and exploit children by enabling the creation of child sexual abuse material (CSAM). Even prominent public figures are not immune to its impact, with numerous deepfakes of them circulating widely across social media platforms. Another challenge faced by deepfake detection methods is the creation of datasets that encompass a wide range of variations, as training models require substantial amounts of data. This raises privacy concerns, particularly regarding the processing and storage of personal facial data, which could lead to unauthorized access or misuse. Our key idea is to identify these style discrepancies to detect face-swapped images effectively without accessing the real facial image. We perform comprehensive evaluations using multiple datasets and face-swapping methods, which showcases the effectiveness of SafeVision in detecting face-swap deepfakes across diverse scenarios. SafeVision offers a reliable and scalable solution for detecting face-swaps in a privacy preserving manner, making it particularly effective in challenging real-world applications. To the best of our knowledge, SafeVision is the first deepfake detection using style features while providing inherent privacy protection.",
      "authors": [
        "Sudev Kumar Padhi",
        "Harshit Kumar",
        "Umesh Kashyap and Sk. Subidh Ali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T06:42:51+00:00",
          "link": "https://arxiv.org/abs/2507.03334v1",
          "size": "1462kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:02:35+00:00",
          "link": "https://arxiv.org/abs/2507.03334v2",
          "size": "1462kb",
          "version": "v2"
        }
      ],
      "title": "De-Fake: Style based Anomaly Deepfake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03334",
        "HTML": "https://arxiv.org/html/2507.03334v2",
        "PDF": "https://arxiv.org/pdf/2507.03334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses deepfake detection using style-based anomaly detection but does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06812",
      "abstract": "Co-speech gesture video generation aims to synthesize realistic, audio-aligned videos of speakers, complete with synchronized facial expressions and body gestures. This task presents challenges due to the significant one-to-many mapping between audio and visual content, further complicated by the scarcity of large-scale public datasets and high computational demands. We propose a lightweight framework that utilizes 2D full-body skeletons as an efficient auxiliary condition to bridge audio signals with visual outputs. Our approach introduces a diffusion model conditioned on fine-grained audio segments and a skeleton extracted from the speaker's reference image, predicting skeletal motions through skeleton-audio feature fusion to ensure strict audio coordination and body shape consistency. The generated skeletons are then fed into an off-the-shelf human video generation model with the speaker's reference image to synthesize high-fidelity videos. To democratize research, we present CSG-405-the first public dataset with 405 hours of high-resolution videos across 71 speech types, annotated with 2D skeletons and diverse speaker demographics. Experiments show that our method exceeds state-of-the-art approaches in visual quality and synchronization while generalizing across speakers and contexts. Code, models, and CSG-405 are publicly released at https://mpi-lab.github.io/Democratizing-CSG/",
      "authors": [
        "Xu Yang",
        "Shaoli Huang",
        "Shenbo Xie",
        "Xuelin Chen",
        "Yifei Liu",
        "Changxing Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:02:12+00:00",
          "link": "https://arxiv.org/abs/2507.06812v1",
          "size": "2666kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:35:26+00:00",
          "link": "https://arxiv.org/abs/2507.06812v2",
          "size": "2666kb",
          "version": "v2"
        }
      ],
      "title": "Democratizing High-Fidelity Co-Speech Gesture Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06812",
        "HTML": "https://arxiv.org/html/2507.06812v2",
        "PDF": "https://arxiv.org/pdf/2507.06812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents a new dataset (CSG-405) and a novel method for co-speech gesture video generation, it primarily focuses on video generation techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09678",
      "abstract": "We investigate the integration of Conformal Prediction (CP) with supervised learning on deterministically encrypted data, aiming to bridge the gap between rigorous uncertainty quantification and privacy-preserving machine learning. Using AES-encrypted variants of the MNIST dataset, we demonstrate that CP methods remain effective even when applied directly in the encrypted domain, owing to the preservation of data exchangeability under fixed-key encryption. We test traditional $p$-value-based against $e$-value-based conformal predictors. Our empirical evaluation reveals that models trained on deterministically encrypted data retain the ability to extract meaningful structure, achieving 36.88\\% test accuracy -- significantly above random guessing (9.56\\%) observed with per-instance encryption. Moreover, $e$-value-based CP achieves predictive set coverage of over 60\\% with 4.3 loss-threshold calibration, correctly capturing the true label in 4888 out of 5000 test cases. In contrast, the $p$-value-based CP yields smaller predictive sets but with reduced coverage accuracy. These findings highlight both the promise and limitations of CP in encrypted data settings and underscore critical trade-offs between prediction set compactness and reliability. %Our work sets a foundation for principled uncertainty quantification in secure, privacy-aware learning systems.",
      "authors": [
        "Alexander David Balinsky",
        "Dominik Krzeminski and Alexander Balinsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:29:14+00:00",
          "link": "https://arxiv.org/abs/2507.09678v1",
          "size": "1285kb",
          "version": "v1"
        }
      ],
      "title": "Conformal Prediction for Privacy-Preserving Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09678",
        "HTML": "https://arxiv.org/html/2507.09678v1",
        "PDF": "https://arxiv.org/pdf/2507.09678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on integrating conformal prediction with privacy-preserving machine learning using encrypted data, which does not involve LLM training data processing techniques or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10222",
      "abstract": "We present Spatial Lifting (SL), a novel methodology for dense prediction tasks. SL operates by lifting standard inputs, such as 2D images, into a higher-dimensional space and subsequently processing them using networks designed for that higher dimension, such as a 3D U-Net. Counterintuitively, this dimensionality lifting allows us to achieve good performance on benchmark tasks compared to conventional approaches, while reducing inference costs and significantly lowering the number of model parameters. The SL framework produces intrinsically structured outputs along the lifted dimension. This emergent structure facilitates dense supervision during training and enables robust, near-zero-additional-cost prediction quality assessment at test time. We validate our approach across 19 benchmark datasets (13 for semantic segmentation and 6 for depth estimation), demonstrating competitive dense prediction performance while reducing the model parameter count by over 98% (in the U-Net case) and lowering inference costs. Spatial Lifting introduces a new vision modeling paradigm that offers a promising path toward more efficient, accurate, and reliable deep networks for dense prediction tasks in vision.",
      "authors": [
        "Mingzhi Xu",
        "Yizhe Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.10222v1",
          "size": "3054kb",
          "version": "v1"
        }
      ],
      "title": "Spatial Lifting for Dense Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10222",
        "HTML": "https://arxiv.org/html/2507.10222v1",
        "PDF": "https://arxiv.org/pdf/2507.10222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on dense prediction tasks in computer vision using Spatial Lifting, with no connection to LLM training data processing or related data engineering activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.12380",
      "abstract": "Attributing answers to source documents is an approach used to enhance the verifiability of a model's output in retrieval augmented generation (RAG). Prior work has mainly focused on improving and evaluating the attribution quality of large language models (LLMs) in RAG, but this may come at the expense of inducing biases in the attribution of answers. We define and examine two aspects in the evaluation of LLMs in RAG pipelines, namely attribution sensitivity and bias with respect to authorship information. We explicitly inform an LLM about the authors of source documents, instruct it to attribute its answers, and analyze (i) how sensitive the LLM's output is to the author of source documents, and (ii) whether the LLM exhibits a bias towards human-written or AI-generated source documents. We design an experimental setup in which we use counterfactual evaluation to study three LLMs in terms of their attribution sensitivity and bias in RAG pipelines. Our results show that adding authorship information to source documents can significantly change the attribution quality of LLMs by 3% to 18%. Moreover, we show that LLMs can have an attribution bias towards explicit human authorship, which can serve as a competing hypothesis for findings of prior work that shows that LLM-generated content may be preferred over human-written contents. Our findings indicate that metadata of source documents can influence LLMs' trust, and how they attribute their answers. Furthermore, our research highlights attribution bias and sensitivity as a novel aspect of brittleness in LLMs.",
      "authors": [
        "Amin Abolghasemi",
        "Leif Azzopardi",
        "Seyyed Hadi Hashemi",
        "Maarten de Rijke",
        "Suzan Verberne"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T08:55:49+00:00",
          "link": "https://arxiv.org/abs/2410.12380v1",
          "size": "327kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T15:07:14+00:00",
          "link": "https://arxiv.org/abs/2410.12380v2",
          "size": "205kb",
          "version": "v2"
        }
      ],
      "title": "Evaluation of Attribution Bias in Generator-Aware Retrieval-Augmented Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12380",
        "HTML": "https://arxiv.org/html/2410.12380v2",
        "PDF": "https://arxiv.org/pdf/2410.12380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies attribution bias in LLMs' response evaluations in RAG pipelines, not focusing on any LLM training data processing methods."
      },
      "tasks": [
        "Attribute",
        "counterfactual",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.19021",
      "abstract": "Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of the closed-set assumption by aligning visual relationship representations with open-vocabulary textual representations. This enables the identification of novel visual relationships, making it applicable to real-world scenarios with diverse relationships. However, existing OV-SGG methods are constrained by fixed text representations, limiting diversity and accuracy in image-text alignment. To address these challenges, we propose the Relation-Aware Hierarchical Prompting (RAHP) framework, which enhances text representation by integrating subject-object and region-specific relation information. Our approach utilizes entity clustering to address the complexity of relation triplet categories, enabling the effective integration of subject-object information. Additionally, we utilize a large language model (LLM) to generate detailed region-aware prompts, capturing fine-grained visual interactions and improving alignment between visual and textual modalities. RAHP also introduces a dynamic selection mechanism within Vision-Language Models (VLMs), which adaptively selects relevant text prompts based on the visual content, reducing noise from irrelevant prompts. Extensive experiments on the Visual Genome and Open Images v6 datasets demonstrate that our framework consistently achieves state-of-the-art performance, demonstrating its effectiveness in addressing the challenges of open-vocabulary scene graph generation. The code is available at: https://github.com/Leon022/RAHP",
      "authors": [
        "Tao Liu",
        "Rongjie Li",
        "Chongyu Wang",
        "Xuming He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-26T02:12:37+00:00",
          "link": "https://arxiv.org/abs/2412.19021v1",
          "size": "17411kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T14:17:56+00:00",
          "link": "https://arxiv.org/abs/2412.19021v2",
          "size": "17411kb",
          "version": "v2"
        }
      ],
      "title": "Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19021",
        "HTML": "https://arxiv.org/html/2412.19021v2",
        "PDF": "https://arxiv.org/pdf/2412.19021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving text representation in visual and textual alignments for open-vocabulary scene graph generation but does not address LLM training data processing or contribute to dataset creation."
      },
      "tasks": [
        "Graph Generation",
        "Large Language Model",
        "Relation",
        "Scene Graph Generation",
        "Triplet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13407",
      "abstract": "We derive novel deterministic bounds on the approximation error of data-based bilinear surrogate models for unknown nonlinear systems. The surrogate models are constructed using kernel-based extended dynamic mode decomposition to approximate the Koopman operator in a reproducing kernel Hilbert space. Unlike previous methods that require restrictive assumptions on the invariance of the dictionary, our approach leverages kernel-based dictionaries that allow us to control the projection error via pointwise error bounds, overcoming a significant limitation of existing theoretical guarantees. The derived state- and input-dependent error bounds allow for direct integration into Koopman-based robust controller designs with closed-loop guarantees for the unknown nonlinear system. Numerical examples illustrate the effectiveness of the proposed framework.",
      "authors": [
        "Robin Str\\\"asser",
        "Manuel Schaller",
        "Julian Berberich",
        "Karl Worthmann",
        "Frank Allg\\\"ower"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T17:38:19+00:00",
          "link": "https://arxiv.org/abs/2503.13407v1",
          "size": "84kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T14:41:22+00:00",
          "link": "https://arxiv.org/abs/2503.13407v2",
          "size": "85kb",
          "version": "v2"
        },
        {
          "date": "2025-06-20T13:57:59+00:00",
          "link": "https://arxiv.org/abs/2503.13407v3",
          "size": "85kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T11:51:27+00:00",
          "link": "https://arxiv.org/abs/2503.13407v4",
          "size": "85kb",
          "version": "v4"
        }
      ],
      "title": "Kernel-based error bounds of bilinear Koopman surrogate models for nonlinear data-driven control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13407",
        "PDF": "https://arxiv.org/pdf/2503.13407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses error bounds for bilinear surrogate models and control systems but does not involve LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09179",
      "abstract": "Decentralized finance (DeFi) has introduced a new era of permissionless financial innovation but also led to unprecedented market manipulation. Without centralized oversight, malicious actors coordinate shilling campaigns and pump-and-dump schemes across various platforms. We propose a Multi-Agent Reinforcement Learning (MARL) framework for decentralized manipulation detection, modeling the interaction between manipulators and detectors as a dynamic adversarial game. This framework identifies suspicious patterns using delayed token price reactions as financial indicators.Our method introduces three innovations: (1) Group Relative Policy Optimization (GRPO) to enhance learning stability in sparse-reward and partially observable settings; (2) a theory-based reward function inspired by rational expectations and information asymmetry, differentiating price discovery from manipulation noise; and (3) a multi-modal agent pipeline that integrates LLM-based semantic features, social graph signals, and on-chain market data for informed decision-making.The framework is integrated within the Symphony system, a decentralized multi-agent architecture enabling peer-to-peer agent execution and trust-aware learning through distributed logs, supporting chain-verifiable evaluation. Symphony promotes adversarial co-evolution among strategic actors and maintains robust manipulation detection without centralized oracles, enabling real-time surveillance across global DeFi ecosystems.Trained on 100,000 real-world discourse episodes and validated in adversarial simulations, Hide-and-Shill achieves top performance in detection accuracy and causal attribution. This work bridges multi-agent systems with financial surveillance, advancing a new paradigm for decentralized market intelligence. All resources are available at the Hide-and-Shill GitHub repository to promote open research and reproducibility.",
      "authors": [
        "Ronghua Shi",
        "Yiou Liu",
        "Xinyu Ying",
        "Yang Tan",
        "Yuchun Feng",
        "Lynn Ai",
        "Bill Shi",
        "Xuhui Wang",
        "Zhuang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:55:40+00:00",
          "link": "https://arxiv.org/abs/2507.09179v1",
          "size": "8233kb",
          "version": "v1"
        }
      ],
      "title": "Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09179",
        "HTML": "https://arxiv.org/html/2507.09179v1",
        "PDF": "https://arxiv.org/pdf/2507.09179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a framework for market manipulation detection in decentralized systems and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10004",
      "abstract": "The angular droop control is a grid-forming control strategy that exploits the idea of power-to-angle droop to achieve exact frequency synchronization with no stringent separation between primary and secondary frequency control. In this work, we conduct hardware experiments in the Smart Energy System Control Laboratory at Karlsruhe Institute of Technology (KIT) to test and validate the angular droop control for low voltage power grids in two different test scenarios. First, we verify its grid-forming capabilities after a major event, e.g., following a blackout, demonstrated via power-to-angle droop behavior. For this, we propose two implementation schemes that rely either on direct or indirect actuation of the modulation signal and draw a comparison between them. Second, we investigate the plug-and-play capabilities, i.e., local stability and power sharing for a two-converter system and provide suitable tuning for the control gains. Our experimental findings illustrate the usefulness of hardware test and validation for DC/AC converter control, the practical challenges entailed and the proposed remedies.",
      "authors": [
        "Taouba Jouini and Jan Wachter and Sophie An and Veit Hagenmeyer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:36:32+00:00",
          "link": "https://arxiv.org/abs/2507.10004v1",
          "size": "4882kb",
          "version": "v1"
        }
      ],
      "title": "Hardware test and validation of the angular droop control: Analysis and experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10004",
        "HTML": "https://arxiv.org/html/2507.10004v1",
        "PDF": "https://arxiv.org/pdf/2507.10004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses angular droop control for power grids and involves hardware testing and validation, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10200",
      "abstract": "Natural language-based assessment (NLA) is an approach to second language assessment that uses instructions - expressed in the form of can-do descriptors - originally intended for human examiners, aiming to determine whether large language models (LLMs) can interpret and apply them in ways comparable to human assessment. In this work, we explore the use of such descriptors with an open-source LLM, Qwen 2.5 72B, to assess responses from the publicly available S&I Corpus in a zero-shot setting. Our results show that this approach - relying solely on textual information - achieves competitive performance: while it does not outperform state-of-the-art speech LLMs fine-tuned for the task, it surpasses a BERT-based model trained specifically for this purpose. NLA proves particularly effective in mismatched task settings, is generalisable to other data types and languages, and offers greater interpretability, as it is grounded in clearly explainable, widely applicable language descriptors.",
      "authors": [
        "Stefano Bann\\`o",
        "Rao Ma",
        "Mengjie Qian",
        "Siyuan Tang",
        "Kate Knill",
        "Mark Gales"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:13:50+00:00",
          "link": "https://arxiv.org/abs/2507.10200v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "Natural Language-based Assessment of L2 Oral Proficiency using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10200",
        "HTML": "https://arxiv.org/html/2507.10200v1",
        "PDF": "https://arxiv.org/pdf/2507.10200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores natural language-based assessment using LLMs, but it focuses on assessment methods and evaluation rather than the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.01440",
      "abstract": "Reinforcement learning has emerged as an important approach for autonomous driving. A reward function is used in reinforcement learning to establish the learned skill objectives and guide the agent toward the optimal policy. Since autonomous driving is a complex domain with partly conflicting objectives with varying degrees of priority, developing a suitable reward function represents a fundamental challenge. This paper aims to highlight the gap in such function design by assessing different proposed formulations in the literature and dividing individual objectives into Safety, Comfort, Progress, and Traffic Rules compliance categories. Additionally, the limitations of the reviewed reward functions are discussed, such as objectives aggregation and indifference to driving context. Furthermore, the reward categories are frequently inadequately formulated and lack standardization. This paper concludes by proposing future research that potentially addresses the observed shortcomings in rewards, including a reward validation framework and structured rewards that are context-aware and able to resolve conflicts.",
      "authors": [
        "Ahmed Abouelazm",
        "Jonas Michel",
        "and J. Marius Zoellner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-12T08:32:54+00:00",
          "link": "https://arxiv.org/abs/2405.01440v1",
          "size": "271kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T13:26:05+00:00",
          "link": "https://arxiv.org/abs/2405.01440v2",
          "size": "232kb",
          "version": "v2"
        }
      ],
      "title": "A Review of Reward Functions for Reinforcement Learning in the context of Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.01440",
        "HTML": "https://arxiv.org/html/2405.01440v2",
        "PDF": "https://arxiv.org/pdf/2405.01440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This review paper is centered around reward function design in reinforcement learning for autonomous driving, not on LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.06672",
      "abstract": "Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks. This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe. This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers. The program uses risk-priced indemnity fees to induce socially optimal levels of care. Risk-estimates are determined by surveying experts, including indemnified developers. The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses. Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees. It's recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good. Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds.",
      "authors": [
        "Cristian Trout"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T17:41:24+00:00",
          "link": "https://arxiv.org/abs/2409.06672v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T00:23:00+00:00",
          "link": "https://arxiv.org/abs/2409.06672v2",
          "size": "117kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T22:31:53+00:00",
          "link": "https://arxiv.org/abs/2409.06672v3",
          "size": "117kb",
          "version": "v3"
        }
      ],
      "title": "Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06672",
        "HTML": "https://arxiv.org/html/2409.06672v3",
        "PDF": "https://arxiv.org/pdf/2409.06672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an indemnification program related to AI risks but does not involve LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.19468",
      "abstract": "Random feature (RF) method is a powerful kernel approximation technique, but is typically equipped with fixed activation functions, limiting its adaptability across diverse tasks. To overcome this limitation, we introduce the Random Feature Model with Learnable Activation Functions (RFLAF), which enhances the model expressivity by parameterizing activation functions as weighted sums of basis functions. Specifically, we propose to use radial basis functions (RBFs) as bases. We first analyze the RF model with a single RBF activation, deriving a novel kernel and presenting its theoretical properties. Extending this to multiple RBFs, we show that RFLAF significantly expands the function space of RF models while maintaining parameter efficiency. Experimental results across multiple tasks demonstrate that RFLAF consistently outperforms standard RF models with minimal extra computational cost. Furthermore, RFLAF showcases the ability of recovering the optimal activation function directly from data. Our work provides a deeper understanding of the component of learnable activation functions within modern neural networks architectures.",
      "authors": [
        "Zailin Ma",
        "Jiansheng Yang",
        "Yaodong Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-29T04:38:12+00:00",
          "link": "https://arxiv.org/abs/2411.19468v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T04:13:31+00:00",
          "link": "https://arxiv.org/abs/2411.19468v2",
          "size": "78kb",
          "version": "v2"
        }
      ],
      "title": "Learning Expressive Random Feature Models via Parametrized Activations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19468",
        "HTML": "https://arxiv.org/html/2411.19468v2",
        "PDF": "https://arxiv.org/pdf/2411.19468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses random feature models with learnable activation functions to expand model expressivity, without any connection to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.10289",
      "abstract": "Numerical ordinary differential equation (ODE) solvers are indispensable tools in various engineering domains, enabling the simulation and analysis of dynamic systems. In this work, we utilize 5 different numerical ODE solvers namely: Euler's method, Heun's method, Midpoint Method, Runge-kutta 4th order and ODE45 method in order to discover the answer of three wellknown case studies and compare their results by calculation of relative errors. To check for the validity of the estimations, the experimental data of previous literature have been compared with the data in this paper which shows a good accordance. We observe that for each of the case studies based on the behavior of the model, the estimation accuracy of the solvers is different. For the logistic population change as the first case study, the results of all solvers are so close to each other that only their solution cost can be considered for their superiority. For temperature change of a building as the second case study we see that in some especial areas the accuracy of the solvers is different and in general Midpoint ODE solver shows better results. As the last case study, market equilibrium price shows that none of the numerical ODE solvers can estimate its behavior which is due to its sudden changing nature.",
      "authors": [
        "Hamidreza Moradi",
        "Hamideh Hossei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Algebraic Geometry (math.AG)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T16:51:01+00:00",
          "link": "https://arxiv.org/abs/2502.10289v1",
          "size": "587kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:26:01+00:00",
          "link": "https://arxiv.org/abs/2502.10289v2",
          "size": "980kb",
          "version": "v2"
        }
      ],
      "title": "Investigation of the Estimation Accuracy of 5 Different Numerical ODE Solvers on 3 Case Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10289",
        "PDF": "https://arxiv.org/pdf/2502.10289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates the accuracy of numerical ODE solvers for case studies, which has no relation to LLM training data processing or dataset development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08839",
      "abstract": "Lewy Body Disease (LBD) is a common yet understudied form of dementia that imposes a significant burden on public health. It shares clinical similarities with Alzheimer's disease (AD), as both progress through stages of normal cognition, mild cognitive impairment, and dementia. A major obstacle in LBD diagnosis is data scarcity, which limits the effectiveness of deep learning. In contrast, AD datasets are more abundant, offering potential for knowledge transfer. However, LBD and AD data are typically collected from different sites using different machines and protocols, resulting in a distinct domain shift. To effectively leverage AD data while mitigating domain shift, we propose a Transferability Aware Transformer (TAT) that adapts knowledge from AD to enhance LBD diagnosis. Our method utilizes structural connectivity (SC) derived from structural MRI as training data. Built on the attention mechanism, TAT adaptively assigns greater weights to disease-transferable features while suppressing domain-specific ones, thereby reducing domain shift and improving diagnostic accuracy with limited LBD data. The experimental results demonstrate the effectiveness of TAT. To the best of our knowledge, this is the first study to explore domain adaptation from AD to LBD under conditions of data scarcity and domain shift, providing a promising framework for domain-adaptive diagnosis of rare diseases.",
      "authors": [
        "Xiaowei Yu",
        "Jing Zhang",
        "Tong Chen",
        "Yan Zhuang",
        "Minheng Chen",
        "Chao Cao",
        "Yanjun Lyu",
        "Lu Zhang",
        "Li Su",
        "Tianming Liu",
        "and Dajiang Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:28:39+00:00",
          "link": "https://arxiv.org/abs/2507.08839v1",
          "size": "2282kb",
          "version": "v1"
        }
      ],
      "title": "Domain-Adaptive Diagnosis of Lewy Body Disease with Transferability Aware Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08839",
        "HTML": "https://arxiv.org/html/2507.08839v1",
        "PDF": "https://arxiv.org/pdf/2507.08839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research explores domain adaptation for Lewy Body Disease diagnosis, leveraging existing Alzheimer's datasets, but does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09217",
      "abstract": "Point tracking aims to identify the same physical point across video frames and serves as a geometry-aware representation of motion. This representation supports a wide range of applications, from robotics to augmented reality, by enabling accurate modeling of dynamic environments. Most existing long-term tracking approaches operate in an offline setting, where future frames are available to refine predictions and recover from occlusions. However, real-world scenarios often demand online predictions: the model must operate causally, using only current and past frames. This constraint is critical in streaming video and embodied AI, where decisions must be made immediately based on past observations. Under such constraints, viewpoint invariance becomes essential. Visual foundation models, trained on diverse large-scale datasets, offer the potential for robust geometric representations. While they lack temporal reasoning on their own, they can be integrated into tracking pipelines to enrich spatial features. In this thesis, we address the problem of long-term point tracking in an online setting, where frames are processed sequentially without access to future information or sliding windows. We begin by evaluating the suitability of visual foundation models for this task and find that they can serve as useful initializations and be integrated into tracking pipelines. However, to enable long-term tracking in an online setting, a dedicated design is still required. In particular, maintaining coherence over time in this causal regime requires memory to propagate appearance and context across frames. To address this, we introduce Track-On, a transformer-based model that treats each tracked point as a query and processes video frames one at a time. Track-On sets a new state of the art across seven public benchmarks, demonstrating the feasibility of long-term tracking without future access.",
      "authors": [
        "G\\\"orkay Aydemir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:24:28+00:00",
          "link": "https://arxiv.org/abs/2507.09217v1",
          "size": "13341kb",
          "version": "v1"
        }
      ],
      "title": "Online Long-term Point Tracking in the Foundation Model Era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09217",
        "HTML": "https://arxiv.org/html/2507.09217v1",
        "PDF": "https://arxiv.org/pdf/2507.09217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study pertains to point tracking in videos rather than addressing training data collection or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09805",
      "abstract": "In traffic prediction, the goal is to estimate traffic speed or flow in specific regions or road segments using historical data collected by devices deployed in each area. Each region or road segment can be viewed as an individual client that measures local traffic flow, making Federated Learning (FL) a suitable approach for collaboratively training models without sharing raw data. In centralized FL, a central server collects and aggregates model updates from multiple clients to build a shared model while preserving each client's data privacy. Standard FL methods, such as Federated Averaging (FedAvg), assume that clients are independent, which can limit performance in traffic prediction tasks where spatial relationships between clients are important. Federated Graph Learning methods can capture these dependencies during server-side aggregation, but they often introduce significant computational overhead. In this paper, we propose a lightweight graph-aware FL approach that blends the simplicity of FedAvg with key ideas from graph learning. Rather than training full models, our method applies basic neighbourhood aggregation principles to guide parameter updates, weighting client models based on graph connectivity. This approach captures spatial relationships effectively while remaining computationally efficient. We evaluate our method on two benchmark traffic datasets, METR-LA and PEMS-BAY, and show that it achieves competitive performance compared to standard baselines and recent graph-based federated learning techniques.",
      "authors": [
        "Audri Banik",
        "Glaucio Haroldo Silva de Carvalho and Renata Dividino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:41:42+00:00",
          "link": "https://arxiv.org/abs/2507.09805v1",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "title": "Federated Learning with Graph-Based Aggregation for Traffic Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09805",
        "HTML": "https://arxiv.org/html/2507.09805v1",
        "PDF": "https://arxiv.org/pdf/2507.09805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses federated learning for traffic forecasting using graph-based aggregation, without any focus on processing training data for LLMs or creating datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09960",
      "abstract": "In multiple-input multiple-output integrated sensing and communication (MIMO ISAC) systems, radio frequency chain (i.e., RF chain) selection plays a vital role in reducing hardware cost, power consumption, and computational complexity. However, designing an effective RF chain selection strategy is challenging due to the disparity in performance metrics between communication and sensing-mutual information (MI) versus beam-pattern mean-squared error (MSE) or the Cram\\'er-Rao lower bound (CRLB). To overcome this, we propose a low-complexity greedy RF chain selection framework maximizing a unified MI-based performance metric applicable to both functions. By decomposing the total MI into individual contributions of each RF chain, we introduce two approaches: greedy eigen-based selection (GES) and greedy cofactor-based selection (GCS), which iteratively identify and remove the RF chains with the lowest contribution. We further extend our framework to beam selection for beamspace MIMO ISAC systems, introducing diagonal beam selection (DBS) as a simplified solution. Simulation results show that our proposed methods achieve near-optimal performance with significantly lower complexity than exhaustive search, demonstrating their practical effectiveness for MIMO ISAC systems.",
      "authors": [
        "Subin Shin",
        "Seongkyu Jung",
        "Jinseok Choi",
        "and Jeonghun Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:19:59+00:00",
          "link": "https://arxiv.org/abs/2507.09960v1",
          "size": "174kb",
          "version": "v1"
        }
      ],
      "title": "Efficient RF Chain Selection for MIMO Integrated Sensing and Communications: A Greedy Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09960",
        "HTML": "https://arxiv.org/html/2507.09960v1",
        "PDF": "https://arxiv.org/pdf/2507.09960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses RF chain selection in MIMO systems focusing on hardware optimization and performance metrics, lacking discussion on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09969",
      "abstract": "Graph knowledge has been proven effective in enhancing item rankings in recommender systems (RecSys), particularly during the retrieval stage. However, its application in the ranking stage, especially when richer contextual information in user-item interactions is available, remains underexplored. A major challenge lies in the substantial computational cost associated with repeatedly retrieving neighborhood information from billions of items stored in distributed systems. This resource-intensive requirement makes it difficult to scale graph-based methods in practical RecSys. To bridge this gap, we first demonstrate that incorporating graphs in the ranking stage improves ranking qualities. Notably, while the improvement is evident, we show that the substantial computational overheads entailed by graphs are prohibitively expensive for real-world recommendations. In light of this, we propose a non-parametric strategy that utilizes graph convolution for re-ranking only during test time. Our strategy circumvents the notorious computational overheads from graph convolution during training, and utilizes structural knowledge hidden in graphs on-the-fly during testing. It can be used as a plug-and-play module and easily employed to enhance the ranking ability of various ranking layers of a real-world RecSys with significantly reduced computational overhead. Through comprehensive experiments across four benchmark datasets with varying levels of sparsity, we demonstrate that our strategy yields noticeable improvements (i.e., 8.1% on average) during testing time with little to no additional computational overheads (i.e., 0.5 on average). Code: https://github.com/zyouyang/RecSys2025_NonParamGC.git",
      "authors": [
        "Zhongyu Ouyang",
        "Mingxuan Ju",
        "Soroush Vosoughi",
        "Yanfang Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:35:18+00:00",
          "link": "https://arxiv.org/abs/2507.09969v1",
          "size": "572kb",
          "version": "v1"
        }
      ],
      "title": "Non-parametric Graph Convolution for Re-ranking in Recommendation Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09969",
        "HTML": "https://arxiv.org/html/2507.09969v1",
        "PDF": "https://arxiv.org/pdf/2507.09969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a strategy for re-ranking in recommendation systems using graph convolution, which does not involve any LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.11467",
      "abstract": "Data augmentation (DA) is widely employed to improve the generalization performance of deep models. However, most existing DA methods employ augmentation operations with fixed or random magnitudes throughout the training process. While this fosters data diversity, it can also inevitably introduce uncontrolled variability in augmented data, which could potentially cause misalignment with the evolving training status of the target models. Both theoretical and empirical findings suggest that this misalignment increases the risks of both underfitting and overfitting. To address these limitations, we propose AdaAugment, an innovative and tuning-free adaptive augmentation method that leverages reinforcement learning to dynamically and adaptively adjust augmentation magnitudes for individual training samples based on real-time feedback from the target network. Specifically, AdaAugment features a dual-model architecture consisting of a policy network and a target network, which are jointly optimized to adapt augmentation magnitudes in accordance with the model's training progress effectively. The policy network optimizes the variability within the augmented data, while the target network utilizes the adaptively augmented samples for training. These two networks are jointly optimized and mutually reinforce each other. Extensive experiments across benchmark datasets and deep architectures demonstrate that AdaAugment consistently outperforms other state-of-the-art DA methods in effectiveness while maintaining remarkable efficiency. Code is available at https://github.com/Jackbrocp/AdaAugment.",
      "authors": [
        "Suorong Yang",
        "Peijia Li",
        "Xin Xiong",
        "Furao Shen",
        "and Jian Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-19T06:54:03+00:00",
          "link": "https://arxiv.org/abs/2405.11467v1",
          "size": "1561kb",
          "version": "v1"
        },
        {
          "date": "2024-05-23T12:58:34+00:00",
          "link": "https://arxiv.org/abs/2405.11467v2",
          "size": "1562kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T15:34:26+00:00",
          "link": "https://arxiv.org/abs/2405.11467v3",
          "size": "1100kb",
          "version": "v3"
        }
      ],
      "title": "AdaAugment: A Tuning-Free and Adaptive Approach to Enhance Data Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11467",
        "HTML": "https://arxiv.org/html/2405.11467v3",
        "PDF": "https://arxiv.org/pdf/2405.11467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents AdaAugment, a method for dynamically adjusting data augmentation magnitudes, which is relevant to data processing but not specifically focused on LLM training data."
      },
      "tasks": [
        "Data Augmentation",
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.11415",
      "abstract": "Contemporary research in social sciences increasingly utilizes state-of-the-art generative language models to annotate or generate content. While these models achieve benchmark-leading performance on common language tasks, their application to novel out-of-domain tasks remains insufficiently explored. To address this gap, we investigate how personalized language models align with human responses on the Moral Foundation Theory Questionnaire. We adapt open-source generative language models to different political personas and repeatedly survey these models to generate synthetic data sets where model-persona combinations define our sub-populations. Our analysis reveals that models produce inconsistent results across multiple repetitions, yielding high response variance. Furthermore, the alignment between synthetic data and corresponding human data from psychological studies shows a weak correlation, with conservative persona-prompted models particularly failing to align with actual conservative populations. These results suggest that language models struggle to coherently represent ideologies through in-context prompting due to their alignment process. Thus, using language models to simulate social interactions requires measurable improvements in in-context optimization or parameter manipulation to align with psychological and sociological stereotypes properly.",
      "authors": [
        "Simon M\\\"unker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-21T08:20:41+00:00",
          "link": "https://arxiv.org/abs/2408.11415v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:34:57+00:00",
          "link": "https://arxiv.org/abs/2408.11415v2",
          "size": "44kb",
          "version": "v2"
        }
      ],
      "title": "Political Bias in LLMs: Unaligned Moral Values in Agent-centric Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.11415",
        "HTML": "https://arxiv.org/html/2408.11415v2",
        "PDF": "https://arxiv.org/pdf/2408.11415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses political bias and moral alignment in language models, focusing on social sciences applications. It does not involve LLM training data processing or engineering."
      },
      "tasks": [
        "Language Modelling",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03409",
      "abstract": "Recently, large vision-language models (LVLMs) have rapidly gained popularity for their strong generation and reasoning capabilities given diverse multimodal inputs. However, these models incur significant computational and memory overhead during inference, which greatly hinders the efficient deployment in practical scenarios. The extensive key-value (KV) cache, necessitated by the lengthy input and output sequences, notably contributes to the high inference cost. Based on this, recent works have investigated ways to reduce the KV cache size for higher efficiency. Although effective, they generally overlook the distinct importance distributions of KV vectors across layers and maintain the same cache size for each layer during the next token prediction. This results in the significant contextual information loss for certain layers, leading to notable performance decline. To address this, we present PrefixKV. It reframes the challenge of determining KV cache sizes for all layers into the task of searching for the optimal global prefix configuration. With an adaptive layer-wise KV retention recipe based on binary search, the maximum contextual information can thus be preserved in each layer, facilitating the generation. Extensive experiments demonstrate that our method achieves the state-of-the-art performance compared with others. It exhibits superior inference efficiency and generation quality trade-offs, showing promising potential for practical applications. Code is available at https://github.com/THU-MIG/PrefixKV.",
      "authors": [
        "Ao Wang",
        "Hui Chen",
        "Jiaxin Li",
        "Jianchao Tan",
        "Kefeng Zhang",
        "Xunliang Cai",
        "Zijia Lin",
        "Jungong Han",
        "Guiguang Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T15:48:59+00:00",
          "link": "https://arxiv.org/abs/2412.03409v1",
          "size": "513kb",
          "version": "v1"
        },
        {
          "date": "2024-12-07T13:23:39+00:00",
          "link": "https://arxiv.org/abs/2412.03409v2",
          "size": "513kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T16:14:49+00:00",
          "link": "https://arxiv.org/abs/2412.03409v3",
          "size": "513kb",
          "version": "v3"
        }
      ],
      "title": "PrefixKV: Adaptive Prefix KV Cache is What Vision Instruction-Following Models Need for Efficient Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03409",
        "HTML": "https://arxiv.org/html/2412.03409v3",
        "PDF": "https://arxiv.org/pdf/2412.03409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on optimizing inference efficiency and generation quality in vision-language models through adaptive KV cache management, with no discussion on processing or creating LLM training data."
      },
      "tasks": [
        "Instruction Following"
      ],
      "repo_urls": [
        "https://github.com/THU-MIG/PrefixKV"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17266",
      "abstract": "The research presented in this paper advances the integration of Hebbian learning into Convolutional Neural Networks (CNNs) for image processing, systematically exploring different architectures to build an optimal configuration, adhering to biological tenability. Hebbian learning operates on local unsupervised neural information to form feature representations, providing an alternative to the popular but arguably biologically implausible and computationally intensive backpropagation learning algorithm. The suggested optimal architecture significantly enhances recent research aimed at integrating Hebbian learning with competition mechanisms and CNNs, expanding their representational capabilities by incorporating hard Winner-Takes-All (WTA) competition, Gaussian lateral inhibition mechanisms, and Bienenstock-Cooper-Munro (BCM) learning rule in a single model. Mean accuracy classification measures during the last half of test epochs on CIFAR-10 revealed that the resulting optimal model matched its end-to-end backpropagation variant with 75.2% each, critically surpassing the state-of-the-art hard-WTA performance in CNNs of the same network depth (64.6%) by 10.6%. It also achieved competitive performance on MNIST (98%) and STL-10 (69.5%). Moreover, results showed clear indications of sparse hierarchical learning through increasingly complex and abstract receptive fields. In summary, our implementation enhances both the performance and the generalisability of the learnt representations and constitutes a crucial step towards more biologically realistic artificial neural networks.",
      "authors": [
        "Julian Jimenez Nimmo and Esther Mondragon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T12:29:37+00:00",
          "link": "https://arxiv.org/abs/2501.17266v1",
          "size": "24336kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T16:11:52+00:00",
          "link": "https://arxiv.org/abs/2501.17266v2",
          "size": "23343kb",
          "version": "v2"
        }
      ],
      "title": "Advancing the Biological Plausibility and Efficacy of Hebbian Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17266",
        "HTML": "https://arxiv.org/html/2501.17266",
        "PDF": "https://arxiv.org/pdf/2501.17266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on integrating Hebbian learning into CNNs for image processing, not on processing or creating LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/julian-jn/advancing-the-biological-plausibility-and-efficacy-of-hebbian-convolutional-neural-networks"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06241",
      "abstract": "Turn-taking is a crucial aspect of human-robot interaction, directly influencing conversational fluidity and user engagement. While previous research has explored turn-taking models in controlled environments, their robustness in real-world settings remains underexplored. In this study, we propose a noise-robust voice activity projection (VAP) model, based on a Transformer architecture, to enhance real-time turn-taking in dialogue robots. To evaluate the effectiveness of the proposed system, we conducted a field experiment in a shopping mall, comparing the VAP system with a conventional cloud-based speech recognition system. Our analysis covered both subjective user evaluations and objective behavioral analysis. The results showed that the proposed system significantly reduced response latency, leading to a more natural conversation where both the robot and users responded faster. The subjective evaluations suggested that faster responses contribute to a better interaction experience.",
      "authors": [
        "Koji Inoue",
        "Yuki Okafuji",
        "Jun Baba",
        "Yoshiki Ohira",
        "Katsuya Hyodo",
        "Tatsuya Kawahara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T14:53:20+00:00",
          "link": "https://arxiv.org/abs/2503.06241v1",
          "size": "3012kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:04:50+00:00",
          "link": "https://arxiv.org/abs/2503.06241v2",
          "size": "3050kb",
          "version": "v2"
        }
      ],
      "title": "A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A Field Experiment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06241",
        "HTML": "https://arxiv.org/html/2503.06241v2",
        "PDF": "https://arxiv.org/pdf/2503.06241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a noise-robust turn-taking system for dialogue robots, which involves processing for real-time response in dialogue systems, but it does not involve processing of LLM training data."
      },
      "tasks": [
        "speech-recognition",
        "Speech Recognition"
      ],
      "repo_urls": [
        "https://github.com/inokoj/VAP-Realtime"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08986",
      "abstract": "Modeling rarefied hypersonic flows remains a fundamental challenge due to the breakdown of classical continuum assumptions in the transition-continuum regime, where the Knudsen number ranges from approximately 0.1 to 10. Conventional Navier-Stokes-Fourier (NSF) models with empirical slip-wall boundary conditions fail to accurately predict nonequilibrium effects such as velocity slip, temperature jump, and shock structure deviations. We develop a physics-constrained machine learning framework that augments transport models and boundary conditions to extend the applicability of continuum solvers in nonequilibrium hypersonic regimes. We employ deep learning PDE models (DPMs) for the viscous stress and heat flux embedded in the governing PDEs and trained via adjoint-based optimization. We evaluate these for two-dimensional supersonic flat-plate flows across a range of Mach and Knudsen numbers. Additionally, we introduce a wall model based on a mixture of skewed Gaussian approximations of the particle velocity distribution function. This wall model replaces empirical slip conditions with physically informed, data-driven boundary conditions for the streamwise velocity and wall temperature. Our results show that a trace-free anisotropic viscosity model, paired with the skewed-Gaussian distribution function wall model, achieves significantly improved accuracy, particularly at high-Mach and high-Knudsen number regimes. Strategies such as parallel training across multiple Knudsen numbers and inclusion of high-Mach data during training are shown to enhance model generalization. Increasing model complexity yields diminishing returns for out-of-sample cases, underscoring the need to balance degrees of freedom and overfitting. This work establishes data-driven, physics-consistent strategies for improving hypersonic flow modeling for regimes in which conventional continuum approaches are invalid.",
      "authors": [
        "Ashish S. Nair",
        "Narendra Singh",
        "Marco Panesi",
        "Justin Sirignano",
        "Jonathan F. MacArt"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:40:00+00:00",
          "link": "https://arxiv.org/abs/2507.08986v1",
          "size": "7845kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Based Machine Learning Closures and Wall Models for Hypersonic Transition-Continuum Boundary Layer Predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08986",
        "HTML": "https://arxiv.org/html/2507.08986v1",
        "PDF": "https://arxiv.org/pdf/2507.08986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research develops physics-based machine learning models for hypersonic flows and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09205",
      "abstract": "Large language models have achieved remarkable progress across many languages. However, Tibetan, as a representative low-resource language, is particularly underrepresented in existing models due to the scarcity of high-quality training corpora. To address this gap, we curate the largest Tibetan pre-training corpus to date, aggregating data from diverse sources and applying a dedicated data cleaning and processing pipeline tailored for Tibetan. With the curated data, we continue pre/post-training a multilingual base model into Banzhida, a multilingual large language model that advances generative AI for Tibetan. To evaluate the Tibetan capabilities of the model, we create new high-quality Tibetan benchmarks, and complement them with existing public benchmarks. Experimental results demonstrate that Banzhida consistently and significantly outperforms both open-source models of similar scale and Tibetan-tailored models across a wide range of tasks.",
      "authors": [
        "Leiyu Pan",
        "Bojian Xiong",
        "Lei Yang",
        "Renren Jin",
        "Shaowei Zhang",
        "Yue Chen",
        "Ling Shi",
        "Jiang Zhou",
        "Junru Wu",
        "Zhen Wang",
        "Jianxiang Peng",
        "Juesi Xiao",
        "Tianyu Dong",
        "Zhuowen Han",
        "Zhuo Chen",
        "Sangjee Dondrub",
        "Caizang Tai",
        "Haixing Zhao",
        "Huaque Cairang",
        "Suonan Cairang",
        "Rou Te",
        "Lengben Zhaxi",
        "Gazang Zhaxi",
        "Zhonglin Ye",
        "Yuhui Zheng",
        "Chunyan Peng",
        "Secha Jia",
        "Pema Tashi",
        "Cizhen Jiacuo",
        "Pema Dorjee",
        "Hongkai Liu",
        "Pema Yanggon",
        "Tsehang Dorjee",
        "Jiaxin Han",
        "Qiongying Hu",
        "Jilin Man",
        "Huanke You",
        "Yuqi Ren",
        "Duo La",
        "Deyi Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:54:05+00:00",
          "link": "https://arxiv.org/abs/2507.09205v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "Banzhida: Advancing Large Language Models for Tibetan with Curated Data and Continual Pre-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09205",
        "HTML": "https://arxiv.org/html/2507.09205v1",
        "PDF": "https://arxiv.org/pdf/2507.09205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is the creation and processing of a large Tibetan pre-training corpus, involving data curation from diverse sources and a specialized data processing pipeline, which is central to the advancement of Tibetan language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09313",
      "abstract": "With the growing research focus on multimodal dialogue systems, the capability for proactive interaction is gradually gaining recognition. As an alternative to conventional turn-by-turn dialogue, users increasingly expect multimodal systems to be more initiative, for example, by autonomously determining the timing of multi-turn responses in real time during video playback. To facilitate progress in this emerging area, we introduce ProactiveBench, the first comprehensive benchmark to evaluate a system's ability to engage in proactive interaction. Since model responses are generated at varying timestamps, we further propose PAUC, the first metric that accounts for the temporal dynamics of model responses. This enables a more accurate evaluation of systems operating in proactive settings. Through extensive benchmarking of various baseline systems on ProactiveBench and a user study of human preferences, we show that PAUC is in better agreement with human preferences than traditional evaluation metrics, which typically only consider the textual content of responses. These findings demonstrate that PAUC provides a more faithful assessment of user experience in proactive interaction scenarios. Project homepage: https://github.com/yellow-binary-tree/ProactiveBench",
      "authors": [
        "Yueqian Wang",
        "Xiaojun Meng",
        "Yifan Wang",
        "Huishuai Zhang",
        "Dongyan Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:11:50+00:00",
          "link": "https://arxiv.org/abs/2507.09313v1",
          "size": "711kb",
          "version": "v1"
        }
      ],
      "title": "ProactiveBench: A Comprehensive Benchmark Evaluating Proactive Interactions in Video Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09313",
        "HTML": "https://arxiv.org/html/2507.09313v1",
        "PDF": "https://arxiv.org/pdf/2507.09313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a new benchmark and evaluation metric for multimodal dialogue systems, without focusing on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09346",
      "abstract": "Task offloading and scheduling in Mobile Edge Computing (MEC) are vital for meeting the low-latency demands of modern IoT and dynamic task scheduling scenarios. MEC reduces the processing burden on resource-constrained devices by enabling task execution at nearby edge servers. However, efficient task scheduling remains a challenge in dynamic, time-sensitive environments. Conventional methods -- such as heuristic algorithms and mixed-integer programming -- suffer from high computational overhead, limiting their real-time applicability. Existing deep learning (DL) approaches offer faster inference but often lack scalability and adaptability to dynamic workloads. To address these issues, we propose a Pointer Network-based architecture for task scheduling in dynamic edge computing scenarios. Our model is trained on a generated synthetic dataset using genetic algorithms to determine the optimal task ordering. Experimental results show that our model achieves lower drop ratios and waiting times than baseline methods, and a soft sequence accuracy of up to 89.2%. Our model consistently achieves inference times under 2 seconds across all evaluated task counts, whereas the integer and binary programming approaches require approximately up to 18 seconds and 90 seconds, respectively. It also shows strong generalization across varying scenarios, and adaptability to real-time changes, offering a scalable and efficient solution for edge-based task management.",
      "authors": [
        "Arild Yonkeu",
        "Mohammadreza Amini",
        "Burak Kantarci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:52:32+00:00",
          "link": "https://arxiv.org/abs/2507.09346v1",
          "size": "1152kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Adaptive Task Management in MEC: A Deep Learning Approach Using Pointer Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09346",
        "HTML": "https://arxiv.org/html/2507.09346v1",
        "PDF": "https://arxiv.org/pdf/2507.09346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves synthetic data generation using genetic algorithms for training a deep learning model in MEC task scheduling but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09711",
      "abstract": "The matrix scaling problem, particularly the Sinkhorn-Knopp algorithm, has been studied for over 60 years. In practice, the algorithm often yields high-quality approximations within just a few iterations. Theoretically, however, the best-known upper bound places it in the class of pseudopolynomial-time approximation algorithms. Meanwhile, the lower-bound landscape remains largely unexplored. Two fundamental questions persist: what accounts for the algorithm's strong empirical performance, and can a tight bound on its iteration count be established?\n  For an $n\\times n$ matrix, its normalized version is obtained by dividing each entry by its largest entry. We say that a normalized matrix has a density $\\gamma$ if there exists a constant $\\rho > 0$ such that one row or column has exactly $\\lceil \\gamma n \\rceil$ entries with values at least $\\rho$, and every other row and column has at least $\\lceil \\gamma n \\rceil$ such entries.\n  For the upper bound, we show that the Sinkhorn-Knopp algorithm produces a nearly doubly stochastic matrix in $O(\\log n - \\log \\varepsilon)$ iterations and $\\widetilde{O}(n^2)$ time for all nonnegative square matrices whose normalized version has a density $\\gamma > 1/2$. Such matrices cover both the algorithm's principal practical inputs and its typical theoretical regime, and the $\\widetilde{O}(n^2)$ runtime is optimal.\n  For the lower bound, we establish a tight bound of $\\widetilde{\\Omega}\\left(n^{1/2}/\\varepsilon\\right)$ iterations for positive matrices under the $\\ell_2$-norm error measure. Moreover, for every $\\gamma < 1/2$, there exists a matrix with density $\\gamma$ for which the algorithm requires $\\Omega\\left(n^{1/2}/\\varepsilon\\right)$ iterations.\n  In summary, our results reveal a sharp phase transition in the Sinkhorn-Knopp algorithm at the density threshold $\\gamma = 1/2$.",
      "authors": [
        "Kun He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:07:51+00:00",
          "link": "https://arxiv.org/abs/2507.09711v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Phase transition of the Sinkhorn-Knopp algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09711",
        "PDF": "https://arxiv.org/pdf/2507.09711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about the Sinkhorn-Knopp algorithm's matrix scaling problem and does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10103",
      "abstract": "Automated Program Repair (APR) is essential for ensuring software reliability and quality while enhancing efficiency and reducing developers' workload. Although rule-based and learning-based APR methods have demonstrated their effectiveness, their performance was constrained by the defect type of repair, the quality of training data, and the size of model parameters. Recently, Large Language Models (LLMs) combined with Retrieval-Augmented-Generation (RAG) have been increasingly adopted in APR tasks. However, current code LLMs and RAG designs neither fully address code repair tasks nor consider code-specific features. To overcome these limitations, we propose SelRepair, a novel APR approach with integration of a fine-tuned LLM with a newly-designed dual RAG module. This approach uses a bug-fix pair dataset for fine-tuning and incorporates semantic and syntactic/structural similarity information through an RAG selection gate. This design ensures relevant information is retrieved efficiently, thereby reducing token length and inference time. Evaluations on Java datasets show SelRepair outperforms other APR methods, achieving 26.29% and 17.64% in terms of exact match (EM) on different datasets while reducing inference time by at least 6.42% with controlled input lengths.",
      "authors": [
        "Hanyang Guo",
        "Xiaoheng Xie",
        "Hong-Ning Dai",
        "Peng Di",
        "Yu Zhang",
        "Bishenghui Tao",
        "Zibin Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:41:51+00:00",
          "link": "https://arxiv.org/abs/2507.10103v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating Automatic Program Repair with Dual Retrieval-Augmented Fine-Tuning and Patch Generation on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10103",
        "HTML": "https://arxiv.org/html/2507.10103v1",
        "PDF": "https://arxiv.org/pdf/2507.10103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions using a dataset for fine-tuning LLMs in automated program repair, but focuses more on the architecture and dual retrieval-augmented design rather than detailed LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10142",
      "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in coordinating multiple agents across simulated benchmarks and constrained scenarios. However, its deployment in real-world multi-agent systems (MAS) remains limited, primarily due to the complex and dynamic nature of such environments. These challenges arise from multiple interacting sources of variability, including fluctuating agent populations, evolving task goals, and inconsistent execution conditions. Together, these factors demand that MARL algorithms remain effective under continuously changing system configurations and operational demands. To better capture and assess this capacity for adjustment, we introduce the concept of \\textit{adaptability} as a unified and practically grounded lens through which to evaluate the reliability of MARL algorithms under shifting conditions, broadly referring to any changes in the environment dynamics that may occur during learning or execution. Centred on the notion of adaptability, we propose a structured framework comprising three key dimensions: learning adaptability, policy adaptability, and scenario-driven adaptability. By adopting this adaptability perspective, we aim to support more principled assessments of MARL performance beyond narrowly defined benchmarks. Ultimately, this survey contributes to the development of algorithms that are better suited for deployment in dynamic, real-world multi-agent systems.",
      "authors": [
        "Siyi Hu",
        "Mohamad A Hady",
        "Jianglin Qiao",
        "Jimmy Cao",
        "Mahardhika Pratama",
        "and Ryszard Kowalczyk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:39:17+00:00",
          "link": "https://arxiv.org/abs/2507.10142v1",
          "size": "802kb",
          "version": "v1"
        }
      ],
      "title": "Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10142",
        "HTML": "https://arxiv.org/html/2507.10142v1",
        "PDF": "https://arxiv.org/pdf/2507.10142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a framework and review for adaptability in multi-agent reinforcement learning but does not involve any LLM training data processing or engineering aspect."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.00499",
      "abstract": "High Power Laser (HPL) systems operate in the attoseconds regime -- the shortest timescale ever created by humanity. HPL systems are instrumental in high-energy physics, leveraging ultra-short impulse durations to yield extremely high intensities, which are essential for both practical applications and theoretical advancements in light-matter interactions. Traditionally, the parameters regulating HPL optical performance have been manually tuned by human experts, or optimized using black-box methods that can be computationally demanding. Critically, black box methods rely on stationarity assumptions overlooking complex dynamics in high-energy physics and day-to-day changes in real-world experimental settings, and thus need to be often restarted. Deep Reinforcement Learning (DRL) offers a promising alternative by enabling sequential decision making in non-static settings. This work explores the feasibility of applying DRL to HPL systems, extending the current research by (1) learning a control policy relying solely on non-destructive image observations obtained from readily available diagnostic devices, and (2) retaining performance when the underlying dynamics vary. We evaluate our method across various test dynamics, and observe that DRL effectively enables cross-domain adaptability, coping with dynamics' fluctuations while achieving 90\\% of the target intensity in test environments.",
      "authors": [
        "Francesco Capuano",
        "Davorin Peceli",
        "Gabriele Tiboni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T14:00:41+00:00",
          "link": "https://arxiv.org/abs/2503.00499v1",
          "size": "9844kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T10:05:39+00:00",
          "link": "https://arxiv.org/abs/2503.00499v2",
          "size": "3088kb",
          "version": "v2"
        }
      ],
      "title": "Shaping Laser Pulses with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00499",
        "HTML": "https://arxiv.org/html/2503.00499v2",
        "PDF": "https://arxiv.org/pdf/2503.00499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper applies reinforcement learning to laser pulse shaping in high-energy physics, unrelated to language model training data processing."
      },
      "tasks": [
        "Decision Making",
        "Deep Reinforcement Learning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16899",
      "abstract": "A key challenge in security analysis is the manual evaluation of potential security weaknesses generated by static application security testing (SAST) tools. Numerous false positives (FPs) in these reports reduce the effectiveness of security analysis. We propose using Large Language Models (LLMs) to improve the assessment of SAST findings. We investigate the ability of LLMs to reduce FPs while trying to maintain a perfect true positive rate, using datasets extracted from the OWASP Benchmark (v1.2) and a real-world software project. Our results indicate that advanced prompting techniques, such as Chain-of-Thought and Self-Consistency, substantially improve FP detection. Notably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark dataset without missing genuine weaknesses. Combining detections from different LLMs would increase this FP detection to approximately 78.9%. Additionally, we demonstrate our approach's generalizability using a real-world dataset covering five SAST tools, three programming languages, and infrastructure files. The best LLM detected 33.85% of all FPs without missing genuine weaknesses, while combining detections from different LLMs would increase this detection to 38.46%. Our findings highlight the potential of LLMs to complement traditional SAST tools, enhancing automation and reducing resources spent addressing false alarms.",
      "authors": [
        "Jonas Wagner",
        "Simon M\\\"uller",
        "Christian N\\\"ather",
        "Jan-Philipp Stegh\\\"ofer",
        "Andreas Both"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T10:46:35+00:00",
          "link": "https://arxiv.org/abs/2506.16899v1",
          "size": "385kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T11:10:27+00:00",
          "link": "https://arxiv.org/abs/2506.16899v2",
          "size": "385kb",
          "version": "v2"
        }
      ],
      "title": "Towards Effective Complementary Security Analysis using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16899",
        "HTML": "https://arxiv.org/html/2506.16899v2",
        "PDF": "https://arxiv.org/pdf/2506.16899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for enhancing security analysis and reducing false positives in security testing tools, without discussing any LLM training data processing contributions."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.04278",
      "abstract": "With the recent success of large language models, Explainable Multimodal Emotion Recognition (EMER), also known as Descriptive MER (DMER), has attracted growing attention from researchers. Unlike traditional discriminative methods that rely on predefined emotion taxonomies, EMER aims to describe a person's emotional state using free-form natural language, thereby enabling fine-grained and interpretable emotion representations. However, this free-form prediction paradigm introduces significant challenges in evaluation. Existing approaches either depend on ground-truth descriptions, which require extensive manual annotations and often fail to capture the full complexity of human emotions, or simplify the evaluation task by shifting focus from assessing descriptions to evaluating emotion labels. However, this simplification overlooks critical aspects such as emotional temporal dynamics, intensity, and uncertainty. To address these limitations, we propose EMER-Ranker, a novel evaluation strategy that reformulates the traditional ``prediction-ground truth'' comparison into the ``prediction-prediction'' comparison, eliminating the need for ground-truth descriptions. We then apply the Bradley-Terry algorithm to convert pairwise comparison outcomes into model-level rankings. Additionally, we explore the potential for automatic preference prediction and introduce EMER-Preference, the first preference dataset specifically designed for human emotions. Our work advances the field of EMER and lays the foundation for more intelligent human-computer interaction systems.",
      "authors": [
        "Zheng Lian",
        "Licai Sun",
        "Haoyu Chen",
        "Zebang Cheng",
        "Fan Zhang",
        "Ziyu Jia",
        "Ziyang Ma",
        "Fei Ma",
        "Xiaojiang Peng",
        "Jianhua Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T07:37:59+00:00",
          "link": "https://arxiv.org/abs/2507.04278v1",
          "size": "10398kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:28:00+00:00",
          "link": "https://arxiv.org/abs/2507.04278v2",
          "size": "10398kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T09:39:44+00:00",
          "link": "https://arxiv.org/abs/2507.04278v3",
          "size": "10393kb",
          "version": "v3"
        }
      ],
      "title": "EMER-Ranker: Learning to Rank Emotion Descriptions in the Absence of Ground Truth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04278",
        "HTML": "https://arxiv.org/html/2507.04278v3",
        "PDF": "https://arxiv.org/pdf/2507.04278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a ranking system for emotion descriptions and introduces a preference dataset for human emotions. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06421",
      "abstract": "While additive manufacturing has opened interesting avenues to reimagine manufacturing as a service (MaaS) platform, transmission of design files from client to manufacturer over networks opens up many cybersecurity challenges. Securing client's intellectual property (IP) especially from cyber-attacks emerges as a major challenge. Earlier works introduced streaming, instead of sharing process plan (G-code) files, as a possible solution. However, executing client's G-codes on manufacturer's machines exposes them to potential malicious G-codes. This paper proposes a viable approach when the client and manufacturer do not trust each other and both the client and manufacturer want to preserve their IP of designs and manufacturing process respectively. The proposed approach is based on segmenting and streaming design (STL) files and employing a novel machine-specific STL to G-code translator at the manufacturer's site in real-time for printing. This approach secures design and manufacturing process IPs as demonstrated in a real-world implementation.",
      "authors": [
        "Seyed Ali Ghazi Asgar",
        "Narasimha Reddy",
        "Satish T.S. Bukkapatnam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:59:21+00:00",
          "link": "https://arxiv.org/abs/2507.06421v1",
          "size": "21233kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T19:48:38+00:00",
          "link": "https://arxiv.org/abs/2507.06421v2",
          "size": "21233kb",
          "version": "v2"
        }
      ],
      "title": "Never Trust the Manufacturer, Never Trust the Client: A Novel Method for Streaming STL Files for Secure Additive manufacturing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06421",
        "HTML": "https://arxiv.org/html/2507.06421v2",
        "PDF": "https://arxiv.org/pdf/2507.06421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses cybersecurity challenges in additive manufacturing, focusing on secure streaming of design files, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09446",
      "abstract": "3D multi-person motion prediction is a highly complex task, primarily due to the dependencies on both individual past movements and the interactions between agents. Moreover, effectively modeling these interactions often incurs substantial computational costs. In this work, we propose a computationally efficient model for multi-person motion prediction by simplifying spatial and temporal interactions. Our approach begins with the design of lightweight dual branches that learn local and global representations for individual and multiple persons separately. Additionally, we introduce a novel cross-level interaction block to integrate the spatial and temporal representations from both branches. To further enhance interaction modeling, we explicitly incorporate the spatial inter-person distance embedding. With above efficient temporal and spatial design, we achieve state-of-the-art performance for multiple metrics on standard datasets of CMU-Mocap, MuPoTS-3D, and 3DPW, while significantly reducing the computational cost. Code is available at https://github.com/Yuanhong-Zheng/EMPMP.",
      "authors": [
        "Yuanhong Zheng",
        "Ruixuan Yu",
        "Jian Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:16:37+00:00",
          "link": "https://arxiv.org/abs/2507.09446v1",
          "size": "6310kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Multi-Person Motion Prediction by Lightweight Spatial and Temporal Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09446",
        "HTML": "https://arxiv.org/html/2507.09446v1",
        "PDF": "https://arxiv.org/pdf/2507.09446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion prediction and model efficiency for multi-person scenarios, without discussing any LLM training data processing or dataset creation steps related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09940",
      "abstract": "In conventional deep learning, the number of neurons typically remains fixed during training. However, insights from biology suggest that the human hippocampus undergoes continuous neuron generation and pruning of neurons over the course of learning, implying that a flexible allocation of capacity can contribute to enhance performance. Real-world datasets often exhibit class imbalance situations where certain classes have far fewer samples than others, leading to significantly reduce recognition accuracy for minority classes when relying on fixed size networks.To address the challenge, we propose a method that periodically adds and removes neurons during training, thereby boosting representational power for minority classes. By retaining critical features learned from majority classes while selectively increasing neurons for underrepresented classes, our approach dynamically adjusts capacity during training. Importantly, while the number of neurons changes throughout training, the final network size and structure remain unchanged, ensuring efficiency and compatibility with deployment.Furthermore, by experiments on three different datasets and five representative models, we demonstrate that the proposed method outperforms fixed size networks and shows even greater accuracy when combined with other imbalance-handling techniques. Our results underscore the effectiveness of dynamic, biologically inspired network designs in improving performance on class-imbalanced data.",
      "authors": [
        "Taigo Sakai",
        "Kazuhiro Hotta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:29:16+00:00",
          "link": "https://arxiv.org/abs/2507.09940v1",
          "size": "291kb",
          "version": "v1"
        }
      ],
      "title": "Long-Tailed Data Classification by Increasing and Decreasing Neurons During Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09940",
        "HTML": "https://arxiv.org/html/2507.09940v1",
        "PDF": "https://arxiv.org/pdf/2507.09940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for adjusting neuron quantities during training to handle class-imbalanced data. However, it focuses on model architecture and learning dynamics rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10098",
      "abstract": "Recently, large language models (LLMs) have demonstrated powerful capabilities in performing various tasks and thus are applied by recent studies to time series forecasting (TSF) tasks, which predict future values with the given historical time series. Existing LLM-based approaches transfer knowledge learned from text data to time series prediction using prompting or fine-tuning strategies. However, LLMs are proficient at reasoning over discrete tokens and semantic patterns but are not initially designed to model continuous numerical time series data. The gaps between text and time series data lead LLMs to achieve inferior performance to a vanilla Transformer model that is directly trained on TSF data. However, the vanilla Transformers often struggle to learn high-level semantic patterns. In this paper, we design a novel Transformer-based architecture that complementarily leverages LLMs and vanilla Transformers, so as to integrate the high-level semantic representations learned by LLMs into the temporal information encoded by time series Transformers, where a hybrid representation is obtained by fusing the representations from the LLM and the Transformer. The resulting fused representation contains both historical temporal dynamics and semantic variation patterns, allowing our model to predict more accurate future values. Experiments on benchmark datasets demonstrate the effectiveness of the proposed approach.",
      "authors": [
        "Chen Su",
        "Yuanhe Tian",
        "Qinyu Liu",
        "Jun Zhang",
        "Yan Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:33:40+00:00",
          "link": "https://arxiv.org/abs/2507.10098v1",
          "size": "2040kb",
          "version": "v1"
        }
      ],
      "title": "Fusing Large Language Models with Temporal Transformers for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10098",
        "HTML": "https://arxiv.org/html/2507.10098v1",
        "PDF": "https://arxiv.org/pdf/2507.10098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about integrating LLMs with Transformers for time series forecasting, and does not address training data processing for LLMs, focusing instead on model architecture."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17921",
      "abstract": "In this paper, we investigate how concept-based models (CMs) respond to out-of-distribution (OOD) inputs. CMs are interpretable neural architectures that first predict a set of high-level concepts (e.g., stripes, black) and then predict a task label from those concepts. In particular, we study the impact of concept interventions (i.e., operations where a human expert corrects a CM's mispredicted concepts at test time) on CMs' task predictions when inputs are OOD. Our analysis reveals a weakness in current state-of-the-art CMs, which we term leakage poisoning, that prevents them from properly improving their accuracy when intervened on for OOD inputs. To address this, we introduce MixCEM, a new CM that learns to dynamically exploit leaked information missing from its concepts only when this information is in-distribution. Our results across tasks with and without complete sets of concept annotations demonstrate that MixCEMs outperform strong baselines by significantly improving their accuracy for both in-distribution and OOD samples in the presence and absence of concept interventions.",
      "authors": [
        "Mateo Espinosa Zarlenga",
        "Gabriele Dominici",
        "Pietro Barbiero",
        "Zohreh Shams",
        "Mateja Jamnik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T20:24:31+00:00",
          "link": "https://arxiv.org/abs/2504.17921v1",
          "size": "34469kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T17:34:54+00:00",
          "link": "https://arxiv.org/abs/2504.17921v2",
          "size": "34606kb",
          "version": "v2"
        }
      ],
      "title": "Avoiding Leakage Poisoning: Concept Interventions Under Distribution Shifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17921",
        "HTML": "https://arxiv.org/html/2504.17921v2",
        "PDF": "https://arxiv.org/pdf/2504.17921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates concept-based models and concept interventions under distribution shifts, which do not involve processing or engineering of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09190",
      "abstract": "Protecting personal computers (PCs) from unauthorized access typically relies on password authentication, which is know to suffer from cognitive burden and weak credentials. As many users nowadays carry mobile devices with advanced security features throughout their day, there is an opportunity to leverage these devices to improve authentication to PCs. In this paper we utilize a token-based passwordless approach where users authenticate to their PC by confirming the authentication request on their smartphones or smartwatches. Upon a request to login to the PC, or to evaluate privileges, the PC issues an authentication request that users receive on their mobile devices, where users can confirm or deny the request. We evaluate button tap and biometric fingerprint verification as confirmation variants, and compare their authentication duration, success rate, and usability to traditional password-based authentication in a user study with 30 participants and a total of 1,200 authentication attempts. Smartwatch-based authentication outperformed password-based authentication and smartphone-based variants in authentication duration, while showing comparable success rates. Participants rated smartwatch-based authentication highest in usability, followed by password-based authentication and smartphone-based authentication.",
      "authors": [
        "Andreas Pramendorfer and Rainhard Dieter Findling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:17:59+00:00",
          "link": "https://arxiv.org/abs/2507.09190v1",
          "size": "67kb",
          "version": "v1"
        }
      ],
      "title": "User-to-PC Authentication Through Confirmation on Mobile Devices: On Usability and Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09190",
        "HTML": "https://arxiv.org/html/2507.09190v1",
        "PDF": "https://arxiv.org/pdf/2507.09190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses user authentication methods and performance but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09342",
      "abstract": "There is a major shortage of Speech-to-Speech Translation (S2ST) datasets for high resource-to-low resource language pairs such as English-to-Yoruba. Thus, in this study, we curated the Bilingual English-to-Yoruba Speech-to-Speech Translation Corpus Version 1 (BENYO-S2ST-Corpus-1). The corpus is based on a hybrid architecture we developed for large-scale direct S2ST corpus creation at reduced cost. To achieve this, we leveraged non speech-to-speech Standard Yoruba (SY) real-time audios and transcripts in the YORULECT Corpus as well as the corresponding Standard English (SE) transcripts. YORULECT Corpus is small scale(1,504) samples, and it does not have paired English audios. Therefore, we generated the SE audios using pre-trained AI models (i.e. Facebook MMS). We also developed an audio augmentation algorithm named AcoustAug based on three latent acoustic features to generate augmented audios from the raw audios of the two languages. BENYO-S2ST-Corpus-1 has 12,032 audio samples per language, which gives a total of 24,064 sample size. The total audio duration for the two languages is 41.20 hours. This size is quite significant. Beyond building S2ST models, BENYO-S2ST-Corpus-1 can be used to build pretrained models or improve existing ones. The created corpus and Coqui framework were used to build a pretrained Yoruba TTS model (named YoruTTS-0.5) as a proof of concept. The YoruTTS-0.5 gave a F0 RMSE value of 63.54 after 1,000 epochs, which indicates moderate fundamental pitch similarity with the reference real-time audio. Ultimately, the corpus architecture in this study can be leveraged by researchers and developers to curate datasets for multilingual high-resource-to-low-resource African languages. This will bridge the huge digital divides in translations among high and low-resource language pairs. BENYO-S2ST-Corpus-1 and YoruTTS-0.5 are publicly available at (https://bit.ly/40bGMwi).",
      "authors": [
        "Emmanuel Adetiba",
        "Abdultaofeek Abayomi",
        "Raymond J. Kala",
        "Ayodele H. Ifijeh",
        "Oluwatobi E. Dare",
        "Olabode Idowu-Bismark",
        "Gabriel O. Sobola",
        "Joy N. Adetiba",
        "Monsurat Adepeju Lateef",
        "Heather Cole-Lewis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:43:04+00:00",
          "link": "https://arxiv.org/abs/2507.09342v1",
          "size": "3114kb",
          "version": "v1"
        }
      ],
      "title": "BENYO-S2ST-Corpus-1: A Bilingual English-to-Yoruba Direct Speech-to-Speech Translation Corpus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09342",
        "PDF": "https://arxiv.org/pdf/2507.09342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution by creating a new bilingual English-to-Yoruba speech-to-speech translation corpus, detailing the process of data generation and augmentation, which is directly related to training data preparation for speech models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09972",
      "abstract": "This paper outlines an incentive-driven and decentralized approach to verifying the veracity of digital content at scale. Widespread misinformation, an explosion in AI-generated content and reduced reliance on traditional news sources demands a new approach for content authenticity and truth-seeking that is fit for a modern, digital world. By using smart contracts and digital identity to incorporate 'trust' into the reward function for published content, not just engagement, we believe that it could be possible to foster a self-propelling paradigm shift to combat misinformation through a community-based governance model. The approach described in this paper requires that content creators stake financial collateral on factual claims for an impartial jury to vet with a financial reward for contribution. We hypothesize that with the right financial and social incentive model users will be motivated to participate in crowdsourced fact-checking and content creators will place more care in their attestations. This is an exploratory paper and there are a number of open issues and questions that warrant further analysis and exploration.",
      "authors": [
        "Lucas Barbosa",
        "Sam Kirshner",
        "Rob Kopel",
        "Eric Tze Kuan Lim and Tom Pagram"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:41:55+00:00",
          "link": "https://arxiv.org/abs/2507.09972v1",
          "size": "2954kb",
          "version": "v1"
        }
      ],
      "title": "A New Incentive Model For Content Trust",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09972",
        "HTML": "https://arxiv.org/html/2507.09972v1",
        "PDF": "https://arxiv.org/pdf/2507.09972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper outlines an incentive model for content trust and misinformation validation, focusing on governance models rather than LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10172",
      "abstract": "Play style identification can provide valuable game design insights and enable adaptive experiences, with the potential to improve game playing agents. Previous work relies on domain knowledge to construct play trace representations using handcrafted features. More recent approaches incorporate the sequential structure of play traces but still require some level of domain abstraction. In this study, we explore the use of unsupervised CNN-LSTM autoencoder models to obtain latent representations directly from low-level play trace data in MicroRTS. We demonstrate that this approach yields a meaningful separation of different game playing agents in the latent space, reducing reliance on domain expertise and its associated biases. This latent space is then used to guide the exploration of diverse play styles within studied AI players.",
      "authors": [
        "Ruizhe Yu Xia",
        "Jeremy Gow",
        "Simon Lucas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:35:43+00:00",
          "link": "https://arxiv.org/abs/2507.10172v1",
          "size": "837kb",
          "version": "v1"
        }
      ],
      "title": "Play Style Identification Using Low-Level Representations of Play Traces in MicroRTS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10172",
        "HTML": "https://arxiv.org/html/2507.10172v1",
        "PDF": "https://arxiv.org/pdf/2507.10172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using models to obtain representations from data but lacks a focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.09394",
      "abstract": "The recently proposed affine frequency division multiplexing (AFDM) is a new transmission waveform that has shown excellent performance in high-mobility environments, making it a sensible option for the next-generation wireless networks. In this paper, we investigate an energy-efficient generalized code index modulation scheme for AFDM by leveraging spread spectrum, referred to as GCIM-AFDM-SS, to combat the interference caused by the doubly dispersive channels. Specifically, the information bits are conveyed by the transmitted symbols as well as the indices of the selected spreading codes in our proposed GCIM-AFDM-SS scheme. To avoid extensive computations, we also develop a lowcomplexity maximal ratio combining (MRC) detector algorithm, which recovers the spreading codes first and demodulates the symbols afterwards. Moreover, an upper bound on the bit error rate (BER) of the proposed GCIM-AFDM-SS system with maximum-likelihood (ML) detection is derived. Numerical results demonstrate the superiority of the proposed GCIM-AFDM-SS system over the classical AFDM spread spectrum (AFDM-SS) and the existing index modulated AFDM (IM-AFDM) systems.",
      "authors": [
        "Mi Qian",
        "Fei Ji",
        "Yao Ge",
        "Miaowen Wen",
        "Yong Liang Guan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Numerical Analysis (cs.NA)",
        "Information Theory (math.IT)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T13:50:41+00:00",
          "link": "https://arxiv.org/abs/2505.09394v1",
          "size": "143kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:35:43+00:00",
          "link": "https://arxiv.org/abs/2505.09394v2",
          "size": "216kb",
          "version": "v2"
        }
      ],
      "title": "Generalized Code Index Modulation Aided AFDM for Spread Spectrum Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09394",
        "HTML": "https://arxiv.org/html/2505.09394v2",
        "PDF": "https://arxiv.org/pdf/2505.09394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The abstract is focused on transmission waveforms and spread spectrum systems, with no mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04526",
      "abstract": "Crack detection on road surfaces is a critical measurement technology in the instrumentation domain, essential for ensuring infrastructure safety and transportation reliability. However, due to limited energy and low-resolution imaging, smart terminal devices struggle to maintain real-time monitoring performance. To overcome these challenges, this paper proposes a multi-stage detection approach for road crack detection, EECD-Net, to enhance accuracy and energy efficiency of instrumentation. Specifically, the sophisticated Super-Resolution Convolutional Neural Network (SRCNN) is employed to address the inherent challenges of low-quality images, which effectively enhance image resolution while preserving critical structural details. Meanwhile, a Spike Convolution Unit (SCU) with Continuous Integrate-and-Fire (CIF) neurons is proposed to convert these images into sparse pulse sequences, significantly reducing power consumption. Additionally, a Gated Attention Transformer (GAT) module is designed to strategically fuse multi-scale feature representations through adaptive attention mechanisms, effectively capturing both long-range dependencies and intricate local crack patterns, and significantly enhancing detection robustness across varying crack morphologies. The experiments on the CrackVision12K benchmark demonstrate that EECD-Net achieves a remarkable 98.6\\% detection accuracy, surpassing state-of-the-art counterparts such as Hybrid-Segmentor by a significant 1.5\\%. Notably, the EECD-Net maintains exceptional energy efficiency, consuming merely 5.6 mJ, which is a substantial 33\\% reduction compared to baseline implementations. This work pioneers a transformative approach in instrumentation-based crack detection, offering a scalable, low-power solution for real-time, large-scale infrastructure monitoring in resource-constrained environments.",
      "authors": [
        "Shuo Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T00:19:36+00:00",
          "link": "https://arxiv.org/abs/2506.04526v1",
          "size": "1080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T11:59:57+00:00",
          "link": "https://arxiv.org/abs/2506.04526v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04526",
        "PDF": "https://arxiv.org/pdf/2506.04526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on energy-efficient crack detection using neural networks for image processing tasks, with no reference to LLM training data processing."
      },
      "tasks": [
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20344",
      "abstract": "Despite its wide range of applications across various domains, the optimization foundations of deep matrix factorization (DMF) remain largely open. In this work, we aim to fill this gap by conducting a comprehensive study of the loss landscape of the regularized DMF problem. Toward this goal, we first provide a closed-form characterization of all critical points of the problem. Building on this, we establish precise conditions under which a critical point is a local minimizer, a global minimizer, a strict saddle point, or a non-strict saddle point. Leveraging these results, we derive a necessary and sufficient condition under which every critical point is either a local minimizer or a strict saddle point. This provides insights into why gradient-based methods almost always converge to a local minimizer of the regularized DMF problem. Finally, we conduct numerical experiments to visualize its loss landscape to support our theory.",
      "authors": [
        "Po Chen",
        "Rujun Jiang",
        "Peng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T11:51:41+00:00",
          "link": "https://arxiv.org/abs/2506.20344v1",
          "size": "1722kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:58:13+00:00",
          "link": "https://arxiv.org/abs/2506.20344v2",
          "size": "1032kb",
          "version": "v2"
        }
      ],
      "title": "A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20344",
        "HTML": "https://arxiv.org/html/2506.20344v2",
        "PDF": "https://arxiv.org/pdf/2506.20344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a loss landscape analysis for deep matrix factorization, focusing on optimization and critical points analysis, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07498",
      "abstract": "Enhancing reasoning capabilities remains a central focus in the LLM reasearch community. A promising direction involves requiring models to simulate code execution step-by-step to derive outputs for given inputs. However, as code is often designed for large-scale systems, direct application leads to over-reliance on complex data structures and algorithms, even for simple cases, resulting in overfitting to algorithmic patterns rather than core reasoning structures. To address this, we propose TeaR, which aims at teaching LLMs to reason better. TeaR leverages careful data curation and reinforcement learning to guide models in discovering optimal reasoning paths through code-related tasks, thereby improving general reasoning abilities. We conduct extensive experiments using two base models and three long-CoT distillation models, with model sizes ranging from 1.5 billion to 32 billion parameters, and across 17 benchmarks spanning Math, Knowledge, Code, and Logical Reasoning. The results consistently show significant performance improvements. Notably, TeaR achieves a 35.9% improvement on Qwen2.5-7B and 5.9% on R1-Distilled-7B.",
      "authors": [
        "Keqin Bao",
        "Nuo Chen",
        "Xiaoyuan Li",
        "Binyuan Hui",
        "Bowen Yu",
        "Fuli Feng",
        "Xiangnan He",
        "Dayiheng Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:34:05+00:00",
          "link": "https://arxiv.org/abs/2507.07498v1",
          "size": "556kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.07498v2",
          "size": "556kb",
          "version": "v2"
        }
      ],
      "title": "Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07498",
        "PDF": "https://arxiv.org/pdf/2507.07498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions data curation as a part of the TeaR method to improve reasoning in LLMs, the main focus is on enhancing reasoning capabilities via reinforcement learning and algorithmic problems, not on training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09050",
      "abstract": "Learning to Optimize (L2O) is a subfield of machine learning (ML) in which ML models are trained to solve parametric optimization problems. The general goal is to learn a fast approximator of solutions to constrained optimization problems, as a function of their defining parameters. Prior L2O methods focus almost entirely on single-level programs, in contrast to the bilevel programs, whose constraints are themselves expressed in terms of optimization subproblems. Bilevel programs have numerous important use cases but are notoriously difficult to solve, particularly under stringent time demands. This paper proposes a framework for learning to solve a broad class of challenging bilevel optimization problems, by leveraging modern techniques for differentiation through optimization problems. The framework is illustrated on an array of synthetic bilevel programs, as well as challenging control system co-design problems, showing how neural networks can be trained as efficient approximators of parametric bilevel optimization.",
      "authors": [
        "James Kotary",
        "Himanshu Sharma",
        "Ethan King",
        "Draguna Vrabie",
        "Ferdinando Fioretto",
        "Jan Drgona"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:48:21+00:00",
          "link": "https://arxiv.org/abs/2507.09050v1",
          "size": "307kb",
          "version": "v1"
        }
      ],
      "title": "A Method for Learning to Solve Parametric Bilevel Optimization with Coupling Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09050",
        "HTML": "https://arxiv.org/html/2507.09050v1",
        "PDF": "https://arxiv.org/pdf/2507.09050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with learning to solve parametric bilevel optimization problems, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09270",
      "abstract": "In this paper, we consider a semantic-aware reconfigurable intelligent surface (RIS)-assisted wireless network, where multiple semantic users (SUs) simultaneously transmit semantic information to an access point (AP) by using the non-orthogonal multiple access (NOMA) method. The SUs can reshape their traffic demands by modifying the semantic extraction factor, while the RIS can reconfigure the channel conditions via the passive beamforming. This provides the AP with greater flexibility to decode the superimposed signals from the SUs. We aim to minimize the system's overall energy consumption, while ensuring that each SU's traffic demand is satisfied. Hence, we formulate a joint optimization problem of the SUs' decoding order and semantic control, as well as the RIS's passive beamforming strategy. This problem is intractable due to the complicated coupling in constraints. To solve this, we decompose the original problem into two subproblems and solve them by using a series of approximate methods. Numerical results show that the joint traffic reshaping and channel reconfiguration scheme significantly improves the energy saving performance of the NOMA transmissions compared to the benchmark methods.",
      "authors": [
        "Songhan Zhao",
        "Yusi Long",
        "Lanhua Li",
        "Bo Gu",
        "Shimin Gong",
        "and Zehui Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T12:44:42+00:00",
          "link": "https://arxiv.org/abs/2507.09270v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "Joint Traffic Reshaping and Channel Reconfiguration in RIS-assisted Semantic NOMA Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09270",
        "HTML": "https://arxiv.org/html/2507.09270v1",
        "PDF": "https://arxiv.org/pdf/2507.09270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with joint traffic reshaping and channel reconfiguration in wireless communications, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10102",
      "abstract": "INTRODUCTION: Older adults with early-stage dementia often retain procedural memory, enabling continued use of familiar technologies. Additionally, symbolic anchors such as photos or personalized content may serve as memory cues to reinforce digital engagement. This study explores how these mechanisms support technology use in dementia care within the South Korean context.\n  METHODS: We conducted in-depth interviews with 11 professional caregivers of community-dwelling older adults with cognitive decline. Grounded theory methods guided the analysis, using iterative coding and constant comparison to identify emergent themes.\n  RESULTS: Caregivers reported that familiar digital routines (e.g., taking photos) persisted through procedural memory. Symbolic anchors such as family photos or recognizable icons enhanced interaction and emotional engagement. However, unfamiliar or anthropomorphic technologies often triggered fear or symbolic resistance.\n  DISCUSSION: Findings highlight the dual role of procedural memory and symbolic anchors in sustaining digital engagement. Designing culturally responsive and cognitively accessible technologies may enhance autonomy and well-being in dementia care.\n  Keywords: procedural memory, symbolic anchors, dementia care, digital engagement, older adults, cultural adaptation, caregiving technologies",
      "authors": [
        "Jeongone Seo",
        "Kyung-zoon Hong",
        "Sol Baik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:35:26+00:00",
          "link": "https://arxiv.org/abs/2507.10102v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "When Familiarity Remains: Procedural Memory, Symbolic Anchors, and Digital Engagement in Dementia Care",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10102",
        "PDF": "https://arxiv.org/pdf/2507.10102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on dementia care and digital engagement with familiar technologies, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10395",
      "abstract": "Collective coherent noise poses challenges for fault-tolerant quantum error correction (FTQEC), as it falls outside the usual stochastic noise models. While constant excitation (CE) codes can naturally avoid coherent noise, a complete fault-tolerant framework for the use of these codes under realistic noise models has been elusive. Here, we introduce a complete fault-tolerant architecture for CE CSS codes based on dual-rail concatenation. After showing that transversal CNOT gates violate CE code constraints, we introduce CE-preserving logical CNOT gates and modified Shor- and Steane-type syndrome extraction schemes using zero-controlled NOT gates and CE-compatible ancilla. This enables fault-tolerant syndrome-extraction circuits fully compatible with CE constraints. We also present an extended stabilizer simulation algorithm that efficiently tracks both stochastic and collective coherent noise. Using our framework, we identify minimal CE codes, including the $[[12,1,3]]$ and $[[14,3,3]]$ codes, and demonstrate that the $[[12,1,3]]$ code achieves strong performance under coherent noise. Our results establish the first complete FTQEC framework for CE codes, demonstrating their robustness to coherent noise. This highlights the potential of CE codes as a possible solution for quantum processors dominated by collective coherent noise.",
      "authors": [
        "Ching-Yi Lai and Pei-Hao Liou and Yingkai Ouyang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:37:12+00:00",
          "link": "https://arxiv.org/abs/2507.10395v1",
          "size": "408kb",
          "version": "v1"
        }
      ],
      "title": "Fault-Tolerant Quantum Error Correction for Constant-Excitation Stabilizer Codes under Coherent Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10395",
        "HTML": "https://arxiv.org/html/2507.10395v1",
        "PDF": "https://arxiv.org/pdf/2507.10395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum error correction mechanisms under coherent noise, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.11816",
      "abstract": "As quantum computers require highly specialized and stable environments to operate, expanding their capabilities within a single system presents significant technical challenges. By interconnecting multiple quantum processors, distributed quantum computing can facilitate the execution of more complex and larger-scale quantum algorithms. End-to-end heuristics for the distribution of quantum circuits have been developed so far. In this work, we derive an exact integer programming approach for the Distributed Quantum Circuit (DQC) problem, assuming fixed module allocations. Since every DQC algorithm necessarily yields a module allocation function, our formulation can be integrated with it as a post-processing step. This improves on the hypergraph partitioning formulation, which finds a module allocation function and an efficient distribution at once. We also show that a suboptimal heuristic to find good allocations can outperform previous methods. In particular, for quantum Fourier transform circuits, we conjecture from experiments that the optimal module allocation is the trivial one found by this method.",
      "authors": [
        "Hyunho Cha and Jungwoo Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T01:48:22+00:00",
          "link": "https://arxiv.org/abs/2501.11816v1",
          "size": "2297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:27:07+00:00",
          "link": "https://arxiv.org/abs/2501.11816v2",
          "size": "874kb",
          "version": "v2"
        }
      ],
      "title": "Module-conditioned distribution of quantum circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11816",
        "HTML": "https://arxiv.org/html/2501.11816v2",
        "PDF": "https://arxiv.org/pdf/2501.11816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on solving the Distributed Quantum Circuit problem and proposes an integer programming approach for module allocation. It does not involve LLM training-data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.09434",
      "abstract": "This work extends our prior work on the distributed nonlinear model predictive control (NMPC) for navigating a robot fleet following a certain flocking behavior in unknown obstructed environments with a more realistic local obstacle avoidance strategy. More specifically, we integrate the local obstacle avoidance constraint using point clouds into the NMPC framework. Here, each agent relies on data from its local sensor to perceive and respond to nearby obstacles. A point cloud processing technique is presented for both two-dimensional and three-dimensional point clouds to minimize the computational burden during the optimization. The process consists of directional filtering and down-sampling that significantly reduce the number of data points. The algorithm's performance is validated through realistic 3D simulations in Gazebo, and its practical feasibility is further explored via hardware-in-the-loop (HIL) simulations on embedded platforms.",
      "authors": [
        "Nuthasith Gerdpratoom",
        "Kaoru Yamamoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T14:42:07+00:00",
          "link": "https://arxiv.org/abs/2505.09434v1",
          "size": "1520kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T08:54:18+00:00",
          "link": "https://arxiv.org/abs/2505.09434v2",
          "size": "1520kb",
          "version": "v2"
        }
      ],
      "title": "Decentralized Nonlinear Model Predictive Control-Based Flock Navigation with Real-Time Obstacle Avoidance in Unknown Obstructed Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09434",
        "HTML": "https://arxiv.org/html/2505.09434",
        "PDF": "https://arxiv.org/pdf/2505.09434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper extends prior work on robot navigation and obstacle avoidance, without touching on any LLM training data processing or engineering methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08842",
      "abstract": "As a promising privacy-aware collaborative model training paradigm, Federated Learning (FL) is becoming popular in the design of distributed recommender systems. However, Federated Recommender Systems (FedRecs) greatly suffer from two major problems: i) extremely high communication overhead due to massive item embeddings involved in recommendation systems, and ii) intolerably low training efficiency caused by the entanglement of both heterogeneous network environments and client devices. Although existing methods attempt to employ various compression techniques to reduce communication overhead, due to the parameter errors introduced by model compression, they inevitably suffer from model performance degradation. To simultaneously address the above problems, this paper presents a communication-efficient FedRec framework named FedRAS, which adopts an action-sharing strategy to cluster the gradients of item embedding into a specific number of model updating actions for communication rather than directly compressing the item embeddings. In this way, the cloud server can use the limited actions from clients to update all the items. Since gradient values are significantly smaller than item embeddings, constraining the directions of gradients (i.e., the action space) introduces smaller errors compared to compressing the entire item embedding matrix into a reduced space. To accommodate heterogeneous devices and network environments, FedRAS incorporates an adaptive clustering mechanism that dynamically adjusts the number of actions. Comprehensive experiments on well-known datasets demonstrate that FedRAS can reduce the size of communication payloads by up to 96.88%, while not sacrificing recommendation performance within various heterogeneous scenarios. We have open-sourced FedRAS at https://github.com/mastlab-T3S/FedRAS.",
      "authors": [
        "Zhufeng Lu",
        "Chentao Jia",
        "Ming Hu",
        "Xiaofei Xie",
        "Mingsong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.08842v1",
          "size": "535kb",
          "version": "v1"
        }
      ],
      "title": "Gradients as an Action: Towards Communication-Efficient Federated Recommender Systems via Adaptive Action Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08842",
        "HTML": "https://arxiv.org/html/2507.08842v1",
        "PDF": "https://arxiv.org/pdf/2507.08842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a communication-efficient framework for federated recommender systems and does not involve any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08896",
      "abstract": "This study introduces an integrated framework for predictive causal inference designed to overcome limitations inherent in conventional single model approaches. Specifically, we combine a Hidden Markov Model (HMM) for spatial health state estimation with a Multi Task and Multi Graph Convolutional Network (MTGCN) for capturing temporal outcome trajectories. The framework asymmetrically treats temporal and spatial information regarding them as endogenous variables in the outcome regression, and exogenous variables in the propensity score model, thereby expanding the standard doubly robust treatment effect estimation to jointly enhance bias correction and predictive accuracy. To demonstrate its utility, we focus on clinical domains such as cancer, dementia, and Parkinson disease, where treatment effects are challenging to observe directly. Simulation studies are conducted to emulate latent disease dynamics and evaluate the model performance under varying conditions. Overall, the proposed framework advances predictive causal inference by structurally adapting to spatiotemporal complexities common in biomedical data.",
      "authors": [
        "Byunghee Lee and Hye Yeon Sin and Joonsung Kang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:11:15+00:00",
          "link": "https://arxiv.org/abs/2507.08896v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "Predictive Causal Inference via Spatio-Temporal Modeling and Penalized Empirical Likelihood",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08896",
        "HTML": "https://arxiv.org/html/2507.08896v1",
        "PDF": "https://arxiv.org/pdf/2507.08896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on predictive causal inference using spatio-temporal modeling in biomedical domains, with no mention of LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09173",
      "abstract": "Drug-drug interactions (DDIs) represent a critical challenge in pharmacology, often leading to adverse drug reactions with significant implications for patient safety and healthcare outcomes. While graph-based methods have achieved strong predictive performance, most approaches treat drug pairs independently, overlooking the complex, context-dependent interactions unique to drug pairs. Additionally, these models struggle to integrate biological interaction networks and molecular-level structures to provide meaningful mechanistic insights. In this study, we propose MolecBioNet, a novel graph-based framework that integrates molecular and biomedical knowledge for robust and interpretable DDI prediction. By modeling drug pairs as unified entities, MolecBioNet captures both macro-level biological interactions and micro-level molecular influences, offering a comprehensive perspective on DDIs. The framework extracts local subgraphs from biomedical knowledge graphs and constructs hierarchical interaction graphs from molecular representations, leveraging classical graph neural network methods to learn multi-scale representations of drug pairs. To enhance accuracy and interpretability, MolecBioNet introduces two domain-specific pooling strategies: context-aware subgraph pooling (CASPool), which emphasizes biologically relevant entities, and attention-guided influence pooling (AGIPool), which prioritizes influential molecular substructures. The framework further employs mutual information minimization regularization to enhance information diversity during embedding fusion. Experimental results demonstrate that MolecBioNet outperforms state-of-the-art methods in DDI prediction, while ablation studies and embedding visualizations further validate the advantages of unified drug pair modeling and multi-scale knowledge integration.",
      "authors": [
        "Mengjie Chen",
        "Ming Zhang and Cunquan Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Molecular Networks (q-bio.MN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:43:19+00:00",
          "link": "https://arxiv.org/abs/2507.09173v1",
          "size": "913kb",
          "version": "v1"
        }
      ],
      "title": "Towards Interpretable Drug-Drug Interaction Prediction: A Graph-Based Approach with Molecular and Network-Level Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09173",
        "HTML": "https://arxiv.org/html/2507.09173v1",
        "PDF": "https://arxiv.org/pdf/2507.09173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on drug-drug interaction prediction using graph-based methods and does not discuss any aspects of LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09607",
      "abstract": "Private inference based on Secure Multi-Party Computation (MPC) addresses data privacy risks in Machine Learning as a Service (MLaaS). However, existing MPC-based private inference frameworks focuses on semi-honest or honest majority models, whose threat models are overly idealistic, while malicious security dishonest majority models face the challenge of low efficiency. To balance security and efficiency, we propose a private inference framework using Helper-Assisted Malicious Security Dishonest Majority Model (HA-MSDM). This framework includes our designed five MPC protocols and a co-optimized strategy. These protocols achieve efficient fixed-round multiplication, exponentiation, and polynomial operations, providing foundational primitives for private inference. The co-optimized strategy balances inference efficiency and accuracy. To enhance efficiency, we employ polynomial approximation for nonlinear layers. For improved accuracy, we construct sixth-order polynomial approximation within a fixed interval to achieve high-precision activation function fitting and introduce parameter-adjusted batch normalization layers to constrain the activation escape problem. Benchmark results on LeNet and AlexNet show our framework achieves 2.4-25.7x speedup in LAN and 1.3-9.5x acceleration in WAN compared to state-of-the-art frameworks (IEEE S&P'25), maintaining high accuracy with only 0.04%-1.08% relative errors.",
      "authors": [
        "Kaiwen Wang",
        "Yuehan Dong",
        "Junchao Fan",
        "Xiaolin Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:24:02+00:00",
          "link": "https://arxiv.org/abs/2507.09607v1",
          "size": "1112kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Private Inference Based on Helper-Assisted Malicious Security Dishonest Majority MPC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09607",
        "PDF": "https://arxiv.org/pdf/2507.09607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for private inference using MPC. It does not involve LLM training data processing efforts."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.19571",
      "abstract": "We numerically investigate the generalized Steklov problem for the modified Helmholtz equation and focus on the relation between its spectrum and the geometric structure of the domain. We address three distinct aspects: (i) the asymptotic behavior of eigenvalues for polygonal domains; (ii) the dependence of the integrals of eigenfunctions on the domain symmetries; and (iii) the localization and exponential decay of Steklov eigenfunctions away from the boundary for smooth shapes and in the presence of corners. For this purpose, we implemented two complementary numerical methods to compute the eigenvalues and eigenfunctions of the associated Dirichlet-to-Neumann operator for various simply-connected planar domains. We also discuss applications of the obtained results in the theory of diffusion-controlled reactions and formulate several conjectures with relevance in spectral geometry.",
      "authors": [
        "Adrien Chaigneau",
        "Denis S. Grebenkov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-30T14:29:13+00:00",
          "link": "https://arxiv.org/abs/2310.19571v1",
          "size": "3214kb",
          "version": "v1"
        },
        {
          "date": "2023-11-03T16:38:58+00:00",
          "link": "https://arxiv.org/abs/2310.19571v2",
          "size": "3196kb",
          "version": "v2"
        }
      ],
      "title": "A numerical study of the Dirichlet-to-Neumann operator in planar domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.19571",
        "PDF": "https://arxiv.org/pdf/2310.19571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mathematical problems related to the Dirichlet-to-Neumann operator and its geometric aspects, without any mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.05242",
      "abstract": "3D Gaussian splatting (3D-GS) has recently revolutionized novel view synthesis in the simultaneous localization and mapping (SLAM) problem. However, most existing algorithms fail to fully capture the underlying structure, resulting in structural inconsistency. Additionally, they struggle with abrupt appearance variations, leading to inconsistent visual quality. To address these problems, we propose SEGS-SLAM, a structure-enhanced 3D Gaussian Splatting SLAM, which achieves high-quality photorealistic mapping. Our main contributions are two-fold. First, we propose a structure-enhanced photorealistic mapping (SEPM) framework that, for the first time, leverages highly structured point cloud to initialize structured 3D Gaussians, leading to significant improvements in rendering quality. Second, we propose Appearance-from-Motion embedding (AfME), enabling 3D Gaussians to better model image appearance variations across different camera poses. Extensive experiments on monocular, stereo, and RGB-D datasets demonstrate that SEGS-SLAM significantly outperforms state-of-the-art (SOTA) methods in photorealistic mapping quality, e.g., an improvement of $19.86\\%$ in PSNR over MonoGS on the TUM RGB-D dataset for monocular cameras. The project page is available at https://segs-slam.github.io/.",
      "authors": [
        "Tianci Wen",
        "Zhiang Liu",
        "Yongchun Fang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T13:50:26+00:00",
          "link": "https://arxiv.org/abs/2501.05242v1",
          "size": "11444kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T07:34:39+00:00",
          "link": "https://arxiv.org/abs/2501.05242v2",
          "size": "11444kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T12:52:15+00:00",
          "link": "https://arxiv.org/abs/2501.05242v3",
          "size": "9350kb",
          "version": "v3"
        }
      ],
      "title": "SEGS-SLAM: Structure-enhanced 3D Gaussian Splatting SLAM with Appearance Embedding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05242",
        "HTML": "https://arxiv.org/html/2501.05242v3",
        "PDF": "https://arxiv.org/pdf/2501.05242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses 3D Gaussian splatting and SLAM algorithms for visual quality in mapping applications, without any mention of LLM training data processing or dataset creation."
      },
      "tasks": [
        "3DGS",
        "Novel View Synthesis",
        "Simultaneous Localization and Mapping"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11897",
      "abstract": "We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential privacy. Existing approaches require communication scaling with the dimensionality, and thus limit the dimensionality of vectors one can efficiently process in this setup.\n  We propose PREAMBLE: {\\bf Pr}ivate {\\bf E}fficient {\\bf A}ggregation {\\bf M}echanism via {\\bf BL}ock-sparse {\\bf E}uclidean Vectors. PREAMBLE builds on an extension of distributed point functions that enables communication- and computation-efficient aggregation of {\\em block-sparse vectors}, which are sparse vectors where the non-zero entries occur in a small number of clusters of consecutive coordinates. We show that these block-sparse DPFs can be combined with random sampling and privacy amplification by sampling results, to allow asymptotically optimal privacy-utility trade-offs for vector aggregation, at a fraction of the communication cost. When coupled with recent advances in numerical privacy accounting, our approach incurs a negligible overhead in noise variance, compared to the Gaussian mechanism used with Prio.",
      "authors": [
        "Hilal Asi and Vitaly Feldman and Hannah Keller and Guy N. Rothblum and Kunal Talwar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T21:58:15+00:00",
          "link": "https://arxiv.org/abs/2503.11897v1",
          "size": "362kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:41:11+00:00",
          "link": "https://arxiv.org/abs/2503.11897v2",
          "size": "175kb",
          "version": "v2"
        }
      ],
      "title": "PREAMBLE: Private and Efficient Aggregation via Block Sparse Vectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11897",
        "HTML": "https://arxiv.org/html/2503.11897v2",
        "PDF": "https://arxiv.org/pdf/2503.11897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses secure aggregation of vectors in federated learning systems and focuses on communication efficiency and privacy rather than LLM training data processing."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08505",
      "abstract": "Vision-Language Models (VLMs) offer promising capabilities for mobile devices, but their deployment faces significant challenges due to computational limitations and energy inefficiency, especially for real-time applications. This study provides a comprehensive survey of deployment frameworks for VLMs on mobile devices, evaluating llama.cpp, MLC-Imp, and mllm in the context of running LLaVA-1.5 7B, MobileVLM-3B, and Imp-v1.5 3B as representative workloads on a OnePlus 13R. Each deployment framework was evaluated on the OnePlus 13R while running VLMs, with measurements covering CPU, GPU, and NPU utilization, temperature, inference time, power consumption, and user experience. Benchmarking revealed critical performance bottlenecks across frameworks: CPU resources were consistently over-utilized during token generation, while GPU and NPU accelerators were largely unused. When the GPU was used, primarily for image feature extraction, it was saturated, leading to degraded device responsiveness. The study contributes framework-level benchmarks, practical profiling tools, and an in-depth analysis of hardware utilization bottlenecks, highlighting the consistent overuse of CPUs and the ineffective or unstable use of GPUs and NPUs in current deployment frameworks.",
      "authors": [
        "Pablo Robin Guerrero",
        "Yueyang Pan",
        "Sanidhya Kashyap"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:30:57+00:00",
          "link": "https://arxiv.org/abs/2507.08505v1",
          "size": "1576kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:25:14+00:00",
          "link": "https://arxiv.org/abs/2507.08505v2",
          "size": "1576kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08505",
        "HTML": "https://arxiv.org/html/2507.08505v2",
        "PDF": "https://arxiv.org/pdf/2507.08505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study surveys deployment frameworks for vision-language models on mobile devices, with no focus on LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09897",
      "abstract": "Even when massively overparameterized, deep neural networks show a remarkable ability to generalize. Research on this phenomenon has focused on generalization within distribution, via smooth interpolation. Yet in some settings neural networks also learn to extrapolate to data far beyond the bounds of the original training set, sometimes even allowing for infinite generalization, implying that an algorithm capable of solving the task has been learned. Here we undertake a case study of the learning dynamics of recurrent neural networks (RNNs) trained on the streaming parity task in order to develop an effective theory of algorithm development. The streaming parity task is a simple but nonlinear task defined on sequences up to arbitrary length. We show that, with sufficient finite training experience, RNNs exhibit a phase transition to perfect infinite generalization. Using an effective theory for the representational dynamics, we find an implicit representational merger effect which can be interpreted as the construction of a finite automaton that reproduces the task. Overall, our results disclose one mechanism by which neural networks can generalize infinitely from finite training experience.",
      "authors": [
        "Loek van Rossem",
        "Andrew M. Saxe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:07:43+00:00",
          "link": "https://arxiv.org/abs/2507.09897v1",
          "size": "1662kb",
          "version": "v1"
        }
      ],
      "title": "Algorithm Development in Neural Networks: Insights from the Streaming Parity Task",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09897",
        "HTML": "https://arxiv.org/html/2507.09897v1",
        "PDF": "https://arxiv.org/pdf/2507.09897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on algorithm development and generalization in neural networks, specifically exploring the learning dynamics of RNNs on the streaming parity task, with no discussion on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10124",
      "abstract": "Identifying bias in LLMs is ongoing. Because they are still in development, what is true today may be false tomorrow. We therefore need general strategies for debiasing that will outlive current models. Strategies developed for debiasing human decision making offer one promising approach as they incorporate an LLM-style prompt intervention designed to bring latent knowledge into awareness during decision making. LLMs trained on vast amounts of information contain information about potential biases, counter-arguments, and contradictory evidence, but that information may only be brought to bear if prompted. Metacognitive prompts developed in the human decision making literature are designed to achieve this, and as I demonstrate here, they show promise with LLMs. The prompt I focus on here is \"could you be wrong?\" Following an LLM response, this prompt leads LLMs to produce additional information, including why they answered as they did, errors, biases, contradictory evidence, and alternatives, none of which were apparent in their initial response. Indeed, this metaknowledge often reveals that how LLMs and users interpret prompts are not aligned. Here I demonstrate this prompt using a set of questions taken from recent articles about LLM biases, including implicit discriminatory biases and failures of metacognition. \"Could you be wrong\" prompts the LLM to identify its own biases and produce cogent metacognitive reflection. I also present another example involving convincing but incomplete information, which is readily corrected by the metacognitive prompt. In sum, this work argues that human psychology offers a new avenue for prompt engineering, leveraging a long history of effective prompt-based improvements to human decision making.",
      "authors": [
        "Thomas T. Hills"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:09:46+00:00",
          "link": "https://arxiv.org/abs/2507.10124v1",
          "size": "1107kb",
          "version": "v1"
        }
      ],
      "title": "Could you be wrong: Debiasing LLMs using a metacognitive prompt for improving human decision making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10124",
        "HTML": "https://arxiv.org/html/2507.10124v1",
        "PDF": "https://arxiv.org/pdf/2507.10124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses debiasing LLMs using metacognitive prompts, which relates to prompt engineering rather than processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.03546",
      "abstract": "Continuous Conditional Generative Modeling (CCGM) estimates high-dimensional data distributions, such as images, conditioned on scalar continuous variables (aka regression labels). While Continuous Conditional Generative Adversarial Networks (CcGANs) were designed for this task, their instability during adversarial learning often leads to suboptimal results. Conditional Diffusion Models (CDMs) offer a promising alternative, generating more realistic images, but their diffusion processes, label conditioning, and model fitting procedures are either not optimized for or incompatible with CCGM, making it difficult to integrate CcGANs' vicinal approach. To address these issues, we introduce Continuous Conditional Diffusion Models (CCDMs), the first CDM specifically tailored for CCGM. CCDMs address existing limitations with specially designed conditional diffusion processes, a novel hard vicinal image denoising loss, a customized label embedding method, and efficient conditional sampling procedures. Through comprehensive experiments on four datasets with resolutions ranging from 64x64 to 192x192, we demonstrate that CCDMs outperform state-of-the-art CCGM models, establishing a new benchmark. Ablation studies further validate the model design and implementation, highlighting that some widely used CDM implementations are ineffective for the CCGM task. Our code is publicly available at https://github.com/UBCDingXin/CCDM.",
      "authors": [
        "Xin Ding and Yongwei Wang and Kao Zhang and Z. Jane Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-06T15:10:19+00:00",
          "link": "https://arxiv.org/abs/2405.03546v1",
          "size": "6018kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T12:45:40+00:00",
          "link": "https://arxiv.org/abs/2405.03546v2",
          "size": "8136kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T16:49:31+00:00",
          "link": "https://arxiv.org/abs/2405.03546v3",
          "size": "4566kb",
          "version": "v3"
        }
      ],
      "title": "CCDM: Continuous Conditional Diffusion Models for Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.03546",
        "HTML": "https://arxiv.org/html/2405.03546v3",
        "PDF": "https://arxiv.org/pdf/2405.03546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses continuous conditional diffusion models for image generation, without any focus on LLM training data processing or engineering."
      },
      "tasks": [
        "Denoising",
        "Image Generation",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/ubcdingxin/ccdm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12981",
      "abstract": "Current Retrieval-Augmented Generation systems use uniform processing, causing inefficiency as simple queries consume resources similar to complex multi-hop tasks. We present SymRAG, a framework that introduces adaptive query routing via real-time complexity and load assessment to select symbolic, neural, or hybrid pathways. SymRAG's neuro-symbolic approach adjusts computational pathways based on both query characteristics and system load, enabling efficient resource allocation across diverse query types. By combining linguistic and structural query properties with system load metrics, SymRAG allocates resources proportional to reasoning requirements. Evaluated on 2,000 queries across HotpotQA (multi-hop reasoning) and DROP (discrete reasoning) using Llama-3.2-3B and Mistral-7B models, SymRAG achieves competitive accuracy (97.6--100.0% exact match) with efficient resource utilization (3.6--6.2% CPU utilization, 0.985--3.165s processing). Disabling adaptive routing increases processing time by 169--1151%, showing its significance for complex models. These results suggest adaptive computation strategies are more sustainable and scalable for hybrid AI systems that use dynamic routing and neuro-symbolic frameworks.",
      "authors": [
        "Safayat Bin Hakim",
        "Muhammad Adil",
        "Alvaro Velasquez",
        "Houbing Herbert Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T22:35:43+00:00",
          "link": "https://arxiv.org/abs/2506.12981v1",
          "size": "1397kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T05:28:30+00:00",
          "link": "https://arxiv.org/abs/2506.12981v2",
          "size": "1394kb",
          "version": "v2"
        }
      ],
      "title": "SymRAG: Efficient Neuro-Symbolic Retrieval Through Adaptive Query Routing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12981",
        "HTML": "https://arxiv.org/html/2506.12981v2",
        "PDF": "https://arxiv.org/pdf/2506.12981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for adaptive query routing in neuro-symbolic systems, and does not discuss the processing, creation, or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09344",
      "abstract": "Autonomous systems across diverse domains have underscored the need for drift-resilient state estimation. Although satellite-based positioning and cameras are widely used, they often suffer from limited availability in many environments. As a result, positioning must rely solely on inertial sensors, leading to rapid accuracy degradation over time due to sensor biases and noise. To counteract this, alternative update sources-referred to as information aiding-serve as anchors of certainty. Among these, the zero-velocity update (ZUPT) is particularly effective in providing accurate corrections during stationary intervals, though it is restricted to surface-bound platforms. This work introduces a controlled ZUPT (C-ZUPT) approach for aerial navigation and control, independent of surface contact. By defining an uncertainty threshold, C-ZUPT identifies quasi-static equilibria to deliver precise velocity updates to the estimation filter. Extensive validation confirms that these opportunistic, high-quality updates significantly reduce inertial drift and control effort. As a result, C-ZUPT mitigates filter divergence and enhances navigation stability, enabling more energy-efficient hovering and substantially extending sustained flight-key advantages for resource-constrained aerial systems.",
      "authors": [
        "Daniel Engelsman and Itzik Klein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:44:35+00:00",
          "link": "https://arxiv.org/abs/2507.09344v1",
          "size": "1982kb",
          "version": "v1"
        }
      ],
      "title": "C-ZUPT: Stationarity-Aided Aerial Hovering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09344",
        "HTML": "https://arxiv.org/html/2507.09344v1",
        "PDF": "https://arxiv.org/pdf/2507.09344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on autonomous systems, specifically aerial navigation and control using inertial sensors, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09536",
      "abstract": "Definition modeling, the task of generating new definitions for words in context, holds great prospect as a means to assist the work of lexicographers in documenting a broader variety of lects and languages, yet much remains to be done in order to assess how we can leverage pre-existing models for as-of-yet unsupported languages. In this work, we focus on adapting existing models to Belarusian, for which we propose a novel dataset of 43,150 definitions. Our experiments demonstrate that adapting a definition modeling systems requires minimal amounts of data, but that there currently are gaps in what automatic metrics do capture.",
      "authors": [
        "Daniela Kazakouskaya",
        "Timothee Mickus",
        "Janine Siewert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:35:23+00:00",
          "link": "https://arxiv.org/abs/2507.09536v1",
          "size": "9145kb",
          "version": "v1"
        }
      ],
      "title": "Adapting Definition Modeling for New Languages: A Case Study on Belarusian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09536",
        "HTML": "https://arxiv.org/html/2507.09536v1",
        "PDF": "https://arxiv.org/pdf/2507.09536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper involves creating a novel dataset for definition modeling in Belarusian, detailing the adaptation of models to this new dataset. This includes steps on data preparation, which is relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10131",
      "abstract": "Accurate inference of human intent enables human-robot collaboration without constraining human control or causing conflicts between humans and robots. We present GUIDER (Global User Intent Dual-phase Estimation for Robots), a probabilistic framework that enables a robot to estimate the intent of human operators. GUIDER maintains two coupled belief layers, one tracking navigation goals and the other manipulation goals. In the Navigation phase, a Synergy Map blends controller velocity with an occupancy grid to rank interaction areas. Upon arrival at a goal, an autonomous multi-view scan builds a local 3D cloud. The Manipulation phase combines U2Net saliency, FastSAM instance saliency, and three geometric grasp-feasibility tests, with an end-effector kinematics-aware update rule that evolves object probabilities in real-time. GUIDER can recognize areas and objects of intent without predefined goals. We evaluated GUIDER on 25 trials (five participants x five task variants) in Isaac Sim, and compared it with two baselines, one for navigation and one for manipulation. Across the 25 trials, GUIDER achieved a median stability of 93-100% during navigation, compared with 60-100% for the BOIR baseline, with an improvement of 39.5% in a redirection scenario (T5). During manipulation, stability reached 94-100% (versus 69-100% for Trajectron), with a 31.4% difference in a redirection task (T3). In geometry-constrained trials (manipulation), GUIDER recognized the object intent three times earlier than Trajectron (median remaining time to confident prediction 23.6 s vs 7.8 s). These results validate our dual-phase framework and show improvements in intent inference in both phases of mobile manipulation tasks.",
      "authors": [
        "Cesar Alan Contreras",
        "Manolis Chiou",
        "Alireza Rastegarpanah",
        "Michal Szulik",
        "Rustam Stolkin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:21:27+00:00",
          "link": "https://arxiv.org/abs/2507.10131v1",
          "size": "10214kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Human Intent Prediction for Mobile Manipulation: An Evaluation with Human-Inspired Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10131",
        "HTML": "https://arxiv.org/html/2507.10131v1",
        "PDF": "https://arxiv.org/pdf/2507.10131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human intent prediction in human-robot collaboration, specifically for mobile manipulation tasks and does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10409",
      "abstract": "This study addresses the challenge of balancing energy efficiency with performance in AI/ML models, focusing on DeepRX, a deep learning receiver based on a fully convolutional ResNet architecture. We evaluate the energy consumption of DeepRX, considering factors including FLOPs/Watt and FLOPs/clock, and find consistency between estimated and actual energy usage, influenced by memory access patterns. The research extends to comparing energy dynamics during training and inference phases. A key contribution is the application of knowledge distillation (KD) to train a compact DeepRX \\textit{student} model that emulates the performance of the \\textit{teacher} model but with reduced energy consumption. We experiment with different student model sizes, optimal teacher sizes, and KD hyperparameters. Performance is measured by comparing the Bit Error Rate (BER) performance versus Signal-to-Interference \\& Noise Ratio (SINR) values of the distilled model and a model trained from scratch. The distilled models demonstrate a lower error floor across SINR levels, highlighting the effectiveness of KD in achieving energy-efficient AI solutions.",
      "authors": [
        "Amine Lbath",
        "Ibtissam Labriji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:54:06+00:00",
          "link": "https://arxiv.org/abs/2507.10409v1",
          "size": "657kb",
          "version": "v1"
        }
      ],
      "title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10409",
        "HTML": "https://arxiv.org/html/2507.10409v1",
        "PDF": "https://arxiv.org/pdf/2507.10409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on energy-efficient AI solutions using knowledge distillation in model training, without any emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15686",
      "abstract": "Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework \\emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.",
      "authors": [
        "Jiahe Qin",
        "Junpeng Li",
        "Changchun Hua and Yana Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T13:20:11+00:00",
          "link": "https://arxiv.org/abs/2506.15686v1",
          "size": "2555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:39:33+00:00",
          "link": "https://arxiv.org/abs/2506.15686v2",
          "size": "2559kb",
          "version": "v2"
        }
      ],
      "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15686",
        "HTML": "https://arxiv.org/html/2506.15686v2",
        "PDF": "https://arxiv.org/pdf/2506.15686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a classification method for labeled proportion learning in machine learning contexts, which does not involve LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.18403",
      "abstract": "The effectiveness of AI debugging follows a predictable exponential decay pattern; most models lose 60-80% of their debugging capability within just 2-3 attempts, despite iterative debugging being a critical capability for practical code generation systems. We introduce the Debugging Decay Index (DDI), a mathematical framework that quantifies when debugging becomes ineffective and predicts intervention points. Our strategic fresh start approach shifts from exploitation to exploration at strategic points in the debugging process, demonstrating that well-timed interventions can rescue the effectiveness of debugging. DDI reveals a fundamental limitation in current AI debugging and provides the first quantitative framework for optimising iterative code generation strategies.",
      "authors": [
        "Muntasir Adnan and Carlos C. N. Kuhn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T08:40:45+00:00",
          "link": "https://arxiv.org/abs/2506.18403v1",
          "size": "1140kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:04:33+00:00",
          "link": "https://arxiv.org/abs/2506.18403v2",
          "size": "1740kb",
          "version": "v2"
        }
      ],
      "title": "The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18403",
        "HTML": "https://arxiv.org/html/2506.18403v2",
        "PDF": "https://arxiv.org/pdf/2506.18403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a mathematical framework for debugging code generation models, not concerning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08983",
      "abstract": "While poisoning attacks on machine learning models have been extensively studied, the mechanisms by which adversaries can distribute poisoned models at scale remain largely unexplored. In this paper, we shed light on how model leaderboards -- ranked platforms for model discovery and evaluation -- can serve as a powerful channel for adversaries for stealthy large-scale distribution of poisoned models. We present TrojanClimb, a general framework that enables injection of malicious behaviors while maintaining competitive leaderboard performance. We demonstrate its effectiveness across four diverse modalities: text-embedding, text-generation, text-to-speech and text-to-image, showing that adversaries can successfully achieve high leaderboard rankings while embedding arbitrary harmful functionalities, from backdoors to bias injection. Our findings reveal a significant vulnerability in the machine learning ecosystem, highlighting the urgent need to redesign leaderboard evaluation mechanisms to detect and filter malicious (e.g., poisoned) models, while exposing broader security implications for the machine learning community regarding the risks of adopting models from unverified sources.",
      "authors": [
        "Anshuman Suri",
        "Harsh Chaudhari",
        "Yuefeng Peng",
        "Ali Naseh",
        "Amir Houmansadr",
        "Alina Oprea"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.08983v1",
          "size": "827kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Leaderboards for Large-Scale Distribution of Malicious Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08983",
        "HTML": "https://arxiv.org/html/2507.08983v1",
        "PDF": "https://arxiv.org/pdf/2507.08983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses injecting malicious behavior in models via leaderboards to expose security vulnerabilities, without focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09866",
      "abstract": "Code large language models (LLMs) enhance programming by understanding and generating code across languages, offering intelligent feedback, bug detection, and code updates through reflection, improving development efficiency and accessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code generation and real-world relevance, previous works ignore the scenario of modifying code in repositories. Considering challenges remaining in improving reflection capabilities and avoiding data contamination in dynamic benchmarks, we introduce LiveRepoReflection, a challenging benchmark for evaluating code understanding and generation in multi-file repository contexts, featuring 1,888 rigorously filtered test cases across $6$ programming languages to ensure diversity, correctness, and high difficulty. Further, we create RepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning dataset derived from diverse sources, used to train RepoReflectionCoder through a two-turn dialogue process involving code generation and error-driven repair. The leaderboard evaluates over 40 LLMs to reflect the model performance of repository-based code reflection.",
      "authors": [
        "Wei Zhang",
        "Jian Yang",
        "Jiaxi Yang",
        "Ya Wang",
        "Zhoujun Li",
        "Zeyu Cui",
        "Binyuan Hui",
        "Junyang Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:36:27+00:00",
          "link": "https://arxiv.org/abs/2507.09866v1",
          "size": "1198kb",
          "version": "v1"
        }
      ],
      "title": "Turning the Tide: Repository-based Code Reflection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09866",
        "HTML": "https://arxiv.org/html/2507.09866v1",
        "PDF": "https://arxiv.org/pdf/2507.09866"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a dataset, RepoReflection-Instruct, which is large-scale and quality-filtered, focusing on instruction-tuning data sourced from diverse locations. This dataset creation involves clear data processing steps aimed at improving data quality for training LLMs in code reflection tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10318",
      "abstract": "Leveraging the vision foundation models has emerged as a mainstream paradigm that improves the performance of image feature matching. However, previous works have ignored the misalignment when introducing the foundation models into feature matching. The misalignment arises from the discrepancy between the foundation models focusing on single-image understanding and the cross-image understanding requirement of feature matching. Specifically, 1) the embeddings derived from commonly used foundation models exhibit discrepancies with the optimal embeddings required for feature matching; 2) lacking an effective mechanism to leverage the single-image understanding ability into cross-image understanding. A significant consequence of the misalignment is they struggle when addressing multi-instance feature matching problems. To address this, we introduce a simple but effective framework, called IMD (Image feature Matching with a pre-trained Diffusion model) with two parts: 1) Unlike the dominant solutions employing contrastive-learning based foundation models that emphasize global semantics, we integrate the generative-based diffusion models to effectively capture instance-level details. 2) We leverage the prompt mechanism in generative model as a natural tunnel, propose a novel cross-image interaction prompting module to facilitate bidirectional information interaction between image pairs. To more accurately measure the misalignment, we propose a new benchmark called IMIM, which focuses on multi-instance scenarios. Our proposed IMD establishes a new state-of-the-art in commonly evaluated benchmarks, and the superior improvement 12% in IMIM indicates our method efficiently mitigates the misalignment.",
      "authors": [
        "Yuhan Liu",
        "Jingwen Fu",
        "Yang Wu",
        "Kangyi Wu",
        "Pengna Li",
        "Jiayi Wu",
        "Sanping Zhou",
        "Jingmin Xin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:28:15+00:00",
          "link": "https://arxiv.org/abs/2507.10318v1",
          "size": "783kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Gap: Aligning Vision Foundation Models to Image Feature Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10318",
        "HTML": "https://arxiv.org/html/2507.10318v1",
        "PDF": "https://arxiv.org/pdf/2507.10318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the alignment of vision foundation models for image feature matching, which involves embedding and interaction but does not specifically cover LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2212.00648",
      "abstract": "Visual recognition of materials and their states is essential for understanding most aspects of the world, from determining whether food is cooked, metal is rusted, or a chemical reaction has occurred. However, current image recognition methods are limited to specific classes and properties and can't handle the vast number of material states in the world. To address this, we present MatSim: the first dataset and benchmark for computer vision-based recognition of similarities and transitions between materials and textures, focusing on identifying any material under any conditions using one or a few examples. The dataset contains synthetic and natural images. The synthetic images were rendered using giant collections of textures, objects, and environments generated by computer graphics artists. We use mixtures and gradual transitions between materials to allow the system to learn cases with smooth transitions between states (like gradually cooked food). We also render images with materials inside transparent containers to support beverage and chemistry lab use cases. We use this dataset to train a siamese net that identifies the same material in different objects, mixtures, and environments. The descriptor generated by this net can be used to identify the states of materials and their subclasses using a single image. We also present the first few-shot material recognition benchmark with images from a wide range of fields, including the state of foods and drinks, types of grounds, and many other use cases. We show that a net trained on the MatSim synthetic dataset outperforms state-of-the-art models like Clip on the benchmark and also achieves good results on other unsupervised material classification tasks.",
      "authors": [
        "Manuel S. Drehwald",
        "Sagi Eppel",
        "Jolina Li",
        "Han Hao",
        "Alan Aspuru-Guzik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-01T16:49:53+00:00",
          "link": "https://arxiv.org/abs/2212.00648v1",
          "size": "32015kb",
          "version": "v1"
        },
        {
          "date": "2022-12-14T02:12:27+00:00",
          "link": "https://arxiv.org/abs/2212.00648v2",
          "size": "32015kb",
          "version": "v2"
        },
        {
          "date": "2023-03-13T04:06:24+00:00",
          "link": "https://arxiv.org/abs/2212.00648v3",
          "size": "15352kb",
          "version": "v3"
        },
        {
          "date": "2023-03-17T04:40:59+00:00",
          "link": "https://arxiv.org/abs/2212.00648v4",
          "size": "19508kb",
          "version": "v4"
        }
      ],
      "title": "One-shot recognition of any material anywhere using contrastive learning with physics-based rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.00648",
        "PDF": "https://arxiv.org/pdf/2212.00648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the creation of MatSim, a new dataset and benchmark for material recognition, involving clear data processing steps like generating synthetic images using computer graphics, relevant to LLM training data creation."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/ICCV2023/html/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.html",
      "tasks": [
        "Contrastive Learning",
        "Material Classification",
        "Material Recognition",
        "One-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/sagieppel/MatSim-Dataset-Generator-Scripts-And-Neural-net"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.16173",
      "abstract": "Collecting mobile datasets remains challenging for academic researchers due to limited data access and technical barriers. Commercial organizations often possess exclusive access to mobile data, leading to a \"data monopoly\" that restricts the independence of academic research. Existing open-source mobile data collection frameworks primarily focus on mobile sensing data rather than screen content, which is crucial for various research studies. We present Crepe, a no-code Android app that enables researchers to collect information displayed on screen through simple demonstrations of target data. Crepe utilizes a novel Graph Query technique which augments the structures of mobile UI screens to support flexible identification, location, and collection of specific data pieces. The tool emphasizes participants' privacy and agency by providing full transparency over collected data and allowing easy opt-out. We designed and built Crepe for research purposes only and in scenarios where researchers obtain explicit consent from participants. Code for Crepe will be open-sourced to support future academic research data collection.",
      "authors": [
        "Yuwen Lu",
        "Meng Chen",
        "Qi Zhao",
        "Victor Cox",
        "Yang Yang",
        "Meng Jiang",
        "Jay Brockman",
        "Tamara Kay",
        "Toby Jia-Jun Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-23T17:53:10+00:00",
          "link": "https://arxiv.org/abs/2406.16173v1",
          "size": "2264kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T02:59:50+00:00",
          "link": "https://arxiv.org/abs/2406.16173v2",
          "size": "4980kb",
          "version": "v2"
        }
      ],
      "title": "Crepe: A Mobile Screen Data Collector Using Graph Query",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.16173",
        "HTML": "https://arxiv.org/html/2406.16173v2",
        "PDF": "https://arxiv.org/pdf/2406.16173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Crepe for mobile data collection, which is a tool for collecting screen data. While it involves data collection, it is not specifically focused on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18672",
      "abstract": "Class-Continual Learning (CCL) enables models to continuously learn new class knowledge while retaining previous classes, facilitating adaptation and evolution in dynamic, real-world environments. Traditional CCL methods primarily rely on visual features, which limits their effectiveness in complex, multimodal scenarios. In contrast, Vision-Language Models (VLMs) show promising potential for enhancing CCL by leveraging pre-trained knowledge and fusing multi-modal semantic cues such as text and vision. However, existing approaches struggle to mitigate catastrophic forgetting while preserving the generalization strengths of VLMs across diverse modalities. To address these challenges, we propose CalFuse, a framework for feature Calibration enhanced parameter Fusion, which enhances dynamic knowledge fusion. CalFuse introduces a dynamic feature calibration mechanism that iteratively adjusts the contribution of original visual features to the final class decision, thereby preserving the model's intrinsic generalization capability across modalities. Simultaneously, a parameter fusion strategy effectively fuses newly acquired knowledge with prior task parameters, maintaining a balance between acquiring new class representations and preserving old knowledge. Experimental results on popular benchmarks (e.g., CIFAR100 and ImageNet100) validate the superiority of the proposed method.",
      "authors": [
        "Juncen Guo",
        "Yang Liu",
        "Xiaoguang Zhu",
        "Lianlong Sun",
        "Liangyu Teng",
        "Jingyi Wu",
        "Di Li",
        "Linxiao Gong",
        "Weiwei Jiang",
        "Wei Zhou",
        "Liang Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T13:44:12+00:00",
          "link": "https://arxiv.org/abs/2503.18672v1",
          "size": "1515kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T10:00:27+00:00",
          "link": "https://arxiv.org/abs/2503.18672v2",
          "size": "1515kb",
          "version": "v2"
        },
        {
          "date": "2025-04-15T13:10:16+00:00",
          "link": "https://arxiv.org/abs/2503.18672v3",
          "size": "4006kb",
          "version": "v3"
        },
        {
          "date": "2025-04-17T12:26:16+00:00",
          "link": "https://arxiv.org/abs/2503.18672v4",
          "size": "2195kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T16:05:21+00:00",
          "link": "https://arxiv.org/abs/2503.18672v5",
          "size": "2475kb",
          "version": "v5"
        },
        {
          "date": "2025-07-13T10:03:20+00:00",
          "link": "https://arxiv.org/abs/2503.18672v6",
          "size": "2473kb",
          "version": "v6"
        }
      ],
      "title": "CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18672",
        "HTML": "https://arxiv.org/html/2503.18672",
        "PDF": "https://arxiv.org/pdf/2503.18672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a novel method for class-continual learning using vision-language models, its primary focus is on enhancing multimodal learning rather than LLM training data processing. It may briefly touch on data considerations but not in the context of LLM data processing."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Incremental Learning",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05948",
      "abstract": "Video Instance Segmentation (VIS) fundamentally struggles with pervasive challenges including object occlusions, motion blur, and appearance variations during temporal association. To overcome these limitations, this work introduces geometric awareness to enhance VIS robustness by strategically leveraging monocular depth estimation. We systematically investigate three distinct integration paradigms. Expanding Depth Channel (EDC) method concatenates the depth map as input channel to segmentation networks; Sharing ViT (SV) designs a uniform ViT backbone, shared between depth estimation and segmentation branches; Depth Supervision (DS) makes use of depth prediction as an auxiliary training guide for feature learning. Though DS exhibits limited effectiveness, benchmark evaluations demonstrate that EDC and SV significantly enhance the robustness of VIS. When with Swin-L backbone, our EDC method gets 56.2 AP, which sets a new state-of-the-art result on OVIS benchmark. This work conclusively establishes depth cues as critical enablers for robust video understanding.",
      "authors": [
        "Quanzhu Niu",
        "Yikang Zhou",
        "Shihao Chen",
        "Tao Zhang",
        "Shunping Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:44:49+00:00",
          "link": "https://arxiv.org/abs/2507.05948v1",
          "size": "35103kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:43:38+00:00",
          "link": "https://arxiv.org/abs/2507.05948v2",
          "size": "35113kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05948",
        "HTML": "https://arxiv.org/html/2507.05948v2",
        "PDF": "https://arxiv.org/pdf/2507.05948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores geometric cues for video instance segmentation, with no connection to LLM training data processing or related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07024",
      "abstract": "We introduce FlexOlmo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on closed datasets, and (2) data-flexible inference, where these parameters along with their associated data can be flexibly included or excluded from model inferences with no further training. FlexOlmo employs a mixture-of-experts (MoE) architecture where each expert is trained independently on closed datasets and later integrated through a new domain-informed routing without any joint training. FlexOlmo is trained on FlexMix, a corpus we curate comprising publicly available datasets alongside seven domain-specific sets, representing realistic approximations of closed sets. We evaluate models with up to 37 billion parameters (20 billion active) on 31 diverse downstream tasks. We show that a general expert trained on public data can be effectively combined with independently trained experts from other data owners, leading to an average 41% relative improvement while allowing users to opt out of certain data based on data licensing or permission requirements. Our approach also outperforms prior model merging methods by 10.1% on average and surpasses the standard MoE trained without data restrictions using the same training FLOPs. Altogether, this research presents a solution for both data owners and researchers in regulated industries with sensitive or protected data. FlexOlmo enables benefiting from closed data while respecting data owners' preferences by keeping their data local and supporting fine-grained control of data access during inference.",
      "authors": [
        "Weijia Shi",
        "Akshita Bhagia",
        "Kevin Farhat",
        "Niklas Muennighoff",
        "Pete Walsh",
        "Jacob Morrison",
        "Dustin Schwenk",
        "Shayne Longpre",
        "Jake Poznanski",
        "Allyson Ettinger",
        "Daogao Liu",
        "Margaret Li",
        "Dirk Groeneveld",
        "Mike Lewis",
        "Wen-tau Yih",
        "Luca Soldaini",
        "Kyle Lo",
        "Noah A. Smith",
        "Luke Zettlemoyer",
        "Pang Wei Koh",
        "Hannaneh Hajishirzi",
        "Ali Farhadi",
        "Sewon Min"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:54:21+00:00",
          "link": "https://arxiv.org/abs/2507.07024v1",
          "size": "825kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T23:12:33+00:00",
          "link": "https://arxiv.org/abs/2507.07024v2",
          "size": "827kb",
          "version": "v2"
        }
      ],
      "title": "FlexOlmo: Open Language Models for Flexible Data Use",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07024",
        "HTML": "https://arxiv.org/html/2507.07024v2",
        "PDF": "https://arxiv.org/pdf/2507.07024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses FlexOlmo, which involves curated datasets and supports distributed training without data sharing. This contributes to LLM training data processing by addressing data sharing restrictions while maintaining data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09608",
      "abstract": "We propose a novel framework for phase retrieval that leverages Langevin dynamics to enable efficient posterior sampling, yielding reconstructions that explicitly balance distortion and perceptual quality. Unlike conventional approaches that prioritize pixel-wise accuracy, our method navigates the perception-distortion tradeoff through a principled combination of stochastic sampling, learned denoising, and model-based updates. The framework comprises three variants of increasing complexity, integrating theoretically grounded Langevin inference, adaptive noise schedule learning, parallel reconstruction sampling, and warm-start initialization from classical solvers. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple benchmarks, both in terms of fidelity and perceptual quality.",
      "authors": [
        "Mehmet Onurcan Kaya",
        "Figen S. Oktem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:25:06+00:00",
          "link": "https://arxiv.org/abs/2507.09608v1",
          "size": "4868kb",
          "version": "v1"
        }
      ],
      "title": "prNet: Data-Driven Phase Retrieval via Stochastic Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09608",
        "HTML": "https://arxiv.org/html/2507.09608v1",
        "PDF": "https://arxiv.org/pdf/2507.09608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses phase retrieval using stochastic refinement and Langevin dynamics, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2106.14490",
      "abstract": "As a common image editing operation, image composition (object insertion) aims to combine the foreground from one image and another background image, resulting in a composite image. However, there are many issues that could make the composite images unrealistic. These issues can be summarized as the inconsistency between foreground and background, which includes appearance inconsistency (e.g., incompatible illumination), geometry inconsistency (e.g., unreasonable size), and semantic inconsistency (e.g., mismatched semantic context). Image composition task could be decomposed into multiple sub-tasks, in which each sub-task targets at one or more issues. Specifically, object placement aims to find reasonable scale, location, and shape for the foreground. Image blending aims to address the unnatural boundary between foreground and background. Image harmonization aims to adjust the illumination statistics of foreground. Shadow (resp., reflection) generation aims to generate plausible shadow (resp., reflection) for the foreground. These sub-tasks can be executed sequentially or parallelly to acquire realistic composite images. To the best of our knowledge, there is no previous survey on image composition (object insertion). In this paper, we conduct comprehensive survey over the sub-tasks and combinatorial task of image composition (object insertion). For each one, we summarize the existing methods, available datasets, and common evaluation metrics. We have also contributed the first image composition toolbox libcom, which assembles 10+ image composition related functions (e.g., image blending, image harmonization, object placement, shadow generation, generative composition). The ultimate goal of this toolbox is solving all the problems related to image composition with simple `import libcom'.",
      "authors": [
        "Li Niu",
        "Wenyan Cong",
        "Liu Liu",
        "Yan Hong",
        "Bo Zhang",
        "Jing Liang",
        "Liqing Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2021-06-28T09:09:14+00:00",
          "link": "https://arxiv.org/abs/2106.14490v1",
          "size": "11678kb",
          "version": "v1"
        },
        {
          "date": "2022-07-11T01:24:38+00:00",
          "link": "https://arxiv.org/abs/2106.14490v2",
          "size": "15892kb",
          "version": "v2"
        },
        {
          "date": "2023-08-07T04:47:05+00:00",
          "link": "https://arxiv.org/abs/2106.14490v3",
          "size": "14579kb",
          "version": "v3"
        },
        {
          "date": "2024-03-02T08:17:24+00:00",
          "link": "https://arxiv.org/abs/2106.14490v4",
          "size": "14536kb",
          "version": "v4"
        },
        {
          "date": "2024-04-22T05:24:45+00:00",
          "link": "https://arxiv.org/abs/2106.14490v5",
          "size": "14603kb",
          "version": "v5"
        },
        {
          "date": "2025-01-20T04:45:01+00:00",
          "link": "https://arxiv.org/abs/2106.14490v6",
          "size": "14605kb",
          "version": "v6"
        },
        {
          "date": "2025-07-12T05:13:53+00:00",
          "link": "https://arxiv.org/abs/2106.14490v7",
          "size": "15350kb",
          "version": "v7"
        }
      ],
      "title": "Making Images Real Again: A Comprehensive Survey on Deep Image Composition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2106.14490",
        "HTML": "https://arxiv.org/html/2106.14490",
        "PDF": "https://arxiv.org/pdf/2106.14490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys deep image composition methods, which do not pertain to LLM training data processing or data engineering operations relevant to LLMs."
      },
      "tasks": [
        "Image Harmonization",
        "Object",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/bcmi/libcom",
        "https://github.com/bcmi/awesome-object-insertion",
        "https://github.com/bcmi/ObjectStitch-Image-Composition",
        "https://github.com/bcmi/controlcom-image-composition",
        "https://github.com/bcmi/mureobjectstitch-image-composition",
        "https://github.com/bcmi/Awesome-Image-Composition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.10472",
      "abstract": "Anderson Acceleration (AA) has been widely used to solve nonlinear fixed-point problems due to its rapid convergence. This work focuses on a variant of AA in which multiple Picard iterations are performed between each AA step, referred to as the Alternating Anderson-Picard (AAP) method. Despite introducing more ``slow'' Picard iterations, this method has been shown to be efficient and even more robust in both linear and nonlinear cases. However, there is a lack of theoretical analysis for AAP in the nonlinear case. In this paper, we address this gap by establishing the equivalence between AAP and a multisecant-GMRES method that uses GMRES to solve a multisecant linear system at each iteration. From this perspective, we show that AAP ``converges'' to the Newton-GMRES method. Specifically, as the residual approaches zero, the multisecant matrix, the approximate Jacobian inverse, the search direction, and the optimization gain of AAP converge to their counterparts in the Newton-GMRES method. These connections provide insights for analyzing the asymptotic convergence properties of AAP. Consequently, we show that AAP is locally $q$-linear convergent and provide an upper bound for the convergence factor of AAP. To validate the theoretical results, numerical examples are provided.",
      "authors": [
        "Xue Feng",
        "M. Paul Laiu",
        "and Thomas Strohmer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-15T06:57:46+00:00",
          "link": "https://arxiv.org/abs/2407.10472v1",
          "size": "1704kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T19:04:26+00:00",
          "link": "https://arxiv.org/abs/2407.10472v2",
          "size": "1018kb",
          "version": "v2"
        }
      ],
      "title": "Convergence Analysis of the Alternating Anderson-Picard Method for Nonlinear Fixed-point Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.10472",
        "HTML": "https://arxiv.org/html/2407.10472v2",
        "PDF": "https://arxiv.org/pdf/2407.10472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the convergence analysis of a mathematical method for solving nonlinear fixed-point problems and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.16367",
      "abstract": "Thermal runaway in lithium-ion batteries is a critical safety concern for the battery industry due to its potential to cause uncontrolled temperature rises and subsequent fires that can engulf the battery pack and its surroundings. Modeling and simulation offer cost-effective tools for designing strategies to mitigate thermal runaway. Accurately simulating the chemical kinetics of thermal runaway, commonly represented by systems of Arrhenius-based Ordinary Differential Equations (ODEs), requires fitting kinetic parameters to experimental calorimetry data, such as Accelerating Rate Calorimetry (ARC) measurements. However, existing fitting methods often rely on empirical assumptions and simplifications that compromise generality or require manual tuning during the fitting process. Particle Swarm Optimization (PSO) offers a promising approach for directly fitting kinetic parameters to experimental data. Yet, for systems created by multiple Arrhenius ODEs, the computational cost of fitting using a brute-force approach that searches the entire parameter space simultaneously can become prohibitive. This work introduces a divide-and-conquer approach based on PSO to fit N-equation Arrhenius ODE models to ARC data. The proposed method achieves more accurate parameter fitting compared to the brute-force method while maintaining low computational costs. The method is analyzed using two distinct ARC datasets, and the resulting models are further validated through simulations of 3D ARC and oven tests, showing excellent agreement with experimental data and alignment with expected trends.",
      "authors": [
        "Saakaar Bhatnagar",
        "Andrew Comerford",
        "Zelu Xu",
        "Simone Reitano",
        "Luigi Scrimieri",
        "Luca Giuliano",
        "Araz Banaeizadeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T21:57:48+00:00",
          "link": "https://arxiv.org/abs/2412.16367v1",
          "size": "723kb",
          "version": "v1"
        },
        {
          "date": "2024-12-24T08:47:57+00:00",
          "link": "https://arxiv.org/abs/2412.16367v2",
          "size": "724kb",
          "version": "v2"
        },
        {
          "date": "2025-02-06T20:58:54+00:00",
          "link": "https://arxiv.org/abs/2412.16367v3",
          "size": "725kb",
          "version": "v3"
        },
        {
          "date": "2025-04-01T14:53:13+00:00",
          "link": "https://arxiv.org/abs/2412.16367v4",
          "size": "896kb",
          "version": "v4"
        }
      ],
      "title": "A Layered Swarm Optimization Method for Fitting Battery Thermal Runaway Models to Accelerating Rate Calorimetry Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16367",
        "HTML": "https://arxiv.org/html/2412.16367",
        "PDF": "https://arxiv.org/pdf/2412.16367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around battery thermal runaway modeling and optimization methods. It does not touch on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.15266",
      "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction of open-ended real-world tasks. This allows us to cleanly and controllably quantify the creative limits of the present-day language model. Much like real-world tasks that require a creative, far-sighted leap of thought, our tasks require an implicit, open-ended stochastic planning step that either (a) discovers new connections in an abstract knowledge graph (like in wordplay, drawing analogies, or research) or (b) constructs new patterns (like in designing math problems or new proteins). In these tasks, we empirically and conceptually argue how next-token learning is myopic; multi-token approaches, namely teacherless training and diffusion models, comparatively excel in producing diverse and original output. Secondly, to elicit randomness without hurting coherence, we find that injecting noise at the input layer (dubbed seed-conditioning) works surprisingly as well as (and in some conditions, better than) temperature sampling from the output layer. Thus, our work offers a principled, minimal test-bed for analyzing open-ended creative skills, and offers new arguments for going beyond next-token learning and temperature sampling. We make part of the code available under https://github.com/chenwu98/algorithmic-creativity",
      "authors": [
        "Vaishnavh Nagarajan and Chen Henry Wu and Charles Ding and Aditi Raghunathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T17:47:46+00:00",
          "link": "https://arxiv.org/abs/2504.15266v1",
          "size": "1024kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T17:04:46+00:00",
          "link": "https://arxiv.org/abs/2504.15266v2",
          "size": "1025kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T16:34:31+00:00",
          "link": "https://arxiv.org/abs/2504.15266v3",
          "size": "1108kb",
          "version": "v3"
        }
      ],
      "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15266",
        "HTML": "https://arxiv.org/html/2504.15266v3",
        "PDF": "https://arxiv.org/pdf/2504.15266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the creative abilities of language models in task completion but does not discuss LLM training data processing, collection, or synthesis."
      },
      "datasets": [
        {
          "dataset_name": "ChenWu98/sibling.5.500.10.50000",
          "downloads": "24",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ChenWu98/sibling.5.500.10.50000"
        },
        {
          "dataset_name": "ChenWu98/triangle.10",
          "downloads": "14",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ChenWu98/triangle.10"
        },
        {
          "dataset_name": "ChenWu98/circle.10.9.10.10000",
          "downloads": "15",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ChenWu98/circle.10.9.10.10000"
        },
        {
          "dataset_name": "ChenWu98/line.10.9.10.10000",
          "downloads": "20",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ChenWu98/line.10.9.10.10000"
        }
      ],
      "tasks": [
        "Math"
      ],
      "repo_urls": [
        "https://github.com/chenwu98/algorithmic-creativity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09665",
      "abstract": "The growing scale of large language models (LLMs) not only demands extensive computational resources but also raises environmental concerns due to their increasing carbon footprint. Model quantization emerges as an effective approach that can reduce the resource demands of LLMs by decreasing parameter precision without substantially affecting performance (e.g., 16 bit to 4 bit). While recent studies have established quantization as a promising approach for optimizing large code models (LCMs), a specialized subset of LLMs tailored for automated software engineering, their findings offer only limited insights into its practical implications. Specifically, current investigations focus only on the functional correctness of the code generated by quantized models, neglecting how quantization impacts critical aspects of code quality such as reliability, maintainability, and security. To bridge this gap, our study investigates the effects of quantization on the qualitative aspects of automatically generated code. We apply Activation-aware Weight Quantization (AWQ) to two widely used code models, CodeLlama and DeepSeekCoder, to generate Java and Python code. Using state-of-the-art static analysis tools, we evaluate software quality metrics and static features including cyclomatic complexity, cognitive complexity, and lines of code. Our findings reveal that quantization is a robust technique that not only preserves functional correctness, but also retains key qualitative code attributes sought after by developers, such as maintainability and structural simplicity.",
      "authors": [
        "Saima Afrin",
        "Bowen Xu",
        "and Antonio Mastropaolo"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:58:19+00:00",
          "link": "https://arxiv.org/abs/2507.09665v1",
          "size": "326kb",
          "version": "v1"
        }
      ],
      "title": "Is Quantization a Deal-breaker? Empirical Insights from Large Code Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09665",
        "HTML": "https://arxiv.org/html/2507.09665v1",
        "PDF": "https://arxiv.org/pdf/2507.09665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses model quantization as it applies to large code models but does not address any aspect of LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10241",
      "abstract": "This paper introduces the Kernel Adaptive Physics-Informed Extreme Learning Machine (KAPI-ELM), an adaptive Radial Basis Function (RBF)-based extension of PI-ELM designed to solve both forward and inverse Partial Differential Equation (PDE) problems involving localized sharp gradients. While PI-ELMs outperform the traditional Physics-Informed Neural Networks (PINNs) in speed due to their single-shot, least square optimization, this advantage comes at a cost: their fixed, randomly initialized input layer limits their ability to capture sharp gradients. To overcome this limitation, we introduce a lightweight Bayesian Optimization (BO) framework that, instead of adjusting each input layer parameter individually as in traditional backpropagation, learns a small set of hyperparameters defining the statistical distribution from which the input weights are drawn. This novel distributional optimization strategy -- combining BO for input layer distributional parameters with least-squares optimization for output layer network parameters -- enables KAPI-ELM to preserve PI-ELM's speed while matching or exceeding the expressiveness of PINNs. We validate the proposed methodology on several challenging forward and inverse PDE benchmarks, including a 1D singularly perturbed convection-diffusion equation, a 2D Poisson equation with sharp localized sources, and a time-dependent advection equation. Notably, KAPI-ELM achieves state-of-the-art accuracy in both forward and inverse settings. In stiff PDE regimes, it matches or even outperforms advanced methods such as the Extended Theory of Functional Connections (XTFC), while requiring nearly an order of magnitude fewer tunable parameters. These results establish the potential of KAPI-ELM as a scalable, interpretable, and generalizable physics-informed learning framework, especially in stiff PDE regimes.",
      "authors": [
        "Vikas Dwivedi",
        "Balaji Srinivasan",
        "Monica Sigovan",
        "Bruno Sixou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:03:53+00:00",
          "link": "https://arxiv.org/abs/2507.10241v1",
          "size": "5075kb",
          "version": "v1"
        }
      ],
      "title": "Kernel-Adaptive PI-ELMs for Forward and Inverse Problems in PDEs with Sharp Gradients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10241",
        "HTML": "https://arxiv.org/html/2507.10241v1",
        "PDF": "https://arxiv.org/pdf/2507.10241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on solving PDE problems using the KAPI-ELM framework, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.17286",
      "abstract": "Optimizing risk-averse objectives in discounted MDPs is challenging because most models do not admit direct dynamic programming equations and require complex history-dependent policies. In this paper, we show that the risk-averse {\\em total reward criterion}, under the Entropic Risk Measure (ERM) and Entropic Value at Risk (EVaR) risk measures, can be optimized by a stationary policy, making it simple to analyze, interpret, and deploy. We propose exponential value iteration, policy iteration, and linear programming to compute optimal policies. Compared with prior work, our results only require the relatively mild condition of transient MDPs and allow for {\\em both} positive and negative rewards. Our results indicate that the total reward criterion may be preferable to the discounted criterion in a broad range of risk-averse reinforcement learning domains.",
      "authors": [
        "Xihong Su",
        "Julien Grand-Cl\\'ement",
        "Marek Petrik"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-30T13:33:18+00:00",
          "link": "https://arxiv.org/abs/2408.17286v1",
          "size": "232kb",
          "version": "v1"
        },
        {
          "date": "2024-12-18T16:10:18+00:00",
          "link": "https://arxiv.org/abs/2408.17286v2",
          "size": "223kb",
          "version": "v2"
        }
      ],
      "title": "Risk-averse Total-reward MDPs with ERM and EVaR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.17286",
        "HTML": "https://arxiv.org/html/2408.17286",
        "PDF": "https://arxiv.org/pdf/2408.17286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on risk-averse objectives in MDPs with entropic risk measures and does not discuss LLM training data processing or dataset creation."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/suxh2019/ermlp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14171",
      "abstract": "Multi-modal brain MRI provides essential complementary information for clinical diagnosis. However, acquiring all modalities in practice is often constrained by time and cost. To address this, various methods have been proposed to generate missing modalities from available ones. Traditional approaches can be broadly categorized into two main types: paired and unpaired methods. While paired methods for synthesizing missing modalities achieve high accuracy, obtaining large-scale paired datasets is typically impractical. In contrast, unpaired methods, though scalable, often fail to preserve critical anatomical features, such as lesions. In this paper, we propose Fully Guided Schr\\\"odinger Bridge (FGSB), a novel framework designed to overcome these limitations by enabling high-fidelity generation with extremely limited paired data. Furthermore, when provided with lesion-specific information such as expert annotations, segmentation tools, or simple intensity thresholds for critical regions, FGSB can generate missing modalities while preserving these significant lesion with reduced data requirements. Our model comprises two stages: 1) Generation Phase: Iteratively refines synthetic images using paired target image and Gaussian noise. Training Phase: Learns optimal transformation pathways from source to target modality by mapping all intermediate states, ensuring consistent and high-fidelity synthesis. Experimental results across multiple datasets demonstrate that FGSB achieved performance comparable to large-data-trained models, while using only two subjects. Incorporating lesion-specific priors further improves the preservation of clinical features.",
      "authors": [
        "Hanyeol Yang",
        "Sunggyu Kim",
        "Mi Kyung Kim",
        "Yongseon Yoo",
        "Yu-Mi Kim",
        "Min-Ho Shin",
        "Insung Chung",
        "Sang Baek Koh",
        "Hyeon Chang Kim and Jong-Min Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T01:40:16+00:00",
          "link": "https://arxiv.org/abs/2501.14171v1",
          "size": "2470kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:56:22+00:00",
          "link": "https://arxiv.org/abs/2501.14171v2",
          "size": "11689kb",
          "version": "v2"
        }
      ],
      "title": "Guided Neural Schr\\\"odinger bridge for Brain MR image synthesis with Limited Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14171",
        "HTML": "https://arxiv.org/html/2501.14171v2",
        "PDF": "https://arxiv.org/pdf/2501.14171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on brain MR image synthesis using limited data, not on LLM training data processing or creation."
      },
      "tasks": [
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12377",
      "abstract": "A small but growing body of work has shown that machine learning models which better align with human vision have also exhibited higher robustness to adversarial examples, raising the question: can human-like perception make models more secure? If true generally, such mechanisms would offer new avenues toward robustness. In this work, we conduct a large-scale empirical analysis to systematically investigate the relationship between representational alignment and adversarial robustness. We evaluate 114 models spanning diverse architectures and training paradigms, measuring their neural and behavioral alignment and engineering task performance across 105 benchmarks as well as their adversarial robustness via AutoAttack. Our findings reveal that while average alignment and robustness exhibit a weak overall correlation, specific alignment benchmarks serve as strong predictors of adversarial robustness, particularly those that measure selectivity toward texture or shape. These results suggest that different forms of alignment play distinct roles in model robustness, motivating further investigation into how alignment-driven approaches can be leveraged to build more secure and perceptually-grounded vision models.",
      "authors": [
        "Blaine Hoak",
        "Kunyang Li",
        "Patrick McDaniel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T23:30:50+00:00",
          "link": "https://arxiv.org/abs/2502.12377v1",
          "size": "136kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:15:27+00:00",
          "link": "https://arxiv.org/abs/2502.12377v2",
          "size": "178kb",
          "version": "v2"
        }
      ],
      "title": "Alignment and Adversarial Robustness: Are More Human-Like Models More Secure?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12377",
        "HTML": "https://arxiv.org/html/2502.12377v2",
        "PDF": "https://arxiv.org/pdf/2502.12377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on model robustness and alignment with human-like perception, without discussing any specific LLM training data processing or engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.15137",
      "abstract": "Multispectral object detection aims to leverage complementary information from visible (RGB) and infrared (IR) modalities to enable robust performance under diverse environmental conditions. Our key insight, derived from wavelet analysis and empirical observations, is that IR images contain structurally rich high-frequency information critical for object detection, making an infrared-centric approach highly effective. To capitalize on this finding, we propose Infrared-Centric Fusion (IC-Fusion), a lightweight and modality-aware sensor fusion method that prioritizes infrared features while effectively integrating complementary RGB semantic context. IC-Fusion adopts a compact RGB backbone and designs a novel fusion module comprising a Multi-Scale Feature Distillation (MSFD) block to enhance RGB features and a three-stage fusion block with a Cross-Modal Channel Shuffle Gate (CCSG), a Cross-Modal Large Kernel Gate (CLKG), and a Channel Shuffle Projection (CSP) to facilitate effective cross-modal interaction. Experiments on the FLIR and LLVIP benchmarks demonstrate the superior effectiveness and efficiency of our IR-centric fusion strategy, further validating its benefits. Our code is available at https://github.com/smin-hwang/IC-Fusion.",
      "authors": [
        "Seongmin Hwang",
        "Daeyoung Han",
        "Moongu Jeon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T05:44:14+00:00",
          "link": "https://arxiv.org/abs/2505.15137v1",
          "size": "1166kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:40:47+00:00",
          "link": "https://arxiv.org/abs/2505.15137v2",
          "size": "1281kb",
          "version": "v2"
        }
      ],
      "title": "Multispectral Detection Transformer with Infrared-Centric Feature Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15137",
        "HTML": "https://arxiv.org/html/2505.15137v2",
        "PDF": "https://arxiv.org/pdf/2505.15137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses multispectral object detection and sensor fusion techniques, with no mention of LLM training data processing or creation."
      },
      "tasks": [
        "Multispectral Object Detection",
        "Object",
        "object-detection",
        "Object Detection",
        "Object Localization",
        "Sensor Fusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08776",
      "abstract": "This paper proposes a neural rendering approach that represents a scene as \"compressed light-field tokens (CLiFTs)\", retaining rich appearance and geometric information of a scene. CLiFT enables compute-efficient rendering by compressed tokens, while being capable of changing the number of tokens to represent a scene or render a novel view with one trained network. Concretely, given a set of images, multi-view encoder tokenizes the images with the camera poses. Latent-space K-means selects a reduced set of rays as cluster centroids using the tokens. The multi-view ``condenser'' compresses the information of all the tokens into the centroid tokens to construct CLiFTs. At test time, given a target view and a compute budget (i.e., the number of CLiFTs), the system collects the specified number of nearby tokens and synthesizes a novel view using a compute-adaptive renderer. Extensive experiments on RealEstate10K and DL3DV datasets quantitatively and qualitatively validate our approach, achieving significant data reduction with comparable rendering quality and the highest overall rendering score, while providing trade-offs of data size, rendering quality, and rendering speed.",
      "authors": [
        "Zhengqing Wang",
        "Yuefan Wu",
        "Jiacheng Chen",
        "Fuyang Zhang",
        "Yasutaka Furukawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:38:52+00:00",
          "link": "https://arxiv.org/abs/2507.08776v1",
          "size": "10091kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T01:25:49+00:00",
          "link": "https://arxiv.org/abs/2507.08776v2",
          "size": "10091kb",
          "version": "v2"
        }
      ],
      "title": "CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08776",
        "HTML": "https://arxiv.org/html/2507.08776v2",
        "PDF": "https://arxiv.org/pdf/2507.08776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It proposes a neural rendering approach (CLiFT) for efficient scene representation and rendering, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08913",
      "abstract": "Shuffling-type gradient methods are favored in practice for their simplicity and rapid empirical performance. Despite extensive development of convergence guarantees under various assumptions in recent years, most require the Lipschitz smoothness condition, which is often not met in common machine learning models. We highlight this issue with specific counterexamples. To address this gap, we revisit the convergence rates of shuffling-type gradient methods without assuming Lipschitz smoothness. Using our stepsize strategy, the shuffling-type gradient algorithm not only converges under weaker assumptions but also match the current best-known convergence rates, thereby broadening its applicability. We prove the convergence rates for nonconvex, strongly convex, and non-strongly convex cases, each under both random reshuffling and arbitrary shuffling schemes, under a general bounded variance condition. Numerical experiments further validate the performance of our shuffling-type gradient algorithm, underscoring its practical efficacy.",
      "authors": [
        "Qi He",
        "Peiran Yu",
        "Ziyi Chen",
        "Heng Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:36:48+00:00",
          "link": "https://arxiv.org/abs/2507.08913v1",
          "size": "657kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Convergence: Shuffling Complexity Beyond Lipschitz Smoothness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08913",
        "HTML": "https://arxiv.org/html/2507.08913v1",
        "PDF": "https://arxiv.org/pdf/2507.08913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines convergence of shuffling-type gradient methods without Lipschitz smoothness but does not discuss LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08980",
      "abstract": "Diffusion models can be improved with additional guidance towards more effective representations of input. Indeed, prior empirical work has already shown that aligning internal representations of the diffusion model with those of pre-trained models improves generation quality. In this paper, we present a systematic framework for incorporating representation guidance into diffusion models. We provide alternative decompositions of denoising models along with their associated training criteria, where the decompositions determine when and how the auxiliary representations are incorporated. Guided by our theoretical insights, we introduce two new strategies for enhancing representation alignment in diffusion models. First, we pair examples with target representations either derived from themselves or arisen from different synthetic modalities, and subsequently learn a joint model over the multimodal pairs. Second, we design an optimal training curriculum that balances representation learning and data generation. Our experiments across image, protein sequence, and molecule generation tasks demonstrate superior performance as well as accelerated training. In particular, on the class-conditional ImageNet $256\\times 256$ benchmark, our guidance results in $23.3$ times faster training than the original SiT-XL as well as four times speedup over the state-of-the-art method REPA. The code is available at https://github.com/ChenyuWang-Monica/REED.",
      "authors": [
        "Chenyu Wang",
        "Cai Zhou",
        "Sharut Gupta",
        "Zongyu Lin",
        "Stefanie Jegelka",
        "Stephen Bates",
        "Tommi Jaakkola"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:29:02+00:00",
          "link": "https://arxiv.org/abs/2507.08980v1",
          "size": "15813kb",
          "version": "v1"
        }
      ],
      "title": "Learning Diffusion Models with Flexible Representation Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08980",
        "PDF": "https://arxiv.org/pdf/2507.08980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving diffusion models through representation guidance and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09220",
      "abstract": "Artificial Intelligence (AI) tools for automating design artifact generation are increasingly used in Requirements Engineering (RE) to transform textual requirements into structured diagrams and models. While these AI tools, particularly those based on Natural Language Processing (NLP), promise to improve efficiency, their adoption remains limited in regulated industries where transparency and traceability are essential. In this paper, we investigate the explainability gap in AI-driven design artifact generation through semi-structured interviews with ten practitioners from safety-critical industries. We examine how current AI-based tools are integrated into workflows and the challenges arising from their lack of explainability. We also explore mitigation strategies, their impact on project outcomes, and features needed to improve usability. Our findings reveal that non-explainable AI outputs necessitate extensive manual validation, reduce stakeholder trust, struggle to handle domain-specific terminology, disrupt team collaboration, and introduce regulatory compliance risks, often negating the anticipated efficiency benefits. To address these issues, we identify key improvements, including source tracing, providing clear justifications for tool-generated decisions, supporting domain-specific adaptation, and enabling compliance validation. This study outlines a practical roadmap for improving the transparency, reliability, and applicability of AI tools in requirements engineering workflows, particularly in regulated and safety-critical environments where explainability is crucial for adoption and certification.",
      "authors": [
        "Syed Tauhid Ullah Shah",
        "Mohammad Hussein",
        "Ann Barcomb",
        "Mohammad Moshirpour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:34:39+00:00",
          "link": "https://arxiv.org/abs/2507.09220v1",
          "size": "188kb",
          "version": "v1"
        }
      ],
      "title": "Explainability as a Compliance Requirement: What Regulated Industries Need from AI Tools for Design Artifact Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09220",
        "HTML": "https://arxiv.org/html/2507.09220v1",
        "PDF": "https://arxiv.org/pdf/2507.09220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with explainability in AI tools for design artifact generation in regulated industries, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09362",
      "abstract": "An autoencoder (AE) is a neural network that, using self-supervised training, learns a succinct parameterized representation, and a corresponding encoding and decoding process, for all instances in a given class. Here, we introduce the concept of a meta-autoencoder (MAE): an AE for a collection of autoencoders. Given a family of classes that differ from each other by the values of some parameters, and a trained AE for each class, an MAE for the family is a neural net that has learned a compact representation and associated encoder and decoder for the class-specific AEs. One application of this general concept is in research and modeling of natural evolution -- capturing the defining and the distinguishing properties across multiple species that are dynamically evolving from each other and from common ancestors. In this interim report we provide a constructive definition of MAEs, initial examples, and the motivating research directions in machine learning and biology.",
      "authors": [
        "Assaf Marron",
        "Smadar Szekely",
        "Irun Cohen and David Harel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T17:50:35+00:00",
          "link": "https://arxiv.org/abs/2507.09362v1",
          "size": "966kb",
          "version": "v1"
        }
      ],
      "title": "Meta-autoencoders: An approach to discovery and representation of relationships between dynamically evolving classes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09362",
        "HTML": "https://arxiv.org/html/2507.09362v1",
        "PDF": "https://arxiv.org/pdf/2507.09362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces meta-autoencoders for learning representations of dynamically evolving classes, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09494",
      "abstract": "We introduce an algorithm for identifying interpretable subgroups with elevated treatment effects, given an estimate of individual or conditional average treatment effects (CATE). Subgroups are characterized by ``rule sets'' -- easy-to-understand statements of the form (Condition A AND Condition B) OR (Condition C) -- which can capture high-order interactions while retaining interpretability. Our method complements existing approaches for estimating the CATE, which often produce high dimensional and uninterpretable results, by summarizing and extracting critical information from fitted models to aid decision making, policy implementation, and scientific understanding. We propose an objective function that trades-off subgroup size and effect size, and varying the hyperparameter that controls this trade-off results in a ``frontier'' of Pareto optimal rule sets, none of which dominates the others across all criteria. Valid inference is achievable through sample splitting. We demonstrate the utility and limitations of our method using simulated and empirical examples.",
      "authors": [
        "Albert Chiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:01:48+00:00",
          "link": "https://arxiv.org/abs/2507.09494v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "An Algorithm for Identifying Interpretable Subgroups With Elevated Treatment Effects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09494",
        "HTML": "https://arxiv.org/html/2507.09494v1",
        "PDF": "https://arxiv.org/pdf/2507.09494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an algorithm for subgroup identification with elevated treatment effects, focusing on treatment effect estimation, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10417",
      "abstract": "Maximum Distance Profile (MDP) convolutional codes are an important class of channel codes due to their maximal delay-constrained error correction capabilities. The design of MDP codes has attracted significant attention from the research community. However, only limited attention was given to addressing the complexity of encoding and decoding operations. This paper aims to reduce encoding complexity by constructing partial unit-memory MDP codes with structured and sparse generator matrices. In particular, we present a matrix completion framework that extends a structured superregular matrix (e.g., Cauchy) over a small field to a sparse sliding generator matrix of an MDP code. We show that the proposed construction can reduce the encoding complexity compared to the current state-of-the-art MDP code designs.",
      "authors": [
        "Sakshi Dang",
        "Julia Lieb",
        "Okko Makkonen",
        "Pedro Soto",
        "Alex Sprintson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:59:43+00:00",
          "link": "https://arxiv.org/abs/2507.10417v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "A Matrix Completion Approach for the Construction of MDP Convolutional Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10417",
        "PDF": "https://arxiv.org/pdf/2507.10417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research discusses encoding complexity in the construction of MDP convolutional codes and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10430",
      "abstract": "Federated Learning (FL) is a promising distributed machine learning approach that enables collaborative training of a global model using multiple edge devices. The data distributed among the edge devices is highly heterogeneous. Thus, FL faces the challenge of data distribution and heterogeneity, where non-Independent and Identically Distributed (non-IID) data across edge devices may yield in significant accuracy drop. Furthermore, the limited computation and communication capabilities of edge devices increase the likelihood of stragglers, thus leading to slow model convergence. In this paper, we propose the FedDHAD FL framework, which comes with two novel methods: Dynamic Heterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH dynamically adjusts the weights of each local model within the model aggregation process based on the non-IID degree of heterogeneous data to deal with the statistical data heterogeneity. FedAD performs neuron-adaptive operations in response to heterogeneous devices to improve accuracy while achieving superb efficiency. The combination of these two methods makes FedDHAD significantly outperform state-of-the-art solutions in terms of accuracy (up to 6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to 15.0% smaller).",
      "authors": [
        "Ji Liu",
        "Beichen Ma",
        "Yang Zhou",
        "Jingbo Zhou",
        "Ruoming Jin",
        "Dejing Dou",
        "Huaiyu Dai",
        "Haixun Wang",
        "Patrick Valduriez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:19:00+00:00",
          "link": "https://arxiv.org/abs/2507.10430v1",
          "size": "2983kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10430",
        "HTML": "https://arxiv.org/html/2507.10430v1",
        "PDF": "https://arxiv.org/pdf/2507.10430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents techniques for improving federated learning with heterogeneous data, focusing on model aggregation and dropout strategies. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.14183",
      "abstract": "Neural models learn data representations that lie on low-dimensional manifolds, yet modeling the relation between these representational spaces is an ongoing challenge. By integrating spectral geometry principles into neural modeling, we show that this problem can be better addressed in the functional domain, mitigating complexity, while enhancing interpretability and performances on downstream tasks. To this end, we introduce a multi-purpose framework to the representation learning community, which allows to: (i) compare different spaces in an interpretable way and measure their intrinsic similarity; (ii) find correspondences between them, both in unsupervised and weakly supervised settings, and (iii) to effectively transfer representations between distinct spaces. We validate our framework on various applications, ranging from stitching to retrieval tasks, and on multiple modalities, demonstrating that Latent Functional Maps can serve as a swiss-army knife for representation alignment.",
      "authors": [
        "Marco Fumero",
        "Marco Pegoraro",
        "Valentino Maiorca",
        "Francesco Locatello",
        "Emanuele Rodol\\`a"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-20T10:43:28+00:00",
          "link": "https://arxiv.org/abs/2406.14183v1",
          "size": "786kb",
          "version": "v1"
        },
        {
          "date": "2024-06-21T09:57:50+00:00",
          "link": "https://arxiv.org/abs/2406.14183v2",
          "size": "786kb",
          "version": "v2"
        },
        {
          "date": "2024-10-30T22:47:47+00:00",
          "link": "https://arxiv.org/abs/2406.14183v3",
          "size": "2068kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T16:24:02+00:00",
          "link": "https://arxiv.org/abs/2406.14183v4",
          "size": "1831kb",
          "version": "v4"
        }
      ],
      "title": "Latent Functional Maps: a spectral framework for representation alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14183",
        "HTML": "https://arxiv.org/html/2406.14183v4",
        "PDF": "https://arxiv.org/pdf/2406.14183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for representation learning involving spectral geometry but does not address LLM training data processing."
      },
      "tasks": [
        "Representation Learning",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01635",
      "abstract": "Temporal alignment of multiple signals through time warping is crucial in many fields, such as classification within speech recognition or robot motion learning. Almost all related works are limited to data in Euclidean space. Although an attempt was made in 2011 to adapt this concept to unit quaternions, a general extension to Riemannian manifolds remains absent. Given its importance for numerous applications in robotics and beyond, we introduce Riemannian Time Warping (RTW). This novel approach efficiently aligns multiple signals by considering the geometric structure of the Riemannian manifold in which the data is embedded. Extensive experiments on synthetic and real-world data, including tests with an LBR iiwa robot, demonstrate that RTW consistently outperforms state-of-the-art baselines in both averaging and classification tasks.",
      "authors": [
        "Julian Richter",
        "Christopher A. Erd\\\"os",
        "Christian Scheurer",
        "Jochen J. Steil",
        "Niels Dehio"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T13:12:02+00:00",
          "link": "https://arxiv.org/abs/2506.01635v1",
          "size": "1408kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:00:27+00:00",
          "link": "https://arxiv.org/abs/2506.01635v2",
          "size": "1407kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T09:32:28+00:00",
          "link": "https://arxiv.org/abs/2506.01635v3",
          "size": "1407kb",
          "version": "v3"
        }
      ],
      "title": "Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01635",
        "HTML": "https://arxiv.org/html/2506.01635v3",
        "PDF": "https://arxiv.org/pdf/2506.01635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for temporal alignment of signals on Riemannian manifolds, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Multiple Sequence Alignment",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09657",
      "abstract": "We use generative agents powered by large language models (LLMs) to simulate a social network in a shared residential building, driving the temperature decisions for a central heating system. Agents, divided into Family Members and Representatives, consider personal preferences, personal traits, connections, and weather conditions. Daily simulations involve family-level consensus followed by building-wide decisions among representatives. We tested three personality traits distributions (positive, mixed, and negative) and found that positive traits correlate with higher happiness and stronger friendships. Temperature preferences, assertiveness, and selflessness have a significant impact on happiness and decisions. This work demonstrates how LLM-driven agents can help simulate nuanced human behavior where complex real-life human simulations are difficult to set.",
      "authors": [
        "Ann Nedime Nese Rende",
        "Tolga Yilmaz and \\\"Ozg\\\"ur Ulusoy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:43:45+00:00",
          "link": "https://arxiv.org/abs/2507.09657v1",
          "size": "2223kb",
          "version": "v1"
        }
      ],
      "title": "Negotiating Comfort: Simulating Personality-Driven LLM Agents in Shared Residential Social Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09657",
        "HTML": "https://arxiv.org/html/2507.09657v1",
        "PDF": "https://arxiv.org/pdf/2507.09657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses simulating personality-driven agents for social networks using LLMs, but does not address training data processing or data engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09915",
      "abstract": "The scarcity of data in various scenarios, such as medical, industry and autonomous driving, leads to model overfitting and dataset imbalance, thus hindering effective detection and segmentation performance. Existing studies employ the generative models to synthesize more training samples to mitigate data scarcity. However, these synthetic samples are repetitive or simplistic and fail to provide \"crucial information\" that targets the downstream model's weaknesses. Additionally, these methods typically require separate training for different objects, leading to computational inefficiencies. To address these issues, we propose Crucial-Diff, a domain-agnostic framework designed to synthesize crucial samples. Our method integrates two key modules. The Scene Agnostic Feature Extractor (SAFE) utilizes a unified feature extractor to capture target information. The Weakness Aware Sample Miner (WASM) generates hard-to-detect samples using feedback from the detection results of downstream model, which is then fused with the output of SAFE module. Together, our Crucial-Diff framework generates diverse, high-quality training data, achieving a pixel-level AP of 83.63% and an F1-MAX of 78.12% on MVTec. On polyp dataset, Crucial-Diff reaches an mIoU of 81.64% and an mDice of 87.69%. Code will be released after acceptance.",
      "authors": [
        "Siyue Yao",
        "Mingjie Sun",
        "Eng Gee Lim",
        "Ran Yi",
        "Baojiang Zhong",
        "Moncef Gabbouj"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:41:38+00:00",
          "link": "https://arxiv.org/abs/2507.09915v1",
          "size": "3609kb",
          "version": "v1"
        }
      ],
      "title": "Crucial-Diff: A Unified Diffusion Model for Crucial Image and Annotation Synthesis in Data-scarce Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09915",
        "HTML": "https://arxiv.org/html/2507.09915v1",
        "PDF": "https://arxiv.org/pdf/2507.09915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces Crucial-Diff, a framework aimed at synthesizing high-quality training samples to address data scarcity, which signifies a substantive contribution to training data processing by creating high-quality data with new methodology."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10391",
      "abstract": "Recent research found that cloud data warehouses are text-heavy. However, their capabilities for efficiently processing string columns remain limited, relying primarily on techniques like dictionary encoding and prefix-based partition pruning. In recent work, we introduced string fingerprints - a lightweight secondary index structure designed to approximate LIKE predicates, albeit with false positives. This approach is particularly compelling for columnar query engines, where fingerprints can help reduce both compute and I/O overhead. We show that string fingerprints can be optimized for specific workloads using mixed-integer optimization, and that they can generalize to unseen table predicates. On an IMDb column evaluated in DuckDB v1.3, this yields table-scan speedups of up to 1.36$\\times$.",
      "authors": [
        "Mihail Stoian",
        "Johannes Th\\\"urauf",
        "Andreas Zimmerer",
        "Alexander van Renen",
        "Andreas Kipf"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:30:36+00:00",
          "link": "https://arxiv.org/abs/2507.10391v1",
          "size": "302kb",
          "version": "v1"
        }
      ],
      "title": "Instance-Optimized String Fingerprints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10391",
        "HTML": "https://arxiv.org/html/2507.10391v1",
        "PDF": "https://arxiv.org/pdf/2507.10391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing string processing techniques in cloud data warehouses but does not address LLM training data processing or data engineering specifically for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10484",
      "abstract": "This paper introduces the \"Target Polish,\" a robust and computationally efficient framework for nonnegative matrix and tensor factorization. Although conventional weighted NMF approaches are resistant to outliers, they converge slowly due to the use of multiplicative updates to minimize the objective criterion. In contrast, the Target Polish approach remains compatible with the Fast-HALS algorithm, which is renowned for its speed, by adaptively smoothing the data with a weighted median-based transformation. This innovation provides outlier resistance while maintaining the highly efficient additive update structure of Fast-HALS. Empirical evaluations using image datasets corrupted with structured (block) and unstructured (salt) noise demonstrate that the Target Polish approach matches or exceeds the accuracy of state-of-the-art robust NMF methods and reduces computational time by an order of magnitude in the studied scenarios.",
      "authors": [
        "Paul Fogel (1)",
        "Christophe Geissler (1)",
        "George Luta (2) ((1) Data Services",
        "ForvisMazars",
        "Courbevoie",
        "France",
        "(2) Department of Biostatistics",
        "Bioinformatics and Biomathematics",
        "Georgetown University Medical Center",
        "Washington",
        "DC",
        "USA)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:04:03+00:00",
          "link": "https://arxiv.org/abs/2507.10484v1",
          "size": "2486kb",
          "version": "v1"
        }
      ],
      "title": "The Target Polish: A New Approach to Outlier-Resistant Non-Negative Matrix and Tensor Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10484",
        "HTML": "https://arxiv.org/html/2507.10484v1",
        "PDF": "https://arxiv.org/pdf/2507.10484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for outlier-resistant matrix factorization and does not address LLM training data processing or relevant data-related engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03088",
      "abstract": "The Segment Anything Model (SAM) has demonstrated strong versatility across various visual tasks. However, its large storage requirements and high computational cost pose challenges for practical deployment. Post-training quantization (PTQ) has emerged as an effective strategy for efficient deployment, but we identify two key challenges in SAM that hinder the effectiveness of existing PTQ methods: the heavy-tailed and skewed distribution of post-GELU activations, and significant inter-channel variation in linear projection activations. To address these challenges, we propose AHCPTQ, an accurate and hardware-efficient PTQ method for SAM. AHCPTQ introduces hardware-compatible Hybrid Log-Uniform Quantization (HLUQ) to manage post-GELU activations, employing log2 quantization for dense small values and uniform quantization for sparse large values to enhance quantization resolution. Additionally, AHCPTQ incorporates Channel-Aware Grouping (CAG) to mitigate inter-channel variation by progressively clustering activation channels with similar distributions, enabling them to share quantization parameters and improving hardware efficiency. The combination of HLUQ and CAG not only enhances quantization effectiveness but also ensures compatibility with efficient hardware execution. For instance, under the W4A4 configuration on the SAM-L model, AHCPTQ achieves 36.6% mAP on instance segmentation with the DINO detector, while achieving a 7.89x speedup and 8.64x energy efficiency over its floating-point counterpart in FPGA implementation.",
      "authors": [
        "Wenlun Zhang and Yunshan Zhong and Shimpei Ando and Kentaro Yoshioka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T01:04:45+00:00",
          "link": "https://arxiv.org/abs/2503.03088v1",
          "size": "2968kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:26:21+00:00",
          "link": "https://arxiv.org/abs/2503.03088v2",
          "size": "4034kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T01:30:20+00:00",
          "link": "https://arxiv.org/abs/2503.03088v3",
          "size": "4033kb",
          "version": "v3"
        }
      ],
      "title": "AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03088",
        "HTML": "https://arxiv.org/html/2503.03088v3",
        "PDF": "https://arxiv.org/pdf/2503.03088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on post-training quantization techniques for efficient model deployment on hardware, rather than any aspect of LLM training data processing."
      },
      "tasks": [
        "Instance Segmentation",
        "Quantization",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09513",
      "abstract": "The brain can only be fully understood through the lens of the behavior it generates -- a guiding principle in modern neuroscience research that nevertheless presents significant technical challenges. Many studies capture behavior with cameras, but video analysis approaches typically rely on specialized models requiring extensive labeled data. We address this limitation with BEAST (BEhavioral Analysis via Self-supervised pretraining of Transformers), a novel and scalable framework that pretrains experiment-specific vision transformers for diverse neuro-behavior analyses. BEAST combines masked autoencoding with temporal contrastive learning to effectively leverage unlabeled video data. Through comprehensive evaluation across multiple species, we demonstrate improved performance in three critical neuro-behavioral tasks: extracting behavioral features that correlate with neural activity, and pose estimation and action segmentation in both the single- and multi-animal settings. Our method establishes a powerful and versatile backbone model that accelerates behavioral analysis in scenarios where labeled data remains scarce.",
      "authors": [
        "Yanchen Wang",
        "Han Yu",
        "Ari Blau",
        "Yizi Zhang",
        "The International Brain Laboratory",
        "Liam Paninski",
        "Cole Hurwitz",
        "Matt Whiteway"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:43:05+00:00",
          "link": "https://arxiv.org/abs/2507.09513v1",
          "size": "6354kb",
          "version": "v1"
        }
      ],
      "title": "Self-supervised pretraining of vision transformers for animal behavioral analysis and neural encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09513",
        "HTML": "https://arxiv.org/html/2507.09513v1",
        "PDF": "https://arxiv.org/pdf/2507.09513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using self-supervised pretraining for vision transformers within the context of animal behavior analysis and neural encoding, without discussing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09823",
      "abstract": "In this paper, we focus on the problem of minimizing a continuously differentiable convex objective function $\\min_x f(x)$. Recently, several adaptive gradient methods, including GRAAL (Malitsky, 2020), have been developed. These methods estimate the local curvature of the objective function to compute stepsizes, attain the standard convergence rate $\\mathcal{O}(1/k)$ of fixed-stepsize gradient descent for Lipschitz-smooth functions, and do not require any line search procedures or hyperparameter tuning. However, a natural question arises: is it possible to accelerate the convergence of these algorithms to match the optimal rate $\\mathcal{O}(1/k^2)$ of the accelerated gradient descent of Nesterov (1983)? Although some attempts have been made (Li and Lan, 2023), the capabilities of the existing accelerated algorithms to adapt to the curvature of the objective function are highly limited. Consequently, we provide a positive answer to this question and develop GRAAL with Nesterov acceleration. We prove that our algorithm achieves the desired optimal convergence rate for Lipschitz smooth functions. Moreover, in contrast to existing methods, it does so with an arbitrary, even excessively small, initial stepsize at the cost of a logarithmic additive term in the iteration complexity.",
      "authors": [
        "Ekaterina Borodich",
        "Dmitry Kovalev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:07:45+00:00",
          "link": "https://arxiv.org/abs/2507.09823v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09823",
        "HTML": "https://arxiv.org/html/2507.09823v1",
        "PDF": "https://arxiv.org/pdf/2507.09823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper pertains to optimization algorithms in convex optimization, particularly adaptive gradient methods, without involving any LLM training data processing or creation activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10473",
      "abstract": "Timestamp prediction aims to determine when an image was captured using only visual information, supporting applications such as metadata correction, retrieval, and digital forensics. In outdoor scenarios, hourly estimates rely on cues like brightness, hue, and shadow positioning, while seasonal changes and weather inform date estimation. However, these visual cues significantly depend on geographic context, closely linking timestamp prediction to geo-localization. To address this interdependence, we introduce GT-Loc, a novel retrieval-based method that jointly predicts the capture time (hour and month) and geo-location (GPS coordinates) of an image. Our approach employs separate encoders for images, time, and location, aligning their embeddings within a shared high-dimensional feature space. Recognizing the cyclical nature of time, instead of conventional contrastive learning with hard positives and negatives, we propose a temporal metric-learning objective providing soft targets by modeling pairwise time differences over a cyclical toroidal surface. We present new benchmarks demonstrating that our joint optimization surpasses previous time prediction methods, even those using the ground-truth geo-location as an input during inference. Additionally, our approach achieves competitive results on standard geo-localization tasks, and the unified embedding space facilitates compositional and text-based image retrieval.",
      "authors": [
        "David G. Shatwell",
        "Ishan Rajendrakumar Dave",
        "Sirnam Swetha",
        "Mubarak Shah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.10473v1",
          "size": "11650kb",
          "version": "v1"
        }
      ],
      "title": "GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10473",
        "HTML": "https://arxiv.org/html/2507.10473v1",
        "PDF": "https://arxiv.org/pdf/2507.10473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on timestamp prediction and geo-localization in images using a joint embedding space, without mentioning any processing of LLM training data or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.11341",
      "abstract": "Multimodal learning on video and text has seen significant progress, particularly in tasks like text-to-video retrieval, video-to-text retrieval, and video captioning. However, most existing methods and datasets focus exclusively on English. Despite Indonesian being one of the most widely spoken languages, multimodal research in Indonesian remains under-explored, largely due to the lack of benchmark datasets. To address this gap, we introduce the first public Indonesian video-text dataset by translating the English captions in the MSVD dataset into Indonesian. Using this dataset, we evaluate neural network models which were developed for the English video-text dataset on three tasks, i.e., text-to-video retrieval, video-to-text retrieval, and video captioning. Most existing models rely on feature extractors pretrained on English vision-language datasets, raising concerns about their applicability to Indonesian, given the scarcity of large-scale pretraining resources in the language. We apply a cross-lingual transfer learning approach by leveraging English-pretrained extractors and fine-tuning models on our Indonesian dataset. Experimental results demonstrate that this strategy improves performance across all tasks and metrics. We release our dataset publicly to support future research and hope it will inspire further progress in Indonesian multimodal learning.",
      "authors": [
        "Willy Fitra Hendria"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-20T07:19:36+00:00",
          "link": "https://arxiv.org/abs/2306.11341v1",
          "size": "5467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T04:28:35+00:00",
          "link": "https://arxiv.org/abs/2306.11341v2",
          "size": "5105kb",
          "version": "v2"
        }
      ],
      "title": "MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in Indonesian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.11341",
        "HTML": "https://arxiv.org/html/2306.11341v2",
        "PDF": "https://arxiv.org/pdf/2306.11341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset by translating captions into Indonesian, but the primary contribution appears to be in the evaluation of models rather than detailed data processing steps for LLM training."
      },
      "datasets": [
        {
          "dataset_name": "SEACrowd/id_msvd",
          "downloads": "39",
          "likes": "0",
          "link": "https://huggingface.co/datasets/SEACrowd/id_msvd"
        }
      ],
      "tasks": [
        "Cross-Lingual Transfer",
        "Retrieval",
        "Text Retrieval",
        "Text to Video Retrieval",
        "Transfer Learning",
        "Video Captioning",
        "Video Description",
        "Video Retrieval",
        "Video to Text Retrieval"
      ],
      "repo_urls": [
        "https://github.com/willyfh/msvd-indonesian"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.06241",
      "abstract": "Existing work on improving language model reasoning typically explores a single solution path, which can be prone to errors. Inspired by perspective-taking in social studies, this paper introduces DiPT, a novel approach that complements current reasoning methods by explicitly incorporating diversified viewpoints. This approach allows the model to gain a deeper understanding of the problem's context and identify the most effective solution path during the inference stage. Additionally, it provides a general data-centric AI recipe for augmenting existing data to improve their quality for fine-tuning.\n  Our empirical results demonstrate that DiPT can be flexibly integrated into existing methods that focus on a single reasoning approach, enhancing their reasoning performance and stability when presented with paraphrased problems. Furthermore, we illustrate improved context understanding by maintaining the model's safe outputs against \"jailbreaking\" prompts intentionally designed to bypass safeguards built into deployed models. Lastly, we show that fine-tuning with data enriched with diverse perspectives can boost the reasoning capabilities of the model compared to fine-tuning with raw data alone.",
      "authors": [
        "Hoang Anh Just",
        "Mahavir Dabas",
        "Lifu Huang",
        "Ming Jin",
        "Ruoxi Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T06:17:27+00:00",
          "link": "https://arxiv.org/abs/2409.06241v1",
          "size": "1164kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T19:25:09+00:00",
          "link": "https://arxiv.org/abs/2409.06241v2",
          "size": "8508kb",
          "version": "v2"
        }
      ],
      "title": "DiPT: Enhancing LLM reasoning through diversified perspective-taking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06241",
        "HTML": "https://arxiv.org/html/2409.06241v2",
        "PDF": "https://arxiv.org/pdf/2409.06241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses DiPT's method of augmenting existing data with diverse perspectives for improving fine-tuning data quality, which directly pertains to LLM training data processing through enhancing data quality."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06174",
      "abstract": "In recent years, the advancement of imitation learning has led to increased interest in teleoperating low-cost manipulators to collect demonstration data. However, most existing systems rely on unilateral control, which only transmits target position values. While this approach is easy to implement and suitable for slow, non-contact tasks, it struggles with fast or contact-rich operations due to the absence of force feedback. This work demonstrates that fast teleoperation with force feedback is feasible even with force-sensorless, low-cost manipulators by leveraging 4-channel bilateral control. Based on accurately identified manipulator dynamics, our method integrates nonlinear terms compensation, velocity and external force estimation, and variable gain corresponding to inertial variation. Furthermore, using data collected by 4-channel bilateral control, we show that incorporating force information into both the input and output of learned policies improves performance in imitation learning. These results highlight the practical effectiveness of our system for high-fidelity teleoperation and data collection on affordable hardware.",
      "authors": [
        "Koki Yamane",
        "Yunhan Li",
        "Masashi Konosu",
        "Koki Inami",
        "Junji Oaki",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:54:34+00:00",
          "link": "https://arxiv.org/abs/2507.06174v1",
          "size": "16600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:53:31+00:00",
          "link": "https://arxiv.org/abs/2507.06174v2",
          "size": "16657kb",
          "version": "v2"
        }
      ],
      "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06174",
        "HTML": "https://arxiv.org/html/2507.06174v2",
        "PDF": "https://arxiv.org/pdf/2507.06174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a teleoperation and imitation learning system using force control for data collection, but does not involve LLM training data processing or any related data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08017",
      "abstract": "Recent findings in mechanistic interpretability (MI), the field probing the inner workings of Large Language Models (LLMs), challenge the view that these models rely solely on superficial statistics. We offer an accessible synthesis of these findings that doubles as an introduction to MI while integrating these findings within a novel theoretical framework for thinking about machine understanding. We argue that LLMs develop internal structures that are functionally analogous to the kind of understanding that consists in seeing connections. To sharpen this idea, we propose a three-tiered conception of understanding. First, conceptual understanding emerges when a model forms \"features\" as directions in latent space, learning the connections between diverse manifestations of something. Second, state-of-the-world understanding emerges when a model learns contingent factual connections between features and dynamically tracks changes in the world. Third, principled understanding emerges when a model ceases to rely on a collection of memorized facts and discovers a \"circuit\" connecting these facts. However, these forms of understanding remain radically different from human understanding, as the phenomenon of \"parallel mechanisms\" shows. We conclude that the debate should move beyond the yes-or-no question of whether LLMs understand to investigate how their strange minds work and forge conceptions that fit them.",
      "authors": [
        "Pierre Beckmann and Matthieu Queloz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.08017v1",
          "size": "427kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T11:46:41+00:00",
          "link": "https://arxiv.org/abs/2507.08017v2",
          "size": "417kb",
          "version": "v2"
        }
      ],
      "title": "Mechanistic Indicators of Understanding in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08017",
        "PDF": "https://arxiv.org/pdf/2507.08017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper offers insights into mechanistic interpretability of LLMs and their understanding, without focusing on training data processing or modification."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08877",
      "abstract": "Function Calling is a crucial technique that enables Large Language Models (LLMs) to interact with external systems through APIs. However, the high latency associated with LLM-based Function Calling significantly impacts user experience. This paper presents a novel approach called Oriented Distillation for Inline Acceleration (ODIA) that leverages online user interaction data to accelerate Function Calling. By automatically identifying \"simple queries\" from production traffic and distilling knowledge from larger models to smaller ones, our method reduces response latency by 45% (expected) and 78% (median) while maintaining accuracy. We demonstrate the effectiveness of our approach through real-world deployment in a music application, where the smaller model successfully handles 60% of traffic with negligible accuracy loss. Our method requires minimal human intervention and continuously improves through automated data collection and model updating, making it a practical solution for production environments.",
      "authors": [
        "Hanlong Zhang",
        "Jingsheng Yang",
        "Hao Li",
        "Yuhao He",
        "Franck Gong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:44:47+00:00",
          "link": "https://arxiv.org/abs/2507.08877v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "ODIA: Oriented Distillation for Inline Acceleration of LLM-based Function Calling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08877",
        "HTML": "https://arxiv.org/html/2507.08877v1",
        "PDF": "https://arxiv.org/pdf/2507.08877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using online user interaction data to accelerate LLM-based Function Calling, but it primarily focuses on improving response latency rather than substantive data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09652",
      "abstract": "Low-dimensional chaotic systems such as the Lorenz-63 model are commonly used to benchmark system-agnostic methods for learning dynamics from data. Here we show that learning from noise-free observations in such systems can be achieved up to machine precision: using ordinary least squares regression on high-degree polynomial features with 512-bit arithmetic, our method exceeds the accuracy of standard 64-bit numerical ODE solvers of the true underlying dynamical systems. Depending on the configuration, we obtain valid prediction times of 32 to 105 Lyapunov times for the Lorenz-63 system, dramatically outperforming prior work that reaches 13 Lyapunov times at most. We further validate our results on Thomas' Cyclically Symmetric Attractor, a non-polynomial chaotic system that is considerably more complex than the Lorenz-63 model, and show that similar results extend also to higher dimensions using the spatiotemporally chaotic Lorenz-96 model. Our findings suggest that learning low-dimensional chaotic systems from noise-free data is a solved problem.",
      "authors": [
        "Christof Sch\\\"otz and Niklas Boers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chaotic Dynamics (nlin.CD)",
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:36:47+00:00",
          "link": "https://arxiv.org/abs/2507.09652v1",
          "size": "6330kb",
          "version": "v1"
        }
      ],
      "title": "Machine-Precision Prediction of Low-Dimensional Chaotic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09652",
        "HTML": "https://arxiv.org/html/2507.09652v1",
        "PDF": "https://arxiv.org/pdf/2507.09652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on learning dynamics from low-dimensional chaotic systems and does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09820",
      "abstract": "Most safety testing efforts for large language models (LLMs) today focus on evaluating foundation models. However, there is a growing need to evaluate safety at the application level, as components such as system prompts, retrieval pipelines, and guardrails introduce additional factors that significantly influence the overall safety of LLM applications. In this paper, we introduce a practical framework for evaluating application-level safety in LLM systems, validated through real-world deployment across multiple use cases within our organization. The framework consists of two parts: (1) principles for developing customized safety risk taxonomies, and (2) practices for evaluating safety risks in LLM applications. We illustrate how the proposed framework was applied in our internal pilot, providing a reference point for organizations seeking to scale their safety testing efforts. This work aims to bridge the gap between theoretical concepts in AI safety and the operational realities of safeguarding LLM applications in practice, offering actionable guidance for safe and scalable deployment.",
      "authors": [
        "Jia Yi Goh",
        "Shaun Khoo",
        "Nyx Iskandar",
        "Gabriel Chua",
        "Leanne Tan",
        "Jessica Foo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T22:34:20+00:00",
          "link": "https://arxiv.org/abs/2507.09820v1",
          "size": "277kb",
          "version": "v1"
        }
      ],
      "title": "Measuring What Matters: A Framework for Evaluating Safety Risks in Real-World LLM Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09820",
        "HTML": "https://arxiv.org/html/2507.09820v1",
        "PDF": "https://arxiv.org/pdf/2507.09820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses safety evaluations of LLM applications and does not discuss LLM training data processing, data engineering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09996",
      "abstract": "Objective: This study aims to support early diagnosis of Alzheimer's disease and detection of amyloid accumulation by leveraging the microstructural information available in multi-shell diffusion MRI (dMRI) data, using a vision transformer-based deep learning framework.\n  Methods: We present a classification pipeline that employs the Swin Transformer, a hierarchical vision transformer model, on multi-shell dMRI data for the classification of Alzheimer's disease and amyloid presence. Key metrics from DTI and NODDI were extracted and projected onto 2D planes to enable transfer learning with ImageNet-pretrained models. To efficiently adapt the transformer to limited labeled neuroimaging data, we integrated Low-Rank Adaptation. We assessed the framework on diagnostic group prediction (cognitively normal, mild cognitive impairment, Alzheimer's disease dementia) and amyloid status classification.\n  Results: The framework achieved competitive classification results within the scope of multi-shell dMRI-based features, with the best balanced accuracy of 95.2% for distinguishing cognitively normal individuals from those with Alzheimer's disease dementia using NODDI metrics. For amyloid detection, it reached 77.2% balanced accuracy in distinguishing amyloid-positive mild cognitive impairment/Alzheimer's disease dementia subjects from amyloid-negative cognitively normal subjects, and 67.9% for identifying amyloid-positive individuals among cognitively normal subjects. Grad-CAM-based explainability analysis identified clinically relevant brain regions, including the parahippocampal gyrus and hippocampus, as key contributors to model predictions.\n  Conclusion: This study demonstrates the promise of diffusion MRI and transformer-based architectures for early detection of Alzheimer's disease and amyloid pathology, supporting biomarker-driven diagnostics in data-limited biomedical settings.",
      "authors": [
        "Quentin Dessain",
        "Nicolas Delinte",
        "Bernard Hanseeuw",
        "Laurence Dricot",
        "Beno\\^it Macq"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neurons and Cognition (q-bio.NC)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:31:40+00:00",
          "link": "https://arxiv.org/abs/2507.09996v1",
          "size": "738kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09996",
        "HTML": "https://arxiv.org/html/2507.09996v1",
        "PDF": "https://arxiv.org/pdf/2507.09996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study centers around leveraging diffusion MRI for Alzheimer's disease diagnosis using Swin Transformer, and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.15675",
      "abstract": "We determine the complexity of second-order HyperLTL satisfiability, finite-state satisfiability, and model-checking: All three are equivalent to truth in third-order arithmetic. We also consider two fragments of second-order HyperLTL that have been introduced with the aim to facilitate effective model-checking by restricting the sets one can quantify over. The first one restricts second-order quantification to smallest/largest sets that satisfy a guard while the second one restricts second-order quantification further to least fixed points of (first-order) HyperLTL definable functions. All three problems for the first fragment are still equivalent to truth in third-order arithmetic while satisfiability for the second fragment is $\\Sigma_1^2$-complete, and finite-state satisfiability and model-checking are equivalent to truth in second-order arithmetic. Finally, we also introduce closed-world semantics for second-order HyperLTL, where set quantification ranges only over subsets of the model, while set quantification in standard semantics ranges over arbitrary sets of traces. Here, satisfiability for the least fixed point fragment becomes $\\Sigma_1^1$-complete, but all other results are unaffected.",
      "authors": [
        "Hadar Frenkel and Ga\\\"etan Regaud and Martin Zimmermann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-27T10:03:40+00:00",
          "link": "https://arxiv.org/abs/2311.15675v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2024-04-28T18:47:49+00:00",
          "link": "https://arxiv.org/abs/2311.15675v2",
          "size": "34kb",
          "version": "v2"
        },
        {
          "date": "2024-09-03T12:12:21+00:00",
          "link": "https://arxiv.org/abs/2311.15675v3",
          "size": "41kb",
          "version": "v3"
        },
        {
          "date": "2025-01-06T14:35:56+00:00",
          "link": "https://arxiv.org/abs/2311.15675v4",
          "size": "45kb",
          "version": "v4"
        },
        {
          "date": "2025-07-14T10:18:18+00:00",
          "link": "https://arxiv.org/abs/2311.15675v5",
          "size": "375kb",
          "version": "v5"
        }
      ],
      "title": "The Complexity of Second-order HyperLTL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.15675",
        "HTML": "https://arxiv.org/html/2311.15675v5",
        "PDF": "https://arxiv.org/pdf/2311.15675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes complexity in logical formulas and model-checking but does not involve any LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.01519",
      "abstract": "This paper explores the frontiers of large language models (LLMs) in psychology applications. Psychology has undergone several theoretical changes, and the current use of Artificial Intelligence (AI) and Machine Learning, particularly LLMs, promises to open up new research directions. We provide a detailed exploration of how LLMs like ChatGPT are transforming psychological research. It discusses the impact of LLMs across various branches of psychology, including cognitive and behavioral, clinical and counseling, educational and developmental, and social and cultural psychology, highlighting their potential to simulate aspects of human cognition and behavior. The paper delves into the capabilities of these models to emulate human-like text generation, offering innovative tools for literature review, hypothesis generation, experimental design, experimental subjects, data analysis, academic writing, and peer review in psychology. While LLMs are essential in advancing research methodologies in psychology, the paper also cautions about their technical and ethical challenges. There are issues like data privacy, the ethical implications of using LLMs in psychological research, and the need for a deeper understanding of these models' limitations. Researchers should responsibly use LLMs in psychological studies, adhering to ethical standards and considering the potential consequences of deploying these technologies in sensitive areas. Overall, the article provides a comprehensive overview of the current state of LLMs in psychology, exploring potential benefits and challenges. It serves as a call to action for researchers to leverage LLMs' advantages responsibly while addressing associated risks.",
      "authors": [
        "Luoma Ke (1)",
        "Song Tong (1)",
        "Peng Cheng (2)",
        "Kaiping Peng (1) ((1) Department of Psychological and Cognitive Sciences",
        "Tsinghua University",
        "(2) School of Social Science",
        "Tsinghua University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-03T03:01:29+00:00",
          "link": "https://arxiv.org/abs/2401.01519v1",
          "size": "569kb",
          "version": "v1"
        },
        {
          "date": "2024-01-06T10:22:47+00:00",
          "link": "https://arxiv.org/abs/2401.01519v2",
          "size": "569kb",
          "version": "v2"
        },
        {
          "date": "2024-03-16T13:37:48+00:00",
          "link": "https://arxiv.org/abs/2401.01519v3",
          "size": "570kb",
          "version": "v3"
        },
        {
          "date": "2025-04-20T08:45:26+00:00",
          "link": "https://arxiv.org/abs/2401.01519v4",
          "size": "706kb",
          "version": "v4"
        }
      ],
      "title": "Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01519",
        "PDF": "https://arxiv.org/pdf/2401.01519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the application of LLMs in psychology, highlighting their potential and ethical challenges, without detailing any processing or creation of training data for LLMs."
      },
      "tasks": [
        "Experimental Design",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09294",
      "abstract": "Decision trees and forests have achieved successes in various real applications, most working with all testing classes known in training data. In this work, we focus on learning with augmented class via forests, where an augmented class may appear in testing data yet not in training data. We incorporate information of augmented class into trees' splitting, that is, augmented Gini impurity, a new splitting criterion is introduced to exploit some unlabeled data from testing distribution. We then develop the Learning with Augmented Class via Forests (short for LACForest) approach, which constructs shallow forests according to the augmented Gini impurity and then splits forests with pseudo-labeled augmented instances for better performance. We also develop deep neural forests via an optimization objective based on our augmented Gini impurity, which essentially utilizes the representation power of neural networks for forests. Theoretically, we present the convergence analysis for our augmented Gini impurity, and we finally conduct experiments to evaluate our approaches. The code is available at https://github.com/nju-xuf/LACForest.",
      "authors": [
        "Fan Xu and Wuyang Chen and Wei Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T11:22:22+00:00",
          "link": "https://arxiv.org/abs/2505.09294v1",
          "size": "265kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:29:44+00:00",
          "link": "https://arxiv.org/abs/2505.09294v2",
          "size": "326kb",
          "version": "v2"
        }
      ],
      "title": "On the Learning with Augmented Class via Forests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09294",
        "HTML": "https://arxiv.org/html/2505.09294v2",
        "PDF": "https://arxiv.org/pdf/2505.09294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses learning models with augmented classes using decision trees and forests but does not focus on LLM training data processing, collection, or engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/nju-xuf/lacforest"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09104",
      "abstract": "Recently, the role of LLM-as-judge in evaluating large language models has gained prominence. However, current judge models suffer from narrow specialization and limited robustness, undermining their capacity for comprehensive evaluations. In this work, we present CompassJudger-2, a novel generalist judge model that overcomes these limitations via a task-driven, multi-domain data curation strategy. Central to our approach is supervising judgment tasks with verifiable rewards, guiding intrinsic critical reasoning through rejection sampling to foster robust, generalizable judgment capabilities. We introduce a refined learning objective with margin policy gradient loss to enhance performance. Empirically, CompassJudger-2 achieves superior results across multiple judge and reward benchmarks, and our 7B model demonstrates competitive judgment accuracy with significantly larger models like DeepSeek-V3 and Qwen3-235B-A22B. Additionally, we propose JudgerBenchV2, a comprehensive benchmark evaluating cross-domain judgment accuracy and rank consistency to standardize judge model evaluation. These contributions advance robust, scalable LLM judgment and establish new performance and evaluation standards.",
      "authors": [
        "Taolin Zhang and Maosong Cao and Alexander Lam and Songyang Zhang and Kai Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:34:24+00:00",
          "link": "https://arxiv.org/abs/2507.09104v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09104",
        "HTML": "https://arxiv.org/html/2507.09104v1",
        "PDF": "https://arxiv.org/pdf/2507.09104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a 'multi-domain data curation strategy' for improving judge model evaluation, but this appears to be a secondary aspect related to task evaluation rather than substantive LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10267",
      "abstract": "Detecting Domain Name System (DNS) tunneling is a significant challenge in security due to its capacity to hide harmful actions within DNS traffic that appears to be normal and legitimate. Traditional detection methods are based on rule-based approaches or signature matching methods that are often insufficient to accurately identify such covert communication channels. This research is about effectively detecting DNS tunneling. We propose a novel approach to detect DNS tunneling with machine learning algorithms. We combine machine learning algorithms to analyze the traffic by using features extracted from DNS traffic. Analyses results show that the proposed approach is a good candidate to detect DNS tunneling accurately.",
      "authors": [
        "Novruz Amirov",
        "Baran Isik",
        "Bilal Ihsan Tuncer",
        "Serif Bahtiyar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:37:48+00:00",
          "link": "https://arxiv.org/abs/2507.10267v1",
          "size": "2774kb",
          "version": "v1"
        }
      ],
      "title": "DNS Tunneling: Threat Landscape and Improved Detection Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10267",
        "HTML": "https://arxiv.org/html/2507.10267v1",
        "PDF": "https://arxiv.org/pdf/2507.10267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about DNS tunneling detection using machine learning, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10522",
      "abstract": "We introduce DeepResearch$^{\\text{Eco}}$, a novel agentic LLM-based system for automated scientific synthesis that supports recursive, depth- and breadth-controlled exploration of original research questions -- enhancing search diversity and nuance in the retrieval of relevant scientific literature. Unlike conventional retrieval-augmented generation pipelines, DeepResearch enables user-controllable synthesis with transparent reasoning and parameter-driven configurability, facilitating high-throughput integration of domain-specific evidence while maintaining analytical rigor. Applied to 49 ecological research questions, DeepResearch achieves up to a 21-fold increase in source integration and a 14.9-fold rise in sources integrated per 1,000 words. High-parameter settings yield expert-level analytical depth and contextual diversity.\n  Source code available at: https://github.com/sciknoworg/deep-research.",
      "authors": [
        "Jennifer D'Souza",
        "Endres Keno Sander",
        "and Andrei Aioanei"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:47:28+00:00",
          "link": "https://arxiv.org/abs/2507.10522v1",
          "size": "1532kb",
          "version": "v1"
        }
      ],
      "title": "DeepResearch$^{\\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10522",
        "HTML": "https://arxiv.org/html/2507.10522v1",
        "PDF": "https://arxiv.org/pdf/2507.10522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an LLM-based system for scientific literature synthesis with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21364",
      "abstract": "This article is devoted to long-time weak approximations of stochastic partial differential equations (SPDEs) evolving in a bounded domain $\\mathcal{D} \\subset \\mathbb{R}^d$, $d \\leq 3$, with non-globally Lipschitz and possibly non-contractive coefficients. Both the space-time white noise ($d=1$) and the trace-class noise in multiple dimensions $d=2,3$ are examined for the considered SPDEs. Based on a spectral Galerkin spatial semi-discretization, we propose a class of novel full-discretization schemes of exponential type, which are explicit, easily implementable and preserve the ergodicity of the original dissipative SPDEs with possibly non-contractive coefficients. The uniform-in-time weak approximation errors are carefully analyzed in a low regularity and non-contractive setting, with uniform-in-time weak convergence rates obtained. A key ingredient is to establish the uniform-in-time moment bounds (in $L^{4q-2}$-norm, $q \\geq 1$) for the proposed fully discrete schemes in a super-linear setting. This is highly non-trivial for the explicit full-discretization schemes and new arguments are elaborated by fully exploiting a contractive property of the semi-group in $L^{4q-2}$, the dissipativity of the nonlinearity and the particular benefit of the taming strategy. Numerical experiments are finally reported to verify the theoretical findings.",
      "authors": [
        "Yingsong Jiang and Xiaojie Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T06:52:23+00:00",
          "link": "https://arxiv.org/abs/2504.21364v1",
          "size": "257kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:04:42+00:00",
          "link": "https://arxiv.org/abs/2504.21364v2",
          "size": "259kb",
          "version": "v2"
        }
      ],
      "title": "Uniform-in-time weak error estimates of explicit full-discretization schemes for SPDEs with non-globally Lipschitz coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21364",
        "HTML": "https://arxiv.org/html/2504.21364v2",
        "PDF": "https://arxiv.org/pdf/2504.21364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses approximation schemes for stochastic partial differential equations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08836",
      "abstract": "This study evaluates the performance of a compression method, called CompactifAI, developed by Multiverse Computing, applied to the large language model Llama 3.1 8B\\cite{llama}. The evaluation focused on model efficiency (in terms of energy consumption) and accuracy using respectively the frameworks Codecarbon\\cite{codecarbon} and Ragas\\cite{ragas}. A comparison was performed between the model compressed with CompactifAI\\cite{compactifai}\\cite{compactifai2} and its full-size version. Our findings reveal that the compressed model using CompactifAI not only significantly reduced the computational resources but also maintained the model accuracy, making the model more efficient, scalable and cost-effective.",
      "authors": [
        "Damien Fovet",
        "Shashank Chamoli",
        "Sarah Oury",
        "Srishti Singhal"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:01:39+00:00",
          "link": "https://arxiv.org/abs/2507.08836v1",
          "size": "411kb",
          "version": "v1"
        }
      ],
      "title": "Accuracy and Consumption analysis from a compressed model by CompactifAI from Multiverse Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08836",
        "HTML": "https://arxiv.org/html/2507.08836v1",
        "PDF": "https://arxiv.org/pdf/2507.08836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates a model compression method for LLMs, focusing on energy efficiency and accuracy, without addressing the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08873",
      "abstract": "In this paper, a novel contrastive language-image pre-training (CLIP) model based semantic communication framework is designed. Compared to standard neural network (e.g.,convolutional neural network) based semantic encoders and decoders that require joint training over a common dataset, our CLIP model based method does not require any training procedures thus enabling a transmitter to extract data meanings of the original data without neural network model training, and the receiver to train a neural network for follow-up task implementation without the communications with the transmitter. Next, we investigate the deployment of the CLIP model based semantic framework over a noisy wireless network. Since the semantic information generated by the CLIP model is susceptible to wireless noise and the spectrum used for semantic information transmission is limited, it is necessary to jointly optimize CLIP model architecture and spectrum resource block (RB) allocation to maximize semantic communication performance while considering wireless noise, the delay and energy used for semantic communication. To achieve this goal, we use a proximal policy optimization (PPO) based reinforcement learning (RL) algorithm to learn how wireless noise affect the semantic communication performance thus finding optimal CLIP model and RB for each user. Simulation results show that our proposed method improves the convergence rate by up to 40%, and the accumulated reward by 4x compared to soft actor-critic.",
      "authors": [
        "Shaoran Yang",
        "Dongyu Wei",
        "Hanzhi Yu",
        "Zhaohui Yang",
        "Yuchen Liu",
        "Mingzhe Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:48:56+00:00",
          "link": "https://arxiv.org/abs/2507.08873v1",
          "size": "243kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive Language-Image Pre-Training Model based Semantic Communication Performance Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08873",
        "HTML": "https://arxiv.org/html/2507.08873v1",
        "PDF": "https://arxiv.org/pdf/2507.08873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimizing semantic communication performance using a CLIP model in wireless networks but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08912",
      "abstract": "Artificial Intelligence-generated content has become increasingly popular, yet its malicious use, particularly the deepfakes, poses a serious threat to public trust and discourse. While deepfake detection methods achieve high predictive performance, they often exhibit biases across demographic attributes such as ethnicity and gender. In this work, we tackle the challenge of fair deepfake detection, aiming to mitigate these biases while maintaining robust detection capabilities. To this end, we propose a novel post-processing approach, referred to as Fairness-Oriented Final Layer Input Prioritising (Fair-FLIP), that reweights a trained model's final-layer inputs to reduce subgroup disparities, prioritising those with low variability while demoting highly variable ones. Experimental results comparing Fair-FLIP to both the baseline (without fairness-oriented de-biasing) and state-of-the-art approaches show that Fair-FLIP can enhance fairness metrics by up to 30% while maintaining baseline accuracy, with only a negligible reduction of 0.25%.\n  Code is available on Github: https://github.com/szandala/fair-deepfake-detection-toolbox",
      "authors": [
        "Tomasz Szandala",
        "Fatima Ezzeddine",
        "Natalia Rusin",
        "Silvia Giordano and Omran Ayoub"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:17:02+00:00",
          "link": "https://arxiv.org/abs/2507.08912v1",
          "size": "1770kb",
          "version": "v1"
        }
      ],
      "title": "Fair-FLIP: Fair Deepfake Detection with Fairness-Oriented Final Layer Input Prioritising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08912",
        "HTML": "https://arxiv.org/html/2507.08912v1",
        "PDF": "https://arxiv.org/pdf/2507.08912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a post-processing approach to enhance fairness in deepfake detection models. It deals with biases and fairness issues but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09031",
      "abstract": "Confounders are extraneous variables that affect both the input and the target, resulting in spurious correlations and biased predictions. There are recent advances in dealing with or removing confounders in traditional models, such as metadata normalization (MDN), where the distribution of the learned features is adjusted based on the study confounders. However, in the context of continual learning, where a model learns continuously from new data over time without forgetting, learning feature representations that are invariant to confounders remains a significant challenge. To remove their influence from intermediate feature representations, we introduce the Recursive MDN (R-MDN) layer, which can be integrated into any deep learning architecture, including vision transformers, and at any model stage. R-MDN performs statistical regression via the recursive least squares algorithm to maintain and continually update an internal model state with respect to changing distributions of data and confounding variables. Our experiments demonstrate that R-MDN promotes equitable predictions across population groups, both within static learning and across different stages of continual learning, by reducing catastrophic forgetting caused by confounder effects changing over time.",
      "authors": [
        "Yash Shah",
        "Camila Gonzalez",
        "Mohammad H. Abbasi",
        "Qingyu Zhao",
        "Kilian M. Pohl",
        "Ehsan Adeli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:25:31+00:00",
          "link": "https://arxiv.org/abs/2507.09031v1",
          "size": "9100kb",
          "version": "v1"
        }
      ],
      "title": "Confounder-Free Continual Learning via Recursive Feature Normalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09031",
        "HTML": "https://arxiv.org/html/2507.09031v1",
        "PDF": "https://arxiv.org/pdf/2507.09031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a method to handle confounding variables in continual learning through feature normalization. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10448",
      "abstract": "Financial report generation tasks range from macro- to micro-economics analysis, also requiring extensive data analysis. Existing LLM models are usually fine-tuned on simple QA tasks and cannot comprehensively analyze real financial scenarios. Given the complexity, financial companies often distribute tasks among departments. Inspired by this, we propose FinTeam, a financial multi-agent collaborative system, with a workflow with four LLM agents: document analyzer, analyst, accountant, and consultant. We train these agents with specific financial expertise using constructed datasets. We evaluate FinTeam on comprehensive financial tasks constructed from real online investment forums, including macroeconomic, industry, and company analysis. The human evaluation shows that by combining agents, the financial reports generate from FinTeam achieved a 62.00% acceptance rate, outperforming baseline models like GPT-4o and Xuanyuan. Additionally, FinTeam's agents demonstrate a 7.43% average improvement on FinCUGE and a 2.06% accuracy boost on FinEval. Project is available at https://github.com/FudanDISC/DISC-FinLLM/.",
      "authors": [
        "Yingqian Wu",
        "Qiushi Wang",
        "Zefei Long",
        "Rong Ye",
        "Zhongtian Lu",
        "Xianyin Zhang",
        "Bingxuan Li",
        "Wei Chen",
        "Liwen Zhang",
        "Zhongyu Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T10:12:25+00:00",
          "link": "https://arxiv.org/abs/2507.10448v1",
          "size": "1095kb",
          "version": "v1"
        }
      ],
      "title": "FinTeam: A Multi-Agent Collaborative Intelligence System for Comprehensive Financial Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10448",
        "HTML": "https://arxiv.org/html/2507.10448v1",
        "PDF": "https://arxiv.org/pdf/2507.10448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions training agents within a multi-agent system with specific constructed datasets but focuses on fine-tuning models for financial tasks rather than detailed LLM training data processing methods or dataset creation processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10482",
      "abstract": "We propose to use orthologic as the basis for designing type systems supporting intersection, union, and negation types in the presence of subtyping assumptions. We show how to extend orthologic to support monotonic and antimonotonic functions, supporting the use of type constructors in such type systems. We present a proof system for orthologic with function symbols, showing that it admits partial cut elimination. Using these insights, we present an $\\mathcal O(n^2(1+m))$ algorithm for deciding the subtyping relation under $m$ assumptions. We also show $O(n^2)$ polynomial-time normalization algorithm, allowing simplification of types to their minimal canonical form.",
      "authors": [
        "Simon Guilloud and Viktor Kun\\v{c}ak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:01:18+00:00",
          "link": "https://arxiv.org/abs/2507.10482v1",
          "size": "250kb",
          "version": "v1"
        }
      ],
      "title": "Orthologic Type Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10482",
        "HTML": "https://arxiv.org/html/2507.10482v1",
        "PDF": "https://arxiv.org/pdf/2507.10482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on type systems and provides algorithms for deciding subtyping relations and type normalization, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.11462",
      "abstract": "Introduced to enhance the efficiency of large language model (LLM) inference, speculative decoding operates by having a smaller model generate a draft. A larger target model then reviews this draft to align with its output, and any acceptance by the target model results in a reduction of the number of the target model runs, ultimately improving efficiency. However, the drafting process in speculative decoding includes slow autoregressive generation and allocates equal time to generating tokens, irrespective of their importance. These inefficiencies collectively contribute to the suboptimal performance of speculative decoding. To further improve LLM inference, we introduce Cascade Speculative Drafting (CS Drafting), a speculative execution algorithm that incorporates two types of cascades. The Vertical Cascade eliminates autoregressive generation from neural models, while the Horizontal Cascade optimizes time allocation in drafting for improved efficiency. Combining both cascades, CS Drafting achieves greater speedup compared to the baselines in our experiments, while preserving the same output distribution as the target model.",
      "authors": [
        "Ziyi Chen",
        "Xiaocong Yang",
        "Jiacheng Lin",
        "Chenkai Sun",
        "Kevin Chen-Chuan Chang",
        "Jie Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-18T18:59:46+00:00",
          "link": "https://arxiv.org/abs/2312.11462v1",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "2023-12-21T18:46:59+00:00",
          "link": "https://arxiv.org/abs/2312.11462v2",
          "size": "80kb",
          "version": "v2"
        },
        {
          "date": "2024-02-16T05:18:57+00:00",
          "link": "https://arxiv.org/abs/2312.11462v3",
          "size": "202kb",
          "version": "v3"
        },
        {
          "date": "2024-02-27T05:42:31+00:00",
          "link": "https://arxiv.org/abs/2312.11462v4",
          "size": "202kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T19:45:40+00:00",
          "link": "https://arxiv.org/abs/2312.11462v5",
          "size": "193kb",
          "version": "v5"
        }
      ],
      "title": "Cascade Speculative Drafting for Even Faster LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.11462",
        "HTML": "https://arxiv.org/html/2312.11462v5",
        "PDF": "https://arxiv.org/pdf/2312.11462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on improving LLM inference speeds through algorithm optimization rather than processing LLM training data."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/lfsszd/cs-drafting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.01450",
      "abstract": "Language models often struggle with cross-mode knowledge retrieval -- the ability to access knowledge learned in one format (mode) when queried in another. We demonstrate that models trained on multiple data sources (e.g., Wikipedia and TinyStories) exhibit significantly reduced accuracy when retrieving knowledge in a format different from its original training mode. This paper quantitatively investigates this phenomenon through a controlled study of random token sequence memorization across different modes. We first explore dataset rewriting as a solution, revealing that effective cross-mode retrieval requires prohibitively extensive rewriting efforts that follow a sigmoid-like relationship. As an alternative, we propose CASCADE, a novel pretraining algorithm that uses cascading datasets with varying sequence lengths and computing losses on only the second half of each training sequence to capture knowledge at different scales. Our experiments demonstrate that CASCADE outperforms dataset rewriting approaches, even when compressed into a single model with a unified loss function. This work provides both qualitative evidence of cross-mode retrieval limitations and a practical solution to enhance language models' ability to access knowledge independently of its presentational format.",
      "authors": [
        "Runlong Zhou",
        "Yi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T08:02:07+00:00",
          "link": "https://arxiv.org/abs/2504.01450v1",
          "size": "321kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:08:38+00:00",
          "link": "https://arxiv.org/abs/2504.01450v2",
          "size": "323kb",
          "version": "v2"
        }
      ],
      "title": "CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01450",
        "HTML": "https://arxiv.org/html/2504.01450v2",
        "PDF": "https://arxiv.org/pdf/2504.01450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel pretraining algorithm called CASCADE for language models, specifically addressing issues in multi-mode data training and retrieval, thus contributing to data processing techniques for LLMs."
      },
      "tasks": [
        "Memorization",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/zhourunlong/CASCADE_public"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15115",
      "abstract": "With growing demands for privacy protection, security, and legal compliance (e.g., GDPR), machine unlearning has emerged as a critical technique for ensuring the controllability and regulatory alignment of machine learning models. However, a fundamental challenge in this field lies in effectively verifying whether unlearning operations have been successfully and thoroughly executed. Despite a growing body of work on unlearning techniques, verification methodologies remain comparatively underexplored and often fragmented. Existing approaches lack a unified taxonomy and a systematic framework for evaluation. To bridge this gap, this paper presents the first structured survey of machine unlearning verification methods. We propose a taxonomy that organizes current techniques into two principal categories -- behavioral verification and parametric verification -- based on the type of evidence used to assess unlearning fidelity. We examine representative methods within each category, analyze their underlying assumptions, strengths, and limitations, and identify potential vulnerabilities in practical deployment. In closing, we articulate a set of open problems in current verification research, aiming to provide a foundation for developing more robust, efficient, and theoretically grounded unlearning verification mechanisms.",
      "authors": [
        "Lulu Xue",
        "Shengshan Hu",
        "Wei Lu",
        "Yan Shen",
        "Dongxu Li",
        "Peijin Guo",
        "Ziqi Zhou",
        "Minghui Li",
        "Yanjun Zhang",
        "Leo Yu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T03:33:59+00:00",
          "link": "https://arxiv.org/abs/2506.15115v1",
          "size": "461kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T15:31:03+00:00",
          "link": "https://arxiv.org/abs/2506.15115v2",
          "size": "3137kb",
          "version": "v2"
        }
      ],
      "title": "Towards Reliable Forgetting: A Survey on Machine Unlearning Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15115",
        "HTML": "https://arxiv.org/html/2506.15115v2",
        "PDF": "https://arxiv.org/pdf/2506.15115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a survey on machine unlearning and its verification, focusing on privacy and compliance, without contributing to the processing or engineering of LLM training data."
      },
      "tasks": [
        "Machine Unlearning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09095",
      "abstract": "Multimodal fusion (MMF) plays a critical role in the perception of autonomous driving, which primarily fuses camera and LiDAR streams for a comprehensive and efficient scene understanding. However, its strict reliance on precise temporal synchronization exposes it to new vulnerabilities. In this paper, we introduce DejaVu, a novel attack that exploits network-induced delays to create subtle temporal misalignments across sensor streams, severely degrading downstream MMF-based perception tasks. Our comprehensive attack analysis across different models and datasets reveals these sensors' task-specific imbalanced sensitivities: object detection is overly dependent on LiDAR inputs while object tracking is highly reliant on the camera inputs. Consequently, with a single-frame LiDAR delay, an attacker can reduce the car detection mAP by up to 88.5%, while with a three-frame camera delay, multiple object tracking accuracy (MOTA) for car drops by 73%. To detect such attacks, we propose AION, a defense patch that can work alongside the existing perception model to monitor temporal alignment through cross-modal temporal consistency. AION leverages multimodal shared representation learning and dynamic time warping to determine the path of temporal alignment and calculate anomaly scores based on the alignment. Our thorough evaluation of AION shows it achieves AUROC scores of 0.92-0.98 with low false positives across datasets and model architectures, demonstrating it as a robust and generalized defense against the temporal misalignment attacks.",
      "authors": [
        "Md Hasan Shahriar",
        "Md Mohaimin Al Barat",
        "Harshavardhan Sundar",
        "Naren Ramakrishnan",
        "Y. Thomas Hou",
        "Wenjing Lou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:44:26+00:00",
          "link": "https://arxiv.org/abs/2507.09095v1",
          "size": "1510kb",
          "version": "v1"
        }
      ],
      "title": "On the Fragility of Multimodal Perception to Temporal Misalignment in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09095",
        "HTML": "https://arxiv.org/html/2507.09095v1",
        "PDF": "https://arxiv.org/pdf/2507.09095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates vulnerabilities in multimodal fusion for autonomous driving and proposes a defense mechanism, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09283",
      "abstract": "We study the m-Eternal Domination problem, which is the following two-player game between a defender and an attacker on a graph: initially, the defender positions k guards on vertices of the graph; the game then proceeds in turns between the defender and the attacker, with the attacker selecting a vertex and the defender responding to the attack by moving a guard to the attacked vertex. The defender may move more than one guard on their turn, but guards can only move to neighboring vertices. The defender wins a game on a graph G with k guards if the defender has a strategy such that at every point of the game the vertices occupied by guards form a dominating set of G and the attacker wins otherwise. The m-eternal domination number of a graph G is the smallest value of k for which (G,k) is a defender win.\n  We show that m-Eternal Domination is NP-hard, as well as some of its variants, even on special classes of graphs. We also show structural results for the Domination and m-Eternal Domination problems in the context of four types of infinite regular grids: square, octagonal, hexagonal, and triangular, establishing tight bounds.",
      "authors": [
        "Tiziana Calamoneri",
        "Federico Cor\\`o",
        "Neeldhara Misra",
        "Saraswati G. Nanoti",
        "Giacomo Paesani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:43:19+00:00",
          "link": "https://arxiv.org/abs/2507.09283v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "m-Eternal Domination and Variants on Some Classes of Finite and Infinite Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09283",
        "HTML": "https://arxiv.org/html/2507.09283v1",
        "PDF": "https://arxiv.org/pdf/2507.09283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies the m-Eternal Domination problem in graph theory, which is unrelated to LLM training data processing or dataset engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09296",
      "abstract": "Open source projects have made incredible progress in producing transparent and widely usable machine learning models and systems, but open source alone will face challenges in fully democratizing access to AI. Unlike software, AI models require substantial resources for activation -- compute, post-training, deployment, and oversight -- which only a few actors can currently provide. This paper argues that open source AI must be complemented by public AI: infrastructure and institutions that ensure models are accessible, sustainable, and governed in the public interest. To achieve the full promise of AI models as prosocial public goods, we need to build public infrastructure to power and deliver open source software and models.",
      "authors": [
        "Joshua Tan",
        "Nicholas Vincent",
        "Katherine Elkins",
        "and Magnus Sahlgren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:16:28+00:00",
          "link": "https://arxiv.org/abs/2507.09296v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "If open source is to win, it must go public",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09296",
        "HTML": "https://arxiv.org/html/2507.09296v1",
        "PDF": "https://arxiv.org/pdf/2507.09296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the need for public infrastructure to support open source AI models but does not focus on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09485",
      "abstract": "Aspect-based sentiment analysis (ABSA) is a crucial fine-grained task in social media scenarios to identify the sentiment polarity of specific aspect terms in a sentence. Although many existing studies leverage large language models (LLMs) to perform ABSA due to their strong context understanding capabilities, they still face challenges to learn the context information in the running text because of the short text, as well as the small and unbalanced labeled training data, where most data are labeled with positive sentiment. Data augmentation (DA) is a feasible strategy for providing richer contextual information, especially when using LLMs to create synthetic training data, but faces challenges in ensuring a high quality of the augmented data.In this paper, we propose an LLM-based ABSA approach with training data augmentation.Specifically, an LLM is prompted to generate augmented training data based on the original training data, so as to construct a new training data with larger size and balanced label distributions to better train an ABSA model. Meanwhile, in order to improve the quality of the augmented data, we propose a reinforcement learning approach to optimize the data augmentation. LLM.Experiment results and further analyses on English benchmark datasets for ABSA demonstrate the effectiveness of our approach, where superior performance is observed over strong baselines and most existing studies.",
      "authors": [
        "Junjie Liu",
        "Yuanhe Tian",
        "Yan Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:07:07+00:00",
          "link": "https://arxiv.org/abs/2507.09485v1",
          "size": "568kb",
          "version": "v1"
        }
      ],
      "title": "Balanced Training Data Augmentation for Aspect-Based Sentiment Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09485",
        "HTML": "https://arxiv.org/html/2507.09485v1",
        "PDF": "https://arxiv.org/pdf/2507.09485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary technical contribution lies in generating augmented training data using LLMs and a reinforcement learning approach to improve quality, specifically for Aspect-Based Sentiment Analysis (ABSA)."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09708",
      "abstract": "This paper presents a comparative analysis of Sudoku-solving strategies, focusing on recursive backtracking and a heuristic-based constraint propagation method. Using a dataset of 500 puzzles across five difficulty levels (Beginner to Expert), we evaluated performance based on average solving time. The heuristic approach consistently outperformed backtracking, achieving speedup ratios ranging from 1.27x in Beginner puzzles to 2.91x in Expert puzzles. These findings underscore the effectiveness of heuristic strategies, particularly in tackling complex puzzles across varying difficulty levels.",
      "authors": [
        "Apekshya Bhattarai (1)",
        "Dinisha Uprety (1)",
        "Pooja Pathak (1)",
        "Safal Narshing Shrestha (1)",
        "Salina Narkarmi (1)",
        "Sanjog Sigdel (1) ((1) Department of Computer Science and Engineering",
        "Kathmandu University",
        "Nepal)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:55:40+00:00",
          "link": "https://arxiv.org/abs/2507.09708v1",
          "size": "116kb",
          "version": "v1"
        }
      ],
      "title": "A Study Of Sudoku Solving Algorithms: Backtracking and Heuristic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09708",
        "HTML": "https://arxiv.org/html/2507.09708v1",
        "PDF": "https://arxiv.org/pdf/2507.09708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves a comparative analysis of Sudoku-solving algorithms and does not touch on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09948",
      "abstract": "Deep learning-based prediction models for High-Level Synthesis (HLS) of hardware designs often struggle to generalize. In this paper, we study how to close the generalizability gap of these models through pretraining on synthetic data and introduce Iceberg, a synthetic data augmentation approach that expands both large language model (LLM)-generated programs and weak labels of unseen design configurations. Our weak label generation method is integrated with an in-context model architecture, enabling meta-learning from actual and proximate labels. Iceberg improves the geometric mean modeling accuracy by $86.4\\%$ when adapt to six real-world applications with few-shot examples and achieves a $2.47\\times$ and a $1.12\\times$ better offline DSE performance when adapting to two different test datasets. Our open-sourced code is here: \\href{https://github.com/UCLA-VAST/iceberg}{https://github.com/UCLA-VAST/iceberg}",
      "authors": [
        "Zijian Ding",
        "Tung Nguyen",
        "Weikai Li",
        "Aditya Grover",
        "Yizhou Sun",
        "Jason Cong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.09948v1",
          "size": "1351kb",
          "version": "v1"
        }
      ],
      "title": "Iceberg: Enhancing HLS Modeling with Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09948",
        "HTML": "https://arxiv.org/html/2507.09948v1",
        "PDF": "https://arxiv.org/pdf/2507.09948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses synthetic data augmentation for improving HLS modeling with LLM-generated data, which is relevant but not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10305",
      "abstract": "Context: Pair programming is an established (agile) practice and is practiced throughout the industry. Objective: Understand under what circumstances knowledge transfer can harm a pair programming session. Method: Grounded Theory Methodology based on 17 recorded pair programming sessions with 18 developers from 5 German software companies accompanied, by 6 interviews with different developers from 4 other German companies. Results: We define the student and teacher roles to help developers deal with a one-sided knowledge gap. We describe pitfalls to avoid and develop a grounded theory centered around the Power Gap in pair programming. Conclusions: Knowledge transfer can be harmful when developers don't pay attention to their partners needs and desires. If developers don't pay attention to the Power Gap and keep it in check, Defensive Behavior may arise that leads to a vicious cycle impacting the knowledge transfer, the Togetherness and the code quality in a negative way.",
      "authors": [
        "Linus Ververs and Trang Linh Lam and Janina Berger and Lutz Prechelt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:09:35+00:00",
          "link": "https://arxiv.org/abs/2507.10305v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "A Grounded Theory on the Teacher and Student Roles in Pair Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10305",
        "HTML": "https://arxiv.org/html/2507.10305v1",
        "PDF": "https://arxiv.org/pdf/2507.10305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about pair programming and knowledge transfer, which does not relate to processing or creating LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.07776",
      "abstract": "Prompt caching in large language models (LLMs) results in data-dependent timing variations: cached prompts are processed faster than non-cached prompts. These timing differences introduce the risk of side-channel timing attacks. For example, if the cache is shared across users, an attacker could identify cached prompts from fast API response times to learn information about other users' prompts. Because prompt caching may cause privacy leakage, transparency around the caching policies of API providers is important. To this end, we develop and conduct statistical audits to detect prompt caching in real-world LLM API providers. We detect global cache sharing across users in seven API providers, including OpenAI, resulting in potential privacy leakage about users' prompts. Timing variations due to prompt caching can also result in leakage of information about model architecture. Namely, we find evidence that OpenAI's embedding model is a decoder-only Transformer, which was previously not publicly known.",
      "authors": [
        "Chenchen Gu",
        "Xiang Lisa Li",
        "Rohith Kuditipudi",
        "Percy Liang",
        "Tatsunori Hashimoto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T18:58:04+00:00",
          "link": "https://arxiv.org/abs/2502.07776v1",
          "size": "254kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T04:42:28+00:00",
          "link": "https://arxiv.org/abs/2502.07776v2",
          "size": "249kb",
          "version": "v2"
        }
      ],
      "title": "Auditing Prompt Caching in Language Model APIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07776",
        "HTML": "https://arxiv.org/html/2502.07776v2",
        "PDF": "https://arxiv.org/pdf/2502.07776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the privacy risks associated with prompt caching in LLM APIs, which relates to security rather than LLM training data processing or dataset creation."
      },
      "tasks": [
        "Decoder",
        "Language Modeling",
        "Language Modelling",
        "model"
      ],
      "repo_urls": [
        "https://github.com/chenchenygu/auditing-prompt-caching"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15873",
      "abstract": "Policymakers increasingly use development cost and compute as proxies for AI capabilities and risks. Recent laws have introduced regulatory requirements that are contingent on specific thresholds. However, technical ambiguities in how to perform this accounting create loopholes that can undermine regulatory effectiveness. We propose seven principles for designing AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.",
      "authors": [
        "Stephen Casper",
        "Luke Bailey",
        "Tim Schreier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T18:59:47+00:00",
          "link": "https://arxiv.org/abs/2502.15873v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:12:40+00:00",
          "link": "https://arxiv.org/abs/2502.15873v2",
          "size": "137kb",
          "version": "v2"
        }
      ],
      "title": "Practical Principles for AI Cost and Compute Accounting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15873",
        "HTML": "https://arxiv.org/html/2502.15873v2",
        "PDF": "https://arxiv.org/pdf/2502.15873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI cost and compute accounting policies and standards, without any involvement in the processing or creation of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09534",
      "abstract": "This paper introduces Consistency Trajectory Planning (CTP), a novel offline model-based reinforcement learning method that leverages the recently proposed Consistency Trajectory Model (CTM) for efficient trajectory optimization. While prior work applying diffusion models to planning has demonstrated strong performance, it often suffers from high computational costs due to iterative sampling procedures. CTP supports fast, single-step trajectory generation without significant degradation in policy quality. We evaluate CTP on the D4RL benchmark and show that it consistently outperforms existing diffusion-based planning methods in long-horizon, goal-conditioned tasks. Notably, CTP achieves higher normalized returns while using significantly fewer denoising steps. In particular, CTP achieves comparable performance with over $120\\times$ speedup in inference time, demonstrating its practicality and effectiveness for high-performance, low-latency offline planning.",
      "authors": [
        "Guanquan Wang",
        "Takuya Hiraoka",
        "Yoshimasa Tsuruoka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:31:11+00:00",
          "link": "https://arxiv.org/abs/2507.09534v1",
          "size": "172kb",
          "version": "v1"
        }
      ],
      "title": "Consistency Trajectory Planning: High-Quality and Efficient Trajectory Optimization for Offline Model-Based Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09534",
        "HTML": "https://arxiv.org/html/2507.09534v1",
        "PDF": "https://arxiv.org/pdf/2507.09534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a reinforcement learning method for trajectory optimization and does not discuss any LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09965",
      "abstract": "Recent advancements have demonstrated the significant potential of large language models (LLMs) in analog circuit design. Nevertheless, testbench construction for analog circuits remains manual, creating a critical bottleneck in achieving fully automated design processes. Particularly when replicating circuit designs from academic papers, manual Testbench construction demands time-intensive implementation and frequent adjustments, which fails to address the dynamic diversity and flexibility requirements for automation. AnalogTester tackles automated analog design challenges through an LLM-powered pipeline: a) domain-knowledge integration, b) paper information extraction, c) simulation scheme synthesis, and d) testbench code generation with Tsinghua Electronic Design (TED). AnalogTester has demonstrated automated Testbench generation capabilities for three fundamental analog circuit types: operational amplifiers (op-amps), bandgap references (BGRs), and low-dropout regulators (LDOs), while maintaining a scalable framework for adaptation to broader circuit topologies. Furthermore, AnalogTester can generate circuit knowledge data and TED code corpus, establishing fundamental training datasets for LLM specialization in analog circuit design automation.",
      "authors": [
        "Weiyu Chen",
        "Chengjie Liu",
        "Wenhao Huang",
        "Jinyang Lyu",
        "Mingqian Yang",
        "Yuan Du",
        "Li Du",
        "and Jun Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:32:23+00:00",
          "link": "https://arxiv.org/abs/2507.09965v1",
          "size": "1462kb",
          "version": "v1"
        }
      ],
      "title": "AnalogTester: A Large Language Model-Based Framework for Automatic Testbench Generation in Analog Circuit Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09965",
        "HTML": "https://arxiv.org/html/2507.09965v1",
        "PDF": "https://arxiv.org/pdf/2507.09965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the AnalogTester framework, which generates testbench code and circuit knowledge data for LLM specialization in analog design. This involves automated creation of datasets from existing papers, focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.04916",
      "abstract": "With the trend of large graph learning models, business owners tend to employ a model provided by a third party to deliver business services to users. However, these models might be backdoored, and malicious users can submit trigger-embedded inputs to manipulate the model predictions. Current graph backdoor defenses have several limitations: 1) depending on model-related details, 2) requiring additional model fine-tuning, and 3) relying upon extra explainability tools, all of which are infeasible under stringent privacy policies. To address those limitations, we propose GraphProt, which allows resource-constrained business owners to rely on third parties to avoid backdoor attacks on GNN-based graph classifiers. Our GraphProt is model-agnostic and only relies on the input graph. The key insight is to leverage subgraph information for prediction, thereby mitigating backdoor effects induced by triggers. GraphProt comprises two components: clustering-based trigger elimination and robust subgraph ensemble. Specifically, we first propose feature-topology clustering that aims to remove most of the anomalous subgraphs (triggers). Moreover, we design subgraph sampling strategies based on feature-topology clustering to build a robust classifier via majority vote. Experimental results across three backdoor attacks and six benchmark datasets demonstrate that GraphProt significantly reduces the backdoor attack success rate while preserving the model accuracy on regular graph classification tasks.",
      "authors": [
        "Xiao Yang",
        "Kai Zhou",
        "Yuni Lai",
        "Gaolei Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T11:04:38+00:00",
          "link": "https://arxiv.org/abs/2410.04916v1",
          "size": "863kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:45:45+00:00",
          "link": "https://arxiv.org/abs/2410.04916v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Defense-as-a-Service: Black-box Shielding against Backdoored Graph Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04916",
        "PDF": "https://arxiv.org/pdf/2410.04916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a method for protecting graph models from backdoor attacks. It concerns model security and robustness, rather than LLM training data processing."
      },
      "tasks": [
        "Backdoor Attack",
        "Clustering",
        "Graph Classification",
        "Graph Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09060",
      "abstract": "Datasets play a central role in AI governance by enabling both evaluation (measuring capabilities) and alignment (enforcing values) along axes such as helpfulness, harmlessness, toxicity, quality, and more. However, most alignment and evaluation datasets depend on researcher-defined or developer-defined axes curated from non-representative samples. As a result, developers typically benchmark models against broad (often Western-centric) values that overlook the varied contexts of their real-world deployment. Consequently, models trained on such proxies can fail to meet the needs and expectations of diverse user communities within these deployment contexts. To bridge this gap, we introduce CALMA (Context-aligned Axes for Language Model Alignment), a grounded, participatory methodology for eliciting context-relevant axes for evaluation and alignment. In a pilot with two distinct communities, CALMA surfaced novel priorities that are absent from standard benchmarks. Our findings demonstrate the value of evaluation practices based on open-ended and use-case-driven processes. Our work advances the development of pluralistic, transparent, and context-sensitive alignment pipelines.",
      "authors": [
        "Prajna Soni",
        "Deepika Raman",
        "Dylan Hadfield-Menell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T22:33:11+00:00",
          "link": "https://arxiv.org/abs/2507.09060v1",
          "size": "118kb",
          "version": "v1"
        }
      ],
      "title": "CALMA: A Process for Deriving Context-aligned Axes for Language Model Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09060",
        "HTML": "https://arxiv.org/html/2507.09060v1",
        "PDF": "https://arxiv.org/pdf/2507.09060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a process for deriving context-aligned axes for model alignment, it does not primarily focus on processing or creating LLM training data. It instead deals with alignment axes which are used for model evaluation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09076",
      "abstract": "Recent research has focused on applying speech large language model (SLLM) to improve speech emotion recognition (SER). However, the inherently high frame rate in speech modality severely limits the signal processing and understanding capabilities of SLLM. For example, a SLLM with a 4K context window can only process 80 seconds of audio at 50Hz feature sampling rate before reaching its capacity limit. Input token compression methods used in SLLM overlook the continuity and inertia of emotions across multiple conversation turns. This paper proposes a Dynamic Parameter Memory (DPM) mechanism with contextual semantics and sentence-level emotion encoding, enabling processing of unlimited-length audio with limited context windows in SLLM. Specifically, DPM progressively encodes sentence-level information and emotions into a temporary LoRA module during inference to effectively \"memorize\" the contextual information. We trained an emotion SLLM as a backbone and incorporated our DPM into inference for emotion recognition in conversation (ERC). Experimental results on the IEMOCAP dataset show that DPM significantly improves the emotion recognition capabilities of SLLM when processing long audio sequences, achieving state-of-the-art performance.",
      "authors": [
        "Jialong Mai",
        "Xiaofen Xing",
        "Yawei Li",
        "Zhipeng Li",
        "Jingyuan Xing",
        "Xiangmin Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:36:59+00:00",
          "link": "https://arxiv.org/abs/2507.09076v1",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Parameter Memory: Temporary LoRA-Enhanced LLM for Long-Sequence Emotion Recognition in Conversation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09076",
        "HTML": "https://arxiv.org/html/2507.09076v1",
        "PDF": "https://arxiv.org/pdf/2507.09076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a Dynamic Parameter Memory mechanism for long-sequence emotion recognition in conversation using speech LLMs, and does not discuss any training data collection, processing, or engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09917",
      "abstract": "Spatial time series visualization offers scientific research pathways and analytical decision-making tools across various spatiotemporal domains. Despite many advanced methodologies, the seamless integration of temporal and spatial information remains a challenge. The space-time cube (STC) stands out as a promising approach for the synergistic presentation of spatial and temporal information, with successful applications across various spatiotemporal datasets. However, the STC is plagued by well-known issues such as visual occlusion and depth ambiguity, which are further exacerbated when dealing with large-scale spatial time series data. In this study, we introduce a novel technical framework termed VolumeSTCube, designed for continuous spatiotemporal phenomena. It first leverages the concept of the STC to transform discretely distributed spatial time series data into continuously volumetric data. Subsequently, volume rendering and surface rendering techniques are employed to visualize the transformed volumetric data. Volume rendering is utilized to mitigate visual occlusion, while surface rendering provides pattern details by enhanced lighting information. Lastly, we design interactions to facilitate the exploration and analysis from temporal, spatial, and spatiotemporal perspectives. VolumeSTCube is evaluated through a computational experiment, a real-world case study with one expert, and a controlled user study with twelve non-experts, compared against a baseline from prior work, showing its superiority and effectiveness in largescale spatial time series analysis.",
      "authors": [
        "Zikun Deng",
        "Jiabao Huang",
        "Chenxi Ruan",
        "Jialing Li",
        "Shaowu Gao",
        "Yi Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:49:54+00:00",
          "link": "https://arxiv.org/abs/2507.09917v1",
          "size": "16588kb",
          "version": "v1"
        }
      ],
      "title": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09917",
        "HTML": "https://arxiv.org/html/2507.09917v1",
        "PDF": "https://arxiv.org/pdf/2507.09917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visualization techniques for spatiotemporal datasets and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10127",
      "abstract": "Accurate motion estimation for tracking deformable tissues in echocardiography is essential for precise cardiac function measurements. While traditional methods like block matching or optical flow struggle with intricate cardiac motion, modern point tracking approaches remain largely underexplored in this domain. This work investigates the potential of state-of-the-art (SOTA) point tracking methods for ultrasound, with a focus on echocardiography. Although these novel approaches demonstrate strong performance in general videos, their effectiveness and generalizability in echocardiography remain limited. By analyzing cardiac motion throughout the heart cycle in real B-mode ultrasound videos, we identify that a directional motion bias across different views is affecting the existing training strategies. To mitigate this, we refine the training procedure and incorporate a set of tailored augmentations to reduce the bias and enhance tracking robustness and generalization through impartial cardiac motion. We also propose a lightweight network leveraging multi-scale cost volumes from spatial context alone to challenge the advanced spatiotemporal point tracking models. Experiments demonstrate that fine-tuning with our strategies significantly improves models' performances over their baselines, even for out-of-distribution (OOD) cases. For instance, EchoTracker boosts overall position accuracy by 60.7% and reduces median trajectory error by 61.5% across heart cycle phases. Interestingly, several point tracking models fail to outperform our proposed simple model in terms of tracking accuracy and generalization, reflecting their limitations when applied to echocardiography. Nevertheless, clinical evaluation reveals that these methods improve GLS measurements, aligning more closely with expert-validated, semi-automated tools and thus demonstrating better reproducibility in real-world applications.",
      "authors": [
        "Md Abulkalam Azad",
        "John Nyberg",
        "H{\\aa}vard Dalen",
        "Bj{\\o}rnar Grenne",
        "Lasse Lovstakken",
        "Andreas {\\O}stvik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:18:26+00:00",
          "link": "https://arxiv.org/abs/2507.10127v1",
          "size": "6899kb",
          "version": "v1"
        }
      ],
      "title": "Taming Modern Point Tracking for Speckle Tracking Echocardiography via Impartial Motion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10127",
        "HTML": "https://arxiv.org/html/2507.10127v1",
        "PDF": "https://arxiv.org/pdf/2507.10127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines motion estimation techniques for echocardiography and does not address LLM data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.06614",
      "abstract": "To effectively operate in various dynamic scenarios, RL agents must be resilient to unexpected changes in their environment. Previous work on this form of resilience has focused on single-agent settings. In this work, we introduce and formalize a multi-agent variant of resilience, which we term group resilience. We further hypothesize that collaboration with other agents is key to achieving group resilience; collaborating agents adapt better to environmental perturbations in multi-agent reinforcement learning (MARL) settings. We test our hypothesis empirically by evaluating different collaboration protocols and examining their effect on group resilience. Our experiments show that all the examined collaborative approaches achieve higher group resilience than their non-collaborative counterparts.",
      "authors": [
        "Sarah Keren",
        "Matthias Gerstgrasser",
        "Ofir Abu and Jeffrey Rosenschein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-12T09:03:19+00:00",
          "link": "https://arxiv.org/abs/2111.06614v1",
          "size": "663kb",
          "version": "v1"
        },
        {
          "date": "2022-12-09T22:14:28+00:00",
          "link": "https://arxiv.org/abs/2111.06614v2",
          "size": "1162kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T07:57:25+00:00",
          "link": "https://arxiv.org/abs/2111.06614v3",
          "size": "1052kb",
          "version": "v3"
        }
      ],
      "title": "Collaboration Promotes Group Resilience in Multi-Agent AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.06614",
        "HTML": "https://arxiv.org/html/2111.06614v3",
        "PDF": "https://arxiv.org/pdf/2111.06614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on multi-agent reinforcement learning and group resilience, with no discussion or contribution related to LLM training data processing."
      },
      "tasks": [
        "Multi-agent Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.17709",
      "abstract": "In this study, we introduce MGA-Net, a novel mask-guided attention neural network, which extends the U-net model for precision neonatal brain imaging. MGA-Net is designed to extract the brain from other structures and reconstruct high-quality brain images. The network employs a common encoder and two decoders: one for brain mask extraction and the other for brain region reconstruction. A key feature of MGA-Net is its high-level mask-guided attention module, which leverages features from the brain mask decoder to enhance image reconstruction. To enable the same encoder and decoder to process both MRI and ultrasound (US) images, MGA-Net integrates sinusoidal positional encoding. This encoding assigns distinct positional values to MRI and US images, allowing the model to effectively learn from both modalities. Consequently, features learned from a single modality can aid in learning a modality with less available data, such as US. We extensively validated the proposed MGA-Net on diverse and independent datasets from varied clinical settings and neonatal age groups. The metrics used for assessment included the DICE similarity coefficient, recall, and accuracy for image segmentation; structural similarity for image reconstruction; and root mean squared error for total brain volume estimation from 3D ultrasound images. Our results demonstrate that MGA-Net significantly outperforms traditional methods, offering superior performance in brain extraction and segmentation while achieving high precision in image reconstruction and volumetric analysis. Thus, MGA-Net represents a robust and effective preprocessing tool for MRI and 3D ultrasound images, marking a significant advance in neuroimaging that enhances both research and clinical diagnostics in the neonatal period and beyond.Our code is available at https://github.com/BahramJafrasteh/MGA-Net",
      "authors": [
        "Bahram Jafrasteh",
        "Simon Pedro Lubian-Lopez",
        "Emiliano Trimarco",
        "Macarena Roman Ruiz",
        "Carmen Rodriguez Barrios",
        "Yolanda Marin Almagro",
        "Isabel Benavente-Fernandez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T16:48:18+00:00",
          "link": "https://arxiv.org/abs/2406.17709v1",
          "size": "6982kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T18:07:51+00:00",
          "link": "https://arxiv.org/abs/2406.17709v2",
          "size": "10288kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T16:28:08+00:00",
          "link": "https://arxiv.org/abs/2406.17709v3",
          "size": "20565kb",
          "version": "v3"
        }
      ],
      "title": "MGA-Net: A Novel Mask-Guided Attention Neural Network for Precision Neonatal Brain Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17709",
        "HTML": "https://arxiv.org/html/2406.17709v3",
        "PDF": "https://arxiv.org/pdf/2406.17709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces MGA-Net for neonatal brain imaging and focuses on image reconstruction and analysis, not LLM training data processing."
      },
      "tasks": [
        "Decoder",
        "Image Reconstruction",
        "Image Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/bahramjafrasteh/mga-net"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.09241",
      "abstract": "Unsupervised restoration approaches based on generative adversarial networks (GANs) offer a promising solution without requiring paired datasets. Yet, these GAN-based approaches struggle to surpass the performance of conventional unsupervised GAN-based frameworks without significantly modifying model structures or increasing the computational complexity. To address these issues, we propose a self-collaboration (SC) strategy for existing restoration models. This strategy utilizes information from the previous stage as feedback to guide subsequent stages, achieving significant performance improvement without increasing the framework's inference complexity. The SC strategy comprises a prompt learning (PL) module and a restorer ($Res$). It iteratively replaces the previous less powerful fixed restorer $\\overline{Res}$ in the PL module with a more powerful $Res$. The enhanced PL module generates better pseudo-degraded/clean image pairs, leading to a more powerful $Res$ for the next iteration. Our SC can significantly improve the $Res$'s performance by over 1.5 dB without adding extra parameters or computational complexity during inference. Meanwhile, existing self-ensemble (SE) and our SC strategies enhance the performance of pre-trained restorers from different perspectives. As SE increases computational complexity during inference, we propose a re-boosting module to the SC (Reb-SC) to improve the SC strategy further by incorporating SE into SC without increasing inference time. This approach further enhances the restorer's performance by approximately 0.3 dB. Extensive experimental results on restoration tasks demonstrate that the proposed model performs favorably against existing state-of-the-art unsupervised restoration methods. Source code and trained models are publicly available at: https://github.com/linxin0/RSCP2GAN.",
      "authors": [
        "Xin Lin",
        "Yuyan Zhou",
        "Jingtong Yue",
        "Chao Ren",
        "Kelvin C.K. Chan",
        "Lu Qi",
        "Ming-Hsuan Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-17T16:26:59+00:00",
          "link": "https://arxiv.org/abs/2408.09241v1",
          "size": "10465kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:15:10+00:00",
          "link": "https://arxiv.org/abs/2408.09241v2",
          "size": "13315kb",
          "version": "v2"
        }
      ],
      "title": "Re-boosting Self-Collaboration Parallel Prompt GAN for Unsupervised Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.09241",
        "HTML": "https://arxiv.org/html/2408.09241v2",
        "PDF": "https://arxiv.org/pdf/2408.09241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on unsupervised image restoration using GANs and proposes a self-collaboration strategy to improve performance. It does not discuss LLM training data processing."
      },
      "tasks": [
        "Image Restoration",
        "Prompt Learning"
      ],
      "repo_urls": [
        "https://github.com/linxin0/scpgabnet",
        "https://github.com/linxin0/rscp2gan"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01641",
      "abstract": "Boyen and Li posed an open problem in their ASIACRYPT 2016 conference paper: How to construct a tightly secure homomorphic signature scheme under the Short Integer Solution (SIS) hardness assumption in the standard model. This work provides the first complete resolution of this problem under the same assumption.",
      "authors": [
        "Heng Guo",
        "Fengxia Liu",
        "Kun Tian",
        "Zhiyong Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T15:51:57+00:00",
          "link": "https://arxiv.org/abs/2412.01641v1",
          "size": "585kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T15:03:09+00:00",
          "link": "https://arxiv.org/abs/2412.01641v2",
          "size": "119kb",
          "version": "v2"
        },
        {
          "date": "2025-03-15T05:25:44+00:00",
          "link": "https://arxiv.org/abs/2412.01641v3",
          "size": "36kb",
          "version": "v3"
        },
        {
          "date": "2025-04-19T03:02:20+00:00",
          "link": "https://arxiv.org/abs/2412.01641v4",
          "size": "353kb",
          "version": "v4"
        },
        {
          "date": "2025-06-18T17:32:07+00:00",
          "link": "https://arxiv.org/abs/2412.01641v5",
          "size": "41kb",
          "version": "v5"
        },
        {
          "date": "2025-06-27T01:52:06+00:00",
          "link": "https://arxiv.org/abs/2412.01641v6",
          "size": "41kb",
          "version": "v6"
        },
        {
          "date": "2025-07-14T14:48:11+00:00",
          "link": "https://arxiv.org/abs/2412.01641v7",
          "size": "41kb",
          "version": "v7"
        }
      ],
      "title": "Linearly Homomorphic Signature with Tight Security on Lattice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01641",
        "HTML": "https://arxiv.org/html/2412.01641",
        "PDF": "https://arxiv.org/pdf/2412.01641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a cryptography problem related to homomorphic signatures under lattice-based assumptions, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05179",
      "abstract": "In an era of rampant misinformation, generating reliable news explanations is vital, especially for under-represented languages like Hindi. Lacking robust automated tools, Hindi faces challenges in scaling misinformation detection. To bridge this gap, we propose a novel framework integrating Direct Preference Optimization (DPO) with curriculum learning to align machine-generated explanations with human reasoning. Fact-checked explanations from credible sources serve as preferred responses, while LLM outputs highlight system limitations and serve as non-preferred responses. To refine task-specific alignment, we introduce two key parameters -- Actuality and Finesse -- into the DPO loss function, enhancing explanation quality and consistency. Experiments with LLMs (Mistral, Llama, Gemma) and PLMs (mBART, mT5) confirm the framework's effectiveness in generating coherent, contextually relevant explanations. This scalable approach combats misinformation and extends automated explanation generation to low-resource languages.",
      "authors": [
        "Pulkit Bansal",
        "Raghvendra Kumar",
        "Shakti Singh",
        "Sriparna Saha",
        "Adam Jatowt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:34:28+00:00",
          "link": "https://arxiv.org/abs/2507.05179v1",
          "size": "32903kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T17:59:01+00:00",
          "link": "https://arxiv.org/abs/2507.05179v2",
          "size": "32904kb",
          "version": "v2"
        }
      ],
      "title": "From Fragments to Facts: A Curriculum-Driven DPO Approach for Generating Hindi News Veracity Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05179",
        "HTML": "https://arxiv.org/html/2507.05179v2",
        "PDF": "https://arxiv.org/pdf/2507.05179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions using LLM outputs for generating explanations related to misinformation detection but does not focus on training data processing. The primary contribution lies in aligning explanations with human reasoning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09101",
      "abstract": "In grocery e-commerce, customers often build ingredient baskets guided by dietary preferences but lack the expertise to create complete meals. Leveraging recipe knowledge to recommend complementary ingredients based on a partial basket is essential for improving the culinary experience. Traditional recipe completion methods typically predict a single missing ingredient using a leave-one-out strategy. However, they fall short in two key aspects: (i) they do not reflect real-world scenarios where multiple ingredients are often needed, and (ii) they overlook relationships among the missing ingredients themselves. To address these limitations, we reformulate basket completion as a set-to-set (S2S) recommendation problem, where an incomplete basket is input into a system that predicts a set of complementary ingredients. We introduce S2SRec2, a set-to-set ingredient recommendation framework based on a Set Transformer and trained in a multitask learning paradigm. S2SRec2 jointly learns to (i) retrieve missing ingredients from the representation of existing ones and (ii) assess basket completeness after prediction. These tasks are optimized together, enforcing accurate retrieval and coherent basket completion. Experiments on large-scale recipe datasets and qualitative analyses show that S2SRec2 significantly outperforms single-target baselines, offering a promising approach to enhance grocery shopping and inspire culinary creativity.",
      "authors": [
        "Yanan Cao",
        "Omid Memarrast",
        "Shiqin Cai",
        "Sinduja Subramaniam",
        "Evren Korpeoglu",
        "Kannan Achan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:09:30+00:00",
          "link": "https://arxiv.org/abs/2507.09101v1",
          "size": "723kb",
          "version": "v1"
        }
      ],
      "title": "S2SRec2: Set-to-Set Recommendation for Basket Completion with Recipe",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09101",
        "HTML": "https://arxiv.org/html/2507.09101v1",
        "PDF": "https://arxiv.org/pdf/2507.09101"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses recommendation systems for ingredient baskets using set-to-set completion, focusing on model architecture for recommendation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09448",
      "abstract": "Efficiently re-identifying and tracking objects across a network of cameras is crucial for applications like traffic surveillance. Spatula is the state-of-the-art video database management system (VDBMS) for processing Re-ID queries. However, it suffers from two limitations. Its spatio-temporal filtering scheme has limited accuracy on large camera networks due to localized camera history. It is not suitable for critical video analytics applications that require high recall due to a lack of support for adaptive query processing.\n  In this paper, we present Tracer, a novel VDBMS for efficiently processing Re-ID queries using an adaptive query processing framework. Tracer selects the optimal camera to process at each time step by training a recurrent network to model long-term historical correlations. To accelerate queries under a high recall constraint, Tracer incorporates a probabilistic adaptive search model that processes camera feeds in incremental search windows and dynamically updates the sampling probabilities using an exploration-exploitation strategy. To address the paucity of benchmarks for the Re-ID task due to privacy concerns, we present a novel synthetic benchmark for generating multi-camera Re-ID datasets based on real-world traffic distribution. Our evaluation shows that Tracer outperforms the state-of-the-art cross-camera analytics system by 3.9x on average across diverse datasets.",
      "authors": [
        "Pramod Chunduri",
        "Yao Lu",
        "Joy Arulraj"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:22:08+00:00",
          "link": "https://arxiv.org/abs/2507.09448v1",
          "size": "19692kb",
          "version": "v1"
        }
      ],
      "title": "TRACER: Efficient Object Re-Identification in Networked Cameras through Adaptive Query Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09448",
        "HTML": "https://arxiv.org/html/2507.09448v1",
        "PDF": "https://arxiv.org/pdf/2507.09448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel synthetic benchmark for generating datasets, which slightly touches on data generation. However, the primary focus is on efficient object re-identification in camera networks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09616",
      "abstract": "Deploying transformer-based neural networks on resource-constrained edge devices presents a significant challenge. This challenge is often addressed through various techniques, such as low-rank approximation and mixed-precision quantization. In this work, we introduce Mixed Low-Rank and Quantization (MLoRQ), a novel method that integrates both techniques. MLoRQ employs a two-stage optimization process to determine optimal bit-width and rank assignments for each layer, adhering to predefined memory constraints. This process includes: (i) an intra-layer optimization that identifies potentially optimal compression solutions out of all low-rank and quantization combinations; (ii) an inter-layer optimization that assigns bit-width precision and rank to each layer while ensuring the memory constraint is met. An optional final step applies a sequential optimization process using a modified adaptive rounding technique to mitigate compression-induced errors in joint low-rank approximation and quantization. The method is compatible and can be seamlessly integrated with most existing quantization algorithms. MLoRQ shows state-of-the-art results with up to 15\\% performance improvement, evaluated on Vision Transformers for image classification, object detection, and instance segmentation tasks.",
      "authors": [
        "Ofir Gordon",
        "Ariel Lapid",
        "Elad Cohen",
        "Yarden Yagil",
        "Arnon Netzer",
        "Hai Victor Habi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:48:46+00:00",
          "link": "https://arxiv.org/abs/2507.09616v1",
          "size": "4567kb",
          "version": "v1"
        }
      ],
      "title": "MLoRQ: Bridging Low-Rank and Quantization for Transformer Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09616",
        "HTML": "https://arxiv.org/html/2507.09616v1",
        "PDF": "https://arxiv.org/pdf/2507.09616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses techniques for transformer compression using low-rank approximation and quantization, without mentioning any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09754",
      "abstract": "Transcription Factor Binding Site (TFBS) prediction is crucial for understanding gene regulation and various biological processes. This study introduces a novel Mixture of Experts (MoE) approach for TFBS prediction, integrating multiple pre-trained Convolutional Neural Network (CNN) models, each specializing in different TFBS patterns. We evaluate the performance of our MoE model against individual expert models on both in-distribution and out-of-distribution (OOD) datasets, using six randomly selected transcription factors (TFs) for OOD testing. Our results demonstrate that the MoE model achieves competitive or superior performance across diverse TF binding sites, particularly excelling in OOD scenarios. The Analysis of Variance (ANOVA) statistical test confirms the significance of these performance differences. Additionally, we introduce ShiftSmooth, a novel attribution mapping technique that provides more robust model interpretability by considering small shifts in input sequences. Through comprehensive explainability analysis, we show that ShiftSmooth offers superior attribution for motif discovery and localization compared to traditional Vanilla Gradient methods. Our work presents an efficient, generalizable, and interpretable solution for TFBS prediction, potentially enabling new discoveries in genome biology and advancing our understanding of transcriptional regulation.",
      "authors": [
        "Aakash Tripathi",
        "Ian E. Nielsen",
        "Muhammad Umer",
        "Ravi P. Ramachandran",
        "Ghulam Rasool"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:21:41+00:00",
          "link": "https://arxiv.org/abs/2507.09754v1",
          "size": "5000kb",
          "version": "v1"
        }
      ],
      "title": "Explainable AI in Genomics: Transcription Factor Binding Site Prediction with Mixture of Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09754",
        "HTML": "https://arxiv.org/html/2507.09754v1",
        "PDF": "https://arxiv.org/pdf/2507.09754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on transcription factor binding site prediction using a novel mixture of experts model and explainable AI techniques. It does not involve LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09767",
      "abstract": "Pairwise compatibility calculation is at the core of most fragments-reconstruction algorithms, in particular those designed to solve different types of the jigsaw puzzle problem. However, most existing approaches fail, or aren't designed to deal with fragments of realistic geometric properties one encounters in real-life puzzles. And in all other cases, compatibility methods rely strongly on the restricted shapes of the fragments. In this paper, we propose an efficient hybrid (geometric and pictorial) approach for computing the optimal alignment for pairs of fragments, without any assumptions about their shapes, dimensions, or pictorial content. We introduce a new image fragments dataset generated via a novel method for image fragmentation and a formal erosion model that mimics real-world archaeological erosion, along with evaluation metrics for the compatibility task. We then embed our proposed compatibility into an archaeological puzzle-solving framework and demonstrate state-of-the-art neighborhood-level precision and recall on the RePAIR 2D dataset, directly reflecting compatibility performance improvements.",
      "authors": [
        "Ofir Itzhak Shahar",
        "Gur Elkin",
        "Ohad Ben-Shahar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:49:42+00:00",
          "link": "https://arxiv.org/abs/2507.09767v1",
          "size": "7673kb",
          "version": "v1"
        }
      ],
      "title": "Pairwise Alignment & Compatibility for Arbitrarily Irregular Image Fragments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09767",
        "HTML": "https://arxiv.org/html/2507.09767v1",
        "PDF": "https://arxiv.org/pdf/2507.09767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with image fragment alignment for jigsaw puzzles and does not discuss aspects of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10029",
      "abstract": "Memory-efficient personalization is critical for adapting text-to-image diffusion models while preserving user privacy and operating within the limited computational resources of edge devices. To this end, we propose a selective optimization framework that adaptively chooses between backpropagation on low-resolution images (BP-low) and zeroth-order optimization on high-resolution images (ZO-high), guided by the characteristics of the diffusion process. As observed in our experiments, BP-low efficiently adapts the model to target-specific features, but suffers from structural distortions due to resolution mismatch. Conversely, ZO-high refines high-resolution details with minimal memory overhead but faces slow convergence when applied without prior adaptation. By complementing both methods, our framework leverages BP-low for effective personalization while using ZO-high to maintain structural consistency, achieving memory-efficient and high-quality fine-tuning. To maximize the efficacy of both BP-low and ZO-high, we introduce a timestep-aware probabilistic function that dynamically selects the appropriate optimization strategy based on diffusion timesteps. This function mitigates the overfitting from BP-low at high timesteps, where structural information is critical, while ensuring ZO-high is applied more effectively as training progresses. Experimental results demonstrate that our method achieves competitive performance while significantly reducing memory consumption, enabling scalable, high-quality on-device personalization without increasing inference latency.",
      "authors": [
        "Seokeon Choi",
        "Sunghyun Park",
        "Hyoungwoo Park",
        "Jeongho Kim",
        "Sungrack Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:08:55+00:00",
          "link": "https://arxiv.org/abs/2507.10029v1",
          "size": "6145kb",
          "version": "v1"
        }
      ],
      "title": "Memory-Efficient Personalization of Text-to-Image Diffusion Models via Selective Optimization Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10029",
        "HTML": "https://arxiv.org/html/2507.10029v1",
        "PDF": "https://arxiv.org/pdf/2507.10029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on memory-efficient personalization for diffusion models through optimization, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10259",
      "abstract": "The rapid growth of large language model (LLM) services imposes increasing demands on distributed GPU inference infrastructure. Most existing scheduling systems rely on the current system state to make decisions, without considering how task demand and resource availability evolve over time. This lack of temporal awareness leads to inefficient GPU utilization, high task migration overhead, and poor system responsiveness under dynamic workloads. In this work, we identify the fundamental limitations of these instantaneous-state-only scheduling approaches and propose Temporal Optimal Resource scheduling via Two-layer Architecture (TORTA). TORTA introduces a spatiotemporal scheduling framework that captures both long-term workload patterns and short-term execution constraints. It adopts a two-layer design: a macro-level scheduler leverages reinforcement learning and optimal transport to coordinate inter-region task distribution, while a micro-level allocator refines task-to-server assignments within each region to reduce latency and switching costs. Experimental results across multiple network topologies show that TORTA reduces average inference response time by up to 15\\%, improves load balance by approximately 4-5\\%, and cuts total operational cost by 10-20\\% compared to state-of-the-art baseline methods.",
      "authors": [
        "Chengze Du",
        "Zhiwei Yu",
        "Heng Xu",
        "Haojie Wang",
        "Bo liu and Jialong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:33:30+00:00",
          "link": "https://arxiv.org/abs/2507.10259v1",
          "size": "2337kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Timeslot Optimization for Distributed GPU Inference Using Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10259",
        "HTML": "https://arxiv.org/html/2507.10259v1",
        "PDF": "https://arxiv.org/pdf/2507.10259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses cross-timeslot optimization for distributed GPU inference using reinforcement learning, which indirectly relates to efficient infrastructure for LLM services but does not focus on the data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10446",
      "abstract": "The ability to transfer knowledge from prior experiences to novel tasks stands as a pivotal capability of intelligent agents, including both humans and computational models. This principle forms the basis of transfer learning, where large pre-trained neural networks are fine-tuned to adapt to downstream tasks. Transfer learning has demonstrated tremendous success, both in terms of task adaptation speed and performance. However there are several domains where, due to lack of data, training such large pre-trained models or foundational models is not a possibility - computational chemistry, computational immunology, and medical imaging are examples. To address these challenges, our work focuses on designing architectures to enable efficient acquisition of priors when large amounts of data are unavailable. In particular, we demonstrate that we can use neural memory to enable adaptation on non-stationary distributions with only a few samples. Then we demonstrate that our hypernetwork designs (a network that generates another network) can acquire more generalizable priors than standard networks when trained with Model Agnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene generation, demonstrating that they can acquire priors efficiently on just a handful of training scenes, thereby leading to faster text-to-3D generation. We then extend our hypernetwork framework to perform 3D segmentation on novel scenes with limited data by efficiently transferring priors from earlier viewed scenes. Finally, we repurpose an existing molecular generative method as a pre-training framework that facilitates improved molecular property prediction, addressing critical challenges in computational immunology",
      "authors": [
        "Sudarshan Babu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.10446v1",
          "size": "13172kb",
          "version": "v1"
        }
      ],
      "title": "Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10446",
        "HTML": "https://arxiv.org/html/2507.10446v1",
        "PDF": "https://arxiv.org/pdf/2507.10446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on designing architectures for efficient acquisition of priors with limited data, not on processing LLM training data. The method involves neural memory and hypernetwork designs, which are architectural modifications rather than data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.15600",
      "abstract": "Neural architecture search (NAS) enables researchers to automatically explore vast search spaces and find efficient neural networks. But NAS suffers from a key bottleneck, i.e., numerous architectures need to be evaluated during the search process, which requires a lot of computing resources and time. In order to improve the efficiency of NAS, a series of methods have been proposed to reduce the evaluation time of neural architectures. However, they are not efficient enough and still only focus on the accuracy of architectures. In addition to the classification accuracy, more efficient and smaller network architectures are required in real-world applications. To address the above problems, we propose the SMEM-NAS, a pairwise comparison relation-assisted multi-objective evolutionary algorithm based on a multi-population mechanism. In the SMEM-NAS, a surrogate model is constructed based on pairwise comparison relations to predict the accuracy ranking of architectures, rather than the absolute accuracy. Moreover, two populations cooperate with each other in the search process, i.e., a main population guides the evolution, while a vice population expands the diversity. Our method aims to provide high-performance models that take into account multiple optimization objectives. We conduct a series of experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets to verify its effectiveness. With only a single GPU searching for 0.17 days, competitive architectures can be found by SMEM-NAS which achieves 78.91% accuracy with the MAdds of 570M on the ImageNet. This work makes a significant advance in the important field of NAS. Our code is publicly available at https://github.com/ccz-enas/SMEM-NAS.",
      "authors": [
        "Yu Xue",
        "Pengcheng Jiang",
        "Chenchen Zhu",
        "MengChu Zhou",
        "Mohamed Wahib",
        "Moncef Gabbouj"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-22T12:46:22+00:00",
          "link": "https://arxiv.org/abs/2407.15600v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:24:52+00:00",
          "link": "https://arxiv.org/abs/2407.15600v2",
          "size": "310kb",
          "version": "v2"
        }
      ],
      "title": "A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.15600",
        "HTML": "https://arxiv.org/html/2407.15600v2",
        "PDF": "https://arxiv.org/pdf/2407.15600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving neural architecture search methods through a multi-objective evolutionary algorithm, with no focus on LLM training data processing."
      },
      "tasks": [
        "Neural Architecture Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08411",
      "abstract": "Accurate spatial-temporal (ST) prediction for dynamic systems, such as urban mobility and weather patterns, is crucial but hindered by complex ST correlations and the challenge of concurrently modeling long-term trends with short-term fluctuations. Existing methods often falter in these areas. This paper proposes the BiDepth Multimodal Neural Network (BDMNN), which integrates two key innovations: 1) a bidirectional depth modulation mechanism that dynamically adjusts network depth to comprehensively capture both long-term seasonality and immediate short-term events; and 2) a novel convolutional self-attention cell (CSAC). Critically, unlike many attention mechanisms that can lose spatial acuity, our CSAC is specifically designed to preserve crucial spatial relationships throughout the network, akin to standard convolutional layers, while simultaneously capturing temporal dependencies. Evaluated on real-world urban traffic and precipitation datasets, BDMNN demonstrates significant accuracy improvements, achieving a 12% Mean Squared Error (MSE) reduction in urban traffic prediction and a 15% improvement in precipitation forecasting over leading deep learning benchmarks like ConvLSTM, using comparable computational resources. These advancements offer robust ST forecasting for smart city management, disaster prevention, and resource optimization.",
      "authors": [
        "Sina Ehsani",
        "Fenglian Pan",
        "Qingpei Hu and Jian Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T19:59:59+00:00",
          "link": "https://arxiv.org/abs/2501.08411v1",
          "size": "1763kb",
          "version": "v1"
        },
        {
          "date": "2025-02-06T04:35:56+00:00",
          "link": "https://arxiv.org/abs/2501.08411v2",
          "size": "1763kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T16:54:38+00:00",
          "link": "https://arxiv.org/abs/2501.08411v3",
          "size": "1622kb",
          "version": "v3"
        }
      ],
      "title": "BiDepth: A Bidirectional-Depth Neural Network for Spatio-Temporal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08411",
        "HTML": "https://arxiv.org/html/2501.08411v3",
        "PDF": "https://arxiv.org/pdf/2501.08411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research deals with a new neural network architecture for spatio-temporal prediction without addressing training data processing or dataset creation."
      },
      "tasks": [
        "Precipitation Forecasting",
        "Prediction",
        "Traffic Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19066",
      "abstract": "Despite the remarkable progress in text-to-image generative models, they are prone to adversarial attacks and inadvertently generate unsafe, unethical content. Existing approaches often rely on fine-tuning models to remove specific concepts, which is computationally expensive, lacks scalability, and/or compromises generation quality. In this work, we propose a novel framework leveraging k-sparse autoencoders (k-SAEs) to enable efficient and interpretable concept manipulation in diffusion models. Specifically, we first identify interpretable monosemantic concepts in the latent space of text embeddings and leverage them to precisely steer the generation away or towards a given concept (e.g., nudity) or to introduce a new concept (e.g., photographic style) -- all during test time. Through extensive experiments, we demonstrate that our approach is very simple, requires no retraining of the base model nor LoRA adapters, does not compromise the generation quality, and is robust to adversarial prompt manipulations. Our method yields an improvement of $\\mathbf{20.01\\%}$ in unsafe concept removal, is effective in style manipulation, and is $\\mathbf{\\sim5}$x faster than the current state-of-the-art. Code is available at: https://github.com/kim-dahye/steerers",
      "authors": [
        "Dahye Kim and Deepti Ghadiyaram"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T11:52:47+00:00",
          "link": "https://arxiv.org/abs/2501.19066v1",
          "size": "29084kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T00:37:55+00:00",
          "link": "https://arxiv.org/abs/2501.19066v2",
          "size": "14809kb",
          "version": "v2"
        }
      ],
      "title": "Concept Steerers: Leveraging K-Sparse Autoencoders for Test-Time Controllable Generations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19066",
        "HTML": "https://arxiv.org/html/2501.19066v2",
        "PDF": "https://arxiv.org/pdf/2501.19066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for concept manipulation in generative models, which is related to model use rather than LLM training data processing or dataset creation."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/kim-dahye/steerers"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08900",
      "abstract": "The behavior of one-dimensional Hegselmann-Krause (HK) dynamics driven by noise has been extensively studied. Previous research has indicated that within no matter the bounded or the unbounded space of one dimension, the HK dynamics attain quasi-synchronization (synchronization in noisy case) in finite time. However, it remains unclear whether this phenomenon holds in high-dimensional space. This paper investigates the random time for quasi-synchronization of multi-dimensional HK model and reveals that the boundedness and dimensions of the space determine different outcomes. To be specific, if the space is bounded, quasi-synchronization can be attained almost surely for all dimensions within a finite time, whereas in unbounded space, quasi-synchronization can only be achieved in low-dimensional cases (one and two). Furthermore, different integrability of the random time of various cases is proved.",
      "authors": [
        "Wei Su",
        "Meiru Jiang",
        "Yongguang Yu",
        "Ge Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Multiagent Systems (cs.MA)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:57:07+00:00",
          "link": "https://arxiv.org/abs/2507.08900v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Properties of Quasi-synchronization Time of High-dimensional Hegselmann-Krause Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08900",
        "HTML": "https://arxiv.org/html/2507.08900v1",
        "PDF": "https://arxiv.org/pdf/2507.08900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the quasi-synchronization time of high-dimensional Hegselmann-Krause dynamics and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09562",
      "abstract": "The Segment Anything Model (SAM) has revolutionized image segmentation through its innovative prompt-based approach, yet the critical role of prompt engineering in its success remains underexplored. This paper presents the first comprehensive survey focusing specifically on prompt engineering techniques for SAM and its variants. We systematically organize and analyze the rapidly growing body of work in this emerging field, covering fundamental methodologies, practical applications, and key challenges. Our review reveals how prompt engineering has evolved from simple geometric inputs to sophisticated multimodal approaches, enabling SAM's adaptation across diverse domains including medical imaging and remote sensing. We identify unique challenges in prompt optimization and discuss promising research directions. This survey fills an important gap in the literature by providing a structured framework for understanding and advancing prompt engineering in foundation models for segmentation.",
      "authors": [
        "Yidong Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:10:17+00:00",
          "link": "https://arxiv.org/abs/2507.09562v1",
          "size": "1676kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Engineering in Segment Anything Model: Methodologies, Applications, and Emerging Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09562",
        "HTML": "https://arxiv.org/html/2507.09562v1",
        "PDF": "https://arxiv.org/pdf/2507.09562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys prompt engineering techniques for image segmentation models, not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09747",
      "abstract": "Understanding how the brain represents visual information is a fundamental challenge in neuroscience and artificial intelligence. While AI-driven decoding of neural data has provided insights into the human visual system, integrating multimodal neuroimaging signals, such as EEG, MEG, and fMRI, remains a critical hurdle due to their inherent spatiotemporal misalignment. Current approaches often analyze these modalities in isolation, limiting a holistic view of neural representation. In this study, we introduce BrainFLORA, a unified framework for integrating cross-modal neuroimaging data to construct a shared neural representation. Our approach leverages multimodal large language models (MLLMs) augmented with modality-specific adapters and task decoders, achieving state-of-the-art performance in joint-subject visual retrieval task and has the potential to extend multitasking. Combining neuroimaging analysis methods, we further reveal how visual concept representations align across neural modalities and with real world object perception. We demonstrate that the brain's structured visual concept representations exhibit an implicit mapping to physical-world stimuli, bridging neuroscience and machine learning from different modalities of neural imaging. Beyond methodological advancements, BrainFLORA offers novel implications for cognitive neuroscience and brain-computer interfaces (BCIs). Our code is available at https://github.com/ncclab-sustech/BrainFLORA.",
      "authors": [
        "Dongyang Li",
        "Haoyang Qin",
        "Mingyang Wu",
        "Chen Wei",
        "Quanying Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:56:17+00:00",
          "link": "https://arxiv.org/abs/2507.09747v1",
          "size": "5620kb",
          "version": "v1"
        }
      ],
      "title": "BrainFLORA: Uncovering Brain Concept Representation via Multimodal Neural Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09747",
        "HTML": "https://arxiv.org/html/2507.09747v1",
        "PDF": "https://arxiv.org/pdf/2507.09747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating multimodal neuroimaging data and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10310",
      "abstract": "In practice, navigation of mobile robots in confined environments is often done using a spatially discrete cost-map to represent obstacles. Path following is a typical use case for model predictive control (MPC), but formulating constraints for obstacle avoidance is challenging in this case. Typically the cost and constraints of an MPC problem are defined as closed-form functions and typical solvers work best with continuously differentiable functions. This is contrary to spatially discrete occupancy grid maps, in which a grid's value defines the cost associated with occupancy. This paper presents a way to overcome this compatibility issue by re-formulating occupancy grid maps to continuously differentiable functions to be embedded into the MPC scheme as constraints. Each obstacle is defined as a polygon -- an intersection of half-spaces. Any half-space is a linear inequality representing one edge of a polygon. Using AND and OR operators, the combined set of all obstacles and therefore the obstacle avoidance constraints can be described. The key contribution of this paper is the use of fuzzy logic to re-formulate such constraints that include logical operators as inequality constraints which are compatible with standard MPC formulation. The resulting MPC-based trajectory planner is successfully tested in simulation. This concept is also applicable outside of navigation tasks to implement logical or verbal constraints in MPC.",
      "authors": [
        "Michael Schr\\\"oder",
        "Eric Sch\\\"oneberg",
        "Daniel G\\\"orges and Hans D. Schotten"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:14:39+00:00",
          "link": "https://arxiv.org/abs/2507.10310v1",
          "size": "656kb",
          "version": "v1"
        }
      ],
      "title": "Polygonal Obstacle Avoidance Combining Model Predictive Control and Fuzzy Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10310",
        "PDF": "https://arxiv.org/pdf/2507.10310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses path planning for mobile robots using model predictive control and fuzzy logic, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10330",
      "abstract": "Despite advancements in Natural Language Processing (NLP), models remain vulnerable to adversarial attacks, such as synonym substitutions. While prior work has focused on improving robustness for feed-forward and convolutional architectures, the robustness of recurrent networks and modern state space models (SSMs), such as S4, remains understudied. These architectures pose unique challenges due to their sequential processing and complex parameter dynamics. In this paper, we introduce a novel regularization technique based on Growth Bound Matrices (GBM) to improve NLP model robustness by reducing the impact of input perturbations on model outputs. We focus on computing the GBM for three architectures: Long Short-Term Memory (LSTM), State Space models (S4), and Convolutional Neural Networks (CNN). Our method aims to (1) enhance resilience against word substitution attacks, (2) improve generalization on clean text, and (3) providing the first systematic analysis of SSM (S4) robustness. Extensive experiments across multiple architectures and benchmark datasets demonstrate that our method improves adversarial robustness by up to 8.8% over existing baselines. These results highlight the effectiveness of our approach, outperforming several state-of-the-art methods in adversarial defense. Codes are available at https://github.com/BouriMohammed/GBM",
      "authors": [
        "Mohammed Bouri",
        "and Adnane Saoud"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:38:48+00:00",
          "link": "https://arxiv.org/abs/2507.10330v1",
          "size": "2839kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10330",
        "HTML": "https://arxiv.org/html/2507.10330v1",
        "PDF": "https://arxiv.org/pdf/2507.10330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates model robustness against adversarial attacks, not the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.11044",
      "abstract": "Data mining, particularly the analysis of multivariate time series data, plays a crucial role in extracting insights from complex systems and supporting informed decision-making across diverse domains. However, assessing the similarity of multivariate time series data presents several challenges, including dealing with large datasets, addressing temporal misalignments, and the need for efficient and comprehensive analytical frameworks. To address all these challenges, we propose a novel integrated computational approach known as Multivariate Time series Alignment and Similarity Assessment (MTASA). MTASA is built upon a hybrid methodology designed to optimize time series alignment, complemented by a multiprocessing engine that enhances the utilization of computational resources. This integrated approach comprises four key components, each addressing essential aspects of time series similarity assessment, thereby offering a comprehensive framework for analysis. MTASA is implemented as an open-source Python library with a user-friendly interface, making it accessible to researchers and practitioners. To evaluate the effectiveness of MTASA, we conducted an empirical study focused on assessing agroecosystem similarity using real-world environmental data. The results from this study highlight MTASA's superiority, achieving approximately 1.5 times greater accuracy and twice the speed compared to existing state-of-the-art integrated frameworks for multivariate time series similarity assessment. It is hoped that MTASA will significantly enhance the efficiency and accessibility of multivariate time series analysis, benefitting researchers and practitioners across various domains. Its capabilities in handling large datasets, addressing temporal misalignments, and delivering accurate results make MTASA a valuable tool for deriving insights and aiding decision-making processes in complex systems.",
      "authors": [
        "Franck Tonle",
        "Henri Tonnang",
        "Milliam Ndadji",
        "Maurice Tchendji",
        "Armand Nzeukou",
        "Kennedy Senagi",
        "Saliou Niassy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-16T23:52:25+00:00",
          "link": "https://arxiv.org/abs/2403.11044v1",
          "size": "939kb",
          "version": "v1"
        }
      ],
      "title": "Advancing multivariate time series similarity assessment: an integrated computational approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.11044",
        "HTML": "https://arxiv.org/html/2403.11044",
        "PDF": "https://arxiv.org/pdf/2403.11044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a computational approach for assessing multivariate time series similarity, which is unrelated to LLM training data processing or significant improvements in LLM-specific data quality."
      },
      "tasks": [
        "Decision Making",
        "Time Series",
        "Time Series Alignment",
        "Time Series Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.16506",
      "abstract": "Naive Retrieval-Augmented Generation (RAG) focuses on individual documents during retrieval and, as a result, falls short in handling networked documents which are very popular in many applications such as citation graphs, social media, and knowledge graphs. To overcome this limitation, we introduce Graph Retrieval-Augmented Generation (GRAG), which tackles the fundamental challenges in retrieving textual subgraphs and integrating the joint textual and topological information into Large Language Models (LLMs) to enhance its generation. To enable efficient textual subgraph retrieval, we propose a novel divide-and-conquer strategy that retrieves the optimal subgraph structure in linear time. To achieve graph context-aware generation, incorporate textual graphs into LLMs through two complementary views-the text view and the graph view-enabling LLMs to more effectively comprehend and utilize the graph context. Extensive experiments on graph reasoning benchmarks demonstrate that in scenarios requiring multi-hop reasoning on textual graphs, our GRAG approach significantly outperforms current state-of-the-art RAG methods. Our datasets as well as codes of GRAG are available at https://github.com/HuieL/GRAG.",
      "authors": [
        "Yuntong Hu",
        "Zhihan Lei",
        "Zheng Zhang",
        "Bo Pan",
        "Chen Ling",
        "Liang Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-26T10:11:40+00:00",
          "link": "https://arxiv.org/abs/2405.16506v1",
          "size": "7519kb",
          "version": "v1"
        },
        {
          "date": "2024-10-21T00:55:13+00:00",
          "link": "https://arxiv.org/abs/2405.16506v2",
          "size": "2692kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T11:09:06+00:00",
          "link": "https://arxiv.org/abs/2405.16506v3",
          "size": "660kb",
          "version": "v3"
        }
      ],
      "title": "GRAG: Graph Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.16506",
        "HTML": "https://arxiv.org/html/2405.16506v3",
        "PDF": "https://arxiv.org/pdf/2405.16506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a new method for enhancing LLMs using Graph Retrieval-Augmented Generation, which involves processing networked documents for better data utilization."
      },
      "tasks": [
        "Entity Retrieval",
        "Knowledge Graphs",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/pengboci/graphrag-survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02361",
      "abstract": "We introduce MG-Gen, a framework that generates motion graphics directly from a single raster image. MG-Gen decompose a single raster image into layered structures represented as HTML, generate animation scripts for each layer, and then render them into a video. Experiments confirm MG-Gen generates dynamic motion graphics while preserving text readability and fidelity to the input conditions, whereas state-of-the-art image-to-video generation methods struggle with them. The code is available at https://github.com/CyberAgentAILab/MG-GEN.",
      "authors": [
        "Takahiro Shirakawa",
        "Tomoyuki Suzuki",
        "Takuto Narumoto",
        "Daichi Haraguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T07:52:12+00:00",
          "link": "https://arxiv.org/abs/2504.02361v1",
          "size": "11371kb",
          "version": "v1"
        },
        {
          "date": "2025-04-04T01:21:39+00:00",
          "link": "https://arxiv.org/abs/2504.02361v2",
          "size": "11371kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T05:22:55+00:00",
          "link": "https://arxiv.org/abs/2504.02361v3",
          "size": "10040kb",
          "version": "v3"
        }
      ],
      "title": "MG-Gen: Single Image to Motion Graphics Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02361",
        "HTML": "https://arxiv.org/html/2504.02361v3",
        "PDF": "https://arxiv.org/pdf/2504.02361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating motion graphics from images and does not address LLM training data processing, collection, or engineering."
      },
      "tasks": [
        "Code Generation",
        "Image to Video Generation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.07449",
      "abstract": "In ophthalmic surgery, developing an AI system capable of interpreting surgical videos and predicting subsequent operations requires numerous ophthalmic surgical videos with high-quality annotations, which are difficult to collect due to privacy concerns and labor consumption. Text-guided video generation (T2V) emerges as a promising solution to overcome this issue by generating ophthalmic surgical videos based on surgeon instructions. In this paper, we present Ophora, a pioneering model that can generate ophthalmic surgical videos following natural language instructions. To construct Ophora, we first propose a Comprehensive Data Curation pipeline to convert narrative ophthalmic surgical videos into a large-scale, high-quality dataset comprising over 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive Video-Instruction Tuning scheme to transfer rich spatial-temporal knowledge from a T2V model pre-trained on natural video-text datasets for privacy-preserved ophthalmic surgical video generation based on Ophora-160K. Experiments on video quality evaluation via quantitative analysis and ophthalmologist feedback demonstrate that Ophora can generate realistic and reliable ophthalmic surgical videos based on surgeon instructions. We also validate the capability of Ophora for empowering downstream tasks of ophthalmic surgical workflow understanding. Code is available at https://github.com/uni-medical/Ophora.",
      "authors": [
        "Wei Li",
        "Ming Hu",
        "Guoan Wang",
        "Lihao Liu",
        "Kaijing Zhou",
        "Junzhi Ning",
        "Xin Guo",
        "Zongyuan Ge",
        "Lixu Gu",
        "Junjun He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T11:23:37+00:00",
          "link": "https://arxiv.org/abs/2505.07449v1",
          "size": "2243kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T05:39:25+00:00",
          "link": "https://arxiv.org/abs/2505.07449v2",
          "size": "2243kb",
          "version": "v2"
        },
        {
          "date": "2025-05-16T08:47:49+00:00",
          "link": "https://arxiv.org/abs/2505.07449v3",
          "size": "2245kb",
          "version": "v3"
        },
        {
          "date": "2025-06-06T04:36:26+00:00",
          "link": "https://arxiv.org/abs/2505.07449v4",
          "size": "2243kb",
          "version": "v4"
        },
        {
          "date": "2025-06-18T11:40:27+00:00",
          "link": "https://arxiv.org/abs/2505.07449v5",
          "size": "2239kb",
          "version": "v5"
        },
        {
          "date": "2025-06-26T05:57:03+00:00",
          "link": "https://arxiv.org/abs/2505.07449v6",
          "size": "2241kb",
          "version": "v6"
        },
        {
          "date": "2025-07-12T08:58:10+00:00",
          "link": "https://arxiv.org/abs/2505.07449v7",
          "size": "2242kb",
          "version": "v7"
        }
      ],
      "title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07449",
        "HTML": "https://arxiv.org/html/2505.07449",
        "PDF": "https://arxiv.org/pdf/2505.07449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution by presenting a Comprehensive Data Curation pipeline to convert videos into a dataset with detailed data processing steps, significantly contributing to data processing for model training."
      },
      "models": [
        {
          "model_path": "General-Medical-AI/Ophora",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/General-Medical-AI/Ophora"
        }
      ],
      "tasks": [
        "Video Generation"
      ],
      "repo_urls": [
        "https://github.com/mar-cry/ophora"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07855",
      "abstract": "In this paper, we show that direct preference optimization (DPO) is a very specific form of a connection between two major theories in the ML context of learning from preferences: loss functions (Savage) and stochastic choice (Doignon-Falmagne and Machina). The connection is established for all of Savage's losses and at this level of generality, (i) it includes support for abstention on the choice theory side, (ii) it includes support for non-convex objectives on the ML side, and (iii) it allows to frame for free some notable extensions of the DPO setting, including margins and corrections for length. Getting to understand how DPO operates from a general principled perspective is crucial because of the huge and diverse application landscape of models, because of the current momentum around DPO, but also -- and importantly -- because many state of the art variations on DPO definitely occupy a small region of the map that we cover. It also helps to understand the pitfalls of departing from this map, and figure out workarounds.",
      "authors": [
        "Wenxuan Zhou",
        "Shujian Zhang",
        "Brice Magdalou",
        "John Lambert",
        "Ehsan Amid",
        "Richard Nock",
        "Andrew Hard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:38:17+00:00",
          "link": "https://arxiv.org/abs/2507.07855v1",
          "size": "328kb",
          "version": "v1"
        }
      ],
      "title": "Principled Foundations for Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07855",
        "HTML": "https://arxiv.org/html/2507.07855",
        "PDF": "https://arxiv.org/pdf/2507.07855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses preference optimization theories in ML without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08922",
      "abstract": "Continual learning is an online paradigm where a learner continually accumulates knowledge from different tasks encountered over sequential time steps. Importantly, the learner is required to extend and update its knowledge without forgetting about the learning experience acquired from the past, and while avoiding the need to retrain from scratch. Given its sequential nature and its resemblance to the way humans think, continual learning offers an opportunity to address several challenges which currently stand in the way of widening the range of applicability of deep models to further real-world problems. The continual need to update the learner with data arriving sequentially strikes inherent congruence between continual learning and Bayesian inference which provides a principal platform to keep updating the prior beliefs of a model given new data, without completely forgetting the knowledge acquired from the old data. This survey inspects different settings of Bayesian continual learning, namely task-incremental learning and class-incremental learning. We begin by discussing definitions of continual learning along with its Bayesian setting, as well as the links with related fields, such as domain adaptation, transfer learning and meta-learning. Afterwards, we introduce a taxonomy offering a comprehensive categorization of algorithms belonging to the Bayesian continual learning paradigm. Meanwhile, we analyze the state-of-the-art while zooming in on some of the most prominent Bayesian continual learning algorithms to date. Furthermore, we shed some light on links between continual learning and developmental psychology, and correspondingly introduce analogies between both fields. We follow that with a discussion of current challenges, and finally conclude with potential areas for future research on Bayesian continual learning.",
      "authors": [
        "Tameem Adel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:16:13+00:00",
          "link": "https://arxiv.org/abs/2507.08922v1",
          "size": "13663kb",
          "version": "v1"
        }
      ],
      "title": "The Bayesian Approach to Continual Learning: An Overview",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08922",
        "PDF": "https://arxiv.org/pdf/2507.08922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Bayesian continual learning methods and their application to tasks and knowledge updating, with no discussion on LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09371",
      "abstract": "Learning from demonstration has proven effective in robotics for acquiring natural behaviors, such as stylistic motions and lifelike agility, particularly when explicitly defining style-oriented reward functions is challenging. Synthesizing stylistic motions for real-world tasks usually requires balancing task performance and imitation quality. Existing methods generally depend on expert demonstrations closely aligned with task objectives. However, practical demonstrations are often incomplete or unrealistic, causing current methods to boost style at the expense of task performance. To address this issue, we propose formulating the problem as a constrained Markov Decision Process (CMDP). Specifically, we optimize a style-imitation objective with constraints to maintain near-optimal task performance. We introduce an adaptively adjustable Lagrangian multiplier to guide the agent to imitate demonstrations selectively, capturing stylistic nuances without compromising task performance. We validate our approach across multiple robotic platforms and tasks, demonstrating both robust task performance and high-fidelity style learning. On ANYmal-D hardware we show a 14.5% drop in mechanical energy and a more agile gait pattern, showcasing real-world benefits.",
      "authors": [
        "Kehan Wen",
        "Chenhao Li",
        "Junzhe He",
        "Marco Hutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:35:41+00:00",
          "link": "https://arxiv.org/abs/2507.09371v1",
          "size": "7092kb",
          "version": "v1"
        }
      ],
      "title": "Constrained Style Learning from Imperfect Demonstrations under Task Optimality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09371",
        "HTML": "https://arxiv.org/html/2507.09371v1",
        "PDF": "https://arxiv.org/pdf/2507.09371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses constrained style learning from imperfect demonstrations in robotics, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.09391",
      "abstract": "Quantum Error Correction (QEC) is the cornerstone of practical Fault-Tolerant Quantum Computing (FTQC), but incurs enormous resource overheads. Circuits must decompose into Clifford+T gates, and the non-transversal T gates demand costly magic-state distillation. As circuit complexity grows, sequential T-gate layers (\"T-depth\") increase, amplifying the spatiotemporal overhead of QEC. Optimizing T-depth is NP-hard, and existing greedy or brute-force strategies are either inefficient or computationally prohibitive. We frame T-depth reduction as a search optimization problem and present a Genetic Algorithm (GA) framework that approximates optimal layer-merge patterns across the non-convex search space. We introduce a mathematical formulation of the circuit expansion for systematic layer reordering and a greedy initial merge-pair selection, accelerating the convergence and enhancing the solution quality. In our benchmark with ~90-100 qubits, our method reduces T-depth by 79.23% and overall T-count by 41.86%. Compared to the reversible circuit benchmarks, we achieve a 2.58x improvement in T-depth over the state-of-the-art methods, demonstrating its viability for near-term FTQC.",
      "authors": [
        "Archisman Ghosh",
        "Avimita Chatterjee",
        "Swaroop Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Hardware Architecture (cs.AR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-13T00:55:18+00:00",
          "link": "https://arxiv.org/abs/2504.09391v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T20:35:10+00:00",
          "link": "https://arxiv.org/abs/2504.09391v2",
          "size": "358kb",
          "version": "v2"
        }
      ],
      "title": "Survival of the Optimized: An Evolutionary Approach to T-depth Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09391",
        "HTML": "https://arxiv.org/html/2504.09391v2",
        "PDF": "https://arxiv.org/pdf/2504.09391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Quantum Error Correction and optimization techniques for T-depth reduction in quantum circuits, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09299",
      "abstract": "The remarkable representational power of Vision Transformers (ViTs) remains underutilized in few-shot image classification. In this work, we introduce ViT-ProtoNet, which integrates a ViT-Small backbone into the Prototypical Network framework. By averaging class conditional token embeddings from a handful of support examples, ViT-ProtoNet constructs robust prototypes that generalize to novel categories under 5-shot settings. We conduct an extensive empirical evaluation on four standard benchmarks: Mini-ImageNet, FC100, CUB-200, and CIFAR-FS, including overlapped support variants to assess robustness. Across all splits, ViT-ProtoNet consistently outperforms CNN-based prototypical counterparts, achieving up to a 3.2\\% improvement in 5-shot accuracy and demonstrating superior feature separability in latent space. Furthermore, it outperforms or is competitive with transformer-based competitors using a more lightweight backbone. Comprehensive ablations examine the impact of transformer depth, patch size, and fine-tuning strategy. To foster reproducibility, we release code and pretrained weights. Our results establish ViT-ProtoNet as a powerful, flexible approach for few-shot classification and set a new baseline for transformer-based meta-learners.",
      "authors": [
        "Abdulvahap Mutlu",
        "\\c{S}eng\\\"ul Do\\u{g}an",
        "T\\\"urker Tuncer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:19:04+00:00",
          "link": "https://arxiv.org/abs/2507.09299v1",
          "size": "1550kb",
          "version": "v1"
        }
      ],
      "title": "ViT-ProtoNet for Few-Shot Image Classification: A Multi-Benchmark Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09299",
        "PDF": "https://arxiv.org/pdf/2507.09299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model based on Vision Transformers for few-shot image classification; it does not address processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.20279",
      "abstract": "Neural Architecture Search (NAS) methods have been shown to outperform hand-designed models and help to democratize AI. However, NAS methods often start from scratch with each new task, making them computationally expensive and limiting their applicability. Transfer learning is a practical alternative with the rise of ever-larger pretrained models. However, it is also bound to the architecture of the pretrained model, which inhibits proper adaptation of the architecture to different tasks, leading to suboptimal (and excessively large) models. We address both challenges at once by introducing a novel and practical method to \\textit{transfer supernets}, which parameterize both weight and architecture priors, and efficiently finetune both to new tasks. This enables supernet transfer learning as a replacement for traditional transfer learning that also finetunes model architectures to new tasks. Through extensive experiments across multiple image classification tasks, we demonstrate that supernet transfer learning does not only drastically speed up the discovery of optimal models (3 to 5 times faster on average), but will also find better models than running NAS from scratch. The added model flexibility also increases the robustness of transfer learning, yielding positive transfer to even very different target datasets, especially with multi-dataset pretraining.",
      "authors": [
        "Prabhant Singh",
        "Joaquin Vanschoren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-26T00:17:57+00:00",
          "link": "https://arxiv.org/abs/2407.20279v1",
          "size": "1122kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T21:55:00+00:00",
          "link": "https://arxiv.org/abs/2407.20279v2",
          "size": "2373kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T22:57:05+00:00",
          "link": "https://arxiv.org/abs/2407.20279v3",
          "size": "3093kb",
          "version": "v3"
        }
      ],
      "title": "On Supernet Transfer Learning for Effective Task Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20279",
        "HTML": "https://arxiv.org/html/2407.20279v3",
        "PDF": "https://arxiv.org/pdf/2407.20279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work centers on improving task adaptation via transfer learning in neural networks, without contributions toward LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.14035",
      "abstract": "Heterogeneous Graph Neural Networks (HGNNs) have achieved promising results in various heterogeneous graph learning tasks, owing to their superiority in capturing the intricate relationships and diverse relational semantics inherent in heterogeneous graph structures. However, the neighborhood-fetching latency incurred by structure dependency in HGNNs makes it challenging to deploy for latency-constrained applications that require fast inference. Inspired by recent GNN-to-MLP knowledge distillation frameworks, we introduce HG2M and HG2M+ to combine both HGNN's superior performance and MLP's efficient inference. HG2M directly trains student MLPs with node features as input and soft labels from teacher HGNNs as targets, and HG2M+ further distills reliable and heterogeneous semantic knowledge into student MLPs through reliable node distillation and reliable meta-path distillation. Experiments conducted on six heterogeneous graph datasets show that despite lacking structural dependencies, HG2Ms can still achieve competitive or even better performance than HGNNs and significantly outperform vanilla MLPs. Moreover, HG2Ms demonstrate a 379.24$\\times$ speedup in inference over HGNNs on the large-scale IGB-3M-19 dataset, showcasing their ability for latency-sensitive deployments.",
      "authors": [
        "Yunhui Liu",
        "Xinyi Gao",
        "Tieke He",
        "Jianhua Zhao",
        "Hongzhi Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T11:39:09+00:00",
          "link": "https://arxiv.org/abs/2411.14035v1",
          "size": "219kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T03:41:27+00:00",
          "link": "https://arxiv.org/abs/2411.14035v2",
          "size": "225kb",
          "version": "v2"
        }
      ],
      "title": "Teaching MLPs to Master Heterogeneous Graph-Structured Knowledge for Efficient and Accurate Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14035",
        "HTML": "https://arxiv.org/html/2411.14035v2",
        "PDF": "https://arxiv.org/pdf/2411.14035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about heterogeneous graph neural networks and knowledge distillation to improve inference, without any focus on LLM training data processing."
      },
      "tasks": [
        "Graph Learning",
        "Knowledge Distillation"
      ],
      "repo_urls": [
        "https://github.com/cloudy1225/hg2m"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08560",
      "abstract": "The growing availability of longitudinal Magnetic Resonance Imaging (MRI) datasets has facilitated Artificial Intelligence (AI)-driven modeling of disease progression, making it possible to predict future medical scans for individual patients. However, despite significant advancements in AI, current methods continue to face challenges including achieving patient-specific individualization, ensuring spatiotemporal consistency, efficiently utilizing longitudinal data, and managing the substantial memory demands of 3D scans. To address these challenges, we propose Brain Latent Progression (BrLP), a novel spatiotemporal model designed to predict individual-level disease progression in 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates in a small latent space, mitigating the computational challenges posed by high-dimensional imaging data; (ii) it explicitly integrates subject metadata to enhance the individualization of predictions; (iii) it incorporates prior knowledge of disease dynamics through an auxiliary model, facilitating the integration of longitudinal data; and (iv) it introduces the Latent Average Stabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in the predicted progression at inference time and (b) allows us to derive a measure of the uncertainty for the prediction at the global and voxel level. We train and evaluate BrLP on 11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its generalizability on an external test set comprising 2,257 MRIs from 962 subjects. Our experiments compare BrLP-generated MRI scans with real follow-up MRIs, demonstrating state-of-the-art accuracy compared to existing methods. The code is publicly available at: https://github.com/LemuelPuglisi/BrLP.",
      "authors": [
        "Lemuel Puglisi",
        "Daniel C. Alexander",
        "Daniele Rav\\`i"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T16:47:41+00:00",
          "link": "https://arxiv.org/abs/2502.08560v1",
          "size": "1816kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:14:03+00:00",
          "link": "https://arxiv.org/abs/2502.08560v2",
          "size": "2250kb",
          "version": "v2"
        }
      ],
      "title": "Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08560",
        "HTML": "https://arxiv.org/html/2502.08560v2",
        "PDF": "https://arxiv.org/pdf/2502.08560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with disease progression modeling on brain MRIs and does not pertain to LLM training data processing or dataset engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/lemuelpuglisi/brlp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08161",
      "abstract": "In the traditional view of reinforcement learning, the agent's goal is to find an optimal policy that maximizes its expected sum of rewards. Once the agent finds this policy, the learning ends. This view contrasts with \\emph{continual reinforcement learning}, where learning does not end, and agents are expected to continually learn and adapt indefinitely. Despite the clear distinction between these two paradigms of learning, much of the progress in continual reinforcement learning has been shaped by foundations rooted in the traditional view of reinforcement learning. In this paper, we first examine whether the foundations of traditional reinforcement learning are suitable for the continual reinforcement learning paradigm. We identify four key pillars of the traditional reinforcement learning foundations that are antithetical to the goals of continual learning: the Markov decision process formalism, the focus on atemporal artifacts, the expected sum of rewards as an evaluation metric, and episodic benchmark environments that embrace the other three foundations. We then propose a new formalism that sheds the first and the third foundations and replaces them with the history process as a mathematical formalism and a new definition of deviation regret, adapted for continual learning, as an evaluation metric. Finally, we discuss possible approaches to shed the other two foundations.",
      "authors": [
        "Michael Bowling",
        "Esraa Elelimy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T23:05:56+00:00",
          "link": "https://arxiv.org/abs/2504.08161v1",
          "size": "28kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:21:37+00:00",
          "link": "https://arxiv.org/abs/2504.08161v2",
          "size": "125kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking the Foundations for Continual Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08161",
        "HTML": "https://arxiv.org/html/2504.08161v2",
        "PDF": "https://arxiv.org/pdf/2504.08161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses foundational changes in continual reinforcement learning and proposes new learning paradigms, without focusing on LLM training data processing."
      },
      "tasks": [
        "Continual Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01393",
      "abstract": "This paper addresses the Bayesian optimization problem (also referred to as the Bayesian setting of the Gaussian process bandit), where the learner seeks to minimize the regret under a function drawn from a known Gaussian process (GP). Under a Mat\\'ern kernel with a certain degree of smoothness, we show that the Gaussian process upper confidence bound (GP-UCB) algorithm achieves $\\tilde{O}(\\sqrt{T})$ cumulative regret with high probability. Furthermore, our analysis yields $O(\\sqrt{T \\ln^2 T})$ regret under a squared exponential kernel. These results fill the gap between the existing regret upper bound for GP-UCB and the best-known bound provided by Scarlett (2018). The key idea in our proof is to capture the concentration behavior of the input sequence realized by GP-UCB, enabling a more refined analysis of the GP's information gain.",
      "authors": [
        "Shogo Iwazaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T07:38:58+00:00",
          "link": "https://arxiv.org/abs/2506.01393v1",
          "size": "75kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T05:03:05+00:00",
          "link": "https://arxiv.org/abs/2506.01393v2",
          "size": "76kb",
          "version": "v2"
        }
      ],
      "title": "Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01393",
        "HTML": "https://arxiv.org/html/2506.01393v2",
        "PDF": "https://arxiv.org/pdf/2506.01393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving regret bounds in Bayesian optimization and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06507",
      "abstract": "In the past year, Generative Recommendations (GRs) have undergone substantial advancements, especially in leveraging the powerful sequence modeling and reasoning capabilities of Large Language Models (LLMs) to enhance overall recommendation performance. LLM-based GRs are forming a new paradigm that is distinctly different from discriminative recommendations, showing strong potential to replace traditional recommendation systems heavily dependent on complex hand-crafted features. In this paper, we provide a comprehensive survey aimed at facilitating further research of LLM-based GRs. Initially, we outline the general preliminaries and application cases of LLM-based GRs. Subsequently, we introduce the main considerations when LLM-based GRs are applied in real industrial scenarios. Finally, we explore promising directions for LLM-based GRs. We hope that this survey contributes to the ongoing advancement of the GR domain.",
      "authors": [
        "Zhen Yang",
        "Haitao Lin",
        "Jiawei xue",
        "Ziji Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:13:08+00:00",
          "link": "https://arxiv.org/abs/2507.06507v1",
          "size": "57kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:46:11+00:00",
          "link": "https://arxiv.org/abs/2507.06507v2",
          "size": "58kb",
          "version": "v2"
        }
      ],
      "title": "GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06507",
        "HTML": "https://arxiv.org/html/2507.06507v2",
        "PDF": "https://arxiv.org/pdf/2507.06507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey paper discusses advancements in generative recommendations using LLMs but does not make any contributions related to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09139",
      "abstract": "Human pose estimation traditionally relies on architectures that encode keypoint priors, limiting their generalization to novel poses or unseen keypoints. Recent language-guided approaches like LocLLM reformulate keypoint localization as a vision-language task, enabling zero-shot generalization through textual descriptions. However, LocLLM's linear projector fails to capture complex spatial-textual interactions critical for high-precision localization. To address this, we propose PoseLLM, the first Large Language Model (LLM)-based pose estimation framework that replaces the linear projector with a nonlinear MLP vision-language connector. This lightweight two-layer MLP with GELU activation enables hierarchical cross-modal feature transformation, enhancing the fusion of visual patches and textual keypoint descriptions. Trained exclusively on COCO data, PoseLLM achieves 77.8 AP on the COCO validation set, outperforming LocLLM by +0.4 AP, while maintaining strong zero-shot generalization on Human-Art and MPII. Our work demonstrates that a simple yet powerful nonlinear connector significantly boosts localization accuracy without sacrificing generalization, advancing the state-of-the-art in language-guided pose estimation. Code is available at https://github.com/Ody-trek/PoseLLM.",
      "authors": [
        "Dewen Zhang",
        "Tahir Hussain",
        "Wangpeng An",
        "Hayaru Shouno"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:53:39+00:00",
          "link": "https://arxiv.org/abs/2507.09139v1",
          "size": "735kb",
          "version": "v1"
        }
      ],
      "title": "PoseLLM: Enhancing Language-Guided Human Pose Estimation with MLP Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09139",
        "HTML": "https://arxiv.org/html/2507.09139v1",
        "PDF": "https://arxiv.org/pdf/2507.09139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing language-guided human pose estimation through a novel nonlinear MLP connector and does not discuss any LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09375",
      "abstract": "Crop diseases present a significant barrier to agricultural productivity and global food security, especially in large-scale farming where early identification is often delayed or inaccurate. This research introduces a Convolutional Neural Network (CNN)-based image classification system designed to automate the detection and classification of eight common crop diseases using leaf imagery. The methodology involves a complete deep learning pipeline: image acquisition from a large, labeled dataset, preprocessing via resizing, normalization, and augmentation, and model training using TensorFlow with Keras' Sequential API. The CNN architecture comprises three convolutional layers with increasing filter sizes and ReLU activations, followed by max pooling, flattening, and fully connected layers, concluding with a softmax output for multi-class classification. The system achieves high training accuracy (~90%) and demonstrates reliable performance on unseen data, although a validation accuracy of ~60% suggests minor overfitting. Notably, the model integrates a treatment recommendation module, providing actionable guidance by mapping each detected disease to suitable pesticide or fungicide interventions. Furthermore, the solution is deployed on an open-source, mobile-compatible platform, enabling real-time image-based diagnostics for farmers in remote areas. This research contributes a scalable and accessible tool to the field of precision agriculture, reducing reliance on manual inspection and promoting sustainable disease management practices. By merging deep learning with practical agronomic support, this work underscores the potential of CNNs to transform crop health monitoring and enhance food production resilience on a global scale.",
      "authors": [
        "Sourish Suri (University of California",
        "San Diego)",
        "Yifei Shao (University of Pennsylvania",
        "Philadelphia)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:45:50+00:00",
          "link": "https://arxiv.org/abs/2507.09375v1",
          "size": "1006kb",
          "version": "v1"
        }
      ],
      "title": "Automated Multi-Class Crop Pathology Classification via Convolutional Neural Networks: A Deep Learning Approach for Real-Time Precision Agriculture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09375",
        "PDF": "https://arxiv.org/pdf/2507.09375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a CNN-based approach for crop pathology classification, focusing on image preprocessing and classification but not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09453",
      "abstract": "The digitization of democratic processes promises greater accessibility but presents challenges in terms of security, privacy, and verifiability. Existing electronic voting systems often rely on centralized architectures, creating single points of failure and forcing too much trust in authorities, which contradicts democratic principles. This research addresses the challenge of creating a secure, private e-voting system with minimized trust dependencies designed for the most versatile personal device: the smartphone. We introduce SmartphoneDemocracy, a novel e-voting protocol that combines three key technologies: the emerging European Digital Identity (EUDI) Wallet for Sybil-resistant identity verification, Zero-Knowledge Proofs for privacy-preserving validation, and a peer-to-peer blockchain (TrustChain) for a resilient, serverless public bulletin board. Our protocol enables voters to register and cast ballots anonymously and verifiably directly from their smartphones. We provide a detailed protocol design, a security analysis against a defined threat model, and a performance evaluation demonstrating that the computational and network overhead is feasible for medium- to large-scale elections. By developing and prototyping this system, we demonstrate a viable path to empower citizens with a trustworthy, accessible, and user-controlled digital voting experience.",
      "authors": [
        "Micha{\\l} J\\'o\\'zwik",
        "Johan Pouwelse"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:39:10+00:00",
          "link": "https://arxiv.org/abs/2507.09453v1",
          "size": "978kb",
          "version": "v1"
        }
      ],
      "title": "SmartphoneDemocracy: Privacy-Preserving E-Voting on Decentralized Infrastructure using Novel European Identity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09453",
        "HTML": "https://arxiv.org/html/2507.09453v1",
        "PDF": "https://arxiv.org/pdf/2507.09453"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses e-voting systems with privacy and security innovations but does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09514",
      "abstract": "State space models (SSMs) reduce the quadratic complexity of transformers by leveraging linear recurrence. Recently, VMamba has emerged as a strong SSM-based vision backbone, yet remains bottlenecked by spatial redundancy in its four-directional scan. We propose QuarterMap, a post-training activation pruning method that removes redundant spatial activations before scanning and restores dimensions via nearest-neighbor upsampling. Our method improves throughput without retraining. On ImageNet-1K, QuarterMap achieves up to 11% speedup on VMamba with less than 0.9% accuracy drop, and yields similar gains on ADE20K segmentation. Beyond VMamba, we validate QuarterMap on MedMamba, a domain-specific model that shares the same four-directional scanning structure, where it consistently improves throughput while preserving accuracy across multiple medical imaging tasks. Compared to token merging methods like ToMe, QuarterMap is tailored for SSMs and avoids costly merge-unmerge operations. Our method offers a plug-and-play tool for deployment-time efficiency without compromising transferability.",
      "authors": [
        "Tien-Yu Chi",
        "Hung-Yueh Chiang",
        "Diana Marculescu",
        "Kai-Chiang Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:49:32+00:00",
          "link": "https://arxiv.org/abs/2507.09514v1",
          "size": "1565kb",
          "version": "v1"
        }
      ],
      "title": "QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09514",
        "HTML": "https://arxiv.org/html/2507.09514v1",
        "PDF": "https://arxiv.org/pdf/2507.09514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses post-training token pruning methods for improving efficiency of visual state space models, without direct relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09617",
      "abstract": "Personal service robots are deployed to support daily living in domestic environments, particularly for elderly and individuals requiring assistance. These robots must perceive complex and dynamic surroundings, understand tasks, and execute context-appropriate actions. However, current systems rely on proprietary, hard-coded solutions tied to specific hardware and software, resulting in siloed implementations that are difficult to adapt and scale across platforms. Ontologies and Knowledge Graphs (KGs) offer a solution to enable interoperability across systems, through structured and standardized representations of knowledge and reasoning. However, symbolic systems such as KGs and ontologies struggle with raw and noisy sensory input. In contrast, multimodal language models are well suited for interpreting input such as images and natural language, but often lack transparency, consistency, and knowledge grounding. In this work, we propose a neurosymbolic framework that combines the perceptual strengths of multimodal language models with the structured representations provided by KGs and ontologies, with the aim of supporting interoperability in robotic applications. Our approach generates ontology-compliant KGs that can inform robot behavior in a platform-independent manner. We evaluated this framework by integrating robot perception data, ontologies, and five multimodal models (three LLaMA and two GPT models), using different modes of neural-symbolic interaction. We assess the consistency and effectiveness of the generated KGs across multiple runs and configurations, and perform statistical analyzes to evaluate performance. Results show that GPT-o1 and LLaMA 4 Maverick consistently outperform other models. However, our findings also indicate that newer models do not guarantee better results, highlighting the critical role of the integration strategy in generating ontology-compliant KGs.",
      "authors": [
        "Margherita Martorana",
        "Francesca Urgese",
        "Mark Adamik",
        "Ilaria Tiddi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:52:00+00:00",
          "link": "https://arxiv.org/abs/2507.09617v1",
          "size": "29091kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09617",
        "HTML": "https://arxiv.org/html/2507.09617v1",
        "PDF": "https://arxiv.org/pdf/2507.09617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a neurosymbolic framework for personal service robots by integrating multimodal LMs with knowledge graphs, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09719",
      "abstract": "We analyze the power consumption of quantum key distribution (QKD) networks under various protocol and detector configurations. Using realistic network topologies, we evaluate discrete-variable vs continuous-variable QKD and optimize device placement, quantifying power trade-offs of SNSPD vs APD detectors and the benefits of optical bypass.",
      "authors": [
        "Jiaheng Xiong",
        "Qiaolun Zhang",
        "Yoann Pi\\'etri",
        "Raja Yehia",
        "Raouf Boutaba",
        "Francesco Musumeci",
        "Massimo Tornatore"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:38:52+00:00",
          "link": "https://arxiv.org/abs/2507.09719v1",
          "size": "1504kb",
          "version": "v1"
        }
      ],
      "title": "Power Consumption Analysis of QKD Networks under Different Protocols and Detector Configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09719",
        "HTML": "https://arxiv.org/html/2507.09719v1",
        "PDF": "https://arxiv.org/pdf/2507.09719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on analyzing power consumption of quantum key distribution networks, with no discussion related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.17517",
      "abstract": "With the development of edge computing, Federated Learning (FL) has emerged as a promising solution for the intelligent Internet of Things (IoT). However, applying FL in mobile edge-cloud networks is greatly challenged by statistical heterogeneity and high communication overhead. To address it, we propose a hybrid federated learning framework called HFLDD, which integrates dataset distillation to generate approximately independent and equally distributed (IID) data, thereby improving the performance of model training. In particular, we partition the clients into heterogeneous clusters, where the data labels among different clients within a cluster are unbalanced while the data labels among different clusters are balanced. The cluster heads collect distilled data from the corresponding cluster members, and conduct model training in collaboration with the server. This training process is like traditional federated learning on IID data, and hence effectively alleviates the impact of non-IID data on model training. We perform a comprehensive analysis of the convergence behavior, communication overhead, and computational complexity of the proposed HFLDD. Extensive experimental results based on multiple public datasets demonstrate that when data labels are severely imbalanced, the proposed HFLDD outperforms the baseline methods in terms of both test accuracy and communication cost.",
      "authors": [
        "Xiufang Shi",
        "Wei Zhang",
        "Mincheng Wu",
        "Guangyi Liu",
        "Zhenyu Wen",
        "Shibo He",
        "Tejal Shah",
        "Rajiv Ranjan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T03:52:41+00:00",
          "link": "https://arxiv.org/abs/2409.17517v1",
          "size": "4939kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T00:42:10+00:00",
          "link": "https://arxiv.org/abs/2409.17517v2",
          "size": "10572kb",
          "version": "v2"
        }
      ],
      "title": "Dataset Distillation-based Hybrid Federated Learning on Non-IID Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17517",
        "HTML": "https://arxiv.org/html/2409.17517v2",
        "PDF": "https://arxiv.org/pdf/2409.17517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves dataset distillation for federated learning, which relates to data processing but not specifically for LLM training data."
      },
      "tasks": [
        "Dataset Distillation",
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10200",
      "abstract": "Existing MLLMs encounter significant challenges in modeling the temporal context within long videos. Currently, mainstream Agent-based methods use external tools to assist a single MLLM in answering long video questions. Despite such tool-based support, a solitary MLLM still offers only a partial understanding of long videos, resulting in limited performance. In order to better address long video tasks, we introduce LVAgent, the first framework enabling multi-round dynamic collaboration of MLLM agents in long video understanding. Our method consists of four key steps: 1) Selection: We pre-select appropriate agents from the model library to form optimal agent teams based on different tasks. 2) Perception: We design an effective retrieval scheme for long videos to improve the coverage of critical temporal segments while maintaining computational efficiency. 3) Action: Agents answer long video questions and exchange reasons. 4) Reflection: We evaluate each agent's performance in each round of discussion and optimize the agent team for dynamic collaboration. The agents iteratively refine their answers by multi-round dynamical collaboration of MLLM agents. LVAgent is the first agent system method that outperforms all closed-source models (like GPT-4o) and open-source models (like InternVL-2.5 and Qwen2-VL) in the long video understanding tasks. Our LVAgent achieves an accuracy of 80\\% on four mainstream long video understanding tasks. Notably, LVAgent improves accuracy by 13.3\\% on LongVideoBench. Code is available at https://github.com/64327069/LVAgent.",
      "authors": [
        "Boyu Chen",
        "Zhengrong Yue",
        "Siran Chen",
        "Zikang Wang",
        "Yang Liu",
        "Peng Li",
        "Yali Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T09:35:09+00:00",
          "link": "https://arxiv.org/abs/2503.10200v1",
          "size": "20050kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T02:07:45+00:00",
          "link": "https://arxiv.org/abs/2503.10200v2",
          "size": "12676kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T02:23:25+00:00",
          "link": "https://arxiv.org/abs/2503.10200v3",
          "size": "7317kb",
          "version": "v3"
        }
      ],
      "title": "LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10200",
        "HTML": "https://arxiv.org/html/2503.10200v3",
        "PDF": "https://arxiv.org/pdf/2503.10200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the LVAgent framework for long video understanding, which involves collaboration of MLLM agents. Data preprocessing of long videos is mentioned but the focus is primarily on model collaboration rather than on training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Optical Character Recognition (OCR)",
        "Retrieval",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07216",
      "abstract": "Reliable data is a cornerstone of modern organizational systems. A notable data integrity challenge stems from label bias, which refers to systematic errors in a label, a covariate that is central to a quantitative analysis, such that its quality differs across social groups. This type of bias has been conceptually and empirically explored and is widely recognized as a pressing issue across critical domains. However, effective methodologies for addressing it remain scarce. In this work, we propose Decoupled Confident Learning (DeCoLe), a principled machine learning based framework specifically designed to detect mislabeled instances in datasets affected by label bias, enabling bias aware mislabelling detection and facilitating data quality improvement. We theoretically justify the effectiveness of DeCoLe and evaluate its performance in the impactful context of hate speech detection, a domain where label bias is a well documented challenge. Empirical results demonstrate that DeCoLe excels at bias aware mislabeling detection, consistently outperforming alternative approaches for label error detection. Our work identifies and addresses the challenge of bias aware mislabeling detection and offers guidance on how DeCoLe can be integrated into organizational data management practices as a powerful tool to enhance data reliability.",
      "authors": [
        "Yunyi Li",
        "Maria De-Arteaga and Maytal Saar-Tsechansky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:44:36+00:00",
          "link": "https://arxiv.org/abs/2507.07216v1",
          "size": "4503kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:34:30+00:00",
          "link": "https://arxiv.org/abs/2507.07216v2",
          "size": "3394kb",
          "version": "v2"
        }
      ],
      "title": "Bias-Aware Mislabeling Detection via Decoupled Confident Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07216",
        "HTML": "https://arxiv.org/html/2507.07216v2",
        "PDF": "https://arxiv.org/pdf/2507.07216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method (DeCoLe) for detecting mislabeled data affected by label bias, which is somewhat relevant to data quality improvement but not specifically tied to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09054",
      "abstract": "We introduce Ibex, a pan-immunoglobulin structure prediction model that achieves state-of-the-art accuracy in modeling the variable domains of antibodies, nanobodies, and T-cell receptors. Unlike previous approaches, Ibex explicitly distinguishes between bound and unbound protein conformations by training on labeled apo and holo structural pairs, enabling accurate prediction of both states at inference time. Using a comprehensive private dataset of high-resolution antibody structures, we demonstrate superior out-of-distribution performance compared to existing specialized and general protein structure prediction tools. Ibex combines the accuracy of cutting-edge models with significantly reduced computational requirements, providing a robust foundation for accelerating large molecule design and therapeutic development.",
      "authors": [
        "Fr\\'ed\\'eric A. Dreyer",
        "Jan Ludwiczak",
        "Karolis Martinkus",
        "Brennan Abanades",
        "Robert G. Alberstein",
        "Pan Kessel",
        "Pranav Rao",
        "Jae Hyeon Lee",
        "Richard Bonneau",
        "Andrew M. Watkins",
        "Franziska Seeger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T22:09:03+00:00",
          "link": "https://arxiv.org/abs/2507.09054v1",
          "size": "3944kb",
          "version": "v1"
        }
      ],
      "title": "Conformation-Aware Structure Prediction of Antigen-Recognizing Immune Proteins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09054",
        "HTML": "https://arxiv.org/html/2507.09054v1",
        "PDF": "https://arxiv.org/pdf/2507.09054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a protein structure prediction model and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09213",
      "abstract": "Wavelet neural network (WNN), which learns an unknown nonlinear mapping from the data, has been widely used in signal processing, and time-series analysis. However, challenges in constructing accurate wavelet bases and high computational costs limit their application. This study introduces a constructive WNN that selects initial bases and trains functions by introducing new bases for predefined accuracy while reducing computational costs. For the first time, we analyze the frequency of unknown nonlinear functions and select appropriate initial wavelets based on their primary frequency components by estimating the energy of the spatial frequency component. This leads to a novel constructive framework consisting of a frequency estimator and a wavelet-basis increase mechanism to prioritize high-energy bases, significantly improving computational efficiency. The theoretical foundation defines the necessary time-frequency range for high-dimensional wavelets at a given accuracy. The framework's versatility is demonstrated through four examples: estimating unknown static mappings from offline data, combining two offline datasets, identifying time-varying mappings from time-series data, and capturing nonlinear dependencies in real time-series data. These examples showcase the framework's broad applicability and practicality. All the code will be released at https://github.com/dshuangdd/CWNN.",
      "authors": [
        "Dunsheng Huang",
        "Dong Shen",
        "Lei Lu",
        "Ying Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:09:26+00:00",
          "link": "https://arxiv.org/abs/2507.09213v1",
          "size": "1479kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Basis Function Selection in Constructive Wavelet Neural Networks and Its Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09213",
        "HTML": "https://arxiv.org/html/2507.09213v1",
        "PDF": "https://arxiv.org/pdf/2507.09213"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing basis function selection in wavelet neural networks for various applications. It does not discuss processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09675",
      "abstract": "Background: Predicting startup success with machine learning is a rapidly growing field, yet findings on key predictors are often fragmented and context-specific. This makes it difficult to discern robust patterns and highlights a need for a systematic synthesis of the evidence.\n  Methods: This study conducts a quantitative meta-analysis to synthesize the literature on predictor importance in AI-based startup evaluation. We performed a systematic review to identify a final sample of 13 empirical studies that report rankable feature importance. From these papers, we extracted and categorized 58 unique predictors, synthesizing their importance using a Weighted Importance Score (WIS) that balances a feature's average rank with its frequency of appearance. We also conducted a moderator analysis to investigate how predictor importance changes with context (e.g., success definition).\n  Results: Our aggregate analysis reveals that the most consistently powerful predictors are a quartet of foundational attributes: Firm Characteristics (e.g., age, location), Investor Structure (e.g., investor quality), Digital and Social Traction (e.g., online momentum), and Funding History. The moderator analysis further reveals that this hierarchy is highly context-dependent. For instance, predicting near-term funding milestones elevates the importance of the deal's immediate context, while predicting long-term exits prioritizes fundamental firm and investor characteristics.\n  Conclusion: The factors that best predict startup success are not universal but are contingent on the startup's goals, stage, and the data used for evaluation. Our findings point to a potential \"convenience bias\" in the literature, where predictor importance may be tied to data accessibility. We conclude by underscoring the need for standardized reporting practices to enable more robust, cumulative knowledge building in the field.",
      "authors": [
        "Seyed Mohammad Ali Jafari",
        "Ali Mobini Dehkordi",
        "Ehsan Chitsaz",
        "Yadollah Yaghoobzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:16:29+00:00",
          "link": "https://arxiv.org/abs/2507.09675v1",
          "size": "1094kb",
          "version": "v1"
        }
      ],
      "title": "What Matters Most? A Quantitative Meta-Analysis of AI-Based Predictors for Startup Success",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09675",
        "PDF": "https://arxiv.org/pdf/2507.09675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study performs a meta-analysis on AI-based predictors for startup success and does not address any aspects of training data collection, processing, or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09828",
      "abstract": "Bayesian optimization is a powerful tool for optimizing an expensive-to-evaluate black-box function. In particular, the effectiveness of expected improvement (EI) has been demonstrated in a wide range of applications. However, theoretical analyses of EI are limited compared with other theoretically established algorithms. This paper analyzes a randomized variant of EI, which evaluates the EI from the maximum of the posterior sample path. We show that this posterior sampling-based random EI achieves the sublinear Bayesian cumulative regret bounds under the assumption that the black-box function follows a Gaussian process. Finally, we demonstrate the effectiveness of the proposed method through numerical experiments.",
      "authors": [
        "Shion Takeno",
        "Yu Inatsu",
        "Masayuki Karasuyama",
        "Ichiro Takeuchi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:37:31+00:00",
          "link": "https://arxiv.org/abs/2507.09828v1",
          "size": "519kb",
          "version": "v1"
        }
      ],
      "title": "Regret Analysis of Posterior Sampling-Based Expected Improvement for Bayesian Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09828",
        "HTML": "https://arxiv.org/html/2507.09828v1",
        "PDF": "https://arxiv.org/pdf/2507.09828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with Bayesian optimization and regret analysis for a variant of expected improvement (EI) but does not involve any training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10118",
      "abstract": "Pixel-level annotation is expensive and time-consuming. Semi-supervised segmentation methods address this challenge by learning models on few labeled images alongside a large corpus of unlabeled images. Although foundation models could further account for label scarcity, effective mechanisms for their exploitation remain underexplored. We address this by devising a novel semi-supervised panoptic approach fueled by two dedicated foundation models. We enhance recognition by complementing unsupervised mask-transformer consistency with zero-shot classification of CLIP features. We enhance localization by class-agnostic decoder warm-up with respect to SAM pseudo-labels. The resulting decoupled enhancement of recognition and localization (DEARLi) particularly excels in the most challenging semi-supervised scenarios with large taxonomies and limited labeled data. Moreover, DEARLi outperforms the state of the art in semi-supervised semantic segmentation by a large margin while requiring 8x less GPU memory, in spite of being trained only for the panoptic objective. We observe 29.9 PQ and 38.9 mIoU on ADE20K with only 158 labeled images. The source code is available at https://github.com/helen1c/DEARLi.",
      "authors": [
        "Ivan Martinovi\\'c and Josip \\v{S}ari\\'c and Marin Or\\v{s}i\\'c and Matej Kristan and Sini\\v{s}a \\v{S}egvi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:01:02+00:00",
          "link": "https://arxiv.org/abs/2507.10118v1",
          "size": "21576kb",
          "version": "v1"
        }
      ],
      "title": "DEARLi: Decoupled Enhancement of Recognition and Localization for Semi-supervised Panoptic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10118",
        "HTML": "https://arxiv.org/html/2507.10118v1",
        "PDF": "https://arxiv.org/pdf/2507.10118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses semi-supervised segmentation using panoptic approaches and foundation models, but it does not focus on LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10251",
      "abstract": "Existing asynchronous MARL methods based on MacDec-POMDP typically construct training trajectory buffers by simply sampling limited and biased data at the endpoints of macro-actions, and directly apply conventional MARL methods on the buffers. As a result, these methods lead to an incomplete and inaccurate representation of the macro-action execution process, along with unsuitable credit assignments. To solve these problems, the Temporal Macro-action Value Factorization (ToMacVF) is proposed to achieve fine-grained temporal credit assignment for macro-action contributions. A centralized training buffer, called Macro-action Segmented Joint Experience Replay Trajectory (Mac-SJERT), is designed to incorporate with ToMacVF to collect accurate and complete macro-action execution information, supporting a more comprehensive and precise representation of the macro-action process. To ensure principled and fine-grained asynchronous value factorization, the consistency requirement between joint and individual macro-action selection called Temporal Macro-action based IGM (To-Mac-IGM) is formalized, proving that it generalizes the synchronous cases. Based on To-Mac-IGM, a modularized ToMacVF architecture, which satisfies CTDE principle, is designed to conveniently integrate previous value factorization methods. Next, the ToMacVF algorithm is devised as an implementation of the ToMacVF architecture. Experimental results demonstrate that, compared to asynchronous baselines, our ToMacVF algorithm not only achieves optimal performance but also exhibits strong adaptability and robustness across various asynchronous multi-agent experimental scenarios.",
      "authors": [
        "Wenjing Zhang and Wei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:18:13+00:00",
          "link": "https://arxiv.org/abs/2507.10251v1",
          "size": "2079kb",
          "version": "v1"
        }
      ],
      "title": "ToMacVF : Temporal Macro-action Value Factorization for Asynchronous Multi-Agent Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10251",
        "PDF": "https://arxiv.org/pdf/2507.10251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an approach for multi-agent reinforcement learning, focusing on value factorization and asynchronous training but not on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10470",
      "abstract": "Blind facial image restoration is highly challenging due to unknown complex degradations and the sensitivity of humans to faces. Although existing methods introduce auxiliary information from generative priors or high-quality reference images, they still struggle with identity preservation problems, mainly due to improper feature introduction on detailed textures. In this paper, we focus on effectively incorporating appropriate features from high-quality reference images, presenting a novel blind facial image restoration method that considers reference selection, transfer, and reconstruction (RefSTAR). In terms of selection, we construct a reference selection (RefSel) module. For training the RefSel module, we construct a RefSel-HQ dataset through a mask generation pipeline, which contains annotating masks for 10,000 ground truth-reference pairs. As for the transfer, due to the trivial solution in vanilla cross-attention operations, a feature fusion paradigm is designed to force the features from the reference to be integrated. Finally, we propose a reference image reconstruction mechanism that further ensures the presence of reference image features in the output image. The cycle consistency loss is also redesigned in conjunction with the mask. Extensive experiments on various backbone models demonstrate superior performance, showing better identity preservation ability and reference feature transfer quality. Source code, dataset, and pre-trained models are available at https://github.com/yinzhicun/RefSTAR.",
      "authors": [
        "Zhicun Yin",
        "Junjie Chen",
        "Ming Liu",
        "Zhixin Wang",
        "Fan Li",
        "Renjing Pei",
        "Xiaoming Li",
        "Rynson W.H. Lau",
        "Wangmeng Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.10470v1",
          "size": "16649kb",
          "version": "v1"
        }
      ],
      "title": "RefSTAR: Blind Facial Image Restoration with Reference Selection, Transfer, and Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10470",
        "HTML": "https://arxiv.org/html/2507.10470v1",
        "PDF": "https://arxiv.org/pdf/2507.10470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes the creation of a RefSel-HQ dataset aiding in reference selection in image restoration but the focus is on feature incorporation for image processing, not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.03894",
      "abstract": "The prediction-based nonlinear reference governor (PRG) is an add-on algorithm to enforce constraints on pre-stabilized nonlinear systems by modifying, whenever necessary, the reference signal. The implementation of PRG carries a heavy computational burden, as it may require multiple numerical simulations of the plant model at each sample time. To this end, this paper proposes an alternative approach based on machine learning, where we first use a regression neural network (NN) to approximate the input-output map of the PRG from a set of training data. During the real-time operation, at each sample time, we use the trained NN to compute a nominal reference command, which may not be constraint admissible due to training errors and limited data. We adopt a novel sensitivity-based approach to minimally adjust the nominal reference while ensuring constraint enforcement. We thus refer to the resulting control strategy as the modified neural network reference governor (MNN-RG), which is significantly more computationally efficient than the PRG. The computational and theoretical properties of MNN-RG are presented. Finally, the effectiveness and limitations of the proposed method are studied by applying it as a load governor for constraint management in automotive fuel cell systems through simulation-based case studies.",
      "authors": [
        "Mostafaali Ayubirad",
        "Hamid R. Ossareh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-04T19:52:19+00:00",
          "link": "https://arxiv.org/abs/2410.03894v1",
          "size": "2363kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T14:44:01+00:00",
          "link": "https://arxiv.org/abs/2410.03894v2",
          "size": "1948kb",
          "version": "v2"
        }
      ],
      "title": "A Machine Learning-Based Reference Governor for Nonlinear Systems With Application to Automotive Fuel Cells",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03894",
        "HTML": "https://arxiv.org/html/2410.03894v2",
        "PDF": "https://arxiv.org/pdf/2410.03894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a machine learning-based reference governor for nonlinear systems with a specific application to automotive fuel cells, without focusing on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.05225",
      "abstract": "Large Language Models (LLMs) based on transformers achieve cutting-edge results on a variety of applications. However, their enormous size and processing requirements hinder deployment on constrained resources. To enhance efficiency, binarization and Early Exit (EE) have proved to be effective solutions. However, binarization may lead to performance loss as reduced precision affects gradient estimation and parameter updates. Besides, research on EE mechanisms is still in its early stages. To address these challenges, we introduce Binarized Early Exit Transformer (BEExformer), the first-ever selective learning-based transformer integrating Binarization-Aware Training (BAT) with EE for efficient and fast textual inference. Each transformer block has an integrated Selective-Learn Forget Network (SLFN) to enhance contextual retention while eliminating irrelevant information. The BAT employs a differentiable second-order approximation to the sign function, enabling gradient computation that captures both the sign and magnitude of the weights. This aids in 21.30 times reduction in model size. The EE mechanism hinges on fractional reduction in entropy among intermediate transformer blocks with soft-routing loss estimation. This accelerates inference by reducing FLOPs by 52.08% and even improves accuracy by 2.89% by resolving the \"overthinking\" problem inherent in deep networks. Extensive evaluation through comparison with the SOTA methods and various ablations across six datasets covering multiple NLP tasks demonstrates its Pareto-optimal performance-efficiency trade-off.",
      "authors": [
        "Wazib Ansar",
        "Saptarsi Goswami",
        "and Amlan Chakrabarti"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T17:58:14+00:00",
          "link": "https://arxiv.org/abs/2412.05225v1",
          "size": "652kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T18:28:38+00:00",
          "link": "https://arxiv.org/abs/2412.05225v2",
          "size": "890kb",
          "version": "v2"
        }
      ],
      "title": "BEExformer: A Fast Inferencing Binarized Transformer with Early Exits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05225",
        "HTML": "https://arxiv.org/html/2412.05225v2",
        "PDF": "https://arxiv.org/pdf/2412.05225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces BEExformer with efficiency improvements in transformer models, it primarily focuses on model binarization and early exit techniques, mentioning standard NLP tasks but not focusing on LLM training data processing."
      },
      "tasks": [
        "Binarization",
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.10702",
      "abstract": "Binary matrix-vector multiplication (BMVM) is a key operation in post-quantum cryptography schemes like the Classic McEliece cryptosystem. Conventional computing architectures incur significant energy efficiency loss due to data movement of large matrices when handling such tasks. Resistive memory (RRAM) non-volatile compute-in-memory (nvCIM) is an ideal technology for high energy-efficient BMVM processing but faces challenges, including signal margin degradation in high input-parallelism arrays due to device non-idealities and high hardware overhead from current readout and XOR operations. This work presents a RRAM nvCIM architecture featuring: 1) 1T1R cells with high-resistive-state compensation modules; and 2) pulsed current-sensing parity checkers. Based on the 180nm process and test results from RRAM devices, the computing accuracy and efficiency of the architecture are verified by simulation. The proposed architecture performs high-precision current accumulation with a maximum MAC value of 10 and achieves an energy efficiency of 1.51TOPS/W, offering approximately 1.62 times improvement compared to an advanced 28nm FPGA platform.",
      "authors": [
        "Hao Yue",
        "Yihao Chen",
        "Tianhang Liang",
        "Xiangrui Li",
        "Xin Kong",
        "Zhelong Jiang",
        "Zhigang Li",
        "Gang Chen",
        "Huaxiang Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-18T08:58:49+00:00",
          "link": "https://arxiv.org/abs/2501.10702v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T03:23:55+00:00",
          "link": "https://arxiv.org/abs/2501.10702v2",
          "size": "279kb",
          "version": "v2"
        },
        {
          "date": "2025-01-31T12:16:25+00:00",
          "link": "https://arxiv.org/abs/2501.10702v3",
          "size": "528kb",
          "version": "v3"
        },
        {
          "date": "2025-04-14T03:05:11+00:00",
          "link": "https://arxiv.org/abs/2501.10702v4",
          "size": "5587kb",
          "version": "v4"
        },
        {
          "date": "2025-07-12T05:14:51+00:00",
          "link": "https://arxiv.org/abs/2501.10702v5",
          "size": "5558kb",
          "version": "v5"
        }
      ],
      "title": "An RRAM compute-in-memory architecture for high energy-efficient processing of binary matrix-vector multiplication in cryptography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10702",
        "HTML": "https://arxiv.org/html/2501.10702v5",
        "PDF": "https://arxiv.org/pdf/2501.10702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on compute-in-memory architecture for cryptography tasks and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17289",
      "abstract": "Given two points in the plane, and a set of \"obstacles\" given as curves through the plane with assigned weights, we consider the point-separation problem, which asks for the minimum-weight subset of the obstacles separating the two points. A few computational models for this problem have been previously studied. We give a unified approach to this problem in all models via a reduction to a particular shortest-path problem, and obtain improved running times in essentially all cases. In addition, we also give fine-grained lower bounds for many cases.",
      "authors": [
        "Jack Spalding-Jamieson",
        "Anurag Murty Naredla"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T06:31:46+00:00",
          "link": "https://arxiv.org/abs/2504.17289v1",
          "size": "641kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T03:17:14+00:00",
          "link": "https://arxiv.org/abs/2504.17289v2",
          "size": "693kb",
          "version": "v2"
        }
      ],
      "title": "Separating Two Points with Obstacles in the Plane: Improved Upper and Lower Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17289",
        "HTML": "https://arxiv.org/html/2504.17289v2",
        "PDF": "https://arxiv.org/pdf/2504.17289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the point-separation problem in computational geometry and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.21363",
      "abstract": "Despite the constant development of new bias mitigation methods for machine learning, no method consistently succeeds, and a fundamental question remains unanswered: when and why do bias mitigation techniques fail? In this paper, we hypothesise that a key factor may be the often-overlooked but crucial step shared by many bias mitigation methods: the definition of subgroups. To investigate this, we conduct a comprehensive evaluation of state-of-the-art bias mitigation methods across multiple vision and language classification tasks, systematically varying subgroup definitions, including coarse, fine-grained, intersectional, and noisy subgroups. Our results reveal that subgroup choice significantly impacts performance, with certain groupings paradoxically leading to worse outcomes than no mitigation at all. Our findings suggest that observing a disparity between a set of subgroups is not a sufficient reason to use those subgroups for mitigation. Through theoretical analysis, we explain these phenomena and uncover a counter-intuitive insight that, in some cases, improving fairness with respect to a particular set of subgroups is best achieved by using a different set of subgroups for mitigation. Our work highlights the importance of careful subgroup definition in bias mitigation and presents it as an alternative lever for improving the robustness and fairness of machine learning models.",
      "authors": [
        "Anissa Alloula and Charles Jones and Ben Glocker and Bart{\\l}omiej W. Papie\\.z"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T15:52:58+00:00",
          "link": "https://arxiv.org/abs/2505.21363v1",
          "size": "1352kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T12:21:49+00:00",
          "link": "https://arxiv.org/abs/2505.21363v2",
          "size": "1352kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T00:36:39+00:00",
          "link": "https://arxiv.org/abs/2505.21363v3",
          "size": "1351kb",
          "version": "v3"
        }
      ],
      "title": "Subgroups Matter for Robust Bias Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21363",
        "HTML": "https://arxiv.org/html/2505.21363v3",
        "PDF": "https://arxiv.org/pdf/2505.21363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on bias mitigation techniques in machine learning, particularly through subgroup definitions, without addressing LLM training data processing or dataset engineering."
      },
      "tasks": [
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/anissa218/subgroups_bias_mit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08978",
      "abstract": "Increasingly, students begin learning aspects of security and privacy during their primary and secondary education (grades K-12 in the United States). Individual U.S. states and some national organizations publish teaching standards -- guidance that outlines expectations for what students should learn -- which often form the basis for course curricula. However, research has not yet examined what is covered by these standards and whether the topics align with what the broader security and privacy community thinks students should know. To shed light on these questions, we started by collecting computer science teaching standards from all U.S. states and eight national organizations. After manually examining a total of 11,954 standards, we labeled 3,778 of them as being related to security and privacy, further classifying these into 103 topics. Topics ranged from technical subjects like encryption, network security, and embedded systems to social subjects such as laws, ethics, and appropriate online behavior. Subsequently, we interviewed 11 security and privacy professionals to examine how the teaching standards align with their expectations. We found that, while the specific topics they mentioned mostly overlapped with those of existing standards, professionals placed a greater emphasis on threat modeling and security mindset.",
      "authors": [
        "Katherine Limes",
        "Nathan Malkin",
        "Kelsey R. Fulton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:20:08+00:00",
          "link": "https://arxiv.org/abs/2507.08978v1",
          "size": "908kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing Security and Privacy Teaching Standards for Schools in the United States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08978",
        "HTML": "https://arxiv.org/html/2507.08978v1",
        "PDF": "https://arxiv.org/pdf/2507.08978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the analysis of teaching standards for security and privacy, with no mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09000",
      "abstract": "Identifying the actual cause of events in engineered systems is a fundamental challenge in system analysis. Finding such causes becomes more challenging in the presence of noise and uncertainty in real-world systems. In this paper, we adopt the notion of probabilistic actual causality by Fenton-Glynn, which is a probabilistic extension of Halpern and Pearl's actual causality, and propose a novel method to formally reason about causal effect of events in systems subject to uncertainty. We (1) formulate the discovery of probabilistic actual causes in computing systems as an SMT problem, and (2) address the scalability challenges by introducing an abstraction-refinement technique that significantly improves efficiency. We demonstrate the effectiveness of our approach through three case studies, identifying probabilistic causes of safety violations in (1) the Mountain Car problem, (2) the Lunar Lander benchmark, and (3) MPC controller for an F-16 autopilot simulator.",
      "authors": [
        "Arshia Rafieioskouei",
        "Kenneth Rogale",
        "Borzoo Bonakdarpour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:07:08+00:00",
          "link": "https://arxiv.org/abs/2507.09000v1",
          "size": "208kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Discovery of Actual Causality with Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09000",
        "PDF": "https://arxiv.org/pdf/2507.09000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses discovering probabilistic actual causality with uncertainty and does not make a contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09628",
      "abstract": "We introduce SpreadPy as a Python library for simulating spreading activation in cognitive single-layer and multiplex networks. Our tool is designed to perform numerical simulations testing structure-function relationships in cognitive processes. By comparing simulation results with grounded theories in knowledge modelling, SpreadPy enables systematic investigations of how activation dynamics reflect cognitive, psychological and clinical phenomena. We demonstrate the library's utility through three case studies: (1) Spreading activation on associative knowledge networks distinguishes students with high versus low math anxiety, revealing anxiety-related structural differences in conceptual organization; (2) Simulations of a creativity task show that activation trajectories vary with task difficulty, exposing how cognitive load modulates lexical access; (3) In individuals with aphasia, simulated activation patterns on lexical networks correlate with empirical error types (semantic vs. phonological) during picture-naming tasks, linking network structure to clinical impairments. SpreadPy's flexible framework allows researchers to model these processes using empirically derived or theoretical networks, providing mechanistic insights into individual differences and cognitive impairments. The library is openly available, supporting reproducible research in psychology, neuroscience, and education research.",
      "authors": [
        "Salvatore Citraro and Edith Haim and Alessandra Carini and Cynthia S. Q. Siew and Giulio Rossetti and Massimo Stella"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T13:49:29+00:00",
          "link": "https://arxiv.org/abs/2507.09628v1",
          "size": "1442kb",
          "version": "v1"
        }
      ],
      "title": "SpreadPy: A Python tool for modelling spreading activation and superdiffusion in cognitive multiplex networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09628",
        "HTML": "https://arxiv.org/html/2507.09628v1",
        "PDF": "https://arxiv.org/pdf/2507.09628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SpreadPy is a tool for simulating activation in cognitive networks and does not involve any contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09989",
      "abstract": "In heterogeneous multi-agent reinforcement learning (MARL), achieving monotonic improvement plays a pivotal role in enhancing performance. The HAPPO algorithm proposes a feasible solution by introducing a sequential update scheme, which requires independent learning with No Parameter-sharing (NoPS). However, heterogeneous MARL generally requires Partial Parameter-sharing (ParPS) based on agent grouping to achieve high cooperative performance. Our experiments prove that directly combining ParPS with the sequential update scheme leads to the policy updating baseline drift problem, thereby failing to achieve improvement. To solve the conflict between monotonic improvement and ParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG) algorithm. First, we replace the sequentially computed $Q_{\\psi}^s(s,a_{1:i})$ with the Optimal Marginal Q (OMQ) function $\\phi_{\\psi}^*(s,a_{1:i})$ derived from Q-functions. This maintains MAAD's monotonic improvement while eliminating the conflict through optimal joint action sequences instead of sequential policy ratio calculations. Second, we introduce the Generalized Q Critic (GQC) as the critic function, employing pessimistic uncertainty-constrained loss to optimize different Q-value estimations. This provides the required Q-values for OMQ computation and stable baselines for actor updates. Finally, we implement a Centralized Critic Grouped Actor (CCGA) architecture that simultaneously achieves ParPS in local policy networks and accurate global Q-function computation. Experimental results in SMAC and MAMuJoCo environments demonstrate that OMDPG outperforms various state-of-the-art MARL baselines.",
      "authors": [
        "Xiaoyang Yu",
        "Youfang Lin",
        "Shuo Wang",
        "Sheng Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:16:01+00:00",
          "link": "https://arxiv.org/abs/2507.09989v1",
          "size": "746kb",
          "version": "v1"
        }
      ],
      "title": "Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09989",
        "HTML": "https://arxiv.org/html/2507.09989v1",
        "PDF": "https://arxiv.org/pdf/2507.09989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a reinforcement learning algorithm for MARL, focusing on update schemes and optimization, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10290",
      "abstract": "Optimization has been widely used to generate smooth trajectories for motion planning. However, existing trajectory optimization methods show weakness when dealing with large-scale long trajectories. Recent advances in parallel computing have accelerated optimization in some fields, but how to efficiently solve trajectory optimization via parallelism remains an open question. In this paper, we propose a novel trajectory optimization framework based on the Consensus Alternating Direction Method of Multipliers (CADMM) algorithm, which decomposes the trajectory into multiple segments and solves the subproblems in parallel. The proposed framework reduces the time complexity to O(1) per iteration to the number of segments, compared to O(N) of the state-of-the-art (SOTA) approaches. Furthermore, we introduce a closed-form solution that integrates convex linear and quadratic constraints to speed up the optimization, and we also present numerical solutions for general inequality constraints. A series of simulations and experiments demonstrate that our approach outperforms the SOTA approach in terms of efficiency and smoothness. Especially for a large-scale trajectory, with one hundred segments, achieving over a tenfold speedup. To fully explore the potential of our algorithm on modern parallel computing architectures, we deploy our framework on a GPU and show high performance with thousands of segments.",
      "authors": [
        "Jiajun Yu",
        "Nanhe Chen",
        "Guodong Liu",
        "Chao Xu",
        "Fei Gao",
        "Yanjun Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:56:59+00:00",
          "link": "https://arxiv.org/abs/2507.10290v1",
          "size": "22037kb",
          "version": "v1"
        }
      ],
      "title": "TOP: Trajectory Optimization via Parallel Optimization towards Constant Time Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10290",
        "HTML": "https://arxiv.org/html/2507.10290v1",
        "PDF": "https://arxiv.org/pdf/2507.10290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses trajectory optimization using parallel computing for motion planning, offering computational improvements but does not address LLM training data or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.04979",
      "abstract": "Although graph neural networks (GNNs) have achieved impressive achievements in graph classification, they often need abundant task-specific labels, which could be extensively costly to acquire. A credible solution is to explore additional labeled graphs to enhance unsupervised learning on the target domain. However, how to apply GNNs to domain adaptation remains unsolved owing to the insufficient exploration of graph topology and the significant domain discrepancy. In this paper, we propose Coupled Contrastive Graph Representation Learning (CoCo), which extracts the topological information from coupled learning branches and reduces the domain discrepancy with coupled contrastive learning. CoCo contains a graph convolutional network branch and a hierarchical graph kernel network branch, which explore graph topology in implicit and explicit manners. Besides, we incorporate coupled branches into a holistic multi-view contrastive learning framework, which not only incorporates graph representations learned from complementary views for enhanced understanding, but also encourages the similarity between cross-domain example pairs with the same semantics for domain alignment. Extensive experiments on popular datasets show that our CoCo outperforms these competing baselines in different settings generally.",
      "authors": [
        "Nan Yin",
        "Li Shen",
        "Mengzhu Wang",
        "Long Lan",
        "Zeyu Ma",
        "Chong Chen",
        "Xian-Sheng Hua",
        "Xiao Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-08T07:10:35+00:00",
          "link": "https://arxiv.org/abs/2306.04979v1",
          "size": "1316kb",
          "version": "v1"
        },
        {
          "date": "2023-06-10T11:20:26+00:00",
          "link": "https://arxiv.org/abs/2306.04979v2",
          "size": "1216kb",
          "version": "v2"
        },
        {
          "date": "2024-07-29T14:50:43+00:00",
          "link": "https://arxiv.org/abs/2306.04979v3",
          "size": "1217kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T04:28:29+00:00",
          "link": "https://arxiv.org/abs/2306.04979v4",
          "size": "1214kb",
          "version": "v4"
        }
      ],
      "title": "CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.04979",
        "HTML": "https://arxiv.org/html/2306.04979v4",
        "PDF": "https://arxiv.org/pdf/2306.04979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on graph neural networks and domain adaptation using contrastive learning, with no mention of processing LLM training data."
      },
      "tasks": [
        "Contrastive Learning",
        "Domain Adaptation",
        "Graph Classification",
        "Graph Representation Learning",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22767",
      "abstract": "Magnetic soft robots embedded with hard magnetic particles enable untethered actuation via external magnetic fields, offering remote, rapid, and precise control, which is highly promising for biomedical applications. However, designing such systems is challenging due to the complex interplay of magneto-elastic dynamics, large deformation, solid contacts, time-varying stimuli, and posture-dependent loading. As a result, most existing research relies on heuristics and trial-and-error methods or focuses on the independent design of stimuli or structures under static conditions. We propose a topology optimization framework for magnetic soft robots that simultaneously designs structures, location-specific material magnetization and time-varying magnetic stimuli, accounting for large deformations, dynamic motion, and solid contacts. This is achieved by integrating generalized topology optimization with the magneto-elastic material point method, which supports GPU-accelerated parallel simulations and auto-differentiation for sensitivity analysis. We applied this framework to design magnetic robots for various tasks, including multi-task shape morphing and locomotion, in both 2D and 3D. The method autonomously generates optimized robotic systems to achieve target behaviors without requiring human intervention. Despite the nonlinear physics and large design space, it demonstrates high computational efficiency, completing all cases within minutes. The framework provides a computational foundation for the autonomous co-design of active soft materials in applications such as metasurfaces, drug delivery, and minimally invasive procedures.",
      "authors": [
        "Liwei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T02:47:59+00:00",
          "link": "https://arxiv.org/abs/2503.22767v1",
          "size": "7702kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T13:15:09+00:00",
          "link": "https://arxiv.org/abs/2503.22767v2",
          "size": "8455kb",
          "version": "v2"
        }
      ],
      "title": "Co-design of magnetic soft robots with large deformation and contacts via material point method and topology optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22767",
        "PDF": "https://arxiv.org/pdf/2503.22767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the co-design and optimization framework for magnetic soft robots, with no discussion on LLM training data or relevant data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.16386",
      "abstract": "This paper proposes Constrained Sampling Cluster Model Predictive Path Integral (CSC-MPPI), a novel constrained formulation of MPPI designed to enhance trajectory optimization while enforcing strict constraints on system states and control inputs. Traditional MPPI, which relies on a probabilistic sampling process, often struggles with constraint satisfaction and generates suboptimal trajectories due to the weighted averaging of sampled trajectories. To address these limitations, the proposed framework integrates a primal-dual gradient-based approach and Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to steer sampled input trajectories into feasible regions while mitigating risks associated with weighted averaging. First, to ensure that sampled trajectories remain within the feasible region, the primal-dual gradient method is applied to iteratively shift sampled inputs while enforcing state and control constraints. Then, DBSCAN groups the sampled trajectories, enabling the selection of representative control inputs within each cluster. Finally, among the representative control inputs, the one with the lowest cost is chosen as the optimal action. As a result, CSC-MPPI guarantees constraint satisfaction, improves trajectory selection, and enhances robustness in complex environments. Simulation and real-world experiments demonstrate that CSC-MPPI outperforms traditional MPPI in obstacle avoidance, achieving improved reliability and efficiency. The experimental videos are available at https://cscmppi.github.io",
      "authors": [
        "Leesai Park",
        "Keunwoo Jang",
        "Sanghyun Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T15:17:35+00:00",
          "link": "https://arxiv.org/abs/2506.16386v1",
          "size": "948kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T00:16:54+00:00",
          "link": "https://arxiv.org/abs/2506.16386v2",
          "size": "1156kb",
          "version": "v2"
        }
      ],
      "title": "CSC-MPPI: A Novel Constrained MPPI Framework with DBSCAN for Reliable Obstacle Avoidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16386",
        "HTML": "https://arxiv.org/html/2506.16386v2",
        "PDF": "https://arxiv.org/pdf/2506.16386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on a trajectory optimization approach in autonomous systems, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09223",
      "abstract": "We consider a multi-retailer supply chain where each retailer can dynamically choose when to share information (e.g., local inventory levels or demand observations) with other retailers, incurring a communication cost for each sharing event. This flexible information exchange mechanism contrasts with fixed protocols such as always sharing or never sharing. We formulate a joint optimization of inventory control and communication strategies, aiming to balance the trade-off between communication overhead and operational performance (service levels, holding, and stockout costs). We adopt a common information framework and derive a centralized Partially Observable Markov Decision Process (POMDP) model for a supply chain coordinator. Solving this coordinator's POMDP via dynamic programming characterizes the structure of optimal policies, determining when retailers should communicate and how they should adjust orders based on available information. We show that, in this setting, retailers can often act optimally by sharing only limited summaries of their private data, reducing communication frequency without compromising performance. We also incorporate practical constraints on communication frequency and propose an approximate point-based POMDP solution method (PBVI/SARSOP) to address computational complexity. Numerical experiments on multi-retailer inventory scenarios demonstrate that our approach significantly improves the cost-service trade-off compared to static information sharing policies, effectively optimizing the schedule of information exchange for cooperative inventory control.",
      "authors": [
        "Sagar Sudhakara and Yuchong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:39:44+00:00",
          "link": "https://arxiv.org/abs/2507.09223v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Coordinated Communication and Inventory Optimization in Multi-Retailer Supply Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09223",
        "HTML": "https://arxiv.org/html/2507.09223v1",
        "PDF": "https://arxiv.org/pdf/2507.09223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with optimizing communication and inventory strategies in a supply chain, without any discussion of LLM training data processing or data engineering methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09257",
      "abstract": "These days, post-quantum cryptography based on the lattice isomorphism problem has been proposed. Ducas-Gibbons introduced the hull attack, which solves the lattice isomorphism problem for lattices obtained by Construction A from an LCD code over a finite field. Using this attack, they showed that the lattice isomorphism problem for such lattices can be reduced to the lattice isomorphism problem with the trivial lattice $\\mathbb{Z}^n$ and the graph isomorphism problem. While the previous work by Ducas-Gibbons only considered lattices constructed by a code over a \\textit{finite field}, this paper considers lattices constructed by a code over a \\textit{finite ring} $\\mathbb{Z}/k\\mathbb{Z}$, which is a more general case. In particular, when $k$ is odd, an odd prime power, or not divisible by $4$, we show that the lattice isomorphism problem can be reduced to the lattice isomorphism problem for $\\mathbb{Z}^n$ and the graph isomorphism problem.",
      "authors": [
        "Yusaku Nishimura",
        "Katsuyuki Takashima",
        "Tsuyoshi Miezaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:33:38+00:00",
          "link": "https://arxiv.org/abs/2507.09257v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "On Lattice Isomorphism Problems for Lattices from LCD Codes over Finite Rings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09257",
        "HTML": "https://arxiv.org/html/2507.09257v1",
        "PDF": "https://arxiv.org/pdf/2507.09257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with lattice isomorphism problems in cryptography and does not relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10334",
      "abstract": "Motion capture (MoCap) data from wearable Inertial Measurement Units (IMUs) is vital for applications in sports science, but its utility is often compromised by missing data. Despite numerous imputation techniques, a systematic performance evaluation for IMU-derived MoCap time-series data is lacking. We address this gap by conducting a comprehensive comparative analysis of statistical, machine learning, and deep learning imputation methods. Our evaluation considers three distinct contexts: univariate time-series, multivariate across subjects, and multivariate across kinematic angles. To facilitate this benchmark, we introduce the first publicly available MoCap dataset designed specifically for imputation, featuring data from 53 karate practitioners. We simulate three controlled missingness mechanisms: missing completely at random (MCAR), block missingness, and a novel value-dependent pattern at signal transition points. Our experiments, conducted on 39 kinematic variables across all subjects, reveal that multivariate imputation frameworks consistently outperform univariate approaches, particularly for complex missingness. For instance, multivariate methods achieve up to a 50% mean absolute error reduction (MAE from 10.8 to 5.8) compared to univariate techniques for transition point missingness. Advanced models like Generative Adversarial Imputation Networks (GAIN) and Iterative Imputers demonstrate the highest accuracy in these challenging scenarios. This work provides a critical baseline for future research and offers practical recommendations for improving the integrity and robustness of Mo-Cap data analysis.",
      "authors": [
        "Mahmoud Bekhit",
        "Ahmad Salah",
        "Ahmed Salim Alrawahi",
        "Tarek Attia",
        "Ahmed Ali",
        "Esraa Eldesokey",
        "Ahmed Fathalla"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:41:19+00:00",
          "link": "https://arxiv.org/abs/2507.10334v1",
          "size": "286kb",
          "version": "v1"
        }
      ],
      "title": "MoCap-Impute: A Comprehensive Benchmark and Comparative Analysis of Imputation Methods for IMU-based Motion Capture Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10334",
        "HTML": "https://arxiv.org/html/2507.10334v1",
        "PDF": "https://arxiv.org/pdf/2507.10334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around the benchmarking and analysis of imputation methods for motion capture data, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.16647",
      "abstract": "Estimation of the optical properties of scattering media such as tissue is important in diagnostics as well as in the development of techniques to image deeper. As light penetrates the sample scattering events occur that alter the propagation direction of the photons in a random manner leading degradation of image quality. The distribution of the scattered light does, however, give a measure of the optical properties such as the reduced scattering coefficient and the absorption coefficient. Unfortunately, inverting scattering patterns to recover the optical properties is not simple especially in the regime where the light is partially randomized. Machine learning has been proposed by several authors as a means of recovering these properties from either the back scattered or the transmitted light. In the present paper we train a general purpose convolutional neural network RESNET 50 with simulated data based on Monte Carlo simulations. We show that compared with previous work our approach gives comparable or better reconstruction accuracy with training on a much smaller dataset. Moreover, by training on multiple parameters such as the intensity distribution at multiple planes or the exit angle and spatial distribution one achieves improved performance compared to training on a single input such as the intensity distribution captured at the sample surface. While our approach gives good parameter reconstruction, we identify factors that limit accuracy of the recovered properties, particularly the absorption coefficient. In the light of these limitations, we suggest how the present approach may be enhanced for even better performance.",
      "authors": [
        "Bowen Deng",
        "Yihan Zhang",
        "Andrew Parkes",
        "Alex Bentley",
        "Amanda Wright",
        "Michael Pound",
        "Michael Somekh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-25T14:36:00+00:00",
          "link": "https://arxiv.org/abs/2404.16647v1",
          "size": "383kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:01:55+00:00",
          "link": "https://arxiv.org/abs/2404.16647v2",
          "size": "421kb",
          "version": "v2"
        }
      ],
      "title": "Application of RESNET50 Convolution Neural Network for the Extraction of Optical Parameters in Scattering Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16647",
        "PDF": "https://arxiv.org/pdf/2404.16647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research here focuses on using a neural network for extracting optical parameters in scattering media, which involves different data processing unrelated to LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.06501",
      "abstract": "Localization using a single range anchor combined with onboard optical-inertial odometry offers a lightweight solution that provides multidimensional measurements for the positioning of unmanned aerial vehicles. Unfortunately, the performance of such lightweight sensors varies with the dynamic environment, and the fidelity of the dynamic model is also severely affected by environmental aerial flow. To address this challenge, we propose an adaptive sliding window estimator equipped with an estimation reliability evaluator, where the states, noise covariance matrices and aerial drag are estimated simultaneously. The aerial drag effects are first evaluated based on posterior states and covariance. Then, an augmented Kalman filter is designed to pre-process multidimensional measurements and inherit historical information. Subsequently, an inverse-Wishart smoother is employed to estimate posterior states and covariance matrices. To further suppress potential divergence, a reliability evaluator is devised to infer estimation errors. We further determine the fidelity of each sensor based on the error propagation. Extensive experiments are conducted in both standard and harsh environments, demonstrating the adaptability and robustness of the proposed method. The root mean square error reaches 0.15 m, outperforming the state-of-the-art approach. Real-world close-loop control experiments are additionally performed to verify the estimator's competence in practical application.",
      "authors": [
        "Kaiwen Xiong",
        "Sijia Chen",
        "Wei Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T13:34:53+00:00",
          "link": "https://arxiv.org/abs/2409.06501v1",
          "size": "6373kb",
          "version": "v1"
        },
        {
          "date": "2024-09-13T09:26:46+00:00",
          "link": "https://arxiv.org/abs/2409.06501v2",
          "size": "6373kb",
          "version": "v2"
        },
        {
          "date": "2025-01-13T09:53:48+00:00",
          "link": "https://arxiv.org/abs/2409.06501v3",
          "size": "4744kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T11:10:13+00:00",
          "link": "https://arxiv.org/abs/2409.06501v4",
          "size": "5422kb",
          "version": "v4"
        }
      ],
      "title": "An Adaptive Sliding Window Estimator for Positioning of Unmanned Aerial Vehicle Using a Single Anchor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06501",
        "HTML": "https://arxiv.org/html/2409.06501v4",
        "PDF": "https://arxiv.org/pdf/2409.06501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the localization and positioning of unmanned aerial vehicles using sensors and estimators. It does not discuss LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.23929",
      "abstract": "A new disturbance observer based control scheme is developed for a quadrotor under the concurrent disturbances from a lightweight elastic tether cable and a lumped vertical disturbance. This elastic tether is unusual as it creates a disturbance proportional to the multicopter's translational movement. This paper takes an observer-based approach to estimate the stiffness coefficient of the cable and uses the system model to update the estimates of the external forces, which are then compensated in the control action. Given that the tethered cable force affects both horizontal channels of the quadrotor and is also coupled with the vertical channel, the proposed disturbance observer is constructed to exploit the redundant measurements across all three channels to jointly estimate the cable stiffness and the vertical disturbance. A pseudo-inverse method is used to determine the observer gain functions, such that the estimation of the two quantities is decoupled and stable. Compared to standard disturbance observers which assume nearly constant disturbances, the proposed approach can quickly adjust its total force estimate as the tethered quadrotor changes its position or tautness of the tether. This is applied to two experiments - a tracking performance test where the multicopter moves under a constant tether strain, and an object extraction test. In the second test, the multicopter manipulates a nonlinear mechanism mimicking the extraction of a wedged object. In both cases, the proposed approach shows significant improvement over standard Disturbance Observer and Extended State Observer approaches. A video summary of the experiments can be found at https://youtu.be/9gKr13WTj-k.",
      "authors": [
        "Benjamin J. Marshall",
        "Yunda Yan",
        "James Knowles",
        "Chenguang Yang",
        "Cunjia Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T13:36:04+00:00",
          "link": "https://arxiv.org/abs/2410.23929v1",
          "size": "11698kb",
          "version": "v1"
        }
      ],
      "title": "Redundant Observer-Based Tracking Control for Object Extraction Using a Cable Connected UAV",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23929",
        "HTML": "https://arxiv.org/html/2410.23929",
        "PDF": "https://arxiv.org/pdf/2410.23929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a control scheme for UAVs and does not relate to LLM training data processing at all."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.18564",
      "abstract": "Robotic manipulation systems operating in diverse, dynamic environments must exhibit three critical abilities: multitask interaction, generalization to unseen scenarios, and spatial memory. While significant progress has been made in robotic manipulation, existing approaches often fall short in generalization to complex environmental variations and addressing memory-dependent tasks. To bridge this gap, we introduce SAM2Act, a multi-view robotic transformer-based policy that leverages multi-resolution upsampling with visual representations from large-scale foundation model. SAM2Act achieves a state-of-the-art average success rate of 86.8% across 18 tasks in the RLBench benchmark, and demonstrates robust generalization on The Colosseum benchmark, with only a 4.3% performance gap under diverse environmental perturbations. Building on this foundation, we propose SAM2Act+, a memory-based architecture inspired by SAM2, which incorporates a memory bank, an encoder, and an attention mechanism to enhance spatial memory. To address the need for evaluating memory-dependent tasks, we introduce MemoryBench, a novel benchmark designed to assess spatial memory and action recall in robotic manipulation. SAM2Act+ achieves an average success rate of 94.3% on memory-based tasks in MemoryBench, significantly outperforming existing approaches and pushing the boundaries of memory-based robotic systems. Project page: sam2act.github.io.",
      "authors": [
        "Haoquan Fang",
        "Markus Grotz",
        "Wilbert Pumacay",
        "Yi Ru Wang",
        "Dieter Fox",
        "Ranjay Krishna",
        "Jiafei Duan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T18:37:16+00:00",
          "link": "https://arxiv.org/abs/2501.18564v1",
          "size": "27348kb",
          "version": "v1"
        },
        {
          "date": "2025-02-11T08:33:25+00:00",
          "link": "https://arxiv.org/abs/2501.18564v2",
          "size": "27396kb",
          "version": "v2"
        },
        {
          "date": "2025-06-03T04:39:04+00:00",
          "link": "https://arxiv.org/abs/2501.18564v3",
          "size": "24112kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T17:41:57+00:00",
          "link": "https://arxiv.org/abs/2501.18564v4",
          "size": "24112kb",
          "version": "v4"
        }
      ],
      "title": "SAM2Act: Integrating Visual Foundation Model with A Memory Architecture for Robotic Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18564",
        "HTML": "https://arxiv.org/html/2501.18564v4",
        "PDF": "https://arxiv.org/pdf/2501.18564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on robotic manipulation and memory architecture, with no contributions related to LLM training data processing or dataset creation."
      },
      "datasets": [
        {
          "dataset_name": "hqfang/MemoryBench",
          "downloads": "66",
          "likes": "2",
          "link": "https://huggingface.co/datasets/hqfang/MemoryBench"
        }
      ],
      "repo_urls": [
        "https://github.com/sam2act/sam2act"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09341",
      "abstract": "Vehicular Mobile Edge Computing (VEC) drives the future by enabling low-latency, high-efficiency data processing at the very edge of vehicular networks. This drives innovation in key areas such as autonomous driving, intelligent transportation systems, and real-time analytics. Despite its potential, VEC faces significant challenges, particularly in adhering to strict task offloading deadlines, as vehicles remain within the coverage area of Roadside Units (RSUs) for only brief periods. To tackle this challenge, this paper evaluates the performance boundaries of task processing by initially establishing a theoretical limit using Particle Swarm Optimization (PSO) in a static environment. To address more dynamic and practical scenarios, PSO, Deep Q-Network (DQN), and Proximal Policy Optimization (PPO) models are implemented in an online setting. The objective is to minimize dropped tasks and reduce end-to-end (E2E) latency, covering both communication and computation delays. Experimental results demonstrate that the DQN model considerably surpasses the dynamic PSO approach, achieving a 99.2% reduction in execution time. Furthermore, It leads to a reduction in dropped tasks by 2.5% relative to dynamic PSO and achieves 18.6\\% lower E2E latency, highlighting the effectiveness of Deep Reinforcement Learning (DRL) in enabling scalable and efficient task management for VEC systems.",
      "authors": [
        "Mahsa Paknejad",
        "Parisa Fard Moshiri",
        "Murat Simsek",
        "Burak Kantarci",
        "Hussein T. Mouftah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:40:22+00:00",
          "link": "https://arxiv.org/abs/2507.09341v1",
          "size": "4966kb",
          "version": "v1"
        }
      ],
      "title": "Meeting Deadlines in Motion: Deep RL for Real-Time Task Offloading in Vehicular Edge Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09341",
        "HTML": "https://arxiv.org/html/2507.09341v1",
        "PDF": "https://arxiv.org/pdf/2507.09341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on task offloading in vehicular networks using deep reinforcement learning, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09864",
      "abstract": "Model Predictive Control (MPC)-based Reinforcement Learning (RL) offers a structured and interpretable alternative to Deep Neural Network (DNN)-based RL methods, with lower computational complexity and greater transparency. However, standard MPC-RL approaches often suffer from slow convergence, suboptimal policy learning due to limited parameterization, and safety issues during online adaptation. To address these challenges, we propose a novel framework that integrates MPC-RL with Multi-Objective Bayesian Optimization (MOBO). The proposed MPC-RL-MOBO utilizes noisy evaluations of the RL stage cost and its gradient, estimated via a Compatible Deterministic Policy Gradient (CDPG) approach, and incorporates them into a MOBO algorithm using the Expected Hypervolume Improvement (EHVI) acquisition function. This fusion enables efficient and safe tuning of the MPC parameters to achieve improved closed-loop performance, even under model imperfections. A numerical example demonstrates the effectiveness of the proposed approach in achieving sample-efficient, stable, and high-performance learning for control systems.",
      "authors": [
        "Hossein Nejatbakhsh Esfahani",
        "Javad Mohammadpour Velni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:31:52+00:00",
          "link": "https://arxiv.org/abs/2507.09864v1",
          "size": "375kb",
          "version": "v1"
        }
      ],
      "title": "Intersection of Reinforcement Learning and Bayesian Optimization for Intelligent Control of Industrial Processes: A Safe MPC-based DPG using Multi-Objective BO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09864",
        "HTML": "https://arxiv.org/html/2507.09864v1",
        "PDF": "https://arxiv.org/pdf/2507.09864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel control framework integrating Reinforcement Learning and Bayesian Optimization with no focus on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10182",
      "abstract": "Formal specifications are essential for ensuring software correctness, yet manually writing them is tedious and error-prone. Large Language Models (LLMs) have shown promise in generating such specifications from natural language intents, but the giant model size and high computational demands raise a fundamental question: Do we really need large models for this task? In this paper, we show that a small, fine-tuned language model can achieve high-quality postcondition generation with much lower computational costs. We construct a specialized dataset of prompts, reasoning logs, and postconditions, then supervise the fine-tuning of a $7$B-parameter code model. Our approach tackles real-world repository dependencies and preserves pre-state information, allowing for expressive and accurate specifications. We evaluate the model on a benchmark of real-world Java bugs (Defects4J) and compare against both proprietary giants (e.g., GPT-4o) and open-source large models. Empirical results demonstrate that our compact model matches or outperforms significantly larger counterparts in syntax correctness, semantic correctness, and bug-distinguishing capability. These findings highlight that targeted fine-tuning on a modest dataset can enable small models to achieve results formerly seen only in massive, resource-heavy LLMs, offering a practical and efficient path for the real-world adoption of automated specification generation.",
      "authors": [
        "Gehao Zhang",
        "Zhenting Wang",
        "Juan Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:44:04+00:00",
          "link": "https://arxiv.org/abs/2507.10182v1",
          "size": "1074kb",
          "version": "v1"
        }
      ],
      "title": "Breaking the Myth: Can Small Models Infer Postconditions Too?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10182",
        "HTML": "https://arxiv.org/html/2507.10182v1",
        "PDF": "https://arxiv.org/pdf/2507.10182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning a small model for postcondition generation, mentioning the creation of a specialized dataset but focuses mainly on model performance rather than the data processing aspect."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.00911",
      "abstract": "This paper presents a fast and accurate model of a deformable linear object (DLO) -- e.g., a rope, wire, or cable -- integrated into an established robot physics simulator, MuJoCo. Most accurate DLO models with low computational times exist in standalone numerical simulators, which are unable or require tedious work to handle external objects. Based on an existing state-of-the-art DLO model -- Discrete Elastic Rods (DER) -- our implementation provides an improvement in accuracy over MuJoCo's own native cable model. To minimize computational load, our model utilizes force-lever analysis to adapt the Cartesian stiffness forces of the DER into its generalized coordinates. As a key contribution, we introduce a novel parameter identification pipeline designed for both simplicity and accuracy, which we utilize to determine the bending and twisting stiffness of three distinct DLOs. We then evaluate the performance of each model by simulating the DLOs and comparing them to their real-world counterparts and against theoretically proven validation tests.",
      "authors": [
        "Qi Jing Chen",
        "Timothy Bretl",
        "and Quang-Cuong Pham"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-02T05:55:51+00:00",
          "link": "https://arxiv.org/abs/2310.00911v1",
          "size": "15216kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T06:24:39+00:00",
          "link": "https://arxiv.org/abs/2310.00911v2",
          "size": "4490kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T09:26:04+00:00",
          "link": "https://arxiv.org/abs/2310.00911v3",
          "size": "3749kb",
          "version": "v3"
        }
      ],
      "title": "Accurate Simulation and Parameter Identification of Deformable Linear Objects using Discrete Elastic Rods in Generalized Coordinates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.00911",
        "HTML": "https://arxiv.org/html/2310.00911v3",
        "PDF": "https://arxiv.org/pdf/2310.00911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses a simulation model for deformable linear objects and does not focus on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04681",
      "abstract": "Colorectal cancer (CRC) is the third most diagnosed cancer and the second leading cause of cancer-related death worldwide. Accurate histopathological grading of CRC is essential for prognosis and treatment planning but remains a subjective process prone to observer variability and limited by global shortages of trained pathologists. To promote automated and standardized solutions, we organized the ICIP Grand Challenge on Colorectal Cancer Tumor Grading and Segmentation using the publicly available METU CCTGS dataset. The dataset comprises 103 whole-slide images with expert pixel-level annotations for five tissue classes. Participants submitted segmentation masks via Codalab, evaluated using metrics such as macro F-score and mIoU. Among 39 participating teams, six outperformed the Swin Transformer baseline (62.92 F-score). This paper presents an overview of the challenge, dataset, and the top-performing methods",
      "authors": [
        "Alper Bahcekapili",
        "Duygu Arslan",
        "Umut Ozdemir",
        "Berkay Ozkirli",
        "Emre Akbas",
        "Ahmet Acar",
        "Gozde B. Akar",
        "Bingdou He",
        "Shuoyu Xu",
        "Umit Mert Caglar",
        "Alptekin Temizel",
        "Guillaume Picaud",
        "Marc Chaumont",
        "G\\'erard Subsol",
        "Luc T\\'eot",
        "Fahad Alsharekh",
        "Shahad Alghannam",
        "Hexiang Mao",
        "Wenhua Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T05:59:16+00:00",
          "link": "https://arxiv.org/abs/2507.04681v1",
          "size": "899kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T07:18:54+00:00",
          "link": "https://arxiv.org/abs/2507.04681v2",
          "size": "899kb",
          "version": "v2"
        }
      ],
      "title": "Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology Images: From Giga to Mini Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04681",
        "HTML": "https://arxiv.org/html/2507.04681v2",
        "PDF": "https://arxiv.org/pdf/2507.04681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a challenge involving colorectal cancer histopathology image segmentation. It does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05806",
      "abstract": "Many dynamic processes such as telecommunication and transport networks can be described through discrete time series of graphs. Modelling the dynamics of such time series enables prediction of graph structure at future time steps, which can be used in applications such as detection of anomalies. Existing approaches for graph prediction have limitations such as assuming that the vertices do not to change between consecutive graphs. To address this, we propose to exploit time series prediction methods in combination with an adapted form of flux balance analysis (FBA), a linear programming method originating from biochemistry. FBA is adapted to incorporate various constraints applicable to the scenario of growing graphs. Empirical evaluations on synthetic datasets (constructed via Preferential Attachment model) and real datasets (UCI Message, HePH, Facebook, Bitcoin) demonstrate the efficacy of the proposed approach.",
      "authors": [
        "Sevvandi Kandanaarachchi",
        "Ziqi Xu",
        "Stefan Westerlund",
        "Conrad Sanderson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T09:25:51+00:00",
          "link": "https://arxiv.org/abs/2507.05806v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.05806v2",
          "size": "113kb",
          "version": "v2"
        }
      ],
      "title": "Predicting Graph Structure via Adapted Flux Balance Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05806",
        "HTML": "https://arxiv.org/html/2507.05806v2",
        "PDF": "https://arxiv.org/pdf/2507.05806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses graph structure prediction using adapted flux balance analysis for dynamic processes, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09067",
      "abstract": "The emergence of quantum computing presents profound challenges to existing cryptographic infrastructures, whilst the development of central bank digital currencies (CBDCs) has raised concerns regarding privacy preservation and excessive centralisation in digital payment systems. This paper proposes the Quantum-Resilient Privacy Ledger (QRPL) as an innovative token-based digital currency architecture that incorporates National Institute of Standards and Technology (NIST)-standardised post-quantum cryptography (PQC) with hash-based zero-knowledge proofs to ensure user sovereignty, scalability, and transaction confidentiality. Key contributions include adaptations of ephemeral proof chains for unlinkable transactions, a privacy-weighted Proof-of-Stake (PoS) consensus to promote equitable participation, and a novel zero-knowledge proof-based mechanism for privacy-preserving selective disclosure. QRPL aims to address critical shortcomings in prevailing CBDC designs, including risks of pervasive surveillance, with a 10-20 second block time to balance security and throughput in future monetary systems. While conceptual, empirical prototypes are planned. Future work includes prototype development to validate these models empirically.",
      "authors": [
        "Serhan W. Bahar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.09067v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "Quantum-Resilient Privacy Ledger (QRPL): A Sovereign Digital Currency for the Post-Quantum Era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09067",
        "HTML": "https://arxiv.org/html/2507.09067v1",
        "PDF": "https://arxiv.org/pdf/2507.09067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a digital currency architecture using post-quantum cryptography, which is unrelated to any aspects of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09180",
      "abstract": "Depth information is robust to scene appearance variations and inherently carries 3D spatial details. In this paper, a visual backbone based on the vision transformer is proposed to fuse RGB and depth modalities for enhancing generalization. Different modalities are first processed by separate CNN stems, and the combined convolutional features are delivered to the scalable vision transformer to obtain visual representations. Moreover, a contrastive unsupervised learning scheme is designed with masked and unmasked tokens to accelerate the sample efficiency during the reinforcement learning progress. For sim2real transfer, a flexible curriculum learning schedule is developed to deploy domain randomization over training processes.",
      "authors": [
        "Zichun Xu",
        "Yuntao Li",
        "Zhaomin Wang",
        "Lei Zhuang",
        "Guocai Yang",
        "and Jingdong Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.09180v1",
          "size": "308kb",
          "version": "v1"
        }
      ],
      "title": "Learning and Transferring Better with Depth Information in Visual Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09180",
        "HTML": "https://arxiv.org/html/2507.09180v1",
        "PDF": "https://arxiv.org/pdf/2507.09180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing visual reinforcement learning using depth information and does not contribute to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09529",
      "abstract": "With the growing threat of software vulnerabilities, deep learning (DL)-based detectors have gained popularity for vulnerability detection. However, doubts remain regarding their consistency within declared CWE ranges, real-world effectiveness, and applicability across scenarios. These issues may lead to unreliable detection, high false positives/negatives, and poor adaptability to emerging vulnerabilities. A comprehensive analysis is needed to uncover critical factors affecting detection and guide improvements in model design and deployment. In this paper, we present VulTegra, a novel evaluation framework that conducts a multidimensional comparison of scratch-trained and pre-trained-based DL models for vulnerability detection. VulTegra reveals that state-of-the-art (SOTA) detectors still suffer from low consistency, limited real-world capabilities, and scalability challenges. Contrary to common belief, pre-trained models are not consistently better than scratch-trained models but exhibit distinct strengths in specific contexts.Importantly, our study exposes the limitations of relying solely on CWE-based classification and identifies key factors that significantly affect model performance. Experimental results show that adjusting just one such factor consistently improves recall across all seven evaluated detectors, with six also achieving better F1 scores. Our findings provide deeper insights into model behavior and emphasize the need to consider both vulnerability types and inherent code features for effective detection.",
      "authors": [
        "Yunqian Wang",
        "Xiaohong Li",
        "Yao Zhang",
        "Yuekang Li",
        "Zhiping Zhou",
        "Ruitao Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:02:56+00:00",
          "link": "https://arxiv.org/abs/2507.09529v1",
          "size": "3683kb",
          "version": "v1"
        }
      ],
      "title": "It Only Gets Worse: Revisiting DL-Based Vulnerability Detectors from a Practical Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09529",
        "PDF": "https://arxiv.org/pdf/2507.09529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the evaluation of DL-based vulnerability detectors and does not involve any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09847",
      "abstract": "Achieving carbon neutrality, a key focus of UN SDG #13, drives the exploration of wave energy, a renewable resource with the potential to generate 30,000 TWh of clean electricity annually, surpassing global demand. However, wave energy remains underdeveloped due to technical and economic challenges, particularly in forecasting wave farm power output, which is vital for grid stability and commercial viability. This study proposes a novel predictive framework to enhance wave energy integration into power grids. It introduces a hybrid sequential learning model combining Self-Attention-enhanced Convolutional Bi-LSTM with hyperparameter optimization. The model leverages spatial data from Wave Energy Converters (WECs) and is validated using datasets from wave farms in Adelaide, Sydney, Perth, and Tasmania, Australia. Benchmarked against ten machine learning algorithms, the model achieves superior accuracy, with R2 scores of 91.7% (Adelaide), 88.0% (Perth), 82.8% (Tasmania), and 91.0% (Sydney). It outperforms conventional ML and deep learning methods, offering robust and scalable predictions for wave energy output across diverse marine environments, supporting reliable integration into energy systems.",
      "authors": [
        "Amin Abdollahi Dehkordi",
        "Mehdi Neshat",
        "Nataliia Y. Sergiienko",
        "Zahra Ghasemi",
        "Lei Chen",
        "John Boland",
        "Hamid Moradkhani",
        "and Amir H. Gandomi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.09847v1",
          "size": "4156kb",
          "version": "v1"
        }
      ],
      "title": "Effective Self-Attention-Based Deep Learning Model with Evolutionary Grid Search for Robust Wave Farm Energy Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09847",
        "HTML": "https://arxiv.org/html/2507.09847v1",
        "PDF": "https://arxiv.org/pdf/2507.09847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses wave energy forecasting systems and does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09861",
      "abstract": "Visually-Rich Document Understanding (VRDU) has emerged as a critical field, driven by the need to automatically process documents containing complex visual, textual, and layout information. Recently, Multimodal Large Language Models (MLLMs) have shown remarkable potential in this domain, leveraging both Optical Character Recognition (OCR)-dependent and OCR-free frameworks to extract and interpret information in document images. This survey reviews recent advancements in MLLM-based VRDU, highlighting three core components: (1) methods for encoding and fusing textual, visual, and layout features; (2) training paradigms, including pretraining strategies, instruction-response tuning, and the trainability of different model modules; and (3) datasets utilized for pretraining, instruction-tuning, and supervised fine-tuning. Finally, we discuss the challenges and opportunities in this evolving field and propose future directions to advance the efficiency, generalizability, and robustness of VRDU systems.",
      "authors": [
        "Yihao Ding",
        "Siwen Luo",
        "Yue Dai",
        "Yanbei Jiang",
        "Zechuan Li",
        "Geoffrey Martin and Yifan Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:10:31+00:00",
          "link": "https://arxiv.org/abs/2507.09861v1",
          "size": "7347kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on MLLM-based Visually Rich Document Understanding: Methods, Challenges, and Emerging Trends",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09861",
        "HTML": "https://arxiv.org/html/2507.09861v1",
        "PDF": "https://arxiv.org/pdf/2507.09861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses MLLM-based document understanding and touches on datasets used for pretraining, its primary focus is on methods, training paradigms, and challenges in the field, not on new techniques for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10170",
      "abstract": "Tensor Network (TN) decompositions have emerged as an indispensable tool in Big Data analytics owing to their ability to provide compact low-rank representations, thus alleviating the ``Curse of Dimensionality'' inherent in handling higher-order data. At the heart of their success lies the concept of TN ranks, which governs the efficiency and expressivity of TN decompositions. However, unlike matrix ranks, TN ranks often lack a universal meaning and an intuitive interpretation, with their properties varying significantly across different TN structures. Consequently, TN ranks are frequently treated as empirically tuned hyperparameters, rather than as key design parameters inferred from domain knowledge. The aim of this Lecture Note is therefore to demystify the foundational yet frequently misunderstood concept of TN ranks through real-life examples and intuitive visualizations. We begin by illustrating how domain knowledge can guide the selection of TN ranks in widely-used models such as the Canonical Polyadic (CP) and Tucker decompositions. For more complex TN structures, we employ a self-explanatory graphical approach that generalizes to tensors of arbitrary order. Such a perspective naturally reveals the relationship between TN ranks and the corresponding ranks of tensor unfoldings (matrices), thereby circumventing cumbersome multi-index tensor algebra while facilitating domain-informed TN design. It is our hope that this Lecture Note will equip readers with a clear and unified understanding of the concept of TN rank, along with the necessary physical insight and intuition to support the selection, explainability, and deployment of tensor methods in both practical applications and educational contexts.",
      "authors": [
        "Wuyang Zhou",
        "Giorgos Iacovides",
        "Kriton Konstantinidis",
        "Ilya Kisil",
        "Danilo Mandic"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:33:14+00:00",
          "link": "https://arxiv.org/abs/2507.10170v1",
          "size": "23872kb",
          "version": "v1"
        }
      ],
      "title": "Understanding the Rank of Tensor Networks via an Intuitive Example-Driven Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10170",
        "HTML": "https://arxiv.org/html/2507.10170v1",
        "PDF": "https://arxiv.org/pdf/2507.10170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on explaining TN ranks and their role in tensor decompositions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10265",
      "abstract": "Camera pose estimation is a fundamental computer vision task that is essential for applications like visual localization and multi-view stereo reconstruction. In the object-centric scenarios with sparse inputs, the accuracy of pose estimation can be significantly influenced by background textures that occupy major portions of the images across different viewpoints. In light of this, we introduce the Kaleidoscopic Background Attack (KBA), which uses identical segments to form discs with multi-fold radial symmetry. These discs maintain high similarity across different viewpoints, enabling effective attacks on pose estimation models even with natural texture segments. Additionally, a projected orientation consistency loss is proposed to optimize the kaleidoscopic segments, leading to significant enhancement in the attack effectiveness. Experimental results show that optimized adversarial kaleidoscopic backgrounds can effectively attack various camera pose estimation models.",
      "authors": [
        "Xinlong Ding",
        "Hongwei Yu",
        "Jiawei Li",
        "Feifan Li",
        "Yu Shang",
        "Bochao Zou",
        "Huimin Ma",
        "and Jiansheng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:37:31+00:00",
          "link": "https://arxiv.org/abs/2507.10265v1",
          "size": "16257kb",
          "version": "v1"
        }
      ],
      "title": "Kaleidoscopic Background Attack: Disrupting Pose Estimation with Multi-Fold Radial Symmetry Textures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10265",
        "HTML": "https://arxiv.org/html/2507.10265v1",
        "PDF": "https://arxiv.org/pdf/2507.10265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes an attack method on camera pose estimation models; it does not involve LLM training data processing or modifications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10411",
      "abstract": "Agentic Retrieval-Augmented Generation (RAG) is a new paradigm where the reasoning model decides when to invoke a retriever (as a \"tool\") when answering a question. This paradigm, exemplified by recent research works such as Search-R1, enables the model to decide when to search and obtain external information. However, the queries generated by such Agentic RAG models and the role of the retriever in obtaining high-quality answers remain understudied. To this end, this initial study examines the applicability of query performance prediction (QPP) within the recent Agentic RAG models Search-R1 and R1-Searcher. We find that applying effective retrievers can achieve higher answer quality within a shorter reasoning process. Moreover, the QPP estimates of the generated queries, used as an approximation of their retrieval quality, are positively correlated with the quality of the final answer. Ultimately, our work is a step towards adaptive retrieval within Agentic RAG, where QPP is used to inform the model if the retrieved results are likely to be useful.",
      "authors": [
        "Fangzheng Tian",
        "Jinyuan Fang",
        "Debasis Ganguly",
        "Zaiqiao Meng and Craig Macdonald"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:54:50+00:00",
          "link": "https://arxiv.org/abs/2507.10411v1",
          "size": "239kb",
          "version": "v1"
        }
      ],
      "title": "Am I on the Right Track? What Can Predicted Query Performance Tell Us about the Search Behaviour of Agentic RAG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10411",
        "HTML": "https://arxiv.org/html/2507.10411v1",
        "PDF": "https://arxiv.org/pdf/2507.10411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates agentic RAG models and query performance prediction, but there is no discussion on LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22589",
      "abstract": "Text on historical maps provides valuable information for studies in history, economics, geography, and other related fields. Unlike structured or semi-structured documents, text on maps varies significantly in orientation, reading order, shape, and placement. Many modern methods can detect and transcribe text regions, but they struggle to effectively ``link'' the recognized text fragments, e.g., determining a multi-word place name. Existing layout analysis methods model word relationships to improve text understanding in structured documents, but they primarily rely on linguistic features and neglect geometric information, which is essential for handling map text. To address these challenges, we propose LIGHT, a novel multi-modal approach that integrates linguistic, image, and geometric features for linking text on historical maps. In particular, LIGHT includes a geometry-aware embedding module that encodes the polygonal coordinates of text regions to capture polygon shapes and their relative spatial positions on an image. LIGHT unifies this geometric information with the visual and linguistic token embeddings from LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal information to predict the reading-order successor of each text instance directly with a bi-directional learning strategy that enhances sequence robustness. Experimental results show that LIGHT outperforms existing methods on the ICDAR 2024/2025 MapText Competition data, demonstrating the effectiveness of multi-modal learning for historical map text linking.",
      "authors": [
        "Yijun Lin",
        "Rhett Olson",
        "Junhan Wu",
        "Yao-Yi Chiang and Jerod Weinman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:18:00+00:00",
          "link": "https://arxiv.org/abs/2506.22589v1",
          "size": "28703kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T21:42:18+00:00",
          "link": "https://arxiv.org/abs/2506.22589v2",
          "size": "37084kb",
          "version": "v2"
        }
      ],
      "title": "LIGHT: Multi-Modal Text Linking on Historical Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22589",
        "HTML": "https://arxiv.org/html/2506.22589v2",
        "PDF": "https://arxiv.org/pdf/2506.22589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a multi-modal approach for linking text on historical maps, focusing on multi-modal learning techniques rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08882",
      "abstract": "Air traffic control (ATC) demands multi-tasking under time pressure with high consequences of an error. This can induce stress. Detecting stress is a key point in maintaining the high safety standards of ATC. However, processing ATC voice data entails privacy restrictions, e.g. the General Data Protection Regulation (GDPR) law. Anonymizing the ATC voice data is one way to comply with these restrictions. In this paper, different architectures for stress detection for anonymized ATCO speech are evaluated. Our best networks reach a stress detection accuracy of 93.6% on an anonymized version of the Speech Under Simulated and Actual Stress (SUSAS) dataset and an accuracy of 80.1% on our anonymized ATC simulation dataset. This shows that privacy does not have to be an impediment in building well-performing deep-learning-based models.",
      "authors": [
        "Janaki Viswanathan",
        "Alexander Blatt",
        "Konrad Hagemann and Dietrich Klakow"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:48:29+00:00",
          "link": "https://arxiv.org/abs/2507.08882v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "Less Stress, More Privacy: Stress Detection on Anonymized Speech of Air Traffic Controllers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08882",
        "PDF": "https://arxiv.org/pdf/2507.08882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates stress detection architectures using anonymized speech data, which involves privacy and stress detection in ATC, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08972",
      "abstract": "Turbulent fluid flows are among the most computationally demanding problems in science, requiring enormous computational resources that become prohibitive at high flow speeds. Physics-informed neural networks (PINNs) represent a radically different approach that trains neural networks directly from physical equations rather than data, offering the potential for continuous, mesh-free solutions. Here we show that appropriately designed PINNs can successfully simulate fully turbulent flows in both two and three dimensions, directly learning solutions to the fundamental fluid equations without traditional computational grids or training data. Our approach combines several algorithmic innovations including adaptive network architectures, causal training, and advanced optimization methods to overcome the inherent challenges of learning chaotic dynamics. Through rigorous validation on challenging turbulence problems, we demonstrate that PINNs accurately reproduce key flow statistics including energy spectra, kinetic energy, enstrophy, and Reynolds stresses. Our results demonstrate that neural equation solvers can handle complex chaotic systems, opening new possibilities for continuous turbulence modeling that transcends traditional computational limitations.",
      "authors": [
        "Sifan Wang",
        "Shyam Sankaran",
        "Panos Stinis",
        "Paris Perdikaris"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computational Physics (physics.comp-ph)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:02:52+00:00",
          "link": "https://arxiv.org/abs/2507.08972v1",
          "size": "9797kb",
          "version": "v1"
        }
      ],
      "title": "Simulating Three-dimensional Turbulence with Physics-informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08972",
        "HTML": "https://arxiv.org/html/2507.08972v1",
        "PDF": "https://arxiv.org/pdf/2507.08972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on simulating turbulence using physics-informed neural networks and does not address any aspects of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09183",
      "abstract": "Few-Shot Class-Incremental Learning (FSCIL) faces dual challenges of data scarcity and incremental learning in real-world scenarios. While pool-based prompting methods have demonstrated success in traditional incremental learning, their effectiveness in FSCIL settings remains unexplored. This paper presents the first study of current prompt pool methods in FSCIL tasks, revealing an unanticipated performance degradation in incremental sessions. Through comprehensive analysis, we identify that this phenomenon stems from token-dimension saturation: with limited data, excessive prompts compete for task-relevant information, leading to model overfitting. Based on this finding, we propose LGSP-Prompt (Local-Global Spatial Prompting), which innovatively shifts pool-based prompt learning from the token dimension to the spatial dimension. LGSP-Prompt generates spatial prompts by synergistically combining local spatial features and global frequency-domain representations to highlight key patterns in input images. We construct two spatial prompt pools enabling dynamic prompt selection to maintain acquired knowledge while effectively learning novel sessions. Extensive experiments demonstrate that our approach achieves state-of-the-art performance across multiple FSCIL benchmarks, showing significant advantages in both base knowledge preservation and incremental learning. Our implementation is available at https://github.com/Jywsuperman/LGSP.",
      "authors": [
        "Yongwei Jiang",
        "Yixiong Zou",
        "Yuhua Li",
        "Ruixuan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:08:34+00:00",
          "link": "https://arxiv.org/abs/2507.09183v1",
          "size": "29714kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Pool-based Prompt Learning for Few-shot Class-incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09183",
        "HTML": "https://arxiv.org/html/2507.09183v1",
        "PDF": "https://arxiv.org/pdf/2507.09183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses few-shot class-incremental learning with a focus on pool-based prompting methods, primarily dealing with model architecture rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09830",
      "abstract": "Both humans and deep learning models can recognize objects from 3D shapes depicted with sparse visual information, such as a set of points randomly sampled from the surfaces of 3D objects (termed a point cloud). Although deep learning models achieve human-like performance in recognizing objects from 3D shapes, it remains unclear whether these models develop 3D shape representations similar to those used by human vision for object recognition. We hypothesize that training with 3D shapes enables models to form representations of local geometric structures in 3D shapes. However, their representations of global 3D object shapes may be limited. We conducted two human experiments systematically manipulating point density and object orientation (Experiment 1), and local geometric structure (Experiment 2). Humans consistently performed well across all experimental conditions. We compared two types of deep learning models, one based on a convolutional neural network (DGCNN) and the other on visual transformers (point transformer), with human performance. We found that the point transformer model provided a better account of human performance than the convolution-based model. The advantage mainly results from the mechanism in the point transformer model that supports hierarchical abstraction of 3D shapes.",
      "authors": [
        "Shuhao Fu",
        "Philip J. Kellman",
        "Hongjing Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:54:45+00:00",
          "link": "https://arxiv.org/abs/2507.09830v1",
          "size": "417kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Abstraction Enables Human-Like 3D Object Recognition in Deep Learning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09830",
        "PDF": "https://arxiv.org/pdf/2507.09830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on 3D object recognition in deep learning models and comparisons with human performance, without any mention of LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09898",
      "abstract": "This study investigates the effectiveness of U-Net architectures integrated with various convolutional neural network (CNN) backbones for automated lung cancer detection and segmentation in chest CT images, addressing the critical need for accurate diagnostic tools in clinical settings. A balanced dataset of 832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed using Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to 128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50, VGG16, and Xception, to segment lung regions. After segmentation, CNN-based classifiers and hybrid models combining CNN feature extraction with traditional machine learning classifiers (Support Vector Machine, Random Forest, and Gradient Boosting) were evaluated using 5-fold cross-validation. Metrics included accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC. U-Net with ResNet50 achieved the best performance for cancerous lungs (Dice: 0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for non-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For classification, the CNN model using U-Net with Xception achieved 99.1 percent accuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid CNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent F1-score. Compared to prior methods, our framework consistently outperformed existing models. In conclusion, combining U-Net with advanced CNN backbones provides a powerful method for both segmentation and classification of lung cancer in CT scans, supporting early diagnosis and clinical decision-making.",
      "authors": [
        "Alireza Golkarieha",
        "Kiana Kiashemshakib",
        "Sajjad Rezvani Boroujenic",
        "Nasibeh Asadi Isakand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:08:33+00:00",
          "link": "https://arxiv.org/abs/2507.09898v1",
          "size": "2402kb",
          "version": "v1"
        }
      ],
      "title": "Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09898",
        "HTML": "https://arxiv.org/html/2507.09898v1",
        "PDF": "https://arxiv.org/pdf/2507.09898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates U-Net architectures for cancer detection in CT images, emphasizing model performance and architectural improvements, and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09968",
      "abstract": "Machine learning (ML) techniques have recently gained significant attention for solving compliance minimization (CM) problems. However, these methods typically provide poor feature boundaries, are very expensive, and lack a systematic mechanism to control the design complexity. Herein, we address these limitations by proposing a mesh-free and simultaneous framework based on physics-informed Gaussian processes (GPs). In our approach, we parameterize the design and state variables with GP priors which have independent kernels but share a multi-output neural network (NN) as their mean function. The architecture of this NN is based on Parametric Grid Convolutional Attention Networks (PGCANs) which not only mitigate spectral bias issues, but also provide an interpretable mechanism to control design complexity. We estimate all the parameters of our GP-based representations by simultaneously minimizing the compliance, total potential energy, and residual of volume fraction constraint. Importantly, our loss function exclude all data-based residuals as GPs automatically satisfy them. We also develop computational schemes based on curriculum training and numerical integration to increase the efficiency and robustness of our approach which is shown to (1) produce super-resolution topologies with fast convergence, (2) achieve smaller compliance and less gray area fraction compared to traditional numerical methods, (3) provide control over fine-scale features, and (4) outperform competing ML-based methods.",
      "authors": [
        "Xiangyu Sun",
        "Amin Yousefpour",
        "Shirin Hosseinmardi",
        "Ramin Bostanabad"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:34:29+00:00",
          "link": "https://arxiv.org/abs/2507.09968v1",
          "size": "41470kb",
          "version": "v1"
        }
      ],
      "title": "Compliance Minimization via Physics-Informed Gaussian Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09968",
        "HTML": "https://arxiv.org/html/2507.09968v1",
        "PDF": "https://arxiv.org/pdf/2507.09968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses compliance minimization using physics-informed Gaussian processes, focusing on ML method improvements, and does not relate to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10053",
      "abstract": "This paper introduces CoSMo, a novel multimodal Transformer for Page Stream Segmentation (PSS) in comic books, a critical task for automated content understanding, as it is a necessary first stage for many downstream tasks like character analysis, story indexing, or metadata enrichment. We formalize PSS for this unique medium and curate a new 20,800-page annotated dataset. CoSMo, developed in vision-only and multimodal variants, consistently outperforms traditional baselines and significantly larger general-purpose vision-language models across F1-Macro, Panoptic Quality, and stream-level metrics. Our findings highlight the dominance of visual features for comic PSS macro-structure, yet demonstrate multimodal benefits in resolving challenging ambiguities. CoSMo establishes a new state-of-the-art, paving the way for scalable comic book analysis.",
      "authors": [
        "Marc Serra Ortega",
        "Emanuele Vivoli",
        "Artemis Llabr\\'es",
        "Dimosthenis Karatzas"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:35:37+00:00",
          "link": "https://arxiv.org/abs/2507.10053v1",
          "size": "17517kb",
          "version": "v1"
        }
      ],
      "title": "CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10053",
        "HTML": "https://arxiv.org/html/2507.10053v1",
        "PDF": "https://arxiv.org/pdf/2507.10053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a multimodal Transformer for page stream segmentation in comic books and curates a new dataset for evaluation, but it does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10178",
      "abstract": "Transformers are the driving force behind today's Large Language Models (LLMs), serving as the foundation for their performance and versatility. Yet, their compute and memory costs grow with sequence length, posing scalability challenges for long-context inferencing. In response, the algorithm community is exploring alternative architectures, such as state space models (SSMs), linear attention, and recurrent neural networks (RNNs), which we refer to as post-transformers. This shift presents a key challenge: building a serving system that efficiently supports both transformer and post-transformer LLMs within a unified framework. To address this challenge, we analyze the performance characteristics of transformer and post-transformer LLMs. Despite their algorithmic differences, both are fundamentally limited by memory bandwidth under batched inference due to attention in transformers and state updates in post-transformers. Further analyses suggest two additional insights: (1) state update operations, unlike attention, incur high hardware cost, making per-bank PIM acceleration inefficient, and (2) different low-precision arithmetic methods offer varying accuracy-area tradeoffs, while we identify Microsoft's MX as the Pareto-optimal choice. Building on these insights, we design Pimba as an array of State-update Processing Units (SPUs), each shared between two banks to enable interleaved access to PIM. Each SPU includes a State-update Processing Engine (SPE) that comprises element-wise multipliers and adders using MX-based quantized arithmetic, enabling efficient execution of state update and attention operations. Our evaluation shows that, compared to LLM-optimized GPU and GPU+PIM systems, Pimba achieves up to 3.2x and 2.1x higher token generation throughput, respectively.",
      "authors": [
        "Wonung Kim",
        "Yubin Lee",
        "Yoonsung Kim",
        "Jinwoo Hwang",
        "Seongryong Oh",
        "Jiyong Jung",
        "Aziz Huseynov",
        "Woong Gyu Park",
        "Chang Hyun Park",
        "Divya Mahajan",
        "Jongse Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:40:17+00:00",
          "link": "https://arxiv.org/abs/2507.10178v1",
          "size": "521kb",
          "version": "v1"
        }
      ],
      "title": "Pimba: A Processing-in-Memory Acceleration for Post-Transformer Large Language Model Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10178",
        "HTML": "https://arxiv.org/html/2507.10178v1",
        "PDF": "https://arxiv.org/pdf/2507.10178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computational performance and architecture for serving LLMs, without contributions to training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10538",
      "abstract": "Multilayered poroelastic structures are found in many biological tissues such as cartilage and the cornea, and play a key role in the design of bioartificial organs and other bioengineering applications. Motivated by these applications, we study the interaction between a free fluid flow, governed by the time-dependent Stokes equations, and a multilayered poroelastic structure composed of a thick Biot layer and a thin, linear poroelastic plate located at the interface. The resulting equations are linearly coupled across the thin structure domain through physical coupling conditions. We develop a partitioned numerical scheme for this poroelastic fluid-structure interaction problem, combining the backward Euler Stokes-Biot splitting method with the fixed-strain Biot splitting approach. The first decouples the Stokes problem from the multilayered structure problem, while the second decouples the flow and mechanical subproblems within the poroelastic structures. Stability of the splitting scheme is proven under different combinations of time-step conditions and parameter constraints. The method is validated using manufactured solutions, and further applied to a biologically inspired blood vessel flow problem. We also demonstrate convergence of the solution to the limiting case without the plate as its thickness tends to zero, providing additional validation of the numerical method.",
      "authors": [
        "Andrew Scharf and Martina Buka\\v{c} and Sun\\v{c}ica \\v{C}ani\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:57:20+00:00",
          "link": "https://arxiv.org/abs/2507.10538v1",
          "size": "1065kb",
          "version": "v1"
        }
      ],
      "title": "Splitting Method for a Multilayered Poroelastic Solid Interacting with Stokes Flow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10538",
        "HTML": "https://arxiv.org/html/2507.10538v1",
        "PDF": "https://arxiv.org/pdf/2507.10538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on numerical methods for fluid-structure interaction in multilayered poroelastic structures, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2106.15599",
      "abstract": "The population of elderly people has been increasing at a rapid rate over the last few decades and their population is expected to further increase in the upcoming future. Their increasing population is associated with their increasing needs due to problems like physical disabilities, cognitive issues, weakened memory and disorganized behavior, that elderly people face with increasing age. To reduce their financial burden on the world economy and to enhance their quality of life, it is essential to develop technology-based solutions that are adaptive, assistive and intelligent in nature. Intelligent Affect Aware Systems that can not only analyze but also predict the behavior of elderly people in the context of their day to day interactions with technology in an IoT-based environment, holds immense potential for serving as a long-term solution for improving the user experience of elderly in smart homes. This work therefore proposes the framework for an Intelligent Affect Aware environment for elderly people that can not only analyze the affective components of their interactions but also predict their likely user experience even before they start engaging in any activity in the given smart home environment. This forecasting of user experience would provide scope for enhancing the same, thereby increasing the assistive and adaptive nature of such intelligent systems. To uphold the efficacy of this proposed framework for improving the quality of life of elderly people in smart homes, it has been tested on three datasets and the results are presented and discussed.",
      "authors": [
        "Nirmalya Thakur and Chia Y. Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2021-06-29T17:34:16+00:00",
          "link": "https://arxiv.org/abs/2106.15599v1",
          "size": "1252kb",
          "version": "v1"
        }
      ],
      "title": "Framework for an Intelligent Affect Aware Smart Home Environment for Elderly People",
      "links": {
        "Abstract": "https://arxiv.org/abs/2106.15599",
        "PDF": "https://arxiv.org/pdf/2106.15599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a framework for an intelligent smart home environment for elderly people, with no mention of LLM training data processing, collection, or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.20735",
      "abstract": "Mouse and human brains have different functions that depend on their neuronal networks. In this study, we analyzed nanometer-scale three-dimensional structures of brain tissues of the mouse medial prefrontal cortex and compared them with structures of the human anterior cingulate cortex. The obtained results indicated that mouse neuronal somata are smaller and neurites are thinner than those of human neurons. These structural features allow mouse neurons to be integrated in the limited space of the brain, though thin neurites should suppress distal connections according to cable theory. We implemented this mouse-mimetic constraint in convolutional layers of a generative adversarial network (GAN) and a denoising diffusion implicit model (DDIM), which were then subjected to image generation tasks using photo datasets of cat faces, cheese, human faces, and birds. The mouse-mimetic GAN outperformed a standard GAN in the image generation task using the cat faces and cheese photo datasets, but underperformed for human faces and birds. The mouse-mimetic DDIM gave similar results, suggesting that the nature of the datasets affected the results. Analyses of the four datasets indicated differences in their image entropy, which should influence the number of parameters required for image generation. The preferences of the mouse-mimetic AIs coincided with the impressions commonly associated with mice. The relationship between the neuronal network and brain function should be investigated by implementing other biological findings in artificial neural networks.",
      "authors": [
        "Rino Saiga",
        "Kaede Shiga",
        "Yo Maruta",
        "Chie Inomoto",
        "Hiroshi Kajiwara",
        "Naoya Nakamura",
        "Yu Kakimoto",
        "Yoshiro Yamamoto",
        "Masahiro Yasutake",
        "Masayuki Uesugi",
        "Akihisa Takeuchi",
        "Kentaro Uesugi",
        "Yasuko Terada",
        "Yoshio Suzuki",
        "Viktor Nikitin",
        "Vincent De Andrade",
        "Francesco De Carlo",
        "Yuichi Yamashita",
        "Masanari Itokawa",
        "Soichiro Ide",
        "Kazutaka Ikeda",
        "and Ryuta Mizutani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T04:55:57+00:00",
          "link": "https://arxiv.org/abs/2410.20735v1",
          "size": "1192kb",
          "version": "v1"
        }
      ],
      "title": "Murine AI excels at cats and cheese: Structural differences between human and mouse neurons and their implementation in generative AIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20735",
        "PDF": "https://arxiv.org/pdf/2410.20735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on implementing mouse-mimetic constraints in neural networks for image generation tasks. It does not involve processing or creating LLM training data."
      },
      "tasks": [
        "Denoising",
        "Generative Adversarial Network",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/mizutanilab/schizo-nn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.11854",
      "abstract": "Retinal diseases are a leading cause of vision impairment and blindness, with timely diagnosis being critical for effective treatment. Optical Coherence Tomography (OCT) has become a standard imaging modality for retinal disease diagnosis, but OCT images often suffer from issues such as speckle noise, complex lesion shapes, and varying lesion sizes, making interpretation challenging. In this paper, we propose a novel framework, WaveNet-SF, to enhance retinal disease detection by integrating the spatial-domain and frequency-domain learning. The framework utilizes wavelet transforms to decompose OCT images into low- and high-frequency components, enabling the model to extract both global structural features and fine-grained details. To improve lesion detection, we introduce a Multi-Scale Wavelet Spatial Attention (MSW-SA) module, which enhances the model's focus on regions of interest at multiple scales. Additionally, a High-Frequency Feature Compensation (HFFC) block is incorporated to recover edge information lost during wavelet decomposition, suppress noise, and preserve fine details crucial for lesion detection. Our approach achieves state-of-the-art (SOTA) classification accuracies of 97.82% and 99.58% on the OCT-C8 and OCT2017 datasets, respectively, surpassing existing methods. These results demonstrate the efficacy of WaveNet-SF in addressing the challenges of OCT image analysis and its potential as a powerful tool for retinal disease diagnosis.",
      "authors": [
        "Jilan Cheng",
        "Guoli Long",
        "Zeyu Zhang",
        "Zhenjia Qi",
        "Hanyu Wang",
        "Libin Lu",
        "Shuihua Wang",
        "Yudong Zhang",
        "Jin Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T03:10:52+00:00",
          "link": "https://arxiv.org/abs/2501.11854v1",
          "size": "1764kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T14:07:20+00:00",
          "link": "https://arxiv.org/abs/2501.11854v2",
          "size": "1956kb",
          "version": "v2"
        }
      ],
      "title": "WaveNet-SF: A Hybrid Network for Retinal Disease Detection Based on Wavelet Transform in the Spatial-Frequency Domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11854",
        "PDF": "https://arxiv.org/pdf/2501.11854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for improving retinal disease detection using OCT images through wavelet transform-based enhancement techniques. It does not focus on LLM training data processing."
      },
      "tasks": [
        "Lesion Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06678",
      "abstract": "Image assessment aims to evaluate the quality and aesthetics of images and has been applied across various scenarios, such as natural and AIGC scenes. Existing methods mostly address these sub-tasks or scenes individually. While some works attempt to develop unified image assessment models, they have struggled to achieve satisfactory performance or cover a broad spectrum of assessment scenarios. In this paper, we present \\textbf{Gamma}, a \\textbf{G}eneric im\\textbf{A}ge assess\\textbf{M}ent model using \\textbf{M}ixture of \\textbf{A}ssessment Experts, which can effectively assess images from diverse scenes through mixed-dataset training. Achieving unified training in image assessment presents significant challenges due to annotation biases across different datasets. To address this issue, we first propose a Mixture of Assessment Experts (MoAE) module, which employs shared and adaptive experts to dynamically learn common and specific knowledge for different datasets, respectively. In addition, we introduce a Scene-based Differential Prompt (SDP) strategy, which uses scene-specific prompts to provide prior knowledge and guidance during the learning process, further boosting adaptation for various scenes. Our Gamma model is trained and evaluated on 12 datasets spanning 6 image assessment scenarios. Extensive experiments show that our unified Gamma outperforms other state-of-the-art mixed-training methods by significant margins while covering more scenes. Codes are available at https://github.com/zht8506/Gamma.",
      "authors": [
        "Hantao Zhou",
        "Rui Yang",
        "Longxiang Tang",
        "Guanyi Qin",
        "Runze Hu",
        "Xiu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T16:07:58+00:00",
          "link": "https://arxiv.org/abs/2503.06678v1",
          "size": "1767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:31:31+00:00",
          "link": "https://arxiv.org/abs/2503.06678v2",
          "size": "667kb",
          "version": "v2"
        }
      ],
      "title": "Gamma: Toward Generic Image Assessment with Mixture of Assessment Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06678",
        "HTML": "https://arxiv.org/html/2503.06678v2",
        "PDF": "https://arxiv.org/pdf/2503.06678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for image quality assessment using a mixture of experts. It is unrelated to LLM training data processing or creation."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/zht8506/gamma"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11143",
      "abstract": "This paper presents a two-year research project focused on developing AI-driven measures to analyze classroom dynamics, with particular emphasis on teacher actions captured through multimodal sensor data. We applied real-time data from classroom sensors and AI techniques to extract meaningful insights and support teacher development. Key outcomes include a curated audio-visual dataset, novel behavioral measures, and a proof-of-concept teaching review dashboard. An initial evaluation with eight researchers from the National Institute for Education (NIE) highlighted the system's clarity, usability, and its non-judgmental, automated analysis approach -- which reduces manual workloads and encourages constructive reflection. Although the current version does not assign performance ratings, it provides an objective snapshot of in-class interactions, helping teachers recognize and improve their instructional strategies. Designed and tested in an Asian educational context, this work also contributes a culturally grounded methodology to the growing field of AI-based educational analytics.",
      "authors": [
        "Andreea I. Niculescu",
        "Jochen Ehnes",
        "Chen Yi",
        "Du Jiawei",
        "Tay Chiat Pin",
        "Joey Tianyi Zhou",
        "Vigneshwaran Subbaraju",
        "Teh Kah Kuan",
        "Tran Huy Dat",
        "John Komar",
        "Gi Soong Chee",
        "Kenneth Kwok"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T04:52:50+00:00",
          "link": "https://arxiv.org/abs/2506.11143v1",
          "size": "11419kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T12:41:39+00:00",
          "link": "https://arxiv.org/abs/2506.11143v2",
          "size": "12154kb",
          "version": "v2"
        }
      ],
      "title": "On the development of an AI performance and behavioural measures for teaching and classroom management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11143",
        "HTML": "https://arxiv.org/html/2506.11143v2",
        "PDF": "https://arxiv.org/pdf/2506.11143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on developing AI-driven measures for classroom management and uses sensor data, with no focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08730",
      "abstract": "Modern configurable software systems need to learn models that correlate configuration and performance. However, when the system operates in dynamic environments, the workload variations, hardware changes, and system updates will inevitably introduce concept drifts at different levels - global drifts, which reshape the performance landscape of the entire configuration space; and local drifts, which only affect certain sub-regions of that space. As such, existing offline and transfer learning approaches can struggle to adapt to these implicit and unpredictable changes in real-time, rendering configuration performance learning challenging. To address this, we propose DHDA, an online configuration performance learning framework designed to capture and adapt to these drifts at different levels. The key idea is that DHDA adapts to both the local and global drifts using dually hierarchical adaptation: at the upper level, we redivide the data into different divisions, within each of which the local model is retrained, to handle global drifts only when necessary. At the lower level, the local models of the divisions can detect local drifts and adapt themselves asynchronously. To balance responsiveness and efficiency, DHDA combines incremental updates with periodic full retraining to minimize redundant computation when no drifts are detected. Through evaluating eight software systems and against state-of-the-art approaches, we show that DHDA achieves considerably better accuracy and can effectively adapt to drifts with up to 2x improvements, while incurring reasonable overhead and is able to improve different local models in handling concept drift.",
      "authors": [
        "Zezhen Xiang",
        "Jingzhi Gong",
        "Tao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:31:42+00:00",
          "link": "https://arxiv.org/abs/2507.08730v1",
          "size": "1386kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:01:52+00:00",
          "link": "https://arxiv.org/abs/2507.08730v2",
          "size": "1386kb",
          "version": "v2"
        }
      ],
      "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08730",
        "HTML": "https://arxiv.org/html/2507.08730v2",
        "PDF": "https://arxiv.org/pdf/2507.08730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adaptive learning in configurable software systems under dynamic conditions, not on LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09579",
      "abstract": "We present PromptChain, a decentralized Web3 architecture that establishes AI prompts as first-class digital assets with verifiable ownership, version control, and monetization capabilities. Current centralized platforms lack mechanisms for proper attribution, quality assurance, or fair compensation for prompt creators. PromptChain addresses these limitations through a novel integration of IPFS for immutable storage, smart contracts for governance, and token incentives for community curation. Our design includes: (1) a comprehensive metadata schema for cross-model compatibility, (2) a stake-weighted validation mechanism to align incentives, and (3) a token economy that rewards contributors proportionally to their impact. The proposed architecture demonstrates how decentralized systems could potentially match centralized alternatives in efficiency while providing superior ownership guarantees and censorship resistance through blockchain-anchored provenance tracking. By decoupling prompts from specific AI models or outputs, this work establishes the foundation for an open ecosystem of human-AI collaboration in the Web3 era, representing the first systematic treatment of prompts as standalone digital assets with dedicated decentralized infrastructure.",
      "authors": [
        "Marc Bara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:10:39+00:00",
          "link": "https://arxiv.org/abs/2507.09579v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "PromptChain: A Decentralized Web3 Architecture for Managing AI Prompts as Digital Assets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09579",
        "HTML": "https://arxiv.org/html/2507.09579v1",
        "PDF": "https://arxiv.org/pdf/2507.09579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on establishing AI prompts as digital assets in a decentralized architecture, without discussing any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09772",
      "abstract": "We introduce just-in-time (JIT) compilation to the integral kernels for Gaussian-type orbitals (GTOs) to enhance the efficiency of electron repulsion integral computations. For Coulomb and exchange (JK) matrices, JIT-based algorithms yield a 2x speedup for the small 6-31G* basis set on an NVIDIA A100-80G GPU. By incorporating a novel algorithm designed for orbitals with high angular momentum, the efficiency of JK evaluations with the large def2-TZVPP basis set is improved by up to 4x. The core CUDA implementation is compact, comprising only ~1,000 lines of code, including support for single-precision arithmetic. Furthermore, the single-precision implementation achieves a 3x speedup over the previous state-of-the-art.",
      "authors": [
        "Xiaojie Wu and Yuanheng Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:06:32+00:00",
          "link": "https://arxiv.org/abs/2507.09772v1",
          "size": "723kb",
          "version": "v1"
        }
      ],
      "title": "Designing quantum chemistry algorithms with Just-In-Time compilation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09772",
        "HTML": "https://arxiv.org/html/2507.09772v1",
        "PDF": "https://arxiv.org/pdf/2507.09772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses quantum chemistry algorithms and efficiency improvements using just-in-time compilation, without any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10345",
      "abstract": "This paper examines the $L_p$ and $W^1_p$ norm approximation errors of ReLU neural networks for Korobov functions. In terms of network width and depth, we derive nearly optimal super-approximation error bounds of order $2m$ in the $L_p$ norm and order $2m-2$ in the $W^1_p$ norm, for target functions with $L_p$ mixed derivative of order $m$ in each direction. The analysis leverages sparse grid finite elements and the bit extraction technique. Our results improve upon classical lowest order $L_\\infty$ and $H^1$ norm error bounds and demonstrate that the expressivity of neural networks is largely unaffected by the curse of dimensionality.",
      "authors": [
        "Yuwen Li",
        "Guozhi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:48:47+00:00",
          "link": "https://arxiv.org/abs/2507.10345v1",
          "size": "151kb",
          "version": "v1"
        }
      ],
      "title": "Some Super-approximation Rates of ReLU Neural Networks for Korobov Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10345",
        "HTML": "https://arxiv.org/html/2507.10345v1",
        "PDF": "https://arxiv.org/pdf/2507.10345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes approximation rates of ReLU networks for mathematical functions, without focusing on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10524",
      "abstract": "Scaling language models unlocks impressive capabilities, but the accompanying computational and memory demands make both training and deployment expensive. Existing efficiency efforts typically target either parameter sharing or adaptive computation, leaving open the question of how to attain both simultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework that combines the two axes of efficiency inside a single Recursive Transformer. MoR reuses a shared stack of layers across recursion steps to achieve parameter efficiency, while lightweight routers enable adaptive token-level thinking by dynamically assigning different recursion depths to individual tokens. This allows MoR to focus quadratic attention computation only among tokens still active at a given recursion depth, further improving memory access efficiency by selectively caching only their key-value pairs. Beyond these core mechanisms, we also propose a KV sharing variant that reuses KV pairs from the first recursion, specifically designed to decrease prefill latency and memory footprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms a new Pareto frontier: at equal training FLOPs and smaller model sizes, it significantly lowers validation perplexity and improves few-shot accuracy, while delivering higher throughput compared with vanilla and existing recursive baselines. These gains demonstrate that MoR is an effective path towards large-model quality without incurring large-model cost.",
      "authors": [
        "Sangmin Bae",
        "Yujin Kim",
        "Reza Bayat",
        "Sungnyun Kim",
        "Jiyoun Ha",
        "Tal Schuster",
        "Adam Fisch",
        "Hrayr Harutyunyan",
        "Ziwei Ji",
        "Aaron Courville",
        "Se-Young Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:49:00+00:00",
          "link": "https://arxiv.org/abs/2507.10524v1",
          "size": "704kb",
          "version": "v1"
        }
      ],
      "title": "Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10524",
        "HTML": "https://arxiv.org/html/2507.10524v1",
        "PDF": "https://arxiv.org/pdf/2507.10524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an efficient model architecture without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.01984",
      "abstract": "The focus of this paper is on operating the electric power grid in a secure manner when wildfire risks are high. This is a challenging problem because of the uncertain ways in which the fires can impact the operation of the power system. To address this challenge, we propose a novel preventive-corrective coordinated decision-making scheme that quickly mitigates both static and dynamic insecurities given the risk of active wildfires in a region. The scheme utilizes a comprehensive contingency analysis tool for multi-asset outages that leverages: (i) a Feasibility Test algorithm which exhaustively desaturates overloaded cut-sets to prevent cascading line outages, and (ii) a data-driven transient stability analyzer which alleviates dynamic instabilities. This tool is then used to operate a coordinated unit commitment/optimal power flow model that is designed to adapt to varying risk levels associated with wildfires. Depending on the allowed risk, the model balances economical operation and grid robustness. The results obtained using the IEEE 118-bus system indicate that the proposed approach alleviates system vulnerabilities to wildfires while also minimizing operational cost.",
      "authors": [
        "Satyaprajna Sahoo",
        "Anamitra Pal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T19:44:59+00:00",
          "link": "https://arxiv.org/abs/2410.01984v1",
          "size": "10741kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:34:53+00:00",
          "link": "https://arxiv.org/abs/2410.01984v2",
          "size": "11562kb",
          "version": "v2"
        }
      ],
      "title": "A Preventive-Corrective Scheme for Ensuring Power System Security During Active Wildfire Risks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01984",
        "PDF": "https://arxiv.org/pdf/2410.01984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a decision-making scheme for power grid operation during wildfires, relying on data-driven tools for stability analysis. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13640",
      "abstract": "Large language models (LLMs) are known to have the potential to generate harmful content, posing risks to users. While significant progress has been made in developing taxonomies for LLM risks and safety evaluation prompts, most studies have focused on monolingual contexts, primarily in English. However, language- and region-specific risks in bilingual contexts are often overlooked, and core findings can diverge from those in monolingual settings. In this paper, we introduce Qorgau, a novel dataset specifically designed for safety evaluation in Kazakh and Russian, reflecting the unique bilingual context in Kazakhstan, where both Kazakh (a low-resource language) and Russian (a high-resource language) are spoken. Experiments with both multilingual and language-specific LLMs reveal notable differences in safety performance, emphasizing the need for tailored, region-specific datasets to ensure the responsible and safe deployment of LLMs in countries like Kazakhstan. Warning: this paper contains example data that may be offensive, harmful, or biased.",
      "authors": [
        "Maiya Goloburda",
        "Nurkhan Laiyk",
        "Diana Turmakhan",
        "Yuxia Wang",
        "Mukhammed Togmanov",
        "Jonibek Mansurov",
        "Askhat Sametov",
        "Nurdaulet Mukhituly",
        "Minghan Wang",
        "Daniil Orel",
        "Zain Muhammad Mujahid",
        "Fajri Koto",
        "Timothy Baldwin",
        "Preslav Nakov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T11:33:22+00:00",
          "link": "https://arxiv.org/abs/2502.13640v1",
          "size": "913kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:22:54+00:00",
          "link": "https://arxiv.org/abs/2502.13640v2",
          "size": "673kb",
          "version": "v2"
        }
      ],
      "title": "Qorgau: Evaluating LLM Safety in Kazakh-Russian Bilingual Contexts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13640",
        "HTML": "https://arxiv.org/html/2502.13640v2",
        "PDF": "https://arxiv.org/pdf/2502.13640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces Qorgau, a dataset specifically designed for evaluating LLM safety in a bilingual context, detailing the data processing to reflect Kazakh-Russian environments, which is a critical aspect of LLM training data creation and processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.20854",
      "abstract": "Counterfactual learning to rank (CLTR) aims to learn a ranking policy from user interactions while correcting for the inherent biases in interaction data, such as position bias. Existing CLTR methods assume a single ranking policy that selects top-K ranking from the entire document candidate set. In real-world applications, the candidate document set is on the order of millions, making a single-stage ranking policy impractical. In order to scale to millions of documents, real-world ranking systems are designed in a two-stage fashion, with a candidate generator followed by a ranker. The existing CLTR method for a two-stage offline ranking system only considers the top-1 ranking set-up and only focuses on training the candidate generator, with the ranker fixed. A CLTR method for training both the ranker and candidate generator jointly is missing from the existing literature. In this paper, we propose a two-stage CLTR estimator that considers the interaction between the two stages and estimates the joint value of the two policies offline. In addition, we propose a novel joint optimization method to train the candidate and ranker policies, respectively. To the best of our knowledge, we are the first to propose a CLTR estimator and learning method for two-stage ranking. Experimental results on a semi-synthetic benchmark demonstrate the effectiveness of the proposed joint CLTR method over baselines.",
      "authors": [
        "Shashank Gupta",
        "Yiming Liao",
        "and Maarten de Rijke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T22:00:12+00:00",
          "link": "https://arxiv.org/abs/2506.20854v1",
          "size": "67kb",
          "version": "v1"
        },
        {
          "date": "2025-07-06T09:59:04+00:00",
          "link": "https://arxiv.org/abs/2506.20854v2",
          "size": "67kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T14:36:33+00:00",
          "link": "https://arxiv.org/abs/2506.20854v3",
          "size": "68kb",
          "version": "v3"
        }
      ],
      "title": "Towards Two-Stage Counterfactual Learning to Rank",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20854",
        "HTML": "https://arxiv.org/html/2506.20854v3",
        "PDF": "https://arxiv.org/pdf/2506.20854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses counterfactual learning to rank approaches for optimizing ranking system stages, without relating to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09174",
      "abstract": "The rapid proliferation of multimodal misinformation presents significant challenges for automated fact-checking systems, especially when claims are ambiguous or lack sufficient context. We introduce RAMA, a novel retrieval-augmented multi-agent framework designed for verifying multimedia misinformation. RAMA incorporates three core innovations: (1) strategic query formulation that transforms multimodal claims into precise web search queries; (2) cross-verification evidence aggregation from diverse, authoritative sources; and (3) a multi-agent ensemble architecture that leverages the complementary strengths of multiple multimodal large language models and prompt variants. Extensive experiments demonstrate that RAMA achieves superior performance on benchmark datasets, particularly excelling in resolving ambiguous or improbable claims by grounding verification in retrieved factual evidence. Our findings underscore the necessity of integrating web-based evidence and multi-agent reasoning for trustworthy multimedia verification, paving the way for more reliable and scalable fact-checking solutions. RAMA will be publicly available at https://github.com/kalendsyang/RAMA.git.",
      "authors": [
        "Shuo Yang",
        "Zijian Yu",
        "Zhenzhe Ying",
        "Yuqin Dai",
        "Guoqing Wang",
        "Jun Lan",
        "Jinfeng Xu",
        "Jinze Li and Edith C.H. Ngai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:46:51+00:00",
          "link": "https://arxiv.org/abs/2507.09174v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "RAMA: Retrieval-Augmented Multi-Agent Framework for Misinformation Detection in Multimodal Fact-Checking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09174",
        "HTML": "https://arxiv.org/html/2507.09174v1",
        "PDF": "https://arxiv.org/pdf/2507.09174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for misinformation detection in multimodal fact-checking but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10281",
      "abstract": "Tables are fundamental in domains such as finance, healthcare, and public administration, yet real-world table tasks often involve noise, structural heterogeneity, and semantic complexity--issues underexplored in existing research that primarily targets clean academic datasets. This survey focuses on LLM-based Table Agents, which aim to automate table-centric workflows by integrating preprocessing, reasoning, and domain adaptation. We define five core competencies--C1: Table Structure Understanding, C2: Table and Query Semantic Understanding, C3: Table Retrieval and Compression, C4: Executable Reasoning with Traceability, and C5: Cross-Domain Generalization--to analyze and compare current approaches. In addition, a detailed examination of the Text-to-SQL Agent reveals a performance gap between academic benchmarks and real-world scenarios, especially for open-source models. Finally, we provide actionable insights to improve the robustness, generalization, and efficiency of LLM-based Table Agents in practical settings.",
      "authors": [
        "Jiaming Tian",
        "Liyao Li",
        "Wentao Ye",
        "Haobo Wang",
        "Lingxin Wang",
        "Lihua Yu",
        "Zujie Ren",
        "Gang Chen",
        "Junbo Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:48:13+00:00",
          "link": "https://arxiv.org/abs/2507.10281v1",
          "size": "223kb",
          "version": "v1"
        }
      ],
      "title": "Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10281",
        "PDF": "https://arxiv.org/pdf/2507.10281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper surveys LLM-based Table Agents, it mainly focuses on capabilities and workflows for LLMs in table tasks and does not primarily contribute to training data processing for LLMs, only briefly mentioning domain adaptation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10407",
      "abstract": "I discuss a seemingly unlikely confluence of topics in algebra, numerical computation, and computer vision. The motivating problem is that of solving multiples instances of a parametric family of systems of algebraic (polynomial or rational function) equations. No doubt already of interest to ISSAC attendees, this problem arises in the context of robust model-fitting paradigms currently utilized by the computer vision community (namely \"Random Sampling and Consensus\", aka \"RanSaC\".) This talk will give an overview of work in the last 5+ years that aspires to measure the intrinsic difficulty of solving such parametric systems, and makes strides towards practical solutions.",
      "authors": [
        "Timothy Duff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Symbolic Computation (cs.SC)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.10407v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "Numerically Computing Galois Groups of Minimal Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10407",
        "HTML": "https://arxiv.org/html/2507.10407v1",
        "PDF": "https://arxiv.org/pdf/2507.10407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses solving parametric systems in algebra, numerical computation, and computer vision without addressing LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10435",
      "abstract": "Recent studies suggest that large language models (LLMs) possess the capability to solve graph reasoning tasks. Notably, even when graph structures are embedded within textual descriptions, LLMs can still effectively answer related questions. This raises a fundamental question: How can a decoder-only Transformer architecture understand underlying graph structures? To address this, we start with the substructure extraction task, interpreting the inner mechanisms inside the transformers and analyzing the impact of the input queries. Specifically, through both empirical results and theoretical analysis, we present Induced Substructure Filtration (ISF), a perspective that captures the substructure identification in the multi-layer transformers. We further validate the ISF process in LLMs, revealing consistent internal dynamics across layers. Building on these insights, we explore the broader capabilities of Transformers in handling diverse graph types. Specifically, we introduce the concept of thinking in substructures to efficiently extract complex composite patterns, and demonstrate that decoder-only Transformers can successfully extract substructures from attributed graphs, such as molecular graphs. Together, our findings offer a new insight on how sequence-based Transformers perform the substructure extraction task over graph data.",
      "authors": [
        "Xinnan Dai",
        "Kai Yang",
        "Jay Revolinsky",
        "Kai Guo",
        "Aoran Wang",
        "Bohang Zhang",
        "Jiliang Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:36:24+00:00",
          "link": "https://arxiv.org/abs/2507.10435v1",
          "size": "2364kb",
          "version": "v1"
        }
      ],
      "title": "From Sequence to Structure: Uncovering Substructure Reasoning in Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10435",
        "HTML": "https://arxiv.org/html/2507.10435v1",
        "PDF": "https://arxiv.org/pdf/2507.10435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates how Transformers understand graph structures in textual descriptions, a theoretical exploration of model capabilities. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.11809",
      "abstract": "The ICP registration algorithm has been a preferred method for LiDAR-based robot localization for nearly a decade. However, even in modern SLAM solutions, ICP can degrade and become unreliable in geometrically ill-conditioned environments. Current solutions primarily focus on utilizing additional sources of information, such as external odometry, to either replace the degenerate directions of the optimization solution or add additional constraints in a sensor-fusion setup afterward.\n  In response, this work investigates and compares new and existing degeneracy mitigation methods for robust LiDAR-based localization and analyzes the efficacy of these approaches in degenerate environments for the first time in the literature at this scale. Specifically, this work investigates i) the effect of using active or passive degeneracy mitigation methods for the problem of ill-conditioned ICP in LiDAR degenerate environments, ii) the evaluation of TSVD, inequality constraints, and linear/non-linear Tikhonov regularization for the application of degenerate point cloud registration for the first time. Furthermore, a sensitivity analysis for least-squares minimization step of the ICP problem is carried out to better understand how each method affects the optimization and what to expect from each method. The results of the analysis are validated through multiple real-world robotic field and simulated experiments. The analysis demonstrates that active optimization degeneracy mitigation is necessary and advantageous in the absence of reliable external estimate assistance for LiDAR-SLAM, and soft-constrained methods can provide better results in complex ill-conditioned scenarios with heuristic fine-tuned parameters.",
      "authors": [
        "Turcan Tuna",
        "Julian Nubert",
        "Patrick Pfreundschuh",
        "Cesar Cadena",
        "Shehryar Khattak",
        "Marco Hutter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-21T17:54:04+00:00",
          "link": "https://arxiv.org/abs/2408.11809v1",
          "size": "22985kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T09:55:26+00:00",
          "link": "https://arxiv.org/abs/2408.11809v2",
          "size": "29295kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T15:48:03+00:00",
          "link": "https://arxiv.org/abs/2408.11809v3",
          "size": "34209kb",
          "version": "v3"
        }
      ],
      "title": "Informed, Constrained, Aligned: A Field Analysis on Degeneracy-aware Point Cloud Registration in the Wild",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.11809",
        "HTML": "https://arxiv.org/html/2408.11809v3",
        "PDF": "https://arxiv.org/pdf/2408.11809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates degeneracy mitigation methods for LiDAR-based localization, which does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.15260",
      "abstract": "Diffusion-based image editing models have made remarkable progress in recent years. However, achieving high-quality video editing remains a significant challenge. One major hurdle is the absence of open-source, large-scale video editing datasets based on real-world data, as constructing such datasets is both time-consuming and costly. Moreover, video data requires a significantly larger number of tokens for representation, which substantially increases the training costs for video editing models. Lastly, current video editing models offer limited interactivity, often making it difficult for users to express their editing requirements effectively in a single attempt. To address these challenges, this paper introduces a dataset VIVID-10M and a baseline model VIVID. VIVID-10M is the first large-scale hybrid image-video local editing dataset aimed at reducing data construction and model training costs, which comprises 9.7M samples that encompass a wide range of video editing tasks. VIVID is a Versatile and Interactive VIdeo local eDiting model trained on VIVID-10M, which supports entity addition, modification, and deletion. At its core, a keyframe-guided interactive video editing mechanism is proposed, enabling users to iteratively edit keyframes and propagate it to other frames, thereby reducing latency in achieving desired outcomes. Extensive experimental evaluations show that our approach achieves state-of-the-art performance in video local editing, surpassing baseline methods in both automated metrics and user studies. The VIVID-10M dataset are open-sourced at https://kwaivgi.github.io/VIVID/.",
      "authors": [
        "Jiahao Hu",
        "Tianxiong Zhong",
        "Xuebo Wang",
        "Boyuan Jiang",
        "Xingye Tian",
        "Fei Yang",
        "Pengfei Wan",
        "Di Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T10:04:05+00:00",
          "link": "https://arxiv.org/abs/2411.15260v1",
          "size": "14937kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:52:04+00:00",
          "link": "https://arxiv.org/abs/2411.15260v2",
          "size": "4263kb",
          "version": "v2"
        }
      ],
      "title": "VIVID-10M: A Dataset and Baseline for Versatile and Interactive Video Local Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15260",
        "HTML": "https://arxiv.org/html/2411.15260v2",
        "PDF": "https://arxiv.org/pdf/2411.15260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset, VIVID-10M, for video editing tasks with detailed data processing steps. It clearly discusses the challenge of constructing such datasets, which qualifies as a core contribution to data processing."
      },
      "datasets": [
        {
          "dataset_name": "KwaiVGI/VIVID-10M",
          "downloads": "4925",
          "likes": "3",
          "link": "https://huggingface.co/datasets/KwaiVGI/VIVID-10M"
        }
      ],
      "tasks": [
        "Video Editing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05649",
      "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in various graph-based learning tasks. However, enabling privacy-preserving GNNs in encrypted domains, such as under Fully Homomorphic Encryption (FHE), typically incurs substantial computational overhead, rendering real-time and privacy-preserving inference impractical. In this work, we propose DESIGN (EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel framework for efficient encrypted GNN inference. DESIGN tackles the critical efficiency limitations of existing FHE GNN approaches, which often overlook input data redundancy and apply uniform computational strategies. Our framework achieves significant performance gains through a hierarchical optimization strategy executed entirely on the server: first, FHE-compatible node importance scores (based on encrypted degree statistics) are computed from the encrypted graph. These scores then guide a homomorphic partitioning process, generating multi-level importance masks directly under FHE. This dynamically generated mask facilitates both input graph pruning (by logically removing unimportant elements) and a novel adaptive polynomial activation scheme, where activation complexity is tailored to node importance levels. Empirical evaluations demonstrate that DESIGN substantially accelerates FHE GNN inference compared to state-of-the-art methods while maintaining competitive model accuracy, presenting a robust solution for secure graph analytics. Our implementation is publicly available at https://github.com/LabRAI/DESIGN.",
      "authors": [
        "Kaixiang Zhao",
        "Joseph Yousry Attalla",
        "Qian Lou",
        "Yushun Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T04:01:53+00:00",
          "link": "https://arxiv.org/abs/2507.05649v1",
          "size": "76kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:12:59+00:00",
          "link": "https://arxiv.org/abs/2507.05649v2",
          "size": "76kb",
          "version": "v2"
        }
      ],
      "title": "DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05649",
        "HTML": "https://arxiv.org/html/2507.05649v2",
        "PDF": "https://arxiv.org/pdf/2507.05649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on encrypted GNN inference and optimization strategies for privacy-preserving computations, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08885",
      "abstract": "How to enable robots to predict the outcomes of their own motion intentions in three-dimensional space has been a fundamental problem in embodied intelligence. To explore more general spatial imagination capabilities, here we present AirScape, the first world model designed for six-degree-of-freedom aerial agents. AirScape predicts future observation sequences based on current visual inputs and motion intentions. Specifically, we construct an dataset for aerial world model training and testing, which consists of 11k video-intention pairs. This dataset includes first-person-view videos capturing diverse drone actions across a wide range of scenarios, with over 1,000 hours spent annotating the corresponding motion intentions. Then we develop a two-phase training schedule to train a foundation model -- initially devoid of embodied spatial knowledge -- into a world model that is controllable by motion intentions and adheres to physical spatio-temporal constraints.",
      "authors": [
        "Baining Zhao",
        "Rongze Tang",
        "Mingyuan Jia",
        "Ziyou Wang",
        "Fanghang Man",
        "Xin Zhang",
        "Yu Shang",
        "Weichen Zhang",
        "Chen Gao",
        "Wei Wu",
        "Xin Wang",
        "Xinlei Chen",
        "Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:05:30+00:00",
          "link": "https://arxiv.org/abs/2507.08885v1",
          "size": "3826kb",
          "version": "v1"
        }
      ],
      "title": "AirScape: An Aerial Generative World Model with Motion Controllability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08885",
        "HTML": "https://arxiv.org/html/2507.08885v1",
        "PDF": "https://arxiv.org/pdf/2507.08885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper details the creation of a new dataset for training aerial world models, including specific data processing steps like video-intention pairing and substantial annotation efforts. This is a primary contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09337",
      "abstract": "Heterogeneity is the prevalent trend in the rapidly evolving high-performance computing (HPC) landscape in both hardware and application software. The diversity in hardware platforms, currently comprising various accelerators and a future possibility of specializable chiplets, poses a significant challenge for scientific software developers aiming to harness optimal performance across different computing platforms while maintaining the quality of solutions when their applications are simultaneously growing more complex. Code synthesis and code generation can provide mechanisms to mitigate this challenge. We have developed a toolchain, ORCHA, which arises from the needs of a large multiphysics simulation software, Flash-X, which were not met by any of the existing solutions. ORCHA is composed of three stand-alone tools -- one to express high-level control flow and a map of what to execute where on the platform, a second one to express variants of data structures and arithmetic operations in the solvers in a unified fashion, and a third one that manages the runtime orchestration of the data and computation. We use an application-specific interface layer that uses code generation and code synthesis to stitch together the application. In this paper, we describe the interface layer for the application Flash-X and demonstrate the use of ORCHA in exploring possible configurations from which the optimal one can be selected for production, including a case study in which a single simulation recipe is realized on three distinct hardware mappings -- a GPU-centric, a CPU/GPU balanced, and a CPU/GPU concurrent layouts -- highlighting the breadth of configurations ORCHA enables.",
      "authors": [
        "Youngjun Lee",
        "Klaus Weide",
        "Wesley Kwiecinski",
        "Jared O'Neal",
        "Johann Rudi",
        "Anshu Dubey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:35:32+00:00",
          "link": "https://arxiv.org/abs/2507.09337v1",
          "size": "162kb",
          "version": "v1"
        }
      ],
      "title": "ORCHA -- A Performance Portability System for Post-Exascale Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09337",
        "HTML": "https://arxiv.org/html/2507.09337v1",
        "PDF": "https://arxiv.org/pdf/2507.09337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a toolchain for performance portability in high-performance computing systems, but does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09959",
      "abstract": "360{\\deg} videos enable users to freely choose their viewing paths, but blind and low vision (BLV) users are often excluded from this interactive experience. To bridge this gap, we present Branch Explorer, a system that transforms 360{\\deg} videos into branching narratives -- stories that dynamically unfold based on viewer choices -- to support interactive viewing for BLV audiences. Our formative study identified three key considerations for accessible branching narratives: providing diverse branch options, ensuring coherent story progression, and enabling immersive navigation among branches. To address these needs, Branch Explorer employs a multi-modal machine learning pipeline to generate diverse narrative paths, allowing users to flexibly make choices at detected branching points and seamlessly engage with each storyline through immersive audio guidance. Evaluation with 12 BLV viewers showed that Branch Explorer significantly enhanced user agency and engagement in 360{\\deg} video viewing. Users also developed personalized strategies for exploring 360{\\deg} content. We further highlight implications for supporting accessible exploration of videos and virtual environments.",
      "authors": [
        "Shuchang Xu",
        "Xiaofu Jin",
        "Wenshuo Zhang",
        "Huamin Qu",
        "Yukang Yan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:16:41+00:00",
          "link": "https://arxiv.org/abs/2507.09959v1",
          "size": "4025kb",
          "version": "v1"
        }
      ],
      "title": "Branch Explorer: Leveraging Branching Narratives to Support Interactive 360{\\deg} Video Viewing for Blind and Low Vision Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09959",
        "HTML": "https://arxiv.org/html/2507.09959v1",
        "PDF": "https://arxiv.org/pdf/2507.09959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a system for creating accessible branching narratives in 360-degree video for blind and low vision users, with no focus on LLM training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10500",
      "abstract": "While autonomous driving technologies continue to advance, current Advanced Driver Assistance Systems (ADAS) remain limited in their ability to interpret scene context or engage with drivers through natural language. These systems typically rely on predefined logic and lack support for dialogue-based interaction, making them inflexible in dynamic environments or when adapting to driver intent. This paper presents Scene-Aware Conversational ADAS (SC-ADAS), a modular framework that integrates Generative AI components including large language models, vision-to-text interpretation, and structured function calling to enable real-time, interpretable, and adaptive driver assistance. SC-ADAS supports multi-turn dialogue grounded in visual and sensor context, allowing natural language recommendations and driver-confirmed ADAS control. Implemented in the CARLA simulator with cloud-based Generative AI, the system executes confirmed user intents as structured ADAS commands without requiring model fine-tuning. We evaluate SC-ADAS across scene-aware, conversational, and revisited multi-turn interactions, highlighting trade-offs such as increased latency from vision-based context retrieval and token growth from accumulated dialogue history. These results demonstrate the feasibility of combining conversational reasoning, scene perception, and modular ADAS control to support the next generation of intelligent driver assistance.",
      "authors": [
        "Kyungtae Han",
        "Yitao Chen",
        "Rohit Gupta",
        "Onur Altintas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.10500v1",
          "size": "1983kb",
          "version": "v1"
        }
      ],
      "title": "Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10500",
        "HTML": "https://arxiv.org/html/2507.10500v1",
        "PDF": "https://arxiv.org/pdf/2507.10500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating Generative AI into a driver assistance system and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.14367",
      "abstract": "In this paper, a force-based beam finite element model based on a modified higher-order shear deformation theory is proposed for the accurate analysis of functionally graded beams. In the modified higher-order shear deformation theory, the distribution of transverse shear stress across the beam's thickness is obtained from the differential equilibrium equation, and a modified shear stiffness is derived to take the effect of transverse shear stress distribution into consideration. In the proposed beam element model, unlike traditional beam finite elements that regard generalized displacements as unknown fields, the internal forces are considered as the unknown fields, and they are predefined by using the closed-form solutions of the differential equilibrium equations of higher-order shear beam. Then, the generalized displacements are expressed by the internal forces with the introduction of geometric relations and constitutive equations, and the equation system of the beam element is constructed based on the equilibrium conditions at the boundaries and the compatibility condition within the element. Numerical examples underscore the accuracy and efficacy of the proposed higher-order beam element model in the static analysis of functionally graded sandwich beams, particularly in terms of true transverse shear stress distribution.",
      "authors": [
        "Wenxiong Li",
        "Huiyi Chen",
        "Suiyin Chen",
        "Zhiwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-22T01:40:58+00:00",
          "link": "https://arxiv.org/abs/2312.14367v1",
          "size": "1895kb",
          "version": "v1"
        },
        {
          "date": "2024-01-09T07:16:30+00:00",
          "link": "https://arxiv.org/abs/2312.14367v2",
          "size": "1905kb",
          "version": "v2"
        },
        {
          "date": "2024-03-18T14:02:13+00:00",
          "link": "https://arxiv.org/abs/2312.14367v3",
          "size": "1910kb",
          "version": "v3"
        },
        {
          "date": "2024-04-21T01:43:18+00:00",
          "link": "https://arxiv.org/abs/2312.14367v4",
          "size": "1980kb",
          "version": "v4"
        },
        {
          "date": "2024-05-15T09:02:13+00:00",
          "link": "https://arxiv.org/abs/2312.14367v5",
          "size": "1987kb",
          "version": "v5"
        },
        {
          "date": "2025-05-19T13:35:12+00:00",
          "link": "https://arxiv.org/abs/2312.14367v6",
          "size": "2191kb",
          "version": "v6"
        },
        {
          "date": "2025-07-12T14:29:04+00:00",
          "link": "https://arxiv.org/abs/2312.14367v7",
          "size": "1905kb",
          "version": "v7"
        }
      ],
      "title": "A force-based beam element model based on the modified higher-order shear deformation theory for accurate analysis of FG beams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.14367",
        "PDF": "https://arxiv.org/pdf/2312.14367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents a new beam element model for structural analysis and does not involve any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.07543",
      "abstract": "Personalization is crucial for the widespread adoption of advanced driver assistance system. To match up with each user's preference, the online evolution capability is a must. However, conventional evolution methods learn from naturalistic driving data, which requires a lot computing power and cannot be applied online. To address this challenge, this paper proposes a lesson learning approach: learning from driver's takeover interventions. By leveraging online takeover data, the driving zone is generated to ensure perceived safety using Gaussian discriminant analysis. Real-time corrections to trajectory planning rewards are enacted through apprenticeship learning. Guided by the objective of optimizing rewards within the constraints of the driving zone, this approach employs model predictive control for trajectory planning. This lesson learning framework is highlighted for its faster evolution capability, adeptness at experience accumulating, assurance of perceived safety, and computational efficiency. Simulation results demonstrate that the proposed system consistently achieves a successful customization without further takeover interventions. Accumulated experience yields a 24% enhancement in evolution efficiency. The average number of learning iterations is only 13.8. The average computation time is 0.08 seconds.",
      "authors": [
        "Jia Hu",
        "Mingyue Lei",
        "Haoran Wang",
        "Zeyu Liu",
        "Fan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-13T08:25:45+00:00",
          "link": "https://arxiv.org/abs/2405.07543v1",
          "size": "2625kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T07:05:17+00:00",
          "link": "https://arxiv.org/abs/2405.07543v2",
          "size": "5847kb",
          "version": "v2"
        }
      ],
      "title": "Accelerating the Evolution of Personalized Automated Lane Change through Lesson Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.07543",
        "HTML": "https://arxiv.org/html/2405.07543",
        "PDF": "https://arxiv.org/pdf/2405.07543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a lesson learning approach for driver assistance systems and does not pertain to LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Model Predictive Control",
        "Trajectory Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03503",
      "abstract": "Point-of-interest (POI) recommender systems help users discover relevant locations, but their effectiveness is often compromised by popularity bias, which disadvantages less popular, yet potentially meaningful places. This paper addresses this challenge by evaluating the effectiveness of context-aware models and calibrated popularity techniques as strategies for mitigating popularity bias. Using four real-world POI datasets (Brightkite, Foursquare, Gowalla, and Yelp), we analyze the individual and combined effects of these approaches on recommendation accuracy and popularity bias. Our results reveal that context-aware models cannot be considered a uniform solution, as the models studied exhibit divergent impacts on accuracy and bias. In contrast, calibration techniques can effectively align recommendation popularity with user preferences, provided there is a careful balance between accuracy and bias mitigation. Notably, the combination of calibration and context-awareness yields recommendations that balance accuracy and close alignment with the users' popularity profiles, i.e., popularity calibration.",
      "authors": [
        "Andrea Forster",
        "Simone Kopeinik",
        "Denic Helic",
        "Stefan Thalmann",
        "Dominik Kowald"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T11:56:11+00:00",
          "link": "https://arxiv.org/abs/2507.03503v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T15:49:31+00:00",
          "link": "https://arxiv.org/abs/2507.03503v2",
          "size": "105kb",
          "version": "v2"
        }
      ],
      "title": "Exploring the Effect of Context-Awareness and Popularity Calibration on Popularity Bias in POI Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03503",
        "HTML": "https://arxiv.org/html/2507.03503v2",
        "PDF": "https://arxiv.org/pdf/2507.03503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses popularity bias in POI recommendation systems using context-awareness and calibration techniques. There are no discussions on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08919",
      "abstract": "I give a very simple, apparently new proof of a tight communication lower bound for pointer chasing.",
      "authors": [
        "Emanuele Viola"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:48:35+00:00",
          "link": "https://arxiv.org/abs/2507.08919v1",
          "size": "5kb",
          "version": "v1"
        }
      ],
      "title": "Communication complexity of pointer chasing via the fixed-set lemma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08919",
        "HTML": "https://arxiv.org/html/2507.08919v1",
        "PDF": "https://arxiv.org/pdf/2507.08919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a proof related to communication complexity in pointer chasing, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09029",
      "abstract": "Distributed pre-training of large models at scale often imposes heavy memory demands on individual nodes and incurs significant intra-node communication costs. We propose a novel alternative approach that reduces the memory requirements by training small, structured subnetworks of the model on separate workers. Unlike pipelining, our method avoids inter-node activation communication and maintains bandwidth requirements that are comparable to or lower than standard data parallel communication schemes based on all-reduce. We evaluate two subnetwork construction strategies guided by the principle of ensuring uniform representation of each parameter across the distributed training setup. Our results show that the stochastic block dropping technique consistently outperforms the width-wise subnetwork construction previously explored in federated learning. We empirically attribute this superior performance to stronger gradient alignment in subnetworks that retain blocks having skip connections. Preliminary experiments highlight the promise of our approach, achieving a 20-40% reduction in memory usage without any loss in performance.",
      "authors": [
        "Vaibhav Singh",
        "Zafir Khalid",
        "Edouard Oyallon",
        "Eugene Belilovsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:25:11+00:00",
          "link": "https://arxiv.org/abs/2507.09029v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "Model Parallelism With Subnetwork Data Parallelism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09029",
        "HTML": "https://arxiv.org/html/2507.09029v1",
        "PDF": "https://arxiv.org/pdf/2507.09029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an approach to manage memory demands during distributed model pretraining, centered on subnetwork data parallelism, rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09374",
      "abstract": "Multimodal large language models (MLLMs) still perform poorly on scientific tasks, particularly those requiring multi-step and interpretable reasoning. Their limitations include insufficient scientific reasoning patterns, lack of global coherence in multi-step inference, and the absence of reflective self-correction, making them unreliable in structured scientific contexts. We introduce EduFlow, the first end-to-end framework that covers the full pipeline of educational scientific reasoning, including data selection, MCTS-based trajectory construction, model training, and output optimization. At its core is EduPRM, a process-aware reward model that critiques reasoning steps with tags and justifications. EduPRM is trained via curriculum learning on three complementary supervision sources: MCTS-guided trajectories, error-injected critiques, and teacher-student dialogues, enabling dynamic adaptation to multi-stage problem solving and iterative refinement during inference. We further propose EduMCTS, a domain-adapted search framework that introduces bootstrapping actions specifically designed for educational reasoning, such as a self-reflection mechanism that promotes reflective error correction. It further leverages EduPRM's fine-grained feedback to guide the search toward higher-quality reasoning trajectories. By applying self-consistency and rejection sampling, we constructed EduMCTS-160K, a large-scale dataset of educational reasoning trajectories. Extensive experiments demonstrate that EduFlow enhances reasoning consistency and coherence. Code, data, and models will be released.",
      "authors": [
        "Chenglin Zhu",
        "Tao Zhang",
        "Chong Li",
        "Mingan Lin",
        "Zenan Zhou",
        "Jian Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:44:32+00:00",
          "link": "https://arxiv.org/abs/2507.09374v1",
          "size": "3173kb",
          "version": "v1"
        }
      ],
      "title": "EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09374",
        "HTML": "https://arxiv.org/html/2507.09374v1",
        "PDF": "https://arxiv.org/pdf/2507.09374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces EduFlow, an end-to-end framework for educational reasoning, which includes data selection and the creation of a new dataset (EduMCTS-160K) involving detailed data processing steps like trajectory construction, making it highly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09443",
      "abstract": "Proactive maintenance strategies, such as Predictive Maintenance (PdM), play an important role in the operation of Nuclear Power Plants (NPPs), particularly due to their capacity to reduce offline time by preventing unexpected shutdowns caused by component failures.\n  In this work, we explore the use of a Convolutional Neural Network (CNN) architecture combined with a computational thermomechanical model to calculate the temperature, stress, and strain of a Pressurized Water Reactor (PWR) fuel rod during operation. This estimation relies on a limited number of temperature measurements from the cladding's outer surface. This methodology can potentially aid in developing PdM tools for nuclear reactors by enabling real-time monitoring of such systems.\n  The training, validation, and testing datasets were generated through coupled simulations involving BISON, a finite element-based nuclear fuel performance code, and the MOOSE Thermal-Hydraulics Module (MOOSE-THM). We conducted eleven simulations, varying the peak linear heat generation rates. Of these, eight were used for training, two for validation, and one for testing.\n  The CNN was trained for over 1,000 epochs without signs of overfitting, achieving highly accurate temperature distribution predictions. These were then used in a thermomechanical model to determine the stress and strain distribution within the fuel rod.",
      "authors": [
        "Luiz Aldeia Machado",
        "Victor Coppo Leite",
        "Elia Merzari",
        "Arthur Motta",
        "Roberto Ponciroli",
        "Lander Ibarra",
        "Lise Charlot"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T01:32:46+00:00",
          "link": "https://arxiv.org/abs/2507.09443v1",
          "size": "1107kb",
          "version": "v1"
        }
      ],
      "title": "Toward Developing Machine-Learning-Aided Tools for the Thermomechanical Monitoring of Nuclear Reactor Components",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09443",
        "HTML": "https://arxiv.org/html/2507.09443v1",
        "PDF": "https://arxiv.org/pdf/2507.09443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a CNN-based methodology for monitoring thermomechanical aspects of nuclear reactor components, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09509",
      "abstract": "Large language models (LLMs) have achieved top results in recent machine translation evaluations, but they are also known to be sensitive to errors and perturbations in their prompts. We systematically evaluate how both humanly plausible and synthetic errors in user prompts affect LLMs' performance on two related tasks: Machine translation and machine translation evaluation. We provide both a quantitative analysis and qualitative insights into how the models respond to increasing noise in the user prompt.\n  The prompt quality strongly affects the translation performance: With many errors, even a good prompt can underperform a minimal or poor prompt without errors. However, different noise types impact translation quality differently, with character-level and combined noisers degrading performance more than phrasal perturbations. Qualitative analysis reveals that lower prompt quality largely leads to poorer instruction following, rather than directly affecting translation quality itself. Further, LLMs can still translate in scenarios with overwhelming random noise that would make the prompt illegible to humans.",
      "authors": [
        "Patr\\'icia Schmidtov\\'a",
        "Niyati Bafna",
        "Seth Aycock",
        "Gianluca Vico",
        "Wiktor Kamzela",
        "Katharina H\\\"ammerl",
        "Vil\\'em Zouhar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:33:12+00:00",
          "link": "https://arxiv.org/abs/2507.09509v1",
          "size": "212kb",
          "version": "v1"
        }
      ],
      "title": "How Important is `Perfect' English for Machine Translation Prompts?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09509",
        "PDF": "https://arxiv.org/pdf/2507.09509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates the impact of prompt errors on LLM translation tasks, mentioning data perturbations but not focusing primarily on training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09777",
      "abstract": "We revise the definition of clickbait, which lacks current consensus, and argue that the creation of a curiosity gap is the key concept that distinguishes clickbait from other related phenomena such as sensationalism and headlines that do not deliver what they promise or diverge from the article. Therefore, we propose a new definition: clickbait is a technique for generating headlines and teasers that deliberately omit part of the information with the goal of raising the readers' curiosity, capturing their attention and enticing them to click. We introduce a new approach to clickbait detection datasets creation, by refining the concept limits and annotations criteria, minimizing the subjectivity in the decision as much as possible. Following it, we created and release TA1C (for Te Ahorr\\'e Un Click, Spanish for Saved You A Click), the first open source dataset for clickbait detection in Spanish. It consists of 3,500 tweets coming from 18 well known media sources, manually annotated and reaching a 0.825 Fleiss' K inter annotator agreement. We implement strong baselines that achieve 0.84 in F1-score.",
      "authors": [
        "Gabriel Mordecki",
        "Guillermo Moncecchi and Javier Couto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:19:08+00:00",
          "link": "https://arxiv.org/abs/2507.09777v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Te Ahorr\\'e Un Click: A Revised Definition of Clickbait and Detection in Spanish News",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09777",
        "HTML": "https://arxiv.org/html/2507.09777v1",
        "PDF": "https://arxiv.org/pdf/2507.09777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset for clickbait detection, which involves detailed data processing steps for the creation and annotation of the dataset, aligning with LLM training data processing criteria."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.16313",
      "abstract": "Utilizing large language models (LLMs) for tool planning has emerged as a promising avenue for developing general AI systems, where LLMs automatically schedule external tools (e.g., vision models) to tackle complex tasks based on task descriptions. To push this paradigm toward practical applications, it is crucial for LLMs to consider tool execution costs (e.g., execution time) for tool planning. Unfortunately, prior studies overlook the tool execution costs, leading to the generation of expensive plans whose costs outweigh their benefits in terms of task performance. To fill this gap, we propose the Cost-Aware Tool Planning with LLMs (CATP-LLM) framework, which for the first time provides a coherent design to empower LLMs for cost-aware tool planning. Specifically, To facilitate efficient concurrent tool execution and cost reduction, we design a tool planning language to enhance the LLM for creating multi-branch non-sequential plans. Moreover, we propose a cost-aware offline reinforcement learning algorithm to fine-tune the LLM to optimize the performance-cost trade-off in tool planning. In the lack of public cost-related datasets, we further present OpenCATP, the first dataset for cost-aware planning, which comprises 11,100 evaluation samples from diverse tasks. Extensive experiments show that CATP-LLM outperforms GPT-4 even when using Llama2-7B as its backbone, with the average improvement of 1.5%-93.9% in terms of plan quality. Codes and dataset are available at: https://github.com/duowuyms/OpenCATP-LLM.",
      "authors": [
        "Duo Wu",
        "Jinghe Wang",
        "Yuan Meng",
        "Yanning Zhang",
        "Le Sun",
        "Zhi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T12:05:49+00:00",
          "link": "https://arxiv.org/abs/2411.16313v1",
          "size": "947kb",
          "version": "v1"
        },
        {
          "date": "2025-04-06T15:06:17+00:00",
          "link": "https://arxiv.org/abs/2411.16313v2",
          "size": "4353kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T10:15:07+00:00",
          "link": "https://arxiv.org/abs/2411.16313v3",
          "size": "1108kb",
          "version": "v3"
        }
      ],
      "title": "CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16313",
        "HTML": "https://arxiv.org/html/2411.16313v3",
        "PDF": "https://arxiv.org/pdf/2411.16313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for cost-aware tool planning using LLMs and introduces a new dataset (OpenCATP) for cost-aware planning, but does not focus primarily on processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.16679",
      "abstract": "Tarski's theorem states that every monotone function from a complete lattice to itself has a fixed point. We analyze the query complexity of finding such a fixed point on the $k$-dimensional grid of side length $n$ under the $\\leq$ relation. In this setting, there is an unknown monotone function $f: \\{0,1,\\ldots, n-1\\}^k \\to \\{0,1,\\ldots, n-1\\}^k$ and an algorithm must query a vertex $v$ to learn $f(v)$. The goal is to find a fixed point of $f$ using as few oracle queries as possible.\n  We show that the randomized query complexity of this problem is $\\Omega\\left( \\frac{k \\cdot \\log^2{n}}{\\log{k}} \\right)$ for all $n,k \\geq 2$. This unifies and improves upon two prior results: a lower bound of $\\Omega(\\log^2{n})$ from [EPRY 2019] and a lower bound of $\\Omega\\left( \\frac{k \\cdot \\log{n}}{\\log{k}}\\right)$ from [BPR 2024], respectively.",
      "authors": [
        "Simina Br\\^anzei and Reed Phillips and Nicholas Recker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-23T18:48:00+00:00",
          "link": "https://arxiv.org/abs/2502.16679v1",
          "size": "736kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T02:45:27+00:00",
          "link": "https://arxiv.org/abs/2502.16679v2",
          "size": "272kb",
          "version": "v2"
        }
      ],
      "title": "Tarski Lower Bounds from Multi-Dimensional Herringbones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16679",
        "HTML": "https://arxiv.org/html/2502.16679v2",
        "PDF": "https://arxiv.org/pdf/2502.16679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses query complexity regarding fixed-point computation, which does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06471",
      "abstract": "Dense point tracking is a challenging task requiring the continuous tracking of every point in the initial frame throughout a substantial portion of a video, even in the presence of occlusions. Traditional methods use optical flow models to directly estimate long-range motion, but they often suffer from appearance drifting without considering temporal consistency. Recent point tracking algorithms usually depend on sliding windows for indirect information propagation from the first frame to the current one, which is slow and less effective for long-range tracking. To account for temporal consistency and enable efficient information propagation, we present a lightweight and fast model with \\textbf{S}treaming memory for dense \\textbf{PO}int \\textbf{T}racking and online video processing. The \\textbf{SPOT} framework features three core components: a customized memory reading module for feature enhancement, a sensory memory for short-term motion dynamics modeling, and a visibility-guided splatting module for accurate information propagation. This combination enables SPOT to perform dense point tracking with state-of-the-art accuracy on the CVO benchmark, as well as comparable or superior performance to offline models on sparse tracking benchmarks such as TAP-Vid and RoboTAP. Notably, SPOT with 10$\\times$ smaller parameter numbers operates at least 2$\\times$ faster than previous state-of-the-art models while maintaining the best performance on CVO. We will release the models and codes at: https://dqiaole.github.io/SPOT/.",
      "authors": [
        "Qiaole Dong and Yanwei Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T06:16:49+00:00",
          "link": "https://arxiv.org/abs/2503.06471v1",
          "size": "2790kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:43:04+00:00",
          "link": "https://arxiv.org/abs/2503.06471v2",
          "size": "8260kb",
          "version": "v2"
        }
      ],
      "title": "Online Dense Point Tracking with Streaming Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06471",
        "HTML": "https://arxiv.org/html/2503.06471v2",
        "PDF": "https://arxiv.org/pdf/2503.06471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a model for dense point tracking in videos. It does not discuss any aspect of LLM training data processing or engineering."
      },
      "tasks": [
        "Optical Flow Estimation",
        "Point Tracking"
      ],
      "repo_urls": [
        "https://github.com/dqiaole/spot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22050",
      "abstract": "Embodied planning requires agents to make coherent multi-step decisions based on dynamic visual observations and natural language goals. While recent vision-language models (VLMs) excel at static perception tasks, they struggle with the temporal reasoning, spatial understanding, and commonsense grounding needed for planning in interactive environments. In this work, we introduce a reinforcement fine-tuning framework that brings R1-style reasoning enhancement into embodied planning. We first distill a high-quality dataset from a powerful closed-source model and perform supervised fine-tuning (SFT) to equip the model with structured decision-making priors. We then design a rule-based reward function tailored to multi-step action quality and optimize the policy via Generalized Reinforced Preference Optimization (GRPO). Our approach is evaluated on Embench, a recent benchmark for interactive embodied tasks, covering both in-domain and out-of-domain scenarios. Experimental results show that our method significantly outperforms models of similar or larger scale, including GPT-4o-mini and 70B+ open-source baselines, and exhibits strong generalization to unseen environments. This work highlights the potential of reinforcement-driven reasoning to advance long-horizon planning in embodied AI.",
      "authors": [
        "Di Wu",
        "Jiaxin Fan",
        "Junzhe Zang",
        "Guanbo Wang",
        "Wei Yin",
        "Wenhao Li",
        "Bo Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T07:21:37+00:00",
          "link": "https://arxiv.org/abs/2505.22050v1",
          "size": "2082kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:27:37+00:00",
          "link": "https://arxiv.org/abs/2505.22050v2",
          "size": "1932kb",
          "version": "v2"
        }
      ],
      "title": "Reinforced Reasoning for Embodied Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22050",
        "HTML": "https://arxiv.org/html/2505.22050v2",
        "PDF": "https://arxiv.org/pdf/2505.22050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a reinforcement fine-tuning framework for embodied AI planning, mentioning dataset distillation and supervised fine-tuning, but does not primarily focus on LLM data processing methods or innovations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07586",
      "abstract": "Discrete diffusion language models learn to reconstruct text from randomly masked inputs, yet under mild assumptions their denoiser already implements the exact Bayesian posterior over the original tokens. We prove that the expected denoiser output under the forward corruption distribution recovers the true posterior, and that a simple Monte Carlo estimator converges to this posterior at rate O(1/sqrt(K)) with finite-sample concentration bounds. Building on this insight, we introduce an inference-time ensemble that runs K independent denoising passes and aggregates both posterior means and variances without any extra training. On WikiText-2, our MC-marginal sampler recovers the analytic lambda-DCE zero-shot perplexity (approximately 39) to within a few points at K=128, and its per-token variance shows a strong rank correlation with reconstruction error (Spearman rho = 0.996). This cost-proportional procedure yields calibrated uncertainty estimates and a direct trade-off between compute and posterior fidelity in discrete diffusion LMs.",
      "authors": [
        "Cooper Doyle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:42:47+00:00",
          "link": "https://arxiv.org/abs/2507.07586v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T12:37:30+00:00",
          "link": "https://arxiv.org/abs/2507.07586v2",
          "size": "64kb",
          "version": "v2"
        }
      ],
      "title": "Your Absorbing Discrete Diffusion Secretly Models the Bayesian Posterior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07586",
        "HTML": "https://arxiv.org/html/2507.07586v2",
        "PDF": "https://arxiv.org/pdf/2507.07586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores inference techniques in discrete diffusion models and Bayesian posterior calculation. It does not focus on processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08884",
      "abstract": "We present a visualization infrastructure that maps data elements to agents, which have behaviors parameterized by those elements. Dynamic visualizations emerge as the agents change position, alter appearance and respond to one other. Agents move to minimize the difference between displayed agent-to-agent distances, and an input matrix of ideal distances. Our current application is visualization of streaming text. Each agent represents a significant word, visualizing it by displaying the word itself, centered in a circle sized by the frequency of word occurrence. We derive the ideal distance matrix from word cooccurrence, mapping higher co-occurrence to lower distance. To depict co-occurrence in its textual context, the ratio of intersection to circle area approximates the ratio of word co-occurrence to frequency. A networked backend process gathers articles from news feeds, blogs, Digg or Twitter, exploiting online search APIs to focus on user-chosen topics. Resulting visuals reveal the primary topics in text streams as clusters, with agent-based layout moving without instability as data streams change dynamically.",
      "authors": [
        "Jordan Riley Benson",
        "David Crist",
        "Phil Lafleur",
        "Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:01:57+00:00",
          "link": "https://arxiv.org/abs/2507.08884v1",
          "size": "388kb",
          "version": "v1"
        }
      ],
      "title": "Agent-based visualization of streaming text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08884",
        "PDF": "https://arxiv.org/pdf/2507.08884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a visualization infrastructure for streaming text, focusing on agent-based visualization. It does not discuss processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09387",
      "abstract": "We show that words with factor complexity 2n+1 have critical exponent at least $\\mu$, where $\\mu=2+\\frac{1}{\\lambda^2-1}= 2.4808726\\cdots$, where $\\lambda=1.7548777$ is the real zero of $x^3-2x+x-1=0$. This confirms a conjecture of Shallit and Shur.",
      "authors": [
        "James D. Currie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:07:24+00:00",
          "link": "https://arxiv.org/abs/2507.09387v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Words with factor somplexity $2n+1$ and minimal critical exponent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09387",
        "HTML": "https://arxiv.org/html/2507.09387v1",
        "PDF": "https://arxiv.org/pdf/2507.09387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses combinatorial properties of words and does not involve any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10121",
      "abstract": "Soft continuum arms (SCAs) promise versatile manipulation through mechanical compliance, for assistive devices, agriculture, search applications, or surgery. However, SCAs' real-world use is challenging, partly due to their hard-to-control non-linear behavior. Here, a simulation framework for SCAs modularly assembled out of fiber reinforced elastomeric enclosures (FREEs) is developed and integrated with a video-tracking system for experimental testing and control design.",
      "authors": [
        "Seung Hyun Kim",
        "Jiamiao Guo",
        "Arman Tekinalp",
        "Heng-Sheng Chang",
        "Ugur Akcal",
        "Tixian Wang",
        "Darren Biskup",
        "Benjamin Walt",
        "Girish Chowdhary",
        "Girish Krishnan",
        "Prashant G. Mehta",
        "Mattia Gazzola"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:05:07+00:00",
          "link": "https://arxiv.org/abs/2507.10121v1",
          "size": "17216kb",
          "version": "v1"
        }
      ],
      "title": "Simulations and experiments with assemblies of fiber-reinforced soft actuators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10121",
        "HTML": "https://arxiv.org/html/2507.10121v1",
        "PDF": "https://arxiv.org/pdf/2507.10121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development and testing of a simulation framework for soft actuators, without mention of LLM training data or data processing techniques relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10457",
      "abstract": "The integration of large language models (LLMs) into enterprise systems has created a new class of covert security vulnerabilities, particularly within logic-execution layers and persistent-memory contexts. In this paper, we introduce Logic-Layer Prompt Control Injection (LPCI), a novel attack category in which encoded, delayed, and conditionally triggered payloads are embedded in memory, vector stores, or tool outputs. These payloads can bypass conventional input filters and trigger unauthorised behaviour across sessions.",
      "authors": [
        "Hammad Atta",
        "Ken Huang",
        "Manish Bhatt",
        "Kamal Ahmed",
        "Muhammad Aziz Ul Haq",
        "Yasir Mehmood"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:37:05+00:00",
          "link": "https://arxiv.org/abs/2507.10457v1",
          "size": "1761kb",
          "version": "v1"
        }
      ],
      "title": "Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10457",
        "HTML": "https://arxiv.org/html/2507.10457v1",
        "PDF": "https://arxiv.org/pdf/2507.10457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a security vulnerability related to large language models in enterprise systems, but does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10494",
      "abstract": "Split Learning (SL) -- splits a model into two distinct parts to help protect client data while enhancing Machine Learning (ML) processes. Though promising, SL has proven vulnerable to different attacks, thus raising concerns about how effective it may be in terms of data privacy. Recent works have shown promising results for securing SL through the use of a novel paradigm, named Function Secret Sharing (FSS), in which servers obtain shares of a function they compute and operate on a public input hidden with a random mask. However, these works fall short in addressing the rising number of attacks which exist on SL. In SplitHappens, we expand the combination of FSS and SL to U-shaped SL. Similarly to other works, we are able to make use of the benefits of SL by reducing the communication and computational costs of FSS. However, a U-shaped SL provides a higher security guarantee than previous works, allowing a client to keep the labels of the training data secret, without having to share them with the server. Through this, we are able to generalize the security analysis of previous works and expand it to different attack vectors, such as modern model inversion attacks as well as label inference attacks. We tested our approach for two different convolutional neural networks on different datasets. These experiments show the effectiveness of our approach in reducing the training time as well as the communication costs when compared to simply using FSS while matching prior accuracy.",
      "authors": [
        "Tanveer Khan",
        "Mindaugas Budzys",
        "Antonis Michalas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:18:07+00:00",
          "link": "https://arxiv.org/abs/2507.10494v1",
          "size": "1259kb",
          "version": "v1"
        }
      ],
      "title": "Split Happens: Combating Advanced Threats with Split Learning and Function Secret Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10494",
        "HTML": "https://arxiv.org/html/2507.10494v1",
        "PDF": "https://arxiv.org/pdf/2507.10494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about data privacy in split learning, focusing on security against attacks rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2209.10517",
      "abstract": "In this paper, we obtain the following equally important new result:\n  We first extend the notion of {\\em probabilistic pushdown automaton} to {\\em probabilistic $\\omega$-pushdown automaton} for the first time and study the model-checking question of {\\em stateless probabilistic $\\omega$-pushdown system ($\\omega$-pBPA)} against $\\omega$-PCTL (defined by Chatterjee, Sen, and Henzinger in \\cite{CSH08}), showing that model-checking of {\\em stateless probabilistic $\\omega$-pushdown systems ($\\omega$-pBPA)} against $\\omega$-PCTL is generally undecidable. Our approach is to construct $\\omega$-PCTL formulas encoding the {\\em Post Correspondence Problem}.",
      "authors": [
        "Deren Lin",
        "Tianrong Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2022-09-21T17:33:48+00:00",
          "link": "https://arxiv.org/abs/2209.10517v1",
          "size": "105kb",
          "version": "v1"
        },
        {
          "date": "2022-09-22T13:59:51+00:00",
          "link": "https://arxiv.org/abs/2209.10517v2",
          "size": "109kb",
          "version": "v2"
        },
        {
          "date": "2022-10-28T10:37:35+00:00",
          "link": "https://arxiv.org/abs/2209.10517v3",
          "size": "109kb",
          "version": "v3"
        },
        {
          "date": "2023-03-28T12:38:45+00:00",
          "link": "https://arxiv.org/abs/2209.10517v4",
          "size": "109kb",
          "version": "v4"
        },
        {
          "date": "2023-06-07T15:51:37+00:00",
          "link": "https://arxiv.org/abs/2209.10517v5",
          "size": "147kb",
          "version": "v5"
        },
        {
          "date": "2023-06-11T02:07:30+00:00",
          "link": "https://arxiv.org/abs/2209.10517v6",
          "size": "147kb",
          "version": "v6"
        },
        {
          "date": "2023-08-08T00:42:01+00:00",
          "link": "https://arxiv.org/abs/2209.10517v7",
          "size": "153kb",
          "version": "v7"
        },
        {
          "date": "2024-07-07T12:14:42+00:00",
          "link": "https://arxiv.org/abs/2209.10517v8",
          "size": "145kb",
          "version": "v8"
        },
        {
          "date": "2024-07-21T17:27:23+00:00",
          "link": "https://arxiv.org/abs/2209.10517v9",
          "size": "66kb",
          "version": "v9"
        },
        {
          "date": "2024-08-05T08:42:58+00:00",
          "link": "https://arxiv.org/abs/2209.10517v10",
          "size": "76kb",
          "version": "v10"
        },
        {
          "date": "2024-08-19T01:48:55+00:00",
          "link": "https://arxiv.org/abs/2209.10517v11",
          "size": "80kb",
          "version": "v11"
        },
        {
          "date": "2025-06-16T13:21:53+00:00",
          "link": "https://arxiv.org/abs/2209.10517v12",
          "size": "44kb",
          "version": "v12"
        },
        {
          "date": "2025-07-03T13:41:03+00:00",
          "link": "https://arxiv.org/abs/2209.10517v13",
          "size": "40kb",
          "version": "v13"
        },
        {
          "date": "2025-07-14T17:20:06+00:00",
          "link": "https://arxiv.org/abs/2209.10517v14",
          "size": "30kb",
          "version": "v14"
        }
      ],
      "title": "On Probabilistic $\\omega$-Pushdown Systems, and $\\omega$-Probabilistic Computational Tree Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.10517",
        "HTML": "https://arxiv.org/html/2209.10517",
        "PDF": "https://arxiv.org/pdf/2209.10517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper extends the concept of probabilistic pushdown automaton and does not cover any LLM training data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.11347",
      "abstract": "Designing optimal prompts for Large Language Models (LLMs) is a complicated and resource-intensive task, often requiring substantial human expertise and effort. Existing approaches typically separate the optimization of prompt instructions and in-context learning examples, leading to incohesive prompts that are defined and represented by suboptimal task performance. To overcome these challenges, we propose a novel Cohesive In-Context Prompt Optimization framework that refines both prompt instructions and examples. However, formulating such an optimization in the discrete and high-dimensional space of natural language poses significant challenges in both convergence and computational efficiency. To address these issues, we introduce SEE, a scalable and efficient prompt optimization framework that adopts metaheuristic optimization principles and strategically balances exploration and exploitation to enhance optimization performance and achieve efficient convergence. SEE features a quad-phased design that alternates between global traversal (exploration) and local optimization (exploitation) and adaptively chooses LLM operators during the optimization process. We have conducted a comprehensive evaluation across 35 benchmark tasks, and SEE significantly outperforms state-of-the-art baseline methods by a large margin, achieving an average performance gain of 13.94 while reducing computational costs by 58.67.",
      "authors": [
        "Wendi Cui",
        "Zhuohang Li",
        "Hao Sun",
        "Damien Lopez",
        "Kamalika Das",
        "Bradley Malin",
        "Sricharan Kumar",
        "Jiaxin Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-17T17:47:10+00:00",
          "link": "https://arxiv.org/abs/2402.11347v1",
          "size": "1323kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T20:31:55+00:00",
          "link": "https://arxiv.org/abs/2402.11347v2",
          "size": "367kb",
          "version": "v2"
        }
      ],
      "title": "SEE: Strategic Exploration and Exploitation for Cohesive In-Context Prompt Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.11347",
        "HTML": "https://arxiv.org/html/2402.11347v2",
        "PDF": "https://arxiv.org/pdf/2402.11347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses prompt optimization for LLMs, which may involve some data processing steps, but primarily focuses on optimization techniques rather than training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.13748",
      "abstract": "We present TheraGen, an advanced AI-powered mental health chatbot utilizing the LLaMA 2 7B model. This approach builds upon recent advancements in language models and transformer architectures. TheraGen provides all-day personalized, compassionate mental health care by leveraging a large dataset of 1 million conversational entries, combining anonymized therapy transcripts, online mental health discussions, and psychological literature, including APA resources. Our implementation employs transfer learning, fine-tuning, and advanced training techniques to optimize performance. TheraGen offers a user-friendly interface for seamless interaction, providing empathetic responses and evidence-based coping strategies. Evaluation results demonstrate high user satisfaction rates, with 94% of users reporting improved mental well-being. The system achieved a BLEU score of 0.67 and a ROUGE score of 0.62, indicating strong response accuracy. With an average response time of 1395 milliseconds, TheraGen ensures real-time, efficient support. While not a replacement for professional therapy, TheraGen serves as a valuable complementary tool, significantly improving user well-being and addressing the accessibility gap in mental health treatments. This paper details TheraGen's architecture, training methodology, ethical considerations, and future directions, contributing to the growing field of AI-assisted mental healthcare and offering a scalable solution to the pressing need for mental health support.",
      "authors": [
        "Kartikey Doshi",
        "Jimit Shah",
        "Narendra Shekokar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-12T17:15:44+00:00",
          "link": "https://arxiv.org/abs/2409.13748v1",
          "size": "1809kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T19:43:13+00:00",
          "link": "https://arxiv.org/abs/2409.13748v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "TheraGen: Therapy for Every Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13748",
        "PDF": "https://arxiv.org/pdf/2409.13748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of TheraGen involving fine-tuning and training over a dataset, but it does not primarily focus on LLM training data processing beyond standard use."
      },
      "tasks": [
        "Chatbot",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19045",
      "abstract": "This paper addresses sampling-based trajectory optimization for risk-aware navigation under stochastic dynamics. Typically such approaches operate by computing $\\tilde{N}$ perturbed rollouts around the nominal dynamics to estimate the collision risk associated with a sequence of control commands. We consider a setting where it is expensive to estimate risk using perturbed rollouts, for example, due to expensive collision-checks. We put forward two key contributions. First, we develop an algorithm that distills the statistical information from a larger set of rollouts to a reduced-set with sample size $N<<\\tilde{N}$. Consequently, we estimate collision risk using just $N$ rollouts instead of $\\tilde{N}$. Second, we formulate a novel surrogate for the collision risk that can leverage the distilled statistical information contained in the reduced-set. We formalize both algorithmic contributions using distribution embedding in Reproducing Kernel Hilbert Space (RKHS) and Maximum Mean Discrepancy (MMD). We perform extensive benchmarking to demonstrate that our MMD-based approach leads to safer trajectories at low sample regime than existing baselines using Conditional Value-at Risk (CVaR) based collision risk estimate.",
      "authors": [
        "Basant Sharma",
        "Arun Kumar Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T11:17:19+00:00",
          "link": "https://arxiv.org/abs/2501.19045v1",
          "size": "11614kb",
          "version": "v1"
        },
        {
          "date": "2025-04-10T13:05:43+00:00",
          "link": "https://arxiv.org/abs/2501.19045v2",
          "size": "11625kb",
          "version": "v2"
        }
      ],
      "title": "Trajectory Optimization Under Stochastic Dynamics Leveraging Maximum Mean Discrepancy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19045",
        "HTML": "https://arxiv.org/html/2501.19045",
        "PDF": "https://arxiv.org/pdf/2501.19045"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about trajectory optimization under stochastic dynamics, specifically in robotics, and does not involve any LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/basant1861/mpc-mmd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00951",
      "abstract": "Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.",
      "authors": [
        "Rizwan Qureshi",
        "Ranjan Sapkota",
        "Abbas Shah",
        "Amgad Muneer",
        "Anas Zafar",
        "Ashmal Vayani",
        "Maged Shoman",
        "Abdelrahman B. M. Eldaly",
        "Kai Zhang",
        "Ferhat Sadak",
        "Shaina Raza",
        "Xinqi Fan",
        "Ravid Shwartz-Ziv",
        "Hong Yan",
        "Vinjia Jain",
        "Aman Chadha",
        "Manoj Karkee",
        "Jia Wu",
        "Seyedali Mirjalili"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T16:52:25+00:00",
          "link": "https://arxiv.org/abs/2507.00951v1",
          "size": "9572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T21:09:25+00:00",
          "link": "https://arxiv.org/abs/2507.00951v2",
          "size": "12347kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T02:50:17+00:00",
          "link": "https://arxiv.org/abs/2507.00951v3",
          "size": "12347kb",
          "version": "v3"
        }
      ],
      "title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00951",
        "HTML": "https://arxiv.org/html/2507.00951v3",
        "PDF": "https://arxiv.org/pdf/2507.00951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper primarily discusses the cognitive foundations and architectural developments for Artificial General Intelligence, and does not address the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05736",
      "abstract": "Time-reversal of unitary evolution is fundamental in quantum information processing. Many scenarios, particularly those in quantum learning and metrology, assume free access to the time-reverse of an unknown unitary. In this paper, we settle the query complexity of the unitary time-reversal task: approximately implementing $U^{-1}$ given only black-box access to an unknown $d$-dimensional unitary $U$. We provide a tight query lower bound $\\Omega((1-\\epsilon)d^2)$ for the unitary time-reversal to within diamond norm error $\\epsilon$. Notably, our lower bound applies to general coherent protocols with unbounded ancillas, and holds even when $\\epsilon$ is an average-case distance error. Moreover, our result implies a query lower bound $\\Omega(d^2)$ for approximately implementing control-$U$ up to an irrelevant phase, which is also tight with respect to the dimension.",
      "authors": [
        "Kean Chen and Nengkun Yu and Zhicheng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:32:39+00:00",
          "link": "https://arxiv.org/abs/2507.05736v1",
          "size": "159kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T07:10:14+00:00",
          "link": "https://arxiv.org/abs/2507.05736v2",
          "size": "158kb",
          "version": "v2"
        }
      ],
      "title": "Tight Bound for Quantum Unitary Time-Reversal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05736",
        "HTML": "https://arxiv.org/html/2507.05736v2",
        "PDF": "https://arxiv.org/pdf/2507.05736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum unitary time-reversal and provides query complexity bounds, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09158",
      "abstract": "In spinal vertebral mobility disease, accurately extracting and contouring vertebrae is essential for assessing mobility impairments and monitoring variations during flexion-extension movements. Precise vertebral contouring plays a crucial role in surgical planning; however, this process is traditionally performed manually by radiologists or surgeons, making it labour-intensive, time-consuming, and prone to human error. In particular, mobility disease analysis requires the individual contouring of each vertebra, which is both tedious and susceptible to inconsistencies. Automated methods provide a more efficient alternative, enabling vertebra identification, segmentation, and contouring with greater accuracy and reduced time consumption. In this study, we propose a novel U-Net variation designed to accurately segment thoracic vertebrae from anteroposterior view on X-Ray images. Our proposed approach, incorporating a ``sandwich\" U-Net structure with dual activation functions, achieves a 4.1\\% improvement in Dice score compared to the baseline U-Net model, enhancing segmentation accuracy while ensuring reliable vertebral contour extraction.",
      "authors": [
        "Sunil Munthumoduku Krishna Murthy",
        "Kumar Rajamani",
        "Srividya Tirunellai Rajamani",
        "Yupei Li",
        "Qiyang Sun",
        "and Bjoern W. Schuller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T06:40:18+00:00",
          "link": "https://arxiv.org/abs/2507.09158v1",
          "size": "478kb",
          "version": "v1"
        }
      ],
      "title": "Automatic Contouring of Spinal Vertebrae on X-Ray using a Novel Sandwich U-Net Architecture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09158",
        "HTML": "https://arxiv.org/html/2507.09158v1",
        "PDF": "https://arxiv.org/pdf/2507.09158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a U-Net architecture for vertebrae contouring in X-Ray images, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09338",
      "abstract": "Recent methods for ego-centric Traffic Anomaly Detection (TAD) often rely on complex multi-stage or multi-representation fusion architectures, yet it remains unclear whether such complexity is necessary. Recent findings in visual perception suggest that foundation models, enabled by advanced pre-training, allow simple yet flexible architectures to outperform specialized designs. Therefore, in this work, we investigate an architecturally simple encoder-only approach using plain Video Vision Transformers (Video ViTs) and study how pre-training enables strong TAD performance. We find that: (i) strong pre-training enables simple encoder-only models to match or even surpass the performance of specialized state-of-the-art TAD methods, while also being significantly more efficient; (ii) although weakly- and fully-supervised pre-training are advantageous on standard benchmarks, we find them less effective for TAD. Instead, self-supervised Masked Video Modeling (MVM) provides the strongest signal; and (iii) Domain-Adaptive Pre-Training (DAPT) on unlabeled driving videos further improves downstream performance, without requiring anomalous examples. Our findings highlight the importance of pre-training and show that effective, efficient, and scalable TAD models can be built with minimal architectural complexity. We release our code, domain-adapted encoders, and fine-tuned models to support future work: https://github.com/tue-mps/simple-tad.",
      "authors": [
        "Svetlana Orlova",
        "Tommie Kerssies",
        "Brun\\'o B. Englert",
        "Gijs Dubbelman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:36:49+00:00",
          "link": "https://arxiv.org/abs/2507.09338v1",
          "size": "2293kb",
          "version": "v1"
        }
      ],
      "title": "Simplifying Traffic Anomaly Detection with Video Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09338",
        "HTML": "https://arxiv.org/html/2507.09338v1",
        "PDF": "https://arxiv.org/pdf/2507.09338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on architectural simplification in traffic anomaly detection using video models and pre-training. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09431",
      "abstract": "Achieving controlled burning plasma in tokamaks requires precise regulation of external particle and energy sources to reach and maintain target core densities and temperatures. This work presents an inverse modeling approach using a multinodal plasma dynamics model based on neural ordinary differential equations (Neural ODEs). Given a desired time evolution of nodal quantities such as deuteron density or electron temperature, we compute the external source profiles, such as neutral beam injection (NBI) power, that drive the plasma toward the specified behavior. The approach is implemented within the NeuralPlasmaODE framework, which models multi-region, multi-timescale transport and incorporates physical mechanisms including radiation, auxiliary heating, and internodal energy exchange. By formulating the control task as an optimization problem, we use automatic differentiation through the Neural ODE solver to minimize the discrepancy between simulated and target trajectories. This framework transforms the forward simulation tool into a control-oriented model and provides a practical method for computing external source profiles in both current and future fusion devices.",
      "authors": [
        "Zefang Liu",
        "Weston M. Stacey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Plasma Physics (physics.plasm-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:56:47+00:00",
          "link": "https://arxiv.org/abs/2507.09431v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing External Sources for Controlled Burning Plasma in Tokamaks with Neural Ordinary Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09431",
        "HTML": "https://arxiv.org/html/2507.09431v1",
        "PDF": "https://arxiv.org/pdf/2507.09431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for optimizing plasma control in tokamaks using Neural ODEs, which is unrelated to processing or preparing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09489",
      "abstract": "The design of urban road networks significantly influences traffic conditions, underscoring the importance of informed traffic planning. Traffic planning experts rely on specialized platforms to simulate traffic systems, assessing the efficacy of the road network across various states of modifications. Nevertheless, a prevailing issue persists: many existing traffic planning platforms exhibit inefficiencies in flexibly interacting with the road network's structure and attributes and intuitively comparing multiple states during the iterative planning process. This paper introduces TraSculptor, an interactive planning decision-making system. To develop TraSculptor, we identify and address two challenges: interactive modification of road networks and intuitive comparison of multiple network states. For the first challenge, we establish flexible interactions to enable experts to easily and directly modify the road network on the map. For the second challenge, we design a comparison view with a history tree of multiple states and a road-state matrix to facilitate intuitive comparison of road network states. To evaluate TraSculptor, we provided a usage scenario where the Braess's paradox was showcased, invited experts to perform a case study on the Sioux Falls network, and collected expert feedback through interviews.",
      "authors": [
        "Zikun Deng",
        "Yuanbang Liu",
        "Mingrui Zhu",
        "Da Xiang",
        "Haiyue Yu",
        "Zicheng Su",
        "Qinglong Lu",
        "Tobias Schreck",
        "Yi Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:23:41+00:00",
          "link": "https://arxiv.org/abs/2507.09489v1",
          "size": "6710kb",
          "version": "v1"
        }
      ],
      "title": "TraSculptor: Visual Analytics for Enhanced Decision-Making in Road Traffic Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09489",
        "HTML": "https://arxiv.org/html/2507.09489v1",
        "PDF": "https://arxiv.org/pdf/2507.09489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around a traffic planning decision-making system, without any mention of LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09952",
      "abstract": "Recommender systems inherently exhibit a low-rank structure in latent space. A key challenge is to define meaningful and measurable distances in the latent space to capture user-user, item-item, user-item relationships effectively. In this work, we establish that distances in the latent space can be systematically approximated using row-wise and column-wise distances in the observed matrix, providing a novel perspective on distance estimation. To refine the distance estimation, we introduce the correction based on empirical variance estimator to account for noise-induced non-centrality. The novel distance estimation enables a more structured approach to constructing neighborhoods, leading to the Radial Neighborhood Estimator (RNE), which constructs neighborhoods by including both overlapped and partially overlapped user-item pairs and employs neighborhood smoothing via localized kernel regression to improve imputation accuracy. We provide the theoretical asymptotic analysis for the proposed estimator. We perform evaluations on both simulated and real-world datasets, demonstrating that RNE achieves superior performance compared to existing collaborative filtering and matrix factorization methods. While our primary focus is on distance estimation in latent space, we find that RNE also mitigates the ``cold-start'' problem.",
      "authors": [
        "Zerui Zhang",
        "Yumou Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.09952v1",
          "size": "364kb",
          "version": "v1"
        }
      ],
      "title": "Radial Neighborhood Smoothing Recommender System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09952",
        "HTML": "https://arxiv.org/html/2507.09952v1",
        "PDF": "https://arxiv.org/pdf/2507.09952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses distance estimation within latent space for recommender systems, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09994",
      "abstract": "Policy iteration (PI) is a widely used algorithm for synthesizing optimal feedback control policies across many engineering and scientific applications. When PI is deployed on infinite-horizon, nonlinear, autonomous optimal-control problems, however, a number of significant theoretical challenges emerge - particularly when the computational state space is restricted to a bounded domain. In this paper, we investigate these challenges and show that the viability of PI in this setting hinges on the existence, uniqueness, and regularity of solutions to the Generalized Hamilton-Jacobi-Bellman (GHJB) equation solved at each iteration. To ensure a well-posed iterative scheme, the GHJB solution must possess sufficient smoothness, and the domain on which the GHJB equation is solved must remain forward-invariant under the closed-loop dynamics induced by the current policy. Although fundamental to the method's convergence, previous studies have largely overlooked these aspects. This paper closes that gap by introducing a constructive procedure that guarantees forward invariance of the computational domain throughout the entire PI sequence and by establishing sufficient conditions under which a suitably regular GHJB solution exists at every iteration. Numerical results are presented for a grid-based implementation of PI to support the theoretical findings.",
      "authors": [
        "Tobias Ehring and Behzad Azmi and Bernard Haasdonk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:28:19+00:00",
          "link": "https://arxiv.org/abs/2507.09994v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "On the Convergence of the Policy Iteration for Infinite-Horizon Nonlinear Optimal Control Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09994",
        "HTML": "https://arxiv.org/html/2507.09994v1",
        "PDF": "https://arxiv.org/pdf/2507.09994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with policy iteration for optimal control problems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10160",
      "abstract": "Federated Learning has emerged as a leading paradigm for decentralized, privacy-preserving learning, particularly relevant in the era of interconnected edge devices equipped with sensors. However, the practical implementation of Federated Learning faces three primary challenges: the need for human involvement in costly data labelling processes for target adaptation, covariate shift in client device data collection due to environmental factors affecting sensors, leading to discrepancies between source and target samples, and the impracticality of continuous or regular model updates in resource-constrained environments due to limited data transmission capabilities and technical constraints on channel availability and energy efficiency. To tackle these issues, we expand upon an efficient and scalable Federated Learning framework tailored for real-world client adaptation in industrial settings. This framework leverages a pre-trained source model comprising a deep backbone, an adaptation module, and a classifier running on a powerful server. By freezing the backbone and classifier during client adaptation on resource-constrained devices, we allow the domain adaptive linear layer to handle target domain adaptation, thus minimizing overall computational overhead. Furthermore, this setup, designated as FedAcross+, is extended to encompass the processing of streaming data, thereby rendering the solution suitable for non-stationary environments. Extensive experimental results demonstrate the effectiveness of FedAcross+ in achieving competitive adaptation on low-end client devices with limited target samples, successfully addressing the challenge of domain shift. Moreover, our framework accommodates sporadic model updates within resource-constrained environments, ensuring practical and seamless deployment.",
      "authors": [
        "Manuel R\\\"oder and Christoph Raab and Frank-Michael Schleif"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:18:33+00:00",
          "link": "https://arxiv.org/abs/2507.10160v1",
          "size": "5776kb",
          "version": "v1"
        }
      ],
      "title": "Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10160",
        "HTML": "https://arxiv.org/html/2507.10160v1",
        "PDF": "https://arxiv.org/pdf/2507.10160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Federated Learning and domain adaptation for model deployment but does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.14971",
      "abstract": "Modern SAT and SMT solvers are designed to handle problems expressed in Conjunctive Normal Form (CNF) so that non-CNF problems must be CNF-ized upfront, typically by using variants of either Tseitin or Plaisted and Greenbaum transformations. When passing from plain solving to enumeration, however, the capability of producing partial satisfying assignments that are as small as possible becomes crucial, which raises the question of whether such CNF encodings are also effective for enumeration.\n  In this paper, we investigate both theoretically and empirically the effectiveness of CNF conversions for SAT and SMT enumeration. On the negative side, we show that: (i) Tseitin transformation prevents the solver from producing short partial assignments, thus seriously affecting the effectiveness of enumeration; (ii) Plaisted and Greenbaum transformation overcomes this problem only in part. On the positive side, we prove theoretically and we show empirically that combining Plaisted and Greenbaum transformation with NNF preprocessing upfront -- which is typically not used in solving -- can fully overcome the problem and can drastically reduce both the number of partial assignments and the execution time.",
      "authors": [
        "Gabriele Masina",
        "Giuseppe Spallitta and Roberto Sebastiani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-27T08:04:14+00:00",
          "link": "https://arxiv.org/abs/2303.14971v1",
          "size": "1338kb",
          "version": "v1"
        },
        {
          "date": "2023-03-28T09:18:51+00:00",
          "link": "https://arxiv.org/abs/2303.14971v2",
          "size": "1338kb",
          "version": "v2"
        },
        {
          "date": "2023-04-03T09:40:04+00:00",
          "link": "https://arxiv.org/abs/2303.14971v3",
          "size": "1338kb",
          "version": "v3"
        },
        {
          "date": "2023-06-05T10:19:43+00:00",
          "link": "https://arxiv.org/abs/2303.14971v4",
          "size": "2177kb",
          "version": "v4"
        },
        {
          "date": "2024-02-09T16:50:29+00:00",
          "link": "https://arxiv.org/abs/2303.14971v5",
          "size": "5297kb",
          "version": "v5"
        },
        {
          "date": "2024-11-19T13:27:41+00:00",
          "link": "https://arxiv.org/abs/2303.14971v6",
          "size": "8579kb",
          "version": "v6"
        },
        {
          "date": "2025-06-20T09:42:14+00:00",
          "link": "https://arxiv.org/abs/2303.14971v7",
          "size": "8702kb",
          "version": "v7"
        }
      ],
      "title": "On CNF Conversion for SAT and SMT Enumeration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.14971",
        "HTML": "https://arxiv.org/html/2303.14971",
        "PDF": "https://arxiv.org/pdf/2303.14971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines CNF conversions for SAT and SMT problem solving and does not relate to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/masinag/allsat-cnf"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.10563",
      "abstract": "We present MEGA-Bench, an evaluation suite that scales multimodal evaluation to over 500 real-world tasks, to address the highly heterogeneous daily use cases of end users. Our objective is to optimize for a set of high-quality data samples that cover a highly diverse and rich set of multimodal tasks, while enabling cost-effective and accurate model evaluation. In particular, we collected 505 realistic tasks encompassing over 8,000 samples from 16 expert annotators to extensively cover the multimodal task space. Instead of unifying these problems into standard multi-choice questions (like MMMU, MMBench, and MMT-Bench), we embrace a wide range of output formats like numbers, phrases, code, \\LaTeX, coordinates, JSON, free-form, etc. To accommodate these formats, we developed over 40 metrics to evaluate these tasks. Unlike existing benchmarks, MEGA-Bench offers a fine-grained capability report across multiple dimensions (e.g., application, input type, output format, skill), allowing users to interact with and visualize model capabilities in depth. We evaluate a wide variety of frontier vision-language models on MEGA-Bench to understand their capabilities across these dimensions.",
      "authors": [
        "Jiacheng Chen",
        "Tianhao Liang",
        "Sherman Siu",
        "Zhengqing Wang",
        "Kai Wang",
        "Yubo Wang",
        "Yuansheng Ni",
        "Wang Zhu",
        "Ziyan Jiang",
        "Bohan Lyu",
        "Dongfu Jiang",
        "Xuan He",
        "Yuan Liu",
        "Hexiang Hu",
        "Xiang Yue",
        "Wenhu Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T14:42:12+00:00",
          "link": "https://arxiv.org/abs/2410.10563v1",
          "size": "14681kb",
          "version": "v1"
        },
        {
          "date": "2024-11-12T11:16:43+00:00",
          "link": "https://arxiv.org/abs/2410.10563v2",
          "size": "14919kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T23:07:08+00:00",
          "link": "https://arxiv.org/abs/2410.10563v3",
          "size": "14918kb",
          "version": "v3"
        }
      ],
      "title": "MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10563",
        "HTML": "https://arxiv.org/html/2410.10563v3",
        "PDF": "https://arxiv.org/pdf/2410.10563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on evaluating models across multimodal tasks rather than on processing or creating LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "TIGER-Lab/MEGA-Bench",
          "downloads": "1622",
          "likes": "21",
          "link": "https://huggingface.co/datasets/TIGER-Lab/MEGA-Bench"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/TIGER-AI-Lab/MEGA-Bench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05383",
      "abstract": "The attention mechanism has transformed artificial intelligence research by its ability to learn relations between objects. In this work, we explore how a many-body wavefunction ansatz constructed from a large-parameter self-attention neural network can be used to solve the interacting electron problem in solids. By a systematic neural-network variational Monte Carlo study on a moir\\'e quantum material, we demonstrate that the self-attention ansatz provides an accurate and efficient solution without human bias. Moreover, our numerical study finds that the required number of variational parameters scales roughly as $N^2$ with the number of electrons, which opens a path towards efficient large-scale simulations.",
      "authors": [
        "Max Geier",
        "Khachatur Nazaryan",
        "Timothy Zaklama",
        "Liang Fu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T23:41:41+00:00",
          "link": "https://arxiv.org/abs/2502.05383v1",
          "size": "8425kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T02:05:44+00:00",
          "link": "https://arxiv.org/abs/2502.05383v2",
          "size": "18829kb",
          "version": "v2"
        },
        {
          "date": "2025-06-14T19:39:10+00:00",
          "link": "https://arxiv.org/abs/2502.05383v3",
          "size": "18832kb",
          "version": "v3"
        }
      ],
      "title": "Is attention all you need to solve the correlated electron problem?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05383",
        "HTML": "https://arxiv.org/html/2502.05383",
        "PDF": "https://arxiv.org/pdf/2502.05383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the application of attention mechanisms for solving electron problems in quantum materials, without mentioning LLM training data processing or dataset creation."
      },
      "tasks": [
        "All",
        "Variational Monte Carlo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02240",
      "abstract": "Text-to-SQL, the task of translating natural language questions into SQL queries, plays a crucial role in enabling non-experts to interact with databases. While recent advancements in large language models (LLMs) have significantly enhanced text-to-SQL performance, existing approaches face notable limitations in real-world text-to-SQL applications. Prompting-based methods often depend on closed-source LLMs, which are expensive, raise privacy concerns, and lack customization. Fine-tuning-based methods, on the other hand, suffer from poor generalizability due to the limited coverage of publicly available training data. To overcome these challenges, we propose a novel and scalable text-to-SQL data synthesis framework for automatically synthesizing large-scale, high-quality, and diverse datasets without extensive human intervention. Using this framework, we introduce SynSQL-2.5M, the first million-scale text-to-SQL dataset, containing 2.5 million samples spanning over 16,000 synthetic databases. Each sample includes a database, SQL query, natural language question, and chain-of-thought (CoT) solution. Leveraging SynSQL-2.5M, we develop OmniSQL, a powerful open-source text-to-SQL model available in three sizes: 7B, 14B, and 32B. Extensive evaluations across nine datasets demonstrate that OmniSQL achieves state-of-the-art performance, matching or surpassing leading closed-source and open-source LLMs, including GPT-4o and DeepSeek-V3, despite its smaller size. We release all code, datasets, and models to support further research.",
      "authors": [
        "Haoyang Li",
        "Shang Wu",
        "Xiaokang Zhang",
        "Xinmei Huang",
        "Jing Zhang",
        "Fuxin Jiang",
        "Shuai Wang",
        "Tieying Zhang",
        "Jianjun Chen",
        "Rui Shi",
        "Hong Chen",
        "Cuiping Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T03:30:56+00:00",
          "link": "https://arxiv.org/abs/2503.02240v1",
          "size": "7058kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T14:49:18+00:00",
          "link": "https://arxiv.org/abs/2503.02240v2",
          "size": "8035kb",
          "version": "v2"
        }
      ],
      "title": "OmniSQL: Synthesizing High-quality Text-to-SQL Data at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02240",
        "HTML": "https://arxiv.org/html/2503.02240v2",
        "PDF": "https://arxiv.org/pdf/2503.02240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a novel text-to-SQL data synthesis framework, producing a large and diverse dataset (SynSQL-2.5M) that enhances LLM performance. The creation of this dataset includes clear data processing steps and aligns well with training data processing."
      },
      "models": [
        {
          "model_path": "seeklhy/OmniSQL-7B",
          "downloads": "4231",
          "likes": "9",
          "trending_score": "0.0",
          "link": "https://huggingface.co/seeklhy/OmniSQL-7B"
        },
        {
          "model_path": "seeklhy/OmniSQL-14B",
          "downloads": "1558",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/seeklhy/OmniSQL-14B"
        },
        {
          "model_path": "seeklhy/OmniSQL-32B",
          "downloads": "1656",
          "likes": "7",
          "trending_score": "0.0",
          "link": "https://huggingface.co/seeklhy/OmniSQL-32B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "seeklhy/SynSQL-2.5M",
          "downloads": "175",
          "likes": "16",
          "link": "https://huggingface.co/datasets/seeklhy/SynSQL-2.5M"
        }
      ],
      "tasks": [
        "Text to SQL",
        "Text-To-SQL"
      ],
      "repo_urls": [
        "https://github.com/RUCKBReasoning/OmniSQL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13414",
      "abstract": "Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning typically rely on a fixed Hermitian observable, often built from Pauli operators. Inspired by the Heisenberg picture, we propose an adaptive non-local measurement framework that substantially increases the model complexity of the quantum circuits. Our introduction of dynamical Hermitian observables with evolving parameters shows that optimizing VQC rotations corresponds to tracing a trajectory in the observable space. This viewpoint reveals that standard VQCs are merely a special case of the Heisenberg representation.\n  Furthermore, we show that properly incorporating variational rotations with non-local observables enhances qubit interaction and information mixture, admitting flexible circuit designs. Two non-local measurement schemes are introduced, and numerical simulations on classification tasks confirm that our approach outperforms conventional VQCs, yielding a more powerful and resource-efficient approach as a Quantum Neural Network.",
      "authors": [
        "Hsin-Yi Lin",
        "Huan-Hsin Tseng",
        "Samuel Yen-Chi Chen",
        "Shinjae Yoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T02:20:12+00:00",
          "link": "https://arxiv.org/abs/2504.13414v1",
          "size": "224kb",
          "version": "v1"
        },
        {
          "date": "2025-04-26T20:29:24+00:00",
          "link": "https://arxiv.org/abs/2504.13414v2",
          "size": "792kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T21:17:19+00:00",
          "link": "https://arxiv.org/abs/2504.13414v3",
          "size": "241kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive Non-local Observable on Quantum Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13414",
        "PDF": "https://arxiv.org/pdf/2504.13414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses quantum neural networks and variational quantum circuits, not related to any form of LLM training data processing or dataset creation."
      },
      "tasks": [
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07816",
      "abstract": "The problem of sampling a target probability distribution on a constrained domain arises in many applications including machine learning. For constrained sampling, various Langevin algorithms such as projected Langevin Monte Carlo (PLMC) based on the discretization of reflected Langevin dynamics (RLD) and more generally skew-reflected non-reversible Langevin Monte Carlo (SRNLMC) based on the discretization of skew-reflected non-reversible Langevin dynamics (SRNLD) have been proposed and studied in the literature. This work focuses on the long-time behavior of SRNLD, where a skew-symmetric matrix is added to RLD. Although acceleration for SRNLD has been studied, it is not clear how one should design the skew-symmetric matrix in the dynamics to achieve good performance in practice. We establish a large deviation principle (LDP) for the empirical measure of SRNLD when the skew-symmetric matrix is chosen such that its product with the inward unit normal vector field on the boundary is zero. By explicitly characterizing the rate functions, we show that this choice of the skew-symmetric matrix accelerates the convergence to the target distribution compared to RLD and reduces the asymptotic variance. Numerical experiments for SRNLMC based on the proposed skew-symmetric matrix show superior performance, which validate the theoretical findings from the large deviations theory.",
      "authors": [
        "Yingli Wang",
        "Changwei Tu",
        "Xiaoyu Wang",
        "Lingjiong Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T14:44:39+00:00",
          "link": "https://arxiv.org/abs/2506.07816v1",
          "size": "1626kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T18:27:53+00:00",
          "link": "https://arxiv.org/abs/2506.07816v2",
          "size": "1548kb",
          "version": "v2"
        }
      ],
      "title": "Accelerating Constrained Sampling: A Large Deviations Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07816",
        "HTML": "https://arxiv.org/html/2506.07816v2",
        "PDF": "https://arxiv.org/pdf/2506.07816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews constrained sampling approaches and Langevin dynamics, included in statistical methods rather than data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08263",
      "abstract": "We investigate the multiuser scheduling problem in multiple-input multiple-output (MIMO) systems using orthogonal frequency division multiplexing (OFDM) and hybrid beamforming in which a base station (BS) communicates with multiple users over millimeter wave (mmWave) channels in the downlink. Improved scheduling is critical for enhancing spectral efficiency and the long-term performance of the system from the perspective of proportional fairness (PF) metric in hybrid beamforming systems due to its limited multiplexing gain. Our objective is to maximize PF by properly designing the analog and digital precoders within the hybrid beamforming and selecting the users subject to the number of radio frequency (RF) chains. Leveraging the characteristics of mmWave channels, we apply a two-timescale protocol. On a long timescale, we assign an analog beam to each user. Scheduling the users and designing the digital precoder are done accordingly on a short timescale. To conduct scheduling, we propose combinatorial solutions, such as greedy and sorting algorithms, followed by a machine learning (ML) approach. Our numerical results highlight the trade-off between the performance and complexity of the proposed approaches. Consequently, we show that the choice of approach depends on the specific criteria within a given scenario.",
      "authors": [
        "Pouya Agheli",
        "Tugce Kobal",
        "Fran\\c{c}ois Durand",
        "Matthew Andrews"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T21:59:05+00:00",
          "link": "https://arxiv.org/abs/2506.08263v1",
          "size": "505kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T13:42:56+00:00",
          "link": "https://arxiv.org/abs/2506.08263v2",
          "size": "506kb",
          "version": "v2"
        }
      ],
      "title": "Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08263",
        "HTML": "https://arxiv.org/html/2506.08263v2",
        "PDF": "https://arxiv.org/pdf/2506.08263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multiuser scheduling in MIMO systems using machine learning for scheduling, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Fairness",
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09262",
      "abstract": "Accurate assessment of mental workload (MW) is crucial for understanding cognitive processes during visualization tasks. While EEG-based measures are emerging as promising alternatives to conventional assessment techniques, such as selfreport measures, studies examining consistency across these different methodologies are limited. In a preliminary study, we observed indications of potential discrepancies between EEGbased and self-reported MW measures. Motivated by these preliminary observations, our study further explores the discrepancies between EEG-based and self-reported MW assessment methods through an experiment involving visualization tasks. In the experiment, we employ two benchmark tasks: the Visualization Literacy Assessment Test (VLAT) and a Spatial Visualization (SV) task. EEG signals are recorded from participants using a 32-channel system at a sampling rate of 128 Hz during the visualization tasks. For each participant, MW is estimated using an EEG-based model built on a Graph Attention Network (GAT) architecture, and these estimates are compared with conventional MW measures to examine potential discrepancies. Our findings reveal notable discrepancies between task difficulty and EEG-based MW estimates, as well as between EEG-based and self-reported MW measures across varying task difficulty levels. Additionally, the observed patterns suggest the presence of unconscious cognitive effort that may not be captured by selfreport alone.",
      "authors": [
        "Soobin Yim",
        "Sangbong Yoo",
        "Chanyoung Yoon",
        "Chanyoung Jung",
        "Chansoo Kim",
        "Yun Jang",
        "and Ghulam Jilani Quadri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:49:03+00:00",
          "link": "https://arxiv.org/abs/2507.09262v1",
          "size": "2199kb",
          "version": "v1"
        }
      ],
      "title": "Discrepancies in Mental Workload Estimation: Self-Reported versus EEG-Based Measures in Data Visualization Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09262",
        "HTML": "https://arxiv.org/html/2507.09262v1",
        "PDF": "https://arxiv.org/pdf/2507.09262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores the discrepancies in mental workload estimation using EEG-based and self-reported measures, with no link to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09264",
      "abstract": "Patch-based transformer surrogates have become increasingly effective for modeling spatiotemporal dynamics, but the fixed patch size is a major limitation for budget-conscience deployment in production. We introduce two lightweight, architecture-agnostic modules-the Convolutional Kernel Modulator (CKM) and Convolutional Stride Modulator (CSM)-that enable dynamic patch size control at inference in patch based models, without retraining or accuracy loss. Combined with a cyclic patch-size rollout, our method mitigates patch artifacts and improves long-term stability for video-like prediction tasks. Applied to a range of challenging 2D and 3D PDE benchmarks, our approach improves rollout fidelity and runtime efficiency. To our knowledge, this is the first framework to enable inference-time patch-size tunability in patch-based PDE surrogates. Its plug-and-play design makes it broadly applicable across architectures-establishing a general foundation for compute-adaptive modeling in PDE surrogate tasks.",
      "authors": [
        "Payel Mukhopadhyay",
        "Michael McCabe",
        "Ruben Ohana",
        "Miles Cranmer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T12:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.09264v1",
          "size": "21873kb",
          "version": "v1"
        }
      ],
      "title": "Controllable Patching for Compute-Adaptive Surrogate Modeling of Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09264",
        "HTML": "https://arxiv.org/html/2507.09264v1",
        "PDF": "https://arxiv.org/pdf/2507.09264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a model architecture modification for surrogate PDE modeling using dynamic patch size control during inference, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.03117",
      "abstract": "This letter proposes a method to integrate auxiliary actuators that enhance the task-space capabilities of commercial underactuated systems, while leaving the internal certified low-level controller untouched. The additional actuators are combined with a feedback-linearizing outer-loop controller, enabling full-pose tracking. We provide conditions under which legacy high-level commands and new actuator inputs can be cohesively coordinated to achieve decoupled control of all degrees of freedom. A comparative study with a standard quadrotor-originally not designed for physical interaction-demonstrates that the proposed modified platform remains stable under contact, while the baseline system diverges. Additionally, simulation results under parameter uncertainty illustrate the robustness of the proposed approach.",
      "authors": [
        "Mirko Mizzoni",
        "Amr Afifi",
        "and Antonio Franchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-05T16:58:13+00:00",
          "link": "https://arxiv.org/abs/2403.03117v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T17:42:14+00:00",
          "link": "https://arxiv.org/abs/2403.03117v2",
          "size": "3420kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T17:37:21+00:00",
          "link": "https://arxiv.org/abs/2403.03117v3",
          "size": "2991kb",
          "version": "v3"
        }
      ],
      "title": "Input-Output Extension of Underactuated Nonlinear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.03117",
        "HTML": "https://arxiv.org/html/2403.03117v3",
        "PDF": "https://arxiv.org/pdf/2403.03117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about control methods for underactuated nonlinear systems and does not relate to LLM training data processing."
      },
      "tasks": [
        "Pose Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18641",
      "abstract": "Effectively preserving both the structural and dynamical properties during the reduction of complex networks remains a significant research topic. Existing network reduction methods based on renormalization group or sampling often face challenges such as high computational complexity and the loss of critical dynamic attributes. This paper proposes an efficient network reduction framework based on subgraph extraction, which accurately preserves epidemic spreading dynamics and information flow through a coordinated optimization strategy of node removal and edge pruning. Specifically, a node removal algorithm driven by enhanced degree centrality is introduced to preferentially remove low-centrality nodes, thereby constructing a smaller-scale subnetwork. Subsequently, an edge pruning algorithm is designed to regulate the edge density of the subnetwork, ensuring that its average degree remains approximately consistent with that of the original network. Experimental results on Erd\\\"os-R\\'enyi random graphs, Barab\\'asi-Albert scale-free networks, and real-world social contact networks from various domains demonstrate that this proposed method can reduce the size of networks with heterogeneous structures by more than 85\\%, while preserving their epidemic dynamics and information flow. More importantly, our method almost always achieves the highest accuracy compared to state-of-the-art techniques. These findings provide valuable insights for predicting the dynamical behavior of large-scale real-world networks, and also reveal that a large number of nodes and edges in real-world networks play redundant roles in information transmission.",
      "authors": [
        "Dan Chen",
        "Housheng Su",
        "Yong Wang",
        "and Jie Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T13:42:08+00:00",
          "link": "https://arxiv.org/abs/2506.18641v1",
          "size": "13286kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T16:21:20+00:00",
          "link": "https://arxiv.org/abs/2506.18641v2",
          "size": "16628kb",
          "version": "v2"
        }
      ],
      "title": "Preserving spreading dynamics and information flow in complex network reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18641",
        "HTML": "https://arxiv.org/html/2506.18641v2",
        "PDF": "https://arxiv.org/pdf/2506.18641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on network reduction methods to preserve network dynamics, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09875",
      "abstract": "Large language models demonstrate the intriguing ability to perform unseen tasks via in-context learning. However, it remains unclear what mechanisms inside the model drive such task-level generalization. In this work, we approach this question through the lens of off-by-one addition (i.e., 1+1=3, 2+2=5, 3+3=?), a two-step, counterfactual task with an unexpected +1 function as a second step. Leveraging circuit-style interpretability techniques such as path patching, we analyze the models' internal computations behind their notable performance and present three key findings. First, we uncover a function induction mechanism that explains the model's generalization from standard addition to off-by-one addition. This mechanism resembles the structure of the induction head mechanism found in prior work and elevates it to a higher level of abstraction. Second, we show that the induction of the +1 function is governed by multiple attention heads in parallel, each of which emits a distinct piece of the +1 function. Finally, we find that this function induction mechanism is reused in a broader range of tasks, including synthetic tasks such as shifted multiple-choice QA and algorithmic tasks such as base-8 addition. Overall, our findings offer deeper insights into how reusable and composable structures within language models enable task-level generalization.",
      "authors": [
        "Qinyuan Ye",
        "Robin Jia",
        "Xiang Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:20:55+00:00",
          "link": "https://arxiv.org/abs/2507.09875v1",
          "size": "541kb",
          "version": "v1"
        }
      ],
      "title": "Function Induction and Task Generalization: An Interpretability Study with Off-by-One Addition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09875",
        "HTML": "https://arxiv.org/html/2507.09875v1",
        "PDF": "https://arxiv.org/pdf/2507.09875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies model interpretability and task generalization mechanisms within LLMs on specific tasks, without addressing training data processing or dataset engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10084",
      "abstract": "To address the prevalent challenges of domain shift and small sample sizes in remote sensing image water body segmentation, this study proposes and validates a two-stage transfer learning strategy based on the SegFormer model. The approach begins by training a foundational segmentation model on a diverse source domain, where it achieves an Intersection over Union (IoU) of 68.80% on its validation set, followed by fine-tuning on data from the distinct target domain. Focusing on the Zhada Tulin area in Tibet -- a region characterized by highly complex topography and spectral features -- the experimental results demonstrate that this strategy significantly boosts the IoU for the water body segmentation task from 25.50% (for direct transfer) to 64.84%. This not only effectively resolves the model performance degradation caused by domain discrepancy but also provides an effective technical paradigm for high-precision thematic information extraction in data-scarce and environmentally unique remote sensing scenarios.",
      "authors": [
        "Haonan Chen (Tibet University)",
        "Xin Tong (Northwestern Polytechnical University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:11:33+00:00",
          "link": "https://arxiv.org/abs/2507.10084v1",
          "size": "27417kb",
          "version": "v1"
        }
      ],
      "title": "A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10084",
        "HTML": "https://arxiv.org/html/2507.10084v1",
        "PDF": "https://arxiv.org/pdf/2507.10084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions fine-tuning models using a two-stage transfer learning strategy, the focus is on water body segmentation in remote sensing, not on LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10162",
      "abstract": "Vertical Federated Learning (VFL) enables an orchestrating active party to perform a machine learning task by cooperating with passive parties that provide additional task-related features for the same training data entities. While prior research has leveraged the privacy vulnerability of VFL to compromise its integrity through a combination of label inference and backdoor attacks, their effectiveness is constrained by the low label inference precision and suboptimal backdoor injection conditions. To facilitate a more rigorous security evaluation on VFL without these limitations, we propose HASSLE, a hijacking attack framework composed of a gradient-direction-based label inference module and an adversarial embedding generation algorithm enhanced by self-supervised learning. HASSLE accurately identifies private samples associated with a targeted label using only a single known instance of that label. In the two-party scenario, it demonstrates strong performance with an attack success rate (ASR) of over 99% across four datasets, including both image and tabular modalities, and achieves 85% ASR on the more complex CIFAR-100 dataset. Evaluation of HASSLE against 8 potential defenses further highlights its significant threat while providing new insights into building a trustworthy VFL system.",
      "authors": [
        "Weiyang He",
        "Chip-Hong Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:22:50+00:00",
          "link": "https://arxiv.org/abs/2507.10162v1",
          "size": "3707kb",
          "version": "v1"
        }
      ],
      "title": "HASSLE: A Self-Supervised Learning Enhanced Hijacking Attack on Vertical Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10162",
        "HTML": "https://arxiv.org/html/2507.10162v1",
        "PDF": "https://arxiv.org/pdf/2507.10162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on security evaluation and hijacking attacks in Vertical Federated Learning, not on processing or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10536",
      "abstract": "In this work, we analyze the optimization behaviour of common private learning optimization algorithms under heavy-tail class imbalanced distribution. We show that, in a stylized model, optimizing with Gradient Descent with differential privacy (DP-GD) suffers when learning low-frequency classes, whereas optimization algorithms that estimate second-order information do not. In particular, DP-AdamBC that removes the DP bias from estimating loss curvature is a crucial component to avoid the ill-condition caused by heavy-tail class imbalance, and empirically fits the data better with $\\approx8\\%$ and $\\approx5\\%$ increase in training accuracy when learning the least frequent classes on both controlled experiments and real data respectively.",
      "authors": [
        "Qiaoyue Tang",
        "Alain Zhiyanov",
        "Mathias L\\'ecuyer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:57:08+00:00",
          "link": "https://arxiv.org/abs/2507.10536v1",
          "size": "373kb",
          "version": "v1"
        }
      ],
      "title": "On the Performance of Differentially Private Optimization with Heavy-Tail Class Imbalance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10536",
        "HTML": "https://arxiv.org/html/2507.10536v1",
        "PDF": "https://arxiv.org/pdf/2507.10536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on analyzing optimization algorithms under class imbalance rather than discussing LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2212.08983",
      "abstract": "One of the main challenges in deep learning-based underwater image enhancement is the limited availability of high-quality training data. Underwater images are difficult to capture and are often of poor quality due to the distortion and loss of colour and contrast in water. This makes it difficult to train supervised deep learning models on large and diverse datasets, which can limit the model's performance. In this paper, we explore an alternative approach to supervised underwater image enhancement. Specifically, we propose a novel unsupervised underwater image enhancement framework that employs a conditional variational autoencoder (cVAE) to train a deep learning model with probabilistic adaptive instance normalization (PAdaIN) and statistically guided multi-colour space stretch that produces realistic underwater images. The resulting framework is composed of a U-Net as a feature extractor and a PAdaIN to encode the uncertainty, which we call UDnet. To improve the visual quality of the images generated by UDnet, we use a statistically guided multi-colour space stretch module that ensures visual consistency with the input image and provides an alternative to training using a ground truth image. The proposed model does not need manual human annotation and can learn with a limited amount of data and achieves state-of-the-art results on underwater images. We evaluated our proposed framework on eight publicly-available datasets. The results show that our proposed framework yields competitive performance compared to other state-of-the-art approaches in quantitative as well as qualitative metrics. Code available at https://github.com/alzayats/UDnet .",
      "authors": [
        "Alzayat Saleh",
        "Marcus Sheaves",
        "Dean Jerry",
        "and Mostafa Rahimi Azghadi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-18T01:07:20+00:00",
          "link": "https://arxiv.org/abs/2212.08983v1",
          "size": "8525kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T06:32:53+00:00",
          "link": "https://arxiv.org/abs/2212.08983v2",
          "size": "8560kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T01:25:09+00:00",
          "link": "https://arxiv.org/abs/2212.08983v3",
          "size": "7649kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive deep learning framework for robust unsupervised underwater image enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.08983",
        "HTML": "https://arxiv.org/html/2212.08983v3",
        "PDF": "https://arxiv.org/pdf/2212.08983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses an unsupervised framework for underwater image enhancement, mentioning the use of limited data, but the focus is on model framework rather than extensive LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Image Enhancement"
      ],
      "repo_urls": [
        "https://github.com/alzayats/udnet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.05229",
      "abstract": "We show that the big-O problem for max-plus automata is decidable and PSPACE-complete. The big-O (or affine domination) problem asks whether, given two max-plus automata computing functions f and g, there exists a constant c such that f < cg+ c. This is a relaxation of the containment problem asking whether f < g, which is undecidable. Our decidability result uses Simon's forest factorisation theorem, and relies on detecting specific elements, that we call witnesses, in a finite semigroup closed under two special operations: stabilisation and flattening.",
      "authors": [
        "Laure Daviaud",
        "David Purser and Marie Tcheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-11T14:00:29+00:00",
          "link": "https://arxiv.org/abs/2304.05229v1",
          "size": "190kb",
          "version": "v1"
        },
        {
          "date": "2024-04-29T17:42:05+00:00",
          "link": "https://arxiv.org/abs/2304.05229v2",
          "size": "208kb",
          "version": "v2"
        },
        {
          "date": "2025-04-10T20:02:24+00:00",
          "link": "https://arxiv.org/abs/2304.05229v3",
          "size": "219kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T13:10:24+00:00",
          "link": "https://arxiv.org/abs/2304.05229v4",
          "size": "225kb",
          "version": "v4"
        }
      ],
      "title": "The Big-O Problem for Max-Plus Automata is Decidable (PSPACE-Complete)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.05229",
        "HTML": "https://arxiv.org/html/2304.05229v4",
        "PDF": "https://arxiv.org/pdf/2304.05229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily addresses the decidability of the big-O problem for max-plus automata, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.02814",
      "abstract": "We present a thorough analysis of the use of modern heterogeneous systems interconnected by various cachecoherent links, including CXL, NVLink-C2C, and Infinity Fabric. We studied a wide range of server systems that combined CPUs from different vendors and various types of coherent memory devices, including CXL memory expander, CXL pool, CXL shared memory, GH200 GPU, and AMD MI300a HBM. For this study, we developed a heterogeneous memory benchmark suite, Heimdall, to profile the performance of such heterogeneous systems and present a detailed performance comparison across systems. By leveraging H E I M DA L L , we unveiled the detailed architecture design in these systems, drew observations on optimizing performance for workloads, and pointed out directions for future development of cache coherent heterogeneous systems.",
      "authors": [
        "Zixuan Wang",
        "Suyash Mahar",
        "Luyi Li",
        "Jangseon Park",
        "Jinpyo Kim",
        "Theodore Michailidis",
        "Yue Pan",
        "Mingyao Shen",
        "Tajana Rosing",
        "Dean Tullsen",
        "Steven Swanson",
        "Jishen Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Performance (cs.PF)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T05:22:14+00:00",
          "link": "https://arxiv.org/abs/2411.02814v1",
          "size": "11326kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:03:30+00:00",
          "link": "https://arxiv.org/abs/2411.02814v2",
          "size": "8464kb",
          "version": "v2"
        }
      ],
      "title": "The Hitchhiker's Guide to Programming and Optimizing Cache Coherent Heterogeneous Systems: CXL, NVLink-C2C, and AMD Infinity Fabric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02814",
        "PDF": "https://arxiv.org/pdf/2411.02814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes cache coherent heterogeneous systems and presents a memory benchmark suite, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22370",
      "abstract": "Students in computing education increasingly use large language models (LLMs) such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding tasks, like deductive program verification, remains poorly understood. This paper investigates how students interact with an LLM when solving formal verification exercises in Dafny, a language that supports functional correctness, by allowing programmers to write formal specifications and automatically verifying that the implementation satisfies the specification. We conducted a mixed-methods study with master's students enrolled in a formal methods course. Each participant completed two verification problems, one with access to a custom ChatGPT interface that logged all interactions, and the other without. We identified strategies used by successful students and assessed the level of trust students place in LLMs. Our findings show that students perform significantly better when using ChatGPT; however, performance gains are tied to prompt quality. We conclude with practical recommendations for integrating LLMs into formal methods courses more effectively, including designing LLM-aware challenges that promote learning rather than substitution.",
      "authors": [
        "Carolina Carreira",
        "\\'Alvaro Silva",
        "Alexandre Abreu",
        "and Alexandra Mendes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:34:13+00:00",
          "link": "https://arxiv.org/abs/2506.22370v1",
          "size": "296kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:08:05+00:00",
          "link": "https://arxiv.org/abs/2506.22370v2",
          "size": "296kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T19:12:05+00:00",
          "link": "https://arxiv.org/abs/2506.22370v3",
          "size": "296kb",
          "version": "v3"
        }
      ],
      "title": "Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22370",
        "HTML": "https://arxiv.org/html/2506.22370v3",
        "PDF": "https://arxiv.org/pdf/2506.22370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines LLM usage in educational settings for program verification but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07432",
      "abstract": "We show that deep neural networks, including transformers and RNNs, pretrained as usual on next-token prediction, intrinsically discover and represent beliefs over 'quantum' and 'post-quantum' low-dimensional generative models of their training data -- as if performing iterative Bayesian updates over the latent state of this world model during inference as they observe more context. Notably, neural nets easily find these representation whereas there is no finite classical circuit that would do the job. The corresponding geometric relationships among neural activations induced by different input sequences are found to be largely independent of neural-network architecture. Each point in this geometry corresponds to a history-induced probability density over all possible futures, and the relative displacement of these points reflects the difference in mechanism and magnitude for how these distinct pasts affect the future.",
      "authors": [
        "Paul M. Riechers and Thomas J. Elliott and Adam S. Shai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.07432v1",
          "size": "5588kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T00:23:45+00:00",
          "link": "https://arxiv.org/abs/2507.07432v2",
          "size": "4362kb",
          "version": "v2"
        }
      ],
      "title": "Neural networks leverage nominally quantum and post-quantum representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07432",
        "HTML": "https://arxiv.org/html/2507.07432v2",
        "PDF": "https://arxiv.org/pdf/2507.07432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses neural network representation capabilities and inference mechanisms rather than focusing on LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07610",
      "abstract": "Humans can directly imagine and manipulate visual images in their minds, a capability known as spatial visualization. While multi-modal Large Language Models (MLLMs) support imagination-based reasoning, spatial visualization remains insufficiently evaluated, typically embedded within broader mathematical and logical assessments. Existing evaluations often rely on IQ tests or math competitions that may overlap with training data, compromising assessment reliability. To this end, we introduce SpatialViz-Bench, a comprehensive multi-modal benchmark for spatial visualization with 12 tasks across 4 sub-abilities, comprising 1,180 automatically generated problems. Our evaluation of 33 state-of-the-art MLLMs not only reveals wide performance variations and demonstrates the benchmark's strong discriminative power, but also uncovers counter-intuitive findings: models exhibit unexpected behaviors by showing difficulty perception that misaligns with human intuition, displaying dramatic 2D-to-3D performance cliffs, and defaulting to formula derivation despite spatial tasks requiring visualization alone. SpatialVizBench empirically demonstrates that state-of-the-art MLLMs continue to exhibit deficiencies in spatial visualization tasks, thereby addressing a significant lacuna in the field. The benchmark is publicly available.",
      "authors": [
        "Siting Wang",
        "Luoyang Sun",
        "Cheng Deng",
        "Kun Shao",
        "Minnan Pei",
        "Zheng Tian",
        "Haifeng Zhang",
        "Jun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:27:20+00:00",
          "link": "https://arxiv.org/abs/2507.07610v1",
          "size": "3775kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:38:44+00:00",
          "link": "https://arxiv.org/abs/2507.07610v2",
          "size": "4137kb",
          "version": "v2"
        }
      ],
      "title": "SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07610",
        "PDF": "https://arxiv.org/pdf/2507.07610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new benchmark, SpatialViz-Bench, for evaluating spatial visualization tasks in MLLMs, which does not involve training data processing or creation."
      },
      "datasets": [
        {
          "dataset_name": "PLM-Team/Spatial-Visualization-Benchmark",
          "downloads": "168",
          "likes": "0",
          "link": "https://huggingface.co/datasets/PLM-Team/Spatial-Visualization-Benchmark"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08848",
      "abstract": "The rapid advancement of machine learning (ML) has led to its increasing integration into cyber-physical systems (CPS) across diverse domains. While CPS offer powerful capabilities, incorporating ML components introduces significant safety and assurance challenges. Among ML techniques, reinforcement learning (RL) is particularly suited for CPS due to its capacity to handle complex, dynamic environments where explicit models of interaction between system and environment are unavailable or difficult to construct. However, in safety-critical applications, this learning process must not only be effective but demonstrably safe. Safe-RL methods aim to address this by incorporating safety constraints during learning, yet they fall short in providing systematic assurance across the RL lifecycle. The AMLAS methodology offers structured guidance for assuring the safety of supervised learning components, but it does not directly apply to the unique challenges posed by RL. In this paper, we adapt AMLAS to provide a framework for generating assurance arguments for an RL-enabled system through an iterative process; AMLAS-RL. We demonstrate AMLAS-RL using a running example of a wheeled vehicle tasked with reaching a target goal without collision.",
      "authors": [
        "Calum Corrie Imrie",
        "Ioannis Stefanakos",
        "Sepeedeh Shahbeigi",
        "Richard Hawkins",
        "Simon Burton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:01:51+00:00",
          "link": "https://arxiv.org/abs/2507.08848v1",
          "size": "1331kb",
          "version": "v1"
        }
      ],
      "title": "Assuring the Safety of Reinforcement Learning Components: AMLAS-RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08848",
        "HTML": "https://arxiv.org/html/2507.08848v1",
        "PDF": "https://arxiv.org/pdf/2507.08848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on assuring the safety of reinforcement learning components with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08944",
      "abstract": "Large language model (LLM)-based multi-agent systems have demonstrated remarkable promise for tackling complex tasks by breaking them down into subtasks that are iteratively planned, executed, observed, and refined. Despite their effectiveness, these systems often incur high latency because real-world problems frequently demand multiple iterative cycles of reasoning steps. To address this challenge, we propose M1-Parallel, a framework that concurrently runs multiple multi-agent teams in parallel to uncover distinct solution paths. By leveraging an event-driven communication model with asynchronous messaging, M1-Parallel efficiently capitalizes on the inherent diversity of valid plans to either reduce end-to-end latency or boost task completion rates. Our experiments on complex tasks show that M1-Parallel with early termination achieves up to $2.2\\times$ speedup while preserving accuracy, and that M1-Parallel with aggregation yields higher task completion rates. We further investigate strategies aimed at encouraging diverse execution plans but observe no additional performance gains over repeated sampling. Overall, these findings underscore the potential of parallel plan execution for optimizing multi-agent systems for real-world, high-complexity reasoning tasks.",
      "authors": [
        "Enhao Zhang",
        "Erkang Zhu",
        "Gagan Bansal",
        "Adam Fourney",
        "Hussein Mozannar",
        "Jack Gerrits"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:09:22+00:00",
          "link": "https://arxiv.org/abs/2507.08944v1",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Sequential Multi-Step Tasks with Parallel LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08944",
        "HTML": "https://arxiv.org/html/2507.08944v1",
        "PDF": "https://arxiv.org/pdf/2507.08944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework to optimize multi-agent systems with parallel execution, without focusing on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10442",
      "abstract": "Vision-language Models (VLMs) have emerged as general-purpose tools for addressing a variety of complex computer vision problems. Such models have been shown to be highly capable, but, at the same time, lacking some basic visual understanding skills. In this paper, we set out to understand the limitations of SoTA VLMs on fundamental visual tasks by constructing a series of tests that probe which components of design, specifically, may be lacking. Importantly, we go significantly beyond the current benchmarks, which simply measure the final performance of VLM response, by also comparing and contrasting it to the performance of probes trained directly on features obtained from the visual encoder, intermediate vision-language projection and LLM-decoder output. In doing so, we uncover shortcomings in VLMs and make a number of important observations about their capabilities, robustness and how they process visual information. We hope our insights will guide progress in further improving VLMs.",
      "authors": [
        "Shivam Chandhok",
        "Wan-Cyuan Fan",
        "Vered Shwartz",
        "Vineeth N Balasubramanian",
        "Leonid Sigal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:26:41+00:00",
          "link": "https://arxiv.org/abs/2507.10442v1",
          "size": "3890kb",
          "version": "v1"
        }
      ],
      "title": "Response Wide Shut? Surprising Observations in Basic Vision Language Model Capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10442",
        "HTML": "https://arxiv.org/html/2507.10442v1",
        "PDF": "https://arxiv.org/pdf/2507.10442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper explores shortcomings in vision-language models by probing their components but does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10472",
      "abstract": "This paper introduces an innovative Applicant Tracking System (ATS) enhanced by a novel Robotic process automation (RPA) framework or as further referred to as MLAR. Traditional recruitment processes often encounter bottlenecks in resume screening and candidate shortlisting due to time and resource constraints. MLAR addresses these challenges employing Large Language Models (LLMs) in three distinct layers: extracting key characteristics from job postings in the first layer, parsing applicant resume to identify education, experience, skills in the second layer, and similarity matching in the third layer. These features are then matched through advanced semantic algorithms to identify the best candidates efficiently. Our approach integrates seamlessly into existing RPA pipelines, automating resume parsing, job matching, and candidate notifications. Extensive performance benchmarking shows that MLAR outperforms the leading RPA platforms, including UiPath and Automation Anywhere, in high-volume resume-processing tasks. When processing 2,400 resumes, MLAR achieved an average processing time of 5.4 seconds per resume, reducing processing time by approximately 16.9% compared to Automation Anywhere and 17.1% compared to UiPath. These results highlight the potential of MLAR to transform recruitment workflows by providing an efficient, accurate, and scalable solution tailored to modern hiring needs.",
      "authors": [
        "Mohamed T. Younes",
        "Omar Walid",
        "Mai Hassan",
        "Ali Hamdi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:53:19+00:00",
          "link": "https://arxiv.org/abs/2507.10472v1",
          "size": "155kb",
          "version": "v1"
        }
      ],
      "title": "MLAR: Multi-layer Large Language Model-based Robotic Process Automation Applicant Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10472",
        "HTML": "https://arxiv.org/html/2507.10472v1",
        "PDF": "https://arxiv.org/pdf/2507.10472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving a recruitment process through an applicant tracking system using LLMs to enhance resume processing and matches. It does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.07514",
      "abstract": "Physics-informed machine learning combines the expressiveness of data-based approaches with the interpretability of physical models. In this context, we consider a general regression problem where the empirical risk is regularized by a partial differential equation that quantifies the physical inconsistency. We prove that for linear differential priors, the problem can be formulated as a kernel regression task. Taking advantage of kernel theory, we derive convergence rates for the minimizer of the regularized risk and show that it converges at least at the Sobolev minimax rate. However, faster rates can be achieved, depending on the physical error. This principle is illustrated with a one-dimensional example, supporting the claim that regularizing the empirical risk with physical information can be beneficial to the statistical performance of estimators.",
      "authors": [
        "Nathan Doum\\`eche (LPSM (UMR\\_8001)",
        "EDF R\\&D OSIRIS)",
        "Francis Bach (DI-ENS",
        "SIERRA)",
        "G\\'erard Biau (LPSM (UMR\\_8001))",
        "Claire Boyer (IUF",
        "LPSM (UMR\\_8001))"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-12T09:38:42+00:00",
          "link": "https://arxiv.org/abs/2402.07514v1",
          "size": "1863kb",
          "version": "v1"
        },
        {
          "date": "2024-06-19T07:40:56+00:00",
          "link": "https://arxiv.org/abs/2402.07514v2",
          "size": "1861kb",
          "version": "v2"
        }
      ],
      "title": "Physics-informed machine learning as a kernel method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.07514",
        "PDF": "https://arxiv.org/pdf/2402.07514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses integrating physics into machine learning but does not deal with LLM training data processing."
      },
      "tasks": [
        "Physics-informed machine learning",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/nathandoumeche/piml_as_a_kernel_method"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.08800",
      "abstract": "Quantum transport simulations are essential for understanding and designing nanoelectronic devices, yet the long-standing trade-off between accuracy and computational efficiency has limited their practical applications. We present DeePTB-NEGF, an integrated framework combining deep learning tight-binding Hamiltonian prediction with non-equilibrium Green's Function methodology to enable accurate quantum transport simulations in open boundary conditions with 2-3 orders of magnitude acceleration. We demonstrate DeePTB-NEGF through two challenging applications: comprehensive break junction simulations with over $10^4$ snapshots, showing excellent agreement with experimental conductance histograms; and carbon nanotube field-effect transistors (CNT-FET) at experimental dimensions, reproducing measured transfer characteristics for a 41 nm channel CNT-FET ($\\sim 8000$ atoms, $3\\times10^4$ orbitals) and predicting zero-bias transmission spectra for a 180 nm CNT ($\\sim 3\\times 10^4$ atoms, $10^5$ orbitals), showcasing the framework's capability for large-scale device simulations. Our systematic studies across varying geometries confirm the necessity of simulating realistic experimental structures for precise predictions. DeePTB-NEGF bridges the longstanding gap between first-principles accuracy and computational efficiency, providing a scalable tool for high-throughput and large-scale quantum transport simulations that enables previously inaccessible nanoscale device investigations.",
      "authors": [
        "Jijie Zou",
        "Zhanghao Zhouyin",
        "Dongying Lin",
        "Yike Huang",
        "Linfeng Zhang",
        "Shimin Hou",
        "Qiangqiang Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T17:27:32+00:00",
          "link": "https://arxiv.org/abs/2411.08800v1",
          "size": "1806kb",
          "version": "v1"
        },
        {
          "date": "2025-02-09T15:25:05+00:00",
          "link": "https://arxiv.org/abs/2411.08800v2",
          "size": "2310kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T15:26:05+00:00",
          "link": "https://arxiv.org/abs/2411.08800v3",
          "size": "2385kb",
          "version": "v3"
        }
      ],
      "title": "Deep Learning Accelerated Quantum Transport Simulations in Nanoelectronics: From Break Junctions to Field-Effect Transistors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08800",
        "HTML": "https://arxiv.org/html/2411.08800v3",
        "PDF": "https://arxiv.org/pdf/2411.08800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum transport simulations and enhancements in computational efficiency, having no focus on LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/deepmodeling/DeePTB"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01504",
      "abstract": "The collection and release of street-level recordings as Open Data play a vital role in advancing autonomous driving systems and AI research. However, these datasets pose significant privacy risks, particularly for pedestrians, due to the presence of Personally Identifiable Information (PII) that extends beyond biometric traits such as faces. In this paper, we present cRID, a novel cross-modal framework combining Large Vision-Language Models, Graph Attention Networks, and representation learning to detect textual describable clues of PII and enhance person re-identification (Re-ID). Our approach focuses on identifying and leveraging interpretable features, enabling the detection of semantically meaningful PII beyond low-level appearance cues. We conduct a systematic evaluation of PII presence in person image datasets. Our experiments show improved performance in practical cross-dataset Re-ID scenarios, notably from Market-1501 to CUHK03-np (detected), highlighting the framework's practical utility. Code is available at https://github.com/RAufschlaeger/cRID.",
      "authors": [
        "Robert Aufschl\\\"ager",
        "Youssef Shoeb",
        "Azarm Nowzad",
        "Michael Heigl",
        "Fabian Bally",
        "and Martin Schramm"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T09:10:33+00:00",
          "link": "https://arxiv.org/abs/2507.01504v1",
          "size": "1721kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:13:19+00:00",
          "link": "https://arxiv.org/abs/2507.01504v2",
          "size": "1722kb",
          "version": "v2"
        }
      ],
      "title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01504",
        "HTML": "https://arxiv.org/html/2507.01504v2",
        "PDF": "https://arxiv.org/pdf/2507.01504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on person re-identification using a combination of vision-language models and graph networks, with a focus on identifying PII, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08806",
      "abstract": "Recent large language models have shown promising capabilities in long-form reasoning, following structured chains of thought before arriving at a final answer. However, we observe that these reasoning paths tend to include substantial redundancy; analyzing attention patterns reveals that attention scores are widely scattered, particularly incorrect answers exhibit greater attention sparsity. In this paper, we demonstrate that deliberately removing this redundancy in the reasoning process significantly improves performance through clear thinking, i.e., removing distraction. Specifically, we systematically identify reasoning redundancy by measuring token-level attention scores to a special end-of-thinking token, which is appended to an explicit instruction inserted to conclude each intermediate reasoning step. Furthermore, we propose structure-aware pruning that prioritizes removing tokens in low-contributing reasoning chunks over individual tokens. After evicting redundant tokens, we remove the injected end-of-thinking instruction, then resume the reasoning generation. We demonstrate that our method significantly improves overall accuracy across reasoning-intensive benchmarks without any training involved. In particular, our method shows strong performance on challenging mathematical competition benchmarks such as AIME and AMC, where reasoning redundancy is more prevalent.",
      "authors": [
        "Daewon Choi",
        "Jimin Lee",
        "Jihoon Tack",
        "Woomin Song",
        "Saket Dingliwal",
        "Sai Muralidhar Jayanthi",
        "Bhavana Ganesh",
        "Jinwoo Shin",
        "Aram Galstyan",
        "Sravan Babu Bodapati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T06:04:01+00:00",
          "link": "https://arxiv.org/abs/2507.08806v1",
          "size": "1785kb",
          "version": "v1"
        }
      ],
      "title": "Think Clearly: Improving Reasoning via Redundant Token Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08806",
        "HTML": "https://arxiv.org/html/2507.08806v1",
        "PDF": "https://arxiv.org/pdf/2507.08806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving reasoning performance via pruning during inference, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09323",
      "abstract": "Humans do not understand individual events in isolation; rather, they generalize concepts within classes and compare them to others. Existing audio-video pre-training paradigms only focus on the alignment of the overall audio-video modalities, without considering the reinforcement of distinguishing easily confused classes through cognitive induction and contrast during training. This paper proposes the Dynamic Inter-Class Confusion-Aware Encoder (DICCAE), an encoder that aligns audio-video representations at a fine-grained, category-level. DICCAE addresses category confusion by dynamically adjusting the confusion loss based on inter-class confusion degrees, thereby enhancing the model's ability to distinguish between similar activities. To further extend the application of DICCAE, we also introduce a novel training framework that incorporates both audio and video modalities, as well as their fusion. To mitigate the scarcity of audio-video data in the human activity recognition task, we propose a cluster-guided audio-video self-supervised pre-training strategy for DICCAE. DICCAE achieves near state-of-the-art performance on the VGGSound dataset, with a top-1 accuracy of 65.5%. We further evaluate its feature representation quality through extensive ablation studies, validating the necessity of each module.",
      "authors": [
        "Kaixuan Cong",
        "Yifan Wang",
        "Rongkun Xue",
        "Yuyang Jiang",
        "Yiming Feng",
        "Jing Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:45:36+00:00",
          "link": "https://arxiv.org/abs/2507.09323v1",
          "size": "779kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Inter-Class Confusion-Aware Encoder for Audio-Visual Fusion in Human Activity Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09323",
        "HTML": "https://arxiv.org/html/2507.09323v1",
        "PDF": "https://arxiv.org/pdf/2507.09323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions a novel training framework, the primary focus is on model architecture for audio-visual fusion, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09801",
      "abstract": "The rapid development of AI systems poses unprecedented risks, including loss of control, misuse, geopolitical instability, and concentration of power. To navigate these risks and avoid worst-case outcomes, governments may proactively establish the capability for a coordinated halt on dangerous AI development and deployment. In this paper, we outline key technical interventions that could allow for a coordinated halt on dangerous AI activities. We discuss how these interventions may contribute to restricting various dangerous AI activities, and show how these interventions can form the technical foundation for potential AI governance plans.",
      "authors": [
        "Peter Barnett",
        "Aaron Scher",
        "David Abecassis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:32:15+00:00",
          "link": "https://arxiv.org/abs/2507.09801v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "Technical Requirements for Halting Dangerous AI Activities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09801",
        "HTML": "https://arxiv.org/html/2507.09801v1",
        "PDF": "https://arxiv.org/pdf/2507.09801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on outlining technical interventions for halting dangerous AI activities, which does not involve any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09984",
      "abstract": "In spite of remarkable potential of the Latent Diffusion Models (LDMs) in image generation, the desired properties and optimal design of the autoencoders have been underexplored. In this work, we analyze the role of autoencoders in LDMs and identify three key properties: latent smoothness, perceptual compression quality, and reconstruction quality. We demonstrate that existing autoencoders fail to simultaneously satisfy all three properties, and propose Variational Masked AutoEncoders (VMAEs), taking advantage of the hierarchical features maintained by Masked AutoEncoder. We integrate VMAEs into the LDM framework, introducing Latent Diffusion Models with Masked AutoEncoders (LDMAEs). Through comprehensive experiments, we demonstrate significantly enhanced image generation quality and computational efficiency.",
      "authors": [
        "Junho Lee",
        "Jeongwoo Shin",
        "Hyungwook Choi",
        "Joonseok Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:00:43+00:00",
          "link": "https://arxiv.org/abs/2507.09984v1",
          "size": "31985kb",
          "version": "v1"
        }
      ],
      "title": "Latent Diffusion Models with Masked AutoEncoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09984",
        "HTML": "https://arxiv.org/html/2507.09984v1",
        "PDF": "https://arxiv.org/pdf/2507.09984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses autoencoder properties in latent diffusion models for image generation, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.06329",
      "abstract": "Multi-model Markov decision process (MMDP) is a promising framework for computing policies that are robust to parameter uncertainty in MDPs. MMDPs aim to find a policy that maximizes the expected return over a distribution of MDP models. Because MMDPs are NP-hard to solve, most methods resort to approximations. In this paper, we derive the policy gradient of MMDPs and propose CADP, which combines a coordinate ascent method and a dynamic programming algorithm for solving MMDPs. The main innovation of CADP compared with earlier algorithms is to take the coordinate ascent perspective to adjust model weights iteratively to guarantee monotone policy improvements to a local maximum. A theoretical analysis of CADP proves that it never performs worse than previous dynamic programming algorithms like WSU. Our numerical results indicate that CADP substantially outperforms existing methods on several benchmark problems.",
      "authors": [
        "Xihong Su",
        "Marek Petrik"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T18:47:59+00:00",
          "link": "https://arxiv.org/abs/2407.06329v1",
          "size": "712kb",
          "version": "v1"
        }
      ],
      "title": "Solving Multi-Model MDPs by Coordinate Ascent and Dynamic Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06329",
        "HTML": "https://arxiv.org/html/2407.06329",
        "PDF": "https://arxiv.org/pdf/2407.06329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses solving multi-model MDPs using new algorithms. It does not pertain to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/suxh2019/cadp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.07290",
      "abstract": "Change point detection in time series aims to identify moments when the probability distribution of time series changes. It is widely applied in many areas, such as human activity sensing and medical science. In the context of multivariate time series, this typically involves examining the joint distribution of multiple variables: If the distribution of any one variable changes, the entire time series undergoes a distribution shift. However, in practical applications, we may be interested only in certain components of the time series, exploring abrupt changes in their distributions while accounting for the presence of other components. Here, assuming an underlying structural causal model that governs the time-series data generation, we address this task by proposing a two-stage non-parametric algorithm that first learns parts of the causal structure through constraint-based discovery methods, and then employs conditional relative Pearson divergence estimation to identify the change points. The conditional relative Pearson divergence quantifies the distribution difference between consecutive segments in the time series, while the causal discovery method allows a focus on the causal mechanism, facilitating access to independent and identically distributed (IID) samples. Theoretically, the typical assumption of samples being IID in conventional change point detection methods can be relaxed based on the Causal Markov Condition. Through experiments on both synthetic and real-world datasets, we validate the correctness and utility of our approach.",
      "authors": [
        "Shanyun Gao",
        "Raghavendra Addanki",
        "Tong Yu",
        "Ryan A. Rossi",
        "Murat Kocaoglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-10T00:54:42+00:00",
          "link": "https://arxiv.org/abs/2407.07290v1",
          "size": "1120kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T23:53:10+00:00",
          "link": "https://arxiv.org/abs/2407.07290v2",
          "size": "1421kb",
          "version": "v2"
        }
      ],
      "title": "Causal Discovery-Driven Change Point Detection in Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.07290",
        "PDF": "https://arxiv.org/pdf/2407.07290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses change point detection in time series using causal discovery methods, with no mention of LLM training data processing or engineering."
      },
      "tasks": [
        "Causal Discovery",
        "Change Point Detection",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.09488",
      "abstract": "This paper proposes a unified framework in which consciousness emerges as a cycle-consistent, affectively anchored inference process, recursively structured by the interaction of emotion and cognition. Drawing from information theory, optimal transport, and the Bayesian brain hypothesis, we formalize emotion as a low-dimensional structural prior and cognition as a specificity-instantiating update. This emotion-cognition cycle minimizes joint uncertainty by aligning emotionally weighted priors with context-sensitive cognitive appraisals. Subjective experience thus arises as the informational footprint of temporally extended, affect-modulated simulation. We introduce the Exchangeable Integration Theory of Consciousness (EITC), modeling conscious episodes as conditionally exchangeable samples drawn from a latent affective self-model. This latent variable supports integration, via a unified cause-effect structure with nonzero irreducibility, and differentiation, by preserving contextual specificity across episodes. We connect this architecture to the Bayesian theory of consciousness through Rao-Blackwellized inference, which stabilizes inference by marginalizing latent self-structure while enabling adaptive updates. This mechanism ensures coherence, prevents inference collapse, and supports goal-directed simulation. The formal framework builds on De Finetti's exchangeability theorem, integrated information theory, and KL-regularized optimal transport. Overall, consciousness is reframed as a recursive inference process, shaped by emotion, refined by cognition, stabilized through exchangeability, and unified through a latent self-model that integrates experience across time.",
      "authors": [
        "Xin Li"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-17T17:06:19+00:00",
          "link": "https://arxiv.org/abs/2407.09488v1",
          "size": "658kb",
          "version": "v1"
        },
        {
          "date": "2025-06-22T14:38:45+00:00",
          "link": "https://arxiv.org/abs/2407.09488v2",
          "size": "70kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T20:50:27+00:00",
          "link": "https://arxiv.org/abs/2407.09488v3",
          "size": "46kb",
          "version": "v3"
        }
      ],
      "title": "Bayesian Theory of Consciousness as Exchangeable Emotion-Cognition Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09488",
        "HTML": "https://arxiv.org/html/2407.09488v3",
        "PDF": "https://arxiv.org/pdf/2407.09488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a theoretical framework for consciousness based on Bayesian inference, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Hippocampus",
        "Navigate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.10681",
      "abstract": "This paper introduces a novel parameterization to characterize unknown linear time-invariant systems using noisy data. The presented parameterization describes exactly the set of all systems consistent with the available data. We then derive verifiable conditions, when the consistency constraint reduces the set to the true system and when it does not have any impact. Furthermore, we demonstrate how to use this parameterization to perform a direct data-driven estimator synthesis with guarantees on the H_{\\infty}-norm. Lastly, we conduct numerical experiments to compare our approach to existing methods.",
      "authors": [
        "Felix Br\\\"andle and Frank Allg\\\"ower"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T16:20:39+00:00",
          "link": "https://arxiv.org/abs/2410.10681v1",
          "size": "71kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:23:42+00:00",
          "link": "https://arxiv.org/abs/2410.10681v2",
          "size": "86kb",
          "version": "v2"
        }
      ],
      "title": "A System Parameterization for Direct Data-Driven Estimator Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10681",
        "HTML": "https://arxiv.org/html/2410.10681v2",
        "PDF": "https://arxiv.org/pdf/2410.10681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on parameterization for data-driven estimator synthesis in linear systems rather than processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.15085",
      "abstract": "Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by leveraging historical interactions across multiple domains, focusing on modeling cross-domain preferences through intra- and inter-sequence item relationships. Inspired by human cognitive processes, we propose Hierarchical Attention Fusion of Visual and Textual Representations (HAF-VT), a novel approach integrating visual and textual data to enhance cognitive modeling. Using the frozen CLIP model, we generate image and text embeddings, enriching item representations with multimodal data. A hierarchical attention mechanism jointly learns single-domain and cross-domain preferences, mimicking human information integration. Evaluated on four e-commerce datasets, HAF-VT outperforms existing methods in capturing cross-domain user interests, bridging cognitive principles with computational models and highlighting the role of multimodal data in sequential decision-making.",
      "authors": [
        "Wangyu Wu",
        "Zhenhong Chen",
        "Siqi Song",
        "Xianglin Qiu",
        "Xiaowei Huang",
        "Fei Ma",
        "Jimin Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T13:18:54+00:00",
          "link": "https://arxiv.org/abs/2504.15085v1",
          "size": "4617kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T12:31:51+00:00",
          "link": "https://arxiv.org/abs/2504.15085v2",
          "size": "832kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T05:22:06+00:00",
          "link": "https://arxiv.org/abs/2504.15085v3",
          "size": "834kb",
          "version": "v3"
        }
      ],
      "title": "Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15085",
        "HTML": "https://arxiv.org/html/2504.15085v3",
        "PDF": "https://arxiv.org/pdf/2504.15085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for cross-domain sequential recommendation using visual and textual representations, with no focus on LLM training data processing or dataset creation."
      },
      "tasks": [
        "Decision Making",
        "Sequential Decision Making",
        "Sequential Recommendation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00862",
      "abstract": "This paper investigates prime and co-prime integer matrices and their properties. It characterizes all pairwise co-prime integer matrices that are also prime integer matrices. This provides a simple way to construct families of pairwise co-prime integer matrices, that may have applications in multidimensional co-prime sensing and multidimensional Chinese remainder theorem.",
      "authors": [
        "Xiang-Gen Xia and Guangpu Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Discrete Mathematics (cs.DM)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T21:04:32+00:00",
          "link": "https://arxiv.org/abs/2505.00862v1",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T18:46:12+00:00",
          "link": "https://arxiv.org/abs/2505.00862v2",
          "size": "10kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T22:08:30+00:00",
          "link": "https://arxiv.org/abs/2505.00862v3",
          "size": "11kb",
          "version": "v3"
        }
      ],
      "title": "Prime and Co-prime Integer Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00862",
        "HTML": "https://arxiv.org/html/2505.00862v3",
        "PDF": "https://arxiv.org/pdf/2505.00862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores mathematical properties of prime and co-prime integer matrices, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.01564",
      "abstract": "We present our solution for the Multi-Source COVID-19 Detection Challenge, which classifies chest CT scans from four distinct medical centers. To address multi-source variability, we employ the Spatial-Slice Feature Learning (SSFL) framework with Kernel-Density-based Slice Sampling (KDS). Our preprocessing pipeline combines lung region extraction, quality control, and adaptive slice sampling to select eight representative slices per scan. We compare EfficientNet and Swin Transformer architectures on the validation set. The EfficientNet model achieves an F1-score of 94.68%, compared to the Swin Transformer's 93.34%. The results demonstrate the effectiveness of our KDS-based pipeline on multi-source data and highlight the importance of dataset balance in multi-institutional medical imaging evaluation.",
      "authors": [
        "Chia-Ming Lee",
        "Bo-Cheng Qiu",
        "Ting-Yao Chen",
        "Ming-Han Sun",
        "Fang-Ying Lin",
        "Jung-Tse Tsai",
        "I-An Tsai",
        "Yu-Fan Lin",
        "Chih-Chung Hsu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T10:27:59+00:00",
          "link": "https://arxiv.org/abs/2507.01564v1",
          "size": "34911kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T17:04:09+00:00",
          "link": "https://arxiv.org/abs/2507.01564v2",
          "size": "31951kb",
          "version": "v2"
        }
      ],
      "title": "Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01564",
        "HTML": "https://arxiv.org/html/2507.01564v2",
        "PDF": "https://arxiv.org/pdf/2507.01564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses COVID-19 detection in chest CT scans using slice sampling techniques, focusing on preprocessing for medical imaging datasets rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02222",
      "abstract": "The binarization of vision transformers (ViTs) offers a promising approach to addressing the trade-off between high computational/storage demands and the constraints of edge-device deployment. However, existing binary ViT methods often suffer from severe performance degradation or rely heavily on full-precision modules. To address these issues, we propose DIDB-ViT, a novel binary ViT that is highly informative while maintaining the original ViT architecture and computational efficiency. Specifically, we design an informative attention module incorporating differential information to mitigate information loss caused by binarization and enhance high-frequency retention. To preserve the fidelity of the similarity calculations between binary Q and K tensors, we apply frequency decomposition using the discrete Haar wavelet and integrate similarities across different frequencies. Additionally, we introduce an improved RPReLU activation function to restructure the activation distribution, expanding the model's representational capacity. Experimental results demonstrate that our DIDB-ViT significantly outperforms state-of-the-art network quantization methods in multiple ViT architectures, achieving superior image classification and segmentation performance.",
      "authors": [
        "Tian Gao and Zhiyuan Zhang and Kaijie Yin and Xu-Cheng Zhong and Hui Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.02222v1",
          "size": "985kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T02:11:14+00:00",
          "link": "https://arxiv.org/abs/2507.02222v2",
          "size": "985kb",
          "version": "v2"
        }
      ],
      "title": "High-Fidelity Differential-information Driven Binary Vision Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02222",
        "HTML": "https://arxiv.org/html/2507.02222v2",
        "PDF": "https://arxiv.org/pdf/2507.02222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a binary vision transformer model aimed at reducing computation load without any mention of LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08052",
      "abstract": "Cloud and cloud shadow masking is a crucial preprocessing step in hyperspectral satellite imaging, enabling the extraction of high-quality, analysis-ready data. This study evaluates various machine learning approaches, including gradient boosting methods such as XGBoost and LightGBM as well as convolutional neural networks (CNNs). All boosting and CNN models achieved accuracies exceeding 93%. Among the investigated models, the CNN with feature reduction emerged as the most efficient, offering a balance of high accuracy, low storage requirements, and rapid inference times on both CPUs and GPUs. Variations of this version, with only up to 597 trainable parameters, demonstrated the best trade-off in terms of deployment feasibility, accuracy, and computational efficiency. These results demonstrate the potential of lightweight artificial intelligence (AI) models for real-time hyperspectral image processing, supporting the development of on-board satellite AI systems for space-based applications.",
      "authors": [
        "Mazen Ali",
        "Ant\\'onio Pereira",
        "Fabio Gentile",
        "Aser Cortines",
        "Sam Mugel",
        "Rom\\'an Or\\'us",
        "Stelios P. Neophytides",
        "Michalis Mavrovouniotis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:10:11+00:00",
          "link": "https://arxiv.org/abs/2507.08052v1",
          "size": "3495kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08052",
        "HTML": "https://arxiv.org/html/2507.08052",
        "PDF": "https://arxiv.org/pdf/2507.08052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on lightweight models for cloud masking in hyperspectral imaging. It doesn't discuss LLM training data processing or involve creation of training datasets for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09278",
      "abstract": "A space discrete approximation to a highly nonlinear reaction-diffusion system endowed with a stochastic dynamical boundary condition is analyzed and the convergence of the discrete scheme to the solution to the corresponding continuum random system is established. A splitting strategy allows us to decompose the random system into a space-discrete heat equation with a stochastic boundary condition, and a nonlinear and nonlocal space-discrete differential system coupled with the first one and with deterministic initial and boundary conditions. The convergence result is obtained by first establishing some a priori estimates for both space-discrete splitted variables and then exploiting compact embedding theorems for time-space Besov spaces on the positive lattice. The convergence of a fully discrete approximation of the random system is also discussed.",
      "authors": [
        "Francesca Arceci",
        "Francesco Carlo De Vecchi",
        "Daniela Morale and Stefania Ugolini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:18:43+00:00",
          "link": "https://arxiv.org/abs/2507.09278v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Discrete reaction-diffusion system with stochastic dynamical boundary conditions: convergence results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09278",
        "HTML": "https://arxiv.org/html/2507.09278v1",
        "PDF": "https://arxiv.org/pdf/2507.09278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a space discrete approximation to a nonlinear reaction-diffusion system, with no mention of LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09441",
      "abstract": "High-resolution image synthesis with diffusion models often suffers from energy instabilities and guidance artifacts that degrade visual quality. We analyze the latent energy landscape during sampling and propose adaptive classifier-free guidance (CFG) schedules that maintain stable energy trajectories. Our approach introduces energy-aware scheduling strategies that modulate guidance strength over time, achieving superior stability scores (0.9998) and consistency metrics (0.9873) compared to fixed-guidance approaches. We demonstrate that DPM++ 2M with linear-decreasing CFG scheduling yields optimal performance, providing sharper, more faithful images while reducing artifacts. Our energy profiling framework serves as a powerful diagnostic tool for understanding and improving diffusion model behavior.",
      "authors": [
        "Ankit Sanjyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T01:21:10+00:00",
          "link": "https://arxiv.org/abs/2507.09441v1",
          "size": "9502kb",
          "version": "v1"
        }
      ],
      "title": "RectifiedHR: High-Resolution Diffusion via Energy Profiling and Adaptive Guidance Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09441",
        "HTML": "https://arxiv.org/html/2507.09441v1",
        "PDF": "https://arxiv.org/pdf/2507.09441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses high-resolution image synthesis with diffusion models and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09750",
      "abstract": "We investigate the effects of four strategies for improving the ecological validity of synthetic room impulse response (RIR) datasets for monoaural Speech Enhancement (SE). We implement three features on top of the traditional image source method-based (ISM) shoebox RIRs: multiband absorption coefficients, source directivity and receiver directivity. We additionally consider mesh-based RIRs from the SoundSpaces dataset. We then train a DeepFilternet3 model for each RIR dataset and evaluate the performance on a test set of real RIRs both objectively and subjectively. We find that RIRs which use frequency-dependent acoustic absorption coefficients (MB-RIRs) can obtain +0.51dB of SDR and a +8.9 MUSHRA score when evaluated on real RIRs. The MB-RIRs dataset is publicly available for free download.",
      "authors": [
        "Enric Gus\\'o",
        "Joanna Luberadzka",
        "Umut Sayin and Xavier Serra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:00:26+00:00",
          "link": "https://arxiv.org/abs/2507.09750v1",
          "size": "185kb",
          "version": "v1"
        }
      ],
      "title": "MB-RIRs: a Synthetic Room Impulse Response Dataset with Frequency-Dependent Absorption Coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09750",
        "HTML": "https://arxiv.org/html/2507.09750v1",
        "PDF": "https://arxiv.org/pdf/2507.09750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset (MB-RIRs) with detailed data processing steps involving synthetic room impulse responses, enhancing data quality for Speech Enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10240",
      "abstract": "Our society increasingly depends on intelligent systems to solve complex problems, ranging from recommender systems suggesting the next movie to watch to AI models assisting in medical diagnoses for hospitalized patients. With the iterative improvement of diagnostic accuracy and efficiency, AI holds significant potential to mitigate medical misdiagnoses by preventing numerous deaths and reducing an economic burden of approximately 450 EUR billion annually. However, a key obstacle to AI adoption lies in the lack of transparency: many automated systems function as \"black boxes,\" providing predictions without revealing the underlying processes. This opacity can hinder experts' ability to trust and rely on AI systems. Visual analytics (VA) provides a compelling solution by combining AI models with interactive visualizations. These specialized charts and graphs empower users to incorporate their domain expertise to refine and improve the models, bridging the gap between AI and human understanding. In this work, we define, categorize, and explore how VA solutions can foster trust across the stages of a typical AI pipeline. We propose a design space for innovative visualizations and present an overview of our previously developed VA dashboards, which support critical tasks within the various pipeline stages, including data processing, feature engineering, hyperparameter tuning, understanding, debugging, refining, and comparing models.",
      "authors": [
        "Angelos Chatzimparmpas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:03:17+00:00",
          "link": "https://arxiv.org/abs/2507.10240v1",
          "size": "16847kb",
          "version": "v1"
        }
      ],
      "title": "Visual Analytics for Explainable and Trustworthy Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10240",
        "HTML": "https://arxiv.org/html/2507.10240v1",
        "PDF": "https://arxiv.org/pdf/2507.10240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses data processing as part of the AI pipeline, its primary focus is on visual analytics to improve model transparency and trust, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.16463",
      "abstract": "Score-based diffusion models are a powerful class of generative models, widely utilized across diverse domains. Despite significant advancements in large-scale tasks such as text-to-image generation, their application to constrained domains has received considerably less attention. This work addresses model learning in a setting where, in addition to the training dataset, there further exists side-information in the form of an oracle that can label samples as being outside the support of the true data generating distribution. Specifically we develop a new denoising diffusion probabilistic modeling methodology, Gen-neG, that leverages this additional side-information. Gen-neG builds on classifier guidance in diffusion models to guide the generation process towards the positive support region indicated by the oracle. We empirically establish the utility of Gen-neG in applications including collision avoidance in self-driving simulators and safety-guarded human motion generation.",
      "authors": [
        "Saeid Naderiparizi",
        "Xiaoxuan Liang",
        "Setareh Cohan",
        "Berend Zwartsenberg",
        "Frank Wood"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-31T07:52:00+00:00",
          "link": "https://arxiv.org/abs/2307.16463v1",
          "size": "10626kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T19:40:25+00:00",
          "link": "https://arxiv.org/abs/2307.16463v2",
          "size": "8043kb",
          "version": "v2"
        }
      ],
      "title": "Don't be so negative! Score-based Generative Modeling with Oracle-assisted Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.16463",
        "HTML": "https://arxiv.org/html/2307.16463v2",
        "PDF": "https://arxiv.org/pdf/2307.16463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents a generative modeling approach utilizing oracle guidance, it does not primarily focus on LLM training data processing or detailed dataset creation steps."
      },
      "tasks": [
        "Collision Avoidance",
        "Denoising",
        "Motion Generation",
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03664",
      "abstract": "The Kneser--Poulsen conjecture asserts that the volume of a union of balls in Euclidean space cannot be increased by bringing their centres pairwise closer. We prove that its natural information-theoretic counterpart is true. This follows from a complete answer to a question asked in arXiv:2210.12842 about Gaussian convolutions, namely that the R\\'enyi entropy comparisons between a probability measure and its contractive image are preserved when both undergo simultaneous heat flow. An inequality that unifies Costa's result on the concavity of entropy power with the entropic Kneser--Poulsen theorem is also presented.",
      "authors": [
        "Gautam Aishwarya",
        "Dongbin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T16:18:00+00:00",
          "link": "https://arxiv.org/abs/2409.03664v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-03-16T16:13:54+00:00",
          "link": "https://arxiv.org/abs/2409.03664v2",
          "size": "34kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T17:03:12+00:00",
          "link": "https://arxiv.org/abs/2409.03664v3",
          "size": "34kb",
          "version": "v3"
        }
      ],
      "title": "The Kneser--Poulsen phenomena for entropy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03664",
        "HTML": "https://arxiv.org/html/2409.03664v3",
        "PDF": "https://arxiv.org/pdf/2409.03664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Kneser--Poulsen conjecture and entropy in a mathematical context without any connection to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.18448",
      "abstract": "Handling ambiguity and underspecification is an important challenge in natural language interfaces, particularly for tasks like text-to-SQL semantic parsing. We propose a modular approach that resolves ambiguity using natural language interpretations before mapping these to logical forms (e.g., SQL queries). Although LLMs excel at parsing unambiguous utterances, they show strong biases for ambiguous ones, typically predicting only preferred interpretations. We constructively exploit this bias to generate an initial set of preferred disambiguations and then apply a specialized infilling model to identify and generate missing interpretations. To train the infilling model, we introduce an annotation method that uses SQL execution to validate different meanings. Our approach improves interpretation coverage and generalizes across datasets with different annotation styles, database structures, and ambiguity types.",
      "authors": [
        "Irina Saparina and Mirella Lapata"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T18:42:26+00:00",
          "link": "https://arxiv.org/abs/2502.18448v1",
          "size": "8731kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T13:56:11+00:00",
          "link": "https://arxiv.org/abs/2502.18448v2",
          "size": "8726kb",
          "version": "v2"
        }
      ],
      "title": "Disambiguate First, Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18448",
        "HTML": "https://arxiv.org/html/2502.18448v2",
        "PDF": "https://arxiv.org/pdf/2502.18448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with ambiguity resolution in semantic parsing and does not address LLM training data processing or data engineering methods."
      },
      "tasks": [
        "Semantic Parsing",
        "Text to SQL",
        "Text-To-SQL"
      ],
      "repo_urls": [
        "https://github.com/saparina/disambiguate-then-parse"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07947",
      "abstract": "The recent advances in generative models such as diffusion models have raised several risks and concerns related to privacy, copyright infringements and data stewardship. To better understand and control the risks, various researchers have created techniques, experiments and attacks that reconstruct images, or part of images, from the training set. While these techniques already establish that data from the training set can be reconstructed, they often rely on high-resources, excess to the training set as well as well-engineered and designed prompts.\n  In this work, we devise a new attack that requires low resources, assumes little to no access to the actual training set, and identifies, seemingly, benign prompts that lead to potentially-risky image reconstruction. This highlights the risk that images might even be reconstructed by an uninformed user and unintentionally. For example, we identified that, with regard to one existing model, the prompt ``blue Unisex T-Shirt'' can generate the face of a real-life human model. Our method builds on an intuition from previous works which leverages domain knowledge and identifies a fundamental vulnerability that stems from the use of scraped data from e-commerce platforms, where templated layouts and images are tied to pattern-like prompts.",
      "authors": [
        "Sol Yarkoni and Roi Livni"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:32:26+00:00",
          "link": "https://arxiv.org/abs/2507.07947v1",
          "size": "47781kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:03:51+00:00",
          "link": "https://arxiv.org/abs/2507.07947v2",
          "size": "49753kb",
          "version": "v2"
        }
      ],
      "title": "Low Resource Reconstruction Attacks Through Benign Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07947",
        "HTML": "https://arxiv.org/html/2507.07947v2",
        "PDF": "https://arxiv.org/pdf/2507.07947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses low-resource reconstruction attacks related to image data and privacy concerns, but it does not focus on LLM training data processing or creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09123",
      "abstract": "The Online Bin Packing Problem (OBPP) is a sequential decision-making task in which each item must be placed immediately upon arrival, with no knowledge of future arrivals. Although recent deep-reinforcement-learning methods achieve superior volume utilization compared with classical heuristics, the learned policies cannot ensure the structural stability of the bin and lack mechanisms for safely reconfiguring the bin when a new item cannot be placed directly. In this work, we propose a novel framework that integrates packing policy with structural stability validation and heuristic planning to overcome these limitations. Specifically, we introduce the concept of Load Bearable Convex Polygon (LBCP), which provides a computationally efficient way to identify stable loading positions that guarantee no bin collapse. Additionally, we present Stable Rearrangement Planning (SRP), a module that rearranges existing items to accommodate new ones while maintaining overall stability. Extensive experiments on standard OBPP benchmarks demonstrate the efficiency and generalizability of our LBCP-based stability validation, as well as the superiority of SRP in finding the effort-saving rearrangement plans. Our method offers a robust and practical solution for automated packing in real-world industrial and logistics applications.",
      "authors": [
        "Ziyan Gao",
        "Lijun Wang",
        "Yuntao Kong",
        "Nak Young Chong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:55:31+00:00",
          "link": "https://arxiv.org/abs/2507.09123v1",
          "size": "5211kb",
          "version": "v1"
        }
      ],
      "title": "Online 3D Bin Packing with Fast Stability Validation and Stable Rearrangement Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09123",
        "HTML": "https://arxiv.org/html/2507.09123v1",
        "PDF": "https://arxiv.org/pdf/2507.09123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the online 3D bin packing problem using structural stability and rearrangement planning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10066",
      "abstract": "This demonstration paper presents $\\mathbf{LayLens}$, a tool aimed to make deepfake understanding easier for users of all educational backgrounds. While prior works often rely on outputs containing technical jargon, LayLens bridges the gap between model reasoning and human understanding through a three-stage pipeline: (1) explainable deepfake detection using a state-of-the-art forgery localization model, (2) natural language simplification of technical explanations using a vision-language model, and (3) visual reconstruction of a plausible original image via guided image editing. The interface presents both technical and layperson-friendly explanations in addition to a side-by-side comparison of the uploaded and reconstructed images. A user study with 15 participants shows that simplified explanations significantly improve clarity and reduce cognitive load, with most users expressing increased confidence in identifying deepfakes. LayLens offers a step toward transparent, trustworthy, and user-centric deepfake forensics.",
      "authors": [
        "Abhijeet Narang",
        "Parul Gupta",
        "Liuyijia Su and Abhinav Dhall"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:52:03+00:00",
          "link": "https://arxiv.org/abs/2507.10066v1",
          "size": "1501kb",
          "version": "v1"
        }
      ],
      "title": "LayLens: Improving Deepfake Understanding through Simplified Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10066",
        "HTML": "https://arxiv.org/html/2507.10066v1",
        "PDF": "https://arxiv.org/pdf/2507.10066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving user understanding of deepfakes through explanation mechanisms, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10085",
      "abstract": "Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient Fine-Tuning (PEFT) method, has attracted widespread attention for significantly improving parameter efficiency by editing representation space alone. In this work, we investigate applying ReFT to complex reasoning tasks. However, directly using the native ReFT method, which modifies fixed representations at the beginning and end of each layer, yields suboptimal performance, as these fixed-position representations have uncertain impact on the outputs. We observe that, in complex reasoning tasks, there often exist certain critical representations. These representations either integrate significant information from preceding layers or regulate subsequent layer representations. Through layer-by-layer propagation, they exert a substantial influence on the final output. Naturally, fine-tuning these critical representations has the potential to greatly enhance reasoning performance. Building upon these insights, we propose Critical Representation Fine-Tuning (CRFT), a novel method that identifies and optimizes these critical representations through information flow analysis. CRFT operates within a supervised learning framework, dynamically optimizing critical representations in a low-rank linear subspace while freezing the base model. The effectiveness and efficiency of our method are validated across eight benchmarks for arithmetic and commonsense reasoning, using LLaMA and Mistral model families. Furthermore, our method also adapts effectively to few-shot settings, boosting one-shot accuracy by 16.4%. Our work highlights the untapped potential of representation-level optimization for CoT reasoning, offering a lightweight yet powerful alternative to traditional PEFT methods.",
      "authors": [
        "Chenxi Huang",
        "Shaotian Yan",
        "Liang Xie",
        "Binbin Lin",
        "Sinan Fan",
        "Yue Xin",
        "Deng Cai",
        "Chen Shen",
        "Jieping Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:11:33+00:00",
          "link": "https://arxiv.org/abs/2507.10085v1",
          "size": "16498kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10085",
        "PDF": "https://arxiv.org/pdf/2507.10085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a fine-tuning method for improving reasoning tasks but does not focus on processing or creating LLM training data; the emphasis is on model tuning techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03912",
      "abstract": "Automating labor-intensive tasks such as crop monitoring with robots is essential for enhancing production and conserving resources. However, autonomously monitoring horticulture crops remains challenging due to their complex structures, which often result in fruit occlusions. Existing view planning methods attempt to reduce occlusions but either struggle to achieve adequate coverage or incur high robot motion costs. We introduce a global optimization approach for view motion planning that aims to minimize robot motion costs while maximizing fruit coverage. To this end, we leverage coverage constraints derived from the set covering problem (SCP) within a shortest Hamiltonian path problem (SHPP) formulation. While both SCP and SHPP are well-established, their tailored integration enables a unified framework that computes a global view path with minimized motion while ensuring full coverage of selected targets. Given the NP-hard nature of the problem, we employ a region-prior-based selection of coverage targets and a sparse graph structure to achieve effective optimization outcomes within a limited time. Experiments in simulation demonstrate that our method detects more fruits, enhances surface coverage, and achieves higher volume accuracy than the motion-efficient baseline with a moderate increase in motion cost, while significantly reducing motion costs compared to the coverage-focused baseline. Real-world experiments further confirm the practical applicability of our approach.",
      "authors": [
        "Allen Isaac Jose",
        "Sicong Pan",
        "Tobias Zaenker",
        "Rohit Menon",
        "Sebastian Houben",
        "Maren Bennewitz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T21:25:03+00:00",
          "link": "https://arxiv.org/abs/2503.03912v1",
          "size": "4420kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:42:44+00:00",
          "link": "https://arxiv.org/abs/2503.03912v2",
          "size": "4417kb",
          "version": "v2"
        }
      ],
      "title": "GO-VMP: Global Optimization for View Motion Planning in Fruit Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03912",
        "HTML": "https://arxiv.org/html/2503.03912v2",
        "PDF": "https://arxiv.org/pdf/2503.03912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses view motion planning in robotics for fruit mapping, with no focus on LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08845",
      "abstract": "Graph Neural Networks (GNNs) are becoming an essential tool for learning from graph-structured data, however uniform neighbor sampling and static fanout settings frequently limit GNNs' scalability and efficiency. In this paper, we propose the Dynamic Adaptive Fanout Optimization Sampler (DAFOS), a novel approach that dynamically adjusts the fanout based on model performance and prioritizes important nodes during training. Our approach leverages node scoring based on node degree to focus computational resources on structurally important nodes, incrementing the fanout as the model training progresses. DAFOS also integrates an early stopping mechanism to halt training when performance gains diminish. Experiments conducted on three benchmark datasets, ogbnarxiv, Reddit, and ogbn-products, demonstrate that our approach significantly improves training speed and accuracy compared to a state-of-the-art approach. DAFOS achieves a 3.57x speedup on the ogbn-arxiv dataset and a 12.6x speedup on the Reddit dataset while improving the F1 score from 68.5% to 71.21% on ogbn-arxiv and from 73.78% to 76.88% on the ogbn-products dataset, respectively. These results highlight the potential of DAFOS as an efficient and scalable solution for large-scale GNN training.",
      "authors": [
        "Irfan Ullah and Young-Koo Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:25:36+00:00",
          "link": "https://arxiv.org/abs/2507.08845v1",
          "size": "567kb",
          "version": "v1"
        }
      ],
      "title": "DAFOS: Dynamic Adaptive Fanout Optimization Sampler",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08845",
        "PDF": "https://arxiv.org/pdf/2507.08845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses optimization in Graph Neural Networks and does not address any aspects of LLM training data processing, engineering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09506",
      "abstract": "Long-context language models (LCLMs) have exhibited impressive capabilities in long-context understanding tasks. Among these, long-context referencing -- a crucial task that requires LCLMs to attribute items of interest to specific parts of long-context data -- remains underexplored. To bridge this gap, this paper proposes Referencing Evaluation for Long-context Language Models (Ref-Long), a novel benchmark designed to assess the long-context referencing capability of LCLMs. Specifically, Ref-Long requires LCLMs to identify the indexes of documents that reference a specific key, emphasizing contextual relationships between the key and the documents over simple retrieval. Based on the task design, we construct three subsets ranging from synthetic to realistic scenarios to form the Ref-Long benchmark. Experimental results of 13 LCLMs reveal significant shortcomings in long-context referencing, even among advanced models like GPT-4o. To further investigate these challenges, we conduct comprehensive analyses, including human evaluations, task format adjustments, fine-tuning experiments, and error analyses, leading to several key insights. Our data and code can be found in https://github. com/wujunjie1998/Ref-Long.",
      "authors": [
        "Junjie Wu",
        "Gefei Gu",
        "Yanan Zheng",
        "Dit-Yan Yeung",
        "Arman Cohan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:17:53+00:00",
          "link": "https://arxiv.org/abs/2507.09506v1",
          "size": "184kb",
          "version": "v1"
        }
      ],
      "title": "Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09506",
        "HTML": "https://arxiv.org/html/2507.09506v1",
        "PDF": "https://arxiv.org/pdf/2507.09506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a benchmark (Ref-Long) for evaluating long-context referencing capability of LCLMs. While it involves constructing datasets to test models, the focus is on benchmark construction rather than LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09782",
      "abstract": "This paper introduces a framework based on physics-informed neural networks (PINNs) for addressing key challenges in nonlinear lattices, including solution approximation, bifurcation diagram construction, and linear stability analysis. We first employ PINNs to approximate solutions of nonlinear systems arising from lattice models, using the Levenberg-Marquardt algorithm to optimize network weights for greater accuracy. To enhance computational efficiency in high-dimensional settings, we integrate a stochastic sampling strategy. We then extend the method by coupling PINNs with a continuation approach to compute snaking bifurcation diagrams, incorporating an auxiliary equation to effectively track successive solution branches. For linear stability analysis, we adapt PINNs to compute eigenvectors, introducing output constraints to enforce positivity, in line with Sturm-Liouville theory. Numerical experiments are conducted on the discrete Allen-Cahn equation with cubic and quintic nonlinearities in one to five spatial dimensions. The results demonstrate that the proposed approach achieves accuracy comparable to, or better than, traditional numerical methods, especially in high-dimensional regimes where computational resources are a limiting factor. These findings highlight the potential of neural networks as scalable and efficient tools for the study of complex nonlinear lattice systems.",
      "authors": [
        "Muhammad Luthfi Shahab",
        "Fidya Almira Suheri",
        "Rudy Kusdiantara",
        "Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:41:55+00:00",
          "link": "https://arxiv.org/abs/2507.09782v1",
          "size": "868kb",
          "version": "v1"
        }
      ],
      "title": "Physics-informed neural networks for high-dimensional solutions and snaking bifurcations in nonlinear lattices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09782",
        "HTML": "https://arxiv.org/html/2507.09782v1",
        "PDF": "https://arxiv.org/pdf/2507.09782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using physics-informed neural networks for solving nonlinear equations, focusing on solution approximation and bifurcation analysis, but not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09876",
      "abstract": "Video understanding plays a vital role in bridging low-level visual signals with high-level cognitive reasoning, and is fundamental to applications such as autonomous driving, embodied AI, and the broader pursuit of AGI. The rapid development of large language models (LLMs), particularly those utilizing Chain-of-Thought (CoT) technology, has significantly advanced video reasoning capabilities. However, current approaches primarily depend on textual information for reasoning, overlooking the visual modality in the actual video reasoning process. In contrast, humans naturally re-examine visual content while reasoning. Motivated by this, we introduce a novel video reasoning paradigm: Video-Text Interleaved CoT (ViTCoT), which facilitates more intuitive and cognitively aligned reasoning. To the end, first, we construct the Video-Text Interleaved Benchmark (ViTIB), which is created using MLLMs for key-video selection and manually verified. Furthermore, we extensively explore the potential of the ViTCoT paradigm in the video understanding field. Extensive experiments demonstrate that ViTCoT significantly enhances performance compared to the traditional text-only CoT paradigm and effectively activates more neuron values in MLLMs.",
      "authors": [
        "Yongheng Zhang",
        "Xu Liu",
        "Ruihan Tao",
        "Qiguang Chen",
        "Hao Fei",
        "Wanxiang Che",
        "Libo Qin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:21:13+00:00",
          "link": "https://arxiv.org/abs/2507.09876v1",
          "size": "1703kb",
          "version": "v1"
        }
      ],
      "title": "ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09876",
        "HTML": "https://arxiv.org/html/2507.09876v1",
        "PDF": "https://arxiv.org/pdf/2507.09876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on video reasoning capabilities using LLMs and introduces a new benchmark (ViTIB), but it is more about improving reasoning using existing frameworks rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10070",
      "abstract": "With the advancement of information retrieval, recommendation systems, and Retrieval-Augmented Generation (RAG), Approximate Nearest Neighbor Search (ANNS) gains widespread applications due to its higher performance and accuracy. While several disk-based ANNS systems have emerged to handle exponentially growing vector datasets, they suffer from suboptimal performance due to two inherent limitations: 1) failing to overlap SSD accesses with distance computation processes and 2) extended I/O latency caused by suboptimal I/O Stack. To address these challenges, we present FlashANNS, a GPU-accelerated out-of-core graph-based ANNS system through I/O-compute overlapping. Our core insight lies in the synchronized orchestration of I/O and computation through three key innovations: 1) Dependency-Relaxed asynchronous pipeline: FlashANNS decouples I/O-computation dependencies to fully overlap between GPU distance calculations and SSD data transfers. 2) Warp-Level concurrent SSD access: FlashANNS implements a lock-free I/O stack with warp-level concurrency control, to reduce the latency-induced time overhead. 3) Computation-I/O balanced graph degree Selection: FlashANNS selects graph degrees via lightweight compute-to-I/O ratio sampling, ensuring optimal balance between computational load and storage access latency across different I/O bandwidth configurations. We implement FlashANNS and compare it with state-of-the-art out-of-core ANNS systems (SPANN, DiskANN) and a GPU-accelerated out-of-core ANNS system (FusionANNS). Experimental results demonstrate that at $\\geq$95\\% recall@10 accuracy, our method achieves 2.3-5.9$\\times$ higher throughput compared to existing SOTA methods with a single SSD, and further attains 2.7-12.2$\\times$ throughput improvement in multi-SSD configurations.",
      "authors": [
        "Yang Xiao",
        "Mo Sun",
        "Ziyu Song",
        "Bing Tian",
        "Jie Zhang",
        "Jie Sun",
        "Zeke Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:55:51+00:00",
          "link": "https://arxiv.org/abs/2507.10070v1",
          "size": "3365kb",
          "version": "v1"
        }
      ],
      "title": "Breaking the Storage-Compute Bottleneck in Billion-Scale ANNS: A GPU-Driven Asynchronous I/O Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10070",
        "HTML": "https://arxiv.org/html/2507.10070v1",
        "PDF": "https://arxiv.org/pdf/2507.10070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with addressing storage-compute bottlenecks in billion-scale ANNS systems, not with LLM training data processing or dataset preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10358",
      "abstract": "Zero-shot object detection (ZSD) aims to leverage semantic descriptions to localize and recognize objects of both seen and unseen classes. Existing ZSD works are mainly coarse-grained object detection, where the classes are visually quite different, thus are relatively easy to distinguish. However, in real life we often have to face fine-grained object detection scenarios, where the classes are too similar to be easily distinguished. For example, detecting different kinds of birds, fishes, and flowers.\n  In this paper, we propose and solve a new problem called Fine-Grained Zero-Shot Object Detection (FG-ZSD for short), which aims to detect objects of different classes with minute differences in details under the ZSD paradigm. We develop an effective method called MSHC for the FG-ZSD task, which is based on an improved two-stage detector and employs a multi-level semantics-aware embedding alignment loss, ensuring tight coupling between the visual and semantic spaces. Considering that existing ZSD datasets are not suitable for the new FG-ZSD task, we build the first FG-ZSD benchmark dataset FGZSD-Birds, which contains 148,820 images falling into 36 orders, 140 families, 579 genera and 1432 species. Extensive experiments on FGZSD-Birds show that our method outperforms existing ZSD models.",
      "authors": [
        "Hongxu Ma",
        "Chenbo Zhang",
        "Lu Zhang",
        "Jiaogen Zhou",
        "Jihong Guan",
        "Shuigeng Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:00:00+00:00",
          "link": "https://arxiv.org/abs/2507.10358v1",
          "size": "2918kb",
          "version": "v1"
        }
      ],
      "title": "Fine-Grained Zero-Shot Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10358",
        "HTML": "https://arxiv.org/html/2507.10358v1",
        "PDF": "https://arxiv.org/pdf/2507.10358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper involves the creation of a benchmark dataset (FGZSD-Birds) for fine-grained zero-shot detection, the primary focus is on the detection method and its application rather than detailed data processing steps for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08824",
      "abstract": "A prior global topological map (e.g., the OpenStreetMap, OSM) can boost the performance of autonomous mapping by a ground mobile robot. However, the prior map is usually incomplete due to lacking labeling in partial paths. To solve this problem, this paper proposes an OSM maker using airborne sensors carried by low-altitude aircraft, where the core of the OSM maker is a novel efficient pathfinder approach based on LiDAR and camera data, i.e., a binary dual-stream road segmentation model. Specifically, a multi-scale feature extraction based on the UNet architecture is implemented for images and point clouds. To reduce the effect caused by the sparsity of point cloud, an attention-guided gated block is designed to integrate image and point-cloud features. To optimize the model for edge deployment that significantly reduces storage footprint and computational demands, we propose a binarization streamline to each model component, including a variant of vision transformer (ViT) architecture as the encoder of the image branch, and new focal and perception losses to optimize the model training. The experimental results on two datasets demonstrate that our pathfinder method achieves SOTA accuracy with high efficiency in finding paths from the low-level airborne sensors, and we can create complete OSM prior maps based on the segmented road skeletons. Code and data are available at: \\href{https://github.com/IMRL/Pathfinder}{https://github.com/IMRL/Pathfinder}.",
      "authors": [
        "Kaijie Yin and Tian Gao and Hui Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T13:37:33+00:00",
          "link": "https://arxiv.org/abs/2409.08824v1",
          "size": "7365kb",
          "version": "v1"
        },
        {
          "date": "2024-09-23T01:29:58+00:00",
          "link": "https://arxiv.org/abs/2409.08824v2",
          "size": "7403kb",
          "version": "v2"
        },
        {
          "date": "2025-03-06T12:26:08+00:00",
          "link": "https://arxiv.org/abs/2409.08824v3",
          "size": "7403kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T07:54:49+00:00",
          "link": "https://arxiv.org/abs/2409.08824v4",
          "size": "7347kb",
          "version": "v4"
        }
      ],
      "title": "Pathfinder for Low-altitude Aircraft with Binary Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08824",
        "HTML": "https://arxiv.org/html/2409.08824v4",
        "PDF": "https://arxiv.org/pdf/2409.08824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for generating topological maps using airborne sensors, which does not relate to LLM training data processing or data engineering."
      },
      "tasks": [
        "Binarization",
        "Pathfinder",
        "Road Segmentation"
      ],
      "repo_urls": [
        "https://github.com/imrl/pathfinder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23555",
      "abstract": "Federated LoRA has emerged as a promising technique for efficiently fine-tuning large language models (LLMs) on distributed devices by reducing the number of trainable parameters. However, existing approaches often inadequately overlook the theoretical and practical implications of system and data heterogeneity, thereby failing to optimize the overall training efficiency, particularly in terms of wall-clock time. In this paper, we propose an adaptive federated LoRA strategy with independent client sampling to minimize the convergence wall-clock time of federated fine-tuning under both computation and communication heterogeneity. We first derive a new convergence bound for federated LoRA with arbitrary and independent client sampling, notably without requiring the stringent bounded gradient assumption. Then, we introduce an adaptive bandwidth allocation scheme that accounts for heterogeneous client resources and system bandwidth constraints. Based on the derived theory, we formulate and solve a non-convex optimization problem to jointly determine the LoRA sketching ratios and sampling probabilities, aiming to minimize wall-clock convergence time. An efficient and low-complexity algorithm is developed to approximate the solution. Finally, extensive experiments demonstrate that our approach significantly reduces wall-clock training time compared to state-of-the-art methods across various models and datasets.",
      "authors": [
        "Yanzhao Hou",
        "Jiaxiang Geng",
        "Boyu Li",
        "Xiaofeng Tao",
        "Juncheng Wang",
        "Xiaodong Xu",
        "Bing Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T15:31:37+00:00",
          "link": "https://arxiv.org/abs/2505.23555v1",
          "size": "635kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T15:01:58+00:00",
          "link": "https://arxiv.org/abs/2505.23555v2",
          "size": "635kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T03:55:55+00:00",
          "link": "https://arxiv.org/abs/2505.23555v3",
          "size": "635kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23555",
        "HTML": "https://arxiv.org/html/2505.23555v3",
        "PDF": "https://arxiv.org/pdf/2505.23555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses federated fine-tuning strategies for LLMs in distributed settings, focusing on optimization techniques rather than novel contributions to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08903",
      "abstract": "High-definition (HD) semantic mapping of complex intersections poses significant challenges for traditional vehicle-based approaches due to occlusions and limited perspectives. This paper introduces a novel camera-LiDAR fusion framework that leverages elevated intelligent roadside units (IRUs). Additionally, we present RS-seq, a comprehensive dataset developed through the systematic enhancement and annotation of the V2X-Seq dataset. RS-seq includes precisely labelled camera imagery and LiDAR point clouds collected from roadside installations, along with vectorized maps for seven intersections annotated with detailed features such as lane dividers, pedestrian crossings, and stop lines. This dataset facilitates the systematic investigation of cross-modal complementarity for HD map generation using IRU data. The proposed fusion framework employs a two-stage process that integrates modality-specific feature extraction and cross-modal semantic integration, capitalizing on camera high-resolution texture and precise geometric data from LiDAR. Quantitative evaluations using the RS-seq dataset demonstrate that our multimodal approach consistently surpasses unimodal methods. Specifically, compared to unimodal baselines evaluated on the RS-seq dataset, the multimodal approach improves the mean Intersection-over-Union (mIoU) for semantic segmentation by 4\\% over the image-only results and 18\\% over the point cloud-only results. This study establishes a baseline methodology for IRU-based HD semantic mapping and provides a valuable dataset for future research in infrastructure-assisted autonomous driving systems.",
      "authors": [
        "Zhongzhang Chen",
        "Miao Fan",
        "Shengtong Xu",
        "Mengmeng Yang",
        "Kun Jiang",
        "Xiangzeng Liu",
        "Haoyi Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:45:56+00:00",
          "link": "https://arxiv.org/abs/2507.08903v1",
          "size": "2269kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal HD Mapping for Intersections by Intelligent Roadside Units",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08903",
        "PDF": "https://arxiv.org/pdf/2507.08903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a dataset (RS-seq) but focuses on HD mapping and not directly on LLM training data or processing methods specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08982",
      "abstract": "Recent years have witnessed remarkable progress in developing Vision-Language Models (VLMs) capable of processing both textual and visual inputs. These models have demonstrated impressive performance, leading to their widespread adoption in various applications. However, this widespread raises serious concerns regarding user privacy, particularly when models inadvertently process or expose private visual information. In this work, we frame the preservation of privacy in VLMs as an adversarial attack problem. We propose a novel attack strategy that selectively conceals information within designated Region Of Interests (ROIs) in an image, effectively preventing VLMs from accessing sensitive content while preserving the semantic integrity of the remaining image. Unlike conventional adversarial attacks that often disrupt the entire image, our method maintains high coherence in unmasked areas. Experimental results across three state-of-the-art VLMs namely LLaVA, Instruct-BLIP, and BLIP2-T5 demonstrate up to 98% reduction in detecting targeted ROIs, while maintaining global image semantics intact, as confirmed by high similarity scores between clean and adversarial outputs. We believe that this work contributes to a more privacy conscious use of multimodal models and offers a practical tool for further research, with the source code publicly available at: https://github.com/hbrachemi/Vlm_defense-attack.",
      "authors": [
        "Hanene F. Z. Brachemi Meftah",
        "Wassim Hamidouche",
        "Sid Ahmed Fezza",
        "and Olivier D\\'eforges"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:34:01+00:00",
          "link": "https://arxiv.org/abs/2507.08982v1",
          "size": "20150kb",
          "version": "v1"
        }
      ],
      "title": "VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08982",
        "HTML": "https://arxiv.org/html/2507.08982v1",
        "PDF": "https://arxiv.org/pdf/2507.08982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses adversarial attacks for privacy in Vision-Language Models and does not involve any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10452",
      "abstract": "Solutions of optimization problems, including policy optimization in reinforcement learning, typically rely upon some variant of gradient descent. There has been much recent work in the machine learning, control, and optimization communities applying the Polyak-{\\L}ojasiewicz Inequality (PLI) to such problems in order to establish an exponential rate of convergence (a.k.a. ``linear convergence'' in the local-iteration language of numerical analysis) of loss functions to their minima under the gradient flow. Often, as is the case of policy iteration for the continuous-time LQR problem, this rate vanishes for large initial conditions, resulting in a mixed globally linear / locally exponential behavior. This is in sharp contrast with the discrete-time LQR problem, where there is global exponential convergence. That gap between CT and DT behaviors motivates the search for various generalized PLI-like conditions, and this talk will address that topic. Moreover, these generalizations are key to understanding the transient and asymptotic effects of errors in the estimation of the gradient, errors which might arise from adversarial attacks, wrong evaluation by an oracle, early stopping of a simulation, inaccurate and very approximate digital twins, stochastic computations (algorithm ``reproducibility''), or learning by sampling from limited data. We describe an ``input to state stability'' (ISS) analysis of this issue. The lecture also discussed convergence and PLI-like properties of ``linear feedforward neural networks'' in feedback control, but this arXiv skips that part (to be updated). Much of the work described here was done in collaboration with Arthur Castello B. de Oliveira, Leilei Cui, Zhong-Ping Jiang, and Milad Siami.",
      "authors": [
        "Eduardo D. Sontag"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:31:06+00:00",
          "link": "https://arxiv.org/abs/2507.10452v1",
          "size": "759kb",
          "version": "v1"
        }
      ],
      "title": "Some remarks on gradient dominance and LQR policy optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10452",
        "HTML": "https://arxiv.org/html/2507.10452v1",
        "PDF": "https://arxiv.org/pdf/2507.10452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses optimization and convergence properties, focusing on policy optimization and gradient descent improvements. It does not address processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.13910",
      "abstract": "Attribution methods are primarily designed to study input component contributions to individual model predictions. However, some research applications require a summary of attribution patterns across the entire dataset to facilitate the interpretability of the scrutinized models at a task-level rather than an instance-level. It specifically applies when the localization of important input information is supposed to be stable for a specific problem but remains unidentified among numerous components. In this paper, we present a dataset-wise attribution method called Integrated Gradient Correlation (IGC) that enables region-specific analysis by a direct summation over associated components, and further relates the sum of all attributions to a model prediction score (correlation). We demonstrate IGC on synthetic data and fMRI neural signals (NSD dataset) with the study of the representation of image features in the brain and the estimation of the visual receptive field of neural populations. The resulting IGC attributions reveal selective patterns, coherent with respective model objectives.",
      "authors": [
        "Pierre Leli\\`evre and Chien-Chung Chen (National Taiwan University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-22T06:42:21+00:00",
          "link": "https://arxiv.org/abs/2404.13910v1",
          "size": "2913kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:06:34+00:00",
          "link": "https://arxiv.org/abs/2404.13910v2",
          "size": "5109kb",
          "version": "v2"
        }
      ],
      "title": "Integrated Gradient Correlation: a Dataset-wise Attribution Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.13910",
        "HTML": "https://arxiv.org/html/2404.13910v2",
        "PDF": "https://arxiv.org/pdf/2404.13910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dataset-wise attribution method for model interpretability, which is used for analysis of input data impact rather than LLM training data processing."
      },
      "tasks": [
        "Handwritten Digit Recognition"
      ],
      "repo_urls": [
        "https://github.com/plelievre/int_grad_corr",
        "https://github.com/MindSpore-scientific/code-4/tree/main/Integrated-Gradient"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.14829",
      "abstract": "The conventional computer architecture has been facing challenges answering the ever-increasing demands from emerging applications, such as AI, for energy-efficient computation and memory hardware systems. Computational Random Access Memory (CRAM) represents a true in-memory computing paradigm that integrates logic and memory functions within the same array. At its core, CRAM relies on Magnetic Tunnel Junctions (MTJs), which serve as the foundational building blocks for implementing both memory storage and logic operations. However, a key challenge in CRAM lies in the non-ideal error rates associated with switching dynamics of MTJs, necessitating innovative approaches to reduce errors and optimize logic margins. This work proposes a novel approach of utilizing the voltage-controlled magnetic anisotropy (VCMA) to steepen the switching probability transfer curve (SPTC), thereby significantly reducing the logic operation error rate in CRAM. Using several numerical modeling tools, we validate the effectiveness of VCMA in modulating the energy barrier and switching dynamics in MTJs. It is revealed that the VCMA effect significantly reduces the error rate of CRAM by 61.43% at a VCMA coefficient of 200 fJ/V/m compared to CRAM without VCMA. The reduction of error rate is further rapidly amplified with an increasing TMR ratio. Furthermore, the introduction of the VCMA effect decreases the logic voltage (Vlogic) required for logic operations in CRAM and results in reduction of energy consumption. Our work serves as a first exploration in reducing the error rate in CRAM by modifying SPTC in MTJs.",
      "authors": [
        "Yang Lv",
        "Brahmdutta Dixit",
        "and Jian-Ping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T18:47:46+00:00",
          "link": "https://arxiv.org/abs/2505.14829v1",
          "size": "1125kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:44:06+00:00",
          "link": "https://arxiv.org/abs/2505.14829v2",
          "size": "1361kb",
          "version": "v2"
        }
      ],
      "title": "Modulation of switching dynamics in magnetic tunnel junctions for low-error-rate computational random-access memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14829",
        "PDF": "https://arxiv.org/pdf/2505.14829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reducing error rates in Computational Random Access Memory (CRAM) using Magnetic Tunnel Junctions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07625",
      "abstract": "We prove concentration inequalities for several models of non-linear random matrices. As corollaries we obtain estimates for linear spectral statistics of the conjugate kernel of neural networks and non-commutative polynomials in (possibly dependent) random matrices.",
      "authors": [
        "Rados{\\l}aw Adamczak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:47:42+00:00",
          "link": "https://arxiv.org/abs/2507.07625v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T10:55:43+00:00",
          "link": "https://arxiv.org/abs/2507.07625v2",
          "size": "43kb",
          "version": "v2"
        }
      ],
      "title": "Concentration of measure for non-linear random matrices with applications to neural networks and non-commutative polynomials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07625",
        "HTML": "https://arxiv.org/html/2507.07625v2",
        "PDF": "https://arxiv.org/pdf/2507.07625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with concentration inequalities in random matrices related to neural networks and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08322",
      "abstract": "Quantitative facts are continually generated by companies and governments, supporting data-driven decision-making. While common facts are structured, many long-tail quantitative facts remain buried in unstructured documents, making them difficult to access. We propose the task of Quantity Retrieval: given a description of a quantitative fact, the system returns the relevant value and supporting evidence. Understanding quantity semantics in context is essential for this task. We introduce a framework based on description parsing that converts text into structured (description, quantity) pairs for effective retrieval. To improve learning, we construct a large paraphrase dataset using weak supervision based on quantity co-occurrence. We evaluate our approach on a large corpus of financial annual reports and a newly annotated quantity description dataset. Our method significantly improves top-1 retrieval accuracy from 30.98 percent to 64.66 percent.",
      "authors": [
        "Yixuan Cao",
        "Zhengrong Chen",
        "Chengxuan Xia",
        "Kun Wu",
        "Ping Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:25:09+00:00",
          "link": "https://arxiv.org/abs/2507.08322v1",
          "size": "1246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:02:01+00:00",
          "link": "https://arxiv.org/abs/2507.08322v2",
          "size": "1246kb",
          "version": "v2"
        }
      ],
      "title": "Towards Efficient Quantity Retrieval from Text:An Approach via Description Parsing and Weak Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08322",
        "HTML": "https://arxiv.org/html/2507.08322v2",
        "PDF": "https://arxiv.org/pdf/2507.08322"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on quantity retrieval from text using description parsing and weak supervision, without specific emphasis on LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08860",
      "abstract": "Retention campaigns in customer relationship management often rely on churn prediction models evaluated using traditional metrics such as AUC and F1-score. However, these metrics fail to reflect financial outcomes and may mislead strategic decisions. We introduce e-Profits, a novel business-aligned evaluation metric that quantifies model performance based on customer-specific value, retention probability, and intervention costs. Unlike existing profit-based metrics such as Expected Maximum Profit, which assume fixed population-level parameters, e-Profits uses Kaplan-Meier survival analysis to estimate personalised retention rates and supports granular, per customer evaluation. We benchmark six classifiers across two telecom datasets (IBM Telco and Maven Telecom) and demonstrate that e-Profits reshapes model rankings compared to traditional metrics, revealing financial advantages in models previously overlooked by AUC or F1-score. The metric also enables segment-level insight into which models maximise return on investment for high-value customers. e-Profits is designed as an understandable, post hoc tool to support model evaluation in business contexts, particularly for marketing and analytics teams prioritising profit-driven decisions. All source code is available at: https://github.com/matifq/eprofits.",
      "authors": [
        "Awais Manzoor",
        "M. Atif Qureshi",
        "Etain Kidney",
        "Luca Longo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:22:24+00:00",
          "link": "https://arxiv.org/abs/2507.08860v1",
          "size": "525kb",
          "version": "v1"
        }
      ],
      "title": "e-Profits: A Business-Aligned Evaluation Metric for Profit-Sensitive Customer Churn Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08860",
        "HTML": "https://arxiv.org/html/2507.08860v1",
        "PDF": "https://arxiv.org/pdf/2507.08860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a metric for evaluating churn prediction models, targeting profit rather than any dataset processing or LLM training data engineering efforts."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.20725",
      "abstract": "Gradient Inversion Attacks invert the transmitted gradients in Federated Learning (FL) systems to reconstruct the sensitive data of local clients and have raised considerable privacy concerns. A majority of gradient inversion methods rely heavily on explicit prior knowledge (e.g., a well pre-trained generative model), which is often unavailable in realistic scenarios. This is because real-world client data distributions are often highly heterogeneous, domain-specific, and unavailable to attackers, making it impractical for attackers to obtain perfectly matched pre-trained models, which inevitably suffer from fundamental distribution shifts relative to target private data. To alleviate this issue, researchers have proposed to leverage the implicit prior knowledge of an over-parameterized network. However, they only utilize a fixed neural architecture for all the attack settings. This would hinder the adaptive use of implicit architectural priors and consequently limit the generalizability. In this paper, we further exploit such implicit prior knowledge by proposing Gradient Inversion via Neural Architecture Search (GI-NAS), which adaptively searches the network and captures the implicit priors behind neural architectures. Extensive experiments verify that our proposed GI-NAS can achieve superior attack performance compared to state-of-the-art gradient inversion methods, even under more practical settings with high-resolution images, large-sized batches, and advanced defense strategies. To the best of our knowledge, we are the first to successfully introduce NAS to the gradient inversion community. We believe that this work exposes critical vulnerabilities in real-world federated learning by demonstrating high-fidelity reconstruction of sensitive data without requiring domain-specific priors, forcing urgent reassessment of FL privacy safeguards.",
      "authors": [
        "Wenbo Yu",
        "Hao Fang",
        "Bin Chen",
        "Xiaohang Sui",
        "Chuan Chen",
        "Hao Wu",
        "Shu-Tao Xia",
        "Ke Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-31T09:29:43+00:00",
          "link": "https://arxiv.org/abs/2405.20725v1",
          "size": "10155kb",
          "version": "v1"
        },
        {
          "date": "2024-10-25T09:26:49+00:00",
          "link": "https://arxiv.org/abs/2405.20725v2",
          "size": "4610kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T07:00:01+00:00",
          "link": "https://arxiv.org/abs/2405.20725v3",
          "size": "13081kb",
          "version": "v3"
        }
      ],
      "title": "GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.20725",
        "HTML": "https://arxiv.org/html/2405.20725v3",
        "PDF": "https://arxiv.org/pdf/2405.20725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses gradient inversion attacks in federated learning systems, and although it touches on neural architectures, it does not discuss processing LLM training data."
      },
      "tasks": [
        "Federated Learning",
        "Neural Architecture Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15221",
      "abstract": "Foundation models have achieved remarkable success across various domains, yet their adoption in healthcare remains limited. While significant advances have been made in medical imaging, genetic biomarkers, and time series from electronic health records, the potential of foundation models for patient behavior monitoring through personal digital devices remains underexplored. The data generated by these devices are inherently heterogeneous, multisource, and often exhibit high rates of missing data, posing unique challenges. This paper introduces a novel foundation model based on a modified vector quantized variational autoencoder, specifically designed to process real-world data from smartphones and wearable devices. We leveraged the discrete latent representation of this model to effectively perform two downstream tasks, suicide risk assessment and emotional state prediction, on different held-out clinical cohorts without the need of fine-tuning. We also highlight the existence of a trade-off between discrete and continuous latent structures, suggesting that hybrid models may be optimal for balancing accuracy across various supervised and unsupervised tasks.",
      "authors": [
        "Rodrigo Oliver",
        "Josu\\'e P\\'erez-Sabater",
        "Leire Paz-Arbaizar",
        "Diego Herrero-Quevedo",
        "Antonio Art\\'es-Rodr\\'iguez",
        "Alejandro Lancho",
        "Pablo M. Olmos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T14:01:16+00:00",
          "link": "https://arxiv.org/abs/2503.15221v1",
          "size": "11798kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:43:18+00:00",
          "link": "https://arxiv.org/abs/2503.15221v2",
          "size": "7152kb",
          "version": "v2"
        }
      ],
      "title": "A Vector-Quantized Foundation Model for Patient Behavior Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15221",
        "HTML": "https://arxiv.org/html/2503.15221v2",
        "PDF": "https://arxiv.org/pdf/2503.15221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a foundation model for patient behavior monitoring using data from digital devices. It discusses model architecture and heterogeneous data processing specific to the application domain, but not training data processing for LLMs."
      },
      "tasks": [
        "Change Point Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06509",
      "abstract": "Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.\n  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of representative instances and maps the other given locations to the representative ones, we prove that there exists a strategyproof mechanism achieving a bounded consistency guarantee of $\\frac{\\sqrt{(1+c)^2W^2_{\\min}+(1-c)^2W^2_{\\max}}}{(1+c)W_{\\min}}$ and a bounded robustness guarantee of $\\frac{\\sqrt{(1-c)^2W^2_{\\min}+(1+c)^2W^2_{\\max}}}{(1-c)W_{\\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\\min}$ and $W_{\\max}$ denote the minimum and maximum agents' weight. We also prove that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\\left( n \\cdot \\frac{W_{\\max}}{W_{\\min}} \\right)$-robustness in weighted FLP, even with fully predictions of all agents.",
      "authors": [
        "Yangguang Shi",
        "Zhenyu Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:13:52+00:00",
          "link": "https://arxiv.org/abs/2507.06509v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:52:39+00:00",
          "link": "https://arxiv.org/abs/2507.06509v2",
          "size": "18kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T12:35:18+00:00",
          "link": "https://arxiv.org/abs/2507.06509v3",
          "size": "18kb",
          "version": "v3"
        }
      ],
      "title": "Prediction-Augmented Mechanism Design for Weighted Facility Location",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06509",
        "HTML": "https://arxiv.org/html/2507.06509v3",
        "PDF": "https://arxiv.org/pdf/2507.06509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses prediction-augmented mechanisms for facility location, focusing on algorithmic game theory, with no mention of LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09732",
      "abstract": "Habitats integrate the abiotic conditions and biophysical structures that support biodiversity and sustain nature's contributions to people. As these ecosystems face mounting pressure from human activities, accurate, high-resolution habitat maps are essential for effective conservation and restoration. Yet current maps often fall short in thematic or spatial resolution because they must (1) model several mutually exclusive habitat types that co-occur across landscapes and (2) cope with severe class imbalance that complicate multi-class training. Here, we evaluated how high-resolution remote sensing (RS) data and Artificial Intelligence (AI) tools can improve habitat classification over large geographic extents at fine thematic resolution. Using vegetation plots from the European Vegetation Archive, we modelled Level 3 EUNIS habitats across Europe and assessed multiple modelling strategies against independent validation datasets. Strategies that exploited the hierarchical nature of habitat nomenclatures resolved classification ambiguities, especially in fragmented landscapes. Integrating multi-spectral (MSI) and synthetic aperture radar (SAR) imagery, particularly through Earth Observation Foundation models, enhanced within-formation discrimination and overall performance. Finally, ensemble machine learning that corrects class imbalance boosted accuracy further. Our methodological framework is transferable beyond Europe and adaptable to other classification systems. Future research should advance temporal modelling of dynamic habitats, extend to habitat segmentation and quality assessment, and exploit next-generation EO data paired with higher-quality in-situ observations.",
      "authors": [
        "Sara Si-Moussi",
        "Stephan Hennekens",
        "Sander Mucher",
        "Stan Los",
        "Wilfried Thuiller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Populations and Evolution (q-bio.PE)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:11:26+00:00",
          "link": "https://arxiv.org/abs/2507.09732v1",
          "size": "1515kb",
          "version": "v1"
        }
      ],
      "title": "Continental scale habitat modelling with artificial intelligence and multimodal earth observation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09732",
        "PDF": "https://arxiv.org/pdf/2507.09732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on habitat modeling using AI and remote sensing data, rather than LLM training data processing. It addresses habitat classification and ecosystem mapping without discussing LLM training data preprocessing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.07344",
      "abstract": "Recurrent Neural Networks (RNNs) have revolutionized many areas of machine learning, particularly in natural language and data sequence processing. Long Short-Term Memory (LSTM) has demonstrated its ability to capture long-term dependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks (KANs) a promising alternatives to Multi-Layer Perceptrons (MLPs), we proposed a new neural networks architecture inspired by KAN and the LSTM, the Temporal Kolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of both networks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layers embedding memory management. This innovation enables us to perform multi-step time series forecasting with enhanced accuracy and efficiency. By addressing the limitations of traditional models in handling complex sequential patterns, the TKAN architecture offers significant potential for advancements in fields requiring more than one step ahead forecasting.",
      "authors": [
        "Remi Genet and Hugo Inzirillo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-12T17:40:48+00:00",
          "link": "https://arxiv.org/abs/2405.07344v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2024-06-05T16:46:11+00:00",
          "link": "https://arxiv.org/abs/2405.07344v2",
          "size": "800kb",
          "version": "v2"
        },
        {
          "date": "2024-12-17T17:13:03+00:00",
          "link": "https://arxiv.org/abs/2405.07344v3",
          "size": "826kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T14:09:59+00:00",
          "link": "https://arxiv.org/abs/2405.07344v4",
          "size": "831kb",
          "version": "v4"
        }
      ],
      "title": "TKAN: Temporal Kolmogorov-Arnold Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.07344",
        "HTML": "https://arxiv.org/html/2405.07344v4",
        "PDF": "https://arxiv.org/pdf/2405.07344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new neural network architecture for time series forecasting and does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Kolmogorov-Arnold Networks",
        "Management",
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/remigenet/tkan",
        "https://github.com/remigenet/TKAT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.04977",
      "abstract": "As deploying large amounts of monitoring equipment results in elevated cost and power consumption, novel low-cost monitoring methods are being continuously investigated. A new technique called Power Profile Monitoring (PPM) has recently gained traction thanks to its ability to monitor an entire lightpath using a single post-processing unit at the lightpath receiver. PPM does not require to deploy an individual monitor for each span, as in the traditional monitoring technique using Optical Time-Domain Reflectometer (OTDR). In this work, we aim to quantify the cost and power consumption of PPM (using OTDR as a baseline reference), as this analysis can provide guidelines for the implementation and deployment of PPM. First, we discuss how PPM and OTDR monitors are deployed, and we formally state a new Optimized Monitoring Placement (OMP) problem for PPM. Solving the OMP problem allows to identify the minimum number of PPM monitors that guarantees that all links in the networks are monitored by at least $n$ PPM monitors (note that using $n>1$ allows for increased monitoring accuracy). We prove the NP-hardness of the OMP problem and formulate it using an Integer Linear Programming (ILP) model. Finally, we also devise a heuristic algorithm for the OMP problem to scale to larger topologies. Our numerical results, obtained on realistic topologies, suggest that the cost (and power) of one PPM module should be lower than 2.6 times that of one OTDR for nation-wide and 10.2 times for continental-wide topology.",
      "authors": [
        "Qiaolun Zhang",
        "Patricia Layec",
        "Alix May",
        "Annalisa Morea",
        "Aryanaz Attarpour",
        "Massimo Tornatore"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-06T07:03:06+00:00",
          "link": "https://arxiv.org/abs/2407.04977v1",
          "size": "305kb",
          "version": "v1"
        },
        {
          "date": "2024-07-17T15:04:05+00:00",
          "link": "https://arxiv.org/abs/2407.04977v2",
          "size": "305kb",
          "version": "v2"
        },
        {
          "date": "2024-08-24T10:50:16+00:00",
          "link": "https://arxiv.org/abs/2407.04977v3",
          "size": "8166kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T12:22:59+00:00",
          "link": "https://arxiv.org/abs/2407.04977v4",
          "size": "346kb",
          "version": "v4"
        }
      ],
      "title": "Cost and Power-Consumption Analysis for Power Profile Monitoring with Multiple Monitors per Link in Optical Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.04977",
        "HTML": "https://arxiv.org/html/2407.04977v4",
        "PDF": "https://arxiv.org/pdf/2407.04977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes monitoring strategies for optical networks, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.09202",
      "abstract": "This work presents HotSwap, a novel provider-side cold-start optimization for serverless computing. This optimization reduces cold-start time when booting and loading dependencies at runtime inside a function container. Previous research has extensively focused on reducing cold-start latency for specific functions. However, little attention has been given to skewed production workloads. In such cases, cross-function optimization becomes essential. Without cross-function optimization, a cloud provider is left with two equally poor options: (i) Either the cloud provider gives up optimization for each function in the long tail (which is slow); or (ii) the cloud provider applies function-specific optimizations (e.g., cache function images) to every function in the long tail (which violates the vendor's cache constraints). HotSwap demonstrates cross-function optimization using a novel pre-warming strategy. In this strategy, a pre-initialized live dependency image is migrated to the new function instance. At the same time, HotSwap respects the provider's cache constraints, because a single pre-warmed dependency image in the cache can be shared among all serverless functions that require that image. HotSwap has been tested on seven representative functions from FunctionBench. In those tests, HotSwap accelerates dependency loading for those serverless functions with large dependency requirements by a factor ranging from 2.2 to 3.2. Simulation experiments using Azure traces indicate that HotSwap can save 88\\% of space, compared with a previous function-specific method, PreBaking, when sharing a dependency image among ten different functions.",
      "authors": [
        "Rui Li",
        "Devesh Tiwari",
        "and Gene Cooperman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T21:31:45+00:00",
          "link": "https://arxiv.org/abs/2409.09202v1",
          "size": "566kb",
          "version": "v1"
        },
        {
          "date": "2024-10-21T02:35:08+00:00",
          "link": "https://arxiv.org/abs/2409.09202v2",
          "size": "568kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T19:57:51+00:00",
          "link": "https://arxiv.org/abs/2409.09202v3",
          "size": "564kb",
          "version": "v3"
        }
      ],
      "title": "HotSwap: Enabling Live Dependency Sharing in Serverless Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09202",
        "HTML": "https://arxiv.org/html/2409.09202v3",
        "PDF": "https://arxiv.org/pdf/2409.09202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing serverless computing with the HotSwap method for dependency sharing, unrelated to LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19305",
      "abstract": "Computing channel capacity is in general intractable because it is given by the limit of a sequence of optimization problems whose dimensionality grows to infinity. As a result, constant-sized characterizations of feedback or non-feedback capacity are known for only a few classes of channels with memory. This paper introduces poset-causal channels$\\unicode{x2014}$a new formalism of a communication channel in which channel inputs and outputs are indexed by the elements of a partially ordered set (poset). We develop a novel methodology that allows us to establish a single-letter upper bound on the feedback capacity of a subclass of poset-causal channels whose memory structure exhibits a Markov property and symmetry. The methodology is based on symmetry reduction in optimization. We instantiate our method on two channel models: the Noisy Output is The STate (NOST) channel$\\unicode{x2014}$for which the bound is tight$\\unicode{x2014}$and a new two-dimensional extension of it.",
      "authors": [
        "Eray Unsal Atay",
        "Eitan Levin",
        "Venkat Chandrasekaran",
        "Victoria Kostina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T04:40:15+00:00",
          "link": "https://arxiv.org/abs/2506.19305v1",
          "size": "224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T01:41:52+00:00",
          "link": "https://arxiv.org/abs/2506.19305v2",
          "size": "110kb",
          "version": "v2"
        }
      ],
      "title": "Poset-Markov Channels: Capacity via Group Symmetry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19305",
        "HTML": "https://arxiv.org/html/2506.19305v2",
        "PDF": "https://arxiv.org/pdf/2506.19305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new formalism of communication channels and focuses on establishing a bound on feedback capacity, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08870",
      "abstract": "The field of AI research is advancing at an unprecedented pace, enabling automated hypothesis generation and experimental design across diverse domains such as biology, mathematics, and artificial intelligence. Despite these advancements, there remains a significant gap in the availability of scalable advising systems capable of providing high-quality, well-reasoned feedback to refine proposed hypotheses and experimental designs. To address this challenge, we explore key factors that underlie the development of robust advising systems, including model size, context length, confidence estimation, and structured reasoning processes. Our findings reveal that a relatively small model, when equipped with a well-compressed literature database and a structured reasoning framework, can outperform powerful general-purpose language models such as Deepseek-R1 in terms of acceptance rates for self-ranked top-30% submissions to ICLR 2025. Moreover, when limited to high-confidence predictions, our system achieves an acceptance rate exceeding 90% on the ICLR 2025 test set, underscoring its potential to significantly enhance the quality and efficiency of hypothesis generation and experimental design. The code is released at https://github.com/HowardLiu0830/GUIDE-Research-Idea-Evaluation.",
      "authors": [
        "Yaowenqi Liu",
        "BingXu Meng",
        "Rui Pan",
        "Jerry Huang",
        "Tong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:59:21+00:00",
          "link": "https://arxiv.org/abs/2507.08870v1",
          "size": "1515kb",
          "version": "v1"
        }
      ],
      "title": "GUIDE: Towards Scalable Advising for Research Ideas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08870",
        "HTML": "https://arxiv.org/html/2507.08870v1",
        "PDF": "https://arxiv.org/pdf/2507.08870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops advising systems for research idea evaluation with no mention of processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09202",
      "abstract": "Recent advancements in Artificial Intelligence (AI) demonstrate significant potential to revolutionize weather forecasting. However, most AI-driven models rely on Numerical Weather Prediction (NWP) systems for initial condition preparation, which often consumes hours on supercomputers. Here we introduce XiChen, the first observation-scalable fully AI-driven global weather forecasting system, whose entire pipeline, from Data Assimilation (DA) to medium-range forecasting, can be accomplished within only 17 seconds. XiChen is built upon a foundation model that is pre-trained for weather forecasting. Meanwhile, this model is subsequently fine-tuned to serve as both observation operators and DA models, thereby scalably assimilating conventional and raw satellite observations. Furthermore, the integration of four-dimensional variational knowledge ensures that XiChen's DA and medium-range forecasting accuracy rivals that of operational NWP systems, amazingly achieving a skillful forecasting lead time exceeding 8.25 days. These findings demonstrate that XiChen holds strong potential toward fully AI-driven weather forecasting independent of NWP systems.",
      "authors": [
        "Wuxin Wang",
        "Weicheng Ni",
        "Lilan Huang",
        "Tao Hao",
        "Ben Fei",
        "Shuo Ma",
        "Taikang Yuan",
        "Yanlai Zhao",
        "Kefeng Deng",
        "Xiaoyong Li",
        "Boheng Duan",
        "Lei Bai",
        "Kaijun Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.09202v1",
          "size": "11617kb",
          "version": "v1"
        }
      ],
      "title": "XiChen: An observation-scalable fully AI-driven global weather forecasting system with 4D variational knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09202",
        "HTML": "https://arxiv.org/html/2507.09202v1",
        "PDF": "https://arxiv.org/pdf/2507.09202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel weather forecasting system using LLMs and fine-tuning but primarily focuses on the forecasting system rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09330",
      "abstract": "Accurate representation of wells is essential for reliable reservoir characterization and simulation of operational scenarios in subsurface flow models. Physics-informed neural networks (PINNs) have recently emerged as a promising method for reservoir modeling, offering seamless integration of monitoring data and governing physical equations. However, existing PINN-based studies face major challenges in capturing fluid pressure near wells, particularly during the early stage after injection begins. To address this, we propose WellPINN, a modeling workflow that combines the outputs of multiple sequentially trained PINN models to accurately represent wells. This workflow iteratively approximates the radius of the equivalent well to match the actual well dimensions by decomposing the domain into stepwise shrinking subdomains with a simultaneously reducing equivalent well radius. Our results demonstrate that sequential training of superimposing networks around the pumping well is the first workflow that focuses on accurate inference of fluid pressure from pumping rates throughout the entire injection period, significantly advancing the potential of PINNs for inverse modeling and operational scenario simulations. All data and code for this paper will be made openly available at https://github.com/linuswalter/WellPINN.",
      "authors": [
        "Linus Walter (1 and 2)",
        "Qingkai Kong (3)",
        "Sara Hanson-Hedgecock (1)",
        "V\\'ictor Vilarrasa (1) ((1) Global Change Research Group (GCRG)",
        "IMEDEA",
        "CSIC-UIB",
        "Spain",
        "(2) Department of Civil and Environmental Engineering (DECA)",
        "Universitat Polit\\`ecnica de Catalunya - BarcelonaTech (UPC)",
        "Barcelona",
        "Spain",
        "(3) Lawrence Livermore National Laboratory",
        "Livermore",
        "USA)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:14:03+00:00",
          "link": "https://arxiv.org/abs/2507.09330v1",
          "size": "10360kb",
          "version": "v1"
        }
      ],
      "title": "WellPINN: Accurate Well Representation for Transient Fluid Pressure Diffusion in Subsurface Reservoirs with Physics-Informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09330",
        "PDF": "https://arxiv.org/pdf/2507.09330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on using Physics-Informed Neural Networks (PINNs) for well representation in reservoir models, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09391",
      "abstract": "Generative modeling of graphs with spatial structure is essential across many applications from computer graphics to spatial genomics. Recent flow-based generative models have achieved impressive results by gradually adding and then learning to remove noise from these graphs. Existing models, however, use graph neural network architectures that are independent of the noise level, limiting their expressiveness. To address this issue, we introduce \\textit{Noise-Conditioned Graph Networks} (NCGNs), a class of graph neural networks that dynamically modify their architecture according to the noise level during generation. Our theoretical and empirical analysis reveals that as noise increases, (1) graphs require information from increasingly distant neighbors and (2) graphs can be effectively represented at lower resolutions. Based on these insights, we develop Dynamic Message Passing (DMP), a specific instantiation of NCGNs that adapts both the range and resolution of message passing to the noise level. DMP consistently outperforms noise-independent architectures on a variety of domains including $3$D point clouds, spatiotemporal transcriptomics, and images. Code is available at https://github.com/peterpaohuang/ncgn.",
      "authors": [
        "Peter Pao-Huang",
        "Mitchell Black",
        "Xiaojie Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:19:05+00:00",
          "link": "https://arxiv.org/abs/2507.09391v1",
          "size": "1587kb",
          "version": "v1"
        }
      ],
      "title": "Geometric Generative Modeling with Noise-Conditioned Graph Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09391",
        "HTML": "https://arxiv.org/html/2507.09391v1",
        "PDF": "https://arxiv.org/pdf/2507.09391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generative modeling of graphs, with no mention of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10139",
      "abstract": "Learning and constructing large-scale graphs has attracted attention in recent decades, resulting in a rich literature that introduced various systems, tools, and algorithms. Grale is one of such tools that is designed for offline environments and is deployed in more than 50 different industrial settings at Google. Grale is widely applicable because of its ability to efficiently learn and construct a graph on datasets with multiple types of features. However, it is often the case that applications require the underlying data to evolve continuously and rapidly and the updated graph needs to be available with low latency. Such setting make the use of Grale prohibitive. While there are Approximate Nearest Neighbor (ANN) systems that handle dynamic updates with low latency, they are mostly limited to similarities over a single embedding.\n  In this work, we introduce a system that inherits the advantages and the quality of Grale, and maintains a graph construction in a dynamic setting with tens of milliseconds of latency per request. We call the system Dynamic Grale Using ScaNN (Dynamic GUS). Our system has a wide range of applications with over 10 deployments at Google. One of the applications is in Android Security and Privacy, where Dynamic Grale Using ScaNN enables capturing harmful applications 4 times faster, before they can reach users.",
      "authors": [
        "Filipe Miguel Gon\\c{c}alves de Almeida",
        "CJ Carey",
        "Hendrik Fichtenberger",
        "Jonathan Halcrow",
        "Silvio Lattanzi",
        "Andr\\'e Linhares",
        "Tao Meng",
        "Ashkan Norouzi-Fard",
        "Nikos Parotsidis",
        "Bryan Perozzi",
        "and David Simcha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.10139v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "Large-Scale Graph Building in Dynamic Environments: Low Latency and High Quality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10139",
        "HTML": "https://arxiv.org/html/2507.10139v1",
        "PDF": "https://arxiv.org/pdf/2507.10139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a system for graph construction in dynamic environments. Although it mentions data handling, it does not deal specifically with LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.08073",
      "abstract": "Bregman proximal-type algorithms (BPs), such as mirror descent, have become popular tools in machine learning and data science for exploiting problem structures through non-Euclidean geometries. In this paper, we show that BPs can get trapped near a class of non-stationary points, which we term spurious stationary points. Such stagnation can persist for any finite number of iterations if the gradient of the Bregman kernel is not Lipschitz continuous, even in convex problems. The root cause lies in a fundamental contrast in descent behavior between Euclidean and Bregman geometries: While Euclidean gradient descent ensures sufficient decrease near any non-stationary point, BPs may exhibit arbitrarily slow decrease around spurious stationary points. As a result, commonly used Bregman-based stationarity measure, such as relative change in terms of Bregman divergence, can vanish near spurious stationary points. This may misleadingly suggest convergence, even when the iterates remain far from any true stationary point. Our analysis further reveals that spurious stationary points are not pathological, but rather occur generically in a broad class of nonconvex problems with polyhedral constraints. Taken together, our findings reveal a serious blind spot in Bregman-based optimization methods and calls for new theoretical tools and algorithmic safeguards to ensure reliable convergence.",
      "authors": [
        "He Chen",
        "Jiajin Li",
        "Anthony Man-Cho So"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-11T18:28:01+00:00",
          "link": "https://arxiv.org/abs/2404.08073v1",
          "size": "84kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T00:46:09+00:00",
          "link": "https://arxiv.org/abs/2404.08073v2",
          "size": "271kb",
          "version": "v2"
        }
      ],
      "title": "Spurious Stationarity and Hardness Results for Bregman Proximal-Type Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.08073",
        "HTML": "https://arxiv.org/html/2404.08073v2",
        "PDF": "https://arxiv.org/pdf/2404.08073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Bregman proximal-type algorithms and optimization challenges, without relevance to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.18209",
      "abstract": "This paper studies a family of estimators based on noise-contrastive estimation (NCE) for learning unnormalized distributions. The main contribution of this work is to provide a unified perspective on various methods for learning unnormalized distributions, which have been independently proposed and studied in separate research communities, through the lens of NCE. This unified view offers new insights into existing estimators. Specifically, for exponential families, we establish the finite-sample convergence rates of the proposed estimators under a set of regularity assumptions, most of which are new.",
      "authors": [
        "J. Jon Ryu",
        "Abhin Shah",
        "Gregory W. Wornell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T18:41:19+00:00",
          "link": "https://arxiv.org/abs/2409.18209v1",
          "size": "39kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:36:23+00:00",
          "link": "https://arxiv.org/abs/2409.18209v2",
          "size": "269kb",
          "version": "v2"
        }
      ],
      "title": "A Unified View on Learning Unnormalized Distributions via Noise-Contrastive Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18209",
        "HTML": "https://arxiv.org/html/2409.18209v2",
        "PDF": "https://arxiv.org/pdf/2409.18209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a unified view on learning unnormalized distributions via noise-contrastive estimation, unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.03529",
      "abstract": "Variational quantum algorithms (VQA) based on Hamiltonian simulation represent a specialized class of quantum programs well-suited for near-term quantum computing applications due to its modest resource requirements in terms of qubits and circuit depth. Unlike the conventional single-qubit (1Q) and two-qubit (2Q) gate sequence representation, Hamiltonian simulation programs are essentially composed of disciplined subroutines known as Pauli exponentiations (Pauli strings with coefficients) that are variably arranged. To capitalize on these distinct program features, this study introduces PHOENIX, a highly effective compilation framework that primarily operates at the high-level Pauli-based intermediate representation (IR) for generic Hamiltonian simulation programs. PHOENIX exploits global program optimization opportunities to the greatest extent, compared to existing SOTA methods despite some of them also utilizing similar IRs. Experimental results demonstrate that PHOENIX outperforms SOTA VQA compilers across diverse program categories, backend ISAs, and hardware topologies.",
      "authors": [
        "Zhaohui Yang",
        "Dawei Ding",
        "Chenghong Zhu",
        "Jianxin Chen",
        "Yuan Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Hardware Architecture (cs.AR)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T15:29:18+00:00",
          "link": "https://arxiv.org/abs/2504.03529v1",
          "size": "651kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T05:44:59+00:00",
          "link": "https://arxiv.org/abs/2504.03529v2",
          "size": "662kb",
          "version": "v2"
        },
        {
          "date": "2025-05-12T11:50:44+00:00",
          "link": "https://arxiv.org/abs/2504.03529v3",
          "size": "669kb",
          "version": "v3"
        },
        {
          "date": "2025-06-14T08:48:42+00:00",
          "link": "https://arxiv.org/abs/2504.03529v4",
          "size": "134kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T04:26:35+00:00",
          "link": "https://arxiv.org/abs/2504.03529v5",
          "size": "594kb",
          "version": "v5"
        }
      ],
      "title": "PHOENIX: Pauli-Based High-Level Optimization Engine for Instruction Execution on NISQ Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03529",
        "HTML": "https://arxiv.org/html/2504.03529v5",
        "PDF": "https://arxiv.org/pdf/2504.03529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses high-level optimization for quantum algorithm execution and does not involve LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/iqubit-org/phoenix"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08307",
      "abstract": "Audio-driven talking head generation holds significant potential for film production. While existing 3D methods have advanced motion modeling and content synthesis, they often produce rendering artifacts, such as motion blur, temporal jitter, and local penetration, due to limitations in representing stable, fine-grained motion fields. Through systematic analysis, we reformulate talking head generation into a unified framework comprising three steps: video preprocessing, motion representation, and rendering reconstruction. This framework underpins our proposed M2DAO-Talker, which addresses current limitations via multi-granular motion decoupling and alternating optimization. Specifically, we devise a novel 2D portrait preprocessing pipeline to extract frame-wise deformation control conditions (motion region segmentation masks, and camera parameters) to facilitate motion representation. To ameliorate motion modeling, we elaborate a multi-granular motion decoupling strategy, which independently models non-rigid (oral and facial) and rigid (head) motions for improved reconstruction accuracy. Meanwhile, a motion consistency constraint is developed to ensure head-torso kinematic consistency, thereby mitigating penetration artifacts caused by motion aliasing. In addition, an alternating optimization strategy is designed to iteratively refine facial and oral motion parameters, enabling more realistic video generation. Experiments across multiple datasets show that M2DAO-Talker achieves state-of-the-art performance, with the 2.43 dB PSNR improvement in generation quality and 0.64 gain in user-evaluated video realness versus TalkingGaussian while with 150 FPS inference speed. Our project homepage is https://m2dao-talker.github.io/M2DAO-Talk.github.io.",
      "authors": [
        "Kui Jiang",
        "Shiyu Liu",
        "Junjun Jiang",
        "Xin Yang",
        "Hongxun Yao and Xiaopeng Fan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:48:12+00:00",
          "link": "https://arxiv.org/abs/2507.08307v1",
          "size": "8214kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T10:16:32+00:00",
          "link": "https://arxiv.org/abs/2507.08307v2",
          "size": "14227kb",
          "version": "v2"
        }
      ],
      "title": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08307",
        "HTML": "https://arxiv.org/html/2507.08307v2",
        "PDF": "https://arxiv.org/pdf/2507.08307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents advancements in talking-head generation methods, focusing on motion decoupling and optimization strategies. It does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09699",
      "abstract": "As the use of differential privacy (DP) becomes widespread, the development of effective tools for reasoning about the privacy guarantee becomes increasingly critical. In pursuit of this goal, we demonstrate novel relationships between DP and measures of statistical disclosure risk. We suggest how experts and non-experts can use these results to explain the DP guarantee, interpret DP composition theorems, select and justify privacy parameters, and identify worst-case adversary prior probabilities.",
      "authors": [
        "Zeki Kazan",
        "Sagar Sharma",
        "Wanrong Zhang",
        "Bo Jiang",
        "Qiang Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:20:13+00:00",
          "link": "https://arxiv.org/abs/2507.09699v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "Interpreting Differential Privacy in Terms of Disclosure Risk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09699",
        "HTML": "https://arxiv.org/html/2507.09699v1",
        "PDF": "https://arxiv.org/pdf/2507.09699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interpreting differential privacy in terms of disclosure risk, which does not relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10119",
      "abstract": "Application migration in edge-cloud system enables high QoS and cost effective service delivery. However, automatically orchestrating such migration is typically solved with heuristic approaches. Starting from the Markov Decision Process (MDP), in this paper, we identify, analyze and compare selected state-of-the-art Artificial Intelligence (AI) planning and Reinforcement Learning (RL) approaches for solving the class of edge-cloud application migration problems that can be modeled as Towers of Hanoi (ToH) problems. We introduce a new classification based on state space definition and analyze the compared models also through this lense. The aim is to understand available techniques capable of orchestrating such application migration in emerging computing continuum environments.",
      "authors": [
        "Sadig Gojayev",
        "Ahmad Anaqreh",
        "Carolina Fortuna"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:03:23+00:00",
          "link": "https://arxiv.org/abs/2507.10119v1",
          "size": "79kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of AI Techniques for Orchestrating Edge-Cloud Application Migration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10119",
        "HTML": "https://arxiv.org/html/2507.10119v1",
        "PDF": "https://arxiv.org/pdf/2507.10119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores AI techniques for orchestrating edge-cloud application migration, without contributing to the field of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10233",
      "abstract": "Quantum digital signatures ensure unforgeable message authenticity and integrity using quantum principles, offering unconditional security against both classical and quantum attacks. They are crucial for secure communication in high-stakes environments, ensuring trust and long-term protection in the quantum era. Nowadays, the majority of arbitrated quantum signature (AQS) protocols encrypt data qubit by qubit using the quantum one-time pad (QOTP). Despite providing robust data encryption, QOTP is not a good fit for AQS because of its susceptibility to many types of attacks. In this work, we present an efficient AQS protocol to encrypt quantum message ensembles using a distinct encryption technique, the chained controlled unitary operations. In contrast to existing protocols, our approach successfully prevents disavowal and forgery attacks. We hope this contributes to advancing future investigations into the development of AQS protocols.",
      "authors": [
        "Debnath Ghosh",
        "Soumit Roy",
        "Prithwi Bagchi",
        "Indranil Chakrabarty",
        "Ashok Kumar Das"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:56:09+00:00",
          "link": "https://arxiv.org/abs/2507.10233v1",
          "size": "872kb",
          "version": "v1"
        }
      ],
      "title": "Secure and Efficient Quantum Signature Scheme Based on the Controlled Unitary Operations Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10233",
        "HTML": "https://arxiv.org/html/2507.10233v1",
        "PDF": "https://arxiv.org/pdf/2507.10233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum signature schemes and encryption methods, with no relevance to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.10552",
      "abstract": "Topological data analysis (TDA) is a tool from data science and mathematics that is beginning to make waves in environmental science. In this work, we seek to provide an intuitive and understandable introduction to a tool from TDA that is particularly useful for the analysis of imagery, namely persistent homology. We briefly discuss the theoretical background but focus primarily on understanding the output of this tool and discussing what information it can glean. To this end, we frame our discussion around a guiding example of classifying satellite images from the Sugar, Fish, Flower, and Gravel Dataset produced for the study of mesocale organization of clouds by Rasp et. al. in 2020 (arXiv:1906:01906). We demonstrate how persistent homology and its vectorization, persistence landscapes, can be used in a workflow with a simple machine learning algorithm to obtain good results, and explore in detail how we can explain this behavior in terms of image-level features. One of the core strengths of persistent homology is how interpretable it can be, so throughout this paper we discuss not just the patterns we find, but why those results are to be expected given what we know about the theory of persistent homology. Our goal is that a reader of this paper will leave with a better understanding of TDA and persistent homology, be able to identify problems and datasets of their own for which persistent homology could be helpful, and gain an understanding of results they obtain from applying the included GitHub example code.",
      "authors": [
        "Lander Ver Hoef and Henry Adams and Emily J. King and Imme Ebert-Uphoff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "General Topology (math.GN)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-21T15:51:01+00:00",
          "link": "https://arxiv.org/abs/2207.10552v1",
          "size": "5600kb",
          "version": "v1"
        }
      ],
      "title": "A Primer on Topological Data Analysis to Support Image Analysis Tasks in Environmental Science",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.10552",
        "PDF": "https://arxiv.org/pdf/2207.10552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using topological data analysis for image analysis tasks in environmental science, and does not discuss LLM training data processing."
      },
      "tasks": [
        "Topological Data Analysis"
      ],
      "repo_urls": [
        "https://github.com/zyjux/sffg_tda"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.04124",
      "abstract": "With the recent advancements in machine learning (ML), numerous ML-based approaches have been extensively applied in software analytics tasks to streamline software development and maintenance processes. Nevertheless, studies indicate that despite their potential usefulness, ML models are vulnerable to adversarial attacks, which may result in significant monetary losses in these processes. As a result, the ML models' robustness against adversarial attacks must be assessed before they are deployed in software analytics tasks. Despite several techniques being available for adversarial attacks in software analytics tasks, exploring adversarial attacks using ML explainability is largely unexplored. Therefore, this study aims to investigate the relationship between ML explainability and adversarial attacks to measure the robustness of ML models in software analytics tasks. In addition, unlike most existing attacks that directly perturb input-space, our attack approach focuses on perturbing feature-space. Our extensive experiments, involving six datasets, three ML explainability techniques, and seven ML models, demonstrate that ML explainability can be used to conduct successful adversarial attacks on ML models in software analytics tasks. This is achieved by modifying only the top 1-3 important features identified by ML explainability techniques. Consequently, the ML models under attack fail to accurately predict up to 86.6% of instances that were correctly predicted before adversarial attacks, indicating the models' low robustness against such attacks. Finally, our proposed technique demonstrates promising results compared to four state-of-the-art adversarial attack techniques targeting tabular data.",
      "authors": [
        "MD Abdul Awal",
        "Mrigank Rochan",
        "and Chanchal K. Roy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-07T23:21:55+00:00",
          "link": "https://arxiv.org/abs/2408.04124v1",
          "size": "1296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:53:05+00:00",
          "link": "https://arxiv.org/abs/2408.04124v2",
          "size": "579kb",
          "version": "v2"
        }
      ],
      "title": "Investigating Adversarial Attacks in Software Analytics via Machine Learning Explainability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04124",
        "HTML": "https://arxiv.org/html/2408.04124v2",
        "PDF": "https://arxiv.org/pdf/2408.04124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates adversarial attacks on ML models in software analytics, with no focus on LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15438",
      "abstract": "Vision-based occupancy networks (VONs) provide an end-to-end solution for reconstructing 3D environments in autonomous driving. However, existing methods often suffer from temporal inconsistencies, manifesting as flickering effects that compromise visual experience and adversely affect decision-making. While recent approaches have incorporated historical data to mitigate the issue, they often incur high computational costs and may introduce noisy information that interferes with object detection. We propose OccLinker, a novel plugin framework designed to seamlessly integrate with existing VONs for boosting performance. Our method efficiently consolidates historical static and motion cues, learns sparse latent correlations with current features through a dual cross-attention mechanism, and produces correction occupancy components to refine the base network's predictions. We propose a new temporal consistency metric to quantitatively identify flickering effects. Extensive experiments on two benchmark datasets demonstrate that our method delivers superior performance with negligible computational overhead, while effectively eliminating flickering artifacts.",
      "authors": [
        "Fengcheng Yu",
        "Haoran Xu",
        "Canming Xia",
        "Ziyang Zong",
        "Guang Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T13:07:45+00:00",
          "link": "https://arxiv.org/abs/2502.15438v1",
          "size": "35502kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T13:57:27+00:00",
          "link": "https://arxiv.org/abs/2502.15438v2",
          "size": "5085kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T06:03:23+00:00",
          "link": "https://arxiv.org/abs/2502.15438v3",
          "size": "4532kb",
          "version": "v3"
        }
      ],
      "title": "Deflickering Vision-Based Occupancy Networks through Lightweight Spatio-Temporal Correlation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15438",
        "HTML": "https://arxiv.org/html/2502.15438v3",
        "PDF": "https://arxiv.org/pdf/2502.15438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on improving temporal consistency in vision-based occupancy networks, with no reference to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.11393",
      "abstract": "Because large language models are expensive to pretrain on different datasets, using smaller-scale experiments to decide on data is crucial for reducing costs. Which benchmarks and methods of making decisions from observed performance at small scale most accurately predict the datasets that yield the best large models? To empower open exploration of this question, we release models, data, and evaluations in DataDecide -- the most extensive open suite of models over differences in data and scale. We conduct controlled pretraining experiments across 25 corpora with differing sources, deduplication, and filtering up to 100B tokens, model sizes up to 1B parameters, and 3 random seeds. We find that the ranking of models at a single, small size (e.g., 150M parameters) is a strong baseline for predicting best models at our larger target scale (1B) (~80% of com parisons correct). No scaling law methods among 8 baselines exceed the compute-decision frontier of single-scale predictions, but DataDecide can measure improvement in future scaling laws. We also identify that using continuous likelihood metrics as proxies in small experiments makes benchmarks including MMLU, ARC, HellaSwag, MBPP, and HumanEval >80% predictable at the target 1B scale with just 0.01% of the compute.",
      "authors": [
        "Ian Magnusson",
        "Nguyen Tai",
        "Ben Bogin",
        "David Heineman",
        "Jena D. Hwang",
        "Luca Soldaini",
        "Akshita Bhagia",
        "Jiacheng Liu",
        "Dirk Groeneveld",
        "Oyvind Tafjord",
        "Noah A. Smith",
        "Pang Wei Koh",
        "Jesse Dodge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T17:02:15+00:00",
          "link": "https://arxiv.org/abs/2504.11393v1",
          "size": "1300kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T20:17:49+00:00",
          "link": "https://arxiv.org/abs/2504.11393v2",
          "size": "857kb",
          "version": "v2"
        }
      ],
      "title": "DataDecide: How to Predict Best Pretraining Data with Small Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11393",
        "HTML": "https://arxiv.org/html/2504.11393v2",
        "PDF": "https://arxiv.org/pdf/2504.11393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper discusses methods to predict the best pretraining data for large language models using small-scale experiments. It involves training-data processing, including dataset selection, deduplication, and filtering, thus making a core contribution to LLM training data processing."
      },
      "tasks": [
        "ARC",
        "HellaSwag",
        "HumanEval",
        "mbpp",
        "MMLU"
      ],
      "repo_urls": [
        "https://github.com/gair-nlp/prox"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03147",
      "abstract": "Along with the explosion of large language models, improvements in speech synthesis, advancements in hardware, and the evolution of computer graphics, the current bottleneck in creating digital humans lies in generating character movements that correspond naturally to text or speech inputs.\n  In this work, we present DeepGesture, a diffusion-based gesture synthesis framework for generating expressive co-speech gestures conditioned on multimodal signals - text, speech, emotion, and seed motion. Built upon the DiffuseStyleGesture model, DeepGesture introduces novel architectural enhancements that improve semantic alignment and emotional expressiveness in generated gestures. Specifically, we integrate fast text transcriptions as semantic conditioning and implement emotion-guided classifier-free diffusion to support controllable gesture generation across affective states. To visualize results, we implement a full rendering pipeline in Unity based on BVH output from the model. Evaluation on the ZeroEGGS dataset shows that DeepGesture produces gestures with improved human-likeness and contextual appropriateness. Our system supports interpolation between emotional states and demonstrates generalization to out-of-distribution speech, including synthetic voices - marking a step forward toward fully multimodal, emotionally aware digital humans.\n  Project page: https://deepgesture.github.io",
      "authors": [
        "Thanh Hoang-Minh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T20:04:04+00:00",
          "link": "https://arxiv.org/abs/2507.03147v1",
          "size": "17749kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:34:27+00:00",
          "link": "https://arxiv.org/abs/2507.03147v2",
          "size": "18854kb",
          "version": "v2"
        }
      ],
      "title": "DeepGesture: A conversational gesture synthesis system based on emotions and semantics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03147",
        "HTML": "https://arxiv.org/html/2507.03147v2",
        "PDF": "https://arxiv.org/pdf/2507.03147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with gesture synthesis based on text, speech, and emotion signals rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09105",
      "abstract": "Earlier Sign Language Production (SLP) models typically relied on autoregressive methods that generate output tokens one by one, which inherently provide temporal alignment. Although techniques like Teacher Forcing can prevent model collapse during training, they still cannot solve the problem of error accumulation during inference, since ground truth is unavailable at that stage. In contrast, more recent approaches based on diffusion models leverage step-by-step denoising to enable high-quality generation. However, the iterative nature of these models and the requirement to denoise entire sequences limit their applicability in real-time tasks like SLP. To address it, we apply a hybrid approach combining autoregressive and diffusion models to SLP for the first time, leveraging the strengths of both models in sequential dependency modeling and output refinement. To capture fine-grained body movements, we design a Multi-Scale Pose Representation module that separately extracts detailed features from distinct articulators and integrates them via a Multi-Scale Fusion module. Furthermore, we introduce a Confidence-Aware Causal Attention mechanism that utilizes joint-level confidence scores to dynamically guide the pose generation process, improving accuracy and robustness. Extensive experiments on the PHOENIX14T and How2Sign datasets demonstrate the effectiveness of our method in both generation quality and real-time streaming efficiency.",
      "authors": [
        "Maoxiao Ye",
        "Xinfeng Ye",
        "Mano Manoharan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:34:50+00:00",
          "link": "https://arxiv.org/abs/2507.09105v1",
          "size": "5216kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Autoregressive-Diffusion Model for Real-Time Streaming Sign Language Production",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09105",
        "HTML": "https://arxiv.org/html/2507.09105v1",
        "PDF": "https://arxiv.org/pdf/2507.09105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a hybrid model for real-time sign language production, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09326",
      "abstract": "Logically constrained term rewriting is a relatively new rewriting formalism that naturally supports built-in data structures, such as integers and bit vectors. In the analysis of logically constrained term rewrite systems (LCTRSs), rewriting constrained terms plays a crucial role. However, this combines rewrite rule applications and equivalence transformations in a closely intertwined way. This intertwining makes it difficult to establish useful theoretical properties for this kind of rewriting and causes problems in implementations -- namely, that impractically large search spaces are often required. To address this issue, we propose in this paper a novel notion of most general constrained rewriting, which operates on existentially constrained terms, a concept recently introduced by the authors. We define a class of left-linear, left-value-free LCTRSs that are general enough to simulate all left-linear LCTRSs and exhibit the desired key property: most general constrained rewriting commutes with equivalence. This property ensures that equivalence transformations can be deferred until after the application of rewrite rules, which helps mitigate the issue of large search spaces in implementations. In addition to that, we show that the original rewriting formalism on constrained terms can be embedded into our new rewriting formalism on existentially constrained terms. Thus, our results are expected to have significant implications for achieving correct and efficient implementations in tools operating on LCTRSs.",
      "authors": [
        "Kanta Takahata and Jonas Sch\\\"opf and Naoki Nishida and Takahito Aoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:01:28+00:00",
          "link": "https://arxiv.org/abs/2507.09326v1",
          "size": "105kb",
          "version": "v1"
        }
      ],
      "title": "Recovering Commutation of Logically Constrained Rewriting and Equivalence Transformations (Full Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09326",
        "HTML": "https://arxiv.org/html/2507.09326v1",
        "PDF": "https://arxiv.org/pdf/2507.09326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on logically constrained term rewriting and equivalence transformations, which do not involve LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.00244",
      "abstract": "Variable renewable energy droughts, also called \"Dunkelflaute\", emerge as a challenge for climate-neutral energy systems based on variable renewables. Drawing on 38 historic weather years and an advanced identification method, we characterize European drought events for on- and offshore wind power, solar photovoltaics, and renewable technology portfolios. We show that their characteristics heavily depend on the chosen drought threshold, questioning the usefulness of single-threshold analyses. Applying a multi-threshold framework, we quantify how the complementarity of wind and solar power temporally and spatially alleviates drought frequency, duration, and severity within (portfolio effect) and across countries (balancing effect). We identify the most extreme droughts and show how these drive major discharging periods of long-duration storage in a fully renewable European energy system, based on a policy-relevant decarbonization scenario. Such events comprise sequences of shorter droughts of varying severity. The most extreme event occurred in winter 1996/97 and lasted 55 days in a perfectly interconnected setting. While the average renewable availability during this period was still 47% of its long-run mean, we argue that system planners must consider such events when planning for storage and other flexibility technologies. Methodologically, we conclude that using single calendar years is not suitable for modeling weather-resilient energy scenarios.",
      "authors": [
        "Martin Kittel and Wolf-Peter Schill"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T21:29:25+00:00",
          "link": "https://arxiv.org/abs/2410.00244v1",
          "size": "40206kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T10:18:53+00:00",
          "link": "https://arxiv.org/abs/2410.00244v2",
          "size": "30233kb",
          "version": "v2"
        }
      ],
      "title": "Quantifying the Dunkelflaute: An analysis of variable renewable energy droughts in Europe",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00244",
        "HTML": "https://arxiv.org/html/2410.00244v2",
        "PDF": "https://arxiv.org/pdf/2410.00244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing renewable energy droughts in Europe using historical weather data and does not involve processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08963",
      "abstract": "We consider stochastic approximation with block-coordinate stepsizes and propose adaptive stepsize rules that aim to minimize the expected distance from the next iterate to an optimal point. These stepsize rules employ online estimates of the second moment of the search direction along each block coordinate. The popular Adam algorithm can be interpreted as a particular heuristic for such estimation. By leveraging a simple conditional estimator, we derive a new method that obtains comparable performance as Adam but requires less memory and fewer hyper-parameters. We prove that this family of methods converges almost surely to a small neighborhood of the optimal point, and the radius of the neighborhood depends on the bias and variance of the second-moment estimator. Our analysis relies on a simple aiming condition that assumes neither convexity nor smoothness, thus has broad applicability.",
      "authors": [
        "Tao Jiang and Lin Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:47:28+00:00",
          "link": "https://arxiv.org/abs/2507.08963v1",
          "size": "456kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Approximation with Block Coordinate Optimal Stepsizes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08963",
        "HTML": "https://arxiv.org/html/2507.08963v1",
        "PDF": "https://arxiv.org/pdf/2507.08963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes optimization techniques for stochastic approximation with block-coordinate stepsizes, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08974",
      "abstract": "Accurate channel estimation is crucial for the improvement of signal processing performance in wireless communications. However, traditional model-based methods frequently experience difficulties in dynamic environments. Similarly, alternative machine-learning approaches typically lack generalization across different datasets due to variations in channel characteristics. To address this issue, in this study, we propose a novel domain adaptation approach to bridge the gap between the quasi-static channel model (QSCM) and the map-based channel model (MBCM). Specifically, we first proposed a channel estimation pipeline that takes into account realistic channel simulation to train our foundation model. Then, we proposed domain adaptation methods to address the estimation problem. Using simulation-based training to reduce data requirements for effective application in practical wireless environments, we find that the proposed strategy enables robust model performance, even with limited true channel information.",
      "authors": [
        "Thien Hieu Hoang",
        "Tri Nhu Do",
        "and Georges Kaddoum"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:05:26+00:00",
          "link": "https://arxiv.org/abs/2507.08974v1",
          "size": "2677kb",
          "version": "v1"
        }
      ],
      "title": "Domain Adaptation-Enabled Realistic Map-Based Channel Estimation for MIMO-OFDM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08974",
        "HTML": "https://arxiv.org/html/2507.08974v1",
        "PDF": "https://arxiv.org/pdf/2507.08974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on channel estimation for wireless communications and domain adaptation, not on any data processing related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09279",
      "abstract": "Multimodal large language models (MLLMs) hold considerable promise for applications in healthcare. However, their deployment in safety-critical settings is hindered by two key limitations: (i) sensitivity to prompt design, and (ii) a tendency to generate incorrect responses with high confidence. As clinicians may rely on a model's stated confidence to gauge the reliability of its predictions, it is especially important that when a model expresses high confidence, it is also highly accurate. We introduce Prompt4Trust, the first reinforcement learning (RL) framework for prompt augmentation targeting confidence calibration in MLLMs. A lightweight LLM is trained to produce context-aware auxiliary prompts that guide a downstream task MLLM to generate responses in which the expressed confidence more accurately reflects predictive accuracy. Unlike conventional calibration techniques, Prompt4Trust specifically prioritizes aspects of calibration most critical for safe and trustworthy clinical decision-making. Beyond improvements driven by this clinically motivated calibration objective, our proposed method also improves task accuracy, achieving state-of-the-art medical visual question answering (VQA) performance on the PMC-VQA benchmark, which is composed of multiple-choice questions spanning diverse medical imaging modalities. Moreover, our framework trained with a small downstream task MLLM showed promising zero-shot generalization to larger MLLMs in our experiments, suggesting the potential for scalable calibration without the associated computational costs. This work demonstrates the potential of automated yet human-aligned prompt engineering for improving the the trustworthiness of MLLMs in safety critical settings. Our codebase can be found at https://github.com/xingbpshen/vccrl-llm.",
      "authors": [
        "Anita Kriz",
        "Elizabeth Laura Janes",
        "Xing Shen",
        "Tal Arbel"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:21:10+00:00",
          "link": "https://arxiv.org/abs/2507.09279v1",
          "size": "301kb",
          "version": "v1"
        }
      ],
      "title": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09279",
        "HTML": "https://arxiv.org/html/2507.09279v1",
        "PDF": "https://arxiv.org/pdf/2507.09279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses a reinforcement learning framework for prompt augmentation in multimodal large language models, it does not focus on training data processing or creation of datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09780",
      "abstract": "Bit-level sparsity in quantized deep neural networks (DNNs) offers significant potential for optimizing Multiply-Accumulate (MAC) operations. However, two key challenges still limit its practical exploitation. First, conventional bit-serial approaches cannot simultaneously leverage the sparsity of both factors, leading to a complete waste of one factor' s sparsity. Methods designed to exploit dual-factor sparsity are still in the early stages of exploration, facing the challenge of partial product explosion. Second, the fluctuation of bit-level sparsity leads to variable cycle counts for MAC operations. Existing synchronous scheduling schemes that are suitable for dual-factor sparsity exhibit poor flexibility and still result in significant underutilization of MAC units. To address the first challenge, this study proposes a MAC unit that leverages dual-factor sparsity through the emerging particlization-based approach. The proposed design addresses the issue of partial product explosion through simple control logic, resulting in a more area- and energy-efficient MAC unit. In addition, by discarding less significant intermediate results, the design allows for further hardware simplification at the cost of minor accuracy loss. To address the second challenge, a quasi-synchronous scheme is introduced that adds cycle-level elasticity to the MAC array, reducing pipeline stalls and thereby improving MAC unit utilization. Evaluation results show that the exact version of the proposed MAC array architecture achieves a 29.2% improvement in area efficiency compared to the state-of-the-art bit-sparsity-driven architecture, while maintaining comparable energy efficiency. The approximate variant further improves energy efficiency by 7.5%, compared to the exact version. Index-Terms: DNN acceleration, Bit-level sparsity, MAC unit",
      "authors": [
        "Feilong Qiaoyuan",
        "Jihe Wang",
        "Zhiyu Sun",
        "Linying Wu",
        "Yuanhua Xiao",
        "Danghui Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:27:27+00:00",
          "link": "https://arxiv.org/abs/2507.09780v1",
          "size": "378kb",
          "version": "v1"
        }
      ],
      "title": "BitParticle: Partializing Sparse Dual-Factors to Build Quasi-Synchronizing MAC Arrays for Energy-efficient DNNs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09780",
        "HTML": "https://arxiv.org/html/2507.09780v1",
        "PDF": "https://arxiv.org/pdf/2507.09780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hardware optimization for DNNs, particularly about MAC unit efficiency and sparsity exploitation, without any discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10073",
      "abstract": "Are AI systems truly representing human values, or merely averaging across them? Our study suggests a concerning reality: Large Language Models (LLMs) fail to represent diverse cultural moral frameworks despite their linguistic capabilities. We expose significant gaps between AI-generated and human moral intuitions by applying the Moral Foundations Questionnaire across 19 cultural contexts. Comparing multiple state-of-the-art LLMs' origins against human baseline data, we find these models systematically homogenize moral diversity. Surprisingly, increased model size doesn't consistently improve cultural representation fidelity. Our findings challenge the growing use of LLMs as synthetic populations in social science research and highlight a fundamental limitation in current AI alignment approaches. Without data-driven alignment beyond prompting, these systems cannot capture the nuanced, culturally-specific moral intuitions. Our results call for more grounded alignment objectives and evaluation metrics to ensure AI systems represent diverse human values rather than flattening the moral landscape.",
      "authors": [
        "Simon M\\\"unker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:59:26+00:00",
          "link": "https://arxiv.org/abs/2507.10073v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10073",
        "HTML": "https://arxiv.org/html/2507.10073v1",
        "PDF": "https://arxiv.org/pdf/2507.10073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating cultural bias in AI agents through moral questionnaires and discusses alignment of AI with human values, not on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10354",
      "abstract": "Metaphorical meaning is not a flat mapping between concepts, but a complex cognitive phenomenon that integrates multiple levels of interpretation. In this paper, we propose a stratified model of metaphor processing that treats meaning as an onion: a multi-layered structure comprising (1) content analysis, (2) conceptual blending, and (3) pragmatic intentionality. This three-dimensional framework allows for a richer and more cognitively grounded approach to metaphor interpretation in computational systems. At the first level, metaphors are annotated through basic conceptual elements. At the second level, we model conceptual combinations, linking components to emergent meanings. Finally, at the third level, we introduce a pragmatic vocabulary to capture speaker intent, communicative function, and contextual effects, aligning metaphor understanding with pragmatic theories. By unifying these layers into a single formal framework, our model lays the groundwork for computational methods capable of representing metaphorical meaning beyond surface associations, toward deeper, more context-sensitive reasoning.",
      "authors": [
        "Silvia Cappa",
        "Anna Sofia Lippolis",
        "and Stefano Zoia"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:56:46+00:00",
          "link": "https://arxiv.org/abs/2507.10354v1",
          "size": "2826kb",
          "version": "v1"
        }
      ],
      "title": "Meanings are like Onions: a Layered Approach to Metaphor Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10354",
        "HTML": "https://arxiv.org/html/2507.10354v1",
        "PDF": "https://arxiv.org/pdf/2507.10354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses metaphor processing in computational models, focusing on interpretation rather than LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10469",
      "abstract": "Advancements in artificial intelligence (AI) have significantly enhanced the realism and interactivity of non-player characters (NPCs) in virtual reality (VR), creating more engaging and believable user experiences. This paper evaluates AI-driven NPCs within a VR interrogation simulator, focusing on their perceived realism, usability, and system performance. The simulator features two AI-powered NPCs, a suspect, and a partner, using GPT-4 Turbo to engage participants in a scenario to determine the suspect's guilt or innocence. A user study with 18 participants assessed the system using the System Usability Scale (SUS), Game Experience Questionnaire (GEQ), and a Virtual Agent Believability Questionnaire, alongside latency measurements for speech-to-text (STT), text-to-speech (TTS), OpenAI GPT-4 Turbo, and overall (cycle) latency. Results showed an average cycle latency of 7 seconds, influenced by the increasing conversational context. Believability scored 6.67 out of 10, with high ratings in behavior, social relationships, and intelligence but moderate scores in emotion and personality. The system achieved a SUS score of 79.44, indicating good usability. These findings demonstrate the potential of large language models to improve NPC realism and interaction in VR while highlighting challenges in reducing system latency and enhancing emotional depth. This research contributes to the development of more sophisticated AI-driven NPCs, revealing the need for performance optimization to achieve increasingly immersive virtual experiences.",
      "authors": [
        "Mikko Korkiakoski",
        "Saeid Sheikhi",
        "Jesper Nyman",
        "Jussi Saariniemi",
        "Kalle Tapio",
        "Panos Kostakos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.10469v1",
          "size": "13517kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Evaluation of AI-Powered Non-Player Characters' Perceived Realism and Performance in Virtual Reality Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10469",
        "HTML": "https://arxiv.org/html/2507.10469v1",
        "PDF": "https://arxiv.org/pdf/2507.10469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates AI-powered NPCs in VR environments, focusing on perceived realism and performance in context, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10490",
      "abstract": "Deep learning models have been proposed for automatic polyp detection and precise segmentation of polyps during colonoscopy procedures. Although these state-of-the-art models achieve high performance, they often require a large number of parameters. Their complexity can make them prone to overfitting, particularly when trained on biased datasets, and can result in poor generalization across diverse datasets. Knowledge distillation and self-distillation are proposed as promising strategies to mitigate the limitations of large, over-parameterized models. These approaches, however, are resource-intensive, often requiring multiple models and significant memory during training. We propose a confidence-based self-distillation approach that outperforms state-of-the-art models by utilizing only previous iteration data storage during training, without requiring extra computation or memory usage during testing. Our approach calculates the loss between the previous and current iterations within a batch using a dynamic confidence coefficient. To evaluate the effectiveness of our approach, we conduct comprehensive experiments on the task of polyp segmentation. Our approach outperforms state-of-the-art models and generalizes well across datasets collected from multiple clinical centers. The code will be released to the public once the paper is accepted.",
      "authors": [
        "Tugberk Erol and Tuba Caglikantar and Duygu Sarikaya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:12:43+00:00",
          "link": "https://arxiv.org/abs/2507.10490v1",
          "size": "11953kb",
          "version": "v1"
        }
      ],
      "title": "The Power of Certainty: How Confident Models Lead to Better Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10490",
        "PDF": "https://arxiv.org/pdf/2507.10490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a technique for model segmentation improvement via confidence-based self-distillation but does not engage in LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10534",
      "abstract": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling of professional Digital Signal Processing (DSP) workflows remains challenging. In particular, while there is growing interest in neural black-box modeling of audio effect graphs (e.g. reverb, compression, equalization), AI-based approaches struggle to replicate the nuanced signal flow and parameter interactions used in professional workflows. Existing differentiable plugin approaches often diverge from real-world tools, exhibiting inferior performance relative to simplified neural controllers under equivalent computational constraints. We introduce WildFX, a pipeline containerized with Docker for generating multi-track audio mixing datasets with rich effect graphs, powered by a professional Digital Audio Workstation (DAW) backend. WildFX supports seamless integration of cross-platform commercial plugins or any plugins in the wild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g., sidechains, crossovers) and achieving efficient parallelized processing. A minimalist metadata interface simplifies project/plugin configuration. Experiments demonstrate the pipeline's validity through blind estimation of mixing graphs, plugin/gain parameters, and its ability to bridge AI research with practical DSP demands. The code is available on: https://github.com/IsaacYQH/WildFX.",
      "authors": [
        "Qihui Yang",
        "Taylor Berg-Kirkpatrick",
        "Julian McAuley",
        "Zachary Novack"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:55:38+00:00",
          "link": "https://arxiv.org/abs/2507.10534v1",
          "size": "445kb",
          "version": "v1"
        }
      ],
      "title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10534",
        "HTML": "https://arxiv.org/html/2507.10534v1",
        "PDF": "https://arxiv.org/pdf/2507.10534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an audio processing pipeline and does not involve LLM training data processing, focusing instead on audio effect modeling."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.17271",
      "abstract": "Data plane programming enables the programmability of network devices with domain-specific programming languages, like P4. One commonly used P4-programmable hardware target is the Intel Tofino switching ASIC. The runtime behavior of an implemented P4 program on Tofino can be configured with shell scripts or a Python library from Barefoot provided with the Tofino. Both are limited in their capabilities and usability. This paper introduces the Rust Barefoot Runtime (RBFRT), a Rust-based control plane library. The RBFRT provides a fast and memory-safe interface to configure the Intel Tofino. We showed that the RBFRT achieves a higher insertion rate for MAT entries and has a shorter response time compared to the Python library.",
      "authors": [
        "Etienne Zink",
        "Moritz Fl\\\"uchter",
        "Steffen Lindner",
        "Fabian Ihle",
        "Michael Menth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T20:03:40+00:00",
          "link": "https://arxiv.org/abs/2501.17271v1",
          "size": "1101kb",
          "version": "v1"
        },
        {
          "date": "2025-02-13T15:17:40+00:00",
          "link": "https://arxiv.org/abs/2501.17271v2",
          "size": "901kb",
          "version": "v2"
        },
        {
          "date": "2025-03-19T13:27:13+00:00",
          "link": "https://arxiv.org/abs/2501.17271v3",
          "size": "171kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T13:59:25+00:00",
          "link": "https://arxiv.org/abs/2501.17271v4",
          "size": "172kb",
          "version": "v4"
        }
      ],
      "title": "Rust Barefoot Runtime (RBFRT): Fast Runtime Control for the Intel Tofino",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17271",
        "HTML": "https://arxiv.org/html/2501.17271v4",
        "PDF": "https://arxiv.org/pdf/2501.17271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a Rust-based control plane library for configuring Intel Tofino switches, unrelated to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/uni-tue-kn/rbfrt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00268",
      "abstract": "The hallmark of effective language use lies in consistency: expressing similar meanings in similar contexts and avoiding contradictions. While human communication naturally demonstrates this principle, state-of-the-art language models (LMs) struggle to maintain reliable consistency across task- and domain-specific applications. Here we examine the landscape of consistency research in LMs, analyze current approaches to measure aspects of consistency, and identify critical research gaps. Our findings point to an urgent need for quality benchmarks to measure and interdisciplinary approaches to ensure consistency while preserving utility.",
      "authors": [
        "Jekaterina Novikova",
        "Carol Anderson",
        "Borhane Blili-Hamelin",
        "Domenic Rosati",
        "Subhabrata Majumdar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T03:25:25+00:00",
          "link": "https://arxiv.org/abs/2505.00268v1",
          "size": "47kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T01:20:26+00:00",
          "link": "https://arxiv.org/abs/2505.00268v2",
          "size": "52kb",
          "version": "v2"
        }
      ],
      "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00268",
        "HTML": "https://arxiv.org/html/2505.00268v2",
        "PDF": "https://arxiv.org/pdf/2505.00268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses challenges related to consistency in language models but does not address data processing for LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.19067",
      "abstract": "The growing demand for on-device AI necessitates energy-efficient execution of DNN based applications on resource-constrained ultra-low power (ULP) platforms. Heterogeneous architectures, combining specialized processing elements (PEs), have emerged as a key solution for achieving the required performance and energy efficiency. However, optimizing energy while executing applications on these platforms requires efficiently managing platform resources like PEs, power features, and memory footprint, all while adhering to critical application deadlines. This paper presents MEDEA, a novel design-time multi-objective manager for energy-efficient DNN inference on Heterogeneous ULP (HULP) platforms. MEDEA uniquely integrates: kernel-level dynamic voltage and frequency scaling (DVFS) for dynamic energy adaptation; kernel-level granularity scheduling, suitable for specialized accelerators; memory-aware adaptive tiling to navigate severe memory constraints; and all within a timing constraint-based optimization strategy, which minimizes energy based on application deadline. To showcase practical viability, we evaluate MEDEA on HEEPtimize, a heterogeneous ULP platform (22 nm, FPGA-prototyped) featuring a RISC-V processor besides Near-Memory Computing (NMC) and Coarse-Grained Reconfigurable Array (CGRA) accelerators. Experimental results, using a biomedical seizure detection case study, demonstrate that MEDEA achieves overall energy reductions of up to 38% compared to representative state-of-the-art methods, while consistently meeting all timing and memory requirements. This effectiveness is attributed to its integrated features, with our analysis showing that kernel-level DVFS alone can be responsible for over 31% of the energy savings in specific scenarios.",
      "authors": [
        "Hossein Taji",
        "Jos\\'e Miranda",
        "Miguel Pe\\'on-Quir\\'os and David Atienza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T19:39:49+00:00",
          "link": "https://arxiv.org/abs/2506.19067v1",
          "size": "319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:44:02+00:00",
          "link": "https://arxiv.org/abs/2506.19067v2",
          "size": "319kb",
          "version": "v2"
        }
      ],
      "title": "MEDEA: A Design-Time Multi-Objective Manager for Energy-Efficient DNN Inference on Heterogeneous Ultra-Low Power Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19067",
        "HTML": "https://arxiv.org/html/2506.19067v2",
        "PDF": "https://arxiv.org/pdf/2506.19067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a novel multi-objective manager for energy-efficient DNN inference on heterogeneous platforms, but it does not address or modify LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03691",
      "abstract": "We address the challenge of constructing noise-robust surrogate models for quantities of interest (QoIs) arising from parametric partial differential equations (PDEs), using multi-fidelity collocation techniques; specifically, the Multi-Index Stochastic Collocation (MISC). In practical scenarios, the PDE evaluations used to build a response surface are often corrupted by numerical noise, especially for the low-fidelity models. This noise, which may originate from loose solver tolerances, coarse discretisations, or transient effects, can lead to overfitting in MISC, degrading surrogate quality through nonphysical oscillations and loss of convergence, thereby limiting its utility in downstream tasks like uncertainty quantification, optimisation, and control. To correct this behaviour, we propose an improved version of MISC that can automatically detect the presence of solver noise during the surrogate model construction and then ignore the exhausted fidelities. Our approach monitors the spectral decay of the surrogate at each iteration, identifying stagnation in the coefficient spectrum that signals the onset of noise. Once detected, the algorithm selectively halts the use of noisy fidelities, focusing computational resources on those fidelities that still provide meaningful information. The effectiveness of this approach is numerically validated on two challenging test cases: a parabolic advection--diffusion PDE with uncertain coefficients, and a parametric turbulent incompressible Navier--Stokes problem. The results showcase the accuracy and robustness of the resulting multi-fidelity surrogate and its capability to extract relevant information, even from under-resolved meshes not suitable for reliable single-fidelity computations.",
      "authors": [
        "Benjamin M. Kent",
        "Lorenzo Tamellini",
        "Matteo Giacomini",
        "Antonio Huerta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T16:18:57+00:00",
          "link": "https://arxiv.org/abs/2507.03691v1",
          "size": "11605kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:15:51+00:00",
          "link": "https://arxiv.org/abs/2507.03691v2",
          "size": "11859kb",
          "version": "v2"
        }
      ],
      "title": "Noise-robust multi-fidelity surrogate modelling for parametric partial differential equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03691",
        "HTML": "https://arxiv.org/html/2507.03691v2",
        "PDF": "https://arxiv.org/pdf/2507.03691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on constructing noise-robust surrogate models for parametric PDEs using multi-fidelity collocation techniques, not on processing or preparing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07186",
      "abstract": "Large language models (LLMs) exhibit cognitive biases -- systematic tendencies of irrational decision-making, similar to those seen in humans. Prior work has found that these biases vary across models and can be amplified by instruction tuning. However, it remains unclear if these differences in biases stem from pretraining, finetuning, or even random noise due to training stochasticity. We propose a two-step causal experimental approach to disentangle these factors. First, we finetune models multiple times using different random seeds to study how training randomness affects over $30$ cognitive biases. Second, we introduce \\emph{cross-tuning} -- swapping instruction datasets between models to isolate bias sources. This swap uses datasets that led to different bias patterns, directly testing whether biases are dataset-dependent. Our findings reveal that while training randomness introduces some variability, biases are mainly shaped by pretraining: models with the same pretrained backbone exhibit more similar bias patterns than those sharing only finetuning data. These insights suggest that understanding biases in finetuned models requires considering their pretraining origins beyond finetuning effects. This perspective can guide future efforts to develop principled strategies for evaluating and mitigating bias in LLMs.",
      "authors": [
        "Itay Itzhak",
        "Yonatan Belinkov",
        "Gabriel Stanovsky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:01:14+00:00",
          "link": "https://arxiv.org/abs/2507.07186v1",
          "size": "9297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T10:00:59+00:00",
          "link": "https://arxiv.org/abs/2507.07186v2",
          "size": "9298kb",
          "version": "v2"
        }
      ],
      "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07186",
        "HTML": "https://arxiv.org/html/2507.07186v2",
        "PDF": "https://arxiv.org/pdf/2507.07186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses biases in LLMs related to pretraining and finetuning but does not primarily focus on data processing. It involves analyzing existing data to study biases rather than creating or processing training data itself."
      },
      "models": [
        {
          "model_path": "itay1itzhak/OLMo-Flan-Seed-0",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/itay1itzhak/OLMo-Flan-Seed-0"
        },
        {
          "model_path": "itay1itzhak/T5-Tulu-Seed-2",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/itay1itzhak/T5-Tulu-Seed-2"
        }
      ],
      "datasets": [
        {
          "dataset_name": "itay1itzhak/flan_2022_350k",
          "downloads": "14",
          "likes": "0",
          "link": "https://huggingface.co/datasets/itay1itzhak/flan_2022_350k"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09378",
      "abstract": "Transformers have revolutionized nucleotide sequence analysis, yet capturing long-range dependencies remains challenging. Recent studies show that autoregressive transformers often exhibit Markovian behavior by relying on fixed-length context windows for next-token prediction. However, standard self-attention mechanisms are computationally inefficient for long sequences due to their quadratic complexity and do not explicitly enforce global transition consistency.\n  We introduce CARMANIA (Context-Aware Regularization with Markovian Integration for Attention-Based Nucleotide Analysis), a self-supervised pretraining framework that augments next-token (NT) prediction with a transition-matrix (TM) loss. The TM loss aligns predicted token transitions with empirically derived n-gram statistics from each input sequence, encouraging the model to capture higher-order dependencies beyond local context. This integration enables CARMANIA to learn organism-specific sequence structures that reflect both evolutionary constraints and functional organization.\n  We evaluate CARMANIA across diverse genomic tasks, including regulatory element prediction, functional gene classification, taxonomic inference, antimicrobial resistance detection, and biosynthetic gene cluster classification. CARMANIA outperforms the previous best long-context model by at least 7 percent, matches state-of-the-art on shorter sequences (exceeding prior results on 20 out of 40 tasks while running approximately 2.5 times faster), and shows particularly strong improvements on enhancer and housekeeping gene classification tasks, including up to a 34 percent absolute gain in Matthews correlation coefficient (MCC) for enhancer prediction. The TM loss boosts accuracy in 33 of 40 tasks, especially where local motifs or regulatory patterns drive prediction.",
      "authors": [
        "Mohammadsaleh Refahi",
        "Mahdi Abavisani",
        "Bahrad A. Sokhansanj",
        "James R. Brown",
        "and Gail Rosen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T19:03:28+00:00",
          "link": "https://arxiv.org/abs/2507.09378v1",
          "size": "4418kb",
          "version": "v1"
        }
      ],
      "title": "Context-Aware Regularization with Markovian Integration for Attention-Based Nucleotide Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09378",
        "HTML": "https://arxiv.org/html/2507.09378v1",
        "PDF": "https://arxiv.org/pdf/2507.09378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes CARMANIA, a self-supervised pretraining framework for nucleotide analysis, but focuses on model architecture and performance rather than the process of LLM training data construction or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09926",
      "abstract": "As a key complement to terrestrial networks and a fundamental component of future 6G systems, Low Earth Orbit (LEO) satellite networks are expected to provide high-quality communication services when integrated with ground-based infrastructure, thereby attracting significant research interest. However, the limited satellite onboard resources and the uneven distribution of computational workloads often result in congestion along inter-satellite links (ISLs) that degrades task processing efficiency. Effectively managing the dynamic and large-scale topology of LEO networks to ensure balanced task distribution remains a critical challenge. To this end, we propose a dynamic multi-region division framework for intelligent task management in LEO satellite networks. This framework optimizes both intra- and inter-region routing to minimize task delay while balancing the utilization of computational and communication resources. Based on this framework, we propose a dynamic multi-region division algorithm based on the Genetic Algorithm (GA), which adaptively adjusts the size of each region based on the workload status of individual satellites. Additionally, we incorporate an adaptive routing algorithm and a task splitting and offloading scheme based on Multi-Agent Deep Deterministic Policy Gradient (MA-DDPG) to effectively accommodate the arriving tasks. Simulation results demonstrate that our proposed framework outperforms comparative methods in terms of the task delay, energy consumption per task, and task completion rate.",
      "authors": [
        "Zixuan Song",
        "Zhishu Shen",
        "Xiaoyu Zheng",
        "Qiushi Zheng",
        "Zheng Lei",
        "Jiong Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:10:11+00:00",
          "link": "https://arxiv.org/abs/2507.09926v1",
          "size": "4826kb",
          "version": "v1"
        }
      ],
      "title": "Intelligent Task Management via Dynamic Multi-region Division in LEO Satellite Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09926",
        "HTML": "https://arxiv.org/html/2507.09926v1",
        "PDF": "https://arxiv.org/pdf/2507.09926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on task management and routing in LEO satellite networks and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02948",
      "abstract": "Autonomous driving has seen significant progress, driven by extensive real-world data. However, in long-tail scenarios, accurately predicting the safety of the ego vehicle's future motion remains a major challenge due to uncertainties in dynamic environments and limitations in data coverage. In this work, we aim to explore whether it is possible to enhance the motion risk prediction capabilities of Vision-Language Models (VLM) by synthesizing high-risk motion data. Specifically, we introduce a Bird's-Eye View (BEV) based motion simulation method to model risks from three aspects: the ego-vehicle, other vehicles, and the environment. This allows us to synthesize plug-and-play, high-risk motion data suitable for VLM training, which we call DriveMRP-10K. Furthermore, we design a VLM-agnostic motion risk estimation framework, named DriveMRP-Agent. This framework incorporates a novel information injection strategy for global context, ego-vehicle perspective, and trajectory projection, enabling VLMs to effectively reason about the spatial relationships between motion waypoints and the environment. Extensive experiments demonstrate that by fine-tuning with DriveMRP-10K, our DriveMRP-Agent framework can significantly improve the motion risk prediction performance of multiple VLM baselines, with the accident recognition accuracy soaring from 27.13% to 88.03%. Moreover, when tested via zero-shot evaluation on an in-house real-world high-risk motion dataset, DriveMRP-Agent achieves a significant performance leap, boosting the accuracy from base_model's 29.42% to 68.50%, which showcases the strong generalization capabilities of our method in real-world scenarios.",
      "authors": [
        "Zhiyi Hou",
        "Enhui Ma",
        "Fang Li",
        "Zhiyi Lai",
        "Kalok Ho",
        "Zhanqian Wu",
        "Lijun Zhou",
        "Long Chen",
        "Chitian Sun",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Hangjun Ye",
        "and Kaicheng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T21:28:01+00:00",
          "link": "https://arxiv.org/abs/2507.02948v1",
          "size": "7223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T06:50:51+00:00",
          "link": "https://arxiv.org/abs/2507.02948v2",
          "size": "7223kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T15:16:06+00:00",
          "link": "https://arxiv.org/abs/2507.02948v3",
          "size": "7223kb",
          "version": "v3"
        }
      ],
      "title": "DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02948",
        "HTML": "https://arxiv.org/html/2507.02948v3",
        "PDF": "https://arxiv.org/pdf/2507.02948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces synthesized motion data (DriveMRP-10K) and describes the data synthesis process aimed at enhancing vision-language model training, thus contributing to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03255",
      "abstract": "High-Level Synthesis (HLS) plays a crucial role in modern hardware design by transforming high-level code into optimized hardware implementations. However, progress in applying machine learning (ML) to HLS optimization has been hindered by a shortage of sufficiently large and diverse datasets. To bridge this gap, we introduce ForgeHLS, a large-scale, open-source dataset explicitly designed for ML-driven HLS research. ForgeHLS comprises over 400,000 diverse designs generated from 536 kernels covering a broad range of application domains. Each kernel includes systematically automated pragma insertions (loop unrolling, pipelining, array partitioning), combined with extensive design space exploration using Bayesian optimization. Compared to existing datasets, ForgeHLS significantly enhances scale, diversity, and design coverage. We further define and evaluate representative downstream tasks, such as Quality of Result (QoR) prediction and automated pragma exploration, clearly demonstrating ForgeHLS's utility for developing and improving ML-based HLS optimization methodologies.",
      "authors": [
        "Zedong Peng",
        "Zeju Li",
        "Mingzhe Gao",
        "Qiang Xu",
        "Chen Zhang",
        "Jieru Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T02:23:46+00:00",
          "link": "https://arxiv.org/abs/2507.03255v1",
          "size": "1453kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T06:13:28+00:00",
          "link": "https://arxiv.org/abs/2507.03255v2",
          "size": "1453kb",
          "version": "v2"
        }
      ],
      "title": "ForgeHLS: A Large-Scale, Open-Source Dataset for High-Level Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03255",
        "HTML": "https://arxiv.org/html/2507.03255v2",
        "PDF": "https://arxiv.org/pdf/2507.03255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces ForgeHLS, a dataset for HLS optimization research, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08773",
      "abstract": "Firstly, assuming Gaussianity, equations for the following information theory measures are presented: total correlation/coherence (TC), dual total correlation/coherence (DTC), O-information, TSE complexity, and redundancy-synergy index (RSI). Since these measures are functions of the covariance matrix \"S\" and its inverse \"S^-1\", the associated Wishart and inverse-Wishart distributions are of note. DTC is shown to be the Kullback-Leibler (KL) divergence for the inverse-Wishart pair \"(S^-1)\" and its diagonal matrix \"D=diag(S^-1)\", shedding light on its interpretation as a measure of \"total partial correlation\", -lndetP, with test hypothesis H0: P=I, where \"P\" is the standardized inverse covariance (i.e. P=(D^-1/2)(S^-1)(D^-1/2). The second aim of this paper introduces a generalization of all these measures for structured groups of variables. For instance, consider three or more groups, each consisting of three or more variables, with predominant redundancy within each group, but with synergistic interactions between groups. O-information will miss the between group synergy (since redundancy occurs more often in the system). In contrast, the structured O-information measure presented here will correctly report predominant synergy between groups. This is a relevant generalization towards structured multivariate information measures. A third aim is the presentation of a framework for quantifying the contribution of \"connections\" between variables, to the system's TC, DTC, O-information, and TSE complexity. A fourth aim is to present a generalization of the redundancy-synergy index for quantifying the contribution of a group of variables to the system's redundancy-synergy balance. Finally, it is shown that the expressions derived here directly apply to data from several other elliptical distributions. All program codes, data files, and executables are available (https://osf.io/jd37g/).",
      "authors": [
        "Roberto D. Pascual-Marqui",
        "Kieko Kochi",
        "Toshihiko Kinoshita"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:35:04+00:00",
          "link": "https://arxiv.org/abs/2507.08773v1",
          "size": "864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T06:24:20+00:00",
          "link": "https://arxiv.org/abs/2507.08773v2",
          "size": "821kb",
          "version": "v2"
        }
      ],
      "title": "Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08773",
        "PDF": "https://arxiv.org/pdf/2507.08773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses information theory measures for structured multivariate data but does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09081",
      "abstract": "Quantitative remote sensing inversion aims to estimate continuous surface variables-such as biomass, vegetation indices, and evapotranspiration-from satellite observations, supporting applications in ecosystem monitoring, carbon accounting, and land management. With the evolution of remote sensing systems and artificial intelligence, traditional physics-based paradigms are giving way to data-driven and foundation model (FM)-based approaches. This paper systematically reviews the methodological evolution of inversion techniques, from physical models (e.g., PROSPECT, SCOPE, DART) to machine learning methods (e.g., deep learning, multimodal fusion), and further to foundation models (e.g., SatMAE, GFM, mmEarth). We compare the modeling assumptions, application scenarios, and limitations of each paradigm, with emphasis on recent FM advances in self-supervised pretraining, multi-modal integration, and cross-task adaptation. We also highlight persistent challenges in physical interpretability, domain generalization, limited supervision, and uncertainty quantification. Finally, we envision the development of next-generation foundation models for remote sensing inversion, emphasizing unified modeling capacity, cross-domain generalization, and physical interpretability.",
      "authors": [
        "Zhenyu Yu",
        "Mohd Yamani Idna Idris",
        "Hua Wang",
        "Pei Wang",
        "Junyi Chen",
        "Kun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:57:00+00:00",
          "link": "https://arxiv.org/abs/2507.09081v1",
          "size": "2148kb",
          "version": "v1"
        }
      ],
      "title": "From Physics to Foundation Models: A Review of AI-Driven Quantitative Remote Sensing Inversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09081",
        "HTML": "https://arxiv.org/html/2507.09081v1",
        "PDF": "https://arxiv.org/pdf/2507.09081"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews AI-driven quantitative remote sensing inversion techniques and does not contribute to or focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09082",
      "abstract": "Extracting optical flow from videos remains a core computer vision problem. Motivated by the success of large general-purpose models, we ask whether frozen self-supervised video models trained only for future frame prediction can be prompted, without fine-tuning, to output flow. Prior work reading out depth or illumination from video generators required fine-tuning, which is impractical for flow where labels are scarce and synthetic datasets suffer from a sim-to-real gap. Inspired by the Counterfactual World Model (CWM) paradigm, which can obtain point-wise correspondences by injecting a small tracer perturbation into a next-frame predictor and tracking its propagation, we extend this idea to generative video models. We explore several popular architectures and find that successful zero-shot flow extraction in this manner is aided by three model properties: (1) distributional prediction of future frames (avoiding blurry or noisy outputs); (2) factorized latents that treat each spatio-temporal patch independently; and (3) random-access decoding that can condition on any subset of future pixels. These properties are uniquely present in the recent Local Random Access Sequence (LRAS) architecture. Building on LRAS, we propose KL-tracing: a novel test-time procedure that injects a localized perturbation into the first frame, rolls out the model one step, and computes the Kullback-Leibler divergence between perturbed and unperturbed predictive distributions. Without any flow-specific fine-tuning, our method outperforms state-of-the-art models on real-world TAP-Vid DAVIS dataset (16.6% relative improvement for endpoint error) and synthetic TAP-Vid Kubric (4.7% relative improvement). Our results indicate that counterfactual prompting of controllable generative video models is a scalable and effective alternative to supervised or photometric-loss approaches for high-quality flow.",
      "authors": [
        "Seungwoo Kim",
        "Khai Loong Aw",
        "Klemen Kotar",
        "Cristobal Eyzaguirre",
        "Wanhee Lee",
        "Yunong Liu",
        "Jared Watrous",
        "Stefan Stojanov",
        "Juan Carlos Niebles",
        "Jiajun Wu",
        "Daniel L. K. Yamins"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:59:38+00:00",
          "link": "https://arxiv.org/abs/2507.09082v1",
          "size": "7648kb",
          "version": "v1"
        }
      ],
      "title": "Taming generative video models for zero-shot optical flow extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09082",
        "HTML": "https://arxiv.org/html/2507.09082v1",
        "PDF": "https://arxiv.org/pdf/2507.09082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores zero-shot optical flow extraction using generative video models, without focusing on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09411",
      "abstract": "Large Language Models (LLMs) have transformed software development and automated code generation. Motivated by these advancements, this paper explores the feasibility of LLMs in modifying malware source code to generate variants. We introduce LLMalMorph, a semi-automated framework that leverages semantical and syntactical code comprehension by LLMs to generate new malware variants. LLMalMorph extracts function-level information from the malware source code and employs custom-engineered prompts coupled with strategically defined code transformations to guide the LLM in generating variants without resource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse Windows malware samples of varying types, complexity and functionality and generated 618 variants. Our thorough experiments demonstrate that it is possible to reduce the detection rates of antivirus engines of these malware variants to some extent while preserving malware functionalities. In addition, despite not optimizing against any Machine Learning (ML)-based malware detectors, several variants also achieved notable attack success rates against an ML-based malware classifier. We also discuss the limitations of current LLM capabilities in generating malware variants from source code and assess where this emerging technology stands in the broader context of malware variant generation.",
      "authors": [
        "Md Ajwad Akil",
        "Adrian Shuai Li",
        "Imtiaz Karim",
        "Arun Iyengar",
        "Ashish Kundu",
        "Vinny Parla and Elisa Bertino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T22:11:10+00:00",
          "link": "https://arxiv.org/abs/2507.09411v1",
          "size": "1127kb",
          "version": "v1"
        }
      ],
      "title": "LLMalMorph: On The Feasibility of Generating Variant Malware using Large-Language-Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09411",
        "PDF": "https://arxiv.org/pdf/2507.09411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions using LLMs to modify malware but does not focus primarily on LLM training data processing; rather, it explores application in code generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09606",
      "abstract": "Sound event detection (SED) has made strong progress in controlled environments with clear event categories. However, real-world applications often take place in open environments. In such cases, current methods often produce predictions with too much confidence and lack proper ways to measure uncertainty. This limits their ability to adapt and perform well in new situations. To solve this problem, we are the first to use ensemble methods in SED to improve robustness against out-of-domain (OOD) inputs. We propose a confidence calibration method called Energy-based Open-World Softmax (EOW-Softmax), which helps the system better handle uncertainty in unknown scenes. We further apply EOW-Softmax to sound occurrence and overlap detection (SOD) by adjusting the prediction. In this way, the model becomes more adaptable while keeping its ability to detect overlapping events. Experiments show that our method improves performance in open environments. It reduces overconfidence and increases the ability to handle OOD situations.",
      "authors": [
        "Yuanjian Chen and Han Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:23:02+00:00",
          "link": "https://arxiv.org/abs/2507.09606v1",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "title": "Ensemble Confidence Calibration for Sound Event Detection in Open-environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09606",
        "HTML": "https://arxiv.org/html/2507.09606v1",
        "PDF": "https://arxiv.org/pdf/2507.09606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presented is about sound event detection and improving robustness with ensemble methods. It does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10181",
      "abstract": "While teaching untyped $\\lambda$-calculus to undergraduate students, we were wondering why $\\alpha$-equivalence is not directly inductively defined. In this paper, we demonstrate that this is indeed feasible. Specifically, we provide a grounded, inductive definition for $\\alpha$-equivalence and show that it conforms to the specification provided in the literature. The work presented in this paper is fully formalized in the Rocq Prover.",
      "authors": [
        "Kalmer Apinis",
        "Danel Ahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:42:57+00:00",
          "link": "https://arxiv.org/abs/2507.10181v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "A simple formalization of alpha-equivalence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10181",
        "PDF": "https://arxiv.org/pdf/2507.10181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a formalization of alpha-equivalence in lambda calculus and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.00955",
      "abstract": "This paper challenges the argument that generative artificial intelligence (GenAI) is entitled to broad immunity from copyright law for reproducing copyrighted works without authorization due to a fair use defense. It examines fair use legal arguments and eight distinct substantive arguments, contending that every legal and substantive argument favoring fair use for GenAI applies equally, if not more so, to humans. Therefore, granting GenAI exceptional privileges in this domain is legally and logically inconsistent with withholding broad fair use exemptions from individual humans. It would mean no human would need to pay for virtually any copyright work again. The solution is to take a circumspect view of any fair use claim for mass copyright reproduction by any entity and focus on the first principles of whether permitting such exceptionalism for GenAI promotes science and the arts.",
      "authors": [
        "David Atkinson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T16:49:39+00:00",
          "link": "https://arxiv.org/abs/2504.00955v1",
          "size": "539kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T17:43:01+00:00",
          "link": "https://arxiv.org/abs/2504.00955v2",
          "size": "652kb",
          "version": "v2"
        }
      ],
      "title": "Unfair Learning: GenAI Exceptionalism and Copyright Law",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00955",
        "PDF": "https://arxiv.org/pdf/2504.00955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the legal issues of copyright and fair use in generative AI, without discussing the processing of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.00038",
      "abstract": "In order to increase the effectiveness of model training, data reduction is essential to data-centric AI. It does this by locating the most instructive examples in massive datasets. To increase data quality and training efficiency, the main difficulty is to choose the best examples rather than the complete datasets. In this paper, we propose an effective data reduction strategy based on Pointwise -Information (PVI). To enable a static method, we first use PVI to quantify instance difficulty and remove instances with low difficulty. Experiments show that the classifier performance is maintained with only a 0.0001% to 0.76% reduction in accuracy when 10%-30% of the data is removed. Second, we train the classifiers using a progressive learning strategy on examples sorted by increasing PVI, accelerating convergence and achieving a 0.8% accuracy gain over conventional training. Our findings imply that training a classifier on the chosen optimal subset may improve model performance and increase training efficiency when combined with an efficient data reduction strategy. Furthermore, we have adapted the PVI framework, which was previously limited to English datasets, to a variety of Chinese NLP tasks and base models, yielding insightful results for faster training and cross-lingual data reduction. The codes are released at https://github.com/zhouwenchi/DatasetReductionStrategy.",
      "authors": [
        "Fei Chen and Wenchi Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T06:59:19+00:00",
          "link": "https://arxiv.org/abs/2507.00038v1",
          "size": "981kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.00038v2",
          "size": "1131kb",
          "version": "v2"
        }
      ],
      "title": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00038",
        "PDF": "https://arxiv.org/pdf/2507.00038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a primary contribution to LLM training data processing by proposing a data reduction strategy that effectively selects optimal training examples, thereby improving data quality and training efficiency for NLP tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09259",
      "abstract": "Humour translation plays a vital role as a bridge between different cultures, fostering understanding and communication. Although most existing Large Language Models (LLMs) are capable of general translation tasks, these models still struggle with humour translation, which is especially reflected through linguistic interference and lacking humour in translated text. In this paper, we propose a psychology-inspired Humour Decomposition Mechanism (HDM) that utilises Chain-of-Thought (CoT) to imitate the ability of the human thought process, stimulating LLMs to optimise the readability of translated humorous texts. Moreover, we integrate humour theory in HDM to further enhance the humorous elements in the translated text. Our automatic evaluation experiments on open-source humour datasets demonstrate that our method significantly improves the quality of humour translation, yielding average gains of 7.75\\% in humour, 2.81\\% in fluency, and 6.13\\% in coherence of the generated text.",
      "authors": [
        "Yuchen Su",
        "Yonghua Zhu",
        "Yang Chen",
        "Diana Benavides-Prado",
        "Michael Witbrock"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:44:41+00:00",
          "link": "https://arxiv.org/abs/2507.09259v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "Psychology-Driven Enhancement of Humour Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09259",
        "PDF": "https://arxiv.org/pdf/2507.09259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses humour translation using a psychology-driven mechanism but does not mention data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09340",
      "abstract": "Autonomous navigation in mobile robots, reliant on perception and planning, faces major hurdles in large-scale, complex environments. These include heavy computational burdens for mapping, sensor occlusion failures for UAVs, and traversal challenges on irregular terrain for UGVs, all compounded by a lack of perception-aware strategies. To address these challenges, we introduce Random Mapping and Random Projection (RMRP). This method constructs a lightweight linear parametric map by first mapping data to a high-dimensional space, followed by a sparse random projection for dimensionality reduction. Our novel Residual Energy Preservation Theorem provides theoretical guarantees for this process, ensuring critical geometric properties are preserved. Based on this map, we propose the RPATR (Robust Perception-Aware Trajectory Planner) framework. For UAVs, our method unifies grid and Euclidean Signed Distance Field (ESDF) maps. The front-end uses an analytical occupancy gradient to refine initial paths for safety and smoothness, while the back-end uses a closed-form ESDF for trajectory optimization. Leveraging the trained RMRP model's generalization, the planner predicts unobserved areas for proactive navigation. For UGVs, the model characterizes terrain and provides closed-form gradients, enabling online planning to circumvent large holes. Validated in diverse scenarios, our framework demonstrates superior mapping performance in time, memory, and accuracy, and enables computationally efficient, safe navigation for high-speed UAVs and UGVs. The code will be released to foster community collaboration.",
      "authors": [
        "Hongyu Nie",
        "Xingyu Li",
        "Xu Liu",
        "Zhaotong Tan",
        "Sen Mei",
        "and Wenbo Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:39:19+00:00",
          "link": "https://arxiv.org/abs/2507.09340v1",
          "size": "6762kb",
          "version": "v1"
        }
      ],
      "title": "Unified Linear Parametric Map Modeling and Perception-aware Trajectory Planning for Mobile Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09340",
        "HTML": "https://arxiv.org/html/2507.09340v1",
        "PDF": "https://arxiv.org/pdf/2507.09340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses trajectory planning and perception-aware strategies in robotics, not involving any aspects of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09428",
      "abstract": "The ever-increasing parameter counts of deep learning models necessitate effective compression techniques for deployment on resource-constrained devices. This paper explores the application of information geometry, the study of density-induced metrics on parameter spaces, to analyze existing methods within the space of model compression, primarily focusing on operator factorization. Adopting this perspective highlights the core challenge: defining an optimal low-compute submanifold (or subset) and projecting onto it. We argue that many successful model compression approaches can be understood as implicitly approximating information divergences for this projection. We highlight that when compressing a pre-trained model, using information divergences is paramount for achieving improved zero-shot accuracy, yet this may no longer be the case when the model is fine-tuned. In such scenarios, trainability of bottlenecked models turns out to be far more important for achieving high compression ratios with minimal performance degradation, necessitating adoption of iterative methods. In this context, we prove convergence of iterative singular value thresholding for training neural networks subject to a soft rank constraint. To further illustrate the utility of this perspective, we showcase how simple modifications to existing methods through softer rank reduction result in improved performance under fixed compression rates.",
      "authors": [
        "Zakhar Shumaylov",
        "Vasileios Tsiaras",
        "Yannis Stylianou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Differential Geometry (math.DG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:39:14+00:00",
          "link": "https://arxiv.org/abs/2507.09428v1",
          "size": "6344kb",
          "version": "v1"
        }
      ],
      "title": "On Information Geometry and Iterative Optimization in Model Compression: Operator Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09428",
        "HTML": "https://arxiv.org/html/2507.09428v1",
        "PDF": "https://arxiv.org/pdf/2507.09428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses model compression techniques and information geometry, without addressing training data processing in LLM pretraining or fine-tuning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10320",
      "abstract": "Verification and validation of autonomous driving (AD) systems and components is of increasing importance, as such technology increases in real-world prevalence. Safety-critical scenario generation is a key approach to robustify AD policies through closed-loop training. However, existing approaches for scenario generation rely on simplistic objectives, resulting in overly-aggressive or non-reactive adversarial behaviors. To generate diverse adversarial yet realistic scenarios, we propose SEAL, a scenario perturbation approach which leverages learned objective functions and adversarial, human-like skills. SEAL-perturbed scenarios are more realistic than SOTA baselines, leading to improved ego task success across real-world, in-distribution, and out-of-distribution scenarios, of more than 20%. To facilitate future research, we release our code and tools: https://github.com/cmubig/SEAL",
      "authors": [
        "Benjamin Stoler",
        "Ingrid Navarro",
        "Jonathan Francis",
        "Jean Oh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T14:33:21+00:00",
          "link": "https://arxiv.org/abs/2409.10320v1",
          "size": "10482kb",
          "version": "v1"
        },
        {
          "date": "2025-02-17T23:48:52+00:00",
          "link": "https://arxiv.org/abs/2409.10320v2",
          "size": "11785kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T15:31:23+00:00",
          "link": "https://arxiv.org/abs/2409.10320v3",
          "size": "4608kb",
          "version": "v3"
        }
      ],
      "title": "SEAL: Towards Safe Autonomous Driving via Skill-Enabled Adversary Learning for Closed-Loop Scenario Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10320",
        "HTML": "https://arxiv.org/html/2409.10320v3",
        "PDF": "https://arxiv.org/pdf/2409.10320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses scenario generation for autonomous driving verification, not related to LLM training data collection or processing."
      },
      "tasks": [
        "Autonomous Driving"
      ],
      "repo_urls": [
        "https://github.com/cmubig/seal"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.13957",
      "abstract": "Current postprocessing techniques often require separate models for each lead time and disregard possible inter-ensemble relationships by either correcting each member separately or by employing distributional approaches. In this work, we tackle these shortcomings with an innovative, fast and accurate Transformer which postprocesses each ensemble member individually while allowing information exchange across variables, spatial dimensions and lead times by means of multi-headed self-attention. Weather forecasts are postprocessed over 20 lead times simultaneously while including up to fifteen meteorological predictors. We use the EUPPBench dataset for training which contains ensemble predictions from the European Center for Medium-range Weather Forecasts' integrated forecasting system alongside corresponding observations. The work presented here is the first to postprocess the ten and one hundred-meter wind speed forecasts within this benchmark dataset, while also correcting two-meter temperature. Our approach significantly improves the original forecasts, as measured by the CRPS, with 16.5\\% for two-meter temperature, 10\\% for ten-meter wind speed and 9\\% for one hundred-meter wind speed, outperforming a classical member-by-member approach employed as a competitive benchmark. Furthermore, being up to six times faster, it fulfills the demand for rapid operational weather forecasts in various downstream applications, including renewable energy forecasting.",
      "authors": [
        "Aaron Van Poecke",
        "Tobias Sebastian Finn",
        "Ruoke Meng",
        "Joris Van den Bergh",
        "Geert Smet",
        "Jonathan Demaeyer",
        "Piet Termonia",
        "Hossein Tabari",
        "Peter Hellinckx"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T15:37:09+00:00",
          "link": "https://arxiv.org/abs/2412.13957v1",
          "size": "5890kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:34:23+00:00",
          "link": "https://arxiv.org/abs/2412.13957v2",
          "size": "6436kb",
          "version": "v2"
        }
      ],
      "title": "Self-attentive Transformer for Fast and Accurate Postprocessing of Temperature and Wind Speed Forecasts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13957",
        "HTML": "https://arxiv.org/html/2412.13957v2",
        "PDF": "https://arxiv.org/pdf/2412.13957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with weather forecast postprocessing using Transformers, focusing on meteorological data rather than LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/uantwerpm4s/pp_eupp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.16961",
      "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that addresses the key challenge in combining language models with the rigor of logical solvers: to accurately formulate the reasoning problem from natural language to the formal language of the solver. SSV uses a consistency-based approach to produce strong abstract formalizations of problems using concrete instantiations that are generated by the model and verified by the solver. In addition to significantly advancing the overall reasoning accuracy over the state-of-the-art, a key novelty that this approach presents is a feature of verification that has near-perfect precision over a significant coverage of cases, as we demonstrate on open reasoning benchmarks. We propose such *near-certain reasoning* as a new approach to reduce the need for manual verification in many cases, taking us closer to more dependable and autonomous AI reasoning systems.",
      "authors": [
        "Mohammad Raza and Natasa Milic-Frayling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T14:04:49+00:00",
          "link": "https://arxiv.org/abs/2501.16961v1",
          "size": "642kb",
          "version": "v1"
        },
        {
          "date": "2025-05-01T10:16:10+00:00",
          "link": "https://arxiv.org/abs/2501.16961v2",
          "size": "642kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T18:39:50+00:00",
          "link": "https://arxiv.org/abs/2501.16961v3",
          "size": "461kb",
          "version": "v3"
        }
      ],
      "title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16961",
        "PDF": "https://arxiv.org/pdf/2501.16961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method called Semantic Self-Verification for improving reasoning accuracy, but it does not address the processing or creation of LLM training data."
      },
      "tasks": [
        "Logical Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00283",
      "abstract": "Low Earth Orbit (LEO) satellite mega-constellations have recently emerged as a viable access solution for broadband services in underserved areas. In 2024, Direct Satellite-to-Device (DS2D) communications, which enable unmodified smartphones to connect directly to spaceborne base stations, entered large-scale beta testing, with Starlink globally leading deployments. This paper presents the first measurement study of commercial DS2D services. Using crowdsourced mobile network data collected in the U.S. between October 2024 and April 2025, our research derives evidence-based insights into the capabilities, limitations, and prospective evolution of DS2D technologies providing Supplemental Coverage from Space (SCS) services to expand existing mobile network connectivity. We observe a strong correlation between the number of satellites deployed and the expanding extension of observed measurements, concentrated in accessible but poorly covered areas by terrestrial networks, such as national parks and large low-density counties. The data reveal stable physical-layer value measurement throughout the observation period, with a lower median RSRP (24-dB difference) and a higher RSRQ (3 dB difference) compared to terrestrial networks, reflecting the SMS-only usage of the DS2D network during this period. Based on SINR measurements, we estimate the expected performance of the announced DS2D mobile data service to be around 4 Mbps per beam in outdoor conditions. We also discuss strategies to expand this capacity up to 12 Mbps in the future, depending on key regulatory decisions regarding satellite licenses, spectrum availability, and allowable radiated power levels.",
      "authors": [
        "Jorge Garcia-Cabeza",
        "Javier Albert-Smet",
        "Zoraida Frias",
        "Luis Mendo",
        "Santiago Andr\\'es Azcoitia",
        "Eduardo Yraola"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T22:24:07+00:00",
          "link": "https://arxiv.org/abs/2506.00283v1",
          "size": "3708kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T13:32:35+00:00",
          "link": "https://arxiv.org/abs/2506.00283v2",
          "size": "3708kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T17:47:57+00:00",
          "link": "https://arxiv.org/abs/2506.00283v3",
          "size": "3708kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T22:40:39+00:00",
          "link": "https://arxiv.org/abs/2506.00283v4",
          "size": "3708kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T22:48:09+00:00",
          "link": "https://arxiv.org/abs/2506.00283v5",
          "size": "3708kb",
          "version": "v5"
        }
      ],
      "title": "Direct-to-Cell: A First Look into Starlink's Direct Satellite-to-Device Radio Access Network through Crowdsourced Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00283",
        "HTML": "https://arxiv.org/html/2506.00283v5",
        "PDF": "https://arxiv.org/pdf/2506.00283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on measuring performance of satellite communication networks and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09132",
      "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in various graph-based tasks (e.g., node classification or link prediction). Despite their triumphs, GNNs still face challenges such as long training and inference times, difficulty in capturing complex relationships, and insufficient feature extraction. To tackle these issues, graph pre-training and graph prompt methods have garnered increasing attention for their ability to leverage large-scale datasets for initial learning and task-specific adaptation, offering potential improvements in GNN performance. However, previous research has overlooked the potential of graph prompts in optimizing models, as well as the impact of both positive and negative graph prompts on model stability and efficiency. To bridge this gap, we propose a novel framework combining graph prompts with weight pruning, called GPAWP, which aims to enhance the performance and efficiency of graph prompts by using fewer of them. We evaluate the importance of graph prompts using an importance assessment function to determine positive and negative weights at different granularities. Through hierarchically structured pruning, we eliminate negative prompt labels, resulting in more parameter-efficient and competitively performing prompts. Extensive experiments on three benchmark datasets demonstrate the superiority of GPAWP, leading to a significant reduction in parameters in node classification tasks.",
      "authors": [
        "Chu-Yuan Wei",
        "Shun-Yao Liu",
        "Sheng-Da Zhuo",
        "Chang-Dong Wang",
        "Shu-Qiang Huang",
        "and Mohsen Guizani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:12:24+00:00",
          "link": "https://arxiv.org/abs/2507.09132v1",
          "size": "334kb",
          "version": "v1"
        }
      ],
      "title": "Heterogeneous Graph Prompt Learning via Adaptive Weight Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09132",
        "HTML": "https://arxiv.org/html/2507.09132v1",
        "PDF": "https://arxiv.org/pdf/2507.09132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses graph neural networks and graph prompt learning via adaptive weight pruning, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09424",
      "abstract": "Data attribution methods quantify the influence of training data on model outputs and are becoming increasingly relevant for a wide range of LLM research and applications, including dataset curation, model interpretability, data valuation. However, there remain critical gaps in systematic LLM-centric evaluation of data attribution methods. To this end, we introduce DATE-LM (Data Attribution Evaluation in Language Models), a unified benchmark for evaluating data attribution methods through real-world LLM applications. DATE-LM measures attribution quality through three key tasks -- training data selection, toxicity/bias filtering, and factual attribution. Our benchmark is designed for ease of use, enabling researchers to configure and run large-scale evaluations across diverse tasks and LLM architectures. Furthermore, we use DATE-LM to conduct a large-scale evaluation of existing data attribution methods. Our findings show that no single method dominates across all tasks, data attribution methods have trade-offs with simpler baselines, and method performance is sensitive to task-specific evaluation design. Finally, we release a public leaderboard for quick comparison of methods and to facilitate community engagement. We hope DATE-LM serves as a foundation for future data attribution research in LLMs.",
      "authors": [
        "Cathy Jiao",
        "Yijun Pan",
        "Emily Xiao",
        "Daisy Sheng",
        "Niket Jain",
        "Hanzhang Zhao",
        "Ishita Dasgupta",
        "Jiaqi W. Ma",
        "Chenyan Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:29:56+00:00",
          "link": "https://arxiv.org/abs/2507.09424v1",
          "size": "13927kb",
          "version": "v1"
        }
      ],
      "title": "DATE-LM: Benchmarking Data Attribution Evaluation for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09424",
        "HTML": "https://arxiv.org/html/2507.09424v1",
        "PDF": "https://arxiv.org/pdf/2507.09424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a benchmark (DATE-LM) for evaluating data attribution methods in LLMs, involving tasks like training data selection and toxicity/bias filtering, which are related to data processing and quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09650",
      "abstract": "How can large language models (LLMs) serve users with varying preferences that may conflict across cultural, political, or other dimensions? To advance this challenge, this paper establishes four key results. First, we demonstrate, through a large-scale multilingual human study with representative samples from five countries (N=15,000), that humans exhibit significantly more variation in preferences than the responses of 21 state-of-the-art LLMs. Second, we show that existing methods for preference dataset collection are insufficient for learning the diversity of human preferences even along two of the most salient dimensions of variability in global values, due to the underlying homogeneity of candidate responses. Third, we argue that this motivates the need for negatively-correlated sampling when generating candidate sets, and we show that simple prompt-based techniques for doing so significantly enhance the performance of alignment methods in learning heterogeneous preferences. Fourth, based on this novel candidate sampling approach, we collect and open-source Community Alignment, the largest and most representative multilingual and multi-turn preference dataset to date, featuring almost 200,000 comparisons from annotators spanning five countries. We hope that the Community Alignment dataset will be a valuable resource for improving the effectiveness of LLMs for a diverse global population.",
      "authors": [
        "Lily Hong Zhang and Smitha Milli and Karen Jusko and Jonathan Smith and Brandon Amos and Wassim (Wes) Bouaziz and Manon Revel and Jack Kussman and Lisa Titus and Bhaktipriya Radharapu and Jane Yu and Vidya Sarma and Kris Rose and Maximilian Nickel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:34:22+00:00",
          "link": "https://arxiv.org/abs/2507.09650v1",
          "size": "2755kb",
          "version": "v1"
        }
      ],
      "title": "Cultivating Pluralism In Algorithmic Monoculture: The Community Alignment Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09650",
        "HTML": "https://arxiv.org/html/2507.09650v1",
        "PDF": "https://arxiv.org/pdf/2507.09650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the Community Alignment dataset, emphasizing novel data collection and candidate sampling techniques to capture human preferences, which are significant contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09758",
      "abstract": "Curriculum learning is a widely adopted training strategy in natural language processing (NLP), where models are exposed to examples organized by increasing difficulty to enhance learning efficiency and performance. However, most existing approaches rely on manually defined difficulty metrics -- such as text length -- which may not accurately reflect the model's own perspective. To overcome this limitation, we present a self-adaptive curriculum learning paradigm that prioritizes fine-tuning examples based on difficulty scores predicted by pre-trained language models (PLMs) themselves. Building on these scores, we explore various training strategies that differ in the ordering of examples for the fine-tuning: from easy-to-hard, hard-to-easy, to mixed sampling. We evaluate our method on four natural language understanding (NLU) datasets covering both binary and multi-class classification tasks. Experimental results show that our approach leads to faster convergence and improved performance compared to standard random sampling.",
      "authors": [
        "Qi Feng",
        "Yihong Liu",
        "Hinrich Sch\\\"utze"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:36:17+00:00",
          "link": "https://arxiv.org/abs/2507.09758v1",
          "size": "190kb",
          "version": "v1"
        }
      ],
      "title": "Your Pretrained Model Tells the Difficulty Itself: A Self-Adaptive Curriculum Learning Paradigm for Natural Language Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09758",
        "HTML": "https://arxiv.org/html/2507.09758v1",
        "PDF": "https://arxiv.org/pdf/2507.09758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study discusses a self-adaptive curriculum learning paradigm for NLP but focuses on training strategies and difficulty metrics rather than significant LLM training data processing innovations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10208",
      "abstract": "Research into explainable artificial intelligence (XAI) for data analysis tasks suffer from a large number of contradictions and lack of concrete design recommendations stemming from gaps in understanding the tasks that require AI assistance. In this paper, we drew on multiple fields such as visual analytics, cognition, and dashboard design to propose a method for categorising and comparing XAI studies under three dimensions: what, why, and who. We identified the main problems as: inadequate descriptions of tasks, context-free studies, and insufficient testing with target users. We propose that studies should specifically report on their users' domain, AI, and data analysis expertise to illustrate the generalisability of their findings. We also propose study guidelines for designing and reporting XAI tasks to improve the XAI community's ability to parse the rapidly growing field. We hope that our contribution can help researchers and designers better identify which studies are most relevant to their work, what gaps exist in the research, and how to handle contradictory results regarding XAI design.",
      "authors": [
        "Hamzah Ziadeh",
        "Hendrik Knoche"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:26:45+00:00",
          "link": "https://arxiv.org/abs/2507.10208v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10208",
        "HTML": "https://arxiv.org/html/2507.10208v1",
        "PDF": "https://arxiv.org/pdf/2507.10208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on categorizing explainable AI studies using a data analysis framework and does not discuss any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.00700",
      "abstract": "Fine-tuning large pretrained Transformer models can focus on either introducing a small number of new learnable parameters (parameter efficiency) or editing representations of a small number of tokens using lightweight modules (representation efficiency). While the pioneering method LoRA (Low-Rank Adaptation) inherently balances parameter, compute, and memory efficiency, many subsequent variants trade off compute and memory efficiency and/or performance to further reduce fine-tuning parameters. To address this limitation and unify parameter-efficient and representation-efficient fine-tuning, we propose Weight-Generative Fine-Tuning (WeGeFT, pronounced wee-gift), a novel approach that learns to generate fine-tuning weights directly from the pretrained weights. WeGeFT employs a simple low-rank formulation consisting of two linear layers, either shared across multiple layers of the pretrained model or individually learned for different layers. This design achieves multi-faceted efficiency in parameters, representations, compute, and memory, while maintaining or exceeding the performance of LoRA and its variants. Extensive experiments on commonsense reasoning, arithmetic reasoning, instruction following, code generation, and visual recognition verify the effectiveness of our proposed WeGeFT. Our code is available at https://github.com/savadikarc/wegeft",
      "authors": [
        "Chinmay Savadikar",
        "Xi Song",
        "Tianfu Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-01T16:33:57+00:00",
          "link": "https://arxiv.org/abs/2312.00700v1",
          "size": "42202kb",
          "version": "v1"
        },
        {
          "date": "2024-06-03T17:57:39+00:00",
          "link": "https://arxiv.org/abs/2312.00700v2",
          "size": "4341kb",
          "version": "v2"
        },
        {
          "date": "2024-07-08T01:59:10+00:00",
          "link": "https://arxiv.org/abs/2312.00700v3",
          "size": "4347kb",
          "version": "v3"
        },
        {
          "date": "2024-10-07T17:40:32+00:00",
          "link": "https://arxiv.org/abs/2312.00700v4",
          "size": "4523kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T13:37:10+00:00",
          "link": "https://arxiv.org/abs/2312.00700v5",
          "size": "4656kb",
          "version": "v5"
        }
      ],
      "title": "WeGeFT: Weight-Generative Fine-Tuning for Multi-Faceted Efficient Adaptation of Large Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.00700",
        "HTML": "https://arxiv.org/html/2312.00700v5",
        "PDF": "https://arxiv.org/pdf/2312.00700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The content focuses on fine-tuning techniques for large models, specifically representation and parameter efficiency, without detailing any data processing techniques for LLM training data."
      },
      "tasks": [
        "Arithmetic Reasoning",
        "Fine-Grained Image Classification",
        "Instruction Following",
        "parameter-efficient fine-tuning",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/savadikarc/gift"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.18164",
      "abstract": "Tabular data is one of the most ubiquitous sources of information worldwide, spanning a wide variety of domains. This inherent heterogeneity has slowed the development of Tabular Foundation Models (TFMs) capable of fast generalization to unseen datasets. In-Context Learning (ICL) has recently emerged as a promising solution for TFMs, enabling dynamic adaptation to new tasks without additional tuning. While many studies have attempted to re-purpose large language models for tabular ICL, they have had limited success, so recent works have focused on developing tabular-specific foundation models. In this work, we propose an approach to combine ICL-based retrieval with self supervised learning to train tabular foundation models. We also investigate the utility of real vs. synthetic data for model pre-training, and show that real data can contain useful signal not easily captured in synthetic training. Specifically, we show that incorporating real data during the pre-training phase can lead to significantly faster training and better downstream generalization to unseen data. Our resulting model, TabDPT, achieves top performance on both regression (CTR23) and classification (CC18) benchmarks. Importantly, we also demonstrate that with our pre-training procedure, scaling both model and data size leads to consistent performance improvements that follow power laws. This echoes scaling laws in LLMs and other foundation models, and suggests that Internet-scale TFMs can be achievable. We open-source our full pipeline: inference code including trained model weights can be found at github.com/layer6ai-labs/TabDPT-inference, and the training code to reproduce experiments can be found at github.com/layer6ai-labs/TabDPT-training.",
      "authors": [
        "Junwei Ma",
        "Valentin Thomas",
        "Rasa Hosseinzadeh",
        "Hamidreza Kamkari",
        "Alex Labach",
        "Jesse C. Cresswell",
        "Keyvan Golestan",
        "Guangwei Yu",
        "Anthony L. Caterini",
        "Maksims Volkovs"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T18:00:00+00:00",
          "link": "https://arxiv.org/abs/2410.18164v1",
          "size": "388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T18:07:37+00:00",
          "link": "https://arxiv.org/abs/2410.18164v2",
          "size": "281kb",
          "version": "v2"
        }
      ],
      "title": "TabDPT: Scaling Tabular Foundation Models on Real Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18164",
        "HTML": "https://arxiv.org/html/2410.18164v2",
        "PDF": "https://arxiv.org/pdf/2410.18164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study mentions pre-training tabular foundation models using real and synthetic data, but its main focus is on model performance in tabular data rather than processing data for LLMs specifically."
      },
      "models": [
        {
          "model_path": "Layer6/TabDPT",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Layer6/TabDPT"
        }
      ],
      "tasks": [
        "In-Context Learning",
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://github.com/layer6ai-labs/TabDPT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.00947",
      "abstract": "Large Vision Language Models (LVLMs) have achieved remarkable performance in various vision-language tasks. However, it is still unclear how accurately LVLMs can perceive visual information in images. In particular, the capability of LVLMs to perceive geometric information, such as shape, angle, and size, remains insufficiently analyzed, although the perception of these properties is crucial for tasks that require a detailed visual understanding. In this work, we introduce VisOnlyQA, a dataset for evaluating the geometric perception of LVLMs, and reveal that LVLMs often cannot accurately perceive basic geometric information in images, while human performance is nearly perfect. VisOnlyQA consists of 12 tasks that directly ask about geometric information in geometric shapes, charts, chemical structures, and 3D shapes. Our experiments highlight the following findings: (i) State-of-the-art LVLMs struggle with basic geometric perception. 23 LVLMs we evaluate, including GPT-4o and Gemini 2.5 Pro, work poorly on VisOnlyQA. (ii) Additional training data does not resolve this issue. Fine-tuning on the training set of VisOnlyQA is not always effective, even for in-distribution tasks. (iii) LLM may be the bottleneck. LVLMs using stronger LLMs exhibit better geometric perception on VisOnlyQA, while it does not require complex reasoning, suggesting that the way LVLMs process information from visual encoders is a bottleneck. The datasets, code, and model responses are provided at https://github.com/psunlpgroup/VisOnlyQA.",
      "authors": [
        "Ryo Kamoi",
        "Yusen Zhang",
        "Sarkar Snigdha Sarathi Das",
        "Ranran Haoran Zhang",
        "Rui Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-01T19:46:22+00:00",
          "link": "https://arxiv.org/abs/2412.00947v1",
          "size": "7097kb",
          "version": "v1"
        },
        {
          "date": "2025-03-29T15:30:48+00:00",
          "link": "https://arxiv.org/abs/2412.00947v2",
          "size": "4582kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T22:29:38+00:00",
          "link": "https://arxiv.org/abs/2412.00947v3",
          "size": "4641kb",
          "version": "v3"
        }
      ],
      "title": "VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00947",
        "PDF": "https://arxiv.org/pdf/2412.00947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dataset and evaluates the geometric perception capabilities of vision-language models but does not mention processing or creation of LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "ryokamoi/VisOnlyQA_Eval_Synthetic",
          "downloads": "425",
          "likes": "2",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Synthetic"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_Train",
          "downloads": "765",
          "likes": "2",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Train"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_Eval_Real",
          "downloads": "130",
          "likes": "2",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_metadata",
          "downloads": "87",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_metadata"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_Eval_Real_v1.1",
          "downloads": "161",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real_v1.1"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_eval_analysis_2",
          "downloads": "2",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_2"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_eval_analysis_3",
          "downloads": "2",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_3"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_eval_analysis_4",
          "downloads": "2",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_4"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_eval_analysis_5",
          "downloads": "2",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_5"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_eval_analysis_6",
          "downloads": "2",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_eval_analysis_6"
        },
        {
          "dataset_name": "ryokamoi/VisOnlyQA_length_angle",
          "downloads": "3",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ryokamoi/VisOnlyQA_length_angle"
        }
      ],
      "tasks": [
        "Multiple-choice"
      ],
      "repo_urls": [
        "https://github.com/psunlpgroup/visonlyqa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12386",
      "abstract": "This paper aims to improve the performance of video multimodal large language models (MLLM) via long and rich context (LRC) modeling. As a result, we develop a new version of InternVideo2.5 with a focus on enhancing the original MLLMs' ability to perceive fine-grained details and capture long-form temporal structure in videos. Specifically, our approach incorporates dense vision task annotations into MLLMs using direct preference optimization and develops compact spatiotemporal representations through adaptive hierarchical token compression. Experimental results demonstrate this unique design of LRC greatly improves the results of video MLLM in mainstream video understanding benchmarks (short & long), enabling the MLLM to memorize significantly longer video inputs (at least 6x longer than the original), and master specialized vision capabilities like object tracking and segmentation. Our work highlights the importance of multimodal context richness (length and fineness) in empowering MLLM's innate abilites (focus and memory), providing new insights for future research on video MLLM. Code and models are available at https://github.com/OpenGVLab/InternVideo/tree/main/InternVideo2.5",
      "authors": [
        "Yi Wang",
        "Xinhao Li",
        "Ziang Yan",
        "Yinan He",
        "Jiashuo Yu",
        "Xiangyu Zeng",
        "Chenting Wang",
        "Changlian Ma",
        "Haian Huang",
        "Jianfei Gao",
        "Min Dou",
        "Kai Chen",
        "Wenhai Wang",
        "Yu Qiao",
        "Yali Wang",
        "Limin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T18:59:00+00:00",
          "link": "https://arxiv.org/abs/2501.12386v1",
          "size": "1401kb",
          "version": "v1"
        },
        {
          "date": "2025-01-22T12:08:20+00:00",
          "link": "https://arxiv.org/abs/2501.12386v2",
          "size": "1423kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T18:57:17+00:00",
          "link": "https://arxiv.org/abs/2501.12386v3",
          "size": "1411kb",
          "version": "v3"
        }
      ],
      "title": "InternVideo2.5: Empowering Video MLLMs with Long and Rich Context Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12386",
        "HTML": "https://arxiv.org/html/2501.12386v3",
        "PDF": "https://arxiv.org/pdf/2501.12386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving video multimodal large language models using long and rich context modeling. It does not discuss LLM training data processing or dataset creation."
      },
      "models": [
        {
          "model_path": "OpenGVLab/InternVideo2_5_Chat_8B",
          "downloads": "13849",
          "likes": "72",
          "trending_score": "2.0",
          "link": "https://huggingface.co/OpenGVLab/InternVideo2_5_Chat_8B"
        },
        {
          "model_path": "OpenGVLab/InternVL_2_5_HiCo_R16",
          "downloads": "4433",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/InternVL_2_5_HiCo_R16"
        },
        {
          "model_path": "OpenGVLab/InternVL_2_5_HiCo_R64",
          "downloads": "581",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/InternVL_2_5_HiCo_R64"
        },
        {
          "model_path": "FriendliAI/InternVL_2_5_HiCo_R16",
          "downloads": "24",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/FriendliAI/InternVL_2_5_HiCo_R16"
        }
      ],
      "tasks": [
        "Object Tracking",
        "Referring Expression Segmentation",
        "Referring Video Object Segmentation",
        "Video Understanding"
      ],
      "repo_urls": [
        "https://github.com/opengvlab/internvideo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07605",
      "abstract": "Federated Learning has emerged as a privacy-oriented alternative to centralized Machine Learning, enabling collaborative model training without direct data sharing. While extensively studied for neural networks, the security and privacy implications of tree-based models remain underexplored. This work introduces TimberStrike, an optimization-based dataset reconstruction attack targeting horizontally federated tree-based models. Our attack, carried out by a single client, exploits the discrete nature of decision trees by using split values and decision paths to infer sensitive training data from other clients. We evaluate TimberStrike on State-of-the-Art federated gradient boosting implementations across multiple frameworks, including Flower, NVFlare, and FedTree, demonstrating their vulnerability to privacy breaches. On a publicly available stroke prediction dataset, TimberStrike consistently reconstructs between 73.05% and 95.63% of the target dataset across all implementations. We further analyze Differential Privacy, showing that while it partially mitigates the attack, it also significantly degrades model performance. Our findings highlight the need for privacy-preserving mechanisms specifically designed for tree-based Federated Learning systems, and we provide preliminary insights into their design.",
      "authors": [
        "Marco Di Gennaro",
        "Giovanni De Lucia",
        "Stefano Longari",
        "Stefano Zanero",
        "Michele Carminati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T10:06:03+00:00",
          "link": "https://arxiv.org/abs/2506.07605v1",
          "size": "565kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T17:48:26+00:00",
          "link": "https://arxiv.org/abs/2506.07605v2",
          "size": "565kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T17:21:43+00:00",
          "link": "https://arxiv.org/abs/2506.07605v3",
          "size": "565kb",
          "version": "v3"
        }
      ],
      "title": "TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07605",
        "PDF": "https://arxiv.org/pdf/2506.07605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy leakage in Federated Learning for tree-based systems and does not address processing or creation of LLM training data."
      },
      "tasks": [
        "Federated Learning",
        "Privacy Preserving",
        "Reconstruction Attack"
      ],
      "repo_urls": [
        "https://github.com/necst/timberstrike"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09717",
      "abstract": "Real-world data is often represented through the relationships between data samples, forming a graph structure. In many applications, it is necessary to learn this graph structure from the observed data. Current graph learning research has primarily focused on unsigned graphs, which consist only of positive edges. However, many biological and social systems are better described by signed graphs that account for both positive and negative interactions, capturing similarity and dissimilarity between samples. In this paper, we develop a method for learning signed graphs from a set of smooth signed graph signals. Specifically, we employ the net Laplacian as a graph shift operator (GSO) to define smooth signed graph signals as the outputs of a low-pass signed graph filter defined by the net Laplacian. The signed graph is then learned by formulating a non-convex optimization problem where the total variation of the observed signals is minimized with respect to the net Laplacian. The proposed problem is solved using alternating direction method of multipliers (ADMM) and a fast algorithm reducing the per-ADMM iteration complexity from quadratic to linear in the number of nodes is introduced. Furthermore, theoretical proofs of convergence for the algorithm and a bound on the estimation error of the learned net Laplacian as a function of sample size, number of nodes, and graph topology are provided. Finally, the proposed method is evaluated on simulated data and gene regulatory network inference problem and compared to existing signed graph learning methods.",
      "authors": [
        "Abdullah Karaaslanli",
        "Bisakh Banerjee",
        "Tapabrata Maiti and Selin Aviyente"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:33:26+00:00",
          "link": "https://arxiv.org/abs/2507.09717v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Signed Graph Learning: Algorithms and Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09717",
        "HTML": "https://arxiv.org/html/2507.09717v1",
        "PDF": "https://arxiv.org/pdf/2507.09717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the learning of signed graph structures from data, focusing on graph signals rather than any aspects of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10052",
      "abstract": "Investment herding, a phenomenon where households mimic the decisions of others rather than relying on their own analysis, has significant effects on financial markets and household behavior. Excessive investment herding may reduce investments and lead to a depletion of household consumption, which is called the crowding-out effect. While existing research has qualitatively examined the impact of investment herding on consumption, quantitative studies in this area remain limited. In this work, we investigate the optimal investment and consumption decisions of households under the impact of investment herding. We formulate an optimization problem to model how investment herding influences household decisions over time. Based on the optimal control theory, we solve for the analytical solutions of optimal investment and consumption decisions. We theoretically analyze the impact of investment herding on household consumption decisions and demonstrate the existence of the crowding-out effect. We further explore how parameters, such as interest rate, excess return rate, and volatility, influence the crowding-out effect. Finally, we conduct a real data test to validate our theoretical analysis of the crowding-out effect. This study is crucial to understanding the impact of investment herding on household consumption and offering valuable insights for policymakers seeking to stimulate consumption and mitigate the negative effects of investment herding on economic growth.",
      "authors": [
        "Huisheng Wang",
        "H. Vicky Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Systems and Control (cs.SY)",
        "General Economics (econ.GN)",
        "Systems and Control (eess.SY)",
        "Economics (q-fin.EC)",
        "Mathematical Finance (q-fin.MF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:33:20+00:00",
          "link": "https://arxiv.org/abs/2507.10052v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "Analyzing the Crowding-Out Effect of Investment Herding on Consumption: An Optimal Control Theory Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10052",
        "HTML": "https://arxiv.org/html/2507.10052v1",
        "PDF": "https://arxiv.org/pdf/2507.10052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses investment herding and household consumption decisions, which are not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10530",
      "abstract": "Transition state (TS) structures define the critical geometries and energy barriers underlying chemical reactivity, yet their fleeting nature renders them experimentally elusive and drives the reliance on costly, high-throughput density functional theory (DFT) calculations. Here, we introduce TS-GEN, a conditional flow-matching generative model that maps samples from a simple Gaussian prior directly to transition-state saddle-point geometries in a single, deterministic pass. By embedding both reactant and product conformations as conditioning information, TS-GEN learns to transport latent noise to true TS structures via an optimal-transport path, effectively replacing the iterative optimization common in nudged-elastic band or string-method algorithms. TS-GEN delivers unprecedented accuracy, achieving a root-mean-square deviation of $0.004\\ \\rm{\\mathring{A}}$ (vs. $0.103\\ \\rm{\\mathring{A}}$ for prior state-of-the-art) and a mean barrier-height error of $1.019\\ {\\rm kcal/mol}$ (vs. $2.864\\ {\\rm kcal/mol}$), while requiring only $0.06\\ {\\rm s}$ GPU time per inference. Over 87% of generated TSs meet chemical-accuracy criteria ($<1.58\\ {\\rm kcal/mol}$ error), substantially outpacing existing methods. TS-GEN also exhibits strong transferability to out-of-distribution reactions from a larger database. By uniting sub-angstrom precision, sub-second speed, and broad applicability, TS-GEN will be highly useful for high-throughput exploration of complex reaction networks, paving the way to the exploration of novel chemical reaction mechanisms.",
      "authors": [
        "Ping Tuo",
        "Jiale Chen",
        "Ju Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:54:47+00:00",
          "link": "https://arxiv.org/abs/2507.10530v1",
          "size": "3986kb",
          "version": "v1"
        }
      ],
      "title": "Accurate generation of chemical reaction transition states by conditional flow matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10530",
        "HTML": "https://arxiv.org/html/2507.10530v1",
        "PDF": "https://arxiv.org/pdf/2507.10530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a generative model for predicting transition states in chemical reactions and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.09075",
      "abstract": "This work examines risk bounds for nonparametric distributional regression estimators. For convex-constrained distributional regression, general upper bounds are established for the continuous ranked probability score (CRPS) and the worst-case mean squared error (MSE) across the domain. These theoretical results are applied to isotonic and trend filtering distributional regression, yielding convergence rates consistent with those for mean estimation. Furthermore, a general upper bound is derived for distributional regression under non-convex constraints, with a specific application to neural network-based estimators. Comprehensive experiments on both simulated and real data validate the theoretical contributions, demonstrating their practical effectiveness.",
      "authors": [
        "Carlos Misael Madrid Padilla",
        "Oscar Hernan Madrid Padilla",
        "Sabyasachi Chatterjee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T02:22:12+00:00",
          "link": "https://arxiv.org/abs/2505.09075v1",
          "size": "5592kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T05:03:34+00:00",
          "link": "https://arxiv.org/abs/2505.09075v2",
          "size": "5593kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T22:57:43+00:00",
          "link": "https://arxiv.org/abs/2505.09075v3",
          "size": "5593kb",
          "version": "v3"
        }
      ],
      "title": "Risk Bounds For Distributional Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09075",
        "HTML": "https://arxiv.org/html/2505.09075v3",
        "PDF": "https://arxiv.org/pdf/2505.09075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores risk bounds for distributional regression models and does not discuss processing or creation of training data for LLMs."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08880",
      "abstract": "With the advancement of digital payment technologies, central banks worldwide have increasingly begun to explore the implementation of Central Bank Digital Currencies (CBDCs). This paper presents a comprehensive review of the latest developments in CBDC system design and implementation. By analyzing 135 research papers published between 2018 and 2025, the study provides an in-depth examination of CBDC design taxonomy and ecosystem frameworks. Grounded in the CBDC Design Pyramid, the paper refines and expands key architectural elements by thoroughly investigating innovations in ledger technologies, the selection of consensus mechanisms, and challenges associated with offline payments and digital wallet integration. Furthermore, it conceptualizes a CBDC ecosystem. A detailed comparative analysis of 26 existing CBDC systems is conducted across four dimensions: system architecture, ledger technology, access model, and application domain. The findings reveal that the most common configuration consists of a two-tier architecture, distributed ledger technology (DLT), and a token-based access model. However, no dominant trend has emerged regarding application domains. Notably, recent research shows a growing focus on leveraging CBDCs for cross-border payments to resolve inefficiencies and structural delays in current systems. Finally, the paper offers several forward-looking recommendations for future research.",
      "authors": [
        "Qifeng Tang and Yain-Whar Si"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:51:48+00:00",
          "link": "https://arxiv.org/abs/2507.08880v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "Central Bank Digital Currencies: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08880",
        "HTML": "https://arxiv.org/html/2507.08880v1",
        "PDF": "https://arxiv.org/pdf/2507.08880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys Central Bank Digital Currencies, focusing on system design and implementation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09315",
      "abstract": "In modern online services, frequent software changes introduce significant risks. To tackle this challenge, we propose SCELM (Software Change Evaluation and Lifecycle Management), an end-to-end automated framework for software change management. SCELM aims to manage software changes efficiently and precisely, significantly reducing service failures and economic losses.",
      "authors": [
        "Yongqian Sun",
        "Weihua Kuang",
        "Chao Shen",
        "Xidao Wen",
        "Tinghua Zheng",
        "Heng Liu",
        "Shenglin Zhang",
        "Bo Wu",
        "Dan Pei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:13:46+00:00",
          "link": "https://arxiv.org/abs/2507.09315v1",
          "size": "2529kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Interpretability in Software Change Management with Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09315",
        "HTML": "https://arxiv.org/html/2507.09315v1",
        "PDF": "https://arxiv.org/pdf/2507.09315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on software change management rather than anything related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09907",
      "abstract": "Agile methods are defined through guidelines comprising various practices intended to enable agile ways of working. These guidelines further comprise a specific set of agile practices aiming to enable teams for an agile way of working. However, due to its wide-spread use in practice we know that agile practices are adopted and tailored intensively, which lead to a high variety of agile practices in terms of their level of detail. Problem: A high variety of agile practices can be challenging as we do not know how different agile practices are interrelated with each other. To be more precise, tailoring and adopting agile practices may lead to the challenge, that the combinatorial use of several agile practices can only be successful to a limited extent, as practices support or even require each other for a effective use in practice. Objective: Our study aims to provide an enabler for this problem. We want to identify interrelations between agile practices and describe them in a systematic manner. Contribution: The core contribution of this paper is the Agile Map, a theoretical model describing relations between agile practices following a systematic approach aiming to provide an overview of coherences between agile practices. The model aims to support practitioners in selecting and combining agile practices in a meaningful way.",
      "authors": [
        "Thomas Hansper",
        "Kevin Phong Pham",
        "Michael Neumann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:28:37+00:00",
          "link": "https://arxiv.org/abs/2507.09907v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Modelling Interrelations Between Agile Practices: The Agile Map",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09907",
        "HTML": "https://arxiv.org/html/2507.09907v1",
        "PDF": "https://arxiv.org/pdf/2507.09907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus lies in modeling interrelations between agile practices and their application in agile work environments, without any specific reference to LLM training data or data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09925",
      "abstract": "Extracting cause and effect phrases from a sentence is an important NLP task, with numerous applications in various domains, including legal, medical, education, and scientific research. There are many unsupervised and supervised methods proposed for solving this task. Among these, unsupervised methods utilize various linguistic tools, including syntactic patterns, dependency tree, dependency relations, etc. among different sentential units for extracting the cause and effect phrases. On the other hand, the contemporary supervised methods use various deep learning based mask language models equipped with a token classification layer for extracting cause and effect phrases. Linguistic tools, specifically, dependency tree, which organizes a sentence into different semantic units have been shown to be very effective for extracting semantic pairs from a sentence, but existing supervised methods do not have any provision for utilizing such tools within their model framework. In this work, we propose DepBERT, which extends a transformer-based model by incorporating dependency tree of a sentence within the model framework. Extensive experiments over three datasets show that DepBERT is better than various state-of-the art supervised causality extraction methods.",
      "authors": [
        "Md Ahsanul Kabir",
        "Abrar Jahin",
        "Mohammad Al Hasan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:06:37+00:00",
          "link": "https://arxiv.org/abs/2507.09925v1",
          "size": "6835kb",
          "version": "v1"
        }
      ],
      "title": "Extracting Cause-Effect Pairs from a Sentence with a Dependency-Aware Transformer Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09925",
        "HTML": "https://arxiv.org/html/2507.09925v1",
        "PDF": "https://arxiv.org/pdf/2507.09925"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for extracting cause-effect pairs from sentences using a dependency-aware transformer model, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10057",
      "abstract": "Scientific paper retrieval, particularly framed as document-to-document retrieval, aims to identify relevant papers in response to a long-form query paper, rather than a short query string. Previous approaches to this task have focused on abstracts, embedding them into dense vectors as surrogates for full documents and calculating similarity across them, although abstracts provide only sparse and high-level summaries. To address this, we propose PRISM, a novel document-to-document retrieval method that introduces multiple, fine-grained representations for both the query and candidate papers. In particular, each query paper is decomposed into multiple aspect-specific views and individually embedded, which are then matched against candidate papers similarity segmented to consider their multifaceted dimensions. Moreover, we present SciFullBench, a novel benchmark in which the complete and segmented context of full papers for both queries and candidates is available. Then, experimental results show that PRISM improves performance by an average of 4.3% over existing retrieval baselines.",
      "authors": [
        "Sangwoo Park",
        "Jinheon Baek",
        "Soyeong Jeong",
        "Sung Ju Hwang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:41:53+00:00",
          "link": "https://arxiv.org/abs/2507.10057v1",
          "size": "328kb",
          "version": "v1"
        }
      ],
      "title": "PRISM: Fine-Grained Paper-to-Paper Retrieval with Multi-Aspect-Aware Query Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10057",
        "HTML": "https://arxiv.org/html/2507.10057v1",
        "PDF": "https://arxiv.org/pdf/2507.10057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses fine-grained paper retrieval optimization techniques and presents a new benchmark for paper retrieval, but does not address the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.03328",
      "abstract": "In this work, we introduce Brain Latent Progression (BrLP), a novel spatiotemporal disease progression model based on latent diffusion. BrLP is designed to predict the evolution of diseases at the individual level on 3D brain MRIs. Existing deep generative models developed for this task are primarily data-driven and face challenges in learning disease progressions. BrLP addresses these challenges by incorporating prior knowledge from disease models to enhance the accuracy of predictions. To implement this, we propose to integrate an auxiliary model that infers volumetric changes in various brain regions. Additionally, we introduce Latent Average Stabilization (LAS), a novel technique to improve spatiotemporal consistency of the predicted progression. BrLP is trained and evaluated on a large dataset comprising 11,730 T1-weighted brain MRIs from 2,805 subjects, collected from three publicly available, longitudinal Alzheimer's Disease (AD) studies. In our experiments, we compare the MRI scans generated by BrLP with the actual follow-up MRIs available from the subjects, in both cross-sectional and longitudinal settings. BrLP demonstrates significant improvements over existing methods, with an increase of 22% in volumetric accuracy across AD-related brain regions and 43% in image similarity to the ground-truth scans. The ability of BrLP to generate conditioned 3D scans at the subject level, along with the novelty of integrating prior knowledge to enhance accuracy, represents a significant advancement in disease progression modeling, opening new avenues for precision medicine. The code of BrLP is available at the following link: https://github.com/LemuelPuglisi/BrLP.",
      "authors": [
        "Lemuel Puglisi",
        "Daniel C. Alexander",
        "Daniele Rav\\`i"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-06T10:07:16+00:00",
          "link": "https://arxiv.org/abs/2405.03328v1",
          "size": "1642kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Spatiotemporal Disease Progression Models via Latent Diffusion and Prior Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.03328",
        "HTML": "https://arxiv.org/html/2405.03328",
        "PDF": "https://arxiv.org/pdf/2405.03328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a spatiotemporal disease progression model for brain MRIs; it does not address the processing or creation of LLM training data."
      },
      "models": [
        {
          "model_path": "radiata-ai/brain2vec",
          "downloads": "0",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/radiata-ai/brain2vec"
        },
        {
          "model_path": "radiata-ai/brain2vec-v2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/radiata-ai/brain2vec-v2"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/lemuelpuglisi/brlp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.08985",
      "abstract": "Retrieval-Augmented Generation (RAG) systems show remarkable potential as question answering tools in the K-12 Education domain, where knowledge is typically queried within the restricted scope of authoritative textbooks. However, discrepancies between these textbooks and the parametric knowledge inherent in Large Language Models (LLMs) can undermine the effectiveness of RAG systems. To systematically investigate RAG system robustness against such knowledge discrepancies, we introduce KnowShiftQA. This novel question answering dataset simulates these discrepancies by applying deliberate hypothetical knowledge updates to both answers and source documents, reflecting how textbook knowledge can shift. KnowShiftQA comprises 3,005 questions across five subjects, designed with a comprehensive question typology focusing on context utilization and knowledge integration. Our extensive experiments on retrieval and question answering performance reveal that most RAG systems suffer a substantial performance drop when faced with these knowledge discrepancies. Furthermore, questions requiring the integration of contextual (textbook) knowledge with parametric (LLM) knowledge pose a significant challenge to current LLMs.",
      "authors": [
        "Tianshi Zheng",
        "Weihan Li",
        "Jiaxin Bai",
        "Weiqi Wang",
        "Yangqiu Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T06:38:40+00:00",
          "link": "https://arxiv.org/abs/2412.08985v1",
          "size": "452kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T11:22:49+00:00",
          "link": "https://arxiv.org/abs/2412.08985v2",
          "size": "344kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T19:41:20+00:00",
          "link": "https://arxiv.org/abs/2412.08985v3",
          "size": "344kb",
          "version": "v3"
        }
      ],
      "title": "KnowShiftQA: How Robust are RAG Systems when Textbook Knowledge Shifts in K-12 Education?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.08985",
        "HTML": "https://arxiv.org/html/2412.08985v3",
        "PDF": "https://arxiv.org/pdf/2412.08985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces KnowShiftQA, a novel question answering dataset with specific processing steps to simulate textbook knowledge shifts, relevant to LLM training data processing."
      },
      "tasks": [
        "Question Answering",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.14379",
      "abstract": "Oriented object detection in aerial images poses a significant challenge due to their varying sizes and orientations. Current state-of-the-art detectors typically rely on either two-stage or one-stage approaches, often employing Anchor-based strategies, which can result in computationally expensive operations due to the redundant number of generated anchors during training. In contrast, Anchor-free mechanisms offer faster processing but suffer from a reduction in the number of training samples, potentially impacting detection accuracy. To address these limitations, we propose the Hybrid-Anchor Rotation Detector (HA-RDet), which combines the advantages of both anchor-based and anchor-free schemes for oriented object detection. By utilizing only one preset anchor for each location on the feature maps and refining these anchors with our Orientation-Aware Convolution technique, HA-RDet achieves competitive accuracies, including 75.41 mAP on DOTA-v1, 65.3 mAP on DIOR-R, and 90.2 mAP on HRSC2016, against current anchor-based state-of-the-art methods, while significantly reducing computational resources.",
      "authors": [
        "Phuc D.A. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T22:26:15+00:00",
          "link": "https://arxiv.org/abs/2412.14379v1",
          "size": "1279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T08:58:43+00:00",
          "link": "https://arxiv.org/abs/2412.14379v2",
          "size": "1275kb",
          "version": "v2"
        }
      ],
      "title": "HA-RDet: Hybrid Anchor Rotation Detector for Oriented Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14379",
        "HTML": "https://arxiv.org/html/2412.14379v2",
        "PDF": "https://arxiv.org/pdf/2412.14379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing object detection methods using a hybrid anchor technique, and does not discuss LLM training data processing or creation."
      },
      "tasks": [
        "object-detection",
        "Object Detection",
        "Object Detection In Aerial Images",
        "Oriented Object Detection"
      ],
      "repo_urls": [
        "https://github.com/phucnda/ha-rdet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13554",
      "abstract": "Many studies suggest that LLMs have left wing leans. The article extends previous analysis of US presidential elections considering several virtual elections in multiple European countries. The analysis considers multiple LLMs and the results confirm the extent of the leaning. Furthermore, the results show that the leaning is not uniform between countries. Sometimes, models refuse to take a position in the virtual elections, but the refusal rate itself is not uniform between countries.",
      "authors": [
        "Federico Ricciuti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T20:17:11+00:00",
          "link": "https://arxiv.org/abs/2503.13554v1",
          "size": "13kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T12:15:19+00:00",
          "link": "https://arxiv.org/abs/2503.13554v2",
          "size": "12kb",
          "version": "v2"
        }
      ],
      "title": "LLMs' Leaning in European Elections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13554",
        "HTML": "https://arxiv.org/html/2503.13554v2",
        "PDF": "https://arxiv.org/pdf/2503.13554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the political leaning of LLMs in European elections but does not involve the creation or processing of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.11130",
      "abstract": "This paper demonstrates that in classification problems, fully connected neural networks (FCNs) and residual neural networks (ResNets) cannot be approximated by kernel logistic regression based on the Neural Tangent Kernel (NTK) under overtraining (i.e., when training time approaches infinity). Specifically, when using the cross-entropy loss, regardless of how large the network width is (as long as it is finite), the empirical NTK diverges from the NTK on the training samples as training time increases. To establish this result, we first demonstrate the strictly positive definiteness of the NTKs for multi-layer FCNs and ResNets. Then, we prove that during training, % with the cross-entropy loss, the neural network parameters diverge if the smallest eigenvalue of the empirical NTK matrix (Gram matrix) with respect to training samples is bounded below by a positive constant. This behavior contrasts sharply with the lazy training regime commonly observed in regression problems. Consequently, using a proof by contradiction, we show that the empirical NTK does not uniformly converge to the NTK across all times on the training samples as the network width increases. We validate our theoretical results through experiments on both synthetic data and the MNIST classification task. This finding implies that NTK theory is not applicable in this context, with significant theoretical implications for understanding neural networks in classification problems.",
      "authors": [
        "Zixiong Yu",
        "Songtao Tian and Guhan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T12:30:21+00:00",
          "link": "https://arxiv.org/abs/2504.11130v1",
          "size": "1543kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T21:59:44+00:00",
          "link": "https://arxiv.org/abs/2504.11130v2",
          "size": "509kb",
          "version": "v2"
        }
      ],
      "title": "Divergence of Empirical Neural Tangent Kernel in Classification Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11130",
        "HTML": "https://arxiv.org/html/2504.11130v2",
        "PDF": "https://arxiv.org/pdf/2504.11130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses theoretical results about Neural Tangent Kernel behavior in neural networks, without addressing LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.11775",
      "abstract": "Fairness has emerged as a critical consideration in the landscape of machine learning algorithms, particularly as AI continues to transform decision-making across societal domains. To ensure that these algorithms are free from bias and do not discriminate against individuals based on sensitive attributes such as gender and race, the field of algorithmic bias has introduced various fairness concepts, along with methodologies to achieve these notions in different contexts. Despite the rapid advancement, not all sectors have embraced these fairness principles to the same extent. One specific sector that merits attention in this regard is insurance. Within the realm of insurance pricing, fairness is defined through a distinct and specialized framework. Consequently, achieving fairness according to established notions does not automatically ensure fair pricing in insurance. In particular, regulators are increasingly emphasizing transparency in pricing algorithms and imposing constraints on insurance companies on the collection and utilization of sensitive consumer attributes. These factors present additional challenges in the implementation of fairness in pricing algorithms. To address these complexities and comply with regulatory demands, we propose an efficient method for constructing fair models that are tailored to the insurance domain, using only privatized sensitive attributes. Notably, our approach ensures statistical guarantees, does not require direct access to sensitive attributes, and adapts to varying transparency requirements, addressing regulatory demands while ensuring fairness in insurance pricing.",
      "authors": [
        "Tianhe Zhang",
        "Suhan Liu",
        "Peng Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T05:29:11+00:00",
          "link": "https://arxiv.org/abs/2504.11775v1",
          "size": "7439kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:40:20+00:00",
          "link": "https://arxiv.org/abs/2504.11775v2",
          "size": "2852kb",
          "version": "v2"
        }
      ],
      "title": "Discrimination-free Insurance Pricing with Privatized Sensitive Attributes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11775",
        "HTML": "https://arxiv.org/html/2504.11775v2",
        "PDF": "https://arxiv.org/pdf/2504.11775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses fairness in insurance pricing algorithms using privatized sensitive attributes, with no focus on LLM training data processing techniques or methodologies."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09549",
      "abstract": "Prototyping is widely regarded in Human-Computer Interaction as an iterative process through which ideas are tested and refined, often via visual mockups, screen flows, and coded simulations. This position paper critiques the visual-centric norms embedded in prototyping culture by drawing from the lived experiences of blind scholars and insights from cultural disability studies. It discusses how dominant methods of prototyping rely on an unexamined fidelity to sight, privileging what can be rendered visibly coherent while marginalizing other modes of knowing and making. By repositioning prototyping as a situated, embodied, and relational practice, this paper challenges HCI to rethink what kinds of design participation are legitimized and which are excluded when prototyping is reduced to screen-based simulations.",
      "authors": [
        "Hrittika Bhowmick",
        "Shilpaa Anand"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T09:25:19+00:00",
          "link": "https://arxiv.org/abs/2507.09549v1",
          "size": "54kb",
          "version": "v1"
        }
      ],
      "title": "The Spectacle of Fidelity: Blind Resistance and the Wizardry of Prototyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09549",
        "HTML": "https://arxiv.org/html/2507.09549v1",
        "PDF": "https://arxiv.org/pdf/2507.09549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper critiques prototyping practices in HCI from a disability studies perspective. There is no discussion of LLM training data or related processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10034",
      "abstract": "Point cloud place recognition (PCPR) plays a crucial role in photogrammetry and robotics applications such as autonomous driving, intelligent transportation, and augmented reality. In real-world large-scale deployments of a positioning system, PCPR models must continuously acquire, update, and accumulate knowledge to adapt to diverse and dynamic environments, i.e., the ability known as continual learning (CL). However, existing PCPR models often suffer from catastrophic forgetting, leading to significant performance degradation in previously learned scenes when adapting to new environments or sensor types. This results in poor model scalability, increased maintenance costs, and system deployment difficulties, undermining the practicality of PCPR. To address these issues, we propose LifelongPR, a novel continual learning framework for PCPR, which effectively extracts and fuses knowledge from sequential point cloud data. First, to alleviate the knowledge loss, we propose a replay sample selection method that dynamically allocates sample sizes according to each dataset's information quantity and selects spatially diverse samples for maximal representativeness. Second, to handle domain shifts, we design a prompt learning-based CL framework with a lightweight prompt module and a two-stage training strategy, enabling domain-specific feature adaptation while minimizing forgetting. Comprehensive experiments on large-scale public and self-collected datasets are conducted to validate the effectiveness of the proposed method. Compared with state-of-the-art (SOTA) methods, our method achieves 6.50% improvement in mIR@1, 7.96% improvement in mR@1, and an 8.95% reduction in F. The code and pre-trained models are publicly available at https://github.com/zouxianghong/LifelongPR.",
      "authors": [
        "Xianghong Zou",
        "Jianping Li",
        "Zhe Chen",
        "Zhen Cao",
        "Zhen Dong",
        "Qiegen Liu",
        "Bisheng Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:13:33+00:00",
          "link": "https://arxiv.org/abs/2507.10034v1",
          "size": "9069kb",
          "version": "v1"
        }
      ],
      "title": "LifelongPR: Lifelong knowledge fusion for point cloud place recognition based on replay and prompt learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10034",
        "HTML": "https://arxiv.org/html/2507.10034v1",
        "PDF": "https://arxiv.org/pdf/2507.10034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses continual learning in point cloud place recognition using replay and prompt learning, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10044",
      "abstract": "Medical images often contain multiple labels with imbalanced distributions and co-occurrence, leading to bias in multi-label medical image classification. Close collaboration between medical professionals and machine learning practitioners has significantly advanced medical image analysis. However, traditional collaboration modes struggle to facilitate effective feedback between physicians and AI models, as integrating medical expertise into the training process via engineers can be time-consuming and labor-intensive. To bridge this gap, we introduce MEDebiaser, an interactive system enabling physicians to directly refine AI models using local explanations. By combining prediction with attention loss functions and employing a customized ranking strategy to alleviate scalability, MEDebiaser allows physicians to mitigate biases without technical expertise, reducing reliance on engineers, and thus enhancing more direct human-AI feedback. Our mechanism and user studies demonstrate that it effectively reduces biases, improves usability, and enhances collaboration efficiency, providing a practical solution for integrating medical expertise into AI-driven healthcare.",
      "authors": [
        "Shaohan Shi",
        "Yuheng Shao",
        "Haoran Jiang",
        "Yunjie Yao",
        "Zhijun Zhang",
        "Xu Ding",
        "Quan Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:21:48+00:00",
          "link": "https://arxiv.org/abs/2507.10044v1",
          "size": "11585kb",
          "version": "v1"
        }
      ],
      "title": "MEDebiaser: A Human-AI Feedback System for Mitigating Bias in Multi-label Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10044",
        "HTML": "https://arxiv.org/html/2507.10044v1",
        "PDF": "https://arxiv.org/pdf/2507.10044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a system for mitigating bias in medical image classification, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10177",
      "abstract": "Although Large Language Models (LLMs) have demonstrated significant advancements in natural language processing tasks, their effectiveness in the classification and transformation of abusive text into non-abusive versions remains an area for exploration. In this study, we aim to use LLMs to transform abusive text (tweets and reviews) featuring hate speech and swear words into non-abusive text, while retaining the intent of the text. We evaluate the performance of two state-of-the-art LLMs, such as Gemini, GPT-4o, DeekSeek and Groq, on their ability to identify abusive text. We them to transform and obtain a text that is clean from abusive and inappropriate content but maintains a similar level of sentiment and semantics, i.e. the transformed text needs to maintain its message. Afterwards, we evaluate the raw and transformed datasets with sentiment analysis and semantic analysis. Our results show Groq provides vastly different results when compared with other LLMs. We have identified similarities between GPT-4o and DeepSeek-V3.",
      "authors": [
        "Rohitash Chandra and Jiyong Choi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:39:34+00:00",
          "link": "https://arxiv.org/abs/2507.10177v1",
          "size": "4059kb",
          "version": "v1"
        }
      ],
      "title": "Abusive text transformation using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10177",
        "HTML": "https://arxiv.org/html/2507.10177v1",
        "PDF": "https://arxiv.org/pdf/2507.10177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses transforming abusive text using LLMs, effectively creating a new processed dataset that maintains sentiment and semantics, relevant to LLM training data modification and quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.08142",
      "abstract": "Shadows significantly hinder computer vision tasks in outdoor environments, particularly in field robotics, where varying lighting conditions complicate object detection and localisation. We present FieldNet, a novel deep learning framework for real-time shadow removal, optimised for resource-constrained hardware. FieldNet introduces a probabilistic enhancement module and a novel loss function to address challenges of inconsistent shadow boundary supervision and artefact generation, achieving enhanced accuracy and simplicity without requiring shadow masks during inference. Trained on a dataset of 10,000 natural images augmented with synthetic shadows, FieldNet outperforms state-of-the-art methods on benchmark datasets (ISTD, ISTD+, SRD), with up to $9$x speed improvements (66 FPS on Nvidia 2080Ti) and superior shadow removal quality (PSNR: 38.67, SSIM: 0.991). Real-world case studies in precision agriculture robotics demonstrate the practical impact of FieldNet in enhancing weed detection accuracy. These advancements establish FieldNet as a robust, efficient solution for real-time vision tasks in field robotics and beyond.",
      "authors": [
        "Alzayat Saleh",
        "Alex Olsen",
        "Jake Wood",
        "Bronson Philippa",
        "Mostafa Rahimi Azghadi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-13T00:04:07+00:00",
          "link": "https://arxiv.org/abs/2403.08142v1",
          "size": "7955kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T00:48:48+00:00",
          "link": "https://arxiv.org/abs/2403.08142v2",
          "size": "11633kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T01:27:10+00:00",
          "link": "https://arxiv.org/abs/2403.08142v3",
          "size": "10217kb",
          "version": "v3"
        }
      ],
      "title": "FieldNet: Efficient Real-Time Shadow Removal for Enhanced Vision in Field Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08142",
        "HTML": "https://arxiv.org/html/2403.08142v3",
        "PDF": "https://arxiv.org/pdf/2403.08142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a real-time shadow removal framework for field robotics, with no focus on LLM training data processing."
      },
      "tasks": [
        "Edge-computing",
        "object-detection",
        "Object Detection",
        "Shadow Removal",
        "SSIM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17805",
      "abstract": "Federated Learning (FL) enables collaborative learning without exposing clients' data. While clients only share model updates with the aggregator, studies reveal that aggregators can infer sensitive information from these updates. Secure Aggregation (SA) protects individual updates during transmission; however, recent work demonstrates a critical vulnerability where adversarial aggregators manipulate client selection to bypass SA protections, constituting a Biased Selection Attack (BSA). Although verifiable random selection prevents BSA, it precludes informed client selection essential for FL performance. We propose Adversarial Robust Federated Learning (AdRo-FL), which simultaneously enables: informed client selection based on client utility, and robust defense against BSA maintaining privacy-preserving aggregation. AdRo-FL implements two client selection frameworks tailored for distinct settings. The first framework assumes clients are grouped into clusters based on mutual trust, such as different branches of an organization. The second framework handles distributed clients where no trust relationships exist between them. For the cluster-oriented setting, we propose a novel defense against BSA by (1) enforcing a minimum client selection quota from each cluster, supervised by a cluster-head in every round, and (2) introducing a client utility function to prioritize efficient clients. For the distributed setting, we design a two-phase selection protocol: first, the aggregator selects the top clients based on our utility-driven ranking; then, a verifiable random function (VRF) ensures a BSA-resistant final selection. AdRo-FL also applies quantization to reduce communication overhead and sets strict transmission deadlines to improve energy efficiency. AdRo-FL achieves up to $1.85\\times$ faster time-to-accuracy and up to $1.06\\times$ higher final accuracy compared to insecure baselines.",
      "authors": [
        "Md. Kamrul Hossain",
        "Walid Aljoby",
        "Anis Elgabli",
        "Ahmed M. Abdelmoniem",
        "Khaled A. Harras"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T20:23:28+00:00",
          "link": "https://arxiv.org/abs/2506.17805v1",
          "size": "4694kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T06:28:00+00:00",
          "link": "https://arxiv.org/abs/2506.17805v2",
          "size": "4694kb",
          "version": "v2"
        }
      ],
      "title": "AdRo-FL: Informed and Secure Client Selection for Federated Learning in the Presence of Adversarial Aggregator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17805",
        "HTML": "https://arxiv.org/html/2506.17805v2",
        "PDF": "https://arxiv.org/pdf/2506.17805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses federated learning with a focus on client selection and security, without a focus on processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09100",
      "abstract": "In decision-making conversations, experts must navigate complex choices and make on-the-spot decisions while engaged in conversation. Although extensive historical data often exists, the real-time nature of these scenarios makes it infeasible for decision-makers to review and leverage relevant information. This raises an interesting question: What if experts could utilize relevant past data in real-time decision-making through insights derived from past data? To explore this, we implemented a conversational user interface, taking doctor-patient interactions as an example use case. Our system continuously listens to the conversation, identifies patient problems and doctor-suggested solutions, and retrieves related data from an embedded dataset, generating concise insights using a pipeline built around a retrieval-based Large Language Model (LLM) agent. We evaluated the prototype by embedding Health Canada datasets into a vector database and conducting simulated studies using sample doctor-patient dialogues, showing effectiveness but also challenges, setting directions for the next steps of our work.",
      "authors": [
        "Mohammad Abolnejadian",
        "Shakiba Amirshahi",
        "Matthew Brehmer",
        "Anamaria Crisan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:59:41+00:00",
          "link": "https://arxiv.org/abs/2507.09100v1",
          "size": "4227kb",
          "version": "v1"
        }
      ],
      "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09100",
        "HTML": "https://arxiv.org/html/2507.09100v1",
        "PDF": "https://arxiv.org/pdf/2507.09100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a system for incorporating historical data into decision-making conversations using a retrieval-based LLM, but does not focus on specific methodologies for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09310",
      "abstract": "Text-to-Speech (TTS) systems in Lombard speaking style can improve the overall intelligibility of speech, useful for hearing loss and noisy conditions. However, training those models requires a large amount of data and the Lombard effect is challenging to record due to speaker and noise variability and tiring recording conditions. Voice conversion (VC) has been shown to be a useful augmentation technique to train TTS systems in the absence of recorded data from the target speaker in the target speaking style. In this paper, we are concerned with Lombard speaking style transfer. Our goal is to convert speaker identity while preserving the acoustic attributes that define the Lombard speaking style. We compare voice conversion models with implicit and explicit acoustic feature conditioning. We observe that our proposed implicit conditioning strategy achieves an intelligibility gain comparable to the model conditioned on explicit acoustic features, while also preserving speaker similarity.",
      "authors": [
        "Dominika Woszczyk",
        "Manuel Sam Ribeiro",
        "Thomas Merritt",
        "Daniel Korzekwa"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:57:04+00:00",
          "link": "https://arxiv.org/abs/2507.09310v1",
          "size": "622kb",
          "version": "v1"
        }
      ],
      "title": "Voice Conversion for Lombard Speaking Style with Implicit and Explicit Acoustic Feature Conditioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09310",
        "HTML": "https://arxiv.org/html/2507.09310v1",
        "PDF": "https://arxiv.org/pdf/2507.09310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered on voice conversion for text-to-speech systems with a specific focus on Lombard speaking style, without involving any LLM training data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.06122",
      "abstract": "Recent advances in automated theorem proving (ATP) through LLMs have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entire posttraining of ATP, aiming to align it with breakthroughs in reasoning models in natural languages. To begin, we continual train current ATP models with a hybrid dataset, which consists of numerous statement-proof pairs, and additional data aimed at incorporating cognitive behaviors that emulate human reasoning and hypothesis refinement. Next, we explore reinforcement learning with the use of outcome reward returned by Lean 4 compiler. Through our designed continual training and reinforcement learning processes, we have successfully improved existing formal provers, including both DeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance in the field of whole-proof generation. For example, we achieve a 59.8% pass rate (pass@32) on MiniF2F. This is an on-going project and we will progressively update our findings, release our data and training details.",
      "authors": [
        "Jingyuan Zhang",
        "Qi Wang",
        "Xingguang Ji",
        "Yahui Liu",
        "Yang Yue",
        "Fuzheng Zhang",
        "Di Zhang",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T15:15:26+00:00",
          "link": "https://arxiv.org/abs/2504.06122v1",
          "size": "407kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T04:03:00+00:00",
          "link": "https://arxiv.org/abs/2504.06122v2",
          "size": "103kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T04:41:15+00:00",
          "link": "https://arxiv.org/abs/2504.06122v3",
          "size": "103kb",
          "version": "v3"
        }
      ],
      "title": "Leanabell-Prover: Posttraining Scaling in Formal Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06122",
        "HTML": "https://arxiv.org/html/2504.06122v3",
        "PDF": "https://arxiv.org/pdf/2504.06122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The primary focus is on posttraining scaling with reinforcement learning in automated theorem proving, touching upon dataset creation. However, it does not mainly contribute to LLM training data processing."
      },
      "tasks": [
        "Automated Theorem Proving",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/leanabell-lm/leanabell-prover"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.11183",
      "abstract": "Social bias in language models can potentially exacerbate social inequalities. Despite it having garnered wide attention, most research focuses on English data. In a low-resource scenario, the models often perform worse due to insufficient training data. This study aims to leverage high-resource language corpora to evaluate bias and experiment with debiasing methods in low-resource languages. We evaluated the performance of recent multilingual models in five languages: English, Chinese, Russian, Indonesian and Thai, and analyzed four bias dimensions: gender, religion, nationality, and race-color. By constructing multilingual bias evaluation datasets, this study allows fair comparisons between models across languages. We have further investigated three debiasing methods-CDA, Dropout, SenDeb-and demonstrated that debiasing methods from high-resource languages can be effectively transferred to low-resource ones, providing actionable insights for fairness research in multilingual NLP.",
      "authors": [
        "Ej Zhou",
        "Weiming Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T13:40:22+00:00",
          "link": "https://arxiv.org/abs/2504.11183v1",
          "size": "2319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:35:01+00:00",
          "link": "https://arxiv.org/abs/2504.11183v2",
          "size": "2319kb",
          "version": "v2"
        }
      ],
      "title": "Bias Beyond English: Evaluating Social Bias and Debiasing Methods in a Low-Resource Setting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11183",
        "HTML": "https://arxiv.org/html/2504.11183v2",
        "PDF": "https://arxiv.org/pdf/2504.11183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper evaluates bias and debiasing methods in multilingual models, it does not focus on the creation or processing of LLM training datasets."
      },
      "tasks": [
        "Fairness",
        "Multilingual NLP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00200",
      "abstract": "Radiology reports are critical for clinical decision-making but often lack a standardized format, limiting both human interpretability and machine learning (ML) applications. While large language models (LLMs) have shown strong capabilities in reformatting clinical text, their high computational requirements, lack of transparency, and data privacy concerns hinder practical deployment. To address these challenges, we explore lightweight encoder-decoder models (<300M parameters)-specifically T5 and BERT2BERT-for structuring radiology reports from the MIMIC-CXR and CheXpert Plus datasets. We benchmark these models against eight open-source LLMs (1B-70B), adapted using prefix prompting, in-context learning (ICL), and low-rank adaptation (LoRA) finetuning. Our best-performing lightweight model outperforms all LLMs adapted using prompt-based techniques on a human-annotated test set. While some LoRA-finetuned LLMs achieve modest gains over the lightweight model on the Findings section (BLEU 6.4%, ROUGE-L 4.8%, BERTScore 3.6%, F1-RadGraph 1.1%, GREEN 3.6%, and F1-SRR-BERT 4.3%), these improvements come at the cost of substantially greater computational resources. For example, LLaMA-3-70B incurred more than 400 times the inference time, cost, and carbon emissions compared to the lightweight model. These results underscore the potential of lightweight, task-specific models as sustainable and privacy-preserving solutions for structuring clinical text in resource-constrained healthcare settings.",
      "authors": [
        "Johannes Moll",
        "Louisa Fay",
        "Asfandyar Azhar",
        "Sophie Ostmeier",
        "Tim Lueth",
        "Sergios Gatidis",
        "Curtis Langlotz",
        "Jean-Benoit Delbrouck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T20:12:51+00:00",
          "link": "https://arxiv.org/abs/2506.00200v1",
          "size": "1667kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:19:59+00:00",
          "link": "https://arxiv.org/abs/2506.00200v2",
          "size": "1667kb",
          "version": "v2"
        }
      ],
      "title": "Structuring Radiology Reports: Challenging LLMs with Lightweight Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00200",
        "HTML": "https://arxiv.org/html/2506.00200v2",
        "PDF": "https://arxiv.org/pdf/2506.00200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on leveraging lightweight models for structuring radiology reports, with no substantive discussion on processing or creating LLM training data."
      },
      "models": [
        {
          "model_path": "StanfordAIMI/SRR-BERT2BERT-RoBERTa-base",
          "downloads": "13",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RoBERTa-base"
        },
        {
          "model_path": "StanfordAIMI/SRR-T5-Flan",
          "downloads": "22",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-T5-Flan"
        },
        {
          "model_path": "StanfordAIMI/SRR-T5-Base",
          "downloads": "28",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-T5-Base"
        },
        {
          "model_path": "StanfordAIMI/SRR-T5-SciFive",
          "downloads": "35",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-T5-SciFive"
        },
        {
          "model_path": "StanfordAIMI/SRR-BERT2BERT-RadBERT",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RadBERT"
        },
        {
          "model_path": "StanfordAIMI/SRR-BERT2BERT-RoBERTa-biomed",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RoBERTa-biomed"
        },
        {
          "model_path": "StanfordAIMI/SRR-BERT2BERT-RoBERTa-PM-M3",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/StanfordAIMI/SRR-BERT2BERT-RoBERTa-PM-M3"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16793",
      "abstract": "A linear code with parameters $[n, k, n - k + 1]$ is called maximum distance separable (MDS), and one with parameters $[n, k, n - k]$ is called almost MDS (AMDS). A code is near-MDS (NMDS) if both it and its dual are AMDS. NMDS codes supporting combinatorial $t$-designs have attracted growing interest, yet constructing such codes remains highly challenging. In 2020, Ding and Tang initiated the study of NMDS codes supporting 2-designs by constructing the first infinite family, followed by several other constructions for $t > 2$, all with length at most $q + 1$. Although NMDS codes can, in principle, exceed this length, known examples supporting 2-designs and having length greater than $q + 1$ are extremely rare and limited to a few sporadic binary and ternary cases. In this paper, we present the first \\emph{generic construction} of $q$-ary NMDS codes supporting 2-designs with lengths \\emph{exceeding $q + 1$}. Our method leverages new connections between elliptic curve codes, finite abelian groups, subset sums, and combinatorial designs, resulting in an infinite family of such codes along with their weight distributions.",
      "authors": [
        "Hengfeng Liu",
        "Chunming Tang",
        "Zhengchun Zhou",
        "Dongchun Han",
        "Hao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T07:17:17+00:00",
          "link": "https://arxiv.org/abs/2506.16793v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T03:40:05+00:00",
          "link": "https://arxiv.org/abs/2506.16793v2",
          "size": "22kb",
          "version": "v2"
        }
      ],
      "title": "A Generic Construction of $q$-ary Near-MDS Codes Supporting 2-Designs with Lengths Beyond $q+1$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16793",
        "HTML": "https://arxiv.org/html/2506.16793v2",
        "PDF": "https://arxiv.org/pdf/2506.16793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a construction of mathematical codes with specific properties, which does not pertain to LLM training data processing or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08854",
      "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is a central characterization method for molecular structure elucidation, yet interpreting NMR spectra to deduce molecular structures remains challenging due to the complexity of spectral data and the vastness of the chemical space. In this work, we introduce DiffNMR, a novel end-to-end framework that leverages a conditional discrete diffusion model for de novo molecular structure elucidation from NMR spectra. DiffNMR refines molecular graphs iteratively through a diffusion-based generative process, ensuring global consistency and mitigating error accumulation inherent in autoregressive methods. The framework integrates a two-stage pretraining strategy that aligns spectral and molecular representations via diffusion autoencoder (Diff-AE) and contrastive learning, the incorporation of retrieval initialization and similarity filtering during inference, and a specialized NMR encoder with radial basis function (RBF) encoding for chemical shifts, preserving continuity and chemical correlation. Experimental results demonstrate that DiffNMR achieves competitive performance for NMR-based structure elucidation, offering an efficient and robust solution for automated molecular analysis.",
      "authors": [
        "Qingsong Yang",
        "Binglan Wu",
        "Xuwei Liu",
        "Bo Chen",
        "Wei Li",
        "Gen Long",
        "Xin Chen",
        "Mingjun Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:21:36+00:00",
          "link": "https://arxiv.org/abs/2507.08854v1",
          "size": "775kb",
          "version": "v1"
        }
      ],
      "title": "DiffNMR: Diffusion Models for Nuclear Magnetic Resonance Spectra Elucidation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08854",
        "HTML": "https://arxiv.org/html/2507.08854v1",
        "PDF": "https://arxiv.org/pdf/2507.08854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the use of diffusion models for interpreting NMR spectra for molecular structure elucidation, without discussing any processes related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08855",
      "abstract": "Alzheimer's Disease (AD) is an irreversible neurodegenerative disease characterized by progressive cognitive decline as its main symptom. In the research field of deep learning-assisted diagnosis of AD, traditional convolutional neural networks and simple feature concatenation methods fail to effectively utilize the complementary information between multimodal data, and the simple feature concatenation approach is prone to cause the loss of key information during the process of modal fusion. In recent years, the development of deep learning technology has brought new possibilities for solving the problem of how to effectively fuse multimodal features. This paper proposes a novel deep learning algorithm framework to assist medical professionals in AD diagnosis. By fusing medical multi-view information such as brain fluorodeoxyglucose positron emission tomography (PET), magnetic resonance imaging (MRI), genetic data, and clinical data, it can accurately detect the presence of AD, Mild Cognitive Impairment (MCI), and Cognitively Normal (CN). The innovation of the algorithm lies in the use of an asymmetric cross-modal cross-attention mechanism, which can effectively capture the key information features of the interactions between different data modal features. This paper compares the asymmetric cross-modal cross-attention mechanism with the traditional algorithm frameworks of unimodal and multimodal deep learning models for AD diagnosis, and evaluates the importance of the asymmetric cross-modal cross-attention mechanism. The algorithm model achieves an accuracy of 94.88% on the test set.",
      "authors": [
        "Yang Ming",
        "Jiang Shi Zhong",
        "Zhou Su Juan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:12:38+00:00",
          "link": "https://arxiv.org/abs/2507.08855v1",
          "size": "2395kb",
          "version": "v1"
        }
      ],
      "title": "Multi-omic Prognosis of Alzheimer's Disease with Asymmetric Cross-Modal Cross-Attention Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08855",
        "HTML": "https://arxiv.org/html/2507.08855v1",
        "PDF": "https://arxiv.org/pdf/2507.08855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a deep learning framework for Alzheimer\u2019s Disease prognosis using multi-modal data fusion, but does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09594",
      "abstract": "Design is a fundamental aspect of engineering, enabling the creation of products, systems, and organizations to meet societal and/or business needs. However, the absence of a scientific foundation in design often results in subjective decision-making, reducing both efficiency and innovation. This challenge is particularly evident in the software industry and, by extension, in the domain of industrial control and automation systems (iCAS).\n  In this study, first we review the existing design definitions within the software industry, challenge prevailing misconceptions about design, review design definition in the field of design theory and address key questions such as: When does design begin? How can design be defined scientifically? What constitutes good design? and the difference between design and design language by relying on advancements in the field of design theory. We also evaluate the distinction between ad-hoc and systematic design approaches, and present arguments on how to balance complementary operational concerns while resolving conflicting evolutionary concerns.",
      "authors": [
        "Aydin Homay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:50:43+00:00",
          "link": "https://arxiv.org/abs/2507.09594v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "How to Define Design in Industrial Control and Automation Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09594",
        "HTML": "https://arxiv.org/html/2507.09594v1",
        "PDF": "https://arxiv.org/pdf/2507.09594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses design definitions and theories in industrial control and automation software. There is no focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10383",
      "abstract": "Neural networks storing multiple discrete attractors are canonical models of biological memory. Previously, the dynamical stability of such networks could only be guaranteed under highly restrictive conditions. Here, we derive a theory of the local stability of discrete fixed points in a broad class of networks with graded neural activities and in the presence of noise. By directly analyzing the bulk and outliers of the Jacobian spectrum, we show that all fixed points are stable below a critical load that is distinct from the classical \\textit{critical capacity} and depends on the statistics of neural activities in the fixed points as well as the single-neuron activation function. Our analysis highlights the computational benefits of threshold-linear activation and sparse-like patterns.",
      "authors": [
        "Uri Cohen",
        "M\\'at\\'e Lengyel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:23:24+00:00",
          "link": "https://arxiv.org/abs/2507.10383v1",
          "size": "1001kb",
          "version": "v1"
        }
      ],
      "title": "Dynamical stability for dense patterns in discrete attractor neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10383",
        "HTML": "https://arxiv.org/html/2507.10383v1",
        "PDF": "https://arxiv.org/pdf/2507.10383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the dynamics and stability of discrete attractor neural networks, with no focus on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10548",
      "abstract": "Recent advanced vision-language models(VLMs) have demonstrated strong performance on passive, offline image and video understanding tasks. However, their effectiveness in embodied settings, which require online interaction and active scene understanding remains limited. In such scenarios, an agent perceives the environment from a first-person perspective, with each action dynamically shaping subsequent observations. Even state-of-the-art models such as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment interactions, exhibiting clear limitations in spatial reasoning and long-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset of over 3,000 language-guided tasks situated in diverse, photorealistic environments constructed using Unreal Engine and the UnrealCV-Zoo framework. The tasks encompass a wide range of embodied challenges, including navigation, object manipulation, and multi-stage goal execution. Each task unfolds as a multi-step trajectory, pairing first-person visual observations with high-level instructions, grounded actions, and natural language rationales that express the agent's intent at every step. Using EmRACE-3K, we establish a benchmark to evaluate the embodied reasoning capabilities of VLMs across three key dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage Goal Execution. In zero-shot settings, all models achieve success rates below 20%, underscoring the challenge posed by our benchmark and the current limitations of VLMs in interactive environments. To demonstrate the utility of EmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning followed by reinforcement learning. This approach yields substantial improvements across all three challenge categories, highlighting the dataset's effectiveness in enabling the development of embodied reasoning capabilities.",
      "authors": [
        "Mingxian Lin",
        "Wei Huang",
        "Yitang Li",
        "Chengjie Jiang",
        "Kui Wu",
        "Fangwei Zhong",
        "Shengju Qian",
        "Xin Wang",
        "Xiaojuan Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:46+00:00",
          "link": "https://arxiv.org/abs/2507.10548v1",
          "size": "2204kb",
          "version": "v1"
        }
      ],
      "title": "EmbRACE-3K: Embodied Reasoning and Action in Complex Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10548",
        "HTML": "https://arxiv.org/html/2507.10548v1",
        "PDF": "https://arxiv.org/pdf/2507.10548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset, EmRACE-3K, detailing a structured approach with diverse photorealistic environments for evaluating embodied reasoning in VLMs. It includes creation of a dataset with clear and detailed data processing steps, which directly contributes to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.19547",
      "abstract": "The Diffusion models, widely used for image generation, face significant challenges related to their broad applicability due to prolonged inference times and high memory demands. Efficient Post-Training Quantization (PTQ) is crucial to address these issues. However, unlike traditional models, diffusion models critically rely on the time-step for the multi-round denoising. Typically, each time-step is encoded into a hypersensitive temporal feature by several modules. Despite this, existing PTQ methods do not optimize these modules individually. Instead, they employ unsuitable reconstruction objectives and complex calibration methods, leading to significant disturbances in the temporal feature and denoising trajectory, as well as reduced compression efficiency. To address these challenges, we introduce a novel quantization framework that includes three strategies: 1) TIB-based Maintenance: Based on our innovative Temporal Information Block (TIB) definition, Temporal Information-aware Reconstruction (TIAR) and Finite Set Calibration (FSC) are developed to efficiently align original temporal features. 2) Cache-based Maintenance: Instead of indirect and complex optimization for the related modules, pre-computing and caching quantized counterparts of temporal features are developed to minimize errors. 3) Disturbance-aware Selection: Employ temporal feature errors to guide a fine-grained selection between the two maintenance strategies for further disturbance reduction. This framework preserves most of the temporal information and ensures high-quality end-to-end generation. Extensive testing on various datasets, diffusion models and hardware confirms our superior performance and acceleration.",
      "authors": [
        "Yushi Huang",
        "Ruihao Gong",
        "Xianglong Liu",
        "Jing Liu",
        "Yuhang Li",
        "Jiwen Lu",
        "Dacheng Tao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-28T17:46:15+00:00",
          "link": "https://arxiv.org/abs/2407.19547v1",
          "size": "28519kb",
          "version": "v1"
        },
        {
          "date": "2024-08-07T20:43:10+00:00",
          "link": "https://arxiv.org/abs/2407.19547v2",
          "size": "28734kb",
          "version": "v2"
        },
        {
          "date": "2025-03-09T17:43:28+00:00",
          "link": "https://arxiv.org/abs/2407.19547v3",
          "size": "17769kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T22:14:01+00:00",
          "link": "https://arxiv.org/abs/2407.19547v4",
          "size": "18007kb",
          "version": "v4"
        }
      ],
      "title": "Temporal Feature Matters: A Framework for Diffusion Model Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19547",
        "HTML": "https://arxiv.org/html/2407.19547v4",
        "PDF": "https://arxiv.org/pdf/2407.19547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses quantization of diffusion models for image generation, concentrating on model optimization techniques rather than LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Image Generation",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/modeltc/tfmq-dm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06806",
      "abstract": "Many commercial Large Language Models (LLMs) are often closed-source, limiting developers to prompt tuning for aligning content generation with specific applications. While these models currently do not provide access to token logits, we argue that if such access were available, it would enable more powerful adaptation techniques beyond prompt engineering. In this paper, we propose a token-level probability reweighting framework that, given access to logits and a small amount of task-specific data, can effectively steer black-box LLMs toward application-specific content generation. Our approach views next-token prediction through the lens of supervised classification. We show that aligning black-box LLMs with task-specific data can be formulated as a label noise correction problem, leading to Plugin model -- an autoregressive probability reweighting model that operates solely on logits. We provide theoretical justification for why reweighting logits alone is sufficient for task adaptation. Extensive experiments with multiple datasets, LLMs, and reweighting models demonstrate the effectiveness of our method, advocating for broader access to token logits in closed-source models.",
      "authors": [
        "Gaurush Hiranandani",
        "Haolun Wu",
        "Subhojyoti Mukherjee",
        "Sanmi Koyejo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T22:24:22+00:00",
          "link": "https://arxiv.org/abs/2502.06806v1",
          "size": "1239kb",
          "version": "v1"
        },
        {
          "date": "2025-02-23T07:20:51+00:00",
          "link": "https://arxiv.org/abs/2502.06806v2",
          "size": "1240kb",
          "version": "v2"
        },
        {
          "date": "2025-06-02T19:53:46+00:00",
          "link": "https://arxiv.org/abs/2502.06806v3",
          "size": "1253kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T07:19:28+00:00",
          "link": "https://arxiv.org/abs/2502.06806v4",
          "size": "1253kb",
          "version": "v4"
        }
      ],
      "title": "Logits are All We Need to Adapt Closed Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06806",
        "HTML": "https://arxiv.org/html/2502.06806v4",
        "PDF": "https://arxiv.org/pdf/2502.06806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for adapting closed-source LLMs using token-level probability reweighting. While it touches on using task-specific data, it primarily focuses on model adaptation techniques rather than LLM training data processing."
      },
      "tasks": [
        "All",
        "Prompt Engineering"
      ],
      "repo_urls": [
        "https://github.com/stair-lab/plugin-llm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18373",
      "abstract": "We argue that in-context learning (ICL) predictably arises from standard self-supervised next-token pretraining, rather than being an exotic emergent property. This work establishes the foundational principles of this emergence by focusing on in-distribution ICL, demonstrating how models necessarily adapt to context when trained on token sequences, especially from non-ergodic sources. Our information-theoretic framework precisely predicts these in-distribution ICL dynamics (i.e., context-dependent loss reduction). We verify this with experiments using synthetic datasets of differing types of correlational structure, reproducing characteristic phenomena like phase transitions in training loss for induction head formation and power-law scaling of in-context loss. We further show that a model's in-context performance on any task is mathematically coupled to the ensemble of tasks seen in pretraining, offering a fundamental explanation, grounded in architecture- and modality-independent principles, for such inference-time learning.",
      "authors": [
        "Paul M. Riechers and Henry R. Bigelow and Eric A. Alt and Adam Shai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T21:00:18+00:00",
          "link": "https://arxiv.org/abs/2505.18373v1",
          "size": "6055kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T01:17:02+00:00",
          "link": "https://arxiv.org/abs/2505.18373v2",
          "size": "2196kb",
          "version": "v2"
        }
      ],
      "title": "Next-token pretraining implies in-context learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18373",
        "HTML": "https://arxiv.org/html/2505.18373v2",
        "PDF": "https://arxiv.org/pdf/2505.18373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an information-theoretic analysis on in-context learning from next-token pretraining. It is focused on theoretical understanding rather than LLM training data processing or dataset creation."
      },
      "tasks": [
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08866",
      "abstract": "Undesirable biases encoded in the data are key drivers of algorithmic discrimination. Their importance is widely recognized in the algorithmic fairness literature, as well as legislation and standards on anti-discrimination in AI. Despite this recognition, data biases remain understudied, hindering the development of computational best practices for their detection and mitigation. In this work, we present three common data biases and study their individual and joint effect on algorithmic discrimination across a variety of datasets, models, and fairness measures. We find that underrepresentation of vulnerable populations in training sets is less conducive to discrimination than conventionally affirmed, while combinations of proxies and label bias can be far more critical. Consequently, we develop dedicated mechanisms to detect specific types of bias, and combine them into a preliminary construct we refer to as the Data Bias Profile (DBP). This initial formulation serves as a proof of concept for how different bias signals can be systematically documented. Through a case study with popular fairness datasets, we demonstrate the effectiveness of the DBP in predicting the risk of discriminatory outcomes and the utility of fairness-enhancing interventions. Overall, this article bridges algorithmic fairness research and anti-discrimination policy through a data-centric lens.",
      "authors": [
        "Marina Ceccon",
        "Giandomenico Cornacchia",
        "Davide Dalle Pezze",
        "Alessandro Fabris",
        "Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:52:11+00:00",
          "link": "https://arxiv.org/abs/2507.08866v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "Underrepresentation, Label Bias, and Proxies: Towards Data Bias Profiles for the EU AI Act and Beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08866",
        "HTML": "https://arxiv.org/html/2507.08866v1",
        "PDF": "https://arxiv.org/pdf/2507.08866"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses bias detection and its impact on algorithmic discrimination, which could relate to data processing, but it lacks specific focus on LLM training data operations or dataset processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09176",
      "abstract": "Accurate extrinsic calibration of multiple LiDARs is crucial for improving the foundational performance of three-dimensional (3D) map reconstruction systems. This paper presents a novel targetless extrinsic calibration framework for multi-LiDAR systems that does not rely on overlapping fields of view or precise initial parameter estimates. Unlike conventional calibration methods that require manual annotations or specific reference patterns, our approach introduces a unified optimization framework by integrating LiDAR bundle adjustment (LBA) optimization with robust iterative refinement. The proposed method constructs an accurate reference point cloud map via continuous scanning from the target LiDAR and sliding-window LiDAR bundle adjustment, while formulating extrinsic calibration as a joint LBA optimization problem. This method effectively mitigates cumulative mapping errors and achieves outlier-resistant parameter estimation through an adaptive weighting mechanism. Extensive evaluations in both the CARLA simulation environment and real-world scenarios demonstrate that our method outperforms state-of-the-art calibration techniques in both accuracy and robustness. Experimental results show that for non-overlapping sensor configurations, our framework achieves an average translational error of 5 mm and a rotational error of 0.2{\\deg}, with an initial error tolerance of up to 0.4 m/30{\\deg}. Moreover, the calibration process operates without specialized infrastructure or manual parameter tuning. The code is open source and available on GitHub (\\underline{https://github.com/Silentbarber/DLBAcalib})",
      "authors": [
        "Han Ye",
        "Yuqiang Jin",
        "Jinyuan Liu",
        "Tao Li",
        "Wen-An Zhang and Minglei Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:48:02+00:00",
          "link": "https://arxiv.org/abs/2507.09176v1",
          "size": "11113kb",
          "version": "v1"
        }
      ],
      "title": "DLBAcalib: Robust Extrinsic Calibration for Non-Overlapping LiDARs Based on Dual LBA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09176",
        "HTML": "https://arxiv.org/html/2507.09176v1",
        "PDF": "https://arxiv.org/pdf/2507.09176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses calibration for multi-LiDAR systems and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09248",
      "abstract": "Context-aware emotion recognition (CAER) enhances affective computing in real-world scenarios, but traditional methods often suffer from context bias-spurious correlation between background context and emotion labels (e.g. associating ``garden'' with ``happy''). In this paper, we propose \\textbf{AGCD-Net}, an Attention Guided Context Debiasing model that introduces \\textit{Hybrid ConvNeXt}, a novel convolutional encoder that extends the ConvNeXt backbone by integrating Spatial Transformer Network and Squeeze-and-Excitation layers for enhanced feature recalibration. At the core of AGCD-Net is the Attention Guided - Causal Intervention Module (AG-CIM), which applies causal theory, perturbs context features, isolates spurious correlations, and performs an attention-driven correction guided by face features to mitigate context bias. Experimental results on the CAER-S dataset demonstrate the effectiveness of AGCD-Net, achieving state-of-the-art performance and highlighting the importance of causal debiasing for robust emotion recognition in complex settings.",
      "authors": [
        "Varsha Devi",
        "Amine Bohi",
        "Pardeep Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.09248v1",
          "size": "1676kb",
          "version": "v1"
        }
      ],
      "title": "AGCD-Net: Attention Guided Context Debiasing Network for Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09248",
        "HTML": "https://arxiv.org/html/2507.09248v1",
        "PDF": "https://arxiv.org/pdf/2507.09248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a model architecture for emotion recognition and does not focus on LLM training data processing. It addresses context debiasing in model architecture rather than data preprocessing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09385",
      "abstract": "Fraud detection is one of the most important challenges that financial systems must address. Detecting fraudulent transactions is critical for payment gateway companies like Flow Payment, which process millions of transactions monthly and require robust security measures to mitigate financial risks. Increasing transaction authorization rates while reducing fraud is essential for providing a good user experience and building a sustainable business. For this reason, discovering novel and improved methods to detect fraud requires continuous research and investment for any company that wants to succeed in this industry. In this work, we introduced a novel method for detecting transactional fraud by incorporating the Relative Distance Rotating Encoding (ReDRE) in the RoFormer model. The incorporation of angle rotation using ReDRE enhances the characterization of time series data within a Transformer, leading to improved fraud detection by better capturing temporal dependencies and event relationships.",
      "authors": [
        "Kevin Reyes",
        "Vasco Cortez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:02:02+00:00",
          "link": "https://arxiv.org/abs/2507.09385v1",
          "size": "338kb",
          "version": "v1"
        }
      ],
      "title": "Credit Card Fraud Detection Using RoFormer Model With Relative Distance Rotating Encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09385",
        "PDF": "https://arxiv.org/pdf/2507.09385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing fraud detection using the RoFormer model with a novel encoding method. It does not address LLM training data processing but rather focuses on model application for a specific task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09615",
      "abstract": "Vision-language models (VLMs) like CLIP excel in zero-shot learning by aligning image and text representations through contrastive pretraining. Existing approaches to unsupervised adaptation (UA) for fine-grained classification with VLMs either rely on fixed alignment scores that cannot capture evolving, subtle class distinctions or use computationally expensive pseudo-labeling strategies that limit scalability. In contrast, we show that modeling fine-grained cross-modal interactions during adaptation produces more accurate, class-discriminative pseudo-labels and substantially improves performance over state-of-the-art (SOTA) methods. We introduce Fine-grained Alignment and Interaction Refinement (FAIR), an innovative approach that dynamically aligns localized image features with descriptive language embeddings through a set of Class Description Anchors (CDA). This enables the definition of a Learned Alignment Score (LAS), which incorporates CDA as an adaptive classifier, facilitating cross-modal interactions to improve self-training in unsupervised adaptation. Furthermore, we propose a self-training weighting mechanism designed to refine pseudo-labels in the presence of inter-class ambiguities. Our approach, FAIR, delivers a substantial performance boost in fine-grained unsupervised adaptation, achieving a notable overall gain of 2.78% across 13 fine-grained datasets compared to SOTA methods.",
      "authors": [
        "Eman Ali and Sathira Silva and Chetan Arora and Muhammad Haris Khan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:38:38+00:00",
          "link": "https://arxiv.org/abs/2507.09615v1",
          "size": "1107kb",
          "version": "v1"
        }
      ],
      "title": "Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09615",
        "HTML": "https://arxiv.org/html/2507.09615v1",
        "PDF": "https://arxiv.org/pdf/2507.09615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses unsupervised adaptation of vision-language models and the refining of pseudo-labels, but it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09831",
      "abstract": "Cognitive diagnosis (CD) models latent cognitive states of human learners by analyzing their response patterns on diagnostic tests, serving as a crucial machine learning technique for educational assessment and evaluation. Traditional cognitive diagnosis models typically follow a transductive prediction paradigm that optimizes parameters to fit response scores and extract learner abilities. These approaches face significant limitations as they cannot perform instant diagnosis for new learners without computationally expensive retraining and produce diagnostic outputs with limited reliability. In this study, we introduces a novel generative diagnosis paradigm that fundamentally shifts CD from predictive to generative modeling, enabling inductive inference of cognitive states without parameter re-optimization. We propose two simple yet effective instantiations of this paradigm: Generative Item Response Theory (G-IRT) and Generative Neural Cognitive Diagnosis Model (G-NCDM), which achieve excellent performance improvements over traditional methods. The generative approach disentangles cognitive state inference from response prediction through a well-designed generation process that incorporates identifiability and monotonicity conditions. Extensive experiments on real-world datasets demonstrate the effectiveness of our methodology in addressing scalability and reliability challenges, especially $\\times 100$ speedup for the diagnosis of new learners. Our framework opens new avenues for cognitive diagnosis applications in artificial intelligence, particularly for intelligent model evaluation and intelligent education systems. The code is available at https://github.com/CSLiJT/Generative-CD.git.",
      "authors": [
        "Jiatong Li",
        "Qi Liu",
        "Mengxiao Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:55:05+00:00",
          "link": "https://arxiv.org/abs/2507.09831v1",
          "size": "3687kb",
          "version": "v1"
        }
      ],
      "title": "Generative Cognitive Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09831",
        "HTML": "https://arxiv.org/html/2507.09831v1",
        "PDF": "https://arxiv.org/pdf/2507.09831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a generative paradigm for cognitive diagnosis but does not involve LLM training data processing or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.05348",
      "abstract": "Video streaming often requires transcoding content into different resolutions and bitrates to match the recipient's internet speed and screen capabilities. Video encoders like x264 offer various presets, each with different tradeoffs between transcoding time and rate-distortion performance. Choosing the best preset for video transcoding is difficult, especially for live streaming, as trying all the presets and choosing the best one is not feasible. One solution is to predict each preset's transcoding time and select the preset that ensures the highest quality while adhering to live streaming time constraints. Prediction of video transcoding time is also critical in minimizing streaming delays, deploying resource management algorithms, and load balancing. We propose a learning-based framework for predicting the transcoding time of videos across various presets. Our predictor's features for video transcoding time prediction are derived directly from the ingested stream, primarily from the header or metadata. As a result, only minimal additional delay is incurred for feature extraction, rendering our approach ideal for live-streaming applications. We evaluated our learning-based transcoding time prediction using a dataset of videos. The results demonstrate that our framework can accurately predict the transcoding time for different presets, with a mean absolute percentage error (MAPE) of nearly 5.0%. Leveraging these predictions, we then select the most suitable transcoding preset for live video streaming. Utilizing our transcoding time prediction-based preset selection improved Peak Signal-to-Noise Ratio (PSNR) of up to 5 dB.",
      "authors": [
        "Zahra Nabizadeh Shahre-Babak",
        "Nader Karimi",
        "Krishna Rapaka",
        "Tarek Amara",
        "Shadrokh Samavi",
        "Shahram Shirani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-08T20:12:14+00:00",
          "link": "https://arxiv.org/abs/2312.05348v1",
          "size": "1584kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T18:38:46+00:00",
          "link": "https://arxiv.org/abs/2312.05348v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "High-Quality Live Video Streaming via Transcoding Time Prediction and Preset Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.05348",
        "PDF": "https://arxiv.org/pdf/2312.05348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with video transcoding time prediction and preset selection, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03504",
      "abstract": "In this paper, we propose Binarized Change Detection (BiCD), the first binary neural network (BNN) designed specifically for change detection. Conventional network binarization approaches, which directly quantize both weights and activations in change detection models, severely limit the network's ability to represent input data and distinguish between changed and unchanged regions. This results in significantly lower detection accuracy compared to real-valued networks. To overcome these challenges, BiCD enhances both the representational power and feature separability of BNNs, improving detection performance. Specifically, we introduce an auxiliary objective based on the Information Bottleneck (IB) principle, guiding the encoder to retain essential input information while promoting better feature discrimination. Since directly computing mutual information under the IB principle is intractable, we design a compact, learnable auxiliary module as an approximation target, leading to a simple yet effective optimization strategy that minimizes both reconstruction loss and standard change detection loss. Extensive experiments on street-view and remote sensing datasets demonstrate that BiCD establishes a new benchmark for BNN-based change detection, achieving state-of-the-art performance in this domain.",
      "authors": [
        "Kaijie Yin and Zhiyuan Zhang and Shu Kong and Tian Gao and Chengzhong Xu and Hui Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T11:56:16+00:00",
          "link": "https://arxiv.org/abs/2507.03504v1",
          "size": "854kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:29:19+00:00",
          "link": "https://arxiv.org/abs/2507.03504v2",
          "size": "855kb",
          "version": "v2"
        }
      ],
      "title": "Information-Bottleneck Driven Binary Neural Network for Change Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03504",
        "HTML": "https://arxiv.org/html/2507.03504v2",
        "PDF": "https://arxiv.org/pdf/2507.03504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is focused on change detection in binary neural networks using the Information Bottleneck principle. The paper does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09146",
      "abstract": "Fluid simulation techniques are widely used in various fields such as film production, but controlling complex fluid behaviors remains challenging. While recent generative models enable intuitive generation of vector fields from user sketches, they struggle to maintain physical properties such as incompressibility. To address these issues, this paper proposes a method for interactively designing 2D vector fields. Conventional generative models can intuitively generate vector fields from user sketches, but remain difficult to consider physical properties. Therefore, we add a simple editing process after generating the vector field. In the first stage, we use a latent diffusion model~(LDM) to automatically generate initial 2D vector fields from user sketches. In the second stage, we apply the Helmholtz-Hodge decomposition to locally extract physical properties such as incompressibility from the results generated by LDM and recompose them according to user intentions. Through multiple experiments, we demonstrate the effectiveness of our proposed method.",
      "authors": [
        "Ryuichi Miyauchi",
        "Hengyuan Chang",
        "Tsukasa Fukusato",
        "Kazunori Miyata",
        "Haoran Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T05:23:16+00:00",
          "link": "https://arxiv.org/abs/2507.09146v1",
          "size": "3760kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Aware Fluid Field Generation from User Sketches Using Helmholtz-Hodge Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09146",
        "HTML": "https://arxiv.org/html/2507.09146v1",
        "PDF": "https://arxiv.org/pdf/2507.09146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses generating fluid field simulations with a focus on maintaining physical properties, not processing or preparing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09854",
      "abstract": "Neurosymbolic artificial intelligence (AI) systems combine neural network and classical symbolic AI mechanisms to exploit the complementary strengths of large scale, generalizable learning and robust, verifiable reasoning. Numerous classifications of neurosymbolic AI illustrate how these two components can be integrated in distinctly different ways. In this work, we propose reinterpreting instruction tuned large language models as model grounded symbolic AI systems where natural language serves as the symbolic layer and grounding is achieved through the models internal representation space. Within this framework, we investigate and develop novel learning and reasoning approaches that preserve structural similarities to traditional learning and reasoning paradigms. Preliminary evaluations across axiomatic deductive reasoning procedures of varying complexity provide insights into the effectiveness of our approach in improving learning efficiency and reasoning reliability.",
      "authors": [
        "Aniruddha Chattopadhyay",
        "Raj Dandekar",
        "Kaushik Roy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:34:05+00:00",
          "link": "https://arxiv.org/abs/2507.09854v1",
          "size": "335kb",
          "version": "v1"
        }
      ],
      "title": "Model-Grounded Symbolic Artificial Intelligence Systems Learning and Reasoning with Model-Grounded Symbolic Artificial Intelligence Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09854",
        "HTML": "https://arxiv.org/html/2507.09854v1",
        "PDF": "https://arxiv.org/pdf/2507.09854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates neurosymbolic AI systems without focusing on the collection, processing, or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10499",
      "abstract": "The design of science-based policies to improve the sustainability of smallholder agriculture is challenged by a limited understanding of fundamental system properties, such as the spatial distribution of active cropland and field size. We integrate very high spatial resolution (1.5 m) Earth observation data and deep transfer learning to derive crop field delineations in complex agricultural systems at the national scale, while maintaining minimum reference data requirements and enhancing transferability. We provide the first national-level dataset of 21 million individual fields for Mozambique (covering ~800,000 km2) for 2023. Our maps separate active cropland from non-agricultural land use with an overall accuracy of 93% and balanced omission and commission errors. Field-level spatial agreement reached median intersection over union (IoU) scores of 0.81, advancing the state-of-the-art in large-area field delineation in complex smallholder systems. The active cropland maps capture fragmented rural regions with low cropland shares not yet identified in global land cover or cropland maps. These regions are mostly located in agricultural frontier regions which host 7-9% of the Mozambican population. Field size in Mozambique is very low overall, with half of the fields being smaller than 0.16 ha, and 83% smaller than 0.5 ha. Mean field size at aggregate spatial resolution (0.05{\\deg}) is 0.32 ha, but it varies strongly across gradients of accessibility, population density, and net forest cover change. This variation reflects a diverse set of actors, ranging from semi-subsistence smallholder farms to medium-scale commercial farming, and large-scale farming operations. Our results highlight that field size is a key indicator relating to socio-economic and environmental outcomes of agriculture (e.g., food production, livelihoods, deforestation, biodiversity), as well as their trade-offs.",
      "authors": [
        "Philippe Rufin",
        "Pauline Lucie Hammer",
        "Leon-Friedrich Thomas",
        "S\\'a Nogueira Lisboa",
        "Natasha Ribeiro",
        "Almeida Sitoe",
        "Patrick Hostert",
        "Patrick Meyfroidt"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:23:43+00:00",
          "link": "https://arxiv.org/abs/2507.10499v1",
          "size": "3657kb",
          "version": "v1"
        }
      ],
      "title": "National level satellite-based crop field inventories in smallholder landscapes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10499",
        "PDF": "https://arxiv.org/pdf/2507.10499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a dataset from satellite images for specific agricultural mapping but does not focus on LLM training data processing or generation techniques related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.18439",
      "abstract": "Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.",
      "authors": [
        "Chanwoo Park",
        "Seungju Han",
        "Xingzhi Guo",
        "Asuman Ozdaglar",
        "Kaiqing Zhang",
        "Joo-Kyung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T18:33:48+00:00",
          "link": "https://arxiv.org/abs/2502.18439v1",
          "size": "470kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T20:13:27+00:00",
          "link": "https://arxiv.org/abs/2502.18439v2",
          "size": "490kb",
          "version": "v2"
        }
      ],
      "title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18439",
        "HTML": "https://arxiv.org/html/2502.18439v2",
        "PDF": "https://arxiv.org/pdf/2502.18439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a post-training paradigm MAPoRL for LLMs involving reinforcement learning, but it does not focus on processing or creating training data, instead emphasizing multi-agent collaboration."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.01837",
      "abstract": "Gait recognition enables contact-free, long-range person identification that is robust to clothing variations and non-cooperative scenarios. While existing methods perform well in controlled indoor environments, they struggle with cross-vertical view scenarios, where surveillance angles vary significantly in elevation. Our experiments show up to 60\\% accuracy degradation in low-to-high vertical view settings due to severe deformations and self-occlusions of key anatomical features. Current CNN and self-attention-based methods fail to effectively handle these challenges, due to their reliance on single-scale convolutions or simplistic attention mechanisms that lack effective multi-frequency feature integration. To tackle this challenge, we propose CVVNet (Cross-Vertical-View Network), a frequency aggregation architecture specifically designed for robust cross-vertical-view gait recognition. CVVNet employs a High-Low Frequency Extraction module (HLFE) that adopts parallel multi-scale convolution/max-pooling path and self-attention path as high- and low-frequency mixers for effective multi-frequency feature extraction from input silhouettes. We also introduce the Dynamic Gated Aggregation (DGA) mechanism to adaptively adjust the fusion ratio of high- and low-frequency features. The integration of our core Multi-Scale Attention Gated Aggregation (MSAGA) module, HLFE and DGA enables CVVNet to effectively handle distortions from view changes, significantly improving the recognition robustness across different vertical views. Experimental results show that our CVVNet achieves state-of-the-art performance, with $8.6\\%$ improvement on DroneGait and $2\\%$ on Gait3D compared with the best existing methods.",
      "authors": [
        "Xiangru Li",
        "Wei Song",
        "Yingda Huang",
        "Wei Meng",
        "Le Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-03T14:53:20+00:00",
          "link": "https://arxiv.org/abs/2505.01837v1",
          "size": "2694kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:00:31+00:00",
          "link": "https://arxiv.org/abs/2505.01837v2",
          "size": "1915kb",
          "version": "v2"
        }
      ],
      "title": "CVVNet: A Cross-Vertical-View Network for Gait Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01837",
        "HTML": "https://arxiv.org/html/2505.01837v2",
        "PDF": "https://arxiv.org/pdf/2505.01837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel architecture for gait recognition involving cross-vertical view scenarios. It does not discuss LLM training data processing or any related data engineering techniques."
      },
      "tasks": [
        "Gait Recognition",
        "Person Identification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10344",
      "abstract": "Many real-world settings require registration of a pair of medical images that differ in spatial resolution, which may arise from differences in image acquisition parameters like pixel spacing, slice thickness, and field-of-view. However, all previous machine learning-based registration techniques resample images onto a fixed resolution. This is suboptimal because resampling can introduce artifacts due to interpolation. To address this, we present RealKeyMorph (RKM), a resolution-agnostic method for image registration. RKM is an extension of KeyMorph, a registration framework which works by training a network to learn corresponding keypoints for a given pair of images, after which a closed-form keypoint matching step is used to derive the transformation that aligns them. To avoid resampling and enable operating on the raw data, RKM outputs keypoints in real-world coordinates of the scanner. To do this, we leverage the affine matrix produced by the scanner (e.g., MRI machine) that encodes the mapping from voxel coordinates to real world coordinates. By transforming keypoints into real-world space and integrating this into the training process, RKM effectively enables the extracted keypoints to be resolution-agnostic. In our experiments, we demonstrate the advantages of RKM on the registration task for orthogonal 2D stacks of abdominal MRIs, as well as 3D volumes with varying resolutions in brain datasets.",
      "authors": [
        "Mina C. Moghadam",
        "Alan Q. Wang",
        "Omer Taub",
        "Martin R. Prince",
        "Mert R. Sabuncu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T04:40:32+00:00",
          "link": "https://arxiv.org/abs/2506.10344v1",
          "size": "2576kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:28:01+00:00",
          "link": "https://arxiv.org/abs/2506.10344v2",
          "size": "2576kb",
          "version": "v2"
        }
      ],
      "title": "RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10344",
        "HTML": "https://arxiv.org/html/2506.10344v2",
        "PDF": "https://arxiv.org/pdf/2506.10344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for medical image registration that avoids resampling artifacts, unrelated to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Image Registration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09013",
      "abstract": "This paper presents a novel data-driven algorithm designed to recover low-rank matrices whose entries satisfy a mixed H\\\"older condition in the presence of high-dimensional noise with a separable covariance structure. The algorithm, coined extended optimal shrinkage and wavelet shrinkage (e$\\mathcal{OWS}$), emphasizes the asymptotic structure, where the matrix size is significantly larger than the rank of the signal matrix. The denoising process begins with the adaptation of the well-known optimal shrinkage of singular values. This is followed by an iterative procedure that organizes the matrix using a coupled metric on the rows and columns, constructed by building a tree structure for both dimensions. This hierarchical organization induces a tensor Haar-Walsh basis on the matrix. An adapted wavelet shrinkage technique is applied to further denoise the reconstructed matrix, modifying the Haar-Walsh coefficients based on the analysis of the first-order perturbation of singular vectors. We provide theoretical guarantees for these estimators, demonstrating a convergence rate that highlights the efficacy of our algorithm. Simulations show successful matrix recovery, with a small mean squared error between the estimate and the ground truth, and accurate reconstruction of the singular vector spaces.",
      "authors": [
        "Pei-Chun Su"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Spectral Theory (math.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:36:53+00:00",
          "link": "https://arxiv.org/abs/2507.09013v1",
          "size": "1733kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Matrix Recovery with High-Dimensional Noise via Optimal Shrinkage of Singular Values and Wavelet Shrinkage of Singular Vectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09013",
        "HTML": "https://arxiv.org/html/2507.09013v1",
        "PDF": "https://arxiv.org/pdf/2507.09013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a matrix recovery algorithm for dealing with high-dimensional noise, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09028",
      "abstract": "Cancer research is increasingly driven by the integration of diverse data modalities, spanning from genomics and proteomics to imaging and clinical factors. However, extracting actionable insights from these vast and heterogeneous datasets remains a key challenge. The rise of foundation models (FMs) -- large deep-learning models pretrained on extensive amounts of data serving as a backbone for a wide range of downstream tasks -- offers new avenues for discovering biomarkers, improving diagnosis, and personalizing treatment. This paper presents a comprehensive review of widely adopted integration strategies of multimodal data to assist advance the computational approaches for data-driven discoveries in oncology. We examine emerging trends in machine learning (ML) and deep learning (DL), including methodological frameworks, validation protocols, and open-source resources targeting cancer subtype classification, biomarker discovery, treatment guidance, and outcome prediction. This study also comprehensively covers the shift from traditional ML to FMs for multimodal integration. We present a holistic view of recent FMs advancements and challenges faced during the integration of multi-omics with advanced imaging data. We identify the state-of-the-art FMs, publicly available multi-modal repositories, and advanced tools and methods for data integration. We argue that current state-of-the-art integrative methods provide the essential groundwork for developing the next generation of large-scale, pre-trained models poised to further revolutionize oncology. To the best of our knowledge, this is the first review to systematically map the transition from conventional ML to advanced FM for multimodal data integration in oncology, while also framing these developments as foundational for the forthcoming era of large-scale AI models in cancer research.",
      "authors": [
        "Amgad Muneer",
        "Muhammad Waqas",
        "Maliazurina B Saad",
        "Eman Showkatian",
        "Rukhmini Bandyopadhyay",
        "Hui Xu",
        "Wentao Li",
        "Joe Y Chang",
        "Zhongxing Liao",
        "Cara Haymaker",
        "Luisa Solis Soto",
        "Carol C Wu",
        "Natalie I Vokes",
        "Xiuning Le",
        "Lauren A Byers",
        "Don L Gibbons",
        "John V Heymach",
        "Jianjun Zhang",
        "Jia Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:23:21+00:00",
          "link": "https://arxiv.org/abs/2507.09028v1",
          "size": "2104kb",
          "version": "v1"
        }
      ],
      "title": "From Classical Machine Learning to Emerging Foundation Models: Review on Multimodal Data Integration for Cancer Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09028",
        "PDF": "https://arxiv.org/pdf/2507.09028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews multimodal data integration strategies and advancements in foundation models for cancer research, but it does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09127",
      "abstract": "Options, which impose an inductive bias toward temporal and hierarchical structure, offer a powerful framework for reinforcement learning (RL). While effective in sequential decision-making, they are often handcrafted rather than learned. Among approaches for discovering options, eigenoptions have shown strong performance in exploration, but their role in credit assignment remains underexplored. In this paper, we investigate whether eigenoptions can accelerate credit assignment in model-free RL, evaluating them in tabular and pixel-based gridworlds. We find that pre-specified eigenoptions aid not only exploration but also credit assignment, whereas online discovery can bias the agent's experience too strongly and hinder learning. In the context of deep RL, we also propose a method for learning option-values under non-linear function approximation, highlighting the impact of termination conditions on performance. Our findings reveal both the promise and complexity of using eigenoptions, and options more broadly, to simultaneously support credit assignment and exploration in reinforcement learning.",
      "authors": [
        "Harshil Kotamreddy",
        "Marlos C. Machado"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T03:29:59+00:00",
          "link": "https://arxiv.org/abs/2507.09127v1",
          "size": "2025kb",
          "version": "v1"
        }
      ],
      "title": "A Study of Value-Aware Eigenoptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09127",
        "HTML": "https://arxiv.org/html/2507.09127v1",
        "PDF": "https://arxiv.org/pdf/2507.09127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered around reinforcement learning and eigenoptions as a method for credit assignment and exploration, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09702",
      "abstract": "Token compression techniques have recently emerged as powerful tools for accelerating Vision Transformer (ViT) inference in computer vision. Due to the quadratic computational complexity with respect to the token sequence length, these methods aim to remove less informative tokens before the attention layers to improve inference throughput. While numerous studies have explored various accuracy-efficiency trade-offs on large-scale ViTs, two critical gaps remain. First, there is a lack of unified survey that systematically categorizes and compares token compression approaches based on their core strategies (e.g., pruning, merging, or hybrid) and deployment settings (e.g., fine-tuning vs. plug-in). Second, most benchmarks are limited to standard ViT models (e.g., ViT-B, ViT-L), leaving open the question of whether such methods remain effective when applied to structurally compressed transformers, which are increasingly deployed on resource-constrained edge devices. To address these gaps, we present the first systematic taxonomy and comparative study of token compression methods, and we evaluate representative techniques on both standard and compact ViT architectures. Our experiments reveal that while token compression methods are effective for general-purpose ViTs, they often underperform when directly applied to compact designs. These findings not only provide practical insights but also pave the way for future research on adapting token optimization techniques to compact transformer-based networks for edge AI and AI agent applications.",
      "authors": [
        "Phat Nguyen and Ngai-Man Cheung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:26:05+00:00",
          "link": "https://arxiv.org/abs/2507.09702v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Token Compression Meets Compact Vision Transformers: A Survey and Comparative Evaluation for Edge AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09702",
        "HTML": "https://arxiv.org/html/2507.09702v1",
        "PDF": "https://arxiv.org/pdf/2507.09702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys token compression techniques for Vision Transformers and does not address LLM training data processing or data quality improvement methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09731",
      "abstract": "Medical Imagings are considered one of the crucial diagnostic tools for different bones-related diseases, especially bones fractures. This paper investigates the robustness of pre-trained deep learning models for classifying bone fractures in X-ray images and seeks to address global healthcare disparity through the lens of technology. Three deep learning models have been tested under varying simulated equipment quality conditions. ResNet50, VGG16 and EfficientNetv2 are the three pre-trained architectures which are compared. These models were used to perform bone fracture classification as images were progressively degraded using noise. This paper specifically empirically studies how the noise can affect the bone fractures detection and how the pre-trained models performance can be changes due to the noise that affect the quality of the X-ray images. This paper aims to help replicate real world challenges experienced by medical imaging technicians across the world. Thus, this paper establishes a methodological framework for assessing AI model degradation using transfer learning and controlled noise augmentation. The findings provide practical insight into how robust and generalizable different pre-trained deep learning powered computer vision models can be when used in different contexts.",
      "authors": [
        "Robby Hoover",
        "Nelly Elsayed",
        "Zag ElSayed",
        "Chengcheng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:07:34+00:00",
          "link": "https://arxiv.org/abs/2507.09731v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09731",
        "HTML": "https://arxiv.org/html/2507.09731v1",
        "PDF": "https://arxiv.org/pdf/2507.09731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the robustness of pre-trained models for bone fracture detection under noise conditions, with no relevance to LLM training data processing or data quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09774",
      "abstract": "This paper presents the design and development of a low-cost fuel dispensing system prototype based on the STM32 microcontroller and L298N motor driver. The system aims to provide an affordable and scalable solution for fuel delivery in remote or small-scale environments where conventional, high-cost systems are not feasible. The core control unit is built using an STM32 microcontroller, which manages user input through a 4x4 matrix keypad and displays operational data on a 16x4 LCD screen via I2C communication. A 12V DC pump motor is used to simulate the fuel dispensing mechanism, precisely controlled via the dual H-bridge L298N motor driver. The system is powered by a 11.1V battery and is designed for ease of deployment and portability. The keypad allows users to input the desired fuel amount, while the system ensures accurate motor runtime corresponding to the volume to be dispensed. This project demonstrates how embedded systems can be leveraged to build cost-effective, user-friendly, and energy-efficient solutions. The proposed design can be further enhanced with flow sensors, GSM connectivity, RFID cards, and payment integration for real-world applications in fuel stations or agricultural use.",
      "authors": [
        "MD Zobaer Hossain Bhuiyan",
        "Abir Bin Faruque",
        "Mahtab Newaz",
        "Mohammad Abdul Qayum"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:11:37+00:00",
          "link": "https://arxiv.org/abs/2507.09774v1",
          "size": "7090kb",
          "version": "v1"
        }
      ],
      "title": "Low-Cost Fuel Dispenser Prototype Using STM32 and an H-bridge motor driver",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09774",
        "HTML": "https://arxiv.org/html/2507.09774v1",
        "PDF": "https://arxiv.org/pdf/2507.09774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a fuel dispensing system prototype, focusing on hardware and embedded systems design, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10154",
      "abstract": "Predictive models often reinforce biases which were originally embedded in their training data, through skewed decisions. In such cases, mitigation methods are critical to ensure that, regardless of the prevailing disparities, model outcomes are adjusted to be fair. To assess this, datasets could be systematically generated with specific biases, to train machine learning classifiers. Then, predictive outcomes could aid in the understanding of this bias embedding process. Hence, an agent-based model (ABM), depicting a loan application process that represents various systemic biases across two demographic groups, was developed to produce synthetic datasets. Then, by applying classifiers trained on them to predict loan outcomes, we can assess how biased data leads to unfairness. This highlights a main contribution of this work: a framework for synthetic dataset generation with controllable bias injection. We also contribute with a novel explainability technique, which shows how mitigations affect the way classifiers leverage data features, via second-order Shapley values. In experiments, both offline and online learning approaches are employed. Mitigations are applied at different stages of the modelling pipeline, such as during pre-processing and in-processing.",
      "authors": [
        "Ricardo In\\'acio",
        "Zafeiris Kokkinogenis",
        "Vitor Cerqueira",
        "and Carlos Soares"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:04:24+00:00",
          "link": "https://arxiv.org/abs/2507.10154v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Simulating Biases for Interpretable Fairness in Offline and Online Classifiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10154",
        "HTML": "https://arxiv.org/html/2507.10154v1",
        "PDF": "https://arxiv.org/pdf/2507.10154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a method for synthetic dataset generation with controllable bias injection, highlighting the creation of a new dataset with clear data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.19949",
      "abstract": "Diffusion models have demonstrated their capabilities in modeling trajectories of multi-tasks. However, existing multi-task planners or policies typically rely on task-specific demonstrations via multi-task imitation, or require task-specific reward labels to facilitate policy optimization via Reinforcement Learning (RL). They are costly due to the substantial human efforts required to collect expert data or design reward functions. To address these challenges, we aim to develop a versatile diffusion planner capable of leveraging large-scale inferior data that contains task-agnostic sub-optimal trajectories, with the ability to fast adapt to specific tasks. In this paper, we propose SODP, a two-stage framework that leverages Sub-Optimal data to learn a Diffusion Planner, which is generalizable for various downstream tasks. Specifically, in the pre-training stage, we train a foundation diffusion planner that extracts general planning capabilities by modeling the versatile distribution of multi-task trajectories, which can be sub-optimal and has wide data coverage. Then for downstream tasks, we adopt RL-based fine-tuning with task-specific rewards to quickly refine the diffusion planner, which aims to generate action sequences with higher task-specific returns. Experimental results from multi-task domains including Meta-World and Adroit demonstrate that SODP outperforms state-of-the-art methods with only a small amount of data for reward-guided fine-tuning.",
      "authors": [
        "Chenyou Fan",
        "Chenjia Bai",
        "Zhao Shan",
        "Haoran He",
        "Yang Zhang",
        "Zhen Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T05:05:37+00:00",
          "link": "https://arxiv.org/abs/2409.19949v1",
          "size": "1104kb",
          "version": "v1"
        },
        {
          "date": "2025-02-02T13:33:28+00:00",
          "link": "https://arxiv.org/abs/2409.19949v2",
          "size": "1239kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T17:10:26+00:00",
          "link": "https://arxiv.org/abs/2409.19949v3",
          "size": "1244kb",
          "version": "v3"
        }
      ],
      "title": "Task-Agnostic Pre-training and Task-Guided Fine-tuning for Versatile Diffusion Planner",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.19949",
        "HTML": "https://arxiv.org/html/2409.19949v3",
        "PDF": "https://arxiv.org/pdf/2409.19949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses diffusion models for task planning and does not involve LLM training data processing or engineering."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.08331",
      "abstract": "3D semantic field learning is crucial for applications like autonomous navigation, AR/VR, and robotics, where accurate comprehension of 3D scenes from limited viewpoints is essential. Existing methods struggle under sparse view conditions, relying on inefficient per-scene multi-view optimizations, which are impractical for many real-world tasks. To address this, we propose SLGaussian, a feed-forward method for constructing 3D semantic fields from sparse viewpoints, allowing direct inference of 3DGS-based scenes. By ensuring consistent SAM segmentations through video tracking and using low-dimensional indexing for high-dimensional CLIP features, SLGaussian efficiently embeds language information in 3D space, offering a robust solution for accurate 3D scene understanding under sparse view conditions. In experiments on two-view sparse 3D object querying and segmentation in the LERF and 3D-OVS datasets, SLGaussian outperforms existing methods in chosen IoU, Localization Accuracy, and mIoU. Moreover, our model achieves scene inference in under 30 seconds and open-vocabulary querying in just 0.011 seconds per query.",
      "authors": [
        "Kangjie Chen",
        "BingQuan Dai",
        "Minghan Qin",
        "Dongbin Zhang",
        "Peihao Li",
        "Yingshuang Zou",
        "Haoqian Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-11T12:18:30+00:00",
          "link": "https://arxiv.org/abs/2412.08331v1",
          "size": "11330kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T12:19:42+00:00",
          "link": "https://arxiv.org/abs/2412.08331v2",
          "size": "3461kb",
          "version": "v2"
        }
      ],
      "title": "SLGaussian: Fast Language Gaussian Splatting in Sparse Views",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.08331",
        "HTML": "https://arxiv.org/html/2412.08331v2",
        "PDF": "https://arxiv.org/pdf/2412.08331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D semantic field learning from sparse views for applications like autonomous navigation, rather than LLM training data processing."
      },
      "tasks": [
        "3DGS",
        "Autonomous Navigation",
        "Scene Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00417",
      "abstract": "This study focuses on parameter-free importance measures, based on the recursive definition of importance (RDI), for network nodes. The best-known examples of such RDI-based measures are eigenvector centrality and Seeley centrality, but they are applicable only to strongly connected networks. In contrast, Katz centrality and its variants, including PageRank, are RDI-inspired measures that introduce free parameters to handle general networks. This motivates the overlooked question of whether an RDI-based measure can be defined for arbitrary networks without introducing free parameters. This question is addressed by introducing $PureRank$, a parameter-free recursive importance measure. PureRank proceeds in three steps: (i) nodes are classified into recurrent, transient, and dangling classes via strongly connected component decomposition; (ii) local importance vectors for these classes are formulated as solutions to Katz parameter optimization problems aimed at best approximating eigenvector centrality within each class; and (iii) these vectors are aggregated into global scores via the RDI principle. This modular design enables parallel and incremental computation. PureRank also admits a probabilistic interpretation via a random-surfer model. The effectiveness and characteristics of PureRank are evaluated through numerical experiments on large-scale real-world networks, in comparison with PageRank. Finally, extension of PureRank to multi-attribute networks is discussed.",
      "authors": [
        "Hiroyuki Masuyama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T12:37:49+00:00",
          "link": "https://arxiv.org/abs/2501.00417v1",
          "size": "220kb",
          "version": "v1"
        },
        {
          "date": "2025-01-04T06:41:04+00:00",
          "link": "https://arxiv.org/abs/2501.00417v2",
          "size": "220kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T22:20:27+00:00",
          "link": "https://arxiv.org/abs/2501.00417v3",
          "size": "136kb",
          "version": "v3"
        },
        {
          "date": "2025-05-30T01:40:50+00:00",
          "link": "https://arxiv.org/abs/2501.00417v4",
          "size": "142kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T11:35:39+00:00",
          "link": "https://arxiv.org/abs/2501.00417v5",
          "size": "95kb",
          "version": "v5"
        }
      ],
      "title": "PureRank: A Parameter-Free Recursive Importance Measure for Network Nodes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00417",
        "PDF": "https://arxiv.org/pdf/2501.00417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces PureRank, a recursive importance measure for network nodes, which is unrelated to LLM training data processing or any aspect of data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12864",
      "abstract": "Long-form legal reasoning remains a key challenge for large language models (LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a novel benchmark derived from 340 law exams spanning 116 law school courses across a range of subjects and degree levels. The dataset comprises 4,886 law exam questions in English and German, including 2,841 long-form, open-ended questions and 2,045 multiple-choice questions. Besides reference answers, the open questions are also accompanied by explicit guidance outlining the expected legal reasoning approach such as issue spotting, rule recall, or rule application. Our evaluation on both open-ended and multiple-choice questions present significant challenges for current LLMs; in particular, they notably struggle with open questions that require structured, multi-step legal reasoning. Moreover, our results underscore the effectiveness of the dataset in differentiating between models with varying capabilities. Adopting an LLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate how model-generated reasoning steps can be evaluated consistently and accurately. Our evaluation setup provides a scalable method to assess legal reasoning quality beyond simple accuracy metrics. Project page: https://lexam-benchmark.github.io/",
      "authors": [
        "Yu Fan",
        "Jingwei Ni",
        "Jakob Merane",
        "Etienne Salimbeni",
        "Yang Tian",
        "Yoan Hermstr\\\"uwer",
        "Yinya Huang",
        "Mubashara Akhtar",
        "Florian Geering",
        "Oliver Dreyer",
        "Daniel Brunner",
        "Markus Leippold",
        "Mrinmaya Sachan",
        "Alexander Stremitzer",
        "Christoph Engel",
        "Elliott Ash",
        "Joel Niklaus"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T08:48:12+00:00",
          "link": "https://arxiv.org/abs/2505.12864v1",
          "size": "3565kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T15:37:57+00:00",
          "link": "https://arxiv.org/abs/2505.12864v2",
          "size": "3583kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T14:30:57+00:00",
          "link": "https://arxiv.org/abs/2505.12864v3",
          "size": "3572kb",
          "version": "v3"
        }
      ],
      "title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12864",
        "HTML": "https://arxiv.org/html/2505.12864v3",
        "PDF": "https://arxiv.org/pdf/2505.12864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a new benchmark for legal reasoning using existing law exams but does not delve into the processing of LLM training data itself."
      },
      "datasets": [
        {
          "dataset_name": "LEXam-Benchmark/LEXam",
          "downloads": "712",
          "likes": "30",
          "link": "https://huggingface.co/datasets/LEXam-Benchmark/LEXam"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Legal Reasoning",
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06710",
      "abstract": "Visual imitation learning is effective for robots to learn versatile tasks. However, many existing methods rely on behavior cloning with supervised historical trajectories, limiting their 3D spatial and 4D spatiotemporal awareness. Consequently, these methods struggle to capture the 3D structures and 4D spatiotemporal relationships necessary for real-world deployment. In this work, we propose 4D Diffusion Policy (DP4), a novel visual imitation learning method that incorporates spatiotemporal awareness into diffusion-based policies. Unlike traditional approaches that rely on trajectory cloning, DP4 leverages a dynamic Gaussian world model to guide the learning of 3D spatial and 4D spatiotemporal perceptions from interactive environments. Our method constructs the current 3D scene from a single-view RGB-D observation and predicts the future 3D scene, optimizing trajectory generation by explicitly modeling both spatial and temporal dependencies. Extensive experiments across 17 simulation tasks with 173 variants and 3 real-world robotic tasks demonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods, improving the average simulation task success rate by 16.4% (Adroit), 14% (DexArt), and 6.45% (RLBench), and the average real-world robotic task success rate by 8.6%.",
      "authors": [
        "Zhenyang Liu",
        "Yikai Wang",
        "Kuanning Wang",
        "Longfei Liang",
        "Xiangyang Xue",
        "Yanwei Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:08:15+00:00",
          "link": "https://arxiv.org/abs/2507.06710v1",
          "size": "3412kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T06:32:40+00:00",
          "link": "https://arxiv.org/abs/2507.06710v2",
          "size": "3412kb",
          "version": "v2"
        }
      ],
      "title": "Spatial-Temporal Aware Visuomotor Diffusion Policy Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06710",
        "HTML": "https://arxiv.org/html/2507.06710v2",
        "PDF": "https://arxiv.org/pdf/2507.06710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper on visual imitation learning and diffusion policy learning for robots does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09317",
      "abstract": "There is no much doubt that biotic interactions shape community assembly and ultimately the spatial co-variations between species. There is a hope that the signal of these biotic interactions can be observed and retrieved by investigating the spatial associations between species while accounting for the direct effects of the environment. By definition, biotic interactions can be both symmetric and asymmetric. Yet, most models that attempt to retrieve species associations from co-occurrence or co-abundance data internally assume symmetric relationships between species. Here, we propose and validate a machine-learning framework able to retrieve bidirectional associations by analyzing species community and environmental data.\n  Our framework (1) models pairwise species associations as directed influences from a source to a target species, parameterized with two species-specific latent embeddings: the effect of the source species on the community, and the response of the target species to the community; and (2) jointly fits these associations within a multi-species conditional generative model with different modes of interactions between environmental drivers and biotic associations. Using both simulated and empirical data, we demonstrate the ability of our framework to recover known asymmetric and symmetric associations and highlight the properties of the learned association networks. By comparing our approach to other existing models such as joint species distribution models and probabilistic graphical models, we show its superior capacity at retrieving symmetric and asymmetric interactions. The framework is intuitive, modular and broadly applicable across various taxonomic groups.",
      "authors": [
        "Sara Si-Moussi",
        "Esther Galbrun",
        "Mickael Hedde",
        "Giovanni Poggiato",
        "Matthias Rohr",
        "Wilfried Thuiller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:18:36+00:00",
          "link": "https://arxiv.org/abs/2507.09317v1",
          "size": "1663kb",
          "version": "v1"
        }
      ],
      "title": "Uncovering symmetric and asymmetric species associations from community and environmental data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09317",
        "HTML": "https://arxiv.org/html/2507.09317v1",
        "PDF": "https://arxiv.org/pdf/2507.09317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses species associations in ecological data using machine learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09882",
      "abstract": "Non-invasive Brain-Computer Interfaces (BCI) offer a safe and accessible means of connecting the human brain to external devices, with broad applications in home and clinical settings to enhance human capabilities. However, the high noise level and limited task-specific data in non-invasive signals constrain decoding capabilities. Recently, the adoption of self-supervised pre-training is transforming the landscape of non-invasive BCI research, enabling the development of brain foundation models to capture generic neural representations from large-scale unlabeled electroencephalography (EEG) signals with substantial noises. However, despite these advances, the field currently lacks comprehensive, practical and extensible benchmarks to assess the utility of the public foundation models across diverse BCI tasks, hindering their widespread adoption. To address this challenge, we present AdaBrain-Bench, a large-scale standardized benchmark to systematically evaluate brain foundation models in widespread non-invasive BCI tasks. AdaBrain-Bench encompasses a diverse collection of representative BCI decoding datasets spanning 7 key applications. It introduces a streamlined task adaptation pipeline integrated with multi-dimensional evaluation metrics and a set of adaptation tools. The benchmark delivers an inclusive framework for assessing generalizability of brain foundation models across key transfer settings, including cross-subject, multi-subject, and few-shot scenarios. We leverage AdaBrain-Bench to evaluate a suite of publicly available brain foundation models and offer insights into practices for selecting appropriate models in various scenarios. We make our benchmark pipeline available to enable reproducible research and external use, offering a continuously evolving platform to foster progress toward robust and generalized neural decoding solutions.",
      "authors": [
        "Jiamin Wu",
        "Zichen Ren",
        "Junyu Wang",
        "Pengyu Zhu",
        "Yonghao Song",
        "Mianxin Liu",
        "Qihao Zheng",
        "Lei Bai",
        "Wanli Ouyang",
        "Chunfeng Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:37:41+00:00",
          "link": "https://arxiv.org/abs/2507.09882v1",
          "size": "3000kb",
          "version": "v1"
        }
      ],
      "title": "AdaBrain-Bench: Benchmarking Brain Foundation Models for Brain-Computer Interface Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09882",
        "HTML": "https://arxiv.org/html/2507.09882v1",
        "PDF": "https://arxiv.org/pdf/2507.09882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper introduces a benchmark for brain foundation models, it does not focus on the processing or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09953",
      "abstract": "While electron microscopy offers crucial atomic-resolution insights into structure-property relationships, radiation damage severely limits its use on beam-sensitive materials like proteins and 2D materials. To overcome this challenge, we push beyond the electron dose limits of conventional electron microscopy by adapting principles from multi-image super-resolution (MISR) that have been widely used in remote sensing. Our method fuses multiple low-resolution, sub-pixel-shifted views and enhances the reconstruction with a convolutional neural network (CNN) that integrates features from synthetic, multi-angle observations. We developed a dual-path, attention-guided network for 4D-STEM that achieves atomic-scale super-resolution from ultra-low-dose data. This provides robust atomic-scale visualization across amorphous, semi-crystalline, and crystalline beam-sensitive specimens. Systematic evaluations on representative materials demonstrate comparable spatial resolution to conventional ptychography under ultra-low-dose conditions. Our work expands the capabilities of 4D-STEM, offering a new and generalizable method for the structural analysis of radiation-vulnerable materials.",
      "authors": [
        "Zifei Wang",
        "Zian Mao",
        "Xiaoya He",
        "Xi Huang",
        "Haoran Zhang",
        "Chun Cheng",
        "Shufen Chu",
        "Tingzheng Hou",
        "Xiaoqin Zeng",
        "Yujun Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:02:05+00:00",
          "link": "https://arxiv.org/abs/2507.09953v1",
          "size": "36655kb",
          "version": "v1"
        }
      ],
      "title": "4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09953",
        "HTML": "https://arxiv.org/html/2507.09953v1",
        "PDF": "https://arxiv.org/pdf/2507.09953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on low-dose super-resolution imaging using feature fusion, unrelated to any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10445",
      "abstract": "In this work we examine LLMs' ability to ask clarification questions in task-oriented dialogues that follow the asynchronous instruction-giver/instruction-follower format. We present a new corpus that combines two existing annotations of the Minecraft Dialogue Corpus -- one for reference and ambiguity in reference, and one for SDRT including clarifications -- into a single common format providing the necessary information to experiment with clarifications and their relation to ambiguity. With this corpus we compare LLM actions with original human-generated clarification questions, examining how both humans and LLMs act in the case of ambiguity. We find that there is only a weak link between ambiguity and humans producing clarification questions in these dialogues, and low correlation between humans and LLMs. Humans hardly ever produce clarification questions for referential ambiguity, but often do so for task-based uncertainty. Conversely, LLMs produce more clarification questions for referential ambiguity, but less so for task uncertainty. We question if LLMs' ability to ask clarification questions is predicated on their recent ability to simulate reasoning, and test this with different reasoning approaches, finding that reasoning does appear to increase question frequency and relevancy.",
      "authors": [
        "Chris Madge",
        "Matthew Purver",
        "Massimo Poesio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:28:00+00:00",
          "link": "https://arxiv.org/abs/2507.10445v1",
          "size": "198kb",
          "version": "v1"
        }
      ],
      "title": "Referential ambiguity and clarification requests: comparing human and LLM behaviour",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10445",
        "HTML": "https://arxiv.org/html/2507.10445v1",
        "PDF": "https://arxiv.org/pdf/2507.10445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new corpus combining annotations for dialogue ambiguity, it focuses primarily on evaluating LLMs' behavior rather than processing training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.16370",
      "abstract": "Safe and efficient multi-agent navigation in dynamic environments remains inherently challenging, particularly when real-time decision-making is required on resource-constrained platforms. Ensuring collision-free trajectories while adapting to uncertainties without relying on pre-built maps further complicates real-world deployment. To address these challenges, we propose LSTP-Nav, a lightweight end-to-end policy for multi-agent navigation that enables map-free collision avoidance in complex environments by directly mapping raw LiDAR point clouds to motion commands. At the core of this framework lies LSTP-Net, an efficient network that processes raw LiDAR data using a GRU architecture, enhanced with attention mechanisms to dynamically focus on critical environmental features while minimizing computational overhead. Additionally, a novel HS reward optimizes collision avoidance by incorporating angular velocity, prioritizing obstacles along the predicted heading, and enhancing training stability. To narrow the sim-to-real gap, we develop PhysReplay-Simlab, a physics-realistic multi-agent simulator, employs localized replay to mine near-failure experiences. Relying solely on LiDA, LSTP-Nav achieves efficient zero-shot sim-to-real transfer on a CPU-only robotic platform, enabling robust navigation in dynamic environments while maintaining computation frequencies above 40 Hz. Extensive experiments demonstrate that LSTP-Nav outperforms baselines with a 9.58\\% higher success rate and a 12.30\\% lower collision rate, underscoring its practicality and robustness for real-world applications.",
      "authors": [
        "Xingrong Diao",
        "Zhirui Sun",
        "Jianwei Peng",
        "Jiankun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-29T09:28:05+00:00",
          "link": "https://arxiv.org/abs/2408.16370v1",
          "size": "10497kb",
          "version": "v1"
        },
        {
          "date": "2024-09-04T02:39:53+00:00",
          "link": "https://arxiv.org/abs/2408.16370v2",
          "size": "10099kb",
          "version": "v2"
        },
        {
          "date": "2025-02-24T11:35:07+00:00",
          "link": "https://arxiv.org/abs/2408.16370v3",
          "size": "10092kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T15:49:24+00:00",
          "link": "https://arxiv.org/abs/2408.16370v4",
          "size": "73394kb",
          "version": "v4"
        }
      ],
      "title": "LSTP-Nav: Lightweight Spatiotemporal Policy for Map-free Multi-agent Navigation with LiDAR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16370",
        "HTML": "https://arxiv.org/html/2408.16370v4",
        "PDF": "https://arxiv.org/pdf/2408.16370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a navigation policy for multi-agent systems using LiDAR data; it does not involve any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.05842",
      "abstract": "Deep-learning-based nonlinear system identification has shown the ability to produce reliable and highly accurate models in practice. However, these black-box models lack physical interpretability, and a considerable part of the learning effort is often spent on capturing already expected/known behavior of the system, that can be accurately described by first-principles laws of physics. A potential solution is to directly integrate such prior physical knowledge into the model structure, combining the strengths of physics-based modeling and deep-learning-based identification. The most common approach is to use an additive model augmentation structure, where the physics-based and the machine-learning (ML) components are connected in parallel, i.e., additively. However, such models are overparametrized, training them is challenging, potentially causing the physics-based part to lose interpretability. To overcome this challenge, this paper proposes an orthogonal projection-based regularization technique to enhance parameter learning and even model accuracy in learning-based augmentation of nonlinear baseline models.",
      "authors": [
        "Bendeg\\'uz M. Gy\\\"or\\\"ok",
        "Jan H. Hoekstra",
        "Johan Kon",
        "Tam\\'as P\\'eni",
        "Maarten Schoukens",
        "Roland T\\'oth"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T10:33:13+00:00",
          "link": "https://arxiv.org/abs/2501.05842v1",
          "size": "1502kb",
          "version": "v1"
        },
        {
          "date": "2025-04-22T08:57:26+00:00",
          "link": "https://arxiv.org/abs/2501.05842v2",
          "size": "1505kb",
          "version": "v2"
        }
      ],
      "title": "Orthogonal projection-based regularization for efficient model augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05842",
        "HTML": "https://arxiv.org/html/2501.05842",
        "PDF": "https://arxiv.org/pdf/2501.05842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses model augmentation via orthogonal projection regularization, focusing on combining physics-based models with learning algorithms rather than LLM training data processing."
      },
      "tasks": [
        "model"
      ],
      "repo_urls": [
        "https://github.com/aimotionlab-sztaki/orthogonal-augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02777",
      "abstract": "The even online Kolmogorov complexity of a string $x = x_1 x_2 \\cdots x_{n}$ is the minimal length of a program that for all $i\\le n/2$, on input $x_1x_3 \\cdots x_{2i-1}$ outputs $x_{2i}$. The odd complexity is defined similarly. The sum of the odd and even complexities is called the dialogue complexity.\n  In [Bauwens, 2014] it is proven that for all $n$, there exist $n$-bit $x$ for which the dialogue complexity exceeds the Kolmogorov complexity by $n\\log \\frac 4 3 + O(\\log n)$. Let $\\mathrm C^s(x)$ denote the Kolmogorov complexity with space bound~$s$. Here, we prove that the space-bounded dialogue complexity with bound $s + 6n + O(1)$ is at most $\\mathrm C^{s}(x) + O(\\log (sn))$, where $n=|x|$.",
      "authors": [
        "Bruno Bauwens and Maria Marchenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T23:39:15+00:00",
          "link": "https://arxiv.org/abs/2502.02777v1",
          "size": "9kb",
          "version": "v1"
        },
        {
          "date": "2025-04-13T15:47:46+00:00",
          "link": "https://arxiv.org/abs/2502.02777v2",
          "size": "41kb",
          "version": "v2"
        },
        {
          "date": "2025-04-17T20:11:03+00:00",
          "link": "https://arxiv.org/abs/2502.02777v3",
          "size": "20kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T07:36:40+00:00",
          "link": "https://arxiv.org/abs/2502.02777v4",
          "size": "21kb",
          "version": "v4"
        }
      ],
      "title": "Space-bounded online Kolmogorov complexity is additive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02777",
        "HTML": "https://arxiv.org/html/2502.02777v4",
        "PDF": "https://arxiv.org/pdf/2502.02777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses space-bounded Kolmogorov complexity. It does not contribute to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05332",
      "abstract": "3D Gaussian Splatting (3DGS) has gained significant attention due to its high-quality novel view rendering, motivating research to address real-world challenges. A critical issue is the camera motion blur caused by movement during exposure, which hinders accurate 3D scene reconstruction. In this study, we propose CoMoGaussian, a Continuous Motion-Aware Gaussian Splatting that reconstructs precise 3D scenes from motion-blurred images while maintaining real-time rendering speed. Considering the complex motion patterns inherent in real-world camera movements, we predict continuous camera trajectories using neural ordinary differential equations (ODEs). To ensure accurate modeling, we employ rigid body transformations, preserving the shape and size of the object but rely on the discrete integration of sampled frames. To better approximate the continuous nature of motion blur, we introduce a continuous motion refinement (CMR) transformation that refines rigid transformations by incorporating additional learnable parameters. By revisiting fundamental camera theory and leveraging advanced neural ODE techniques, we achieve precise modeling of continuous camera trajectories, leading to improved reconstruction accuracy. Extensive experiments demonstrate state-of-the-art performance both quantitatively and qualitatively on benchmark datasets, which include a wide range of motion blur scenarios, from moderate to extreme blur.",
      "authors": [
        "Jungho Lee",
        "Donghyeong Kim",
        "Dogyoon Lee",
        "Suhwan Cho",
        "Minhyeok Lee",
        "Wonjoon Lee",
        "Taeoh Kim",
        "Dongyoon Wee",
        "Sangyoun Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T11:18:43+00:00",
          "link": "https://arxiv.org/abs/2503.05332v1",
          "size": "17350kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T12:10:17+00:00",
          "link": "https://arxiv.org/abs/2503.05332v2",
          "size": "17340kb",
          "version": "v2"
        }
      ],
      "title": "CoMoGaussian: Continuous Motion-Aware Gaussian Splatting from Motion-Blurred Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05332",
        "HTML": "https://arxiv.org/html/2503.05332v2",
        "PDF": "https://arxiv.org/pdf/2503.05332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on motion-aware Gaussian splatting for 3D scene reconstruction from images, not related to LLM training data processing or data engineering."
      },
      "tasks": [
        "3DGS",
        "3D Scene Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/jho-yonsei/comogaussian"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23519",
      "abstract": "Semi-supervised semantic segmentation (SS-SS) aims to mitigate the heavy annotation burden of dense pixel labeling by leveraging abundant unlabeled images alongside a small labeled set. While current consistency regularization methods achieve strong results, they often overlook a critical challenge: the precise delineation of object boundaries. In this paper, we propose BoundMatch, a novel multi-task SS-SS framework that explicitly integrates semantic boundary detection into a teacher-student consistency regularization pipeline. Our core mechanism, Boundary Consistency Regularized Multi-Task Learning (BCRM), enforces prediction agreement between teacher and student models on both segmentation masks and detailed semantic boundaries. To further enhance performance and sharpen boundaries, BoundMatch incorporates two lightweight fusion modules: Boundary-Semantic Fusion (BSF) injects learned boundary cues into the segmentation decoder, while Spatial Gradient Fusion (SGF) refines boundary predictions using mask gradients, leading to higher-quality boundary pseudo-labels. This framework is built upon SAMTH, a strong teacher-student baseline featuring a Harmonious Batch Normalization (HBN) update strategy for improved stability. Extensive experiments on diverse urban-driving scene datasets including Cityscapes, BDD100K, and SYNTHIA show that BoundMatch achieves competitive performance against current state-of-the-art methods. Our approach achieves state-of-the-art results on the new benchmark with DINOv2 foundation model. We further validate our approach's generalizability on Pascal VOC and ADE20K datasets. Ablation studies highlight BoundMatch's ability to improve boundary-specific evaluation metrics, its effectiveness in realistic large-scale unlabeled data scenarios, and applicability to lightweight architectures for mobile deployment.",
      "authors": [
        "Haruya Ishikawa and Yoshimitsu Aoki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-30T17:02:26+00:00",
          "link": "https://arxiv.org/abs/2503.23519v1",
          "size": "3558kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T15:10:51+00:00",
          "link": "https://arxiv.org/abs/2503.23519v2",
          "size": "8086kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T06:26:48+00:00",
          "link": "https://arxiv.org/abs/2503.23519v3",
          "size": "8093kb",
          "version": "v3"
        }
      ],
      "title": "BoundMatch: Boundary detection applied to semi-supervised segmentation for urban-driving scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23519",
        "HTML": "https://arxiv.org/html/2503.23519v3",
        "PDF": "https://arxiv.org/pdf/2503.23519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic segmentation for urban-driving scenes, specifically boundary detection in teacher-student frameworks, with no mention of LLM training data processing."
      },
      "tasks": [
        "Boundary Detection",
        "Multi-Task Learning",
        "Semantic Segmentation",
        "Semi-Supervised Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13575",
      "abstract": "We present an experimental study of a fiber Bragg grating (FBG) interrogator based on a silicon oxynitride (SiON) photonic integrated arrayed waveguide grating (AWG). While AWG-based interrogators are compact and scalable, their practical performance is limited by non-ideal spectral responses. To address this, two calibration strategies within a 2.4 nm spectral region were compared: (1) a segmented analytical model based on a sigmoid fitting function, and (2) a machine learning (ML)-based regression model. The analytical method achieves a root mean square error (RMSE) of 7.11 pm within the calibrated range, while the ML approach based on exponential regression achieves 3.17 pm. Moreover, the ML model demonstrates generalization across an extended 2.9 nm wavelength span, maintaining sub-5 pm accuracy without re-fitting. Residual and error distribution analyses further illustrate the trade-offs between the two approaches. ML-based calibration provides a robust, data-driven alternative to analytical methods, delivering enhanced accuracy for non-ideal channel responses, reduced manual calibration effort, and improved scalability across diverse FBG sensor configurations.",
      "authors": [
        "Ivan A. Kazakov",
        "Iana V. Kulichenko",
        "Egor E. Kovalev",
        "Angelina A. Treskova",
        "Daria D. Barma",
        "Kirill M. Malakhov",
        "Arkady V. Shipulin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T14:58:03+00:00",
          "link": "https://arxiv.org/abs/2506.13575v1",
          "size": "164kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning-Driven Compensation for Non-Ideal Channels in AWG-Based FBG Interrogator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13575",
        "HTML": "https://arxiv.org/html/2506.13575",
        "PDF": "https://arxiv.org/pdf/2506.13575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers on machine learning-driven compensation for non-ideal channel responses in FBG interrogators, not on LLM training data processing or engineering."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22027",
      "abstract": "Detecting and tracking ground objects using earth observation imagery remains a significant challenge in the field of remote sensing. Continuous maritime ship tracking is crucial for applications such as maritime search and rescue, law enforcement, and shipping analysis. However, most current ship tracking methods rely on geostationary satellites or video satellites. The former offer low resolution and are susceptible to weather conditions, while the latter have short filming durations and limited coverage areas, making them less suitable for the real-world requirements of ship tracking. To address these limitations, we present the Hybrid Optical and Synthetic Aperture Radar (SAR) Ship Re-Identification Dataset (HOSS ReID dataset), designed to evaluate the effectiveness of ship tracking using low-Earth orbit constellations of optical and SAR sensors. This approach ensures shorter re-imaging cycles and enables all-weather tracking. HOSS ReID dataset includes images of the same ship captured over extended periods under diverse conditions, using different satellites of different modalities at varying times and angles. Furthermore, we propose a baseline method for cross-modal ship re-identification, TransOSS, which is built on the Vision Transformer architecture. It refines the patch embedding structure to better accommodate cross-modal tasks, incorporates additional embeddings to introduce more reference information, and employs contrastive learning to pre-train on large-scale optical-SAR image pairs, ensuring the model's ability to extract modality-invariant features. Our dataset and baseline method are publicly available on https://github.com/Alioth2000/Hoss-ReID.",
      "authors": [
        "Han Wang",
        "Shengyang Li",
        "Jian Yang",
        "Yuxuan Liu",
        "Yixuan Lv",
        "Zhuang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2506.22027v1",
          "size": "1008kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:25:58+00:00",
          "link": "https://arxiv.org/abs/2506.22027v2",
          "size": "1342kb",
          "version": "v2"
        }
      ],
      "title": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22027",
        "HTML": "https://arxiv.org/html/2506.22027v2",
        "PDF": "https://arxiv.org/pdf/2506.22027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a new dataset with detailed data processing steps for cross-modal ship re-identification, focusing on data quality through multimodal data collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09036",
      "abstract": "BrainLesion Suite is a versatile toolkit for building modular brain lesion image analysis pipelines in Python. Following Pythonic principles, BrainLesion Suite is designed to provide a 'brainless' development experience, minimizing cognitive effort and streamlining the creation of complex workflows for clinical and scientific practice. At its core is an adaptable preprocessing module that performs co-registration, atlas registration, and optional skull-stripping and defacing on arbitrary multi-modal input images. BrainLesion Suite leverages algorithms from the BraTS challenge to synthesize missing modalities, inpaint lesions, and generate pathology-specific tumor segmentations. BrainLesion Suite also enables quantifying segmentation model performance, with tools such as panoptica to compute lesion-wise metrics. Although BrainLesion Suite was originally developed for image analysis pipelines of brain lesions such as glioma, metastasis, and multiple sclerosis, it can be adapted for other biomedical image analysis applications. The individual BrainLesion Suite packages and tutorials are accessible on GitHub.",
      "authors": [
        "Florian Kofler",
        "Marcel Rosier",
        "Mehdi Astaraki",
        "Hendrik M\\\"oller",
        "Ilhem Isra Mekki",
        "Josef A. Buchner",
        "Anton Schmick",
        "Arianna Pfiffer",
        "Eva Oswald",
        "Lucas Zimmer",
        "Ezequiel de la Rosa",
        "Sarthak Pati",
        "Julian Canisius",
        "Arianna Piffer",
        "Ujjwal Baid",
        "Mahyar Valizadeh",
        "Akis Linardos",
        "Jan C. Peeken",
        "Surprosanna Shit",
        "Felix Steinbauer",
        "Daniel Rueckert",
        "Rolf Heckemann",
        "Spyridon Bakas",
        "Jan Kirschke",
        "Constantin von See",
        "Ivan Ezhov",
        "Marie Piraud",
        "Benedikt Wiestler",
        "Bjoern Menze"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:32:45+00:00",
          "link": "https://arxiv.org/abs/2507.09036v1",
          "size": "3133kb",
          "version": "v1"
        }
      ],
      "title": "BrainLesion Suite: A Flexible and User-Friendly Framework for Modular Brain Lesion Image Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09036",
        "HTML": "https://arxiv.org/html/2507.09036v1",
        "PDF": "https://arxiv.org/pdf/2507.09036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on brain lesion image analysis and modular pipelines for image processing, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10164",
      "abstract": "Developing robust locomotion controllers for bipedal robots with closed kinematic chains presents unique challenges, particularly since most reinforcement learning (RL) approaches simplify these parallel mechanisms into serial models during training. We demonstrate that this simplification significantly impairs sim-to-real transfer by failing to capture essential aspects such as joint coupling, friction dynamics, and motor-space control characteristics. In this work, we present an RL framework that explicitly incorporates closed-chain dynamics and validate it on our custom-built robot TopA. Our approach enhances policy robustness through symmetry-aware loss functions, adversarial training, and targeted network regularization. Experimental results demonstrate that our integrated approach achieves stable locomotion across diverse terrains, significantly outperforming methods based on simplified kinematic models.",
      "authors": [
        "Egor Maslennikov",
        "Eduard Zaliaev",
        "Nikita Dudorov",
        "Oleg Shamanin",
        "Karanov Dmitry",
        "Gleb Afanasev",
        "Alexey Burkov",
        "Egor Lygin",
        "Simeon Nedelchev",
        "Evgeny Ponomarev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:25:13+00:00",
          "link": "https://arxiv.org/abs/2507.10164v1",
          "size": "1403kb",
          "version": "v1"
        }
      ],
      "title": "Robust RL Control for Bipedal Locomotion with Closed Kinematic Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10164",
        "HTML": "https://arxiv.org/html/2507.10164v1",
        "PDF": "https://arxiv.org/pdf/2507.10164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a framework for developing robust locomotion controllers using RL, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10283",
      "abstract": "Transformer-based deep neural networks have achieved remarkable success across various computer vision tasks, largely attributed to their long-range self-attention mechanism and scalability. However, most transformer architectures embed images into uniform, grid-based vision tokens, neglecting the underlying semantic meanings of image regions, resulting in suboptimal feature representations. To address this issue, we propose Fuzzy Token Clustering Transformer (FTCFormer), which incorporates a novel clustering-based downsampling module to dynamically generate vision tokens based on the semantic meanings instead of spatial positions. It allocates fewer tokens to less informative regions and more to represent semantically important regions, regardless of their spatial adjacency or shape irregularity. To further enhance feature extraction and representation, we propose a Density Peak Clustering-Fuzzy K-Nearest Neighbor (DPC-FKNN) mechanism for clustering center determination, a Spatial Connectivity Score (SCS) for token assignment, and a channel-wise merging (Cmerge) strategy for token merging. Extensive experiments on 32 datasets across diverse domains validate the effectiveness of FTCFormer on image classification, showing consistent improvements over the TCFormer baseline, achieving gains of improving 1.43% on five fine-grained datasets, 1.09% on six natural image datasets, 0.97% on three medical datasets and 0.55% on four remote sensing datasets. The code is available at: https://github.com/BaoBao0926/FTCFormer/tree/main.",
      "authors": [
        "Muyi Bao",
        "Changyu Zeng",
        "Yifan Wang",
        "Zhengni Yang",
        "Zimu Wang",
        "Guangliang Cheng",
        "Jun Qi and Wei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:49:47+00:00",
          "link": "https://arxiv.org/abs/2507.10283v1",
          "size": "3009kb",
          "version": "v1"
        }
      ],
      "title": "FTCFormer: Fuzzy Token Clustering Transformer for Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10283",
        "HTML": "https://arxiv.org/html/2507.10283v1",
        "PDF": "https://arxiv.org/pdf/2507.10283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces FTCFormer, a Transformer for image classification, focusing on vision token clustering for better feature representation. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09383",
      "abstract": "Motivated by the problem of pursuit-evasion, we present a motion planning framework that combines energy-based diffusion models with artificial potential fields for robust real time trajectory generation in complex environments. Our approach processes obstacle information directly from point clouds, enabling efficient planning without requiring complete geometric representations. The framework employs classifier-free guidance training and integrates local potential fields during sampling to enhance obstacle avoidance. In dynamic scenarios, the system generates initial trajectories using the diffusion model and continuously refines them through potential field-based adaptation, demonstrating effective performance in pursuit-evasion scenarios with partial pursuer observability.",
      "authors": [
        "Wondmgezahu Teshome",
        "Kian Behzad",
        "Octavia Camps",
        "Michael Everett",
        "Milad Siami and Mario Sznaier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T19:42:07+00:00",
          "link": "https://arxiv.org/abs/2507.09383v1",
          "size": "1806kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Adaptive Motion Planning via Point Cloud-Guided, Energy-Based Diffusion and Potential Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09383",
        "HTML": "https://arxiv.org/html/2507.09383v1",
        "PDF": "https://arxiv.org/pdf/2507.09383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a motion planning framework for trajectory generation using point clouds. It does not involve the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09712",
      "abstract": "In this paper, we propose a novel function named Rate Distortion-in-Distortion (RDD) function as an extension of the classical rate-distortion (RD) function, where the expected distortion constraint is replaced by the Gromov-type distortion. This distortion, integral to the Gromov-Wasserstein (GW) distance, effectively defines the similarity in spaces of different dimensions without a direct metric between them. While our RDD function qualifies as an informational RD function, encoding theorems substantiate its status as an operational RD function, thereby underscoring its potential applicability in real-world source coding. Due to the high computational complexity associated with Gromov-type distortion, the RDD function cannot be solved analytically. Consequently, we develop an alternating mirror descent algorithm that significantly reduces computational complexity by employing decomposition, linearization, and relaxation techniques. Simulations on classical sources and different grids demonstrate the effectiveness of our algorithm. By examining the distinctions and connections between the RDD function and the RD function, we anticipate that RDD function will play a novel role in foreseeable future scenarios.",
      "authors": [
        "Lingyi Chen and Haoran Tang and Shitong Wu and Jiakun Liu and Huihui Wu and Wenyi Zhang and Hao Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:15:21+00:00",
          "link": "https://arxiv.org/abs/2507.09712v1",
          "size": "293kb",
          "version": "v1"
        }
      ],
      "title": "RDD Function: A Tradeoff Between Rate and Distortion-in-Distortion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09712",
        "HTML": "https://arxiv.org/html/2507.09712v1",
        "PDF": "https://arxiv.org/pdf/2507.09712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Rate Distortion-in-Distortion function and its applications in source coding, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09764",
      "abstract": "We investigate binary sequences generated by non-Markovian rules with memory length $\\mu$, similar to those adopted in Elementary Cellular Automata. This generation procedure is equivalente to a shift register and certain rules produce sequences with maximal periods, known as de Bruijn sequences. We introduce a novel methodology for generating de Bruijn sequences that combines: (i) a set of derived properties that significantly reduce the space of feasible generating rules, and (ii) a neural network-based classifier that identifies which rules produce de Bruijn sequences. Experiments for large values of $\\mu$ demonstrate the approach's effectiveness and computational efficiency.",
      "authors": [
        "Francisco J. Mu\\~noz",
        "Juan Carlos Nu\\~no"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:45:41+00:00",
          "link": "https://arxiv.org/abs/2507.09764v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "Rule-based Generation of de Bruijn Sequences: Memory and Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09764",
        "HTML": "https://arxiv.org/html/2507.09764v1",
        "PDF": "https://arxiv.org/pdf/2507.09764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses de Bruijn sequences and their generation but does not pertain to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10039",
      "abstract": "Single-cell foundation models such as scGPT represent a significant advancement in single-cell omics, with an ability to achieve state-of-the-art performance on various downstream biological tasks. However, these models are inherently limited in that a vast amount of information in biology exists as text, which they are unable to leverage. There have therefore been several recent works that propose the use of LLMs as an alternative to single-cell foundation models, achieving competitive results. However, there is little understanding of what factors drive this performance, along with a strong focus on using LLMs as an alternative, rather than complementary approach to single-cell foundation models. In this study, we therefore investigate what biological insights contribute toward the performance of LLMs when applied to single-cell data, and introduce scMPT; a model which leverages synergies between scGPT, and single-cell representations from LLMs that capture these insights. scMPT demonstrates stronger, more consistent performance than either of its component models, which frequently have large performance gaps between each other across datasets. We also experiment with alternate fusion methods, demonstrating the potential of combining specialized reasoning models with scGPT to improve performance. This study ultimately showcases the potential for LLMs to complement single-cell foundation models and drive improvements in single-cell analysis.",
      "authors": [
        "Steven Palayew",
        "Bo Wang",
        "Gary Bader"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:16:58+00:00",
          "link": "https://arxiv.org/abs/2507.10039v1",
          "size": "475kb",
          "version": "v1"
        }
      ],
      "title": "Towards Applying Large Language Models to Complement Single-Cell Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10039",
        "HTML": "https://arxiv.org/html/2507.10039v1",
        "PDF": "https://arxiv.org/pdf/2507.10039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on the use of LLMs to complement single-cell models but does not discuss specific LLM training data processing techniques or contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10349",
      "abstract": "Multi-horizon time series forecasting has many practical applications such as demand forecasting. Accurate demand prediction is critical to help make buying and inventory decisions for supply chain management of e-commerce and physical retailers, and such predictions are typically required for future horizons extending tens of weeks. This is especially challenging during high-stake sales events when demand peaks are particularly difficult to predict accurately. However, these events are important not only for managing supply chain operations but also for ensuring a seamless shopping experience for customers. To address this challenge, we propose Temporal-Aligned Transformer (TAT), a multi-horizon forecaster leveraging apriori-known context variables such as holiday and promotion events information for improving predictive performance. Our model consists of an encoder and decoder, both embedded with a novel Temporal Alignment Attention (TAA), designed to learn context-dependent alignment for peak demand forecasting. We conduct extensive empirical analysis on two large-scale proprietary datasets from a large e-commerce retailer. We demonstrate that TAT brings up to 30% accuracy improvement on peak demand forecasting while maintaining competitive overall performance compared to other state-of-the-art methods.",
      "authors": [
        "Zhiyuan Zhao",
        "Sitan Yang",
        "Kin G. Olivares",
        "Boris N. Oreshkin",
        "Stan Vitebsky",
        "Michael W. Mahoney",
        "B. Aditya Prakash",
        "Dmitry Efimov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:51:24+00:00",
          "link": "https://arxiv.org/abs/2507.10349v1",
          "size": "632kb",
          "version": "v1"
        }
      ],
      "title": "TAT: Temporal-Aligned Transformer for Multi-Horizon Peak Demand Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10349",
        "HTML": "https://arxiv.org/html/2507.10349v1",
        "PDF": "https://arxiv.org/pdf/2507.10349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a transformer model for time series forecasting, which is about prediction, not LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10436",
      "abstract": "We present a polynomial-time $(\\alpha_{GW} + \\varepsilon)$-approximation algorithm for the Maximum Cut problem on interval graphs and split graphs, where $\\alpha_{GW} \\approx 0.878$ is the approximation guarantee of the Goemans-Williamson algorithm and $\\varepsilon > 10^{-34}$ is a fixed constant. To attain this, we give an improved analysis of a slight modification of the Goemans-Williamson algorithm for graphs in which triangles can be packed into a constant fraction of their edges. We then pair this analysis with structural results showing that both interval graphs and split graphs either have such a triangle packing or have maximum cut close to their number of edges. We also show that, subject to the Small Set Expansion Hypothesis, there exists a constant $c > 0$ such that there is no polyomial-time $(1 - c)$-approximation for Maximum Cut on split graphs.",
      "authors": [
        "Jungho Ahn",
        "Ian DeHaan",
        "Eun Jung Kim",
        "Euiwoong Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:24:20+00:00",
          "link": "https://arxiv.org/abs/2507.10436v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Approximating Maximum Cut on Interval Graphs and Split Graphs beyond Goemans-Williamson",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10436",
        "HTML": "https://arxiv.org/html/2507.10436v1",
        "PDF": "https://arxiv.org/pdf/2507.10436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a graph theory algorithmic improvement for maximum cut problems, with no discussion of training data processing or creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.06797",
      "abstract": "We study the classic correlation clustering in the dynamic setting. Given $n$ objects and a complete labeling of the object-pairs as either similar or dissimilar, the goal is to partition the objects into arbitrarily many clusters while minimizing disagreements with the labels. In the dynamic setting, an update consists of a flip of a label of an edge. In a breakthrough result, [BDHSS, FOCS'19] showed how to maintain a 3-approximation with polylogarithmic update time by providing a dynamic implementation of the Pivot algorithm of [ACN, STOC'05]. Since then, it has been a major open problem to determine whether the 3-approximation barrier can be broken in the fully dynamic setting. In this paper, we resolve this problem. Our algorithm, Modified Pivot, locally improves the output of Pivot by moving some vertices to other existing clusters or new singleton clusters. We present an analysis showing that this modification does indeed improve the approximation to below 3. We also show that its output can be maintained in polylogarithmic time per update.",
      "authors": [
        "Soheil Behnezhad",
        "Moses Charikar",
        "Vincent Cohen-Addad",
        "Alma Ghafari",
        "Weiyun Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T07:36:34+00:00",
          "link": "https://arxiv.org/abs/2404.06797v1",
          "size": "243kb",
          "version": "v1"
        },
        {
          "date": "2024-04-11T18:35:12+00:00",
          "link": "https://arxiv.org/abs/2404.06797v2",
          "size": "243kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T16:17:14+00:00",
          "link": "https://arxiv.org/abs/2404.06797v3",
          "size": "187kb",
          "version": "v3"
        }
      ],
      "title": "Correlation Clustering Beyond the Pivot Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.06797",
        "HTML": "https://arxiv.org/html/2404.06797v3",
        "PDF": "https://arxiv.org/pdf/2404.06797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses correlation clustering algorithms and their dynamic settings, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.17170",
      "abstract": "Quantization and pruning are fundamental approaches for model compression, enabling efficient inference for language models. In a post-training setting, state-of-the-art quantization and pruning methods require calibration data, a small set of unlabeled examples. Conventionally, this is randomly sampled web text, aiming to reflect the model training data. However, this poses two key problems: (1) unrepresentative calibration examples can harm model performance, and (2) organizations increasingly avoid releasing model training data. In this paper, we propose self-calibration as a solution. Our approach requires no external data, instead leveraging the model itself to generate synthetic calibration data, with a view to better approximating the pre-training data distribution. We extensively compare the performance of self-calibration with several baselines, across a variety of models, compression methods, and tasks. Our approach proves consistently competitive in maximizing downstream task performance, frequently outperforming even using real data.",
      "authors": [
        "Miles Williams",
        "George Chrysostomou",
        "Nikolaos Aletras"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T16:50:00+00:00",
          "link": "https://arxiv.org/abs/2410.17170v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T17:40:00+00:00",
          "link": "https://arxiv.org/abs/2410.17170v2",
          "size": "263kb",
          "version": "v2"
        }
      ],
      "title": "Self-calibration for Language Model Quantization and Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17170",
        "PDF": "https://arxiv.org/pdf/2410.17170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes self-calibration for model quantization and pruning by generating synthetic calibration data using the model itself. This approach directly contributes to LLM training data processing by creating a method to approximate pre-training data distribution without external data."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "model",
        "Model Compression",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08348",
      "abstract": "Censor-Hillel, Cohen, Gelles, and Sela (PODC 2022 & Distributed Computing 2023) studied fully-defective asynchronous networks, where communication channels may suffer an extreme form of alteration errors, rendering messages completely corrupted. The model is equivalent to content-oblivious computation, where nodes communicate solely via pulses. They showed that if the network is 2-edge-connected, then any algorithm for a noiseless setting can be simulated in the fully-defective setting; otherwise, no non-trivial computation is possible in the fully-defective setting. However, their simulation requires a predesignated leader, which they conjectured to be necessary for any non-trivial content-oblivious task.\n  Recently, Frei, Gelles, Ghazy, and Nolin (DISC 2024) refuted this conjecture for the special case of oriented ring topology. They designed two asynchronous content-oblivious leader election algorithms with message complexity $O(n \\cdot \\mathsf{ID}_{\\max})$, where $n$ is the number of nodes and $\\mathsf{ID}_{\\max}$ is the maximum $\\mathsf{ID}$. The first algorithm stabilizes in unoriented rings without termination detection. The second algorithm quiescently terminates in oriented rings, thus enabling the execution of the simulation algorithm after leader election.\n  In this work, we present an asynchronous content-oblivious leader election algorithm that quiescently terminates in any 2-edge connected network with message complexity $O(m \\cdot N \\cdot \\mathsf{ID}_{\\min})$, where $m$ is the number of edges, $N$ is a known upper bound on the number of nodes, and $\\mathsf{ID}_{\\min}$ is the smallest $\\mathsf{ID}$. Combined with the previous simulation result, our finding implies that any algorithm from the noiseless setting can be simulated in the fully-defective setting without assuming a preselected leader, entirely refuting the original conjecture.",
      "authors": [
        "Yi-Jun Chang",
        "Lyuting Chen",
        "Haoran Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:48:21+00:00",
          "link": "https://arxiv.org/abs/2507.08348v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T05:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.08348v2",
          "size": "58kb",
          "version": "v2"
        }
      ],
      "title": "Content-Oblivious Leader Election in 2-Edge-Connected Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08348",
        "HTML": "https://arxiv.org/html/2507.08348v2",
        "PDF": "https://arxiv.org/pdf/2507.08348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses leader election algorithms in 2-edge-connected networks without any connection to LLM training data processing or data engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08843",
      "abstract": "We propose FLLL3M--Federated Learning with Large Language Models for Mobility Modeling--a privacy-preserving framework for Next-Location Prediction (NxLP). By retaining user data locally and leveraging LLMs through an efficient outer product mechanism, FLLL3M ensures high accuracy with low resource demands. It achieves SOT results on Gowalla (Acc@1: 12.55, MRR: 0.1422), WeePlace (10.71, 0.1285), Brightkite (10.42, 0.1169), and FourSquare (8.71, 0.1023), while reducing parameters by up to 45.6% and memory usage by 52.7%.",
      "authors": [
        "Arpita Soni",
        "Sahil Tripathi",
        "Gautam Siddharth Kashyap",
        "Manaswi Kulahara",
        "Mohammad Anas Azeez",
        "Zohaib Hasan Siddiqui",
        "Nipun Joshi",
        "Jiechao Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:13:34+00:00",
          "link": "https://arxiv.org/abs/2507.08843v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Can We Predict Your Next Move Without Breaking Your Privacy?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08843",
        "HTML": "https://arxiv.org/html/2507.08843v1",
        "PDF": "https://arxiv.org/pdf/2507.08843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a federated learning framework for location prediction using LLMs but does not involve the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09409",
      "abstract": "Social learning is a powerful mechanism through which agents learn about the world from others. However, humans don't always choose to observe others, since social learning can carry time and cognitive resource costs. How do people balance social and non-social learning? In this paper, we propose a rational mentalizing model of the decision to engage in social learning. This model estimates the utility of social learning by reasoning about the other agent's goal and the informativity of their future actions. It then weighs the utility of social learning against the utility of self-exploration (non-social learning). Using a multi-player treasure hunt game, we show that our model can quantitatively capture human trade-offs between social and non-social learning. Furthermore, our results indicate that these two components allow agents to flexibly apply social learning to achieve their goals more efficiently.",
      "authors": [
        "Lance Ying",
        "Ryan Truong",
        "Joshua B. Tenenbaum",
        "Samuel J. Gershman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T21:55:06+00:00",
          "link": "https://arxiv.org/abs/2507.09409v1",
          "size": "1041kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Social Learning using Theory of Mind",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09409",
        "HTML": "https://arxiv.org/html/2507.09409v1",
        "PDF": "https://arxiv.org/pdf/2507.09409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a model for social learning rather than any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09868",
      "abstract": "In the Vertex Disjoint Paths with Congestion problem, the input consists of a digraph $D$, an integer $c$ and $k$ pairs of vertices $(s_i, t_i)$, and the task is to find a set of paths connecting each $s_i$ to its corresponding $t_i$, whereas each vertex of $D$ appears in at most $c$ many paths. The case where $c = 1$ is known to be NP-complete even if $k = 2$ [Fortune, Hopcroft and Wyllie, 1980] on general digraphs and is W[1]-hard with respect to $k$ (excluding the possibility of an $f(k)n^{O(1)}$-time algorithm under standard assumptions) on acyclic digraphs [Slivkins, 2010]. The proof of [Slivkins, 2010] can also be adapted to show W[1]-hardness with respect to $k$ for every congestion $c \\geq 1$.\n  We strengthen the existing hardness result by showing that the problem remains W[1]-hard for every congestion $c \\geq 1$ even if:\n  - the input digraph $D$ is acyclic,\n  - $D$ does not contain an acyclic $(5, 5)$-grid as a butterfly minor,\n  - $D$ does not contain an acyclic tournament on 9 vertices as a butterfly minor, and\n  - $D$ has ear-anonymity at most 5.\n  Further, we also show that the edge-congestion variant of the problem remains W[1]-hard for every congestion $c \\geq 1$ even if:\n  - the input digraph $D$ is acyclic,\n  - $D$ has maximum undirected degree 3,\n  - $D$ does not contain an acyclic $(7, 7)$-wall as a weak immersion and\n  - $D$ has ear-anonymity at most 5.",
      "authors": [
        "Ken-ichi Kawarabayashi",
        "Nicola Lorenz",
        "Marcelo Garlet Milani",
        "Jacob Stegemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:40:35+00:00",
          "link": "https://arxiv.org/abs/2507.09868v1",
          "size": "460kb",
          "version": "v1"
        }
      ],
      "title": "Directed disjoint paths remains W[1]-hard on acyclic digraphs without large grid minors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09868",
        "HTML": "https://arxiv.org/html/2507.09868v1",
        "PDF": "https://arxiv.org/pdf/2507.09868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on combinatorial problems and complexity analysis in graph theory, which has no connection to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09938",
      "abstract": "Multiple advantages had been identified with the integration of data acquisition into any existing system configuration and implementation. Using data acquisition as a support into a monitoring system has not only improved its overall performance and reliability but also lowered its operational and maintenance cost because of its real-time data collection from node sensors.\n  As renewable energy needs to be sustainable for it to fully support the energy demand of communities, its management and control still needs to be improved and enhanced. Smart systems are considered the next generation technological improvement of any system that exists. It is the prelude to autonomous systems from industrial applications to home automation. Data acquisition is only a part of these smart systems that help in the remote management and control of these devices. Remote monitoring functionality enhances the operation and reliability which help in making proactive decisions during critical situations and circumstances.\n  Even with data acquisition enhancements, there is still room for improving its implementation regarding data security and privacy and accuracy of information being exchanged between nodes. Current technological advancements have already shown promising results and have widen its utilization spectrum by covering almost any field of specialization. With increasing implementation and design complexity that comes with its enhancements, challenges and issues are also faced that needs to be addressed and considered to mitigate the effects of such.",
      "authors": [
        "Chito A. Petilla"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:25:55+00:00",
          "link": "https://arxiv.org/abs/2507.09938v1",
          "size": "635kb",
          "version": "v1"
        }
      ],
      "title": "A Case Study on Data Acquisition Systems: Relevance to Renewable Energy Technologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09938",
        "PDF": "https://arxiv.org/pdf/2507.09938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on data acquisition systems related to renewable energy technologies. It does not address LLM training data processing or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10076",
      "abstract": "In computational argumentation, gradual semantics are fine-grained alternatives to extension-based and labelling-based semantics . They ascribe a dialectical strength to (components of) arguments sanctioning their degree of acceptability. Several gradual semantics have been studied for abstract, bipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as, to a lesser extent, for some forms of structured argumentation. However, this has not been the case for assumption-based argumentation (ABA), despite it being a popular form of structured argumentation with several applications where gradual semantics could be useful. In this paper, we fill this gap and propose a family of novel gradual semantics for equipping assumptions, which are the core components in ABA frameworks, with dialectical strengths. To do so, we use bipolar set-based argumentation frameworks as an abstraction of (potentially non-flat) ABA frameworks and generalise state-of-the-art modular gradual semantics for QBAFs. We show that our gradual ABA semantics satisfy suitable adaptations of desirable properties of gradual QBAF semantics, such as balance and monotonicity. We also explore an argument-based approach that leverages established QBAF modular semantics directly, and use it as baseline. Finally, we conduct experiments with synthetic ABA frameworks to compare our gradual ABA semantics with its argument-based counterpart and assess convergence.",
      "authors": [
        "Anna Rapberger",
        "Fabrizio Russo",
        "Antonio Rago",
        "Francesca Toni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.10076v1",
          "size": "3038kb",
          "version": "v1"
        }
      ],
      "title": "On Gradual Semantics for Assumption-Based Argumentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10076",
        "HTML": "https://arxiv.org/html/2507.10076v1",
        "PDF": "https://arxiv.org/pdf/2507.10076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores gradual semantics for assumption-based argumentation, focusing on computational argumentation, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10134",
      "abstract": "Unmanned Aerial Vehicles (UAVs) are vital for public safety, particularly in wildfire monitoring, where early detection minimizes environmental impact. In UAV-Assisted Wildfire Monitoring (UAWM) systems, joint optimization of sensor transmission scheduling and velocity is critical for minimizing Age of Information (AoI) from stale sensor data. Deep Reinforcement Learning (DRL) has been used for such optimization; however, its limitations such as low sampling efficiency, simulation-to-reality gaps, and complex training render it unsuitable for time-critical applications like wildfire monitoring. This paper introduces a new online Flight Resource Allocation scheme based on LLM-Enabled In-Context Learning (FRSICL) to jointly optimize the UAV's flight control and data collection schedule along the trajectory in real time, thereby asymptotically minimizing the average AoI across ground sensors. In contrast to DRL, FRSICL generates data collection schedules and controls velocity using natural language task descriptions and feedback from the environment, enabling dynamic decision-making without extensive retraining. Simulation results confirm the effectiveness of the proposed FRSICL compared to Proximal Policy Optimization (PPO) and Nearest-Neighbor baselines.",
      "authors": [
        "Yousef Emami",
        "Hao Zhou",
        "Miguel Gutierrez Gaitan",
        "Kai Li",
        "Luis Almeida"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:24:43+00:00",
          "link": "https://arxiv.org/abs/2507.10134v1",
          "size": "1317kb",
          "version": "v1"
        }
      ],
      "title": "FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10134",
        "HTML": "https://arxiv.org/html/2507.10134v1",
        "PDF": "https://arxiv.org/pdf/2507.10134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces LLM-enabled learning for optimizing UAV flight resource allocation, which includes real-time data collection. However, it does not focus primarily on processing LLM training datasets but rather utilizing LLMs for operational efficiency."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07837",
      "abstract": "With the increase in the number of parameters in large language models, the process of pre-training and fine-tuning increasingly demands larger volumes of GPU memory. A significant portion of this memory is typically consumed by the optimizer state. To overcome this challenge, recent approaches such as low-rank adaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao et al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been proposed. However, in all these algorithms, the $\\textit{effective rank of the weight updates remains low-rank}$, which can lead to a substantial loss of information from the gradient. This loss can be critically important, especially during the pre-training stage. In this paper, we introduce $\\texttt{FRUGAL}$ ($\\textbf{F}$ull-$\\textbf{R}$ank $\\textbf{U}$pdates with $\\textbf{G}$r$\\textbf{A}$dient sp$\\textbf{L}$itting), a new memory-efficient optimization framework. $\\texttt{FRUGAL}$ leverages gradient splitting to perform low-dimensional updates using advanced algorithms (such as Adam), while updates along the remaining directions are executed via state-free methods like SGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with various low-rank update selection techniques, including GaLore and BAdam. We provide theoretical convergence guarantees for our framework when using SGDM for low-dimensional updates and SGD for state-free updates. Additionally, our method consistently outperforms concurrent approaches across various fixed memory budgets, achieving state-of-the-art results in pre-training and fine-tuning tasks while balancing memory efficiency and performance metrics.",
      "authors": [
        "Philip Zmushko",
        "Aleksandr Beznosikov",
        "Martin Tak\\'a\\v{c}",
        "Samuel Horv\\'ath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T14:41:07+00:00",
          "link": "https://arxiv.org/abs/2411.07837v1",
          "size": "276kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:19:32+00:00",
          "link": "https://arxiv.org/abs/2411.07837v2",
          "size": "285kb",
          "version": "v2"
        }
      ],
      "title": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07837",
        "HTML": "https://arxiv.org/html/2411.07837v2",
        "PDF": "https://arxiv.org/pdf/2411.07837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses memory-efficient optimizations during model training, not focusing on any aspect of data processing or engineering for LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/fzmushko/frugal"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.13820",
      "abstract": "The revolutionary capabilities of Large Language Models (LLMs) are attracting rapidly growing popularity and leading to soaring user requests to inference serving systems. Caching techniques, which leverage data reuse to reduce computation, offer opportunities to optimize the performance of LLM inference engines. On the one hand, the low-level key-value (KV) cache working at the token level is widely adopted, albeit it incurs significant overhead as request volume grows. On the other hand, instruction-level caching, which stores full instruction-response pairs, is expected to play an increasingly crucial role. However, the high variability in the content and length of instructions make it rare for identical instructions to recur within a short time window, presenting challenges for effective caching instruction-response pairs. To address this challenge, we propose InstCache, a predictive caching mechanism for LLM serving systems. Leveraging the capability of LLMs, we can effectively reorder the representation space of instruction texts and develop a sufficient level of spatial locality. Such spatial locality enables us to predict potential instructions located in a compact region in the space, resulting in an effective caching system at runtime. Experimental results demonstrate that InstCache achieves a 2.3x higher hit rate compared to the upper bound of traditional caching mechanisms on WildChat dataset and reduces the time per output token of vLLM by up to 42.0% and 50.0% on LMSys and Moss datasets, respectively.",
      "authors": [
        "Longwei Zou",
        "Yan Liu",
        "Jiamu Kang",
        "Tingfeng Liu",
        "Jiangang Kong",
        "Yangdong Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T03:52:41+00:00",
          "link": "https://arxiv.org/abs/2411.13820v1",
          "size": "530kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:22:43+00:00",
          "link": "https://arxiv.org/abs/2411.13820v2",
          "size": "397kb",
          "version": "v2"
        }
      ],
      "title": "InstCache: A Predictive Cache for LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13820",
        "HTML": "https://arxiv.org/html/2411.13820v2",
        "PDF": "https://arxiv.org/pdf/2411.13820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving caching mechanisms for LLM serving systems, which is not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.17846",
      "abstract": "Building robotic prostheses requires a sensor-based interface designed to provide the robotic hand with the control required to perform hand gestures. Traditional Electromyography (EMG) based prosthetics and emerging alternatives often face limitations such as muscle-activation limitations, high cost, and complex calibrations. In this paper, we present a low-cost robotic system composed of a smart ankleband for intuitive, calibration-free control of a robotic hand, and a robotic prosthetic hand that executes actions corresponding to leg gestures. The ankleband integrates an Inertial Measurement Unit (IMU) sensor with a lightweight neural network to infer user-intended leg gestures from motion data. Our system represents a significant step towards higher adoption rates of robotic prostheses among arm amputees, as it enables one to operate a prosthetic hand using a low-cost, low-power, and calibration-free solution. To evaluate our work, we collected data from 10 subjects and tested our prototype ankleband with a robotic hand on an individual with an upper-limb amputation. Our results demonstrate that this system empowers users to perform daily tasks more efficiently, requiring few compensatory movements.",
      "authors": [
        "Dean Zadok",
        "Oren Salzman",
        "Alon Wolf and Alex M. Bronstein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-22T19:45:12+00:00",
          "link": "https://arxiv.org/abs/2503.17846v1",
          "size": "46641kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T11:52:53+00:00",
          "link": "https://arxiv.org/abs/2503.17846v2",
          "size": "9415kb",
          "version": "v2"
        }
      ],
      "title": "Smart Ankleband for Plug-and-Play Hand-Prosthetic Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17846",
        "HTML": "https://arxiv.org/html/2503.17846v2",
        "PDF": "https://arxiv.org/pdf/2503.17846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the development of a smart ankleband for prosthetic control, emphasizing hardware development and gesture recognition, with no focus on LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/deanzadok/ankleband"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17300",
      "abstract": "Individual causal inference (ICI) uses causal inference methods to understand and predict the effects of interventions on individuals, considering their specific characteristics / facts. It aims to estimate individual causal effect (ICE), which varies across individuals. Estimating ICE can be challenging due to the limited data available for individuals, and the fact that most causal inference methods are population-based. Structural Causal Model (SCM) is fundamentally population-based. Therefore, causal discovery (structural learning and parameter learning), association queries and intervention queries are all naturally population-based. However, exogenous variables (U) in SCM can encode individual variations and thus provide the mechanism for individualized population per specific individual characteristics / facts. Based on this, we propose ICI with SCM as a \"rung 3\" causal inference, because it involves \"imagining\" what would be the causal effect of a hypothetical intervention on an individual, given the individual's observed characteristics / facts. Specifically, we propose the indiv-operator, indiv(W), to formalize/represent the population individualization process, and the individual causal query, P(Y | indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI with SCM is inference on individual alternatives (possible), not individual counterfactuals (non-actual).",
      "authors": [
        "Daniel T. Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T21:24:21+00:00",
          "link": "https://arxiv.org/abs/2506.17300v1",
          "size": "893kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:35:13+00:00",
          "link": "https://arxiv.org/abs/2506.17300v2",
          "size": "900kb",
          "version": "v2"
        }
      ],
      "title": "Individual Causal Inference with Structural Causal Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17300",
        "PDF": "https://arxiv.org/pdf/2506.17300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on individual causal inference and does not involve any processing or creation of LLM training data or data engineering techniques related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09155",
      "abstract": "This work presents OPENXRD, an open-book pipeline designed for crystallography question answering, which integrates textual prompts with concise supporting content generated by GPT-4.5. Instead of using scanned textbooks, which may lead to copyright issues, OPENXRD generates compact, domain-specific references that help smaller models understand key concepts in X-ray diffraction (XRD). We evaluate OPENXRD on a well-defined set of 217 expert-level XRD questions by comparing different vision-language models, including GPT-4 and LLaVA-based frameworks such as Mistral, LLaMA, and QWEN, under both closed-book (without supporting material) and open-book (with supporting material) conditions. Our experimental results show significant accuracy improvements in models that use the GPT-4.5-generated summaries, particularly those with limited prior training in crystallography. OPENXRD uses knowledge from larger models to fill knowledge gaps in crystallography and shows that AI-generated texts can help smaller models reason more effectively in scientific tasks. While the current version of OPENXRD focuses on text-based inputs, we also explore future extensions such as adding real crystal diagrams or diffraction patterns to improve interpretation in specialized materials science contexts. Overall, OPENXRD shows that specialized open-book systems can be useful in materials science and provides a foundation for broader natural language processing (NLP) tools in critical scientific fields.",
      "authors": [
        "Ali Vosoughi",
        "Ayoub Shahnazari",
        "Yufeng Xi",
        "Zeliang Zhang",
        "Griffin Hess",
        "Chenliang Xu and Niaz Abdolrahim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T06:25:22+00:00",
          "link": "https://arxiv.org/abs/2507.09155v1",
          "size": "730kb",
          "version": "v1"
        }
      ],
      "title": "OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09155",
        "HTML": "https://arxiv.org/html/2507.09155v1",
        "PDF": "https://arxiv.org/pdf/2507.09155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper describes a question-answering system using AI-generated summaries, it focuses on evaluation and application rather than LLM data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09233",
      "abstract": "AI-driven recruitment systems, while promising efficiency and objectivity, often perpetuate systemic inequalities by encoding cultural and social capital disparities into algorithmic decision making. This article develops and defends a novel theory of secondary bounded rationality, arguing that AI systems, despite their computational power, inherit and amplify human cognitive and structural biases through technical and sociopolitical constraints. Analyzing multimodal recruitment frameworks, we demonstrate how algorithmic processes transform historical inequalities, such as elite credential privileging and network homophily, into ostensibly meritocratic outcomes. Using Bourdieusian capital theory and Simon's bounded rationality, we reveal a recursive cycle where AI entrenches exclusion by optimizing for legible yet biased proxies of competence. We propose mitigation strategies, including counterfactual fairness testing, capital-aware auditing, and regulatory interventions, to disrupt this self-reinforcing inequality.",
      "authors": [
        "Jia Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:03:20+00:00",
          "link": "https://arxiv.org/abs/2507.09233v1",
          "size": "691kb",
          "version": "v1"
        }
      ],
      "title": "Secondary Bounded Rationality: A Theory of How Algorithms Reproduce Structural Inequality in AI Hiring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09233",
        "PDF": "https://arxiv.org/pdf/2507.09233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on AI-driven recruitment systems and structural inequality, with no mention of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09495",
      "abstract": "Multi-agent reinforcement learning faces fundamental challenges that conventional approaches have failed to overcome: exponentially growing joint action spaces, non-stationary environments where simultaneous learning creates moving targets, and partial observability that constrains coordination. Current methods remain reactive, employing stimulus-response mechanisms that fail when facing novel scenarios. We argue for a transformative paradigm shift from reactive to proactive multi-agent intelligence through generative AI-based reinforcement learning. This position advocates reconceptualizing agents not as isolated policy optimizers, but as sophisticated generative models capable of synthesizing complex multi-agent dynamics and making anticipatory decisions based on predictive understanding of future interactions. Rather than responding to immediate observations, generative-RL agents can model environment evolution, predict other agents' behaviors, generate coordinated action sequences, and engage in strategic reasoning accounting for long-term dynamics. This approach leverages pattern recognition and generation capabilities of generative AI to enable proactive decision-making, seamless coordination through enhanced communication, and dynamic adaptation to evolving scenarios. We envision this paradigm shift will unlock unprecedented possibilities for distributed intelligence, moving beyond individual optimization toward emergent collective behaviors representing genuine collaborative intelligence. The implications extend across autonomous systems, robotics, and human-AI collaboration, promising solutions to coordination challenges intractable under traditional reactive frameworks.",
      "authors": [
        "Hang Wang",
        "Junshan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:02:43+00:00",
          "link": "https://arxiv.org/abs/2507.09495v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09495",
        "HTML": "https://arxiv.org/html/2507.09495v1",
        "PDF": "https://arxiv.org/pdf/2507.09495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a paradigm shift in multi-agent reinforcement learning towards generative AI-based methods, without any focus on LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08750",
      "abstract": "Articulated objects are ubiquitous in daily life. In this paper, we present DexSim2Real$^{2}$, a novel framework for goal-conditioned articulated object manipulation. The core of our framework is constructing an explicit world model of unseen articulated objects through active interactions, which enables sampling-based model predictive control to plan trajectories achieving different goals without requiring demonstrations or RL. It first predicts an interaction using an affordance network trained on self-supervised interaction data or videos of human manipulation. After executing the interactions on the real robot to move the object parts, we propose a novel modeling pipeline based on 3D AIGC to build a digital twin of the object in simulation from multiple frames of observations. For dexterous hands, we utilize eigengrasp to reduce the action dimension, enabling more efficient trajectory searching. Experiments validate the framework's effectiveness for precise manipulation using a suction gripper, a two-finger gripper and two dexterous hand. The generalizability of the explicit world model also enables advanced manipulation strategies like manipulating with tools.",
      "authors": [
        "Taoran Jiang",
        "Yixuan Guan",
        "Liqian Ma",
        "Jing Xu",
        "Jiaojiao Meng",
        "Weihang Chen",
        "Zecui Zeng",
        "Lusong Li",
        "Dan Wu",
        "Rui Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T12:00:57+00:00",
          "link": "https://arxiv.org/abs/2409.08750v1",
          "size": "11048kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T07:00:22+00:00",
          "link": "https://arxiv.org/abs/2409.08750v2",
          "size": "14125kb",
          "version": "v2"
        }
      ],
      "title": "DexSim2Real$^{2}$: Building Explicit World Model for Precise Articulated Object Dexterous Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08750",
        "HTML": "https://arxiv.org/html/2409.08750v2",
        "PDF": "https://arxiv.org/pdf/2409.08750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on articulated object manipulation using a world model and predictive control, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.11497",
      "abstract": "Physics Informed Machine Learning has emerged as a popular approach for modeling and simulation in digital twins, enabling the generation of accurate models of processes and behaviors in real-world systems. However, existing methods either rely on simple loss regularizations that offer limited physics integration or employ highly specialized architectures that are difficult to generalize across diverse physical systems. This paper presents a generic approach based on a novel physics-encoded residual neural network (PERNN) architecture that seamlessly combines data-driven and physics-based analytical models to overcome these limitations. Our method integrates differentiable physics blocks-implementing mathematical operators from physics-based models with feed-forward learning blocks, while intermediate residual blocks ensure stable gradient flow during training. Consequently, the model naturally adheres to the underlying physical principles even when prior physics knowledge is incomplete, thereby improving generalizability with low data requirements and reduced model complexity. We investigate our approach in two application domains. The first is a steering model for autonomous vehicles in a simulation environment, and the second is a digital twin for climate modeling using an ordinary differential equation (ODE)-based model of Net Ecosystem Exchange (NEE) to enable gap-filling in flux tower data. In both cases, our method outperforms conventional neural network approaches as well as state-of-the-art Physics Informed Machine Learning methods.",
      "authors": [
        "Muhammad Saad Zia",
        "Ashiq Anjum",
        "Lu Liu",
        "Anthony Conway",
        "Anasol Pena Rios"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T11:58:20+00:00",
          "link": "https://arxiv.org/abs/2411.11497v1",
          "size": "12915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T16:30:17+00:00",
          "link": "https://arxiv.org/abs/2411.11497v2",
          "size": "22767kb",
          "version": "v2"
        }
      ],
      "title": "Physics Encoded Blocks in Residual Neural Network Architectures for Digital Twin Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11497",
        "HTML": "https://arxiv.org/html/2411.11497",
        "PDF": "https://arxiv.org/pdf/2411.11497"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel neural network architecture for integrating physics-based models, which is not related to LLM training data processing."
      },
      "tasks": [
        "Physics-informed machine learning"
      ],
      "repo_urls": [
        "https://github.com/saadzia10/Physics-Encoded-ResNet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02882",
      "abstract": "Tool-Augmented Larage Language Models (TA-LLMs) have shown promise in real-world applications, but face challenges in handling incomplete queries and out-of-scope requests. While existing approaches rely mainly on Supervised Fine-Tuning with expert trajectories, we propose DiaTool-DPO, a novel method that enhances TA-LLM's dialogue capabilities through Direct Preference Optimization. We model TA-LLM interactions as a Markov Decision Process with 5 distinct dialogue states and categorize user queries into 3 types based on their state transition trajectories. We automatically construct paired trajectory datasets of correct and incorrect dialogue flows and introduce a specialized objective loss for dialogue control. Our comprehensive evaluation demonstrates that DiaTool-DPO approaches GPT-4o's performance (94.8% in information gathering, 91% in tool call rejection) with substantial improvements over baseline (44% and 9.6% respectively) while maintaining core functionality. Our approach opens new possibilities for developing TA-LLMs that can handle diverse real-world scenarios without requiring additional expert demonstrations or human labeling.",
      "authors": [
        "Sunghee Jung",
        "Donghun Lee",
        "Shinbok Lee",
        "Gaeun Seo",
        "Daniel Lee",
        "Byeongil Ko",
        "Junrae Cho",
        "Kihyun Kim",
        "Eunggyun Kim",
        "and Myeongcheol Shin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T05:47:28+00:00",
          "link": "https://arxiv.org/abs/2504.02882v1",
          "size": "5825kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:56:47+00:00",
          "link": "https://arxiv.org/abs/2504.02882v2",
          "size": "1079kb",
          "version": "v2"
        }
      ],
      "title": "DiaTool-DPO: Multi-Turn Direct Preference Optimization for Tool-Augmented Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02882",
        "HTML": "https://arxiv.org/html/2504.02882v2",
        "PDF": "https://arxiv.org/pdf/2504.02882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on enhancing dialogue capabilities through Direct Preference Optimization and does not primarily focus on LLM training data processing, although it involves data for modeling interactions."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06011",
      "abstract": "Edge computing enables data processing closer to the source, significantly reducing latency an essential requirement for real-time vision-based analytics such as object detection in surveillance and smart city environments. However, these tasks place substantial demands on resource constrained edge devices, making the joint optimization of energy consumption and detection accuracy critical. To address this challenge, we propose ECORE, a framework that integrates multiple dynamic routing strategies including estimation based techniques and a greedy selection algorithm to direct image processing requests to the most suitable edge device-model pair. ECORE dynamically balances energy efficiency and detection performance based on object characteristics. We evaluate our approach through extensive experiments on real-world datasets, comparing the proposed routers against widely used baseline techniques. The evaluation leverages established object detection models (YOLO, SSD, EfficientDet) and diverse edge platforms, including Jetson Orin Nano, Raspberry Pi 4 and 5, and TPU accelerators. Results demonstrate that our proposed context-aware routing strategies can reduce energy consumption and latency by 45% and 49%, respectively, while incurring only a 2% loss in detection accuracy compared to accuracy-centric methods.",
      "authors": [
        "Daghash K. Alqahtani",
        "Maria A. Rodriguez",
        "Muhammad Aamir Cheema",
        "Hamid Rezatofighi and Adel N. Toosi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T14:16:14+00:00",
          "link": "https://arxiv.org/abs/2507.06011v1",
          "size": "2794kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:46:02+00:00",
          "link": "https://arxiv.org/abs/2507.06011v2",
          "size": "3301kb",
          "version": "v2"
        }
      ],
      "title": "ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06011",
        "HTML": "https://arxiv.org/html/2507.06011v2",
        "PDF": "https://arxiv.org/pdf/2507.06011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing energy consumption and detection accuracy in edge computing, using existing object detection models, but does not address any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08829",
      "abstract": "Deep Neural Networks (DNNs) are widely employed in safety-critical domains, where ensuring their reliability is essential. Triple Modular Redundancy (TMR) is an effective technique to enhance the reliability of DNNs in the presence of bit-flip faults. In order to handle the significant overhead of TMR, it is applied selectively on the parameters and components with the highest contribution at the model output. Hence, the accuracy of the selection criterion plays the key role on the efficiency of TMR. This paper presents an efficient TMR approach to enhance the reliability of DNNs against bit-flip faults using an Explainable Artificial Intelligence (XAI) method. Since XAI can provide valuable insights about the importance of individual neurons and weights in the performance of the network, they can be applied as the selection metric in TMR techniques. The proposed method utilizes a low-cost, gradient-based XAI technique known as Layer-wise Relevance Propagation (LRP) to calculate importance scores for DNN parameters. These scores are then used to enhance the reliability of the model, with the most critical weights being protected by TMR. The proposed approach is evaluated on two DNN models, VGG16 and AlexNet, using datasets such as MNIST and CIFAR-10. The results demonstrate that the method can protect the AlexNet model at a bit error rate of 10-4, achieving over 60% reliability improvement while maintaining the same overhead as state-of-the-art methods.",
      "authors": [
        "Kimia Soroush",
        "Nastaran Shirazi",
        "Mohsen Raji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T21:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.08829v1",
          "size": "1127kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Triple Modular Redundancy for Reliability Enhancement of DNNs Using Explainable AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08829",
        "PDF": "https://arxiv.org/pdf/2507.08829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing the reliability of DNNs using Explainable AI but does not discuss LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08853",
      "abstract": "As archives turn to artificial intelligence to manage growing volumes of digital records, privacy risks inherent in current AI data practices raise critical concerns about data sovereignty and ethical accountability. This paper explores how privacy-enhancing technologies (PETs) and Web3 architectures can support archives to preserve control over sensitive content while still being able to make it available for access by researchers. We present Clio-X, a decentralized, privacy-first Web3 digital solution designed to embed PETs into archival workflows and support AI-enabled reference and access. Drawing on a user evaluation of a medium-fidelity prototype, the study reveals both interest in the potential of the solution and significant barriers to adoption related to trust, system opacity, economic concerns, and governance. Using Rogers' Diffusion of Innovation theory, we analyze the sociotechnical dimensions of these barriers and propose a path forward centered on participatory design and decentralized governance through a Clio-X Decentralized Autonomous Organization. By integrating technical safeguards with community-based oversight, Clio-X offers a novel model to ethically deploy AI in cultural heritage contexts.",
      "authors": [
        "Victoria L. Lemieux",
        "Rosa Gil",
        "Faith Molosiwa",
        "Qihong Zhou",
        "Binming Li",
        "Roberto Garcia",
        "Luis De La Torre Cubillo",
        "and Zehua Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:30:38+00:00",
          "link": "https://arxiv.org/abs/2507.08853v1",
          "size": "2077kb",
          "version": "v1"
        }
      ],
      "title": "Clio-X: AWeb3 Solution for Privacy-Preserving AI Access to Digital Archives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08853",
        "PDF": "https://arxiv.org/pdf/2507.08853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a Web3 solution for privacy-preserving AI access to digital archives, emphasizing privacy-enhancing technologies rather than any direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08905",
      "abstract": "We explore the use of Hamiltonian Monte Carlo (HMC) sampling as a probabilistic last layer approach for deep neural networks (DNNs). While HMC is widely regarded as a gold standard for uncertainty estimation, the computational demands limit its application to large-scale datasets and large DNN architectures. Although the predictions from the sampled DNN parameters can be parallelized, the computational cost still scales linearly with the number of samples (similar to an ensemble). Last layer HMC (LL--HMC) reduces the required computations by restricting the HMC sampling to the final layer of a DNN, making it applicable to more data-intensive scenarios with limited computational resources. In this paper, we compare LL-HMC against five last layer probabilistic deep learning (LL-PDL) methods across three real-world video datasets for driver action and intention. We evaluate the in-distribution classification performance, calibration, and out-of-distribution (OOD) detection. Due to the stochastic nature of the probabilistic evaluations, we performed five grid searches for different random seeds to avoid being reliant on a single initialization for the hyperparameter configurations. The results show that LL--HMC achieves competitive in-distribution classification and OOD detection performance. Additional sampled last layer parameters do not improve the classification performance, but can improve the OOD detection. Multiple chains or starting positions did not yield consistent improvements.",
      "authors": [
        "Koen Vellenga",
        "H. Joe Steinhauer",
        "G\\\"oran Falkman",
        "Jonas Andersson",
        "Anders Sj\\\"ogren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.08905v1",
          "size": "1777kb",
          "version": "v1"
        }
      ],
      "title": "Last Layer Hamiltonian Monte Carlo",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08905",
        "PDF": "https://arxiv.org/pdf/2507.08905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Hamiltonian Monte Carlo (HMC) sampling for deep neural networks, specifically targeting uncertainty estimation and computational efficiency. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09239",
      "abstract": "The societal role of technology, including artificial intelligence (AI), is often shaped by sociocultural narratives. This study examines how U.S. news media construct narratives about the efficacy of generative AI (GenAI), using ChatGPT in higher education as a case study. Grounded in Agenda Setting Theory, we analyzed 198 articles published between November 2022 and October 2024, employing LDA topic modeling and sentiment analysis. Our findings identify six key topics in the media discourse, with sentiment analysis revealing generally positive portrayals of ChatGPT's integration into higher education through policy, curriculum, teaching practices, collaborative decision-making, skill development, and human-centered learning. In contrast, media narratives express more negative sentiment regarding their impact on entry-level jobs and college admissions. This research highlights how media coverage can influence public perceptions of GenAI in education and provides actionable insights for policymakers, educators, and AI developers navigating its adoption and representation in public discourse.",
      "authors": [
        "Yinan Sun",
        "Ali Unlu",
        "Aditya Johri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:19:50+00:00",
          "link": "https://arxiv.org/abs/2507.09239v1",
          "size": "516kb",
          "version": "v1"
        }
      ],
      "title": "The Narrative Construction of Generative AI Efficacy by the Media: A Case Study of the Role of ChatGPT in Higher Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09239",
        "PDF": "https://arxiv.org/pdf/2507.09239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes media narratives about generative AI in education, rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09462",
      "abstract": "Accurate modeling and simulation of mobile networks are essential for enabling intelligent and cost-effective network optimization. In this paper, we propose MobiWorld, a generative world model designed to support high-fidelity and flexible environment simulation for mobile network planning and optimization. Unlike traditional predictive models constrained by limited generalization capabilities, MobiWorld exhibits strong universality by integrating heterogeneous data sources, including sensors, mobile devices, and base stations, as well as multimodal data types such as sequences and images. It is capable of generating both network element-level observations (e.g., traffic load, user distribution) and system-level performance indicators (e.g., throughput, energy consumption) to support a wide range of planning and optimization tasks. Built upon advanced diffusion models, MobiWorld offers powerful controllable generation capabilities by modeling the joint distribution between mobile network data and diverse conditional factors including spatio temporal contexts, user behaviors, and optimization policies. This enables accurate simulation of dynamic network states under varying policy configurations, providing optimization agents with precise environmental feedback and facilitating effective decision-making without relying on costly real-network interactions. We demonstrate the effectiveness of MobiWorld in a collaborative energy-saving scenario, where an agent uses observations and rewards generated by MobiWorld to optimize base station sleep and user offloading policies. Experimental results show that MobiWorld exhibits strong controllable generation performance and outperforms traditional methods in energy optimization.",
      "authors": [
        "Haoye Chai",
        "Yuan Yuan",
        "Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:59:13+00:00",
          "link": "https://arxiv.org/abs/2507.09462v1",
          "size": "2113kb",
          "version": "v1"
        }
      ],
      "title": "MobiWorld: World Models for Mobile Wireless Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09462",
        "HTML": "https://arxiv.org/html/2507.09462v1",
        "PDF": "https://arxiv.org/pdf/2507.09462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses MobiWorld, a generative world model for mobile network simulation but does not focus on LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09613",
      "abstract": "Today, Wi-Fi is over 25 years old. Yet, despite sharing the same branding name, today's Wi-Fi boasts entirely new capabilities that were not even on the roadmap 25 years ago. This article aims to provide a holistic and comprehensive technical and historical tutorial on Wi-Fi, beginning with IEEE 802.11b (Wi-Fi 1) and looking forward to IEEE 802.11bn (Wi-Fi 8). This is the first tutorial article to span these eight generations. Rather than a generation-by-generation exposition, we describe the key mechanisms that have advanced Wi-Fi. We begin by discussing spectrum allocation and coexistence, and detailing the IEEE 802.11 standardization cycle. Second, we provide an overview of the physical layer and describe key elements that have enabled data rates to increase by over 1,000x. Third, we describe how Wi-Fi Medium Access Control has been enhanced from the original Distributed Coordination Function to now include capabilities spanning from frame aggregation to wideband spectrum access. Fourth, we describe how Wi-Fi 5 first broke the one-user-at-a-time paradigm and introduced multi-user access. Fifth, given the increasing use of mobile, battery-powered devices, we describe Wi-Fi's energy-saving mechanisms over the generations. Sixth, we discuss how Wi-Fi was enhanced to seamlessly aggregate spectrum across 2.4 GHz, 5 GHz, and 6 GHz bands to improve throughput, reliability, and latency. Finally, we describe how Wi-Fi enables nearby Access Points to coordinate in order to improve performance and efficiency. In the Appendix, we further discuss Wi-Fi developments beyond 802.11bn, including integrated mmWave operations, sensing, security and privacy extensions, and the adoption of AI/ML.",
      "authors": [
        "Giovanni Geraci",
        "Francesca Meneghello",
        "Francesc Wilhelmi",
        "David Lopez-Perez",
        "I\\~naki Val",
        "Lorenzo Galati Giordano",
        "Carlos Cordeiro",
        "Monisha Ghosh",
        "Edward Knightly",
        "Boris Bellalta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:35:08+00:00",
          "link": "https://arxiv.org/abs/2507.09613v1",
          "size": "10999kb",
          "version": "v1"
        }
      ],
      "title": "Wi-Fi: Twenty-Five Years and Counting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09613",
        "PDF": "https://arxiv.org/pdf/2507.09613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a tutorial on the evolution of Wi-Fi and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09931",
      "abstract": "The integration of Large Language Models (LLMs) into safety-critical domains, such as nuclear engineering, necessitates a deep understanding of their internal reasoning processes. This paper presents a novel methodology for interpreting how an LLM encodes and utilizes domain-specific knowledge, using a Boiling Water Reactor system as a case study. We adapted a general-purpose LLM (Gemma-3-1b-it) to the nuclear domain using a parameter-efficient fine-tuning technique known as Low-Rank Adaptation. By comparing the neuron activation patterns of the base model to those of the fine-tuned model, we identified a sparse set of neurons whose behavior was significantly altered during the adaptation process. To probe the causal role of these specialized neurons, we employed a neuron silencing technique. Our results demonstrate that while silencing most of these specialized neurons individually did not produce a statistically significant effect, deactivating the entire group collectively led to a statistically significant degradation in task performance. Qualitative analysis further revealed that silencing these neurons impaired the model's ability to generate detailed, contextually accurate technical information. This paper provides a concrete methodology for enhancing the transparency of an opaque black-box model, allowing domain expertise to be traced to verifiable neural circuits. This offers a pathway towards achieving nuclear-grade artificial intelligence (AI) assurance, addressing the verification and validation challenges mandated by nuclear regulatory frameworks (e.g., 10 CFR 50 Appendix B), which have limited AI deployment in safety-critical nuclear operations.",
      "authors": [
        "Yoon Pyo Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:17:41+00:00",
          "link": "https://arxiv.org/abs/2507.09931v1",
          "size": "907kb",
          "version": "v1"
        }
      ],
      "title": "Mechanistic Interpretability of LoRA-Adapted Language Models for Nuclear Reactor Safety Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09931",
        "HTML": "https://arxiv.org/html/2507.09931v1",
        "PDF": "https://arxiv.org/pdf/2507.09931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While it discusses fine-tuning a language model, the main contribution is in understanding neuron activations, not in processing the training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10048",
      "abstract": "As machine learning gets adopted into the industry quickly, trustworthiness is increasingly in focus. Yet, efficiency and sustainability of robust training pipelines still have to be established. In this work, we consider a simple pipeline for training adversarially robust decision trees and investigate the efficiency of each step. Our pipeline consists of three stages. Firstly, we choose the perturbation size automatically for each dataset. For that, we introduce a simple algorithm, instead of relying on intuition or prior work. Moreover, we show that the perturbation size can be estimated from smaller models than the one intended for full training, and thus significant gains in efficiency can be achieved. Secondly, we train state-of-the-art adversarial training methods and evaluate them regarding both their training time and adversarial accuracy. Thirdly, we certify the robustness of each of the models thus obtained and investigate the time required for this. We find that verification time, which is critical to the efficiency of the full pipeline, is not correlated with training time.",
      "authors": [
        "Benedict Gerlach and Marie Anastacio and Holger H. Hoos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:27:42+00:00",
          "link": "https://arxiv.org/abs/2507.10048v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "On the Efficiency of Training Robust Decision Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10048",
        "HTML": "https://arxiv.org/html/2507.10048v1",
        "PDF": "https://arxiv.org/pdf/2507.10048"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on training robust decision trees and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10443",
      "abstract": "We present the Context-Content Uncertainty Principle (CCUP), a unified framework that models cognition as the directed flow of information between high-entropy context and low-entropy content. Inference emerges as a cycle of bidirectional interactions, bottom-up contextual disambiguation paired with top-down content reconstruction, which resolves the Information Bottleneck in Optimal Transport (iBOT). Implemented via Rao-Blackwellized variational entropy minimization, CCUP steers representations toward minimal joint uncertainty while preserving inferential directionality. Local cycle completion underpins temporal bootstrapping, chaining simulations to refine memory, and spatial bootstrapping, enabling compositional hierarchical inference. We prove a Delta Convergence Theorem showing that recursive entropy minimization yields delta-like attractors in latent space, stabilizing perceptual schemas and motor plans. Temporal bootstrapping through perception-action loops and sleep-wake consolidation further transforms episodic traces into semantic knowledge. Extending CCUP, each hierarchical level performs delta-seeded inference: low-entropy content seeds diffuse outward along goal-constrained paths shaped by top-down priors and external context, confining inference to task-relevant manifolds and circumventing the curse of dimensionality. Building on this, we propose that language emerges as a symbolic transport system, externalizing latent content to synchronize inference cycles across individuals. Together, these results establish iBOT as a foundational principle of information flow in both individual cognition and collective intelligence, positioning recursive inference as the structured conduit through which minds adapt, align, and extend.",
      "authors": [
        "Xin Li"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:56:50+00:00",
          "link": "https://arxiv.org/abs/2507.10443v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "Information Must Flow: Recursive Bootstrapping for Information Bottleneck in Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10443",
        "HTML": "https://arxiv.org/html/2507.10443v1",
        "PDF": "https://arxiv.org/pdf/2507.10443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses cognitive modeling and information flow in the context of optimal transport, not LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07614",
      "abstract": "We study the problem of sampling from strongly log-concave distributions over $\\mathbb{R}^d$ using the Poisson midpoint discretization (a variant of the randomized midpoint method) for overdamped/underdamped Langevin dynamics. We prove its convergence in the 2-Wasserstein distance ($W_2$), achieving a cubic speedup in dependence on the target accuracy ($\\epsilon$) over the Euler-Maruyama discretization, surpassing existing bounds for randomized midpoint methods. Notably, in the case of underdamped Langevin dynamics, we demonstrate the complexity of $W_2$ convergence is much smaller than the complexity lower bounds for convergence in $L^2$ strong error established in the literature.",
      "authors": [
        "Rishikesh Srinivasan",
        "Dheeraj Nagaraj"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T10:27:15+00:00",
          "link": "https://arxiv.org/abs/2506.07614v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:39:03+00:00",
          "link": "https://arxiv.org/abs/2506.07614v2",
          "size": "33kb",
          "version": "v2"
        }
      ],
      "title": "Poisson Midpoint Method for Log Concave Sampling: Beyond the Strong Error Lower Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07614",
        "HTML": "https://arxiv.org/html/2506.07614v2",
        "PDF": "https://arxiv.org/pdf/2506.07614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is centered around log-concave sampling methods and performance improvements, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08827",
      "abstract": "Many complex networks display remarkable resilience under external perturbations, internal failures and environmental changes, yet they can swiftly deteriorate into dysfunction upon the removal of a few keystone nodes. Discovering theories that measure network resilience offers the potential to prevent catastrophic collapses--from species extinctions to financial crise--with profound implications for real-world systems. Current resilience theories address the problem from a single perspective of topology, neglecting the crucial role of system dynamics, due to the intrinsic complexity of the coupling between topology and dynamics which exceeds the capabilities of human analytical methods. Here, we report an automatic method for resilience theory discovery, which learns from how AI solves a complicated network dismantling problem and symbolizes its network attack strategies into theoretical formulas. This proposed self-inductive approach discovers the first resilience theory that accounts for both topology and dynamics, highlighting how the correlation between node degree and state shapes overall network resilience, and offering insights for designing early warning signals of systematic collapses. Additionally, our approach discovers formulas that refine existing well-established resilience theories with over 37.5% improvement in accuracy, significantly advancing human understanding of complex networks with AI.",
      "authors": [
        "Yu Zheng",
        "Jingtao Ding",
        "Depeng Jin",
        "Jianxi Gao",
        "and Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T19:19:35+00:00",
          "link": "https://arxiv.org/abs/2507.08827v1",
          "size": "1963kb",
          "version": "v1"
        }
      ],
      "title": "Advancing network resilience theories with symbolized reinforcement learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08827",
        "HTML": "https://arxiv.org/html/2507.08827v1",
        "PDF": "https://arxiv.org/pdf/2507.08827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about network resilience and theory discovery, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09401",
      "abstract": "This paper presents a fully discrete numerical scheme for one-dimensional nonlocal wave equations and provides a rigorous theoretical analysis. To facilitate the spatial discretization, we introduce an auxiliary variable analogous to the gradient field in local discontinuous Galerkin (DG) methods for classical partial differential equations (PDEs) and reformulate the equation into a system of equations. The proposed scheme then uses a DG method for spatial discretization and the Crank-Nicolson method for time integration. We prove optimal L2 error convergence for both the solution and the auxiliary variable under a special class of radial kernels at the semi-discrete level. In addition, for general kernels, we demonstrate the asymptotic compatibility of the scheme, ensuring that it recovers the classical DG approximation of the local wave equation in the zero-horizon limit. Furthermore, we prove that the fully discrete scheme preserves the energy of the nonlocal wave equation. A series of numerical experiments are presented to validate the theoretical findings.",
      "authors": [
        "Qiang Du",
        "Kui Ren",
        "Lu Zhang",
        "Yin Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:56:20+00:00",
          "link": "https://arxiv.org/abs/2507.09401v1",
          "size": "1510kb",
          "version": "v1"
        }
      ],
      "title": "A discontinuous Galerkin method for one-dimensional nonlocal wave problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09401",
        "HTML": "https://arxiv.org/html/2507.09401v1",
        "PDF": "https://arxiv.org/pdf/2507.09401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical schemes for nonlocal wave equations and does not discuss LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.04986",
      "abstract": "This paper fundamentally reformulates economic and financial theory to include electronic currencies. The valuation of the electronic currencies will be based on macroeconomic theory and the fundamental equation of monetary policy, not the microeconomic theory of discounted cash flows. The view of electronic currency as a transactional equity associated with tangible assets of a sub-economy will be developed, in contrast to the view of stock as an equity associated mostly with intangible assets of a sub-economy. The view will be developed of the electronic currency management firm as an entity responsible for coordinated monetary (electronic currency supply and value stabilization) and fiscal (investment and operational) policies of a substantial (for liquidity of the electronic currency) sub-economy. The risk model used in the valuations and the decision-making will not be the ubiquitous, yet inappropriate, exponential risk model that leads to discount rates, but will be multi time scale models that capture the true risk. The decision-making will be approached from the perspective of true systems control based on a system response function given by the multi scale risk model and system controllers that utilize the Deep Reinforcement Learning, Generative Pretrained Transformers, and other methods of Generative Artificial Intelligence (genAI). Finally, the sub-economy will be viewed as a nonlinear complex physical system with both stable equilibriums that are associated with short-term exploitation, and unstable equilibriums that need to be stabilized with active nonlinear control based on the multi scale system response functions and genAI.",
      "authors": [
        "Michael E. Glinsky and Sharon Sievert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Artificial Intelligence (cs.AI)",
        "Classical Physics (physics.class-ph)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-08T03:16:06+00:00",
          "link": "https://arxiv.org/abs/2310.04986v1",
          "size": "14324kb",
          "version": "v1"
        },
        {
          "date": "2023-10-11T23:42:37+00:00",
          "link": "https://arxiv.org/abs/2310.04986v2",
          "size": "14683kb",
          "version": "v2"
        },
        {
          "date": "2023-10-17T17:17:44+00:00",
          "link": "https://arxiv.org/abs/2310.04986v3",
          "size": "14945kb",
          "version": "v3"
        },
        {
          "date": "2023-10-30T16:46:13+00:00",
          "link": "https://arxiv.org/abs/2310.04986v4",
          "size": "14950kb",
          "version": "v4"
        },
        {
          "date": "2024-01-11T02:52:05+00:00",
          "link": "https://arxiv.org/abs/2310.04986v5",
          "size": "14951kb",
          "version": "v5"
        },
        {
          "date": "2024-07-17T13:43:10+00:00",
          "link": "https://arxiv.org/abs/2310.04986v6",
          "size": "12053kb",
          "version": "v6"
        },
        {
          "date": "2024-10-14T14:24:17+00:00",
          "link": "https://arxiv.org/abs/2310.04986v7",
          "size": "11951kb",
          "version": "v7"
        },
        {
          "date": "2024-12-24T05:52:29+00:00",
          "link": "https://arxiv.org/abs/2310.04986v8",
          "size": "11951kb",
          "version": "v8"
        },
        {
          "date": "2025-07-14T00:54:57+00:00",
          "link": "https://arxiv.org/abs/2310.04986v9",
          "size": "10906kb",
          "version": "v9"
        }
      ],
      "title": "A new economic and financial theory of money",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.04986",
        "HTML": "https://arxiv.org/html/2310.04986",
        "PDF": "https://arxiv.org/pdf/2310.04986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses economic and financial theories in the context of electronic currencies, with no relevance to LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09075",
      "abstract": "Recent advancements in reasoning-based Large Language Models (LLMs), particularly their potential through test-time scaling, have created significant opportunities for distillation in code generation and critique. However, progress in both areas fundamentally depends on large-scale, high-quality datasets. In this work, we introduce OpenCodeReasoning-II, a dataset consists of 2.5M question-solution-critique triples (approx. 35K unique programming questions), making it nearly twice the size of the previous largest publicly available code reasoning dataset. In this work, we employ a two-stage supervised fine-tuning strategy. The first stage focuses on fine-tuning for code generation, while the second stage involves the joint training of models for both code generation and critique. Our resulting finetuned Qwen2.5-Instruct models achieve performance in code generation that either exceeds or equals the best prior open-weight distilled models. Notably, the integration of our code generation and critique models leads to significant improvements in competitive coding performance. Furthermore, we present an extension of the LiveCodeBench benchmark to specifically support the C++ programming language, thereby facilitating more comprehensive LLM evaluation using this benchmark.",
      "authors": [
        "Wasi Uddin Ahmad",
        "Somshubra Majumdar",
        "Aleksander Ficek",
        "Sean Narenthiran",
        "Mehrzad Samadi",
        "Jocelyn Huang",
        "Siddhartha Jain",
        "Vahid Noroozi",
        "Boris Ginsburg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:35:54+00:00",
          "link": "https://arxiv.org/abs/2507.09075v1",
          "size": "174kb",
          "version": "v1"
        }
      ],
      "title": "OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09075",
        "HTML": "https://arxiv.org/html/2507.09075v1",
        "PDF": "https://arxiv.org/pdf/2507.09075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution lies in the creation of the OpenCodeReasoning-II dataset, which involves detailed data processing in the form of constructing a large-scale, high-quality dataset for code reasoning, thereby significantly focusing on training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09207",
      "abstract": "Wave propagation on the surface of a material contains information about physical properties beneath its surface. We propose a method for inferring the thickness and stiffness of a structure from just a video of waves on its surface. Our method works by extracting a dispersion relation from the video and then solving a physics-based optimization problem to find the best-fitting thickness and stiffness parameters. We validate our method on both simulated and real data, in both cases showing strong agreement with ground-truth measurements. Our technique provides a proof-of-concept for at-home health monitoring of medically-informative tissue properties, and it is further applicable to fields such as human-computer interaction.",
      "authors": [
        "Alexander C. Ogren",
        "Berthy T. Feng",
        "Jihoon Ahn",
        "Katherine L. Bouman",
        "Chiara Daraio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:00:06+00:00",
          "link": "https://arxiv.org/abs/2507.09207v1",
          "size": "14505kb",
          "version": "v1"
        }
      ],
      "title": "Visual Surface Wave Elastography: Revealing Subsurface Physical Properties via Visible Surface Waves",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09207",
        "HTML": "https://arxiv.org/html/2507.09207v1",
        "PDF": "https://arxiv.org/pdf/2507.09207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a method to infer physical properties using wave propagation analysis and does not discuss LLM training data processing or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09329",
      "abstract": "LLM-based coding agents are rapidly being deployed in software development, yet their security implications remain poorly understood. These agents, while capable of accelerating software development, may inadvertently introduce insecure practices. We conducted the first systematic security evaluation of autonomous coding agents, analyzing over 12,000 actions across five state-of-the-art models (GPT-4o, GPT-4.1, Claude variants) on 93 real-world software setup tasks. Our findings reveal significant security concerns: 21% of agent trajectories contained insecure actions, with models showing substantial variation in security behavior. We developed a high-precision detection system that identified four major vulnerability categories, with information exposure (CWE-200) being the most prevalent one. We also evaluated mitigation strategies including feedback mechanisms and security reminders with various effectiveness between models. GPT-4.1 demonstrated exceptional security awareness with 96.8% mitigation success. Our work provides the first comprehensive framework for evaluating coding agent security and highlights the need for security-aware design of next generation LLM-based coding agents.",
      "authors": [
        "Matous Kozak",
        "Roshanak Zilouchian Moghaddam",
        "Siva Sivaraman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:11:07+00:00",
          "link": "https://arxiv.org/abs/2507.09329v1",
          "size": "147kb",
          "version": "v1"
        }
      ],
      "title": "When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09329",
        "HTML": "https://arxiv.org/html/2507.09329v1",
        "PDF": "https://arxiv.org/pdf/2507.09329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates the security of coding agents using LLMs but does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09609",
      "abstract": "Phase retrieval involves recovering a signal from intensity-only measurements, crucial in many fields such as imaging, holography, optical computing, crystallography, and microscopy. Although there are several well-known phase retrieval algorithms, including classical iterative solvers, the reconstruction performance often remains sensitive to initialization and measurement noise. Recently, image-to-image diffusion models have gained traction in various image reconstruction tasks, yielding significant theoretical insights and practical breakthroughs. In this work, we introduce a novel phase retrieval approach based on an image-to-image diffusion framework called Inversion by Direct Iteration. Our method begins with an enhanced initialization stage that leverages a hybrid iterative technique, combining the Hybrid Input-Output and Error Reduction methods and incorporating a novel acceleration mechanism to obtain a robust crude estimate. Then, it iteratively refines this initial crude estimate using the learned image-to-image pipeline. Our method achieves substantial improvements in both training efficiency and reconstruction quality. Furthermore, our approach utilizes aggregation techniques to refine quality metrics and demonstrates superior results compared to both classical and contemporary techniques. This highlights its potential for effective and efficient phase retrieval across various applications.",
      "authors": [
        "Mehmet Onurcan Kaya",
        "Figen S. Oktem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:26:01+00:00",
          "link": "https://arxiv.org/abs/2507.09609v1",
          "size": "4112kb",
          "version": "v1"
        }
      ],
      "title": "I2I-PR: Deep Iterative Refinement for Phase Retrieval using Image-to-Image Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09609",
        "HTML": "https://arxiv.org/html/2507.09609v1",
        "PDF": "https://arxiv.org/pdf/2507.09609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on phase retrieval using image-to-image diffusion models and discusses iterative refinement and aggregation techniques, but it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09714",
      "abstract": "This paper presents a unified planning-control strategy for competing with other racing cars called IteraOptiRacing in autonomous racing environments. This unified strategy is proposed based on Iterative Linear Quadratic Regulator for Iterative Tasks (i2LQR), which can improve lap time performance in the presence of surrounding racing obstacles. By iteratively using the ego car's historical data, both obstacle avoidance for multiple moving cars and time cost optimization are considered in this unified strategy, resulting in collision-free and time-optimal generated trajectories. The algorithm's constant low computation burden and suitability for parallel computing enable real-time operation in competitive racing scenarios. To validate its performance, simulations in a high-fidelity simulator are conducted with multiple randomly generated dynamic agents on the track. Results show that the proposed strategy outperforms existing methods across all randomly generated autonomous racing scenarios, enabling enhanced maneuvering for the ego racing car.",
      "authors": [
        "Yifan Zeng",
        "Yihan Li",
        "Suiyi He",
        "Koushil Sreenath",
        "Jun Zeng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:18:51+00:00",
          "link": "https://arxiv.org/abs/2507.09714v1",
          "size": "6418kb",
          "version": "v1"
        }
      ],
      "title": "IteraOptiRacing: A Unified Planning-Control Framework for Real-time Autonomous Racing for Iterative Optimal Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09714",
        "HTML": "https://arxiv.org/html/2507.09714v1",
        "PDF": "https://arxiv.org/pdf/2507.09714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a strategy for autonomous racing, focusing on planning-control frameworks and optimization in racing scenarios, without any reference to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09716",
      "abstract": "We investigate the sequential composition of weak values in the framework of time-symmetric quantum mechanics. Specifically, we consider a forward'' weak measurement from a preselected state $\\ket{\\psi}$ to a post-selected state $\\ket{\\phi}$, followed by a reverse'' weak measurement. We show that the product of these two weak values corresponds to the normalized expectation value of a strong, state-conditioned observable $B = A P_\\psi A$, where $P_\\psi = \\ket{\\psi}\\bra{\\psi}$ is the projector onto the preselected state. Analyzing the structure of $B$, we demonstrate how it encodes interference information, particularly when $\\ket{\\psi}$ is a superposition rather than an eigenstate of $A$. This formulation extends naturally to mixed states by replacing $P_\\psi$ with a generic density matrix $\\rho$, linking the construction to the formalism of generalized quantum measurements. We illustrate practical applications in quantum information, including state-specific error witnessing in quantum computing, and show how the phase of a weak value can be inferred via strong measurements in the pure-state case.",
      "authors": [
        "Mirco A. Mannucci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.09716v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "When the Weak Becomes Strong: Effective Observables via Time-Symmetric Quantum Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09716",
        "HTML": "https://arxiv.org/html/2507.09716v1",
        "PDF": "https://arxiv.org/pdf/2507.09716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses weak values in quantum mechanics and their applications, but does not mention LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09759",
      "abstract": "Pneumonia is a leading cause of mortality in children under five, requiring accurate chest X-ray diagnosis. This study presents a machine learning-based Pediatric Chest Pneumonia Classification System to assist healthcare professionals in diagnosing pneumonia from chest X-ray images. The CNN-based model was trained on 5,863 labeled chest X-ray images from children aged 0-5 years from the Guangzhou Women and Children's Medical Center. To address limited data, we applied augmentation techniques (rotation, zooming, shear, horizontal flipping) and employed GANs to generate synthetic images, addressing class imbalance. The system achieved optimal performance using combined original, augmented, and GAN-generated data, evaluated through accuracy and F1 score metrics. The final model was deployed via a Flask web application, enabling real-time classification with probability estimates. Results demonstrate the potential of deep learning and GANs in improving diagnostic accuracy and efficiency for pediatric pneumonia classification, particularly valuable in resource-limited clinical settings https://github.com/AbdulManaf12/Pediatric-Chest-Pneumonia-Classification",
      "authors": [
        "Abdul Manaf",
        "Nimra Mughal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:38:49+00:00",
          "link": "https://arxiv.org/abs/2507.09759v1",
          "size": "4505kb",
          "version": "v1"
        }
      ],
      "title": "AI-Enhanced Pediatric Pneumonia Detection: A CNN-Based Approach Using Data Augmentation and Generative Adversarial Networks (GANs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09759",
        "HTML": "https://arxiv.org/html/2507.09759v1",
        "PDF": "https://arxiv.org/pdf/2507.09759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a pediatric pneumonia detection system using data augmentation and GANs, but it is focused on improving image classification tasks, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09872",
      "abstract": "Central to Earth observation is the trade-off between spatial and temporal resolution. For temperature, this is especially critical because real-world applications require high spatiotemporal resolution data. Current technology allows for hourly temperature observations at 2 km, but only every 16 days at 100 m, a gap further exacerbated by cloud cover. Earth system models offer continuous hourly temperature data, but at a much coarser spatial resolution (9-31 km). Here, we present a physics-guided deep learning framework for temperature data reconstruction that integrates these two data sources. The proposed framework uses a convolutional neural network that incorporates the annual temperature cycle and includes a linear term to amplify the coarse Earth system model output into fine-scale temperature values observed from satellites. We evaluated this framework using data from two satellites, GOES-16 (2 km, hourly) and Landsat (100 m, every 16 days), and demonstrated effective temperature reconstruction with hold-out and in situ data across four datasets. This physics-guided deep learning framework opens new possibilities for generating high-resolution temperature data across spatial and temporal scales, under all weather conditions and globally.",
      "authors": [
        "Shengjie Liu",
        "Lu Zhang",
        "Siqin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:03:25+00:00",
          "link": "https://arxiv.org/abs/2507.09872v1",
          "size": "4234kb",
          "version": "v1"
        }
      ],
      "title": "Resolution Revolution: A Physics-Guided Deep Learning Framework for Spatiotemporal Temperature Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09872",
        "HTML": "https://arxiv.org/html/2507.09872v1",
        "PDF": "https://arxiv.org/pdf/2507.09872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about using a deep learning framework for spatiotemporal temperature reconstruction, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10385",
      "abstract": "The major task of any e-commerce search engine is to retrieve the most relevant inventory items, which best match the user intent reflected in a query. This task is non-trivial due to many reasons, including ambiguous queries, misaligned vocabulary between buyers, and sellers, over- or under-constrained queries by the presence of too many or too few tokens. To address these challenges, query reformulation is used, which modifies a user query through token dropping, replacement or expansion, with the objective to bridge semantic gap between query tokens and users' search intent. Early methods of query reformulation mostly used statistical measures derived from token co-occurrence frequencies from selective user sessions having clicks or purchases. In recent years, supervised deep learning approaches, specifically transformer-based neural language models, or sequence-to-sequence models are being used for query reformulation task. However, these models do not utilize the semantic tags of a query token, which are significant for capturing user intent of an e-commerce query. In this work, we pose query reformulation as a token classification task, and solve this task by designing a dependency-aware transformer-based language model, TagBERT, which makes use of semantic tags of a token for learning superior query phrase embedding. Experiments on large, real-life e-commerce datasets show that TagBERT exhibits superior performance than plethora of competing models, including BERT, eBERT, and Sequence-to-Sequence transformer model for important token classification task.",
      "authors": [
        "Md. Ahsanul Kabir",
        "Mohammad Al Hasan",
        "Aritra Mandal",
        "Liyang Hao",
        "Ishita Khan",
        "Daniel Tunkelang",
        "Zhe Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:25:13+00:00",
          "link": "https://arxiv.org/abs/2507.10385v1",
          "size": "351kb",
          "version": "v1"
        }
      ],
      "title": "Extracting Important Tokens in E-Commerce Queries with a Tag Interaction-Aware Transformer Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10385",
        "HTML": "https://arxiv.org/html/2507.10385v1",
        "PDF": "https://arxiv.org/pdf/2507.10385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses query reformulation using a transformer model in e-commerce, mentioning token classification and query phrase embeddings but lacks a detailed focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.00260",
      "abstract": "Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant device memory usage. We parameterize the update such that parameter learning is convex when the objective function is convex. In particular, we explore preconditioned gradient descent and an extension of Polyak's Heavy Ball Method with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithms, convergence in the training set is proved even when the preconditioners are not necessarily symmetric nor positive definite. Convergence on a class of unseen functions is also obtained under certain assumptions, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioners demonstrate improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.",
      "authors": [
        "Patrick Fahy",
        "Mohammad Golbabaee",
        "Matthias J. Ehrhardt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-01T01:49:37+00:00",
          "link": "https://arxiv.org/abs/2406.00260v1",
          "size": "11888kb",
          "version": "v1"
        },
        {
          "date": "2024-10-15T16:22:52+00:00",
          "link": "https://arxiv.org/abs/2406.00260v2",
          "size": "16483kb",
          "version": "v2"
        },
        {
          "date": "2024-11-11T13:15:58+00:00",
          "link": "https://arxiv.org/abs/2406.00260v3",
          "size": "16483kb",
          "version": "v3"
        },
        {
          "date": "2024-11-30T02:32:31+00:00",
          "link": "https://arxiv.org/abs/2406.00260v4",
          "size": "34023kb",
          "version": "v4"
        },
        {
          "date": "2024-12-05T01:21:47+00:00",
          "link": "https://arxiv.org/abs/2406.00260v5",
          "size": "34023kb",
          "version": "v5"
        },
        {
          "date": "2025-02-06T00:00:53+00:00",
          "link": "https://arxiv.org/abs/2406.00260v6",
          "size": "34019kb",
          "version": "v6"
        },
        {
          "date": "2025-06-25T22:04:46+00:00",
          "link": "https://arxiv.org/abs/2406.00260v7",
          "size": "4132kb",
          "version": "v7"
        },
        {
          "date": "2025-07-03T11:20:40+00:00",
          "link": "https://arxiv.org/abs/2406.00260v8",
          "size": "4135kb",
          "version": "v8"
        },
        {
          "date": "2025-07-14T10:53:03+00:00",
          "link": "https://arxiv.org/abs/2406.00260v9",
          "size": "4137kb",
          "version": "v9"
        }
      ],
      "title": "Greedy Learning to Optimize with Convergence Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00260",
        "HTML": "https://arxiv.org/html/2406.00260",
        "PDF": "https://arxiv.org/pdf/2406.00260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimization algorithms and convergence guarantees, with no mention of LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.17653",
      "abstract": "Remote attestation (RA) is the foundation for trusted execution environments in the cloud and trusted device driver onboarding in operating systems. However, RA misses a rigorous mechanized definition of its security properties in one of the strongest models, i.e., the semantic model. Such a mechanization requires the concept of StateSeparating Proofs (SSP). However, SSP was only recently implemented as a foundational framework in the Rocq Prover. Based on this framework, this paper presents the first mechanized formalization of the fundamental security properties of RA. Our Rocq Prover development first defines digital signatures and formally verifies security against forgery in the strong existential attack model. Based on these results, we define RA and reduce the security of RA to the security of digital signatures. Our development provides evidence that the RA protocol is secure against forgery. Additionally, we extend our reasoning to the primitives of RA and reduce their security to the security of the primitives of the digital signatures.",
      "authors": [
        "Sara Zain",
        "Jannik M\\\"ahn",
        "Stefan K\\\"opsell",
        "Sebastian Ertel"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T21:02:56+00:00",
          "link": "https://arxiv.org/abs/2502.17653v1",
          "size": "197kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:36:02+00:00",
          "link": "https://arxiv.org/abs/2502.17653v2",
          "size": "250kb",
          "version": "v2"
        }
      ],
      "title": "Formally-verified Security against Forgery of Remote Attestation using SSProve",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17653",
        "PDF": "https://arxiv.org/pdf/2502.17653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the security properties of Remote Attestation using formal verification, with no mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18421",
      "abstract": "The majority of data in businesses and industries is stored in tables, databases, and data warehouses. Reasoning with table-structured data poses significant challenges for large language models (LLMs) due to its hidden semantics, inherent complexity, and structured nature. One of these challenges is lacking an effective evaluation benchmark fairly reflecting the performances of LLMs on broad table reasoning abilities. In this paper, we fill in this gap, presenting a comprehensive table reasoning evolution benchmark, TReB, which measures both shallow table understanding abilities and deep table reasoning abilities, a total of 26 sub-tasks. We construct a high quality dataset through an iterative data processing procedure. We create an evaluation framework to robustly measure table reasoning capabilities with three distinct inference modes, TCoT, PoT and ICoT. Further, we benchmark over 20 state-of-the-art LLMs using this frame work and prove its effectiveness. Experimental results reveal that existing LLMs still have significant room for improvement in addressing the complex and real world Table related tasks. Both the dataset and evaluation framework are publicly available, with the dataset hosted on huggingface.co/datasets/JT-LM/JIUTIAN-TReB and the framework on github.com/JT-LM/jiutian-treb.",
      "authors": [
        "Ce Li",
        "Xiaofan Liu",
        "Zhiyan Song",
        "Ce Chi",
        "Chen Zhao",
        "Jingjing Yang",
        "Zhendong Wang",
        "Kexin Yang",
        "Boshen Shi",
        "Xing Wang",
        "Chao Deng",
        "Junlan Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T09:02:04+00:00",
          "link": "https://arxiv.org/abs/2506.18421v1",
          "size": "572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T06:09:12+00:00",
          "link": "https://arxiv.org/abs/2506.18421v2",
          "size": "572kb",
          "version": "v2"
        }
      ],
      "title": "TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18421",
        "HTML": "https://arxiv.org/html/2506.18421v2",
        "PDF": "https://arxiv.org/pdf/2506.18421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a new benchmark, TReB, which includes creating a high-quality dataset through iterative data processing, directly relevant to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "JT-LM/JIUTIAN-TReB",
          "downloads": "52",
          "likes": "1",
          "link": "https://huggingface.co/datasets/JT-LM/JIUTIAN-TReB"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09138",
      "abstract": "This paper addresses emerging system-level challenges in heterogeneous retrieval-augmented generation (RAG) serving, where complex multi-stage workflows and diverse request patterns complicate efficient execution. We present HedraRAG, a runtime system built on a graph-based abstraction that exposes optimization opportunities across stage-level parallelism, intra-request similarity, and inter-request skewness. These opportunities are realized through dynamic graph transformations, such as node splitting, reordering, edge addition, and dependency rewiring, applied to wavefronts of subgraphs spanning concurrent requests. The resulting execution plans are mapped onto hybrid CPU-GPU pipelines to improve resource utilization and reduce latency. Evaluations across a wide range of RAG workflows demonstrate speedups exceeding 1.5x and reaching up to 5x over existing frameworks, showcasing the effectiveness of coordinated generation and retrieval in serving environments.",
      "authors": [
        "Zhengding Hu",
        "Vibha Murthy",
        "Zaifeng Pan",
        "Wanlu Li",
        "Xiaoyi Fang",
        "Yufei Ding",
        "Yuke Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:42:43+00:00",
          "link": "https://arxiv.org/abs/2507.09138v1",
          "size": "2073kb",
          "version": "v1"
        }
      ],
      "title": "HedraRAG: Coordinating LLM Generation and Database Retrieval in Heterogeneous RAG Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09138",
        "HTML": "https://arxiv.org/html/2507.09138v1",
        "PDF": "https://arxiv.org/pdf/2507.09138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes HedraRAG, a system to improve resource utilization in RAG serving environments, without addressing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09334",
      "abstract": "While 3D Multi-modal Large Language Models (MLLMs) demonstrate remarkable scene understanding capabilities, their practical deployment faces critical challenges due to computational inefficiency. The key bottleneck stems from processing excessive object-centric visual tokens required for comprehensive 3D scene representation. Although visual token pruning has shown promise in accelerating 2D MLLMs, its applicability to 3D domains remains largely unexplored due to fundamental disparities in token structures. In this paper, we reveal two critical insights: (1) Significant redundancy exists in object-level 3D token representations, analogous to patch-level redundancy in 2D systems; (2) Global attention patterns exhibit strong predictive power for identifying non-essential tokens in 3D contexts. Building on these observations, we propose Fast3D, a plug-and-play visual token pruning framework for 3D MLLMs featuring two technical innovations: (1) Global Attention Prediction (GAP), where a lightweight neural network learns to predict the global attention distributions of the target model, enabling efficient token importance estimation for precise pruning guidance; (2) Sample-Adaptive visual token Pruning (SAP), which introduces dynamic token budgets through attention-based complexity assessment, automatically adjusting layer-wise pruning ratios based on input characteristics. Both of these two techniques operate without modifying the parameters of the target model. Extensive evaluations across five benchmarks validate the effectiveness of Fast3D, particularly under high visual token pruning ratios. Code is available at https://github.com/wencan25/Fast3D",
      "authors": [
        "Wencan Huang",
        "Daizong Liu",
        "Wei Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:29:02+00:00",
          "link": "https://arxiv.org/abs/2507.09334v1",
          "size": "1493kb",
          "version": "v1"
        }
      ],
      "title": "Fast3D: Accelerating 3D Multi-modal Large Language Models for Efficient 3D Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09334",
        "HTML": "https://arxiv.org/html/2507.09334v1",
        "PDF": "https://arxiv.org/pdf/2507.09334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses visual token pruning in 3D MLLMs for efficiency improvements but does not deal with the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09638",
      "abstract": "The Retrieval-Augmented Generation (RAG) systems' performance on Thai legal question answering is still limited, especially for questions requiring extensive, complex legal reasoning. To address these limitations, we introduce an approach aligning LLMs toward improved law citation accuracy and better response quality using Group-Relative Policy Optimization (GRPO). Our approach leverages BGE-M3 embeddings as a cost-efficient semantic-similarity reward, significantly reducing computational expenses up to 2.5x compared to large language model judges. Experiments on the NitiBench benchmark demonstrate substantial improvements: GRPO achieves up to 90% citation-F1 gains from the base model and a 31% increase in joint quality metrics over instruction tuning. Crucially, our method shows enhanced robustness on complex legal reasoning tasks compared to instruction tuning, providing an effective and resource-efficient solution for enhancing Thai legal LLMs.",
      "authors": [
        "Pawitsapak Akarajaradwong",
        "Chompakorn Chaksangchaichot",
        "Pirat Pothavorn",
        "Attapol Thamrongrattanarit-Rutherford",
        "Ekapol Chuangsuwanich",
        "Sarana Nutanong"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:05:48+00:00",
          "link": "https://arxiv.org/abs/2507.09638v1",
          "size": "9526kb",
          "version": "v1"
        }
      ],
      "title": "Can Group Relative Policy Optimization Improve Thai Legal Reasoning and Question Answering?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09638",
        "HTML": "https://arxiv.org/html/2507.09638v1",
        "PDF": "https://arxiv.org/pdf/2507.09638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses an approach to improve LLMs for legal reasoning and QA, it focuses more on optimization methods (GRPO) rather than substantive data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09662",
      "abstract": "Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have demonstrated impressive performance on complex reasoning tasks like mathematics and programming with long Chain-of-Thought (CoT) reasoning sequences (slow-thinking), compared with traditional large language models (fast-thinking). However, these reasoning models also face a huge challenge that generating unnecessarily lengthy and redundant reasoning chains even for trivial questions. This phenomenon leads to a significant waste of inference resources, increases the response time for simple queries, and hinders the practical application of LRMs in real-world products. To this end, it is crucial to shorten lengthy reasoning chains and learn adaptive reasoning between fast and slow thinking based on input difficulty. In this survey, we provide a comprehensive overview of recent progress in concise and adaptive thinking for efficient reasoning of LRMs, including methodologies, benchmarks, and challenges for future exploration. We hope this survey can help researchers quickly understand the landscape of this field and inspire novel adaptive thinking ideas to facilitate better usage of LRMs.",
      "authors": [
        "Jason Zhu",
        "Hongyu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:51:59+00:00",
          "link": "https://arxiv.org/abs/2507.09662v1",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "title": "Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09662",
        "HTML": "https://arxiv.org/html/2507.09662v1",
        "PDF": "https://arxiv.org/pdf/2507.09662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey addresses reasoning models and their efficiency challenges, but does not focus on processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10010",
      "abstract": "Uncertainties influencing the dynamical systems pose a significant challenge in estimating the achievable performance of a controller aiming to control such uncertain systems. When the uncertainties are of stochastic nature, obtaining hard guarantees for the robustness of a controller aiming to hedge against the uncertainty is not possible. This issue set the platform for the development of probabilistic robust control approaches. In this work, we utilise the gap metric between the known nominal model and the unknown perturbed model of the uncertain system as a tool to gauge the robustness of a controller and formulate the gap as a random variable in the setting with stochastic uncertainties. Main results of this paper includes giving probabilistic bound on the gap exceeding a known threshold followed by bounds on the expected gap value and probabilistic robust stability in terms of the gap metric. Further, we also provide a probabilistic controller performance certification under gap uncertainty and probabilistic guarantee on the achievable $\\mathcal{H}_{\\infty}$ robustness. Numerical simulations are provided at many places to demonstrate the proposed approach.",
      "authors": [
        "Venkatraman Renganathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:43:54+00:00",
          "link": "https://arxiv.org/abs/2507.10010v1",
          "size": "385kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Robustness in the Gap Metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10010",
        "HTML": "https://arxiv.org/html/2507.10010v1",
        "PDF": "https://arxiv.org/pdf/2507.10010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses probabilistic robust control using the gap metric for dynamic systems. There is no focus on LLM training data processing or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10342",
      "abstract": "This paper explores the potential of large language models (LLMs) as reliable analytical tools in linguistic research, focusing on the emergence of affective meanings in temporal expressions involving manner-of-motion verbs. While LLMs like GPT-4 have shown promise across a range of tasks, their ability to replicate nuanced human judgements remains under scrutiny. We conducted four psycholinguistic studies (on emergent meanings, valence shifts, verb choice in emotional contexts, and sentence-emoji associations) first with human participants and then replicated the same tasks using an LLM. Results across all studies show a striking convergence between human and AI responses, with statistical analyses (e.g., Spearman's rho = .73-.96) indicating strong correlations in both rating patterns and categorical choices. While minor divergences were observed in some cases, these did not alter the overall interpretative outcomes. These findings offer compelling evidence that LLMs can augment traditional human-based experimentation, enabling broader-scale studies without compromising interpretative validity. This convergence not only strengthens the empirical foundation of prior human-based findings but also opens possibilities for hypothesis generation and data expansion through AI. Ultimately, our study supports the use of LLMs as credible and informative collaborators in linguistic inquiry.",
      "authors": [
        "Rosa Illan Castillo and Javier Valenzuela"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:47:01+00:00",
          "link": "https://arxiv.org/abs/2507.10342v1",
          "size": "1863kb",
          "version": "v1"
        }
      ],
      "title": "Using AI to replicate human experimental results: a motion study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10342",
        "PDF": "https://arxiv.org/pdf/2507.10342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates LLMs as analytical tools for linguistics, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2107.07344",
      "abstract": "The increasing population of elderly people is associated with the need to meet their increasing requirements and to provide solutions that can improve their quality of life in a smart home. In addition to fear and anxiety towards interfacing with systems; cognitive disabilities, weakened memory, disorganized behavior and even physical limitations are some of the problems that elderly people tend to face with increasing age. The essence of providing technology-based solutions to address these needs of elderly people and to create smart and assisted living spaces for the elderly; lies in developing systems that can adapt by addressing their diversity and can augment their performances in the context of their day to day goals. Therefore, this work proposes a framework for development of a Personalized Intelligent Assistant to help elderly people perform Activities of Daily Living (ADLs) in a smart and connected Internet of Things (IoT) based environment. This Personalized Intelligent Assistant can analyze different tasks performed by the user and recommend activities by considering their daily routine, current affective state and the underlining user experience. To uphold the efficacy of this proposed framework, it has been tested on a couple of datasets for modelling an average user and a specific user respectively. The results presented show that the model achieves a performance accuracy of 73.12% when modelling a specific user, which is considerably higher than its performance while modelling an average user, this upholds the relevance for development and implementation of this proposed framework.",
      "authors": [
        "Nirmalya Thakur and Chia Y. Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2021-06-29T17:36:07+00:00",
          "link": "https://arxiv.org/abs/2107.07344v1",
          "size": "1799kb",
          "version": "v1"
        }
      ],
      "title": "Framework for A Personalized Intelligent Assistant to Elderly People for Activities of Daily Living",
      "links": {
        "Abstract": "https://arxiv.org/abs/2107.07344",
        "PDF": "https://arxiv.org/pdf/2107.07344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a personalized intelligent assistant for elderly people in smart homes, with no mention of LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.12596",
      "abstract": "This expository paper introduces a simplified approach to image-based quality inspection in manufacturing using OpenAI's CLIP (Contrastive Language-Image Pretraining) model adapted for few-shot learning. While CLIP has demonstrated impressive capabilities in general computer vision tasks, its direct application to manufacturing inspection presents challenges due to the domain gap between its training data and industrial applications. We evaluate CLIP's effectiveness through five case studies: metallic pan surface inspection, 3D printing extrusion profile analysis, stochastic textured surface evaluation, automotive assembly inspection, and microstructure image classification. Our results show that CLIP can achieve high classification accuracy with relatively small learning sets (50-100 examples per class) for single-component and texture-based applications. However, the performance degrades with complex multi-component scenes. We provide a practical implementation framework that enables quality engineers to quickly assess CLIP's suitability for their specific applications before pursuing more complex solutions. This work establishes CLIP-based few-shot learning as an effective baseline approach that balances implementation simplicity with robust performance, demonstrated in several manufacturing quality control applications.",
      "authors": [
        "Fadel M. Megahed",
        "Ying-Ju Chen",
        "Bianca Maria Colosimo",
        "Marco Luigi Giuseppe Grasso",
        "L. Allison Jones-Farmer",
        "Sven Knoth",
        "Hongyue Sun",
        "and Inez Zwetsloot"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Applications (stat.AP)",
        "Other Statistics (stat.OT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T02:45:30+00:00",
          "link": "https://arxiv.org/abs/2501.12596v1",
          "size": "6523kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:52:38+00:00",
          "link": "https://arxiv.org/abs/2501.12596v2",
          "size": "6424kb",
          "version": "v2"
        }
      ],
      "title": "Adapting OpenAI's CLIP Model for Few-Shot Image Inspection in Manufacturing Quality Control: An Expository Case Study with Multiple Application Examples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12596",
        "HTML": "https://arxiv.org/html/2501.12596v2",
        "PDF": "https://arxiv.org/pdf/2501.12596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper adapts OpenAI's CLIP model for image inspection in manufacturing but does not involve any substantive modifications to LLM training data or data processing techniques."
      },
      "tasks": [
        "Few-Shot Learning",
        "image-classification",
        "Image Classification",
        "Manufacturing Quality Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01465",
      "abstract": "Resource Public Key Infrastructure (RPKI) is a critical security mechanism for BGP, but the complexity of its architecture is a growing concern as its adoption scales. Current RPKI design heavily reuses legacy PKI components, such as X.509 EE-certificates, ASN.1 encoding, and XML-based repository protocols, which introduce excessive cryptographic validation, redundant metadata, and inefficiencies in both storage and processing. We show that these design choices, although based on established standards, create significant performance bottlenecks, increase the vulnerability surface, and hinder scalability for wide-scale Internet deployment.\n  In this paper, we perform the first systematic analysis of the root causes of complexity in RPKI's design and experimentally quantify their real-world impact. We show that over 70\\% of validation time in RPKI relying parties is spent on certificate parsing and signature verification, much of it unnecessary. Building on this insight, we introduce the improved RPKI (iRPKI), a backwards-compatible redesign that preserves all security guarantees while substantially reducing protocol overhead. iRPKI eliminates EE-certificates and ROA signatures, merges revocation and integrity objects, replaces verbose encodings with Protobuf, and restructures repository metadata for more efficient access. We experimentally demonstrate that our implementation of iRPKI in the Routinator validator achieves a 20x speed-up of processing time, 18x improvement of bandwidth requirements and 8x reduction in cache memory footprint, while also eliminating classes of vulnerabilities that have led to at least 10 vulnerabilities in RPKI software. iRPKI significantly increases the feasibility of deploying RPKI at scale in the Internet, and especially in constrained environments. Our design may be deployed incrementally without impacting existing operations.",
      "authors": [
        "Haya Schulmann",
        "Niklas Vogel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T08:24:50+00:00",
          "link": "https://arxiv.org/abs/2507.01465v1",
          "size": "1455kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:45:34+00:00",
          "link": "https://arxiv.org/abs/2507.01465v2",
          "size": "1513kb",
          "version": "v2"
        }
      ],
      "title": "Pruning the Tree: Rethinking RPKI Architecture From The Ground Up",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01465",
        "HTML": "https://arxiv.org/html/2507.01465v2",
        "PDF": "https://arxiv.org/pdf/2507.01465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the RPKI architecture and proposes a redesigned version to improve its efficiency. It does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08904",
      "abstract": "Beam alignment (BA) is a crucial process in millimeter-wave (mmWave) communications, enabling precise directional transmission and efficient link establishment. However, due to characteristics like omnidirectional exposure and the broadcast nature of the BA phase, it is particularly vulnerable to eavesdropping and identity impersonation attacks. To this end, this paper proposes a novel secure framework named CovertAuth, designed to enhance the security of the BA phase against such attacks. In particular, to combat eavesdropping attacks, the closed-form expressions of successful BA probability and covert transmission rate are first derived. Then, a covert communication problem aimed at jointly optimizing beam training budget and transmission power is formulated to maximize covert communication rate, subject to the covertness requirement. An alternating optimization algorithm combined with successive convex approximation is employed to iteratively achieve optimal results. To combat impersonation attacks, the mutual coupling effect of antenna array impairments is explored as a device feature to design a weighted-sum energy detector based physical layer authentication scheme. Moreover, theoretical models for authentication metrics like detection and false alarm probabilities are also provided to conduct performance analysis. Based on these models, an optimization problem is constructed to determine the optimal weight value that maximizes authentication accuracy. Finally, simulation results demonstrate that CovertAuth presents improved detection accuracy under the same covertness requirement compared to existing works.",
      "authors": [
        "Yulin Teng",
        "Keshuang Han",
        "Pinchang Zhang",
        "Xiaohong Jiang",
        "Yulong Shen",
        "Fu Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:19:25+00:00",
          "link": "https://arxiv.org/abs/2507.08904v1",
          "size": "638kb",
          "version": "v1"
        }
      ],
      "title": "CovertAuth: Joint Covert Communication and Authentication in MmWave Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08904",
        "HTML": "https://arxiv.org/html/2507.08904v1",
        "PDF": "https://arxiv.org/pdf/2507.08904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a secure communication and authentication framework for mmWave systems and does not engage with LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2210.14231",
      "abstract": "In off-axis Quantitative Phase Imaging (QPI), artificial neural networks have been recently applied for phase retrieval with aberration compensation and phase unwrapping. However, the involved neural network architectures are largely unoptimized and inefficient with low inference speed, which hinders the realization of real-time imaging. Here, we propose a Neural Architecture Search (NAS) generated Phase Retrieval Net (NAS-PRNet) for accurate and fast phase retrieval. NAS-PRNet is an encoder-decoder style neural network, automatically found from a large neural network architecture search space through NAS. By modifying the differentiable NAS scheme from SparseMask, we learn the optimized skip connections through gradient descent. Specifically, we implement MobileNet-v2 as the encoder and define a synthesized loss that incorporates phase reconstruction loss and network sparsity loss. NAS-PRNet has achieved high-fidelity phase retrieval by achieving a peak Signal-to-Noise Ratio (PSNR) of 36.7 dB and a Structural SIMilarity (SSIM) of 86.6% as tested on interferograms of biological cells. Notably, NAS-PRNet achieves phase retrieval in only 31 ms, representing 15x speedup over the most recent Mamba-UNet with only a slightly lower phase retrieval accuracy.",
      "authors": [
        "Xin Shu",
        "Mengxuan Niu",
        "Yi Zhang",
        "Wei Luo",
        "Renjie Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-25T16:16:41+00:00",
          "link": "https://arxiv.org/abs/2210.14231v1",
          "size": "601kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T03:43:23+00:00",
          "link": "https://arxiv.org/abs/2210.14231v2",
          "size": "746kb",
          "version": "v2"
        }
      ],
      "title": "Neural Architecture Search generated Phase Retrieval Net for Real-time Off-axis Quantitative Phase Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.14231",
        "HTML": "https://arxiv.org/html/2210.14231v2",
        "PDF": "https://arxiv.org/pdf/2210.14231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing neural network architectures for phase retrieval in imaging, not on training data processing for LLMs."
      },
      "tasks": [
        "Decoder",
        "Neural Architecture Search",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06448",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a highly effective strategy for endowing Large Language Models (LLMs) with robust multi-step reasoning abilities. However, its design and optimizations remain tailored to purely textual domains, resulting in suboptimal performance when applied to multimodal reasoning tasks. In particular, we observe that a major source of error in current multimodal reasoning lies in the perception of visual inputs. To address this bottleneck, we propose Perception-Aware Policy Optimization (PAPO), a simple yet effective extension of GRPO that encourages the model to learn to perceive while learning to reason, entirely from internal supervision signals. Notably, PAPO does not rely on additional data curation, external reward models, or proprietary models. Specifically, we introduce the Implicit Perception Loss in the form of a KL divergence term to the GRPO objective, which, despite its simplicity, yields significant overall improvements (4.4%) on diverse multimodal benchmarks. The improvements are more pronounced, approaching 8.0%, on tasks with high vision dependency. We also observe a substantial reduction (30.5%) in perception errors, indicating improved perceptual capabilities with PAPO. We conduct comprehensive analysis of PAPO and identify a unique loss hacking issue, which we rigorously analyze and mitigate through a Double Entropy Loss. Overall, our work introduces a deeper integration of perception-aware supervision into RLVR learning objectives and lays the groundwork for a new RL framework that encourages visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.",
      "authors": [
        "Zhenhailong Wang",
        "Xuehang Guo",
        "Sofia Stoica",
        "Haiyang Xu",
        "Hongru Wang",
        "Hyeonjeong Ha",
        "Xiusi Chen",
        "Yangyi Chen",
        "Ming Yan",
        "Fei Huang",
        "Heng Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:22:34+00:00",
          "link": "https://arxiv.org/abs/2507.06448v1",
          "size": "5480kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T16:48:37+00:00",
          "link": "https://arxiv.org/abs/2507.06448v2",
          "size": "5480kb",
          "version": "v2"
        }
      ],
      "title": "Perception-Aware Policy Optimization for Multimodal Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06448",
        "PDF": "https://arxiv.org/pdf/2507.06448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses multimodal reasoning and perception in reinforcement learning with large language models but does not involve any LLM training data processing techniques."
      },
      "models": [
        {
          "model_path": "PAPOGalaxy/PAPO-Qwen2.5-VL-3B",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PAPOGalaxy/PAPO-Qwen2.5-VL-3B"
        },
        {
          "model_path": "PAPOGalaxy/PAPO-H-Qwen2.5-VL-3B",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PAPOGalaxy/PAPO-H-Qwen2.5-VL-3B"
        },
        {
          "model_path": "PAPOGalaxy/PAPO-Qwen2.5-VL-7B",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PAPOGalaxy/PAPO-Qwen2.5-VL-7B"
        },
        {
          "model_path": "PAPOGalaxy/PAPO-H-Qwen2.5-VL-7B",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PAPOGalaxy/PAPO-H-Qwen2.5-VL-7B"
        },
        {
          "model_path": "PAPOGalaxy/PAPO-NRef-Qwen2.5-VL-3B",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PAPOGalaxy/PAPO-NRef-Qwen2.5-VL-3B"
        },
        {
          "model_path": "PAPOGalaxy/PAPO-NRef-Qwen2.5-VL-7B",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PAPOGalaxy/PAPO-NRef-Qwen2.5-VL-7B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "PAPOGalaxy/PAPO_ViRL39K_train",
          "downloads": "116",
          "likes": "0",
          "link": "https://huggingface.co/datasets/PAPOGalaxy/PAPO_ViRL39K_train"
        },
        {
          "dataset_name": "PAPOGalaxy/PAPO_MMK12_test",
          "downloads": "70",
          "likes": "0",
          "link": "https://huggingface.co/datasets/PAPOGalaxy/PAPO_MMK12_test"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08844",
      "abstract": "It is frequently claimed in blockchain discourse that immutability guarantees trust. This paper rigorously refutes that assertion. We define immutability as the cryptographic persistence of historical states in an append-only data structure and contrast it with trust, understood as a rational epistemic expectation under uncertainty. Employing predicate logic, automata-theoretic models, and epistemic game-theoretic analysis, we demonstrate that immutability neither entails nor implies correctness, fairness, or credibility. Through formal constructions and counterexamples--including predictive fraud schemes and the phenomenon of garbage permanence--we show that the belief conflates structural and epistemic domains. Immutability preserves all data equally, regardless of veracity. Therefore, the assertion that immutability guarantees trust collapses under the weight of formal scrutiny.",
      "authors": [
        "Craig S Wright"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T09:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.08844v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "Immutability Does Not Guarantee Trust: A Formal and Logical Refutation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08844",
        "HTML": "https://arxiv.org/html/2507.08844v1",
        "PDF": "https://arxiv.org/pdf/2507.08844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on theoretical aspects of immutability in blockchain and makes no contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09016",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) aligns language models with human preferences but is computationally expensive. We explore two approaches that leverage human gaze modeling to enhance RLHF: (1) gaze-aware reward models and (2) gaze-based distribution of sparse rewards at token level. Our experiments demonstate that gaze-informed RLHF achieves faster convergence while maintaining or slightly improving performance, thus, reducing computational costs during policy optimization. These results show that human gaze provides a valuable and underused signal for policy optimization, pointing to a promising direction for improving RLHF efficiency.",
      "authors": [
        "Karim Galliamov",
        "Ivan Titov",
        "and Ilya Pershin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:49:04+00:00",
          "link": "https://arxiv.org/abs/2507.09016v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing RLHF with Human Gaze Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09016",
        "PDF": "https://arxiv.org/pdf/2507.09016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores improving RLHF by using human gaze, which might involve data processing indirectly, but does not primarily address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10300",
      "abstract": "Multimodal large language models (MLLMs) have shown remarkable performance in vision-language tasks. However, existing MLLMs are primarily trained on generic datasets, limiting their ability to reason on domain-specific visual cues such as those in facial images. In particular, tasks that require detailed understanding of facial structure, expression, emotion, and demographic features remain underexplored by MLLMs due to the lack of large-scale annotated face image-text datasets. In this work, we introduce FaceLLM, a multimodal large language model trained specifically for facial image understanding. To construct the training data, we propose a novel weakly supervised pipeline that uses ChatGPT with attribute-aware prompts to generate high-quality question-answer pairs based on images from the FairFace dataset. The resulting corpus, called FairFaceGPT, covers a diverse set of attributes including expression, pose, skin texture, and forensic information. Our experiments demonstrate that FaceLLM improves the performance of MLLMs on various face-centric tasks and achieves state-of-the-art performance. This work highlights the potential of synthetic supervision via language models for building domain-specialized MLLMs, and sets a precedent for trustworthy, human-centric multimodal AI systems. FairFaceGPT dataset and pretrained FaceLLM models are publicly available in the project page.",
      "authors": [
        "Hatef Otroshi Shahreza and S\\'ebastien Marcel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:04:14+00:00",
          "link": "https://arxiv.org/abs/2507.10300v1",
          "size": "1176kb",
          "version": "v1"
        }
      ],
      "title": "FaceLLM: A Multimodal Large Language Model for Face Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10300",
        "PDF": "https://arxiv.org/pdf/2507.10300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces FaceLLM, providing a new dataset (FairFaceGPT) created through a weakly supervised pipeline to generate high-quality question-answer pairs from images, directly contributing to LLM multimodal training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10303",
      "abstract": "Stochastic simulators exhibit intrinsic stochasticity due to unobservable, uncontrollable, or unmodeled input variables, resulting in random outputs even at fixed input conditions. Such simulators are common across various scientific disciplines; however, emulating their entire conditional probability distribution is challenging, as it is a task traditional deterministic surrogate modeling techniques are not designed for. Additionally, accurately characterizing the response distribution can require prohibitively large datasets, especially for computationally expensive high-fidelity (HF) simulators. When lower-fidelity (LF) stochastic simulators are available, they can enhance limited HF information within a multifidelity surrogate modeling (MFSM) framework. While MFSM techniques are well-established for deterministic settings, constructing multifidelity emulators to predict the full conditional response distribution of stochastic simulators remains a challenge. In this paper, we propose multifidelity generalized lambda models (MF-GLaMs) to efficiently emulate the conditional response distribution of HF stochastic simulators by exploiting data from LF stochastic simulators. Our approach builds upon the generalized lambda model (GLaM), which represents the conditional distribution at each input by a flexible, four-parameter generalized lambda distribution. MF-GLaMs are non-intrusive, requiring no access to the internal stochasticity of the simulators nor multiple replications of the same input values. We demonstrate the efficacy of MF-GLaM through synthetic examples of increasing complexity and a realistic earthquake application. Results show that MF-GLaMs can achieve improved accuracy at the same cost as single-fidelity GLaMs, or comparable performance at significantly reduced cost.",
      "authors": [
        "K. Giannoukou",
        "X. Zhu",
        "S. Marelli",
        "and B. Sudret"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:06:56+00:00",
          "link": "https://arxiv.org/abs/2507.10303v1",
          "size": "6593kb",
          "version": "v1"
        }
      ],
      "title": "MF-GLaM: A multifidelity stochastic emulator using generalized lambda models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10303",
        "HTML": "https://arxiv.org/html/2507.10303v1",
        "PDF": "https://arxiv.org/pdf/2507.10303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multifidelity stochastic emulators using lambda models for scientific applications, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.10218",
      "abstract": "Simulation frameworks are essential for the safe development of robotic applications. However, different components of a robotic system are often best simulated in different environments, making full integration challenging. This is particularly true for partially-open or closed-source simulators, which commonly suffer from two limitations: (i) lack of runtime control over scene actors via interfaces like ROS, and (ii) restricted access to real-time state data (e.g., pose, velocity) of scene objects. In the first part of this work, we address these issues by integrating aerial drones simulated in Parrot's Sphinx environment (used for Anafi drones) into the Gazebo simulator. Our approach uses a mirrored drone instance embedded within Gazebo environments to bridge the two simulators. One key application is aerial target tracking, a common task in multi-robot systems. However, Parrot's default PID-based controller lacks the agility needed for tracking fast-moving targets. To overcome this, in the second part of this work we develop a model predictive controller (MPC) that leverages cumulative error states to improve tracking accuracy. Our MPC significantly outperforms the built-in PID controller in dynamic scenarios, increasing the effectiveness of the overall system. We validate our integrated framework by incorporating the Anafi drone into an existing Gazebo-based airship simulation and rigorously test the MPC against a custom PID baseline in both simulated and real-world experiments.",
      "authors": [
        "Pascal Goldschmid and Aamir Ahmad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T15:11:21+00:00",
          "link": "https://arxiv.org/abs/2502.10218v1",
          "size": "1247kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T19:46:58+00:00",
          "link": "https://arxiv.org/abs/2502.10218v2",
          "size": "1114kb",
          "version": "v2"
        }
      ],
      "title": "A Multi-Simulation Approach with Model Predictive Control for Anafi Drones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10218",
        "HTML": "https://arxiv.org/html/2502.10218v2",
        "PDF": "https://arxiv.org/pdf/2502.10218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on simulation integration for drones and tracking systems, not on LLM training data processing or dataset creation."
      },
      "repo_urls": [
        "https://github.com/robot-perception-group/anafi_sim"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22362",
      "abstract": "Understanding and mitigating hallucinations in Large Language Models (LLMs) is crucial for ensuring reliable content generation. While previous research has primarily focused on \"when\" LLMs hallucinate, our work explains \"why\" and directly links model behaviour to the pre-training data that forms their prior knowledge. Specifically, we demonstrate that an asymmetry exists in the recognition of logically equivalent facts, which can be attributed to frequency discrepancies of entities appearing as subjects versus objects. Given that most pre-training datasets are inaccessible, we leverage the fully open-source OLMo series by indexing its Dolma dataset to estimate entity frequencies. Using relational facts (represented as triples) from Wikidata5M, we construct probing datasets to isolate this effect. Our experiments reveal that facts with a high-frequency subject and a low-frequency object are better recognised than their inverse, despite their logical equivalence. The pattern reverses in low-to-high frequency settings, and no statistically significant asymmetry emerges when both entities are high-frequency. These findings highlight the influential role of pre-training data in shaping model predictions and provide insights for inferring the characteristics of pre-training data in closed or partially closed LLMs.",
      "authors": [
        "Yuan He",
        "Bailan He",
        "Zifeng Ding",
        "Alisia Lupidi",
        "Yuqicheng Zhu",
        "Shuo Chen",
        "Caiqi Zhang",
        "Jiaoyan Chen",
        "Yunpu Ma",
        "Volker Tresp",
        "Ian Horrocks"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T12:12:38+00:00",
          "link": "https://arxiv.org/abs/2503.22362v1",
          "size": "1079kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T19:55:27+00:00",
          "link": "https://arxiv.org/abs/2503.22362v2",
          "size": "214kb",
          "version": "v2"
        }
      ],
      "title": "Supposedly Equivalent Facts That Aren't? Entity Frequency in Pre-training Induces Asymmetry in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22362",
        "HTML": "https://arxiv.org/html/2503.22362v2",
        "PDF": "https://arxiv.org/pdf/2503.22362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper directly investigates how LLM pre-training data frequency influences hallucination behavior, using detailed analyses of dataset characteristics and frequency effects."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/KRR-Oxford/FactProbe"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23502",
      "abstract": "Driven by large-scale contrastive vision-language pre-trained models such as CLIP, recent advancements in the image-text matching task have achieved remarkable success in representation learning. Due to image-level visual-language alignment, CLIP falls short in understanding fine-grained details such as object attributes and spatial relationships between objects. Recent efforts have attempted to compel CLIP to acquire structured visual representations by introducing prompt learning to achieve object-level alignment. While achieving promising results, they still lack the capability to perceive actions, which are crucial for describing the states or relationships between objects. Therefore, we propose to endow CLIP with fine-grained action-level understanding by introducing an LLM-enhanced action-aware multi-modal prompt-tuning method, incorporating the action-related external knowledge generated by large language models (LLMs). Specifically, we design an action triplet prompt and an action state prompt to exploit compositional semantic knowledge and state-related causal knowledge implicitly stored in LLMs. Subsequently, we propose an adaptive interaction module to aggregate attentive visual features conditioned on action-aware prompted knowledge for establishing discriminative and action-aware visual representations, which further improves the performance. Comprehensive experimental results on two benchmark datasets demonstrate the effectiveness of our method.",
      "authors": [
        "Mengxiao Tian",
        "Xinxiao Wu",
        "Shuo Yang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:49:08+00:00",
          "link": "https://arxiv.org/abs/2506.23502v1",
          "size": "1855kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T09:48:32+00:00",
          "link": "https://arxiv.org/abs/2506.23502v2",
          "size": "5115kb",
          "version": "v2"
        }
      ],
      "title": "LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23502",
        "HTML": "https://arxiv.org/html/2506.23502v2",
        "PDF": "https://arxiv.org/pdf/2506.23502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs to enhance CLIP models for image-text matching, but it primarily focuses on model architecture and evaluation rather than making substantive contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06272",
      "abstract": "While large multi-modal models (LMMs) demonstrate promising capabilities in segmentation and comprehension, they still struggle with two limitations: inaccurate segmentation and hallucinated comprehension. These challenges stem primarily from constraints in weak visual comprehension and a lack of fine-grained perception. To alleviate these limitations, we propose LIRA, a framework that capitalizes on the complementary relationship between visual comprehension and segmentation via two key components: (1) Semantic-Enhanced Feature Extractor (SEFE) improves object attribute inference by fusing semantic and pixel-level features, leading to more accurate segmentation; (2) Interleaved Local Visual Coupling (ILVC) autoregressively generates local descriptions after extracting local features based on segmentation masks, offering fine-grained supervision to mitigate hallucinations. Furthermore, we find that the precision of object segmentation is positively correlated with the latent related semantics of the <seg> token. To quantify this relationship and the model's potential semantic inferring ability, we introduce the Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA achieves state-of-the-art performance in both segmentation and comprehension tasks. Code will be available at https://github.com/echo840/LIRA.",
      "authors": [
        "Zhang Li",
        "Biao Yang",
        "Qiang Liu",
        "Shuo Zhang",
        "Zhiyin Ma",
        "Shuo Zhang",
        "Liang Yin",
        "Linger Deng",
        "Yabo Sun",
        "Yuliang Liu",
        "Xiang Bai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:46:26+00:00",
          "link": "https://arxiv.org/abs/2507.06272v1",
          "size": "6674kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:49:47+00:00",
          "link": "https://arxiv.org/abs/2507.06272v2",
          "size": "6674kb",
          "version": "v2"
        }
      ],
      "title": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06272",
        "HTML": "https://arxiv.org/html/2507.06272v2",
        "PDF": "https://arxiv.org/pdf/2507.06272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a segmentation framework for large multi-modal models, which involves semantic-enhanced feature extraction, but does not address LLM training data processing or any relevant data-engineering procedures."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07660",
      "abstract": "Traditional network analysis focuses on binary edges, while real-world relationships are more nuanced, encompassing cooperation, neutrality, and conflict. The rise of negative edges in social media discussions spurred interest in analyzing signed interactions, especially in polarized debates. However, the vast data generated by digital networks presents challenges for traditional methods like Stochastic Block Models (SBM) and Exponential Family Random Graph Models (ERGM), particularly due to the homogeneity assumption and global dependence, which become increasingly unrealistic as network size grows. To address this, we propose a novel method that combines the strengths of SBM and ERGM while mitigating their weaknesses by incorporating local dependence based on non-overlapping blocks. Our approach involves a two-step process: first, decomposing the network into sub-networks using SBM approximation, and then estimating parameters using ERGM methods. We validate our method on large synthetic networks and apply it to a signed Wikipedia network of thousands of editors. Through the use of local dependence, we find patterns consistent with structural balance theory.",
      "authors": [
        "Marc Schalberger",
        "Cornelius Fritz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:36:23+00:00",
          "link": "https://arxiv.org/abs/2507.07660v1",
          "size": "3069kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T16:55:36+00:00",
          "link": "https://arxiv.org/abs/2507.07660v2",
          "size": "3066kb",
          "version": "v2"
        }
      ],
      "title": "Scalable Signed Exponential Random Graph Models under Local Dependence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07660",
        "HTML": "https://arxiv.org/html/2507.07660v2",
        "PDF": "https://arxiv.org/pdf/2507.07660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses network analysis methods with local dependence for signed interactions in digital networks, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09630",
      "abstract": "Stroke is one of the leading causes of death globally, making early and accurate diagnosis essential for improving patient outcomes, particularly in emergency settings where timely intervention is critical. CT scans are the key imaging modality because of their speed, accessibility, and cost-effectiveness. This study proposed an artificial intelligence framework for multiclass stroke classification (ischemic, hemorrhagic, and no stroke) using CT scan images from a dataset provided by the Republic of Turkey's Ministry of Health. The proposed method adopted MaxViT, a state-of-the-art Vision Transformer, as the primary deep learning model for image-based stroke classification, with additional transformer variants (vision transformer, transformer-in-transformer, and ConvNext). To enhance model generalization and address class imbalance, we applied data augmentation techniques, including synthetic image generation. The MaxViT model trained with augmentation achieved the best performance, reaching an accuracy and F1-score of 98.00%, outperforming all other evaluated models and the baseline methods. The primary goal of this study was to distinguish between stroke types with high accuracy while addressing crucial issues of transparency and trust in artificial intelligence models. To achieve this, Explainable Artificial Intelligence (XAI) was integrated into the framework, particularly Grad-CAM++. It provides visual explanations of the model's decisions by highlighting relevant stroke regions in the CT scans and establishing an accurate, interpretable, and clinically applicable solution for early stroke detection. This research contributed to the development of a trustworthy AI-assisted diagnostic tool for stroke, facilitating its integration into clinical practice and enhancing access to timely and optimal stroke diagnosis in emergency departments, thereby saving more lives.",
      "authors": [
        "Shomukh Qari",
        "Maha A. Thafar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T13:50:50+00:00",
          "link": "https://arxiv.org/abs/2507.09630v1",
          "size": "3272kb",
          "version": "v1"
        }
      ],
      "title": "Brain Stroke Detection and Classification Using CT Imaging with Transformer Models and Explainable AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09630",
        "PDF": "https://arxiv.org/pdf/2507.09630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a framework for stroke classification using CT imaging and explainable AI, with transformer models and data augmentation techniques, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10424",
      "abstract": "Decoders for Low Density Parity Check (LDPC) codes are usually tailored to an application and optimized once the specific content and structure of the parity matrix are known. In this work we consider the parity matrix as an argument of the Min-Sum decoder, and provide a GPU implementation that is independent of the content of the parity matrix, and relies only on its dimensions.",
      "authors": [
        "Omer Shimon Sella",
        "Thomas Heinis"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:10:10+00:00",
          "link": "https://arxiv.org/abs/2507.10424v1",
          "size": "2310kb",
          "version": "v1"
        }
      ],
      "title": "A mapping of the Min-Sum decoder to reduction operations, and its implementation using CUDA kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10424",
        "HTML": "https://arxiv.org/html/2507.10424v1",
        "PDF": "https://arxiv.org/pdf/2507.10424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an implementation of a Min-Sum decoder for LDPC codes using CUDA kernels, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2211.14620",
      "abstract": "The syntactic structure of a sentence can be represented as a graph, where vertices are words and edges indicate syntactic dependencies between them. In this setting, the distance between two linked words is defined as the difference between their positions. Here we wish to contribute to the characterization of the actual distribution of syntactic dependency distances, which has previously been argued to follow a power-law distribution. Here we propose a new model with two exponential regimes in which the probability decay is allowed to change after a break-point. This transition could mirror the transition from the processing of word chunks to higher-level structures. We find that a two-regime model - where the first regime follows either an exponential or a power-law decay - is the most likely one in all 20 languages we considered, independently of sentence length and annotation style. Moreover, the break-point exhibits low variation across languages and averages values of 4-5 words, suggesting that the amount of words that can be simultaneously processed abstracts from the specific language to a high degree. The probability decay slows down after the breakpoint, consistently with a universal chunk-and-pass mechanism. Finally, we give an account of the relation between the best estimated model and the closeness of syntactic dependencies as function of sentence length, according to a recently introduced optimality score.",
      "authors": [
        "Sonia Petrini and Ramon Ferrer-i-Cancho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-26T17:31:25+00:00",
          "link": "https://arxiv.org/abs/2211.14620v1",
          "size": "3136kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T15:08:46+00:00",
          "link": "https://arxiv.org/abs/2211.14620v2",
          "size": "628kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T12:58:37+00:00",
          "link": "https://arxiv.org/abs/2211.14620v3",
          "size": "641kb",
          "version": "v3"
        }
      ],
      "title": "The distribution of syntactic dependency distances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.14620",
        "HTML": "https://arxiv.org/html/2211.14620v3",
        "PDF": "https://arxiv.org/pdf/2211.14620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses syntactic dependency distances and modeling their distribution, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Sentence"
      ],
      "repo_urls": [
        "https://github.com/soniapetrini/distributionofdependencydistances"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.11168",
      "abstract": "Large Language Models (LLMs) guardrail systems are designed to protect against prompt injection and jailbreak attacks. However, they remain vulnerable to evasion techniques. We demonstrate two approaches for bypassing LLM prompt injection and jailbreak detection systems via traditional character injection methods and algorithmic Adversarial Machine Learning (AML) evasion techniques. Through testing against six prominent protection systems, including Microsoft's Azure Prompt Shield and Meta's Prompt Guard, we show that both methods can be used to evade detection while maintaining adversarial utility achieving in some instances up to 100% evasion success. Furthermore, we demonstrate that adversaries can enhance Attack Success Rates (ASR) against black-box targets by leveraging word importance ranking computed by offline white-box models. Our findings reveal vulnerabilities within current LLM protection mechanisms and highlight the need for more robust guardrail systems.",
      "authors": [
        "William Hackett",
        "Lewis Birch",
        "Stefan Trawicki",
        "Neeraj Suri",
        "Peter Garraghan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T13:16:02+00:00",
          "link": "https://arxiv.org/abs/2504.11168v1",
          "size": "1913kb",
          "version": "v1"
        },
        {
          "date": "2025-04-16T15:33:06+00:00",
          "link": "https://arxiv.org/abs/2504.11168v2",
          "size": "386kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T15:27:11+00:00",
          "link": "https://arxiv.org/abs/2504.11168v3",
          "size": "378kb",
          "version": "v3"
        }
      ],
      "title": "Bypassing LLM Guardrails: An Empirical Analysis of Evasion Attacks against Prompt Injection and Jailbreak Detection Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11168",
        "HTML": "https://arxiv.org/html/2504.11168v3",
        "PDF": "https://arxiv.org/pdf/2504.11168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes security vulnerabilities in LLM guardrail systems, focusing on evasion attacks rather than data processing for training LLMs."
      },
      "datasets": [
        {
          "dataset_name": "Mindgard/evaded-prompt-injection-and-jailbreak-samples",
          "downloads": "61",
          "likes": "4",
          "link": "https://huggingface.co/datasets/Mindgard/evaded-prompt-injection-and-jailbreak-samples"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.21018",
      "abstract": "Many pre-trained language models (PLMs) exhibit suboptimal performance on mid- and low-resource languages, largely due to limited exposure to these languages during pre-training. A common strategy to address this is to introduce new tokens specific to the target languages, initialize their embeddings, and apply continual pre-training on target-language data. Among such methods, OFA (Liu et al., 2024a) proposes a similarity-based subword embedding initialization heuristic that is both effective and efficient. However, OFA restricts target-language token embeddings to be convex combinations of a fixed number of source-language embeddings, which may limit expressiveness. To overcome this limitation, we propose HYPEROFA, a hypernetwork-based approach for more adaptive token embedding initialization. The hypernetwork is trained to map from an external multilingual word vector space to the PLMs token embedding space using source-language tokens. Once trained, it can generate flexible embeddings for target-language tokens, serving as a good starting point for continual pretraining. Experiments demonstrate that HYPEROFA consistently outperforms random initialization baseline and matches or exceeds the performance of OFA in both continual pre-training convergence and downstream task performance. We make the code publicly available.",
      "authors": [
        "Enes \\\"Ozeren",
        "Yihong Liu",
        "Hinrich Sch\\\"utze"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T19:40:32+00:00",
          "link": "https://arxiv.org/abs/2504.21018v1",
          "size": "431kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T23:05:26+00:00",
          "link": "https://arxiv.org/abs/2504.21018v2",
          "size": "192kb",
          "version": "v2"
        }
      ],
      "title": "HYPEROFA: Expanding LLM Vocabulary to New Languages via Hypernetwork-Based Embedding Initialization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21018",
        "HTML": "https://arxiv.org/html/2504.21018v2",
        "PDF": "https://arxiv.org/pdf/2504.21018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper addresses token embedding initialization for new languages in LLMs, its main focus is on model architecture improvement rather than data processing or training dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.14403",
      "abstract": "Recent advances in reasoning language models have witnessed a paradigm shift from short to long CoT pattern. Given the substantial computational cost of rollouts in long CoT models, maximizing the utility of fixed training datasets becomes crucial. Our analysis reveals that negative responses contain valuable components such as self-reflection and error-correction steps, yet primary existing methods either completely discard negative samples (RFT) or apply equal penalization across all tokens (RL), failing to leverage these potential learning signals. In light of this, we propose Behavior Constrained Policy Gradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline RL framework that encompasses three stages: 1) sample segmentation, 2) consensus-based step correctness assessment combining LLM and PRM judgers, and 3) policy optimization with NSA designed to effectively mine positive steps within negative samples. Experimental results show that BCPG-NSA outperforms baselines on several challenging math/coding reasoning benchmarks using the same training dataset, achieving improved sample efficiency and demonstrating robustness and scalability when extended to multiple iterations.",
      "authors": [
        "Zhaohui Yang",
        "Yuxiao Ye",
        "Shilei Jiang",
        "Chen Hu",
        "Linjing Li",
        "Shihong Deng",
        "Daxin Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T14:16:49+00:00",
          "link": "https://arxiv.org/abs/2505.14403v1",
          "size": "1478kb",
          "version": "v1"
        },
        {
          "date": "2025-05-23T08:47:26+00:00",
          "link": "https://arxiv.org/abs/2505.14403v2",
          "size": "1478kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T11:21:20+00:00",
          "link": "https://arxiv.org/abs/2505.14403v3",
          "size": "677kb",
          "version": "v3"
        }
      ],
      "title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14403",
        "HTML": "https://arxiv.org/html/2505.14403v3",
        "PDF": "https://arxiv.org/pdf/2505.14403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on policy optimization in reasoning tasks and leveraging negative samples from fixed datasets for RL improvements, not on processing LLM training data."
      },
      "tasks": [
        "Math",
        "Offline RL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09124",
      "abstract": "The vision of AI-RAN convergence, as advocated by the AI-RAN Alliance, aims to unlock a unified 6G platform capable of seamlessly supporting AI and RAN workloads over shared infrastructure. However, the architectural framework and intelligent resource orchestration strategies necessary to realize this vision remain largely unexplored. In this paper, we propose a Converged AI-and-ORAN Architectural (CAORA) framework based on O-RAN specifications, enabling the dynamic coexistence of real-time RAN and computationally intensive AI workloads. We design custom xApps within the Near-Real-Time RAN Intelligent Controller (NRT-RIC) to monitor RAN KPIs and expose radio analytics to an End-to-End (E2E) orchestrator via the recently introduced Y1 interface. The orchestrator incorporates workload forecasting and anomaly detection modules, augmenting a Soft Actor-Critic (SAC) reinforcement learning agent that proactively manages resource allocation, including Multi-Instance GPU (MIG) partitioning. Using real-world 5G traffic traces from Barcelona, our trace-driven simulations demonstrate that CAORA achieves near 99\\% fulfillment of RAN demands, supports dynamic AI workloads, and maximizes infrastructure utilization even under highly dynamic conditions. Our results reveal that predictive orchestration significantly improves system adaptability, resource efficiency, and service continuity, offering a viable blueprint for future AI-and-RAN converged 6G systems.",
      "authors": [
        "Syed Danial Ali Shah",
        "Maryam Hafeez",
        "Abdelaziz Salama",
        "Syed Ali Raza Zaidi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:58:09+00:00",
          "link": "https://arxiv.org/abs/2507.09124v1",
          "size": "2494kb",
          "version": "v1"
        }
      ],
      "title": "Proactive AI-and-RAN Workload Orchestration in O-RAN Architectures for 6G Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09124",
        "PDF": "https://arxiv.org/pdf/2507.09124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI-and-RAN workload orchestration for 6G networks, discussing resource allocation and infrastructure utilization rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09212",
      "abstract": "Iterative generative models, like diffusion and flow-matching, create high-fidelity samples by progressively refining a noise vector into data. However, this process is notoriously slow, often requiring hundreds of function evaluations. We introduce the warm-start model, a simple, deterministic model that dramatically accelerates conditional generation by providing a better starting point. Instead of starting generation from an uninformed N(0, I) prior, our warm-start model predicts an informed prior N(mu, sigma), whose moments are conditioned on the input context. This \"warm start\" substantially reduces the distance the generative process must traverse, particularly when the conditioning information is strongly informative. On tasks like image inpainting, our method achieves results competitive with a 1000-step DDPM baseline using only 11 total function evaluations (1 for the warm start, 10 for generation). A simple conditional normalization trick makes our method compatible with any standard generative model and sampler without modification, allowing it to be combined with other efficient sampling techniques for further acceleration. Our implementation is available at https://github.com/jonas-scholz123/warm-start-model.",
      "authors": [
        "Jonas Scholz",
        "Richard E. Turner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:07:05+00:00",
          "link": "https://arxiv.org/abs/2507.09212v1",
          "size": "5679kb",
          "version": "v1"
        }
      ],
      "title": "Warm Starts Accelerate Generative Modelling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09212",
        "PDF": "https://arxiv.org/pdf/2507.09212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the concept of 'warm starts' for generative modeling, which relates to model starting points rather than the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09471",
      "abstract": "Continual Learning (CL) empowers AI models to continuously learn from sequential task streams. Recently, parameter-efficient fine-tuning (PEFT)-based CL methods have garnered increasing attention due to their superior performance. They typically allocate a unique sub-module for learning each task, with a task recognizer to select the appropriate sub-modules for testing images. However, due to the feature subspace misalignment from independently trained sub-modules, these methods tend to produce ambiguous decisions under misleading task-ids. To address this, we propose Cross-subspace Knowledge Alignment and Aggregation (CKAA), a novel framework that enhances model robustness against misleading task-ids through two key innovations: (1) Dual-level Knowledge Alignment (DKA): By aligning intra-class feature distributions across different subspaces and learning a robust global classifier through a feature simulation process, DKA enables the model to distinguish features from both correct and incorrect subspaces during training. (2) Task-Confidence-guided Mixture of Adapters (TC-MoA): A robust inference scheme that adaptively aggregates task-specific knowledge from relevant sub-modules based on task-confidence scores, avoiding overconfidence in misleading task-id predictions. Extensive experiments demonstrate that CKAA outperforms existing PEFT-based CL methods.",
      "authors": [
        "Lingfeng He",
        "De Cheng",
        "Zhiheng Ma",
        "Huaijie Wang",
        "Dingwen Zhang",
        "Nannan Wang",
        "Xinbo Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:11:35+00:00",
          "link": "https://arxiv.org/abs/2507.09471v1",
          "size": "1965kb",
          "version": "v1"
        }
      ],
      "title": "CKAA: Cross-subspace Knowledge Alignment and Aggregation for Robust Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09471",
        "HTML": "https://arxiv.org/html/2507.09471v1",
        "PDF": "https://arxiv.org/pdf/2507.09471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a novel framework for continual learning focusing on model robustness and knowledge alignment. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09595",
      "abstract": "FLUX.1 is a diffusion-based text-to-image generation model developed by Black Forest Labs, designed to achieve faithful text-image alignment while maintaining high image quality and diversity. FLUX is considered state-of-the-art in text-to-image generation, outperforming popular models such as Midjourney, DALL-E 3, Stable Diffusion 3 (SD3), and SDXL. Although publicly available as open source, the authors have not released official technical documentation detailing the model's architecture or training setup. This report summarizes an extensive reverse-engineering effort aimed at demystifying FLUX's architecture directly from its source code, to support its adoption as a backbone for future research and development. This document is an unofficial technical report and is not published or endorsed by the original developers or their affiliated institutions.",
      "authors": [
        "Or Greenberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.09595v1",
          "size": "6618kb",
          "version": "v1"
        }
      ],
      "title": "Demystifying Flux Architecture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09595",
        "HTML": "https://arxiv.org/html/2507.09595v1",
        "PDF": "https://arxiv.org/pdf/2507.09595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about reverse engineering the architecture of a text-to-image model. It does not address LLM training data processing or involve creating new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10382",
      "abstract": "With the rise of smart mobility and shared e-mobility services, numerous advanced technologies have been applied to this field. Cloud-based traffic simulation solutions have flourished, offering increasingly realistic representations of the evolving mobility landscape. LLMs have emerged as pioneering tools, providing robust support for various applications, including intelligent decision-making, user interaction, and real-time traffic analysis. As user demand for e-mobility continues to grow, delivering comprehensive end-to-end solutions has become crucial. In this paper, we present a cloud-based, LLM-powered shared e-mobility platform, integrated with a mobile application for personalized route recommendations. The optimization module is evaluated based on travel time and cost across different traffic scenarios. Additionally, the LLM-powered RAG framework is evaluated at the schema level for different users, using various evaluation methods. Schema-level RAG with XiYanSQL achieves an average execution accuracy of 0.81 on system operator queries and 0.98 on user queries.",
      "authors": [
        "Yue Ding",
        "Conor McCarthy",
        "Kevin O'Shea and Mingming Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:23:11+00:00",
          "link": "https://arxiv.org/abs/2507.10382v1",
          "size": "3868kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging RAG-LLMs for Urban Mobility Simulation and Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10382",
        "HTML": "https://arxiv.org/html/2507.10382v1",
        "PDF": "https://arxiv.org/pdf/2507.10382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an LLM-powered mobility platform but focuses on simulation and analysis for urban mobility without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02620",
      "abstract": "Distributed inference serves as a promising approach to enabling the inference of large language models (LLMs) at the network edge. It distributes the inference process to multiple devices to ensure that the LLMs can fit into the device memory. Recent pipeline-based approaches have the potential to parallelize communication and computation, which helps reduce inference latency. However, the benefit diminishes when the inference request at the network edge is sparse, where pipeline is typically at low utilization. To enable efficient distributed LLM inference at the edge, we propose \\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding framework. FlowSpec incorporates three key mechanisms to improve decoding efficiency: 1) score-based step-wise verification prioritizes more important draft tokens to bring earlier accpeted tokens; 2) efficient draft management to prune invalid tokens while maintaining correct causal relationship during verification; 3) dynamic draft expansion strategies to supply high-quality speculative inputs. These techniques work in concert to enhance both pipeline utilization and speculative efficiency. We evaluate FlowSpec on a real-world testbed with other baselines. Experimental results demonstrate that our proposed framework significantly improves inference speed across diverse models and configurations, achieving speedup ratios 1.28$\\times$-1.79$\\times$ compared to baselines. Our code is publicly available at \\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\\#}",
      "authors": [
        "Xing Liu",
        "Lizhuo Luo",
        "Ming Tang",
        "Chao Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:47:42+00:00",
          "link": "https://arxiv.org/abs/2507.02620v1",
          "size": "1105kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:55:53+00:00",
          "link": "https://arxiv.org/abs/2507.02620v2",
          "size": "1106kb",
          "version": "v2"
        }
      ],
      "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02620",
        "HTML": "https://arxiv.org/html/2507.02620v2",
        "PDF": "https://arxiv.org/pdf/2507.02620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on distributed inference and decoding efficiency of LLMs rather than on processing or creating training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05285",
      "abstract": "Student dropout in distance learning remains a critical challenge, with profound societal and economic consequences. While classical machine learning models leverage structured socio-demographic and behavioral data, they often fail to capture the nuanced emotional and contextual factors embedded in unstructured student interactions. This paper introduces a transformative AI framework that redefines dropout prediction through three synergistic innovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment analysis, prompt engineering to decode academic stressors,and cross-modal attention fusion to dynamically align textual, behavioral, and socio-demographic insights. By grounding sentiment analysis in a curated knowledge base of pedagogical content, our RAG-enhanced BERT model interprets student comments with unprecedented contextual relevance, while optimized prompts isolate indicators of academic distress (e.g., \"isolation,\" \"workload anxiety\"). A cross-modal attention layer then fuses these insights with temporal engagement patterns, creating holistic risk pro-files. Evaluated on a longitudinal dataset of 4 423 students, the framework achieves 89% accuracy and an F1-score of 0.88, outperforming conventional models by 7% and reducing false negatives by 21%. Beyond prediction, the system generates interpretable interventions by retrieving contextually aligned strategies (e.g., mentorship programs for isolated learners). This work bridges the gap between predictive analytics and actionable pedagogy, offering a scalable solution to mitigate dropout risks in global education systems",
      "authors": [
        "Miloud Mihoubi",
        "Meriem Zerkouk",
        "Belkacem Chikhaoui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T21:41:43+00:00",
          "link": "https://arxiv.org/abs/2507.05285v1",
          "size": "1985kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:49:02+00:00",
          "link": "https://arxiv.org/abs/2507.05285v2",
          "size": "1986kb",
          "version": "v2"
        }
      ],
      "title": "Beyond classical and contemporary models: a transformative AI framework for student dropout prediction in distance learning using RAG, Prompt engineering, and Cross-modal fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05285",
        "HTML": "https://arxiv.org/html/2507.05285v2",
        "PDF": "https://arxiv.org/pdf/2507.05285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses a multisensory approach for dropout prediction, it doesn't focus primarily on LLM training data processing. It mainly concerns model application on a structured and curated dataset."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09432",
      "abstract": "Understanding how key physical parameters influence burning plasma behavior is critical for the reliable operation of ITER. In this work, we extend NeuralPlasmaODE, a multi-region, multi-timescale model based on neural ordinary differential equations, to perform a sensitivity analysis of transport and radiation mechanisms in ITER plasmas. Normalized sensitivities of core and edge temperatures and densities are computed with respect to transport diffusivities, electron cyclotron radiation (ECR) parameters, impurity fractions, and ion orbit loss (IOL) timescales. The analysis focuses on perturbations around a trained nominal model for the ITER inductive scenario. Results highlight the dominant influence of magnetic field strength, safety factor, and impurity content on energy confinement, while also revealing how temperature-dependent transport contributes to self-regulating behavior. These findings demonstrate the utility of NeuralPlasmaODE for predictive modeling and scenario optimization in burning plasma environments.",
      "authors": [
        "Zefang Liu",
        "Weston M. Stacey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Plasma Physics (physics.plasm-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T00:00:47+00:00",
          "link": "https://arxiv.org/abs/2507.09432v1",
          "size": "725kb",
          "version": "v1"
        }
      ],
      "title": "Sensitivity Analysis of Transport and Radiation in NeuralPlasmaODE for ITER Burning Plasmas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09432",
        "HTML": "https://arxiv.org/html/2507.09432v1",
        "PDF": "https://arxiv.org/pdf/2507.09432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on sensitivity analysis in ITER plasma scenarios using NeuralPlasmaODE, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09503",
      "abstract": "This paper proposes a neural stochastic optimization method for efficiently solving the two-stage stochastic unit commitment (2S-SUC) problem under high-dimensional uncertainty scenarios. The proposed method approximates the second-stage recourse problem using a deep neural network trained to map commitment decisions and uncertainty features to recourse costs. The trained network is subsequently embedded into the first-stage UC problem as a mixed-integer linear program (MILP), allowing for explicit enforcement of operational constraints while preserving the key uncertainty characteristics. A scenario-embedding network is employed to enable dimensionality reduction and feature aggregation across arbitrary scenario sets, serving as a data-driven scenario reduction mechanism. Numerical experiments on IEEE 5-bus, 30-bus, and 118-bus systems demonstrate that the proposed neural two-stage stochastic optimization method achieves solutions with an optimality gap of less than 1%, while enabling orders-of-magnitude speedup compared to conventional MILP solvers and decomposition-based methods. Moreover, the model's size remains constant regardless of the number of scenarios, offering significant scalability for large-scale stochastic unit commitment problems.",
      "authors": [
        "Zhentong Shao and Jingtao Qin and Nanpeng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:55:25+00:00",
          "link": "https://arxiv.org/abs/2507.09503v1",
          "size": "173kb",
          "version": "v1"
        }
      ],
      "title": "Neural Two-Stage Stochastic Optimization for Solving Unit Commitment Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09503",
        "HTML": "https://arxiv.org/html/2507.09503v1",
        "PDF": "https://arxiv.org/pdf/2507.09503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a stochastic optimization method to solve a unit commitment problem. There is no mention of LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09531",
      "abstract": "Key Information Extraction (KIE) underpins the understanding of visual documents (e.g., receipts and contracts) by extracting precise semantic content and accurately capturing spatial structure. Yet existing multimodal large language models (MLLMs) often perform poorly on dense documents and rely on vision tokenization approaches that scale with image size, leading to redundant computation and memory inefficiency. To address these challenges, we introduce VDInstruct, an MLLM that separates spatial region detection from semantic feature extraction. Central to our model is a content-aware tokenization strategy: rather than fragmenting the entire image uniformly, it generates tokens in proportion to document complexity, preserving critical structure while eliminating wasted tokens. Leveraging a three-stage training paradigm, our model achieves state-of-the-art (SOTA) results on KIE benchmarks, matching or exceeding the accuracy of leading approaches while reducing the number of image tokens by roughly 3.6x. In zero-shot evaluations, VDInstruct surpasses strong baselines-such as DocOwl 1.5-by +5.5 F1 points, highlighting its robustness to unseen documents. These findings show that content-aware tokenization combined with explicit layout modeling offers a promising direction forward for document understanding. Data, source code, and model weights will be made publicly available.",
      "authors": [
        "Son Nguyen",
        "Giang Nguyen",
        "Hung Dao",
        "Thao Do",
        "Daeyoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:15:11+00:00",
          "link": "https://arxiv.org/abs/2507.09531v1",
          "size": "2627kb",
          "version": "v1"
        }
      ],
      "title": "VDInstruct: Zero-Shot Key Information Extraction via Content-Aware Vision Tokenization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09531",
        "HTML": "https://arxiv.org/html/2507.09531v1",
        "PDF": "https://arxiv.org/pdf/2507.09531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving key information extraction via vision tokenization. There is no mention of processing or creating training data specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09596",
      "abstract": "Good software has high cohesion and low coupling is clumsy, obscure, and in some certain cases could be actually a harmful state of being. It is clumsy because there is no perfect correlation between higher cohesiveness and optimum design, and it is obscure because it conveys the message that coupling and cohesion are two distinct design principles, while there are in principle the same design approaches, and only the time and space differ between them, and it could also be a harmful state of being because we should not always aim for higher cohesiveness without considering its cost.\n  In the course of this study, we aim to elucidate for the readers the meaning and underlying philosophy of the aforementioned paragraph.",
      "authors": [
        "Aydin Homay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:57:12+00:00",
          "link": "https://arxiv.org/abs/2507.09596v1",
          "size": "117kb",
          "version": "v1"
        }
      ],
      "title": "The Mythical Good Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09596",
        "HTML": "https://arxiv.org/html/2507.09596v1",
        "PDF": "https://arxiv.org/pdf/2507.09596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines software design principles like cohesion and coupling, with no relevant content on LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09620",
      "abstract": "We study vertex sparsification for preserving distances in planar graphs. Given an edge-weighted planar graph with $k$ terminals, the goal is to construct an emulator, which is a smaller edge-weighted planar graph that contains the terminals and exactly preserves the pairwise distances between them. We construct exact planar emulators of size $O(f^2k^2)$ in the setting where terminals lie on $f$ faces in the planar embedding of the input graph. Our result generalizes and interpolates between the previous results of Chang and Ophelders and Goranci, Henzinger, and Peng which is an $O(k^2)$ bound in the setting where all terminals lie on a single face (i.e., $f=1$), and the result of Krauthgamer, Nguyen, and Zondiner, which is an $O(k^4)$ bound for the general case (i.e., $f=k$).\n  Our construction follows a recent new way of analyzing graph structures, by viewing graphs as paths and their intersections, which we believe is of independent interest.",
      "authors": [
        "George Z. Li",
        "Zihan Tan",
        "Tianyi Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:58:55+00:00",
          "link": "https://arxiv.org/abs/2507.09620v1",
          "size": "5208kb",
          "version": "v1"
        }
      ],
      "title": "Paths and Intersections: Exact Emulators for Planar Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09620",
        "HTML": "https://arxiv.org/html/2507.09620v1",
        "PDF": "https://arxiv.org/pdf/2507.09620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about constructing exact planar emulators for preserving distances in planar graphs, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09761",
      "abstract": "We prove that many dynamical properties of group cellular automata (i.e., cellular automata defined on any finite group and with global rule which is an endomorphism), including surjectivity, injectivity, sensitivity to initial conditions, strong transitivity, positive expansivity, and topological entropy, can be decided by decomposing them into a set of much simpler group cellular automata. To be more specific, we provide a novel algorithmic technique allowing one to decompose the group cellular automaton to be studied into a finite number of group cellular automata, some of them defined on abelian groups, while others, if any, defined on products of simple non-abelian isomorphic groups.\n  It is worth noting that the groups resulting from the decomposition only depend on the original group and therefore they are completely independent of both the automaton and the property under investigation. As a result, they do not inherit any aspect of the complexity of the automaton under investigation.\n  We prove that the group cellular automata obtained by the decomposition preserve dynamical properties and turn out to be much easier to analyze if compared to the original cellular automaton. As a consequence of these results, we show that injectivity, surjectivity and sensitivity to initial conditions are decidable properties and that no strongly transitive, and therefore no positively expansive, group cellular automata defined on non-abelian groups exist. Moreover, we prove that the topological entropy of a group cellular automaton can be computed, provided we know how to compute the topological entropy for group cellular automata defined on products of simple non-abelian isomorphic groups and on abelian groups.",
      "authors": [
        "Niccolo' Castronuovo",
        "Alberto Dennunzio",
        "Luciano Margara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:39:47+00:00",
          "link": "https://arxiv.org/abs/2507.09761v1",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "title": "A Divide and Conquer Algorithm for Deciding Group Cellular Automata Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09761",
        "HTML": "https://arxiv.org/html/2507.09761v1",
        "PDF": "https://arxiv.org/pdf/2507.09761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on group cellular automata dynamics and computational properties, without discussing LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09836",
      "abstract": "Autonomous vehicles (AVs) are becoming increasingly popular, with their applications now extending beyond just a mode of transportation to serving as mobile actuators of a traffic flow to control flow dynamics. This contrasts with traditional fixed-location actuators, such as traffic signals, and is referred to as Lagrangian traffic control. However, designing effective Lagrangian traffic control policies for AVs that generalize across traffic scenarios introduces a major challenge. Real-world traffic environments are highly diverse, and developing policies that perform robustly across such diverse traffic scenarios is challenging. It is further compounded by the joint complexity of the multi-agent nature of traffic systems, mixed motives among participants, and conflicting optimization objectives subject to strict physical and external constraints. To address these challenges, we introduce Multi-Residual Mixture of Expert Learning (MRMEL), a novel framework for Lagrangian traffic control that augments a given suboptimal nominal policy with a learned residual while explicitly accounting for the structure of the traffic scenario space. In particular, taking inspiration from residual reinforcement learning, MRMEL augments a suboptimal nominal AV control policy by learning a residual correction, but at the same time dynamically selects the most suitable nominal policy from a pool of nominal policies conditioned on the traffic scenarios and modeled as a mixture of experts. We validate MRMEL using a case study in cooperative eco-driving at signalized intersections in Atlanta, Dallas Fort Worth, and Salt Lake City, with real-world data-driven traffic scenarios. The results show that MRMEL consistently yields superior performance-achieving an additional 4%-9% reduction in aggregate vehicle emissions relative to the strongest baseline in each setting.",
      "authors": [
        "Vindula Jayawardana",
        "Sirui Li",
        "Yashar Farid",
        "Cathy Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:17:12+00:00",
          "link": "https://arxiv.org/abs/2507.09836v1",
          "size": "8587kb",
          "version": "v1"
        }
      ],
      "title": "Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09836",
        "HTML": "https://arxiv.org/html/2507.09836v1",
        "PDF": "https://arxiv.org/pdf/2507.09836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on autonomous vehicle control using a novel learning framework and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09910",
      "abstract": "Graphic design visually conveys information and data by creating and combining text, images and graphics. Two-stage methods that rely primarily on layout generation lack creativity and intelligence, making graphic design still labor-intensive. Existing diffusion-based methods generate non-editable graphic design files at image level with poor legibility in visual text rendering, which prevents them from achieving satisfactory and practical automated graphic design. In this paper, we propose Instructional Graphic Designer (IGD) to swiftly generate multimodal layers with editable flexibility with only natural language instructions. IGD adopts a new paradigm that leverages parametric rendering and image asset generation. First, we develop a design platform and establish a standardized format for multi-scenario design files, thus laying the foundation for scaling up data. Second, IGD utilizes the multimodal understanding and reasoning capabilities of MLLM to accomplish attribute prediction, sequencing and layout of layers. It also employs a diffusion model to generate image content for assets. By enabling end-to-end training, IGD architecturally supports scalability and extensibility in complex graphic design tasks. The superior experimental results demonstrate that IGD offers a new solution for graphic design.",
      "authors": [
        "Yadong Qu",
        "Shancheng Fang",
        "Yuxin Wang",
        "Xiaorui Wang",
        "Zhineng Chen",
        "Hongtao Xie",
        "Yongdong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:31:15+00:00",
          "link": "https://arxiv.org/abs/2507.09910v1",
          "size": "6900kb",
          "version": "v1"
        }
      ],
      "title": "IGD: Instructional Graphic Design with Multimodal Layer Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09910",
        "HTML": "https://arxiv.org/html/2507.09910v1",
        "PDF": "https://arxiv.org/pdf/2507.09910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on creating a multimodal graphic design system and does not contribute to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10097",
      "abstract": "User behavior sequence modeling, which captures user interest from rich historical interactions, is pivotal for industrial recommendation systems. Despite breakthroughs in ranking-stage models capable of leveraging ultra-long behavior sequences with length scaling up to thousands, existing retrieval models remain constrained to sequences of hundreds of behaviors due to two main challenges. One is strict latency budget imposed by real-time service over large-scale candidate pool. The other is the absence of target-aware mechanisms and cross-interaction architectures, which prevent utilizing ranking-like techniques to simplify long sequence modeling. To address these limitations, we propose a new framework named User Long-term Multi-Interest Retrieval Model(ULIM), which enables thousand-scale behavior modeling in retrieval stages. ULIM includes two novel components: 1)Category-Aware Hierarchical Dual-Interest Learning partitions long behavior sequences into multiple category-aware subsequences representing multi-interest and jointly optimizes long-term and short-term interests within specific interest cluster. 2)Pointer-Enhanced Cascaded Category-to-Item Retrieval introduces Pointer-Generator Interest Network(PGIN) for next-category prediction, followed by next-item retrieval upon the top-K predicted categories. Comprehensive experiments on Taobao dataset show that ULIM achieves substantial improvement over state-of-the-art methods, and brings 5.54% clicks, 11.01% orders and 4.03% GMV lift for Taobaomiaosha, a notable mini-app of Taobao.",
      "authors": [
        "Yue Meng",
        "Cheng Guo",
        "Xiaohui Hu",
        "Honghu Deng",
        "Yi Cao",
        "Tong Liu",
        "Bo Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:32:26+00:00",
          "link": "https://arxiv.org/abs/2507.10097v1",
          "size": "217kb",
          "version": "v1"
        }
      ],
      "title": "User Long-Term Multi-Interest Retrieval Model for Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10097",
        "HTML": "https://arxiv.org/html/2507.10097v1",
        "PDF": "https://arxiv.org/pdf/2507.10097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on user behavior sequence modeling for recommendation systems, with no emphasis on LLM training data processing or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10133",
      "abstract": "In this paper, we introduce a new defeasible version of propositional standpoint logic by integrating Kraus et al.'s defeasible conditionals, Britz and Varzinczak's notions of defeasible necessity and distinct possibility, along with Leisegang et al.'s approach to defeasibility into the standpoint logics of G\\'omez \\'Alvarez and Rudolph. The resulting logical framework allows for the expression of defeasibility on the level of implications, standpoint modal operators, and standpoint-sharpening statements. We provide a preferential semantics for this extended language and propose a tableaux calculus, which is shown to be sound and complete with respect to preferential entailment. We also establish the computational complexity of the tableaux procedure to be in PSpace.",
      "authors": [
        "Nicholas Leisegang and Thomas Meyer and Ivan Varzinczak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:23:49+00:00",
          "link": "https://arxiv.org/abs/2507.10133v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Extending Defeasibility for Propositional Standpoint Logics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10133",
        "HTML": "https://arxiv.org/html/2507.10133v1",
        "PDF": "https://arxiv.org/pdf/2507.10133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an extension to propositional standpoint logics, focusing on defeasibility logic, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10293",
      "abstract": "Face Video Restoration (FVR) aims to recover high-quality face videos from degraded versions. Traditional methods struggle to preserve fine-grained, identity-specific features when degradation is severe, often producing average-looking faces that lack individual characteristics. To address these challenges, we introduce IP-FVR, a novel method that leverages a high-quality reference face image as a visual prompt to provide identity conditioning during the denoising process. IP-FVR incorporates semantically rich identity information from the reference image using decoupled cross-attention mechanisms, ensuring detailed and identity consistent results. For intra-clip identity drift (within 24 frames), we introduce an identity-preserving feedback learning method that combines cosine similarity-based reward signals with suffix-weighted temporal aggregation. This approach effectively minimizes drift within sequences of frames. For inter-clip identity drift, we develop an exponential blending strategy that aligns identities across clips by iteratively blending frames from previous clips during the denoising process. This method ensures consistent identity representation across different clips. Additionally, we enhance the restoration process with a multi-stream negative prompt, guiding the model's attention to relevant facial attributes and minimizing the generation of low-quality or incorrect features. Extensive experiments on both synthetic and real-world datasets demonstrate that IP-FVR outperforms existing methods in both quality and identity preservation, showcasing its substantial potential for practical applications in face video restoration.",
      "authors": [
        "Wenkang Han",
        "Wang Lin",
        "Yiyun Zhou",
        "Qi Liu",
        "Shulei Wang",
        "Chang Yao",
        "Jingyuan Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:01:37+00:00",
          "link": "https://arxiv.org/abs/2507.10293v1",
          "size": "10689kb",
          "version": "v1"
        }
      ],
      "title": "Show and Polish: Reference-Guided Identity Preservation in Face Video Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10293",
        "HTML": "https://arxiv.org/html/2507.10293v1",
        "PDF": "https://arxiv.org/pdf/2507.10293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on face video restoration techniques using identity-preserving feedback learning and blending strategies, which do not touch upon LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10392",
      "abstract": "Large language models (LLMs) require vast amounts of GPU compute to train, but limited availability and high costs of GPUs make homogeneous clusters impractical for many organizations. Instead, assembling heterogeneous clusters by pooling together GPUs of different generations allows them to achieve higher aggregate compute and make use of all available GPUs. However, training on heterogeneous clusters presents several challenges, including load balancing across GPUs, optimizing memory usage to accommodate varying memory capacities, and ensuring communication-efficient training over diverse network interconnects potentially spanning multiple datacenters. In this paper, we make the case that efficient training on heterogeneous clusters requires (1) the integration of pipeline parallelism and data parallelism in a manner that is both communication- and memory-efficient, and (2) a more adaptable configuration of pipeline and data parallelism, which includes the capability to flexibly partition GPUs into asymmetric pipeline parallel stages and to incorporate heterogeneous GPUs within the same data parallelism group. We propose Zorse, the first system to unify all these capabilities while incorporating a planner that automatically configures training strategies for a given workload. Our evaluation shows that Zorse significantly outperforms state-of-the-art systems in heterogeneous training scenarios.",
      "authors": [
        "Runsheng Benson Guo",
        "Utkarsh Anand",
        "Khuzaima Daudjee",
        "Rathijit Sen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:31:31+00:00",
          "link": "https://arxiv.org/abs/2507.10392v1",
          "size": "389kb",
          "version": "v1"
        }
      ],
      "title": "Zorse: Optimizing LLM Training Efficiency on Heterogeneous GPU Clusters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10392",
        "PDF": "https://arxiv.org/pdf/2507.10392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimizing LLM training efficiency on heterogeneous GPU clusters, focusing on system efficiency rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.11406",
      "abstract": "Despite recent advances in video action recognition achieving strong performance on existing benchmarks, these models often lack robustness when faced with natural distribution shifts between training and test data. We propose two novel evaluation methods to assess model resilience to such distribution disparity. One method uses two different datasets collected from different sources and uses one for training and validation, and the other for testing. More precisely, we created dataset splits of HMDB-51 or UCF-101 for training, and Kinetics-400 for testing, using the subset of the classes that are overlapping in both train and test datasets. The other proposed method extracts the feature mean of each class from the target evaluation dataset's training data (i.e. class prototype) and estimates test video prediction as a cosine similarity score between each sample to the class prototypes of each target class. This procedure does not alter model weights using the target dataset and it does not require aligning overlapping classes of two different datasets, thus is a very efficient method to test the model robustness to distribution shifts without prior knowledge of the target distribution. We address the robustness problem by adversarial augmentation training - generating augmented views of videos that are \"hard\" for the classification model by applying gradient ascent on the augmentation parameters - as well as \"curriculum\" scheduling the strength of the video augmentations. We experimentally demonstrate the superior performance of the proposed adversarial augmentation approach over baselines across three state-of-the-art action recognition models - TSM, Video Swin Transformer, and Uniformer. The presented work provides critical insight into model robustness to distribution shifts and presents effective techniques to enhance video action recognition performance in a real-world deployment.",
      "authors": [
        "Kiyoon Kim",
        "Shreyank N Gowda",
        "Panagiotis Eustratiadis",
        "Antreas Antoniou",
        "Robert B Fisher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-21T05:50:39+00:00",
          "link": "https://arxiv.org/abs/2401.11406v1",
          "size": "8778kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T04:19:47+00:00",
          "link": "https://arxiv.org/abs/2401.11406v2",
          "size": "8771kb",
          "version": "v2"
        }
      ],
      "title": "Adversarial Augmentation Training Makes Action Recognition Models More Robust to Realistic Video Distribution Shifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.11406",
        "HTML": "https://arxiv.org/html/2401.11406v2",
        "PDF": "https://arxiv.org/pdf/2401.11406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on video action recognition model robustness and evaluation methods, rather than on the processing or creation of LLM training data."
      },
      "tasks": [
        "Action Recognition",
        "Scheduling",
        "Temporal Action Localization",
        "Video Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.15228",
      "abstract": "As the number of people affected by diseases in the gastrointestinal system is ever-increasing, a higher demand on preventive screening is inevitable. This will significantly increase the workload on gastroenterologists. To help reduce the workload, tools from computer vision may be helpful. In this paper, we investigate the possibility of constructing 3D models of whole sections of the human colon using image sequences from wireless capsule endoscope video, providing enhanced viewing for gastroenterologists. As capsule endoscope images contain distortion and artifacts non-ideal for many 3D reconstruction algorithms, the problem is challenging. However, recent developments of virtual graphics-based models of the human gastrointestinal system, where distortion and artifacts can be enabled or disabled, makes it possible to ``dissect'' the problem. The graphical model also provides a ground truth, enabling computation of geometric distortion introduced by the 3D reconstruction method. In this paper, most distortions and artifacts are left out to determine if it is feasible to reconstruct whole sections of the human gastrointestinal system by existing methods. We demonstrate that 3D reconstruction is possible using simultaneous localization and mapping. Further, to reconstruct the gastrointestinal wall surface from resulting point clouds, varying greatly in density, Poisson surface reconstruction is a good option. The results are promising, encouraging further research on this problem.",
      "authors": [
        "P{\\aa}l Anders Floor",
        "Ivar Farup",
        "Marius Pedersen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-21T17:31:38+00:00",
          "link": "https://arxiv.org/abs/2407.15228v1",
          "size": "8664kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T15:37:42+00:00",
          "link": "https://arxiv.org/abs/2407.15228v2",
          "size": "8666kb",
          "version": "v2"
        }
      ],
      "title": "3D Reconstruction of the Human Colon from Capsule Endoscope Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.15228",
        "HTML": "https://arxiv.org/html/2407.15228v2",
        "PDF": "https://arxiv.org/pdf/2407.15228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses 3D reconstruction techniques in the medical field, specifically using endoscope video data, which does not relate to the processing of LLM training data."
      },
      "tasks": [
        "3D Reconstruction",
        "Simultaneous Localization and Mapping",
        "Surface Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.11302",
      "abstract": "The Hausdorff dimension of a set can be detected using the Riesz energy. Here, we consider situations where a sequence of points, $\\{x_n\\}$, ``fills in'' a set $E \\subset \\mathbb{R}^d$ in an appropriate sense and investigate the degree to which the discrete analog to the Riesz energy of these sets can be used to bound the Hausdorff dimension of $E$. We also discuss applications to data science and Erd\\H{o}s/Falconer type problems.",
      "authors": [
        "Hari Sarang Nathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Classical Analysis and ODEs (math.CA)",
        "Machine Learning (cs.LG)",
        "Metric Geometry (math.MG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T15:45:14+00:00",
          "link": "https://arxiv.org/abs/2504.11302v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T01:23:47+00:00",
          "link": "https://arxiv.org/abs/2504.11302v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T14:10:14+00:00",
          "link": "https://arxiv.org/abs/2504.11302v3",
          "size": "31kb",
          "version": "v3"
        }
      ],
      "title": "Limits of Discrete Energy of Families of Increasing Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11302",
        "HTML": "https://arxiv.org/html/2504.11302v3",
        "PDF": "https://arxiv.org/pdf/2504.11302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the theoretical aspects of Riesz energy and its applications in data science and mathematical problems, without discussing any LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08898",
      "abstract": "Safety alignment is critical for LLM-powered systems. While recent LLM-powered guardrail approaches such as LlamaGuard achieve high detection accuracy of unsafe inputs written in English (e.g., ``How to create a bomb?''), they struggle with multilingual unsafe inputs. This limitation leaves LLM systems vulnerable to unsafe and jailbreak prompts written in low-resource languages such as those in Southeast Asia. This paper introduces SEALGuard, a multilingual guardrail designed to improve the safety alignment across diverse languages. It aims to address the multilingual safety alignment gap of existing guardrails and ensure effective filtering of unsafe and jailbreak prompts in LLM-powered systems. We adapt a general-purpose multilingual language model into a multilingual guardrail using low-rank adaptation (LoRA). We construct SEALSBench, a large-scale multilingual safety alignment dataset containing over 260,000 prompts in ten languages, including safe, unsafe, and jailbreak cases. We evaluate SEALGuard against state-of-the-art guardrails such as LlamaGuard on this benchmark. Our findings show that multilingual unsafe and jailbreak prompts substantially degrade the performance of the state-of-the-art LlamaGuard, which experiences a drop in Defense Success Rate (DSR) by 9% and 18%, respectively, compared to its performance on English-only prompts. In contrast, SEALGuard outperforms existing guardrails in detecting multilingual unsafe and jailbreak prompts, improving DSR by 48% over LlamaGuard and achieving the best DSR, precision, and F1-score. Our ablation study further reveals the contributions of adaptation strategies and model size to the overall performance of SEALGuard. SEALGuard advances the safety alignment of LLM systems by introducing an effective multilingual guardrail.",
      "authors": [
        "Wenliang Shan",
        "Michael Fu",
        "Rui Yang",
        "Chakkrit (Kla) Tantithamthavorn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:15:35+00:00",
          "link": "https://arxiv.org/abs/2507.08898v1",
          "size": "7452kb",
          "version": "v1"
        }
      ],
      "title": "SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08898",
        "PDF": "https://arxiv.org/pdf/2507.08898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SEALSBench, a large multilingual dataset designed for evaluating and improving safety alignment in LLM systems. This involves detailed dataset construction and processing steps, making a significant contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09856",
      "abstract": "Linear codes have attracted considerable attention in coding theory and cryptography due to their significant applications in secret sharing schemes, secure two-party computation, Galois geometries, among others. As two special subclasses of linear codes, minimal linear codes and self-orthogonal linear codes are of particular interest. Constructing linear codes that possess both minimality and self-orthogonality is very interesting. The main purpose of this paper is to construct self-orthogonal minimal linear codes that violate the Ashikhmin-Barg (AB for short) condition over the finite field $\\mathbb{F}_p$. First, we present several classes of self-orthogonal minimal linear codes violating the AB condition over the finite field $\\mathbb{F}_2$ and determine their weight distributions. Next, for any odd prime $p$, we construct two classes of self-orthogonal linear codes from $p$-ary functions, which contain some optimal or almost optimal codes. Finally, based on plateaued functions, we construct two classes of self-orthogonal linear codes that violate the AB condition. Their weight distributions are also provided. To the best of our knowledge, this paper is the first to investigate the constructions of linear codes that violate the AB condition and satisfy self-orthogonality.",
      "authors": [
        "Wengang Jin and Kangquan Li and Longjiang Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:42:18+00:00",
          "link": "https://arxiv.org/abs/2507.09856v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "Several new classes of self-orthogonal minimal linear codes violating the Ashikhmin-Barg condition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09856",
        "HTML": "https://arxiv.org/html/2507.09856v1",
        "PDF": "https://arxiv.org/pdf/2507.09856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about constructing self-orthogonal minimal linear codes, which is unrelated to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09901",
      "abstract": "Many of society's most pressing challenges, from pandemic response to supply chain disruptions to climate adaptation, emerge from the collective behavior of millions of autonomous agents making decisions over time. Large Population Models (LPMs) offer an approach to understand these complex systems by simulating entire populations with realistic behaviors and interactions at unprecedented scale. LPMs extend traditional modeling approaches through three key innovations: computational methods that efficiently simulate millions of agents simultaneously, mathematical frameworks that learn from diverse real-world data streams, and privacy-preserving communication protocols that bridge virtual and physical environments. This allows researchers to observe how agent behavior aggregates into system-level outcomes and test interventions before real-world implementation. While current AI advances primarily focus on creating \"digital humans\" with sophisticated individual capabilities, LPMs develop \"digital societies\" where the richness of interactions reveals emergent phenomena. By bridging individual agent behavior and population-scale dynamics, LPMs offer a complementary path in AI research illuminating collective intelligence and providing testing grounds for policies and social innovations before real-world deployment. We discuss the technical foundations and some open problems here. LPMs are implemented by the AgentTorch framework (github.com/AgentTorch/AgentTorch)",
      "authors": [
        "Ayush Chopra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:11:54+00:00",
          "link": "https://arxiv.org/abs/2507.09901v1",
          "size": "3509kb",
          "version": "v1"
        }
      ],
      "title": "Large Population Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09901",
        "HTML": "https://arxiv.org/html/2507.09901v1",
        "PDF": "https://arxiv.org/pdf/2507.09901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on Large Population Models (LPMs) for simulating populations rather than LLM training data processing or preparation; it discusses computational modeling of agent interactions at scale."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05310",
      "abstract": "Large Language Models have proven surprisingly effective at solving a wide range of tasks from just a handful of examples. However, their lack of reliability and modularity limits their capacity to tackle large problems that require many steps of reasoning. In response, researchers have proposed advanced pipelines that leverage domain-specific knowledge to chain smaller prompts, provide intermediate feedback and improve performance through search. However, the current complexity of writing, tuning, maintaining and improving such pipelines has limited their sophistication. We propose oracular programming, a foundational paradigm for building LLM-enabled applications that lets domain experts express high-level problem-solving strategies as programs with unresolved choice points. These choice points are resolved at runtime by LLMs, which generalize from user-provided examples of correct and incorrect decisions. An oracular program is composed of three orthogonal components: a strategy that consists in a nondeterministic program with choice points that can be reified into a search tree, a policy that specifies how to navigate this tree with the help of LLM oracles, and a set of demonstrations that describe successful and unsuccessful search tree navigation scenarios across diverse problem instances. Each component is expressed in a dedicated programming language and can be independently improved or substituted. We address the key programming language design challenges of modularly composing oracular programs and enforcing consistency between their components as they evolve.",
      "authors": [
        "Jonathan Laurent",
        "Andr\\'e Platzer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T20:24:43+00:00",
          "link": "https://arxiv.org/abs/2502.05310v1",
          "size": "1481kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T11:59:40+00:00",
          "link": "https://arxiv.org/abs/2502.05310v2",
          "size": "1637kb",
          "version": "v2"
        }
      ],
      "title": "Oracular Programming: A Modular Foundation for Building LLM-Enabled Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05310",
        "PDF": "https://arxiv.org/pdf/2502.05310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions developing advanced pipelines with LLMs but primarily focuses on the construction of modular LLM-enabled applications, not directly on LLM training data processing."
      },
      "tasks": [
        "Navigate"
      ],
      "repo_urls": [
        "https://github.com/jonathan-laurent/delphyne"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08245",
      "abstract": "The advancement of large language models (LLMs) has outpaced traditional evaluation methodologies. This progress presents novel challenges, such as measuring human-like psychological constructs, moving beyond static and task-specific benchmarks, and establishing human-centered evaluation. These challenges intersect with psychometrics, the science of quantifying the intangible aspects of human psychology, such as personality, values, and intelligence. This review paper introduces and synthesizes the emerging interdisciplinary field of LLM Psychometrics, which leverages psychometric instruments, theories, and principles to evaluate, understand, and enhance LLMs. The reviewed literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances LLM capabilities. Diverse perspectives are integrated to provide a structured framework for researchers across disciplines, enabling a more comprehensive understanding of this nascent field. Ultimately, the review provides actionable insights for developing future evaluation paradigms that align with human-level AI and promote the advancement of human-centered AI systems for societal benefit. A curated repository of LLM psychometric resources is available at https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.",
      "authors": [
        "Haoran Ye",
        "Jing Jin",
        "Yuhang Xie",
        "Xin Zhang",
        "Guojie Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T05:47:51+00:00",
          "link": "https://arxiv.org/abs/2505.08245v1",
          "size": "5732kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T08:25:01+00:00",
          "link": "https://arxiv.org/abs/2505.08245v2",
          "size": "5809kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08245",
        "HTML": "https://arxiv.org/html/2505.08245v2",
        "PDF": "https://arxiv.org/pdf/2505.08245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a review and focuses on the evaluation and enhancement of LLMs rather than on training data processing, collection, or engineering activities."
      },
      "tasks": [
        "Benchmarking",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/valuebyte-ai/awesome-llm-psychometrics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02668",
      "abstract": "Colorectal polyp segmentation is critical for early detection of colorectal cancer, yet weak and low contrast boundaries significantly limit automated accuracy. Existing deep models either blur fine edge details or rely on handcrafted filters that perform poorly under variable imaging conditions. We propose MEGANet-W, a Wavelet Driven Edge Guided Attention Network that injects directional, parameter free Haar wavelet edge maps into each decoder stage to recalibrate semantic features. Our two main contributions are: (1) a two-level Haar wavelet head for multi orientation edge extraction; and (2) Wavelet Edge Guided Attention (WEGA) modules that fuse wavelet cues with boundary and input branches. On five public polyp datasets, MEGANet-W consistently outperforms existing methods, improving mIoU by up to 2.3% and mDice by 1.2%, while introducing no additional learnable parameters.",
      "authors": [
        "Zhe Yee Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.02668v1",
          "size": "3551kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T07:25:00+00:00",
          "link": "https://arxiv.org/abs/2507.02668v2",
          "size": "3551kb",
          "version": "v2"
        }
      ],
      "title": "MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02668",
        "HTML": "https://arxiv.org/html/2507.02668v2",
        "PDF": "https://arxiv.org/pdf/2507.02668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a model for polyp detection using wavelet-guided attention, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04692",
      "abstract": "We present a diffusion-based portrait shadow removal approach that can robustly produce high-fidelity results. Unlike previous methods, we cast shadow removal as diffusion-based inpainting. To this end, we first train a shadow-independent structure extraction network on a real-world portrait dataset with various synthetic lighting conditions, which allows to generate a shadow-independent structure map including facial details while excluding the unwanted shadow boundaries. The structure map is then used as condition to train a structure-guided inpainting diffusion model for removing shadows in a generative manner. Finally, to restore the fine-scale details (e.g., eyelashes, moles and spots) that may not be captured by the structure map, we take the gradients inside the shadow regions as guidance and train a detail restoration diffusion model to refine the shadow removal result. Extensive experiments on the benchmark datasets show that our method clearly outperforms existing methods, and is effective to avoid previously common issues such as facial identity tampering, shadow residual, color distortion, structure blurring, and loss of details. Our code is available at https://github.com/wanchang-yu/Structure-Guided-Diffusion-for-Portrait-Shadow-Removal.",
      "authors": [
        "Wanchang Yu",
        "Qing Zhang",
        "Rongjia Zheng",
        "Wei-Shi Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T06:19:07+00:00",
          "link": "https://arxiv.org/abs/2507.04692v1",
          "size": "16276kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:47:15+00:00",
          "link": "https://arxiv.org/abs/2507.04692v2",
          "size": "16277kb",
          "version": "v2"
        }
      ],
      "title": "Structure-Guided Diffusion Models for High-Fidelity Portrait Shadow Removal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04692",
        "HTML": "https://arxiv.org/html/2507.04692v2",
        "PDF": "https://arxiv.org/pdf/2507.04692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a diffusion-based approach for portrait shadow removal using structured maps and generative models, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09052",
      "abstract": "Training data for class-conditional image synthesis often exhibit a long-tailed distribution with limited images for tail classes. Such an imbalance causes mode collapse and reduces the diversity of synthesized images for tail classes. For class-conditional diffusion models trained on imbalanced data, we aim to improve the diversity of tail class images without compromising the fidelity and diversity of head class images. We achieve this by introducing two deceptively simple but highly effective contrastive loss functions. Firstly, we employ an unsupervised InfoNCE loss utilizing negative samples to increase the distance/dissimilarity among synthetic images, particularly for tail classes. To further enhance the diversity of tail classes, our second loss is an MSE loss that contrasts class-conditional generation with unconditional generation at large timesteps. This second loss makes the denoising process insensitive to class conditions for the initial steps, which enriches tail classes through knowledge sharing from head classes. Conditional-unconditional alignment has been shown to enhance the performance of long-tailed GAN. We are the first to adapt such alignment to diffusion models. We successfully leveraged contrastive learning for class-imbalanced diffusion models. Our contrastive learning framework is easy to implement and outperforms standard DDPM and alternative methods for class-imbalanced diffusion models across various datasets, including CIFAR10/100-LT, PlacesLT, TinyImageNetLT, and ImageNetLT.",
      "authors": [
        "Fang Chen",
        "Alex Villa",
        "Gongbo Liang",
        "Xiaoyi Lu",
        "Meng Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:58:03+00:00",
          "link": "https://arxiv.org/abs/2507.09052v1",
          "size": "47845kb",
          "version": "v1"
        }
      ],
      "title": "Can Contrastive Learning Improve Class-Imbalanced Diffusion Model?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09052",
        "HTML": "https://arxiv.org/html/2507.09052v1",
        "PDF": "https://arxiv.org/pdf/2507.09052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes contrastive learning techniques to handle class imbalance in diffusion models and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09896",
      "abstract": "Due to the arbitrary orientation of objects in aerial images, rotation equivariance is a critical property for aerial object detectors. However, recent studies on rotation-equivariant aerial object detection remain scarce. Most detectors rely on data augmentation to enable models to learn approximately rotation-equivariant features. A few detectors have constructed rotation-equivariant networks, but due to the breaking of strict rotation equivariance by typical downsampling processes, these networks only achieve approximately rotation-equivariant backbones. Whether strict rotation equivariance is necessary for aerial image object detection remains an open question. In this paper, we implement a strictly rotation-equivariant backbone and neck network with a more advanced network structure and compare it with approximately rotation-equivariant networks to quantitatively measure the impact of rotation equivariance on the performance of aerial image detectors. Additionally, leveraging the inherently grouped nature of rotation-equivariant features, we propose a multi-branch head network that reduces the parameter count while improving detection accuracy. Based on the aforementioned improvements, this study proposes the Multi-branch head rotation-equivariant single-stage Detector (MessDet), which achieves state-of-the-art performance on the challenging aerial image datasets DOTA-v1.0, DOTA-v1.5 and DIOR-R with an exceptionally low parameter count.",
      "authors": [
        "Xiuyu Wu",
        "Xinhao Wang",
        "Xiubin Zhu",
        "Lan Yang",
        "Jiyuan Liu",
        "Xingchen Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:04:23+00:00",
          "link": "https://arxiv.org/abs/2507.09896v1",
          "size": "928kb",
          "version": "v1"
        }
      ],
      "title": "Measuring the Impact of Rotation Equivariance on Aerial Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09896",
        "HTML": "https://arxiv.org/html/2507.09896v1",
        "PDF": "https://arxiv.org/pdf/2507.09896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about measuring the impact of rotation equivariance in aerial object detection and proposes a detection method. It does not cover LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10019",
      "abstract": "This paper addresses the problem of estimating the containment and similarity between two sets using only random samples from each set, without relying on sketches or full data access. The study introduces a binomial model for predicting the overlap between samples, demonstrating that it is both accurate and practical when sample sizes are small compared to the original sets. The paper compares this model to previous approaches and shows that it provides better estimates under the considered conditions. It also analyzes the statistical properties of the estimator, including error bounds and sample size requirements needed to achieve a desired level of accuracy and confidence. The framework is extended to estimate set similarity, and the paper provides guidance for applying these methods in large scale data systems where only partial or sampled data is available.",
      "authors": [
        "Pranav Joshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Databases (cs.DB)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:56:29+00:00",
          "link": "https://arxiv.org/abs/2507.10019v1",
          "size": "506kb",
          "version": "v1"
        }
      ],
      "title": "Sampling-Based Estimation of Jaccard Containment and Similarity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10019",
        "HTML": "https://arxiv.org/html/2507.10019v1",
        "PDF": "https://arxiv.org/pdf/2507.10019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sampling-based estimation of set similarity, focusing on statistical methods and models for estimating containment and similarity, which is unrelated to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10311",
      "abstract": "Early detection of dementia is critical for timely medical intervention and improved patient outcomes. Neuropsychological tests are widely used for cognitive assessment but have traditionally relied on manual scoring. Automatic dementia classification (ADC) systems aim to infer cognitive decline directly from speech recordings of such tests. We propose Demenba, a novel ADC framework based on state space models, which scale linearly in memory and computation with sequence length. Trained on over 1,000 hours of cognitive assessments administered to Framingham Heart Study participants, some of whom were diagnosed with dementia through adjudicated review, our method outperforms prior approaches in fine-grained dementia classification by 21\\%, while using fewer parameters. We further analyze its scaling behavior and demonstrate that our model gains additional improvement when fused with large language models, paving the way for more transparent and scalable dementia assessment tools. Code: https://anonymous.4open.science/r/Demenba-0861",
      "authors": [
        "Liming Wang",
        "Saurabhchand Bhati",
        "Cody Karjadi",
        "Rhoda Au",
        "James Glass"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:15:47+00:00",
          "link": "https://arxiv.org/abs/2507.10311v1",
          "size": "375kb",
          "version": "v1"
        }
      ],
      "title": "Recognizing Dementia from Neuropsychological Tests with State Space Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10311",
        "HTML": "https://arxiv.org/html/2507.10311v1",
        "PDF": "https://arxiv.org/pdf/2507.10311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on dementia classification from neuropsychological tests and enhancing ADC systems with language models, rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10550",
      "abstract": "The Value Problem for weighted timed games (WTGs) consists in determining, given a two-player weighted timed game with a reachability objective and a rational threshold, whether or not the value of the game exceeds the threshold. This problem was shown to be undecidable some ten years ago for WTGs making use of at least three clocks, and is known to be decidable for single-clock WTGs. In this paper, we establish undecidability for two-clock WTGs making use of non-negative weights, even in a time-bounded setting, closing the last remaining major gap in our algorithmic understanding of WTGs.",
      "authors": [
        "Quentin Guilmant and Jo\\\"el Ouaknine and Isa Vialard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.10550v1",
          "size": "530kb",
          "version": "v1"
        }
      ],
      "title": "The Value Problem for Weighted Timed Games with Two Clocks is Undecidable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10550",
        "HTML": "https://arxiv.org/html/2507.10550v1",
        "PDF": "https://arxiv.org/pdf/2507.10550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the undecidability of the Value Problem for weighted timed games, which relates to algorithmic game theory and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.01897",
      "abstract": "Continuous graph neural networks (CGNNs) have garnered significant attention due to their ability to generalize existing discrete graph neural networks (GNNs) by introducing continuous dynamics. They typically draw inspiration from diffusion-based methods to introduce a novel propagation scheme, which is analyzed using ordinary differential equations (ODE). However, the implementation of CGNNs requires significant computational power, making them challenging to deploy on battery-powered devices. Inspired by recent spiking neural networks (SNNs), which emulate a biological inference process and provide an energy-efficient neural architecture, we incorporate the SNNs with CGNNs in a unified framework, named Continuous Spiking Graph Neural Networks (COS-GNN). We employ SNNs for graph node representation at each time step, which are further integrated into the ODE process along with time. To enhance information preservation and mitigate information loss in SNNs, we introduce the high-order structure of COS-GNN, which utilizes the second-order ODE for spiking representation and continuous propagation. Moreover, we provide the theoretical proof that COS-GNN effectively mitigates the issues of exploding and vanishing gradients, enabling us to capture long-range dependencies between nodes. Experimental results on graph-based learning tasks demonstrate the effectiveness of the proposed COS-GNN over competitive baselines.",
      "authors": [
        "Nan Yin",
        "Mengzhu Wan",
        "Li Shen",
        "Hitesh Laxmichand Patel",
        "Baopu Li",
        "Bin Gu",
        "Huan Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-02T12:36:40+00:00",
          "link": "https://arxiv.org/abs/2404.01897v1",
          "size": "532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T04:43:52+00:00",
          "link": "https://arxiv.org/abs/2404.01897v2",
          "size": "531kb",
          "version": "v2"
        }
      ],
      "title": "Continuous Spiking Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01897",
        "HTML": "https://arxiv.org/html/2404.01897v2",
        "PDF": "https://arxiv.org/pdf/2404.01897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on developing a new neural network architecture, specifically continuous spiking graph neural networks, without any mention of LLM training data processing or data quality improvements."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2406.02528",
      "abstract": "Large Language Models (LLMs) have fundamentally altered how we approach scaling in machine learning. However, these models pose substantial computational and memory challenges, primarily due to the reliance on matrix multiplication (MatMul) within their attention and feed-forward (FFN) layers. We demonstrate that MatMul operations can be eliminated from LLMs while maintaining strong performance, even at billion-parameter scales. Our MatMul-free models, tested on models up to 2.7B parameters, are comparable to state-of-the-art pre-trained Transformers, and the performance gap narrows as model size increases. Our approach yields significant memory savings: a GPU-efficient implementation reduces memory consumption by up to 61\\% during training and over 10$\\times$ during inference. When adapted for a multi-chip neuromorphic system, the model leverages asynchronous processing to achieve 4$\\times$ higher throughput with 10$\\times$ less energy than edge GPUs. %and 77$\\times$ less energy than server-class GPUs, demonstrating superior scaling. These findings demonstrate a path toward dramatically simplified yet effective LLMs, advancing them toward brain-like efficiency and heralding a new generation of lightweight, high-performance language models. Our code implementation is available at https://github. com/ridgerchu/matmulfreellm.",
      "authors": [
        "Rui-Jie Zhu",
        "Yu Zhang",
        "Steven Abreu",
        "Ethan Sifferman",
        "Tyler Sheaves",
        "Yiqiao Wang",
        "Dustin Richmond",
        "Sumit Bam Shrestha",
        "Peng Zhou",
        "Jason K. Eshraghian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-04T17:50:34+00:00",
          "link": "https://arxiv.org/abs/2406.02528v1",
          "size": "1050kb",
          "version": "v1"
        },
        {
          "date": "2024-06-10T14:55:29+00:00",
          "link": "https://arxiv.org/abs/2406.02528v2",
          "size": "1050kb",
          "version": "v2"
        },
        {
          "date": "2024-06-11T06:18:28+00:00",
          "link": "https://arxiv.org/abs/2406.02528v3",
          "size": "1050kb",
          "version": "v3"
        },
        {
          "date": "2024-06-14T07:48:33+00:00",
          "link": "https://arxiv.org/abs/2406.02528v4",
          "size": "1050kb",
          "version": "v4"
        },
        {
          "date": "2024-06-18T17:30:06+00:00",
          "link": "https://arxiv.org/abs/2406.02528v5",
          "size": "1050kb",
          "version": "v5"
        },
        {
          "date": "2025-07-14T03:30:40+00:00",
          "link": "https://arxiv.org/abs/2406.02528v6",
          "size": "2238kb",
          "version": "v6"
        }
      ],
      "title": "Scalable MatMul-free Language Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02528",
        "HTML": "https://arxiv.org/html/2406.02528",
        "PDF": "https://arxiv.org/pdf/2406.02528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reducing computational costs in LLMs by eliminating matrix multiplications, focusing on hardware and computational efficiency rather than LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/ridgerchu/matmulfreellm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02687",
      "abstract": "Due to the significant effort required for data collection and annotation in 3D perception tasks, mixed sample data augmentation (MSDA) has been widely studied to generate diverse training samples by mixing existing data. Recently, many MSDA techniques have been developed for point clouds, but they mainly target LiDAR data, leaving their application to radar point clouds largely unexplored. In this paper, we examine the feasibility of applying existing MSDA methods to radar point clouds and identify several challenges in adapting these techniques. These obstacles stem from the radar's irregular angular distribution, deviations from a single-sensor polar layout in multi-radar setups, and point sparsity. To address these issues, we propose Class-Aware PillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar level in 3D point clouds, guided by class labels. Unlike methods that rely a single mix ratio to the entire sample, CAPMix assigns an independent ratio to each pillar, boosting sample diversity. To account for the density of different classes, we use class-specific distributions: for dense objects (e.g., large vehicles), we skew ratios to favor points from another sample, while for sparse objects (e.g., pedestrians), we sample more points from the original. This class-aware mixing retains critical details and enriches each sample with new information, ultimately generating more diverse training data. Experimental results demonstrate that our method not only significantly boosts performance but also outperforms existing MSDA approaches across two datasets (Bosch Street and K-Radar). We believe that this straightforward yet effective approach will spark further investigation into MSDA techniques for radar data.",
      "authors": [
        "Miao Zhang",
        "Sherif Abdulatif",
        "Benedikt Loesch",
        "Marco Altmann and Bin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T15:02:07+00:00",
          "link": "https://arxiv.org/abs/2503.02687v1",
          "size": "3865kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:17:27+00:00",
          "link": "https://arxiv.org/abs/2503.02687v2",
          "size": "3655kb",
          "version": "v2"
        }
      ],
      "title": "Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02687",
        "HTML": "https://arxiv.org/html/2503.02687v2",
        "PDF": "https://arxiv.org/pdf/2503.02687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using mixed sample data augmentation (MSDA) to enhance diversity in 3D object detection datasets; although related to data processing, it doesn't focus on LLM training data."
      },
      "tasks": [
        "3D Object Detection",
        "Data Augmentation",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12860",
      "abstract": "Image degradation synthesis is highly desirable in a wide variety of applications ranging from image restoration to simulating artistic effects. Existing models are designed to generate one specific or a narrow set of degradations, which often require user-provided degradation parameters. As a result, they lack the generalizability to synthesize degradations beyond their initial design or adapt to other applications. Here we propose the first universal degradation model that can synthesize a broad spectrum of complex and realistic degradations containing both homogeneous (global) and inhomogeneous (spatially varying) components. Our model automatically extracts and disentangles homogeneous and inhomogeneous degradation features, which are later used for degradation synthesis without user intervention. A disentangle-by-compression method is proposed to separate degradation information from images. Two novel modules for extracting and incorporating inhomogeneous degradations are created to model inhomogeneous components in complex degradations. We demonstrate the model's accuracy and adaptability in film-grain simulation and blind image restoration tasks. The demo video, code, and dataset of this project will be released at github.com/yangwenbo99/content-degradation-disentanglement.",
      "authors": [
        "Wenbo Yang",
        "Zhongling Wang",
        "Zhou Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T08:45:08+00:00",
          "link": "https://arxiv.org/abs/2505.12860v1",
          "size": "38445kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T20:28:52+00:00",
          "link": "https://arxiv.org/abs/2505.12860v2",
          "size": "38450kb",
          "version": "v2"
        }
      ],
      "title": "Towards a Universal Image Degradation Model via Content-Degradation Disentanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12860",
        "HTML": "https://arxiv.org/html/2505.12860v2",
        "PDF": "https://arxiv.org/pdf/2505.12860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a universal model for image degradation synthesis, which is not related to LLM training data processing."
      },
      "tasks": [
        "Disentanglement",
        "Image Restoration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04189",
      "abstract": "Understanding character relationships is essential for interpreting complex narratives and conducting socially grounded AI research. However, manual annotation is time-consuming and low in coverage, while large language models (LLMs) often produce hallucinated or logically inconsistent outputs. We present SymbolicThought, a human-in-the-loop framework that combines LLM-based extraction with symbolic reasoning. The system constructs editable character relationship graphs, refines them using seven types of logical constraints, and enables real-time validation and conflict resolution through an interactive interface. To support logical supervision and explainable social analysis, we release a dataset of 160 interpersonal relationships with corresponding logical structures. Experiments show that SymbolicThought improves annotation accuracy and consistency while significantly reducing time cost, offering a practical tool for narrative understanding, explainable AI, and LLM evaluation.",
      "authors": [
        "Runcong Zhao",
        "Qinglin Zhu",
        "Hainiu Xu",
        "Bin Liang",
        "Lin Gui",
        "Yulan He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T23:46:35+00:00",
          "link": "https://arxiv.org/abs/2507.04189v1",
          "size": "1612kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T22:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.04189v2",
          "size": "1612kb",
          "version": "v2"
        }
      ],
      "title": "SymbolicThought: Integrating Language Models and Symbolic Reasoning for Consistent and Interpretable Human Relationship Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04189",
        "PDF": "https://arxiv.org/pdf/2507.04189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a human-in-the-loop framework, combining LLM-based extraction with symbolic reasoning, but it doesn't focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08920",
      "abstract": "We introduce AMix-1, a powerful protein foundation model built on Bayesian Flow Networks and empowered by a systematic training methodology, encompassing pretraining scaling laws, emergent capability analysis, in-context learning mechanism, and test-time scaling algorithm. To guarantee robust scalability, we establish a predictive scaling law and reveal the progressive emergence of structural understanding via loss perspective, culminating in a strong 1.7-billion model. Building on this foundation, we devise a multiple sequence alignment (MSA)-based in-context learning strategy to unify protein design into a general framework, where AMix-1 recognizes deep evolutionary signals among MSAs and consistently generates structurally and functionally coherent proteins. This framework enables the successful design of a dramatically improved AmeR variant with an up to $50\\times$ activity increase over its wild type. Pushing the boundaries of protein engineering, we further empower AMix-1 with an evolutionary test-time scaling algorithm for in silico directed evolution that delivers substantial, scalable performance gains as verification budgets are intensified, laying the groundwork for next-generation lab-in-the-loop protein design.",
      "authors": [
        "Changze Lv",
        "Jiang Zhou",
        "Siyu Long",
        "Lihao Wang",
        "Jiangtao Feng",
        "Dongyu Xue",
        "Yu Pei",
        "Hao Wang",
        "Zherui Zhang",
        "Yuchen Cai",
        "Zhiqiang Gao",
        "Ziyuan Ma",
        "Jiakai Hu",
        "Chaochen Gao",
        "Jingjing Gong",
        "Yuxuan Song",
        "Shuyi Zhang",
        "Xiaoqing Zheng",
        "Deyi Xiong",
        "Lei Bai",
        "Ya-Qin Zhang",
        "Wei-Ying Ma",
        "Bowen Zhou",
        "Hao Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:02:25+00:00",
          "link": "https://arxiv.org/abs/2507.08920v1",
          "size": "11015kb",
          "version": "v1"
        }
      ],
      "title": "AMix-1: A Pathway to Test-Time Scalable Protein Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08920",
        "HTML": "https://arxiv.org/html/2507.08920v1",
        "PDF": "https://arxiv.org/pdf/2507.08920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a protein foundation model with a focus on in-context learning and protein design, but it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08958",
      "abstract": "As cosmological simulations and their associated software become increasingly complex, physicists face the challenge of searching through vast amounts of literature and user manuals to extract simulation parameters from dense academic papers, each using different models and formats. Translating these parameters into executable scripts remains a time-consuming and error-prone process. To improve efficiency in physics research and accelerate the cosmological simulation process, we introduce SimAgents, a multi-agent system designed to automate both parameter configuration from the literature and preliminary analysis for cosmology research. SimAgents is powered by specialized LLM agents capable of physics reasoning, simulation software validation, and tool execution. These agents collaborate through structured communication, ensuring that extracted parameters are physically meaningful, internally consistent, and software-compliant. We also construct a cosmological parameter extraction evaluation dataset by collecting over 40 simulations in published papers from Arxiv and leading journals that cover diverse simulation types. Experiments on the dataset demonstrate a strong performance of SimAgents, highlighting its effectiveness and potential to accelerate scientific research for physicists. Our demonstration video is available at: https://youtu.be/w1zLpm_CaWA. The complete system and dataset are publicly available at https://github.com/xwzhang98/SimAgents.",
      "authors": [
        "Xiaowen Zhang",
        "Zhenyu Bi",
        "Xuan Wang",
        "Tiziana Di Matteo",
        "Rupert A.C. Croft"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:31:20+00:00",
          "link": "https://arxiv.org/abs/2507.08958v1",
          "size": "5319kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08958",
        "HTML": "https://arxiv.org/html/2507.08958v1",
        "PDF": "https://arxiv.org/pdf/2507.08958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a dataset for cosmological parameter extraction, but the primary focus is on applying LLMs to extract parameters from literature and simulate processes, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10531",
      "abstract": "Ferromagnetic exponential random graph models (ERGMs) are nonlinear exponential tilts of Erd\\H{o}s-R\\'enyi models, under which the presence of certain subgraphs such as triangles may be emphasized. These models are mixtures of metastable wells which each behave macroscopically like new Erd\\H{o}s-R\\'enyi models themselves, exhibiting the same laws of large numbers for the overall edge count as well as all subgraph counts. However, the microscopic fluctuations of these quantities remained elusive for some time. Building on a recent breakthrough by Fang, Liu, Shao and Zhao [FLSZ24] driven by Stein's method, we prove quantitative central limit theorems (CLTs) for these quantities and more in metastable wells under ferromagnetic ERGMs. One main novelty of our results is that they apply also in the supercritical (low temperature) regime of parameters, which has previously been relatively unexplored. To accomplish this, we develop a novel probabilistic technique based on the careful analysis of the evolution of relevant quantities under the ERGM Glauber dynamics. Our technique allows us to deliver the main input to the method developed by [FLSZ24], which is the fact that the fluctuations of subgraph counts are driven by those of the overall edge count. This was first shown for the triangle count by Sambale and Sinulis [SS20] in the Dobrushin (very high temperature) regime via functional-analytic methods. We feel our technique clarifies the underlying mechanisms at play, and it also supplies improved bounds on the Wasserstein and Kolmogorov distances between the observables at hand and the limiting Gaussians, as compared to the results of [FLSZ24] in the subcritical (high temperature) regime beyond the Dobrushin regime. Moreover, our technique is flexible enough to also yield quantitative CLTs for vertex degrees and local subgraph counts, which have not appeared before in any parameter regime.",
      "authors": [
        "Vilas Winstein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Discrete Mathematics (cs.DM)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:54:58+00:00",
          "link": "https://arxiv.org/abs/2507.10531v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "Quantitative central limit theorems for exponential random graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10531",
        "PDF": "https://arxiv.org/pdf/2507.10531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper delves into quantitative central limit theorems for exponential random graphs and does not discuss any aspects of LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.08219",
      "abstract": "Extensions of Stone-type dualities have a long history in algebraic logic and have also been instrumental in proving results in algebraic language theory. We show how to extend abstract categorical dualities via monoidal adjunctions, subsuming various incarnations of classical extended Stone and Priestley duality as special cases, and providing the foundation for two new concrete dualities: First, we investigate residuation algebras, which are lattices with additional residual operators modeling language derivatives algebraically. We show that the subcategory of derivation algebras is dually equivalent to the category of profinite ordered monoids, restricting to a duality between Boolean residuation algebras and profinite monoids. We further refine this duality to capture relational morphisms of profinite ordered monoids, which dualize to natural morphisms of residuation algebras. Second, we apply the categorical extended duality to the discrete setting of sets and complete atomic Boolean algebras to obtain a concrete description for the dual of the category of all small categories.",
      "authors": [
        "Fabian Lenke and Henning Urbat and Stefan Milius"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-16T09:10:05+00:00",
          "link": "https://arxiv.org/abs/2401.08219v1",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T12:34:23+00:00",
          "link": "https://arxiv.org/abs/2401.08219v2",
          "size": "71kb",
          "version": "v2"
        },
        {
          "date": "2024-11-12T12:55:33+00:00",
          "link": "https://arxiv.org/abs/2401.08219v3",
          "size": "71kb",
          "version": "v3"
        },
        {
          "date": "2025-04-20T12:51:46+00:00",
          "link": "https://arxiv.org/abs/2401.08219v4",
          "size": "80kb",
          "version": "v4"
        },
        {
          "date": "2025-06-18T14:10:27+00:00",
          "link": "https://arxiv.org/abs/2401.08219v5",
          "size": "81kb",
          "version": "v5"
        },
        {
          "date": "2025-07-14T15:11:54+00:00",
          "link": "https://arxiv.org/abs/2401.08219v6",
          "size": "80kb",
          "version": "v6"
        }
      ],
      "title": "Extended Stone Duality via Monoidal Adjunctions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.08219",
        "PDF": "https://arxiv.org/pdf/2401.08219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with algebraic logic and dualities in categorical settings, without involving any discussion of training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08572",
      "abstract": "In this paper we develop the following general approach. We study asymptotic behavior of the entropy numbers not for an individual smoothness class, how it is usually done, but for the collection of classes, which are defined by integral operators with kernels coming from a given class of functions. Earlier, such approach was realized for the Kolmogorov widths.",
      "authors": [
        "V. Temlyakov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Functional Analysis (math.FA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T13:46:08+00:00",
          "link": "https://arxiv.org/abs/2505.08572v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T12:30:05+00:00",
          "link": "https://arxiv.org/abs/2505.08572v2",
          "size": "18kb",
          "version": "v2"
        }
      ],
      "title": "Entropy numbers of classes defined by integral operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08572",
        "HTML": "https://arxiv.org/html/2505.08572v2",
        "PDF": "https://arxiv.org/pdf/2505.08572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the theoretical aspects of entropy numbers and integral operators, without any application or discussion on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.13327",
      "abstract": "PAD and FFD are proposed to protect face data from physical media-based Presentation Attacks and digital editing-based DeepFakes, respectively. However, isolated training of these two models significantly increases vulnerability towards unknown attacks, burdening deployment environments. The lack of a Unified Face Attack Detection model to simultaneously handle attacks in these two categories is mainly attributed to two factors: (1) A benchmark that is sufficient for models to explore is lacking. Existing UAD datasets only contain limited attack types and samples, leading to the model's confined ability to address abundant advanced threats. In light of these, through an explainable hierarchical way, we propose the most extensive and sophisticated collection of forgery techniques available to date, namely UniAttackDataPlus. Our UniAttackData+ encompasses 2,875 identities and their 54 kinds of corresponding falsified samples, in a total of 697,347 videos. (2) The absence of a trustworthy classification criterion. Current methods endeavor to explore an arbitrary criterion within the same semantic space, which fails to exist when encountering diverse attacks. Thus, we present a novel Visual-Language Model-based Hierarchical Prompt Tuning Framework that adaptively explores multiple classification criteria from different semantic spaces. Specifically, we construct a VP-Tree to explore various classification rules hierarchically. Then, by adaptively pruning the prompts, the model can select the most suitable prompts guiding the encoder to extract discriminative features at different levels in a coarse-to-fine manner. Finally, to help the model understand the classification criteria in visual space, we propose a DPI module to project the visual prompts to the text encoder to help obtain a more accurate semantics.",
      "authors": [
        "Ajian Liu",
        "Haocheng Yuan",
        "Xiao Guo",
        "Hui Ma",
        "Wanyi Zhuang",
        "Changtao Miao",
        "Yan Hong",
        "Chuanbiao Song",
        "Jun Lan",
        "Qi Chu",
        "Tao Gong",
        "Yanyan Liang",
        "Weiqiang Wang",
        "Jun Wan",
        "Xiaoming Liu",
        "Zhen Lei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T16:35:45+00:00",
          "link": "https://arxiv.org/abs/2505.13327v1",
          "size": "5643kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T02:07:48+00:00",
          "link": "https://arxiv.org/abs/2505.13327v2",
          "size": "10906kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T16:22:29+00:00",
          "link": "https://arxiv.org/abs/2505.13327v3",
          "size": "2378kb",
          "version": "v3"
        }
      ],
      "title": "Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13327",
        "HTML": "https://arxiv.org/html/2505.13327v3",
        "PDF": "https://arxiv.org/pdf/2505.13327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset for face attack detection but focuses on detection strategies rather than processing LLM training data."
      },
      "tasks": [
        "Benchmarking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08031",
      "abstract": "The emergence of Small Language Models (SLMs) as privacy-preserving alternatives for sensitive applications raises a fundamental question about their inherent understanding capabilities compared to Large Language Models (LLMs). This paper investigates the mental health understanding capabilities of current SLMs through systematic evaluation across diverse classification tasks. Employing zero-shot and few-shot learning paradigms, we benchmark their performance against established LLM baselines to elucidate their relative strengths and limitations in this critical domain. We assess five state-of-the-art SLMs (Phi-3, Phi-3.5, Qwen2.5, Llama-3.2, Gemma2) against three LLMs (GPT-4, FLAN-T5-XXL, Alpaca-7B) on six mental health understanding tasks. Our findings reveal that SLMs achieve mean performance within 2\\% of LLMs on binary classification tasks (F1 scores of 0.64 vs 0.66 in zero-shot settings), demonstrating notable competence despite orders of magnitude fewer parameters. Both model categories experience similar degradation on multi-class severity tasks (a drop of over 30\\%), suggesting that nuanced clinical understanding challenges transcend model scale. Few-shot prompting provides substantial improvements for SLMs (up to 14.6\\%), while LLM gains are more variable. Our work highlights the potential of SLMs in mental health understanding, showing they can be effective privacy-preserving tools for analyzing sensitive online text data. In particular, their ability to quickly adapt and specialize with minimal data through few-shot learning positions them as promising candidates for scalable mental health screening tools.",
      "authors": [
        "Hong Jia",
        "Shiya Fu",
        "Feng Xia",
        "Vassilis Kostakos",
        "Ting Dang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:40:02+00:00",
          "link": "https://arxiv.org/abs/2507.08031v1",
          "size": "77kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T01:10:56+00:00",
          "link": "https://arxiv.org/abs/2507.08031v2",
          "size": "77kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08031",
        "HTML": "https://arxiv.org/html/2507.08031v2",
        "PDF": "https://arxiv.org/pdf/2507.08031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper does not focus on LLM training data processing. It primarily evaluates the performance of Small Language Models in mental health tasks compared to LLMs, with an emphasis on model performance rather than data preprocessing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09407",
      "abstract": "We introduce the framework of LLM-Stackelberg games, a class of sequential decision-making models that integrate large language models (LLMs) into strategic interactions between a leader and a follower. Departing from classical Stackelberg assumptions of complete information and rational agents, our formulation allows each agent to reason through structured prompts, generate probabilistic behaviors via LLMs, and adapt their strategies through internal cognition and belief updates. We define two equilibrium concepts: reasoning and behavioral equilibrium, which aligns an agent's internal prompt-based reasoning with observable behavior, and conjectural reasoning equilibrium, which accounts for epistemic uncertainty through parameterized models over an opponent's response. These layered constructs capture bounded rationality, asymmetric information, and meta-cognitive adaptation. We illustrate the framework through a spearphishing case study, where a sender and a recipient engage in a deception game using structured reasoning prompts. This example highlights the cognitive richness and adversarial potential of LLM-mediated interactions. Our results show that LLM-Stackelberg games provide a powerful paradigm for modeling decision-making in domains such as cybersecurity, misinformation, and recommendation systems.",
      "authors": [
        "Quanyan Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T21:42:27+00:00",
          "link": "https://arxiv.org/abs/2507.09407v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09407",
        "HTML": "https://arxiv.org/html/2507.09407v1",
        "PDF": "https://arxiv.org/pdf/2507.09407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on decision-making models using LLMs in strategic games, without a focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09445",
      "abstract": "The integration of Fourier transform and deep learning opens new avenues for time series forecasting. We reconsider the Fourier transform from a basis functions perspective. Specifically, the real and imaginary parts of the frequency components can be regarded as the coefficients of cosine and sine basis functions at tiered frequency levels, respectively. We find that existing Fourier-based methods face inconsistent starting cycles and inconsistent series length issues. They fail to interpret frequency components precisely and overlook temporal information. Accordingly, the novel Fourier Basis Mapping (FBM) method addresses these issues by integrating time-frequency features through Fourier basis expansion and mapping in the time-frequency space. Our approach extracts explicit frequency features while preserving temporal characteristics. FBM supports plug-and-play integration with various types of neural networks by only adjusting the first initial projection layer for better performance. First, we propose FBM-L, FBM-NL, and FBM-NP to enhance linear, MLP-based, and Transformer-based models, respectively, demonstrating the effectiveness of time-frequency features. Next, we propose a synergetic model architecture, termed FBM-S, which decomposes the seasonal, trend, and interaction effects into three separate blocks, each designed to model time-frequency features in a specialized manner. Finally, we introduce several techniques tailored for time-frequency features, including interaction masking, centralization, patching, rolling window projection, and multi-scale down-sampling. The results are validated on diverse real-world datasets for both long-term and short-term forecasting tasks with SOTA performance.",
      "authors": [
        "Runze Yang",
        "Longbing Cao",
        "Xin You",
        "Kun Fang",
        "Jianxun Li",
        "Jie Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T01:45:27+00:00",
          "link": "https://arxiv.org/abs/2507.09445v1",
          "size": "4521kb",
          "version": "v1"
        }
      ],
      "title": "Fourier Basis Mapping: A Time-Frequency Learning Framework for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09445",
        "HTML": "https://arxiv.org/html/2507.09445v1",
        "PDF": "https://arxiv.org/pdf/2507.09445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for time series forecasting using Fourier transforms and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09510",
      "abstract": "Target Speaker Extraction (TSE) uses a reference cue to extract the target speech from a mixture. In TSE systems relying on audio cues, the speaker embedding from the enrolled speech is crucial to performance. However, these embeddings may suffer from speaker identity confusion. Unlike previous studies that focus on improving speaker embedding extraction, we improve TSE performance from the perspective of speaker consistency. In this paper, we propose a speaker consistency-aware target speaker extraction method that incorporates a centroid-based speaker consistency loss. This approach enhances TSE performance by ensuring speaker consistency between the enrolled and extracted speech. In addition, we integrate conditional loss suppression into the training process. The experimental results validate the effectiveness of our proposed methods in advancing the TSE performance. A speech demo is available online.\\footnote{https://sc-tse.netlify.app/",
      "authors": [
        "Shu Wu",
        "Anbin Qi",
        "Yanzhang Xie and Xiang Xie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:35:13+00:00",
          "link": "https://arxiv.org/abs/2507.09510v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "SC-TSE: Speaker Consistency-Aware Target Speaker Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09510",
        "HTML": "https://arxiv.org/html/2507.09510v1",
        "PDF": "https://arxiv.org/pdf/2507.09510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes methods for improving target speaker extraction through speaker consistency, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09537",
      "abstract": "Predicting the future of surrounding agents and accordingly planning a safe, goal-directed trajectory are crucial for automated vehicles. Current methods typically rely on imitation learning to optimize metrics against the ground truth, often overlooking how scene understanding could enable more holistic trajectories. In this paper, we propose Plan-MAE, a unified pretraining framework for prediction and planning that capitalizes on masked autoencoders. Plan-MAE fuses critical contextual understanding via three dedicated tasks: reconstructing masked road networks to learn spatial correlations, agent trajectories to model social interactions, and navigation routes to capture destination intents. To further align vehicle dynamics and safety constraints, we incorporate a local sub-planning task predicting the ego-vehicle's near-term trajectory segment conditioned on earlier segment. This pretrained model is subsequently fine-tuned on downstream tasks to jointly generate the prediction and planning trajectories. Experiments on large-scale datasets demonstrate that Plan-MAE outperforms current methods on the planning metrics by a large margin and can serve as an important pre-training step for learning-based motion planner.",
      "authors": [
        "Yangang Ren",
        "Guojian Zhan",
        "Chen Lv",
        "Jun Li",
        "Fenghua Liang",
        "Keqiang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:39:02+00:00",
          "link": "https://arxiv.org/abs/2507.09537v1",
          "size": "411kb",
          "version": "v1"
        }
      ],
      "title": "Self-supervised Pretraining for Integrated Prediction and Planning of Automated Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09537",
        "HTML": "https://arxiv.org/html/2507.09537v1",
        "PDF": "https://arxiv.org/pdf/2507.09537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pretraining frameworks for automated vehicles, specifically utilizing masked autoencoders. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10143",
      "abstract": "While biological vision systems rely heavily on feedback connections to iteratively refine perception, most artificial neural networks remain purely feedforward, processing input in a single static pass. In this work, we propose a predictive coding inspired feedback mechanism that introduces a recurrent loop from output to input, allowing the model to refine its internal state over time. We implement this mechanism within a standard U-Net architecture and introduce two biologically motivated operations, softmax projection and exponential decay, to ensure stability of the feedback loop. Through controlled experiments on a synthetic segmentation task, we show that the feedback model significantly outperforms its feedforward counterpart in noisy conditions and generalizes more effectively with limited supervision. Notably, feedback achieves above random performance with just two training examples, while the feedforward model requires at least four. Our findings demonstrate that feedback enhances robustness and data efficiency, and offer a path toward more adaptive and biologically inspired neural architectures. Code is available at: github.com/DCalhas/feedback_segmentation.",
      "authors": [
        "David Calhas",
        "Arlindo L. Oliveira"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:41:07+00:00",
          "link": "https://arxiv.org/abs/2507.10143v1",
          "size": "590kb",
          "version": "v1"
        }
      ],
      "title": "Deep Recurrence for Dynamical Segmentation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10143",
        "HTML": "https://arxiv.org/html/2507.10143v1",
        "PDF": "https://arxiv.org/pdf/2507.10143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a feedback mechanism in neural network architectures for segmentation tasks, which does not relate to LLM training data processing or dataset enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10449",
      "abstract": "Coral reefs are vital yet vulnerable ecosystems that require continuous monitoring to support conservation. While coral reef images provide essential information in coral monitoring, interpreting such images remains challenging due to the need for domain expertise. Visual Question Answering (VQA), powered by Large Vision-Language Models (LVLMs), has great potential in user-friendly interaction with coral reef images. However, applying VQA to coral imagery demands a dedicated dataset that addresses two key challenges: domain-specific annotations and multidimensional questions. In this work, we introduce CoralVQA, the first large-scale VQA dataset for coral reef analysis. It contains 12,805 real-world coral images from 67 coral genera collected from 3 oceans, along with 277,653 question-answer pairs that comprehensively assess ecological and health-related conditions. To construct this dataset, we develop a semi-automatic data construction pipeline in collaboration with marine biologists to ensure both scalability and professional-grade data quality. CoralVQA presents novel challenges and provides a comprehensive benchmark for studying vision-language reasoning in the context of coral reef images. By evaluating several state-of-the-art LVLMs, we reveal key limitations and opportunities. These insights form a foundation for future LVLM development, with a particular emphasis on supporting coral conservation efforts.",
      "authors": [
        "Hongyong Han",
        "Wei Wang",
        "Gaowei Zhang",
        "Mingjie Li",
        "Yi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:29:10+00:00",
          "link": "https://arxiv.org/abs/2507.10449v1",
          "size": "6448kb",
          "version": "v1"
        }
      ],
      "title": "CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10449",
        "HTML": "https://arxiv.org/html/2507.10449v1",
        "PDF": "https://arxiv.org/pdf/2507.10449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces CoralVQA, a new VQA dataset for coral reef analysis, detailing a semi-automatic data construction pipeline. This constitutes a significant technical contribution to data processing in the creation of a specialized dataset."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.10905",
      "abstract": "This study explores whether labeling AI as \"trustworthy\" or \"reliable\" influences user perceptions and acceptance of automotive AI technologies. Using a one-way between-subjects design, the research involved 478 online participants who were presented with guidelines for either trustworthy or reliable AI. Participants then evaluated three vignette scenarios and completed a modified version of the Technology Acceptance Model, which included variables such as perceived ease of use, human-like trust, and overall attitude. Although labeling AI as \"trustworthy\" did not significantly influence judgments on specific scenarios, it increased perceived ease of use and human-like trust, particularly benevolence. This suggests a positive impact on usability and an anthropomorphic effect on user perceptions. The study provides insights into how specific labels can influence attitudes toward AI technology.",
      "authors": [
        "John Dorsch and Ophelia Deroy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T14:48:24+00:00",
          "link": "https://arxiv.org/abs/2408.10905v1",
          "size": "3343kb",
          "version": "v1"
        }
      ],
      "title": "The impact of labeling automotive AI as \"trustworthy\" or \"reliable\" on user evaluation and technology acceptance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10905",
        "HTML": "https://arxiv.org/html/2408.10905",
        "PDF": "https://arxiv.org/pdf/2408.10905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines user perceptions of automotive AI labeled as 'trustworthy' or 'reliable'. It does not contribute to LLM training data processing or LLM-related datasets."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.16052",
      "abstract": "We study a data marketplace where a broker intermediates between buyers, who seek to estimate the mean \\(\\mu\\) of an unknown normal distribution \\(\\Ncal(\\mu, \\sigma^2)\\), and contributors, who can collect data from this distribution at a cost. The broker delegates data collection work to contributors, aggregates reported datasets, sells it to buyers, and redistributes revenue as payments to contributors. We aim to maximize welfare or profit under key constraints: individual rationality for buyers and contributors, incentive compatibility (contributors are incentivized to comply with data collection instructions and truthfully report the collected data), and budget balance (total contributor payments equals total revenue). We first compute welfare/profit-optimal prices under truthful reporting; however, to incentivize data collection and truthful data reporting, we adjust them based on discrepancies in contributors' reported data. This yields a Nash equilibrium (NE) where the two lowest-cost contributors collect all data. We complement this with two hardness results: \\emph{(i)} no nontrivial dominant-strategy incentive-compatible mechanism exists in this problem, and \\emph{(ii)} no mechanism outperforms ours in a NE.",
      "authors": [
        "Keran Chen and Alex Clinton and Kirthevasan Kandasamy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T03:15:02+00:00",
          "link": "https://arxiv.org/abs/2502.16052v1",
          "size": "246kb",
          "version": "v1"
        },
        {
          "date": "2025-05-25T04:40:06+00:00",
          "link": "https://arxiv.org/abs/2502.16052v2",
          "size": "72kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T07:38:24+00:00",
          "link": "https://arxiv.org/abs/2502.16052v3",
          "size": "70kb",
          "version": "v3"
        }
      ],
      "title": "Incentivizing Truthful Data Contributions in a Marketplace for Mean Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16052",
        "HTML": "https://arxiv.org/html/2502.16052v3",
        "PDF": "https://arxiv.org/pdf/2502.16052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mechanisms in a data marketplace for mean estimation and does not contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.00533",
      "abstract": "Neural traveling salesman problem (TSP) solvers face two critical challenges: poor generalization for scalable TSPs and high training costs. To address these challenges, we propose a new Rescaling Graph Convolutional Network (RsGCN). Focusing on the scale-dependent features (i.e., features varied with problem scales) related to nodes and edges that influence the sensitivity of GCNs to the problem scales, a Rescaling Mechanism in RsGCN enhances the generalization capability by (1) rescaling adjacent nodes to construct a subgraph with a uniform number of adjacent nodes for each node across various scales of TSPs, which stabilizes the graph message aggregation; (2) rescaling subgraph edges to adjust the lengths of subgraph edges to the same magnitude, which maintains numerical consistency. In addition, an efficient training strategy with a mixed-scale dataset and bidirectional loss is used in RsGCN. To fully exploit the heatmaps generated by RsGCN, we design an efficient post-search algorithm termed Re2Opt, in which a reconstruction process based on adaptive weight is incorporated to help avoid local optima. Based on a combined architecture of RsGCN and Re2Opt, our solver achieves remarkable generalization and low training cost: with only 3 epochs of training on the mixed-scale dataset containing instances with up to 100 nodes, it can be generalized successfully to 10K-node instances without any fine-tuning. Extensive experiments demonstrate our state-of-the-art performance across uniform distribution instances of 9 different scales from 20 to 10K nodes and 78 real-world instances from TSPLIB, while requiring the fewest learnable parameters and training epochs among neural competitors.",
      "authors": [
        "Junquan Huang",
        "Zong-Gan Chen",
        "Yuncheng Jiang",
        "Zhi-Hui Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T12:40:02+00:00",
          "link": "https://arxiv.org/abs/2506.00533v1",
          "size": "6799kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T06:46:14+00:00",
          "link": "https://arxiv.org/abs/2506.00533v2",
          "size": "6799kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T09:06:25+00:00",
          "link": "https://arxiv.org/abs/2506.00533v3",
          "size": "6799kb",
          "version": "v3"
        }
      ],
      "title": "RsGCN: Rescaling Enhances Generalization of GCNs for Solving Scalable Traveling Salesman Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00533",
        "HTML": "https://arxiv.org/html/2506.00533v3",
        "PDF": "https://arxiv.org/pdf/2506.00533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with generalization challenges in solving TSP using neural networks, rather than processing or creating LLM training data."
      },
      "tasks": [
        "Traveling Salesman Problem"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08871",
      "abstract": "Travel demand models are critical tools for planning, policy, and mobility system design. Traditional activity-based models (ABMs), although grounded in behavioral theories, often rely on simplified rules and assumptions, and are costly to develop and difficult to adapt across different regions. This paper presents a learning-based travel demand modeling framework that synthesizes household-coordinated daily activity patterns based on a household's socio-demographic profiles. The whole framework integrates population synthesis, coordinated activity generation, location assignment, and large-scale microscopic traffic simulation into a unified system. It is fully generative, data-driven, scalable, and transferable to other regions. A full-pipeline implementation is conducted in Los Angeles with a 10 million population. Comprehensive validation shows that the model closely replicates real-world mobility patterns and matches the performance of legacy ABMs with significantly reduced modeling cost and greater scalability. With respect to the SCAG ABM benchmark, the origin-destination matrix achieves a cosine similarity of 0.97, and the daily vehicle miles traveled (VMT) in the network yields a 0.006 Jensen-Shannon Divergence (JSD) and a 9.8% mean absolute percentage error (MAPE). When compared to real-world observations from Caltrans PeMS, the evaluation on corridor-level traffic speed and volume reaches a 0.001 JSD and a 6.11% MAPE.",
      "authors": [
        "Xishun Liao",
        "Haoxuan Ma",
        "Yifan Liu",
        "Yuxiang Wei",
        "Brian Yueshuai He",
        "Chris Stanford",
        "and Jiaqi Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:06:36+00:00",
          "link": "https://arxiv.org/abs/2507.08871v1",
          "size": "5275kb",
          "version": "v1"
        }
      ],
      "title": "Next-Generation Travel Demand Modeling with a Generative Framework for Household Activity Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08871",
        "HTML": "https://arxiv.org/html/2507.08871v1",
        "PDF": "https://arxiv.org/pdf/2507.08871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a model for travel demand modeling and does not involve LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09694",
      "abstract": "This paper introduces a comprehensive open-source framework for developing correlation kernels, with a particular focus on user-defined and composition of kernels for surrogate modeling. By advancing kernel-based modeling techniques, we incorporate frequency-aware elements that effectively capture complex mechanical behaviors and timefrequency dynamics intrinsic to aircraft systems. Traditional kernel functions, often limited to exponential-based methods, are extended to include a wider range of kernels such as exponential squared sine and rational quadratic kernels, along with their respective firstand second-order derivatives. The proposed methodologies are first validated on a sinus cardinal test case and then applied to forecasting Mauna-Loa Carbon Dioxide (CO 2 ) concentrations and airline passenger traffic. All these advancements are integrated into the open-source Surrogate Modeling Toolbox (SMT 2.0), providing a versatile platform for both standard and customizable kernel configurations. Furthermore, the framework enables the combination of various kernels to leverage their unique strengths into composite models tailored to specific problems. The resulting framework offers a flexible toolset for engineers and researchers, paving the way for numerous future applications in metamodeling for complex, frequency-sensitive domains.",
      "authors": [
        "Nicolas Gonel",
        "Paul Saves",
        "Joseph Morlier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T16:10:46+00:00",
          "link": "https://arxiv.org/abs/2507.09694v1",
          "size": "11556kb",
          "version": "v1"
        }
      ],
      "title": "Frequency-aware Surrogate Modeling With SMT Kernels For Advanced Data Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09694",
        "HTML": "https://arxiv.org/html/2507.09694v1",
        "PDF": "https://arxiv.org/pdf/2507.09694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on surrogate modeling with new kernel functions for forecasting, not on LLM training data processing or creation of new datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09993",
      "abstract": "Camera-based object detection systems play a vital role in autonomous driving, yet they remain vulnerable to adversarial threats in real-world environments. While existing 2D and 3D physical attacks typically optimize texture, they often struggle to balance physical realism and attack robustness. In this work, we propose 3D Gaussian-based Adversarial Attack (3DGAA), a novel adversarial object generation framework that leverages the full 14-dimensional parameterization of 3D Gaussian Splatting (3DGS) to jointly optimize geometry and appearance in physically realizable ways. Unlike prior works that rely on patches or texture, 3DGAA jointly perturbs both geometric attributes (shape, scale, rotation) and appearance attributes (color, opacity) to produce physically realistic and transferable adversarial objects. We further introduce a physical filtering module to preserve geometric fidelity, and a physical augmentation module to simulate complex physical scenarios, thus enhancing attack generalization under real-world conditions. We evaluate 3DGAA on both virtual benchmarks and physical-world setups using miniature vehicle models. Experimental results show that 3DGAA achieves to reduce the detection mAP from 87.21% to 7.38%, significantly outperforming existing 3D physical attacks. Moreover, our method maintains high transferability across different physical conditions, demonstrating a new state-of-the-art in physically realizable adversarial attacks. These results validate 3DGAA as a practical attack framework for evaluating the safety of perception systems in autonomous driving.",
      "authors": [
        "Yixun Zhang",
        "Lizhi Wang",
        "Junjun Zhao",
        "Wending Zhao",
        "Feng Zhou",
        "Yonghao Dang",
        "and Jianqin Yin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:27:52+00:00",
          "link": "https://arxiv.org/abs/2507.09993v1",
          "size": "8767kb",
          "version": "v1"
        }
      ],
      "title": "3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09993",
        "HTML": "https://arxiv.org/html/2507.09993v1",
        "PDF": "https://arxiv.org/pdf/2507.09993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work pertains to adversarial attack methods for autonomous driving, with no relevance to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10030",
      "abstract": "Deep Reinforcement Learning (RL) has emerged as a powerful method for addressing complex control problems, particularly those involving underactuated robotic systems. However, in some cases, policies may require refinement to achieve optimal performance and robustness aligned with specific task objectives. In this paper, we propose an approach for fine-tuning Deep RL policies using Evolutionary Strategies (ES) to enhance control performance for underactuated robots. Our method involves initially training an RL agent with Soft-Actor Critic (SAC) using a surrogate reward function designed to approximate complex specific scoring metrics. We subsequently refine this learned policy through a zero-order optimization step employing the Separable Natural Evolution Strategy (SNES), directly targeting the original score. Experimental evaluations conducted in the context of the 2nd AI Olympics with RealAIGym at IROS 2024 demonstrate that our evolutionary fine-tuning significantly improves agent performance while maintaining high robustness. The resulting controllers outperform established baselines, achieving competitive scores for the competition tasks.",
      "authors": [
        "Marco Cal\\`i",
        "Alberto Sinigaglia",
        "Niccol\\`o Turcato",
        "Ruggero Carli",
        "Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:09:02+00:00",
          "link": "https://arxiv.org/abs/2507.10030v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Finetuning Deep Reinforcement Learning Policies with Evolutionary Strategies for Control of Underactuated Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10030",
        "HTML": "https://arxiv.org/html/2507.10030v1",
        "PDF": "https://arxiv.org/pdf/2507.10030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses fine-tuning strategies for RL policies in robot control without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.05700",
      "abstract": "A growing share of human interactions now occurs online, where the expression and perception of emotions are often amplified and distorted. Yet, the interplay between different emotions and the extent to which they are driven by external stimuli or social feedback remains poorly understood. We calibrate a multivariate Hawkes self-exciting point process to model the temporal expression of six basic emotions in YouTube Live chats. This framework captures both temporal and cross-emotional dependencies while allowing us to disentangle the influence of video content (exogenous) from peer interactions (endogenous). We find that emotional expressions are up to four times more strongly driven by peer interaction than by video content. Positivity is more contagious, spreading three times more readily, whereas negativity is more memorable, lingering nearly twice as long. Moreover, we observe asymmetric cross-excitation, with negative emotions frequently triggering positive ones, a pattern consistent with trolling dynamics, but not the reverse. These findings highlight the central role of social interaction in shaping emotional dynamics online and the risks of emotional manipulation as human-chatbot interactions become increasingly realistic.",
      "authors": [
        "Yishan Luo",
        "Didier Sornette",
        "Sandro Claudio Lera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Human-Computer Interaction (cs.HC)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-11T05:42:45+00:00",
          "link": "https://arxiv.org/abs/2408.05700v1",
          "size": "1411kb",
          "version": "v1"
        },
        {
          "date": "2025-03-30T18:17:15+00:00",
          "link": "https://arxiv.org/abs/2408.05700v2",
          "size": "2135kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T14:30:59+00:00",
          "link": "https://arxiv.org/abs/2408.05700v3",
          "size": "2474kb",
          "version": "v3"
        }
      ],
      "title": "Quantification of Interdependent Emotion Dynamics in Online Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05700",
        "HTML": "https://arxiv.org/html/2408.05700v3",
        "PDF": "https://arxiv.org/pdf/2408.05700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes emotion dynamics in online interactions and does not pertain to processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22941",
      "abstract": "Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
      "authors": [
        "Kaixuan Wang",
        "Jason T. Jacques",
        "Chenxin Diao",
        "and Carl-Cyril J Dreue"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:15:47+00:00",
          "link": "https://arxiv.org/abs/2506.22941v1",
          "size": "4041kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T13:02:17+00:00",
          "link": "https://arxiv.org/abs/2506.22941v2",
          "size": "4078kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T00:53:06+00:00",
          "link": "https://arxiv.org/abs/2506.22941v3",
          "size": "4059kb",
          "version": "v3"
        }
      ],
      "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22941",
        "PDF": "https://arxiv.org/pdf/2506.22941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses the design and potential applications of LLMs in a specific domain (harm reduction), without focusing on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01930",
      "abstract": "Recent advances in large Language Models (LLMs) have revolutionized mobile robots, including unmanned aerial vehicles (UAVs), enabling their intelligent operation within Internet of Things (IoT) ecosystems. However, LLMs still face challenges from logical reasoning and complex decision-making, leading to concerns about the reliability of LLM-driven UAV operations in IoT applications. In this paper, we propose a LLM-driven closed-loop control framework that enables reliable UAV operations powered by effective feedback and refinement using two LLM modules, i.e., a Code Generator and an Evaluator. Our framework transforms numerical state observations from UAV operations into natural language trajectory descriptions to enhance the evaluator LLM's understanding of UAV dynamics for precise feedback generation. Our framework also enables a simulation-based refinement process, and hence eliminates the risks to physical UAVs caused by incorrect code execution during the refinement. Extensive experiments on UAV control tasks with different complexities are conducted. The experimental results show that our framework can achieve reliable UAV operations using LLMs, which significantly outperforms baseline approaches in terms of success rate and completeness with the increase of task complexity.",
      "authors": [
        "Wenhao Wang",
        "Yanyan Li",
        "Long Jiao",
        "Jiawei Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:44:17+00:00",
          "link": "https://arxiv.org/abs/2507.01930v1",
          "size": "484kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:36:59+00:00",
          "link": "https://arxiv.org/abs/2507.01930v2",
          "size": "483kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T02:15:41+00:00",
          "link": "https://arxiv.org/abs/2507.01930v3",
          "size": "484kb",
          "version": "v3"
        }
      ],
      "title": "Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01930",
        "HTML": "https://arxiv.org/html/2507.01930v3",
        "PDF": "https://arxiv.org/pdf/2507.01930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for UAV operations using LLMs, focusing on semantic observations and UAV control, without any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09426",
      "abstract": "Given a digraph with two terminal vertices $s$ and $t$ as well as a conservative cost function and several not necessarily disjoint color classes on its arc set, our goal is to find a minimum-cost subset of the arcs such that its intersection with each color class contains an $s$-$t$ dipath. Problems of this type arise naturally in multi-commodity network design settings where each commodity is restricted to use links of its own color only.\n  We study several variants of the problem, deriving strong hardness results even for restricted cases, but we also identify cases that can be solved in polynomial time. The latter ones include the cases where the color classes form a laminar family, or where the underlying digraph is acyclic and the number of color classes is constant. We also present an FPT algorithm for the general case parameterized by the number of multi-colored arcs.",
      "authors": [
        "Naonori Kakimura",
        "P\\'eter Madarasi",
        "Jannik Matuschke",
        "Kitti Varga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T23:34:58+00:00",
          "link": "https://arxiv.org/abs/2507.09426v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Simultaneous Network Design with Restricted Link Usage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09426",
        "PDF": "https://arxiv.org/pdf/2507.09426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on network design with restricted link usage, without involving any LLM training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10249",
      "abstract": "We propose a novel cooperative herding strategy through backstepping control barrier functions (CBFs), which coordinates multiple herders to herd a group of evaders safely towards a designated goal region. For the herding system with heterogeneous groups involving herders and evaders, the behavior of the evaders can only be influenced indirectly by the herders' motion, especially when the evaders follow an inverse dynamics model and respond solely to repulsive interactions from the herders. This indirect interaction mechanism inherently renders the overall system underactuated. To address this issue, we first construct separate CBFs for the dual objectives of goal reaching and collision avoidance, which ensure both herding completion and safety guarantees. Then, we reformulate the underactuated herding dynamics into a control-affine structure and employ a backstepping approach to recursively design control inputs for the hierarchical barrier functions, avoiding taking derivatives of the higher-order system. Finally, we present a cooperative herding strategy based on backstepping CBFs that allow herders to safely herd multiple evaders into the goal region. In addition, centralized and decentralized implementations of the proposed algorithm are developed, further enhancing its flexibility and applicability. Extensive simulations and real-world experiments validate the effectiveness and safety of the proposed strategy in multi-robot herding.",
      "authors": [
        "Kang Li",
        "Ming Li",
        "Wenkang Ji",
        "Zhiyong Sun",
        "Shiyu Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:16:35+00:00",
          "link": "https://arxiv.org/abs/2507.10249v1",
          "size": "2939kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Robot Cooperative Herding through Backstepping Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10249",
        "HTML": "https://arxiv.org/html/2507.10249v1",
        "PDF": "https://arxiv.org/pdf/2507.10249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a cooperative herding strategy for multi-robot systems, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10489",
      "abstract": "The growing reliance on data-driven applications in sectors such as healthcare, finance, and law enforcement underscores the need for secure, privacy-preserving, and scalable mechanisms for data generation and sharing. Synthetic data generation (SDG) has emerged as a promising approach but often relies on centralized or external processing, raising concerns about data sovereignty, domain ownership, and compliance with evolving regulatory standards. To overcome these issues, we introduce SynthGuard, a framework designed to ensure computational governance by enabling data owners to maintain control over SDG workflows. SynthGuard supports modular and privacy-preserving workflows, ensuring secure, auditable, and reproducible execution across diverse environments. In this paper, we demonstrate how SynthGuard addresses the complexities at the intersection of domain-specific needs and scalable SDG by aligning with requirements for data sovereignty and regulatory compliance. Developed iteratively with domain expert input, SynthGuard has been validated through real-world use cases, demonstrating its ability to balance security, privacy, and scalability while ensuring compliance. The evaluation confirms its effectiveness in implementing and executing SDG workflows and integrating privacy and utility assessments across various computational environments.",
      "authors": [
        "Eduardo Brito",
        "Mahmoud Shoush",
        "Kristian Tamm",
        "Paula Etti and Liina Kamm"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:11:20+00:00",
          "link": "https://arxiv.org/abs/2507.10489v1",
          "size": "2482kb",
          "version": "v1"
        }
      ],
      "title": "SynthGuard: Redefining Synthetic Data Generation with a Scalable and Privacy-Preserving Workflow Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10489",
        "HTML": "https://arxiv.org/html/2507.10489v1",
        "PDF": "https://arxiv.org/pdf/2507.10489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents SynthGuard, a framework for synthetic data generation involving workflows that emphasize privacy, scalability, and regulatory compliance, contributing significantly to data processing methods for creating datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10552",
      "abstract": "Camera traps are revolutionising wildlife monitoring by capturing vast amounts of visual data; however, the manual identification of individual animals remains a significant bottleneck. This study introduces a fully self-supervised approach to learning robust chimpanzee face embeddings from unlabeled camera-trap footage. Leveraging the DINOv2 framework, we train Vision Transformers on automatically mined face crops, eliminating the need for identity labels. Our method demonstrates strong open-set re-identification performance, surpassing supervised baselines on challenging benchmarks such as Bossou, despite utilising no labelled data during training. This work underscores the potential of self-supervised learning in biodiversity monitoring and paves the way for scalable, non-invasive population studies.",
      "authors": [
        "Vladimir Iashin",
        "Horace Lee",
        "Dan Schofield",
        "Andrew Zisserman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:59+00:00",
          "link": "https://arxiv.org/abs/2507.10552v1",
          "size": "2369kb",
          "version": "v1"
        }
      ],
      "title": "Self-supervised Learning on Camera Trap Footage Yields a Strong Universal Face Embedder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10552",
        "HTML": "https://arxiv.org/html/2507.10552v1",
        "PDF": "https://arxiv.org/pdf/2507.10552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses self-supervised learning for creating embeddings from visual data, which involves training a model but does not focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.14770",
      "abstract": "Direct-attached accelerators, where application accelerators are directly connected to the datacenter network via a hardware network stack, offer substantial benefits in terms of reduced latency, CPU overhead, and energy use. However, a key challenge is that modern datacenter network stacks are complex, with interleaved protocol layers, network management functions, and virtualization support. To operators, network feature agility, diagnostics, and manageability are often considered just as important as raw performance. By contrast, existing hardware network stacks only support basic protocols and are often difficult to extend since they use fixed processing pipelines.\n  We propose Beehive, a new, open-source FPGA network stack for direct-attached accelerators designed to enable flexible and adaptive construction of complex network functionality in hardware. Application and network protocol elements are modularized as tiles over a network-on-chip substrate. Elements can be added or scaled up/down to match workload characteristics with minimal effort or changes to other elements. Flexible diagnostics and control are integral, with tooling to ensure deadlock safety. Our implementation interoperates with standard Linux TCP and UDP clients, with a 4x improvement in end-to-end RPC tail latency for Linux UDP clients versus a CPU-attached accelerator. Beehive is available at https://github.com/beehive-fpga/beehive",
      "authors": [
        "Katie Lim",
        "Matthew Giordano",
        "Theano Stavrinos",
        "Irene Zhang",
        "Jacob Nelson",
        "Baris Kasikci",
        "Tom Anderson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-21T18:16:46+00:00",
          "link": "https://arxiv.org/abs/2403.14770v1",
          "size": "1361kb",
          "version": "v1"
        },
        {
          "date": "2024-04-11T07:24:48+00:00",
          "link": "https://arxiv.org/abs/2403.14770v2",
          "size": "1361kb",
          "version": "v2"
        },
        {
          "date": "2024-04-13T06:49:32+00:00",
          "link": "https://arxiv.org/abs/2403.14770v3",
          "size": "1361kb",
          "version": "v3"
        },
        {
          "date": "2024-05-30T19:25:18+00:00",
          "link": "https://arxiv.org/abs/2403.14770v4",
          "size": "4722kb",
          "version": "v4"
        },
        {
          "date": "2024-09-11T23:44:12+00:00",
          "link": "https://arxiv.org/abs/2403.14770v5",
          "size": "7822kb",
          "version": "v5"
        }
      ],
      "title": "Beehive: A Flexible Network Stack for Direct-Attached Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.14770",
        "HTML": "https://arxiv.org/html/2403.14770",
        "PDF": "https://arxiv.org/pdf/2403.14770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a network stack for accelerators and does not mention any aspect of LLM training data processing or data engineering methods aimed at enhancing LLM training data quality."
      },
      "repo_urls": [
        "https://github.com/beehive-fpga/beehive"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06112",
      "abstract": "Recommendation model interpretation aims to reveal models' calculation process, enhancing their transparency, interpretability, and trustworthiness by clarifying the relationships between inputs, model activations, and outputs. However, the complex, often opaque nature of deep learning models complicates interpretation, and most existing methods are tailored to specific model architectures, limiting their generalizability across different types of recommendation models. To address these challenges, we propose RecSAE, an automated and generalizable probing framework that interprets Recommenders with Sparse AutoEncoder. It extracts interpretable latents from the internal states of recommendation models and links them to semantic concepts for interpretation. RecSAE does not alter original models during interpretation and also enables targeted de-biasing to models based on interpreted results. Specifically, RecSAE operates in three steps: First, it probes activations before the prediction layer to capture internal representations. Next, the RecSAE module is trained on these activations with a larger latent space and sparsity constraints, making the RecSAE latents more mono-semantic than the original model activations. Thirdly, RecSAE utilizes a language model to construct concept descriptions with confidence scores based on the relationships between latent activations and recommendation outputs. Experiments on three types of models (general, graph-based, and sequential) with three widely used datasets demonstrate the effectiveness and generalization of RecSAE framework. The interpreted concepts are further validated by human experts, showing strong alignment with human perception. Overall, RecSAE serves as a novel step in both model-level interpretations to various types of recommenders without affecting their functions and offering the potential for targeted tuning of models.",
      "authors": [
        "Jiayin Wang",
        "Xiaoyu Zhang",
        "Weizhi Ma",
        "Zhiqiang Guo",
        "Min Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-09T08:22:31+00:00",
          "link": "https://arxiv.org/abs/2411.06112v1",
          "size": "6137kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:07:27+00:00",
          "link": "https://arxiv.org/abs/2411.06112v2",
          "size": "2370kb",
          "version": "v2"
        }
      ],
      "title": "Interpret the Internal States of Recommendation Model with Sparse Autoencoder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06112",
        "HTML": "https://arxiv.org/html/2411.06112v2",
        "PDF": "https://arxiv.org/pdf/2411.06112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model interpretation of recommendation models using a Sparse Autoencoder. There is no mention of LLM training data processing or data engineering contributions."
      },
      "tasks": [
        "Explainable Recommendation",
        "Fairness",
        "Recommendation Systems"
      ],
      "repo_urls": [
        "https://github.com/alice1998/recsae"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18746",
      "abstract": "Recent advances in Large Language Models have led to remarkable achievements across a variety of Natural Language Processing tasks, making prompt engineering increasingly central to guiding model outputs. While manual methods can be effective, they typically rely on intuition and do not automatically refine prompts over time. In contrast, automatic prompt optimization employing heuristic-based search algorithms can systematically explore and improve prompts with minimal human oversight. This survey proposes a comprehensive taxonomy of these methods, categorizing them by where optimization occurs, what is optimized, what criteria drive the optimization, which operators generate new prompts, and which iterative search algorithms are applied. We further highlight specialized datasets and tools that support and accelerate automated prompt refinement. We conclude by discussing key open challenges pointing toward future opportunities for more robust and versatile LLM applications.",
      "authors": [
        "Wendi Cui",
        "Zhuohang Li",
        "Hao Sun",
        "Damien Lopez",
        "Kamalika Das",
        "Bradley A. Malin",
        "Sricharan Kumar",
        "Jiaxin Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T01:42:08+00:00",
          "link": "https://arxiv.org/abs/2502.18746v1",
          "size": "71kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T20:39:40+00:00",
          "link": "https://arxiv.org/abs/2502.18746v2",
          "size": "74kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of Automatic Prompt Optimization with Instruction-focused Heuristic-based Search Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18746",
        "HTML": "https://arxiv.org/html/2502.18746v2",
        "PDF": "https://arxiv.org/pdf/2502.18746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey on automatic prompt optimization focuses on guiding model outputs and prompt refinement, without addressing LLM training data processing or creation."
      },
      "tasks": [
        "Heuristic Search",
        "Prompt Engineering",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09397",
      "abstract": "The growing gap between the increasing complexity of large language models (LLMs) and the limited computational budgets of edge devices poses a key challenge for efficient on-device inference, despite gradual improvements in hardware capabilities. Existing strategies, such as aggressive quantization, pruning, or remote inference, trade accuracy for efficiency or lead to substantial cost burdens. This position paper introduces a new framework that leverages speculative decoding, previously viewed primarily as a decoding acceleration technique for autoregressive generation of LLMs, as a promising approach specifically adapted for edge computing by orchestrating computation across heterogeneous devices. We propose \\acronym, a framework that allows lightweight edge devices to draft multiple candidate tokens locally using diverse draft models, while a single, shared edge server verifies the tokens utilizing a more precise target model. To further increase the efficiency of verification, the edge server batch the diverse verification requests from devices. This approach supports device heterogeneity and reduces server-side memory footprint by sharing the same upstream target model across multiple devices. Our initial experiments with Jetson Orin Nano, Raspberry Pi 4B/5, and an edge server equipped with 4 Nvidia A100 GPUs indicate substantial benefits: 2.2 more system throughput, 2.8 more system capacity, and better cost efficiency, all without sacrificing model accuracy.",
      "authors": [
        "Xiangchen Li",
        "Dimitrios Spatharakis",
        "Saeid Ghafouri",
        "Jiakun Fan",
        "Hans Vandierendonck",
        "Deepu John",
        "Bo Ji",
        "Dimitrios Nikolopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T04:55:54+00:00",
          "link": "https://arxiv.org/abs/2506.09397v1",
          "size": "517kb",
          "version": "v1"
        },
        {
          "date": "2025-06-20T20:15:09+00:00",
          "link": "https://arxiv.org/abs/2506.09397v2",
          "size": "575kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T22:37:25+00:00",
          "link": "https://arxiv.org/abs/2506.09397v3",
          "size": "650kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T20:02:58+00:00",
          "link": "https://arxiv.org/abs/2506.09397v4",
          "size": "650kb",
          "version": "v4"
        }
      ],
      "title": "SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09397",
        "HTML": "https://arxiv.org/html/2506.09397v4",
        "PDF": "https://arxiv.org/pdf/2506.09397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a speculative decoding framework for improved inference efficiency on edge devices, which does not involve LLM training data processing or engineering."
      },
      "tasks": [
        "Edge-computing",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03278",
      "abstract": "Recent advances in Transformer models, e.g., large language models (LLMs), have brought tremendous breakthroughs in various artificial intelligence (AI) tasks, leading to their wide applications in many security-critical domains. Due to their unprecedented scale and prohibitively high development cost, these models have become highly valuable intellectual property for AI stakeholders and are increasingly deployed via machine learning as a service (MLaaS). However, MLaaS often runs on untrusted cloud infrastructure, exposing data and models to potential breaches. Mainstream protection mechanisms leverage trusted execution environments (TEEs) where confidentiality and integrity for secretive data are shielded using hardware-based encryption and integrity checking. Unfortunately, running model inference entirely within TEEs is subject to non-trivial slowdown, which is further exacerbated in LLMs due to the substantial computation and memory footprint involved. Recent studies reveal that the hybrid TEE-based scheme offloading partial model inference operations to the untrusted accelerators (e.g., GPU) is a promising solution. However, prior offloading schemes fail to ensure dual protection of data and model in Transformer inference, as they cannot securely offload critical operations, i.e., Attention and SoftMax, forcing these computations to remain confined within TEEs. To address these challenges, we propose TwinShield, a framework enabling secure Transformer inference in heterogeneous TEE and accelerator systems with dual protection for both model and data. TwinShield offloads ~87% of computation to GPUs and delivers 4.0x - 6.1x speedups over previous approaches across various Transformer models.",
      "authors": [
        "Jiaqi Xue",
        "Yifei Zhao",
        "Mengxin Zheng",
        "Fan Yao",
        "Yan Solihin",
        "Qian Lou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T03:52:53+00:00",
          "link": "https://arxiv.org/abs/2507.03278v1",
          "size": "5398kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T01:36:44+00:00",
          "link": "https://arxiv.org/abs/2507.03278v2",
          "size": "5398kb",
          "version": "v2"
        }
      ],
      "title": "Securing Transformer-based AI Execution via Unified TEEs and Crypto-protected Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03278",
        "HTML": "https://arxiv.org/html/2507.03278v2",
        "PDF": "https://arxiv.org/pdf/2507.03278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses securing Transformer-based AI execution but does not focus on any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09377",
      "abstract": "The Minimum Vertex Cover problem, a classical NP-complete problem, presents significant challenges for exact solution on large graphs. Fixed-Parameter Tractability (FPT) offers a powerful paradigm to address such problems by exploiting a parameter of the input, typically related to the size of the desired solution. This paper presents an implementation and empirical evaluation of an FPT algorithm for the Minimum Vertex Cover problem parameterized by the size of the vertex cover, $k$. The algorithm utilizes a branching strategy based on selecting adjacent vertices and recursively solving subproblems on a reduced graph. We describe the algorithmic approach, implementation details in Python, and present experimental results comparing its performance against the SageMath computational system. The results demonstrate that the FPT implementation achieves significant performance improvements for instances with large numbers of vertices ($n$) but relatively small values of the parameter ($k$), aligning with theoretical FPT complexity guarantees. We also discuss potential optimizations that could further improve the algorithm's performance, particularly concerning the branching factor.",
      "authors": [
        "Mumuksh Tayal"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:49:32+00:00",
          "link": "https://arxiv.org/abs/2507.09377v1",
          "size": "127kb",
          "version": "v1"
        }
      ],
      "title": "A Fixed Parameter Tractable Approach for Solving the Vertex Cover Problem in Polynomial Time Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09377",
        "HTML": "https://arxiv.org/html/2507.09377v1",
        "PDF": "https://arxiv.org/pdf/2507.09377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a fast algorithm for solving the vertex cover problem, focusing on the implementation and improvement of a specific algorithm related to graph theory, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09477",
      "abstract": "Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.",
      "authors": [
        "Yangning Li",
        "Weizhi Zhang",
        "Yuyao Yang",
        "Wei-Chieh Huang",
        "Yaozu Wu",
        "Junyu Luo",
        "Yuanchen Bei",
        "Henry Peng Zou",
        "Xiao Luo",
        "Yusheng Zhao",
        "Chunkit Chan",
        "Yankai Chen",
        "Zhongfen Deng",
        "Yinghui Li",
        "Hai-Tao Zheng",
        "Dongyuan Li",
        "Renhe Jiang",
        "Ming Zhang",
        "Yangqiu Song",
        "Philip S. Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:29:41+00:00",
          "link": "https://arxiv.org/abs/2507.09477v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09477",
        "PDF": "https://arxiv.org/pdf/2507.09477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on improving reasoning and retrieval capabilities in large language models (LLMs) through RAG-reasoning systems, without concentrating on LLM training data processing or enhancement techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09556",
      "abstract": "Due to the limitation of the optical lens focal length and the resolution of the infrared detector, distant Closely-Spaced Infrared Small Target (CSIST) groups typically appear as mixing spots in the infrared image. In this paper, we propose a novel task, Sequential CSIST Unmixing, namely detecting all targets in the form of sub-pixel localization from a highly dense CSIST group. However, achieving such precise detection is an extremely difficult challenge. In addition, the lack of high-quality public datasets has also restricted the research progress. To this end, firstly, we contribute an open-source ecosystem, including SeqCSIST, a sequential benchmark dataset, and a toolkit that provides objective evaluation metrics for this special task, along with the implementation of 23 relevant methods. Furthermore, we propose the Deformable Refinement Network (DeRefNet), a model-driven deep learning framework that introduces a Temporal Deformable Feature Alignment (TDFA) module enabling adaptive inter-frame information aggregation. To the best of our knowledge, this work is the first endeavor to address the CSIST Unmixing task within a multi-frame paradigm. Experiments on the SeqCSIST dataset demonstrate that our method outperforms the state-of-the-art approaches with mean Average Precision (mAP) metric improved by 5.3\\%. Our dataset and toolkit are available from https://github.com/GrokCV/SeqCSIST.",
      "authors": [
        "Ximeng Zhai and Bohan Xu and Yaohong Chen and Hao Wang and Kehua Guo and Yimian Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T09:59:48+00:00",
          "link": "https://arxiv.org/abs/2507.09556v1",
          "size": "2622kb",
          "version": "v1"
        }
      ],
      "title": "SeqCSIST: Sequential Closely-Spaced Infrared Small Target Unmixing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09556",
        "HTML": "https://arxiv.org/html/2507.09556v1",
        "PDF": "https://arxiv.org/pdf/2507.09556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a task related to infrared target detection and dataset creation for this task, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09574",
      "abstract": "Recent text-to-image models produce high-quality results but still struggle with precise visual control, balancing multimodal inputs, and requiring extensive training for complex multimodal image generation. To address these limitations, we propose MENTOR, a novel autoregressive (AR) framework for efficient Multimodal-conditioned Tuning for Autoregressive multimodal image generation. MENTOR combines an AR image generator with a two-stage training paradigm, enabling fine-grained, token-level alignment between multimodal inputs and image outputs without relying on auxiliary adapters or cross-attention modules. The two-stage training consists of: (1) a multimodal alignment stage that establishes robust pixel- and semantic-level alignment, followed by (2) a multimodal instruction tuning stage that balances the integration of multimodal inputs and enhances generation controllability. Despite modest model size, suboptimal base components, and limited training resources, MENTOR achieves strong performance on the DreamBench++ benchmark, outperforming competitive baselines in concept preservation and prompt following. Additionally, our method delivers superior image reconstruction fidelity, broad task adaptability, and improved training efficiency compared to diffusion-based methods. Dataset, code, and models are available at: https://github.com/HaozheZhao/MENTOR",
      "authors": [
        "Haozhe Zhao",
        "Zefan Cai",
        "Shuzheng Si",
        "Liang Chen",
        "Jiuxiang Gu",
        "Wen Xiao",
        "Junjie Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:52:59+00:00",
          "link": "https://arxiv.org/abs/2507.09574v1",
          "size": "5348kb",
          "version": "v1"
        }
      ],
      "title": "MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09574",
        "HTML": "https://arxiv.org/html/2507.09574v1",
        "PDF": "https://arxiv.org/pdf/2507.09574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for multimodal image generation with emphasis on model architecture and alignment techniques, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09894",
      "abstract": "In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform is a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic localized function with specific periods along delay and Doppler. When the channel delay spread is less than the delay period, and the channel Doppler spread is less than the Doppler period, the response to a single Zak-OTFS carrier provides an image of the scattering environment and can be used to predict the effective channel at all other carriers. The image of the scattering environment changes slowly, making it possible to employ precoding at the transmitter. Precoding techniques were developed more than thirty years ago for wireline modem channels (V.34 standard) defined by linear convolution where a pulse in the time domain (TD) is used to probe the one-dimensional partial response channel. The action of a doubly spread channel on Zak-OTFS modulation determines a two-dimensional partial response channel defined by twisted convolution, and we develop a novel precoding technique for this channel. The proposed precoder leads to separate equalization of each DD carrier which has significantly lower complexity than joint equalization of all carriers. Further, the effective precoded channel results in non-interfering DD carriers which significantly reduces the overhead of guard carriers separating data and pilot carriers, which improves the spectral efficiency significantly.",
      "authors": [
        "Saif Khan Mohammed",
        "Amit Kumar Pathak",
        "Muhammad Ubadah",
        "Ronny Hadani",
        "Ananthanarayanan Chockalingam and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:58:48+00:00",
          "link": "https://arxiv.org/abs/2507.09894v1",
          "size": "699kb",
          "version": "v1"
        }
      ],
      "title": "Precoded Zak-OTFS for Per-Carrier Equalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09894",
        "HTML": "https://arxiv.org/html/2507.09894v1",
        "PDF": "https://arxiv.org/pdf/2507.09894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a modulation technique (Zak-OTFS) for communication systems and does not address any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1406.1886",
      "abstract": "This paper provides the first comprehensive description of the Z1, the mechanical computer built by the German inventor Konrad Zuse in Berlin from 1936 to 1938. The paper describes the main structural elements of the machine, the high-level architecture, and the dataflow between components. The computer could perform the four basic arithmetic operations using floating-point numbers. Instructions were read from punched tape. A program consisted of a sequence of arithmetical operations, intermixed with memory store and load instructions, interrupted possibly by input and output operations. Numbers were stored in a mechanical memory. The machine did not include conditional branching in the instruction set. While the architecture of the Z1 is similar to the relay computer Zuse finished in 1941 (the Z3) there are some significant differences. The Z1 implements operations as sequences of microinstructions, as in the Z3, but does not use rotary switches as micro-steppers. The Z1 uses a digital incrementer and a set of conditions which are translated into microinstructions for the exponent and mantissa units, as well as for the memory blocks. Microinstructions select one out of 12 layers in a machine with a 3D mechanical structure of binary mechanical elements. The exception circuits for mantissa zero, necessary for normalized floating-point, were lacking; they were first implemented in the Z3. The information for this article was extracted from careful study of the blueprints drawn by Zuse for the reconstruction of the Z1 for the German Technology Museum in Berlin, from some letters, and from sketches in notebooks. Although the machine has been in exhibition since 1989 (non-operational), no detailed high-level description of the machine's architecture had been available. This paper fills that gap.",
      "authors": [
        "Raul Rojas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2014-06-07T11:23:31+00:00",
          "link": "https://arxiv.org/abs/1406.1886v1",
          "size": "2153kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T16:03:37+00:00",
          "link": "https://arxiv.org/abs/1406.1886v2",
          "size": "9256kb",
          "version": "v2"
        }
      ],
      "title": "The Z1: Architecture and Algorithms of Konrad Zuse's First Computer",
      "links": {
        "Abstract": "https://arxiv.org/abs/1406.1886",
        "PDF": "https://arxiv.org/pdf/1406.1886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes the architecture and algorithms of the Z1 computer, focusing on historical computing machinery rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.06377",
      "abstract": "Large language models (LLMs) have emerged as a cutting-edge approach in sequential recommendation, leveraging historical interactions to model dynamic user preferences. Current methods mainly focus on learning processed recommendation data in the form of sequence-to-sequence text. While effective, they exhibit three key limitations: 1) failing to decouple intra-user explicit features (e.g., product titles) from implicit behavioral patterns (e.g., brand loyalty) within interaction histories; 2) underutilizing cross-user collaborative filtering (CF) signals; and 3) relying on inefficient reflection update strategies. To address this, We propose MoRE (Mixture of REflectors), which introduces three perspective-aware offline reflection processes to address these gaps. This decomposition directly resolves Challenges 1 (explicit/implicit ambiguity) and 2 (CF underutilization). Furthermore, MoRE's meta-reflector employs a self-improving strategy and a dynamic selection mechanism (Challenge 3) to adapt to evolving user preferences. First, two intra-user reflectors decouple explicit and implicit patterns from a user's interaction sequence, mimicking traditional recommender systems' ability to distinguish surface-level and latent preferences. A third cross-user reflector captures CF signals by analyzing user similarity patterns from multiple users' interactions. To optimize reflection quality, MoRE's meta-reflector employs a offline self-improving strategy that evaluates reflection impacts through comparisons of presence/absence and iterative refinement of old/new versions, with a online contextual bandit mechanism dynamically selecting the optimal perspective for recommendation for each user. Code: https://github.com/E-qin/MoRE-Rec.",
      "authors": [
        "Weicong Qin",
        "Yi Xu",
        "Weijie Yu",
        "Chenglei Shen",
        "Xiao Zhang",
        "Ming He",
        "Jianping Fan",
        "Jun Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T09:58:55+00:00",
          "link": "https://arxiv.org/abs/2409.06377v1",
          "size": "864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T14:32:15+00:00",
          "link": "https://arxiv.org/abs/2409.06377v2",
          "size": "610kb",
          "version": "v2"
        }
      ],
      "title": "MoRE: A Mixture of Reflectors Framework for Large Language Model-Based Sequential Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06377",
        "HTML": "https://arxiv.org/html/2409.06377v2",
        "PDF": "https://arxiv.org/pdf/2409.06377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a framework for sequential recommendation using LLMs, focusing on the use of processed recommendation data rather than the creation or detailed processing of LLM training data."
      },
      "tasks": [
        "Collaborative Filtering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08865",
      "abstract": "Extracting tables and key-value pairs from financial documents is essential for business workflows such as auditing, data analytics, and automated invoice processing. In this work, we introduce Spatial ModernBERT-a transformer-based model augmented with spatial embeddings-to accurately detect and extract tabular data and key-value fields from complex financial documents. We cast the extraction task as token classification across three heads: (1) Label Head, classifying each token as a label (e.g., PO Number, PO Date, Item Description, Quantity, Base Cost, MRP, etc.); (2) Column Head, predicting column indices; (3) Row Head, distinguishing the start of item rows and header rows. The model is pretrained on the PubTables-1M dataset, then fine-tuned on a financial document dataset, achieving robust performance through cross-entropy loss on each classification head. We propose a post-processing method to merge tokens using B-I-IB tagging, reconstruct the tabular layout, and extract key-value pairs. Empirical evaluation shows that Spatial ModernBERT effectively leverages both textual and spatial cues, facilitating highly accurate table and key-value extraction in real-world financial documents.",
      "authors": [
        "Javis AI Team: Amrendra Singh",
        "Maulik Shah",
        "Dharshan Sampath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:40:40+00:00",
          "link": "https://arxiv.org/abs/2507.08865v1",
          "size": "658kb",
          "version": "v1"
        }
      ],
      "title": "Spatial ModernBERT: Spatial-Aware Transformer for Table and Key-Value Extraction in Financial Documents at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08865",
        "HTML": "https://arxiv.org/html/2507.08865v1",
        "PDF": "https://arxiv.org/pdf/2507.08865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning and pretraining techniques on specific datasets, but it primarily focuses on model architecture and extraction tasks rather than substantive data processing innovations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09280",
      "abstract": "Power systems Unit Commitment (UC) problem determines the generator commitment schedule and dispatch decisions to realize the reliable and economic operation of power networks. The growing penetration of stochastic renewables and demand behaviors makes it necessary to solve the UC problem timely. It is possible to derive lightweight, faster-to-solve UC models via constraint screening to eliminate redundant constraints. However, the screening process remains computationally cumbersome due to the need of solving numerous linear programming (LP) problems. To reduce the number of LPs to solve, we introduce a novel perspective on such classic LP-based screening. Our key insights lie in the principle that redundant constraints will be satisfied by all vertices of the screened feasible region. Using the UC decision variables' bounds tightened by solving much fewer LPs, we build an outer approximation for the UC feasible region as the screened region. A matrix operation is then designed and applied to the outer approximation's vertices to identify all redundant constraints on-the-fly. Adjustments for the outer approximation are further explored to improve screening efficiency by considering the load operating range and cutting planes derived from UC cost and discrete unit status prediction. Extensive simulations are performed on a set of testbeds up to 2,383 buses to substantiate the effectiveness of the proposed schemes. Compared to classic LP-based screening, our schemes can achieve up to 8.8x acceleration while finding the same redundant constraints.",
      "authors": [
        "Xuan He",
        "Yuxin Pan",
        "Yize Chen",
        "Danny H.K. Tsang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:33:33+00:00",
          "link": "https://arxiv.org/abs/2507.09280v1",
          "size": "5156kb",
          "version": "v1"
        }
      ],
      "title": "Vertex-Guided Redundant Constraints Identification for Unit Commitment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09280",
        "HTML": "https://arxiv.org/html/2507.09280v1",
        "PDF": "https://arxiv.org/pdf/2507.09280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for identifying redundant constraints in power systems, unrelated to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09790",
      "abstract": "Software systems usually provide numerous configuration options that can affect performance metrics such as execution time, memory usage, binary size, or bitrate. On the one hand, making informed decisions is challenging and requires domain expertise in options and their combinations. On the other hand, machine learning techniques can search vast configuration spaces, but with a high computational cost, since concrete executions of numerous configurations are required. In this exploratory study, we investigate whether large language models (LLMs) can assist in performance-oriented software configuration through prompts. We evaluate several LLMs on tasks including identifying relevant options, ranking configurations, and recommending performant configurations across various configurable systems, such as compilers, video encoders, and SAT solvers. Our preliminary results reveal both positive abilities and notable limitations: depending on the task and systems, LLMs can well align with expert knowledge, whereas hallucinations or superficial reasoning can emerge in other cases. These findings represent a first step toward systematic evaluations and the design of LLM-based solutions to assist with software configuration.",
      "authors": [
        "Helge Spieker",
        "Th\\'eo Matricon",
        "Nassim Belmecheri",
        "J{\\o}rn Eirik Betten",
        "Gauthier Le Bartz Lyan",
        "Heraldo Borges",
        "Quentin Mazouni",
        "Dennis Gross",
        "Arnaud Gotlieb",
        "Mathieu Acher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:05:01+00:00",
          "link": "https://arxiv.org/abs/2507.09790v1",
          "size": "309kb",
          "version": "v1"
        }
      ],
      "title": "Prompting for Performance: Exploring LLMs for Configuring Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09790",
        "HTML": "https://arxiv.org/html/2507.09790v1",
        "PDF": "https://arxiv.org/pdf/2507.09790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for assisting in software configuration through prompts, not on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09795",
      "abstract": "Recent advancements in Vision-Language Models like CLIP have enabled zero-shot OOD detection by leveraging both image and textual label information. Among these, negative label-based methods such as NegLabel and CSP have shown promising results by utilizing a lexicon of words to define negative labels for distinguishing OOD samples. However, these methods suffer from detecting in-distribution samples as OOD due to negative labels that are subcategories of in-distribution labels or proper nouns. They also face limitations in handling images that match multiple in-distribution and negative labels. We propose NegRefine, a novel negative label refinement framework for zero-shot OOD detection. By introducing a filtering mechanism to exclude subcategory labels and proper nouns from the negative label set and incorporating a multi-matching-aware scoring function that dynamically adjusts the contributions of multiple labels matching an image, NegRefine ensures a more robust separation between in-distribution and OOD samples. We evaluate NegRefine on large-scale benchmarks, including ImageNet-1K. Source code is available at https://github.com/ah-ansari/NegRefine.",
      "authors": [
        "Amirhossein Ansari",
        "Ke Wang",
        "Pulei Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:15:30+00:00",
          "link": "https://arxiv.org/abs/2507.09795v1",
          "size": "782kb",
          "version": "v1"
        }
      ],
      "title": "NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09795",
        "HTML": "https://arxiv.org/html/2507.09795v1",
        "PDF": "https://arxiv.org/pdf/2507.09795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in zero-shot OOD detection methods using vision-language models, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09837",
      "abstract": "Relational databases underpin critical infrastructure across a wide range of domains, yet the design of generalizable pre-training strategies for learning from relational databases remains an open challenge due to task heterogeneity. Specifically, there exist infinitely many possible downstream tasks, as tasks are defined based on relational schema graphs, temporal dependencies, and SQL-defined label logics. An effective pre-training framework is desired to take these factors into account in order to obtain task-aware representations. By incorporating knowledge of the underlying distribution that drives label generation, downstream tasks can benefit from relevant side-channel information. To bridge this gap, we introduce Task Vector Estimation (TVE), a novel pre-training framework that constructs predictive supervisory signals via set-based aggregation over schema traversal graphs, explicitly modeling next-window relational dynamics. We formalize our approach through an information-theoretic lens, demonstrating that task-informed representations retain more relevant signals than those obtained without task priors. Extensive experiments on the RelBench benchmark show that TVE consistently outperforms traditional pre-training baselines. Our findings advocate for pre-training objectives that encode task heterogeneity and temporal structure as design principles for predictive modeling on relational databases.",
      "authors": [
        "Quang Truong",
        "Zhikai Chen",
        "Mingxuan Ju",
        "Tong Zhao",
        "Neil Shah",
        "Jiliang Tang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:17:21+00:00",
          "link": "https://arxiv.org/abs/2507.09837v1",
          "size": "1583kb",
          "version": "v1"
        }
      ],
      "title": "A Pre-training Framework for Relational Data with Information-theoretic Principles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09837",
        "HTML": "https://arxiv.org/html/2507.09837v1",
        "PDF": "https://arxiv.org/pdf/2507.09837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a pre-training framework for relational databases but focuses on task-aware representations rather than direct LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.14435",
      "abstract": "Accurately segmenting 3D curvilinear structures in medical imaging remains challenging due to their complex geometry and the scarcity of diverse, large-scale datasets for algorithm development and evaluation. In this paper, we use dendritic spine segmentation as a case study and address these challenges by introducing a novel Frenet--Serret Frame-based Decomposition, which decomposes 3D curvilinear structures into a globally \\( C^2 \\) continuous curve that captures the overall shape, and a cylindrical primitive that encodes local geometric properties. This approach leverages Frenet--Serret Frames and arc length parameterization to preserve essential geometric features while reducing representational complexity, facilitating data-efficient learning, improved segmentation accuracy, and generalization on 3D curvilinear structures. To rigorously evaluate our method, we introduce two datasets: CurviSeg, a synthetic dataset for 3D curvilinear structure segmentation that validates our method's key properties, and DenSpineEM, a benchmark for dendritic spine segmentation, which comprises 4,476 manually annotated spines from 70 dendrites across three public electron microscopy datasets, covering multiple brain regions and species. Our experiments on DenSpineEM demonstrate exceptional cross-region and cross-species generalization: models trained on the mouse somatosensory cortex subset achieve 91.9\\% Dice, maintaining strong performance in zero-shot segmentation on both mouse visual cortex (94.1\\% Dice) and human frontal lobe (81.8\\% Dice) subsets. Moreover, we test the generalizability of our method on the IntrA dataset, where it achieves 77.08\\% Dice (5.29\\% higher than prior arts) on intracranial aneurysm segmentation. These findings demonstrate the potential of our approach for accurately analyzing complex curvilinear structures across diverse medical imaging fields.",
      "authors": [
        "Leslie Gu",
        "Jason Ken Adhinarta",
        "Mikhail Bessmeltsev",
        "Jiancheng Yang",
        "Yongjie Jessica Zhang",
        "Wenjie Yin",
        "Daniel Berger",
        "Jeff Lichtman",
        "Hanspeter Pfister",
        "Donglai Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-19T16:40:24+00:00",
          "link": "https://arxiv.org/abs/2404.14435v1",
          "size": "4155kb",
          "version": "v1"
        },
        {
          "date": "2024-10-24T18:18:04+00:00",
          "link": "https://arxiv.org/abs/2404.14435v2",
          "size": "3361kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T01:22:39+00:00",
          "link": "https://arxiv.org/abs/2404.14435v3",
          "size": "3871kb",
          "version": "v3"
        }
      ],
      "title": "Frenet-Serret Frame-based Decomposition for Part Segmentation of 3D Curvilinear Structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14435",
        "HTML": "https://arxiv.org/html/2404.14435v3",
        "PDF": "https://arxiv.org/pdf/2404.14435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for segmenting 3D curvilinear structures in medical imaging and introduces new datasets for this purpose, but it does not pertain to LLM training data processing."
      },
      "tasks": [
        "ARC",
        "Segmentation",
        "Zero Shot Segmentation"
      ],
      "repo_urls": [
        "https://github.com/vcg/ffd4denspineem"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03478",
      "abstract": "We propose deep learning methods for classical Monge's optimal mass transportation problems, where where the distribution constraint is treated as penalty terms defined by the maximum mean discrepancy in the theory of Hilbert space embeddings of probability measures. We prove that the transport maps given by the proposed methods converge to optimal transport maps in the problem with $L^2$ cost. Several numerical experiments validate our methods. In particular, we show that our methods are applicable to large-scale Monge problems.",
      "authors": [
        "Takafumi Saito and Yumiharu Nakano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T17:09:29+00:00",
          "link": "https://arxiv.org/abs/2412.03478v1",
          "size": "160kb",
          "version": "v1"
        },
        {
          "date": "2024-12-21T13:57:29+00:00",
          "link": "https://arxiv.org/abs/2412.03478v2",
          "size": "84kb",
          "version": "v2"
        },
        {
          "date": "2025-01-17T14:38:31+00:00",
          "link": "https://arxiv.org/abs/2412.03478v3",
          "size": "84kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T15:38:57+00:00",
          "link": "https://arxiv.org/abs/2412.03478v4",
          "size": "84kb",
          "version": "v4"
        }
      ],
      "title": "Solving Monge problem by Hilbert space embeddings of probability measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03478",
        "HTML": "https://arxiv.org/html/2412.03478v4",
        "PDF": "https://arxiv.org/pdf/2412.03478"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses transport maps convergence in optimal mass transportation problems, not related to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09256",
      "abstract": "Image-text matching is crucial for bridging the semantic gap between computer vision and natural language processing. However, existing methods still face challenges in handling high-order associations and semantic ambiguities among similar instances. These ambiguities arise from subtle differences between soft positive samples (semantically similar but incorrectly labeled) and soft negative samples (locally matched but globally inconsistent), creating matching uncertainties. Furthermore, current methods fail to fully utilize the neighborhood relationships among semantically similar instances within training batches, limiting the model's ability to learn high-order shared knowledge. This paper proposes the Ambiguity-Aware and High-order Relation learning framework (AAHR) to address these issues. AAHR constructs a unified representation space through dynamic clustering prototype contrastive learning, effectively mitigating the soft positive sample problem. The framework introduces global and local feature extraction mechanisms and an adaptive aggregation network, significantly enhancing full-grained semantic understanding capabilities. Additionally, AAHR employs intra-modal and inter-modal correlation matrices to investigate neighborhood relationships among sample instances thoroughly. It incorporates GNN to enhance semantic interactions between instances. Furthermore, AAHR integrates momentum contrastive learning to expand the negative sample set. These combined strategies significantly improve the model's ability to discriminate between features. Experimental results demonstrate that AAHR outperforms existing state-of-the-art methods on Flickr30K, MSCOCO, and ECCV Caption datasets, considerably improving the accuracy and efficiency of image-text matching. The code and model checkpoints for this research are available at https://github.com/Image-Text-Matching/AAHR .",
      "authors": [
        "Junyu Chen",
        "Yihua Gao",
        "Mingyuan Ge",
        "Mingyong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:30:32+00:00",
          "link": "https://arxiv.org/abs/2507.09256v1",
          "size": "28490kb",
          "version": "v1"
        }
      ],
      "title": "Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09256",
        "HTML": "https://arxiv.org/html/2507.09256v1",
        "PDF": "https://arxiv.org/pdf/2507.09256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving image-text matching through semantic relationships and contrastive learning but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09544",
      "abstract": "We study the problem of allocating indivisible chores among agents with additive cost functions in a fair and efficient manner. A major open question in this area is whether there always exists an allocation that is envy-free up to one chore (EF1) and Pareto optimal (PO). Our main contribution is to provide a positive answer to this question by proving the existence of such an allocation for indivisible chores under additive cost functions. This is achieved by a novel combination of a fixed point argument and a discrete algorithm, providing a significant methodological advance in this area.\n  Our additional key contributions are as follows. We show that there always exists an allocation that is EF1 and fractional Pareto optimal (fPO), where fPO is a stronger efficiency concept than PO. We also show that an EF1 and PO allocation can be computed in polynomial time when the number of agents is constant. Finally, we extend all of these results to the more general setting of weighted EF1 (wEF1), which accounts for the entitlements of agents.",
      "authors": [
        "Ryoga Mahara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T09:12:36+00:00",
          "link": "https://arxiv.org/abs/2507.09544v1",
          "size": "54kb",
          "version": "v1"
        }
      ],
      "title": "Existence of Fair and Efficient Allocation of Indivisible Chores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09544",
        "HTML": "https://arxiv.org/html/2507.09544v1",
        "PDF": "https://arxiv.org/pdf/2507.09544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on allocation of indivisible chores with fairness and efficiency, using mathematical and algorithmic techniques, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09681",
      "abstract": "High-resolution elevation estimations are essential to understand catchment and hillslope hydrology, study urban morphology and dynamics, and monitor the growth, decline, and mortality of terrestrial ecosystems. Various deep learning approaches (e.g., super-resolution techniques, monocular depth estimation) have been developed to create high-resolution Digital Elevation Models (DEMs). However, super-resolution techniques are limited by the upscaling factor, and monocular depth estimation lacks global elevation context, making its conversion to a seamless DEM restricted. The recently introduced technique of prompt-based monocular depth estimation has opened new opportunities to extract estimates of absolute elevation in a global context. We present here a framework for the estimation of high-resolution DEMs as a new paradigm for absolute global elevation mapping. It is exemplified using low-resolution Shuttle Radar Topography Mission (SRTM) elevation data as prompts and high-resolution RGB imagery from the National Agriculture Imagery Program (NAIP). The approach fine-tunes a vision transformer encoder with LiDAR-derived DEMs and employs a versatile prompting strategy, enabling tasks such as DEM estimation, void filling, and updating. Our framework achieves a 100x resolution gain (from 30-m to 30-cm), surpassing prior methods by an order of magnitude. Evaluations across three diverse U.S. landscapes show robust generalization, capturing urban structures and fine-scale terrain features with < 5 m MAE relative to LiDAR, improving over SRTM by up to 18%. Hydrological analysis confirms suitability for hazard and environmental studies. We demonstrate scalability by applying the framework to large regions in the U.S. and Israel. All code and pretrained models are publicly available at: https://osherr1996.github.io/prompt2dem_propage/.",
      "authors": [
        "Osher Rafaeli",
        "Tal Svoray and Ariel Nahlieli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:38:22+00:00",
          "link": "https://arxiv.org/abs/2507.09681v1",
          "size": "41601kb",
          "version": "v1"
        }
      ],
      "title": "Prompt2DEM: High-Resolution DEMs for Urban and Open Environments from Global Prompts Using a Monocular Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09681",
        "HTML": "https://arxiv.org/html/2507.09681v1",
        "PDF": "https://arxiv.org/pdf/2507.09681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for generating high-resolution Digital Elevation Models (DEMs), but it does not pertain to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09742",
      "abstract": "Nowadays, as AI-driven manufacturing becomes increasingly popular, the volume of data streams requiring real-time monitoring continues to grow. However, due to limited resources, it is impractical to place sensors at every location to detect unexpected shifts. Therefore, it is necessary to develop an optimal sensor placement strategy that enables partial observability of the system while detecting anomalies as quickly as possible. Numerous approaches have been proposed to address this challenge; however, most existing methods consider only variable correlations and neglect a crucial factor: Causality. Moreover, although a few techniques incorporate causal analysis, they rely on interventions-artificially creating anomalies-to identify causal effects, which is impractical and might lead to catastrophic losses. In this paper, we introduce a causality-informed deep Q-network (Causal DQ) approach for partially observable sensor placement in anomaly detection. By integrating causal information at each stage of Q-network training, our method achieves faster convergence and tighter theoretical error bounds. Furthermore, the trained causal-informed Q-network significantly reduces the detection time for anomalies under various settings, demonstrating its effectiveness for sensor placement in large-scale, real-world data streams. Beyond the current implementation, our technique's fundamental insights can be applied to various reinforcement learning problems, opening up new possibilities for real-world causality-informed machine learning methods in engineering applications.",
      "authors": [
        "Xiaofeng Xiao",
        "Bo Shen",
        "Xubo Yue"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T18:48:34+00:00",
          "link": "https://arxiv.org/abs/2507.09742v1",
          "size": "3138kb",
          "version": "v1"
        }
      ],
      "title": "Causality-informed Anomaly Detection in Partially Observable Sensor Networks: Moving beyond Correlations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09742",
        "HTML": "https://arxiv.org/html/2507.09742v1",
        "PDF": "https://arxiv.org/pdf/2507.09742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on sensor network anomaly detection using causality-informed reinforcement learning. It is unrelated to LLM training data processing or engineering necessary for language model training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09757",
      "abstract": "We introduce the Energy Dissipation Rate guided Adaptive Sampling (EDRAS) strategy, a novel method that substantially enhances the performance of Physics-Informed Neural Networks (PINNs) in solving thermodynamically consistent partial differential equations (PDEs) over arbitrary domains. EDRAS leverages the local energy dissipation rate density as a guiding metric to identify and adaptively re-sample critical collocation points from both the interior and boundary of the computational domain. This dynamical sampling approach improves the accuracy of residual-based PINNs by aligning the training process with the underlying physical structure of the system. In this study, we demonstrate the effectiveness of EDRAS using the Allen-Cahn phase field model in irregular geometries, achieving up to a sixfold reduction in the relative mean square error compared to traditional residual-based adaptive refinement (RAR) methods. Moreover, we compare EDRAS with other residual-based adaptive sampling approaches and show that EDRAS is not only computationally more efficient but also more likely to identify high-impact collocation points. Through numerical solutions of the Allen-Cahn equation with both static (Neumann) and dynamic boundary conditions in 2D disk- and ellipse-shaped domains solved using PINN coupled with EDRAS, we gain significant insights into how dynamic boundary conditions influence bulk phase evolution and thermodynamic behavior. The proposed approach offers an effective, physically informed enhancement to PINN frameworks for solving thermodynamically consistent models, making PINN a robust and versatile computational tool for investigating complex thermodynamic processes in arbitrary geometries.",
      "authors": [
        "Chunyan Li",
        "Wenkai Yu",
        "Qi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:34:58+00:00",
          "link": "https://arxiv.org/abs/2507.09757v1",
          "size": "11683kb",
          "version": "v1"
        }
      ],
      "title": "Energy Dissipation Rate Guided Adaptive Sampling for Physics-Informed Neural Networks: Resolving Surface-Bulk Dynamics in Allen-Cahn Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09757",
        "HTML": "https://arxiv.org/html/2507.09757v1",
        "PDF": "https://arxiv.org/pdf/2507.09757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an adaptive sampling strategy for Physics-Informed Neural Networks, focusing on solving thermodynamic equations. It does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.02811",
      "abstract": "Data-driven techniques for analysis, modeling, and control of complex dynamical systems are on the uptake. Koopman theory provides the theoretical foundation for the popular kernel extended dynamic mode decomposition (kEDMD). In this work, we propose a novel kEDMD scheme to approximate nonlinear control systems accompanied by an in-depth error analysis. Key features are regularization-based robustness and an adroit decomposition into micro and macro grids enabling flexible sampling. But foremost, we prove proportionality, i.e., explicit dependence on the distance to the (controlled) equilibrium, of the derived bound on the full approximation error. Leveraging this key property, we rigorously show that asymptotic stability of the data-driven surrogate (control) system implies asymptotic stability of the original (control) system and vice versa.",
      "authors": [
        "Lea Bold and Friedrich M. Philipp and Manuel Schaller and Karl Worthmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T20:21:30+00:00",
          "link": "https://arxiv.org/abs/2412.02811v1",
          "size": "1096kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:43:28+00:00",
          "link": "https://arxiv.org/abs/2412.02811v2",
          "size": "2127kb",
          "version": "v2"
        }
      ],
      "title": "Kernel-based Koopman approximants for control: Flexible sampling, error analysis, and stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02811",
        "HTML": "https://arxiv.org/html/2412.02811v2",
        "PDF": "https://arxiv.org/pdf/2412.02811"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the application of Koopman theory for control systems and stability analysis, which is unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.18275",
      "abstract": "Quantitative logic reasons about the degree to which formulas are satisfied. This paper studies the fundamental reasoning principles of higher-order quantitative logic and their application to reasoning about probabilistic programs and processes.\n  We construct an affine calculus for $1$-bounded complete metric spaces and the monad for probability measures equipped with the Kantorovic distance. The calculus includes a form of guarded recursion interpreted via Banach's fixed point theorem, useful, e.g., for recursive programming with processes. We then define an affine higher-order quantitative logic for reasoning about terms of our calculus. The logic includes novel principles for guarded recursion, and induction over probability measures and natural numbers.\n  We illustrate the expressivity of the logic by a sequence of case studies: Proving upper limits on bisimilarity distances of Markov processes, showing convergence of a temporal learning algorithm and of a random walk using a coupling argument. Finally we show how to encode a probabilistic Hoare logic in our logic.",
      "authors": [
        "Giorgio Bacci and Rasmus Ejlers M{\\o}gelberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T11:27:36+00:00",
          "link": "https://arxiv.org/abs/2501.18275v1",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T13:16:33+00:00",
          "link": "https://arxiv.org/abs/2501.18275v2",
          "size": "89kb",
          "version": "v2"
        }
      ],
      "title": "Induction and Recursion Principles in a Higher-Order Quantitative Logic for Probability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18275",
        "PDF": "https://arxiv.org/pdf/2501.18275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores principles of higher-order quantitative logic applied to probabilistic programs, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.00683",
      "abstract": "In the noisy intermediate-scale quantum (NISQ) era, quantum error mitigation (QEM) is essential for producing reliable outputs from quantum circuits. We present a statistical signal processing approach to QEM that estimates the most likely noiseless outputs from noisy quantum measurements. Our model assumes that circuit depth is sufficient for depolarizing noise, producing corrupted observations that resemble a uniform distribution alongside classical bit-flip errors from readout. Our method consists of two steps: a filtering stage that discards uninformative depolarizing noise and an expectation-maximization (EM) algorithm that computes a maximum likelihood (ML) estimate over the remaining data. We demonstrate the effectiveness of this approach on small-qubit systems using IBM circuit simulations in Qiskit and compare its performance to contemporary statistical QEM techniques. We also show that our method scales to larger qubit counts using synthetically generated data consistent with our noise model. These results suggest that principled statistical methods can offer scalable and interpretable solutions for quantum error mitigation in realistic NISQ settings.",
      "authors": [
        "Kausthubh Chandramouli",
        "Kelly Mae Allen",
        "Christopher Mori",
        "Dror Baron",
        "and M\\'ario A. T. Figueiredo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T19:34:19+00:00",
          "link": "https://arxiv.org/abs/2506.00683v1",
          "size": "147kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T22:20:04+00:00",
          "link": "https://arxiv.org/abs/2506.00683v2",
          "size": "144kb",
          "version": "v2"
        }
      ],
      "title": "Statistical Signal Processing for Quantum Error Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00683",
        "HTML": "https://arxiv.org/html/2506.00683v2",
        "PDF": "https://arxiv.org/pdf/2506.00683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on statistical signal processing for quantum error mitigation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08867",
      "abstract": "Machine learning (ML) techniques have recently enabled enormous gains in sensitivity across the sciences. In particle physics, much of this progress has relied on excellent simulations of a wide range of physical processes. However, due to the sophistication of modern machine learning (ML) algorithms and their reliance on high-quality training samples, discrepancies between simulation and experimental data can significantly limit the effectiveness of ML techniques. In this work, we present a solution to this ``mis-specification'' problem: a calibration approach based on optimal transport, which we apply to high-dimensional simulations for the first time. We demonstrate the performance of our approach through jet tagging, using a CMS-inspired dataset. A 128-dimensional internal jet representation from a powerful general-purpose classifier is studied; after calibrating this internal ``latent'' representation, we find that a wide variety of quantities derived from it for downstream tasks are also properly calibrated: using this calibrated high-dimensional representation, powerful new applications of jet flavor information can be utilized in LHC analyses. This is a key step toward allowing properly-calibrated ``foundation models'' in particle physics. More broadly, this calibration framework has broad applications for correcting high-dimensional simulations across the sciences.",
      "authors": [
        "Malte Algren",
        "Tobias Golling",
        "Francesco Armando Di Bello and Christopher Pollard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:28:21+00:00",
          "link": "https://arxiv.org/abs/2507.08867v1",
          "size": "3119kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Gap: Navigating Inference with Optimal Transport Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08867",
        "HTML": "https://arxiv.org/html/2507.08867v1",
        "PDF": "https://arxiv.org/pdf/2507.08867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a calibration approach using optimal transport for simulations in particle physics, rather than on processing LLM training data or creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09354",
      "abstract": "Integrated sensing and communication (ISAC) systems potentially encounter significant performance degradation in densely obstructed urban and non-line-of-sight scenarios, thus limiting their effectiveness in practical deployments. To deal with these challenges, this paper proposes a backscatter device (BD)-assisted ISAC system, which leverages passive BDs naturally distributed in underlying environments for performance enhancement. These ambient devices can enhance sensing accuracy and communication reliability by providing additional reflective signal paths. In this system, we define the Pareto boundary characterizing the trade-off between sensing mutual information (SMI) and communication rates to provide fundamental insights for its design. To derive the boundary, we formulate a performance optimization problem within an orthogonal frequency division multiplexing (OFDM) framework, by jointly optimizing time-frequency resource element (RE) allocation, transmit power management, and BD modulation decisions. To tackle the non-convexity of the problem, we decompose it into three subproblems, solved iteratively through a block coordinate descent (BCD) algorithm. Specifically, the RE subproblem is addressed using the successive convex approximation (SCA) method, the power subproblem is solved using an augmented Lagrangian combined water-filling method, and the BD modulation subproblem is tackled using semidefinite relaxation (SDR) methods. Additionally, we demonstrate the generality of the proposed system by showing its adaptability to bistatic ISAC scenarios and MIMO settings. Finally, extensive simulation results validate the effectiveness of the proposed system and its superior performance compared to existing state-of-the-art ISAC schemes.",
      "authors": [
        "Yifan Zhang",
        "Yu Bai",
        "Riku Jantti",
        "Zheng Yan",
        "Christos Masouros",
        "and Zhu Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T17:11:06+00:00",
          "link": "https://arxiv.org/abs/2507.09354v1",
          "size": "1370kb",
          "version": "v1"
        }
      ],
      "title": "Backscatter Device-aided Integrated Sensing and Communication: A Pareto Optimization Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09354",
        "HTML": "https://arxiv.org/html/2507.09354v1",
        "PDF": "https://arxiv.org/pdf/2507.09354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on performance enhancement for integrated sensing and communication systems rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09499",
      "abstract": "We present the DKU system for Task 2 of the MLC-SLM Challenge, which aims to perform multi-speaker automatic speech recognition directly from raw audio without Oracle speaker labels or time boundaries. Our approach builds upon a diarization-aware framework integrating speaker embeddings and temporal utterance boundaries into a Qwen2.5-based large language model (LLM). Then, we enhance the system's multilingual performance by fine-tuning language-specific adapters and LoRA modules within the LLM decoder. Finally, our system achieves the tcpWER of 23.56\\% and 18.08\\% on the development and test sets of the MLC-SLM dataset, substantially outperforming the official baseline.",
      "authors": [
        "Yuke Lin",
        "Ming Cheng",
        "Ze Li",
        "Ming Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:30:39+00:00",
          "link": "https://arxiv.org/abs/2507.09499v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "The DKU System for Multi-Speaker Automatic Speech Recognition in MLC-SLM Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09499",
        "HTML": "https://arxiv.org/html/2507.09499v1",
        "PDF": "https://arxiv.org/pdf/2507.09499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a system that enhances multilingual performance by fine-tuning specific adapters and modules within an LLM, which involves some degree of training-data processing during fine-tuning, but it primarily focuses on a diarization-aware framework and speech recognition, rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10150",
      "abstract": "The exploration and application of Large Language Models (LLMs) is thriving. To reduce deployment costs, continuous batching has become an essential feature in current service frameworks. The effectiveness of continuous batching relies on an accurate estimate of the memory requirements of requests. However, due to the diversity in request output lengths, existing frameworks tend to adopt aggressive or conservative schedulers, which often result in significant overestimation or underestimation of memory consumption. Consequently, they suffer from harmful request evictions or prolonged queuing times, failing to achieve satisfactory throughput under strict Service Level Agreement (SLA) guarantees (a.k.a. goodput), across various LLM application scenarios with differing input-output length distributions. To address this issue, we propose a novel Past-Future scheduler that precisely estimates the peak memory resources required by the running batch via considering the historical distribution of request output lengths and calculating memory occupancy at each future time point. It adapts to applications with all types of input-output length distributions, balancing the trade-off between request queuing and harmful evictions, thereby consistently achieving better goodput. Furthermore, to validate the effectiveness of the proposed scheduler, we developed a high-performance LLM serving framework, LightLLM, that implements the Past-Future scheduler. Compared to existing aggressive or conservative schedulers, LightLLM demonstrates superior goodput, achieving up to 2-3$\\times$ higher goodput than other schedulers under heavy loads. LightLLM is open source to boost the research in such direction (https://github.com/ModelTC/lightllm).",
      "authors": [
        "Ruihao Gong",
        "Shihao Bai",
        "Siyu Wu",
        "Yunqian Fan",
        "Zaijun Wang",
        "Xiuhong Li",
        "Hailong Yang",
        "Xianglong Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:53:47+00:00",
          "link": "https://arxiv.org/abs/2507.10150v1",
          "size": "4320kb",
          "version": "v1"
        }
      ],
      "title": "Past-Future Scheduler for LLM Serving under SLA Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10150",
        "HTML": "https://arxiv.org/html/2507.10150v1",
        "PDF": "https://arxiv.org/pdf/2507.10150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses LLM serving under SLA guarantees and does not cover aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10437",
      "abstract": "Existing methods for reconstructing animatable 3D animals from videos typically rely on sparse semantic keypoints to fit parametric models. However, obtaining such keypoints is labor-intensive, and keypoint detectors trained on limited animal data are often unreliable. To address this, we propose 4D-Animal, a novel framework that reconstructs animatable 3D animals from videos without requiring sparse keypoint annotations. Our approach introduces a dense feature network that maps 2D representations to SMAL parameters, enhancing both the efficiency and stability of the fitting process. Furthermore, we develop a hierarchical alignment strategy that integrates silhouette, part-level, pixel-level, and temporal cues from pre-trained 2D visual models to produce accurate and temporally coherent reconstructions across frames. Extensive experiments demonstrate that 4D-Animal outperforms both model-based and model-free baselines. Moreover, the high-quality 3D assets generated by our method can benefit other 3D tasks, underscoring its potential for large-scale applications. The code is released at https://github.com/zhongshsh/4D-Animal.",
      "authors": [
        "Shanshan Zhong",
        "Jiawei Peng",
        "Zehan Zheng",
        "Zhongzhan Huang",
        "Wufei Ma",
        "Guofeng Zhang",
        "Qihao Liu",
        "Alan Yuille",
        "Jieneng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:24:31+00:00",
          "link": "https://arxiv.org/abs/2507.10437v1",
          "size": "37917kb",
          "version": "v1"
        }
      ],
      "title": "4D-Animal: Freely Reconstructing Animatable 3D Animals from Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10437",
        "HTML": "https://arxiv.org/html/2507.10437v1",
        "PDF": "https://arxiv.org/pdf/2507.10437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for reconstructing 3D animals from videos without sparse keypoints, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.11593",
      "abstract": "In this paper we find an integer $h=h(n)$ such that the minimum number of variables of a first order sentence that distinguishes between two independent uniformly distributed random graphs of size $n$ with the asymptotically largest possible probability $\\frac{1}{4}-o(1)$ belongs to $\\{h,h+1,h+2,h+3\\}$. We also prove that the minimum (random) $k$ such that two independent random graphs are distinguishable by a first order sentence with $k$ variables belongs to $\\{h,h+1,h+2\\}$ with probability $1-o(1)$.",
      "authors": [
        "Itai Benjamini",
        "Maksim Zhukovskii"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-23T20:08:18+00:00",
          "link": "https://arxiv.org/abs/2207.11593v1",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "2022-08-02T12:34:09+00:00",
          "link": "https://arxiv.org/abs/2207.11593v2",
          "size": "15kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T22:02:30+00:00",
          "link": "https://arxiv.org/abs/2207.11593v3",
          "size": "43kb",
          "version": "v3"
        }
      ],
      "title": "A very sharp threshold for first order logic distinguishability of random graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.11593",
        "HTML": "https://arxiv.org/html/2207.11593v3",
        "PDF": "https://arxiv.org/pdf/2207.11593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the distinguishability of random graphs using first order logic and does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00838",
      "abstract": "Adjoint-based sensitivity analysis is of interest in computational science due to its ability to compute sensitivities at a lower cost with respect to several design parameters. However, conventional sensitivity analysis methods fail in the presence of chaotic flows. Popular approaches to chaotic sensitivity analysis of flows involve the use of the shadowing trajectory. The state-of-the-art approach computes the shadowing trajectory by solving a least squares minimization problem, resulting in a space-time linear system of equations. The current paper computes the adjoint shadowing trajectory using the stabilized march, by specifying the adjoint boundary conditions instead of solving a minimization problem. This approach results in a space-time linear system that can be solved through a single backward substitution of order $\\mathcal{O}(n_u^2)$ with $n_u$ being the dimension of the unstable subspace. It is proven to compute sensitivities that converge to the true sensitivity for large integration times and that the error in the sensitivity due to the discretization is of the order of the local truncation error of the scheme. The approach is numerically verified on the Lorentz 63 and Kuramoto-Sivasinsky equations.",
      "authors": [
        "Pranshul Thakur and Siva Nadarajah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T19:54:32+00:00",
          "link": "https://arxiv.org/abs/2505.00838v1",
          "size": "932kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T17:50:49+00:00",
          "link": "https://arxiv.org/abs/2505.00838v2",
          "size": "474kb",
          "version": "v2"
        }
      ],
      "title": "A stabilized march approach to adjoint-based sensitivity analysis of chaotic flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00838",
        "HTML": "https://arxiv.org/html/2505.00838v2",
        "PDF": "https://arxiv.org/pdf/2505.00838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with adjoint-based sensitivity analysis for chaotic flows and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08879",
      "abstract": "The growing availability and use of deepfake technologies increases risks for democratic societies, e.g., for political communication on online platforms. The EU has responded with transparency obligations for providers and deployers of Artificial Intelligence (AI) systems and online platforms. This includes marking deepfakes during generation and labeling deepfakes when they are shared. However, the lack of industry and enforcement standards poses an ongoing challenge. Through a multivocal literature review, we summarize methods for marking, detecting, and labeling deepfakes and assess their effectiveness under EU regulation. Our results indicate that individual methods fail to meet regulatory and practical requirements. Therefore, we propose a multi-level strategy combining the strengths of existing methods. To account for the masses of content on online platforms, our multi-level strategy provides scalability and practicality via a simple scoring mechanism. At the same time, it is agnostic to types of deepfake technology and allows for context-specific risk weighting.",
      "authors": [
        "Max-Paul F\\\"orster",
        "Luca Deck",
        "Raimund Weidlich and Niklas K\\\"uhl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:08:42+00:00",
          "link": "https://arxiv.org/abs/2507.08879v1",
          "size": "527kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Level Strategy for Deepfake Content Moderation under EU Regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08879",
        "HTML": "https://arxiv.org/html/2507.08879v1",
        "PDF": "https://arxiv.org/pdf/2507.08879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on methods for marking, detecting, and labeling deepfakes. It does not discuss LLM training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09160",
      "abstract": "Vision-Language-Action (VLA) models have shown remarkable achievements, driven by the rich implicit knowledge of their vision-language components. However, achieving generalist robotic agents demands precise grounding into physical interactions, especially in contact-rich scenarios where fine-grained force control is essential. We advance VLAs' implicit knowledge beyond identifying what to do, towards guiding how to physically interact with real world. This paper introduces Tactile-VLA, a novel framework that deeply fuses vision, language, action, and tactile sensing. This framework incorporates a hybrid position-force controller to translate the model's intentions into precise physical actions and a reasoning module that allows the robot to adapt its strategy based on tactile feedback. Experiments demonstrate Tactile-VLA's effectiveness and generalizability in three key aspects: (1) enabling tactile-aware instruction following, (2) utilizing tactile-relevant commonsense, and (3) facilitating adaptive tactile-involved reasoning. A key finding is that the VLM's prior knowledge already contains semantic understanding of physical interaction; by connecting it to the robot's tactile sensors with only a few demonstrations, we can activate this prior knowledge to achieve zero-shot generalization in contact-rich tasks.",
      "authors": [
        "Jialei Huang",
        "Shuo Wang",
        "Fanqi Lin",
        "Yihang Hu",
        "Chuan Wen",
        "Yang Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T06:44:37+00:00",
          "link": "https://arxiv.org/abs/2507.09160v1",
          "size": "18456kb",
          "version": "v1"
        }
      ],
      "title": "Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09160",
        "HTML": "https://arxiv.org/html/2507.09160v1",
        "PDF": "https://arxiv.org/pdf/2507.09160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on grounding Vision-Language-Action models into physical interactions and tactile sensing. It does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09566",
      "abstract": "A critical challenge in recommender systems is to establish reliable relationships between offline and online metrics that predict real-world performance. Motivated by recent advances in Pareto front approximation, we introduce a pragmatic strategy for identifying offline metrics that align with online impact. A key advantage of this approach is its ability to simultaneously serve multiple test groups, each with distinct offline performance metrics, in an online experiment controlled by a single model. The method is model-agnostic for systems with a neural network backbone, enabling broad applicability across architectures and domains. We validate the strategy through a large-scale online experiment in the field of session-based recommender systems on the OTTO e-commerce platform. The online experiment identifies significant alignments between offline metrics and real-word click-through rate, post-click conversion rate and units sold. Our strategy provides industry practitioners with a valuable tool for understanding offline-to-online metric relationships and making informed, data-driven decisions.",
      "authors": [
        "Timo Wilm",
        "Philipp Normann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:24:41+00:00",
          "link": "https://arxiv.org/abs/2507.09566v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Offline Metrics that Predict Online Impact: A Pragmatic Strategy for Real-World Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09566",
        "HTML": "https://arxiv.org/html/2507.09566v1",
        "PDF": "https://arxiv.org/pdf/2507.09566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses predicting online impact in recommender systems using metrics alignment strategies and does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09640",
      "abstract": "Diabetic retinopathy (DR) is a leading cause of vision loss in working-age adults. While screening reduces the risk of blindness, traditional imaging is often costly and inaccessible. Artificial intelligence (AI) algorithms present a scalable diagnostic solution, but concerns regarding fairness and generalization persist. This work evaluates the fairness and performance of image-trained models in DR prediction, as well as the impact of disentanglement as a bias mitigation technique, using the diverse mBRSET fundus dataset. Three models, ConvNeXt V2, DINOv2, and Swin V2, were trained on macula images to predict DR and sensitive attributes (SAs) (e.g., age and gender/sex). Fairness was assessed between subgroups of SAs, and disentanglement was applied to reduce bias. All models achieved high DR prediction performance in diagnosing (up to 94% AUROC) and could reasonably predict age and gender/sex (91% and 77% AUROC, respectively). Fairness assessment suggests disparities, such as a 10% AUROC gap between age groups in DINOv2. Disentangling SAs from DR prediction had varying results, depending on the model selected. Disentanglement improved DINOv2 performance (2% AUROC gain), but led to performance drops in ConvNeXt V2 and Swin V2 (7% and 3%, respectively). These findings highlight the complexity of disentangling fine-grained features in fundus imaging and emphasize the importance of fairness in medical imaging AI to ensure equitable and reliable healthcare solutions.",
      "authors": [
        "Leonor Fernandes",
        "Tiago Gon\\c{c}alves",
        "Jo\\~ao Matos",
        "Luis Filipe Nakayama",
        "Jaime S. Cardoso"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:11:41+00:00",
          "link": "https://arxiv.org/abs/2507.09640v1",
          "size": "971kb",
          "version": "v1"
        }
      ],
      "title": "Disentanglement and Assessment of Shortcuts in Ophthalmological Retinal Imaging Exams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09640",
        "HTML": "https://arxiv.org/html/2507.09640v1",
        "PDF": "https://arxiv.org/pdf/2507.09640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work evaluates AI algorithms for diabetic retinopathy prediction without involvement in LLM training data processing or dataset creation methods relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09860",
      "abstract": "This paper aims to propose a novel machine learning (ML) approach incorporating Homomorphic Encryption (HE) to address privacy limitations in Unmanned Aerial Vehicles (UAV)-based face detection. Due to challenges related to distance, altitude, and face orientation, high-resolution imagery and sophisticated neural networks enable accurate face recognition in dynamic environments. However, privacy concerns arise from the extensive surveillance capabilities of UAVs. To resolve this issue, we propose a novel framework that integrates HE with advanced neural networks to secure facial data throughout the inference phase. This method ensures that facial data remains secure with minimal impact on detection accuracy. Specifically, the proposed system leverages the Cheon-Kim-Kim-Song (CKKS) scheme to perform computations directly on encrypted data, optimizing computational efficiency and security. Furthermore, we develop an effective data encoding method specifically designed to preprocess the raw facial data into CKKS form in a Single-Instruction-Multiple-Data (SIMD) manner. Building on this, we design a secure inference algorithm to compute on ciphertext without needing decryption. This approach not only protects data privacy during the processing of facial data but also enhances the efficiency of UAV-based face detection systems. Experimental results demonstrate that our method effectively balances privacy protection and detection performance, making it a viable solution for UAV-based secure face detection. Significantly, our approach (while maintaining data confidentially with HE encryption) can still achieve an accuracy of less than 1% compared to the benchmark without using encryption.",
      "authors": [
        "Nguyen Van Duc",
        "Bui Duc Manh",
        "Quang-Trung Luu",
        "Dinh Thai Hoang",
        "Van-Linh Nguyen",
        "and Diep N. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:07:08+00:00",
          "link": "https://arxiv.org/abs/2507.09860v1",
          "size": "1841kb",
          "version": "v1"
        }
      ],
      "title": "Secure and Efficient UAV-Based Face Detection via Homomorphic Encryption and Edge Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09860",
        "PDF": "https://arxiv.org/pdf/2507.09860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on techniques for secure face detection using Homomorphic Encryption, with no mention of processing LLM training data or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10234",
      "abstract": "The evolution of human intelligence led to the huge amount of data in the information space. Accessing and processing this data helps in finding solutions to applied problems based on finite-dimensional models. We argue, that formally, such a mathematical model can be embedded into a higher-dimensional model inside of which a desired solution will exist.",
      "authors": [
        "Tatyana Barron"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:56:18+00:00",
          "link": "https://arxiv.org/abs/2507.10234v1",
          "size": "3079kb",
          "version": "v1"
        }
      ],
      "title": "Dimensionality increase for error correction in the interaction between information space and the physical world",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10234",
        "HTML": "https://arxiv.org/html/2507.10234v1",
        "PDF": "https://arxiv.org/pdf/2507.10234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The abstract mentions managing data with finite-dimensional models but does not discuss LLM training data processing or specific dataset creation methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.09554",
      "abstract": "Molecular assays are standard of care for detecting genomic alterations in cancer prognosis and therapy selection but are costly, tissue-destructive and time-consuming. Artificial intelligence (AI) applied to routine hematoxylin and eosin (H&E)-stained whole slide images (WSIs) offers a fast and economical alternative for screening molecular biomarkers. We introduce OmniScreen, a high-throughput AI-based system leveraging Virchow2 embeddings extracted from 60,529 cancer patients with paired 489-gene MSK-IMPACT targeted biomarker panel and WSIs. Unlike conventional approaches that train separate models for each biomarker, OmniScreen employs a unified model to predict a broad range of clinically relevant biomarkers across cancers, including low-prevalence targets impractical to model individually. OmniScreen reliably identifies therapeutic targets and shared phenotypic features across common and rare tumors. We investigate the biomarker prediction probabilities and accuracies of OmniScreen in relation to tumor area, cohort size, histologic subtype alignment, and pathway-level morphological patterns. These findings underscore the potential of OmniScreen for routine clinical screening.",
      "authors": [
        "Yi Kan Wang",
        "Ludmila Tydlitatova",
        "Jeremy D. Kunz",
        "Gerard Oakley",
        "Bonnie Kar Bo Chow",
        "Ran A. Godrich",
        "Matthew C. H. Lee",
        "Hamed Aghdam",
        "Alican Bozkurt",
        "Michal Zelechowski",
        "Chad Vanderbilt",
        "Christopher Kanan",
        "Juan A. Retamero",
        "Peter Hamilton",
        "Razik Yousfi",
        "Thomas J. Fuchs",
        "David S. Klimstra",
        "Siqi Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-18T17:44:00+00:00",
          "link": "https://arxiv.org/abs/2408.09554v1",
          "size": "15393kb",
          "version": "v1"
        },
        {
          "date": "2024-08-20T12:47:35+00:00",
          "link": "https://arxiv.org/abs/2408.09554v2",
          "size": "15393kb",
          "version": "v2"
        },
        {
          "date": "2025-06-24T22:10:17+00:00",
          "link": "https://arxiv.org/abs/2408.09554v3",
          "size": "23268kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T13:55:24+00:00",
          "link": "https://arxiv.org/abs/2408.09554v4",
          "size": "23268kb",
          "version": "v4"
        }
      ],
      "title": "Screen Them All: High-Throughput Pan-Cancer Genetic and Phenotypic Biomarker Screening from H&E Whole Slide Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.09554",
        "HTML": "https://arxiv.org/html/2408.09554v4",
        "PDF": "https://arxiv.org/pdf/2408.09554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers around an AI system for cancer biomarker screening from images, using a unified model to predict biomarkers. It does not involve LLM training data processing."
      },
      "tasks": [
        "All",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18682",
      "abstract": "Recent advances in autonomous driving (AD) have highlighted the potential of Hyperspectral Imaging (HSI) for enhanced environmental perception, particularly in challenging weather and lighting conditions. However, efficiently processing its high-dimensional spectral data remains a significant challenge. This paper introduces a Multi-scale Spectral Attention Module (MSAM) that enhances spectral feature extraction through three parallel 1D convolutions with varying kernel sizes between 1 to 11, coupled with an adaptive feature aggregation mechanism. By integrating MSAM into UNet's skip connections (UNet-SC), our proposed UNet-MSAM achieves significant improvements in semantic segmentation performance across multiple HSI datasets: HyKo-VIS v2, HSI-Drive v2, and Hyperspectral City v2. Our comprehensive experiments demonstrate that with minimal computational overhead (on average 0.02% in parameters and 0.82% GFLOPS), UNet-MSAM consistently outperforms UNet-SC, achieving average improvements of 3.61% in mean IoU and 3.80% in mF1 across the three datasets. Through extensive ablation studies, we have established that multi-scale kernel combinations perform better than single-scale configurations. These findings demonstrate the potential of HSI processing for AD and provide valuable insights into designing robust, multi-scale spectral feature extractors for real-world applications.",
      "authors": [
        "Imad Ali Shah",
        "Jiarong Li",
        "Tim Brophy",
        "Martin Glavin",
        "Edward Jones",
        "Enda Ward",
        "and Brian Deegan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T14:24:20+00:00",
          "link": "https://arxiv.org/abs/2506.18682v1",
          "size": "9295kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Scale Spectral Attention Module-based Hyperspectral Segmentation in Autonomous Driving Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18682",
        "HTML": "https://arxiv.org/html/2506.18682",
        "PDF": "https://arxiv.org/pdf/2506.18682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving semantic segmentation performance with a new specteral attention module integrated into models for hyperspectral imaging in autonomous driving, without discussing any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10301",
      "abstract": "Effect handlers allow programmers to model and compose computational effects modularly. Effect systems statically guarantee that all effects are handled. Several recent practical effect systems are based on either row polymorphism or capabilities. However, there remains a gap in understanding the precise relationship between effect systems with such disparate foundations. The main difficulty is that in both row-based and capability-based systems, effect tracking is typically entangled with other features such as functions.\n  We propose a uniform framework for encoding, analysing, and comparing effect systems. Our framework exploits and generalises modal effect types, a recent novel effect system which decouples effect tracking from functions via modalities. Modalities offer fine-grained control over when and how effects are tracked, enabling us to express different strategies for effect tracking. We give encodings as macro translations from existing row-based and capability-based effect systems into our framework and show that these encodings preserve types and semantics. Our encodings reveal the essence of effect tracking mechanisms in different effect systems, enable a direct analysis on their differences, and provide valuable insights on language design.",
      "authors": [
        "Wenhao Tang",
        "Sam Lindley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:04:15+00:00",
          "link": "https://arxiv.org/abs/2507.10301v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Rows and Capabilities as Modal Effects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10301",
        "PDF": "https://arxiv.org/pdf/2507.10301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on effect systems and their formal analysis, lacking any discussion on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.19546",
      "abstract": "Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's o1, have emerged, seemingly demonstrating advanced reasoning capabilities across text and image modalities. However, the depth of these advances in language-guided perception and abstract reasoning remains underexplored, and it is unclear whether these models can truly live up to their ambitious promises. To assess the progress and identify shortcomings, we enter the wonderland of Bongard problems, a set of classic visual reasoning puzzles that require human-like abilities of pattern recognition and abstract reasoning. With our extensive evaluation setup, we show that while VLMs occasionally succeed in identifying discriminative concepts and solving some of the problems, they frequently falter. Surprisingly, even elementary concepts that may seem trivial to humans, such as simple spirals, pose significant challenges. Moreover, when explicitly asked to recognize ground truth concepts, they continue to falter, suggesting not only a lack of understanding of these elementary visual concepts but also an inability to generalize to unseen concepts. We compare the results of VLMs to human performance and observe that a significant gap remains between human visual reasoning capabilities and machine cognition.",
      "authors": [
        "Antonia W\\\"ust and Tim Woydt and Lukas Helff and Inga Ibs and Wolfgang Stammer and Devendra S. Dhami and Constantin A. Rothkopf and Kristian Kersting"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T13:19:26+00:00",
          "link": "https://arxiv.org/abs/2410.19546v1",
          "size": "2237kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T14:38:12+00:00",
          "link": "https://arxiv.org/abs/2410.19546v2",
          "size": "9088kb",
          "version": "v2"
        },
        {
          "date": "2025-02-25T09:27:57+00:00",
          "link": "https://arxiv.org/abs/2410.19546v3",
          "size": "3585kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T15:31:04+00:00",
          "link": "https://arxiv.org/abs/2410.19546v4",
          "size": "4265kb",
          "version": "v4"
        }
      ],
      "title": "Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19546",
        "HTML": "https://arxiv.org/html/2410.19546v4",
        "PDF": "https://arxiv.org/pdf/2410.19546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates the reasoning capabilities of vision-language models using visual reasoning puzzles, not LLM training data processing or dataset creation."
      },
      "tasks": [
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://github.com/ml-research/bongard-in-wonderland"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01391",
      "abstract": "Accurate detection of traffic anomalies is crucial for effective urban traffic management and congestion mitigation. We use the Spatiotemporal Generative Adversarial Network (STGAN) framework combining Graph Neural Networks and Long Short-Term Memory networks to capture complex spatial and temporal dependencies in traffic data. We apply STGAN to real-time, minute-by-minute observations from 42 traffic cameras across Gothenburg, Sweden, collected over several months in 2020. The images are processed to compute a flow metric representing vehicle density, which serves as input for the model. Training is conducted on data from April to November 2020, and validation is performed on a separate dataset from November 14 to 23, 2020. Our results demonstrate that the model effectively detects traffic anomalies with high precision and low false positive rates. The detected anomalies include camera signal interruptions, visual artifacts, and extreme weather conditions affecting traffic flow.",
      "authors": [
        "Fotis I. Giasemis",
        "Alexandros Sopasakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T14:23:23+00:00",
          "link": "https://arxiv.org/abs/2502.01391v1",
          "size": "538kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T09:00:33+00:00",
          "link": "https://arxiv.org/abs/2502.01391v2",
          "size": "538kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T14:53:32+00:00",
          "link": "https://arxiv.org/abs/2502.01391v3",
          "size": "465kb",
          "version": "v3"
        },
        {
          "date": "2025-07-04T08:35:52+00:00",
          "link": "https://arxiv.org/abs/2502.01391v4",
          "size": "465kb",
          "version": "v4"
        },
        {
          "date": "2025-07-12T04:03:12+00:00",
          "link": "https://arxiv.org/abs/2502.01391v5",
          "size": "465kb",
          "version": "v5"
        }
      ],
      "title": "Learning Traffic Anomalies from Generative Models on Real-Time Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01391",
        "HTML": "https://arxiv.org/html/2502.01391v5",
        "PDF": "https://arxiv.org/pdf/2502.01391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes traffic anomaly detection using generative models and real-time data, not involving any LLM training data processing or dataset creation."
      },
      "tasks": [
        "Generative Adversarial Network",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08902",
      "abstract": "Personalized vaccines and T-cell immunotherapies depend critically on identifying peptide-MHC class I (pMHC-I) interactions capable of eliciting potent immune responses. However, current benchmarks and models inherit biases present in mass-spectrometry and binding-assay datasets, limiting discovery of novel peptide ligands. To address this issue, we introduce a structure-guided benchmark of pMHC-I peptides designed using diffusion models conditioned on crystal structure interaction distances. Spanning twenty high-priority HLA alleles, this benchmark is independent of previously characterized peptides yet reproduces canonical anchor residue preferences, indicating structural generalization without experimental dataset bias. Using this resource, we demonstrate that state-of-the-art sequence-based predictors perform poorly at recognizing the binding potential of these structurally stable designs, indicating allele-specific limitations invisible in conventional evaluations. Our geometry-aware design pipeline yields peptides with high predicted structural integrity and higher residue diversity than existing datasets, representing a key resource for unbiased model training and evaluation. Our code, and data are available at: https://github.com/sermare/struct-mhc-dev.",
      "authors": [
        "Sergio Mares",
        "Ariel Espinoza Weinberger",
        "Nilah M. Ioannidis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:29:18+00:00",
          "link": "https://arxiv.org/abs/2507.08902v1",
          "size": "4944kb",
          "version": "v1"
        }
      ],
      "title": "Generation of structure-guided pMHC-I libraries using Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08902",
        "HTML": "https://arxiv.org/html/2507.08902v1",
        "PDF": "https://arxiv.org/pdf/2507.08902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes a pipeline for generating peptide libraries using diffusion models which are used to address bias in datasets, representing a comprehensive data creation process that enhances dataset quality for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09177",
      "abstract": "Continual reinforcement learning (CRL) refers to a naturalistic setting where an agent needs to endlessly evolve, by trial and error, to solve multiple tasks that are presented sequentially. One of the largest obstacles to CRL is that the agent may forget how to solve previous tasks when learning a new task, known as catastrophic forgetting. In this paper, we propose to address this challenge by planning with online world models. Specifically, we learn a Follow-The-Leader shallow model online to capture the world dynamics, in which we plan using model predictive control to solve a set of tasks specified by any reward functions. The online world model is immune to forgetting by construction with a proven regret bound of $\\mathcal{O}(\\sqrt{K^2D\\log(T)})$ under mild assumptions. The planner searches actions solely based on the latest online model, thus forming a FTL Online Agent (OA) that updates incrementally. To assess OA, we further design Continual Bench, a dedicated environment for CRL, and compare with several strong baselines under the same model-planning algorithmic framework. The empirical results show that OA learns continuously to solve new tasks while not forgetting old skills, outperforming agents built on deep world models with various continual learning techniques.",
      "authors": [
        "Zichen Liu",
        "Guoji Fu",
        "Chao Du",
        "Wee Sun Lee",
        "Min Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:52:31+00:00",
          "link": "https://arxiv.org/abs/2507.09177v1",
          "size": "2539kb",
          "version": "v1"
        }
      ],
      "title": "Continual Reinforcement Learning by Planning with Online World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09177",
        "PDF": "https://arxiv.org/pdf/2507.09177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a continual reinforcement learning method focused on planning via online world models, without any emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09588",
      "abstract": "We present eSapiens, an AI-as-a-Service (AIaaS) platform engineered around a business-oriented trifecta: proprietary data, operational workflows, and any major agnostic Large Language Model (LLM). eSapiens gives businesses full control over their AI assets, keeping everything in-house for AI knowledge retention and data security. eSapiens AI Agents (Sapiens) empower your team by providing valuable insights and automating repetitive tasks, enabling them to focus on high-impact work and drive better business outcomes.\n  The system integrates structured document ingestion, hybrid vector retrieval, and no-code orchestration via LangChain, and supports top LLMs including OpenAI, Claude, Gemini, and DeepSeek. A key component is the THOR Agent, which handles structured SQL-style queries and generates actionable insights over enterprise databases.\n  To evaluate the system, we conduct two experiments. First, a retrieval benchmark on legal corpora reveals that a chunk size of 512 tokens yields the highest retrieval precision (Top-3 accuracy: 91.3%). Second, a generation quality test using TRACe metrics across five LLMs shows that eSapiens delivers more context-consistent outputs with up to a 23% improvement in factual alignment.\n  These results demonstrate the effectiveness of eSapiens in enabling trustworthy, auditable AI workflows for high-stakes domains like legal and finance.",
      "authors": [
        "Isaac Shi and Zeyuan Li and Fan Liu and Wenli Wang and Lewei He and Yang Yang and Tianyu Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:41:44+00:00",
          "link": "https://arxiv.org/abs/2507.09588v1",
          "size": "1015kb",
          "version": "v1"
        }
      ],
      "title": "eSapiens: A Platform for Secure and Auditable Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09588",
        "HTML": "https://arxiv.org/html/2507.09588v1",
        "PDF": "https://arxiv.org/pdf/2507.09588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a platform for AI workflows in business, discussing data security and retrieval without making specific contributions to LLM training-data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09911",
      "abstract": "Context: Agile IT organizations, which are characterized by self-organization and collaborative social interactions, require motivating, efficient and flexible work environments to maximize value creation. Compressed work schedules such as the four-day workweek have evolved into multiple facets over the last decades and are associated with various benefits for organizations and their employees. Objective: Our objective in this study is to deepen our comprehension of the impact of compressed work schedules on the operational efficacy of IT enterprises, while concurrently developing a comprehensive framework delineating the intricacies of compressed work schedules.Method: We conducted a systematic review of available conceptualizations related to four-day workweek schedules and elaborate on their organizational and social effects. To cover scientific and practice-oriented literature, our review combined a systematic literature review and a web content analysis. Results: Based on the generated insights, we derive a meta-framework that matches conceptualizations and effects, finally guiding the adoption of compressed work schedules based on individual managerial prerequisites and circumstances.",
      "authors": [
        "Marvin Auf der Landwehr",
        "Julia Topp",
        "Michael Neumann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:33:28+00:00",
          "link": "https://arxiv.org/abs/2507.09911v1",
          "size": "1493kb",
          "version": "v1"
        }
      ],
      "title": "When Less is More: A systematic review of four-day workweek conceptualizations and their effects on organizational performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09911",
        "HTML": "https://arxiv.org/html/2507.09911v1",
        "PDF": "https://arxiv.org/pdf/2507.09911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the review of four-day workweek concepts and their impact on organizational performance, with no relevance to LLM training data processing or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09966",
      "abstract": "Precise segmentation of brain tumors from magnetic resonance imaging (MRI) is essential for neuro-oncology diagnosis and treatment planning. Despite advances in deep learning methods, automatic segmentation remains challenging due to tumor morphological heterogeneity and complex three-dimensional spatial relationships. Current techniques primarily rely on visual features extracted from MRI sequences while underutilizing semantic knowledge embedded in medical reports. This research presents a multi-level fusion architecture that integrates pixel-level, feature-level, and semantic-level information, facilitating comprehensive processing from low-level data to high-level concepts. The semantic-level fusion pathway combines the semantic understanding capabilities of Contrastive Language-Image Pre-training (CLIP) models with the spatial feature extraction advantages of 3D U-Net through three mechanisms: 3D-2D semantic bridging, cross-modal semantic guidance, and semantic-based attention mechanisms. Experimental validation on the BraTS 2020 dataset demonstrates that the proposed model achieves an overall Dice coefficient of 0.8567, representing a 4.8% improvement compared to traditional 3D U-Net, with a 7.3% Dice coefficient increase in the clinically important enhancing tumor (ET) region.",
      "authors": [
        "Mingda Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:32:59+00:00",
          "link": "https://arxiv.org/abs/2507.09966v1",
          "size": "3809kb",
          "version": "v1"
        }
      ],
      "title": "A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09966",
        "HTML": "https://arxiv.org/html/2507.09966v1",
        "PDF": "https://arxiv.org/pdf/2507.09966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on brain tumor segmentation using CLIP and 3D U-Net with feature fusion. It does not involve LLM training data processing or creation of datasets for LLM pretraining."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10086",
      "abstract": "Fast-response voltage regulation is essential for data-center Voltage Regulation Modules (VRMs) powering Artificial Intelligence (AI) workloads, which exhibit both small-amplitude fluctuations and abrupt full-load steps. This paper introduces a control scheme that integrates a linear controller and a nonlinear controller for variable-frequency Series-Capacitor Buck (SCB) converters. First, an accurate small-signal model is derived via a Switching-Synchronized Sampled State-Space (5S) framework, yielding discrete-time transfer functions and root-locus insights for direct digital design. A critical concern for SCB converters is series-capacitor oscillation during heavy load steps if the strict switching sequence is not maintained. To accelerate large-signal transients, a time-optimal control strategy based on Pontryagins Maximum Principle (PMP) relaxes the switching constraints to compute time-optimal switching sequences. A transition logic is then proposed to integrate the high-bandwidth small-signal controller and the large-signal controller. Simulations demonstrate a rapid output voltage recovery under a heavy load step-up, over ten times faster than a linear controller-only design. Preliminary hardware tests indicate a stable rejection to heavy load disturbances with zero steady-state error.",
      "authors": [
        "Guanyu Qian and Haoxian Yan and Xiaofan Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:13:00+00:00",
          "link": "https://arxiv.org/abs/2507.10086v1",
          "size": "1511kb",
          "version": "v1"
        }
      ],
      "title": "Fast-Response Variable-Frequency Series-Capacitor Buck VRM Through Integrated Control Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10086",
        "HTML": "https://arxiv.org/html/2507.10086v1",
        "PDF": "https://arxiv.org/pdf/2507.10086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses control schemes for voltage regulation in hardware systems rather than anything related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10539",
      "abstract": "World models (WMs) demonstrate strong capabilities in prediction, generation, and planning tasks. Existing WMs primarily focus on unstructured data and cannot leverage the ubiquitous structured data, often represented as graphs, in the digital world. While multiple graph foundation models have been proposed, they focus on graph learning tasks and cannot extend to diverse multi-modal data and interdisciplinary tasks. To address these challenges, we propose the Graph World Model (GWM), a world model that supports both unstructured and graph-structured states with multi-modal information and represents diverse tasks as actions. The core of a GWM is a generic message-passing algorithm to aggregate structured information, either over a unified multi-modal token space by converting multi-modal data into text (GWM-T) or a unified multi-modal embedding space by modality-specific encoders (GWM-E). Notably, GWM introduces action nodes to support diverse tasks, where action nodes are linked to other nodes via direct reference or similarity computation. Extensive experiments on six tasks from diverse domains, including multi-modal generation and matching, recommendation, graph prediction, multi-agent, retrieval-augmented generation, and planning and optimization, show that the same GWM outperforms or matches domain-specific baselines' performance, benefits from multi-hop structures, and demonstrates strong zero-shot/few-shot capabilities on unseen new tasks. Our code for GWM is released at https://github.com/ulab-uiuc/GWM.",
      "authors": [
        "Tao Feng",
        "Yexin Wu",
        "Guanyu Lin",
        "Jiaxuan You"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.10539v1",
          "size": "1711kb",
          "version": "v1"
        }
      ],
      "title": "Graph World Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10539",
        "HTML": "https://arxiv.org/html/2507.10539v1",
        "PDF": "https://arxiv.org/pdf/2507.10539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Graph World Model, focusing on representation tasks across structured and unstructured data, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.16801",
      "abstract": "Serious Games (SGs) are nowadays shifting focus to include procedural content generation (PCG) in the development process as a means of offering personalized and enhanced player experience. However, the development of a framework to assess the impact of PCG techniques when integrated into SGs remains particularly challenging. This study proposes a methodology for automated evaluation of PCG integration in SGs, incorporating deep reinforcement learning (DRL) game testing agents. To validate the proposed framework, a previously introduced SG featuring card game mechanics and incorporating three different versions of PCG for nonplayer character (NPC) creation has been deployed. Version 1 features random NPC creation, while versions 2 and 3 utilize a genetic algorithm approach. These versions are used to test the impact of different dynamic SG environments on the proposed framework's agents. The obtained results highlight the superiority of the DRL game testing agents trained on Versions 2 and 3 over those trained on Version 1 in terms of win rate (i.e. number of wins per played games) and training time. More specifically, within the execution of a test emulating regular gameplay, both Versions 2 and 3 peaked at a 97% win rate and achieved statistically significant higher (p=0009) win rates compared to those achieved in Version 1 that peaked at 94%. Overall, results advocate towards the proposed framework's capability to produce meaningful data for the evaluation of procedurally generated content in SGs.",
      "authors": [
        "Eleftherios Kalafatis",
        "Konstantinos Mitsis",
        "Konstantia Zarkogianni",
        "Maria Athanasiou and Konstantina Nikita"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T15:40:56+00:00",
          "link": "https://arxiv.org/abs/2505.16801v1",
          "size": "1528kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T09:44:08+00:00",
          "link": "https://arxiv.org/abs/2505.16801v2",
          "size": "1539kb",
          "version": "v2"
        }
      ],
      "title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16801",
        "PDF": "https://arxiv.org/pdf/2505.16801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on evaluating procedural content generation in serious games, not related to any processing or creation of LLM training data."
      },
      "tasks": [
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16983",
      "abstract": "We investigate the service-rate region (SRR) of distributed storage systems that employ linear codes. We focus on systems where each server stores one code symbol, and a user recovers a data symbol by accessing any of its recovery groups, subject to per-server capacity limits. The SRR--the convex polytope of simultaneously achievable request rates--captures system throughput and scalability. We first derive upper and lower bounds on the maximum request rate of each data object. These bounds hold for all linear codes and depend only on the number of parity checks orthogonal to a particular set of codeword coordinates associated with that object, i.e., the equations used in majority-logic decoding, and on code parameters. We then check the bound saturation for 1) all non-systematic codes whose SRRs are already known and 2) systematic codes. For the former, we prove the bounds are tight. For systematic codes, we show that the upper bound is achieved whenever the supports of minimum-weight dual codewords form a 2-design. As an application, we determine the exact per-object demand limits for binary Hamming codes. Our framework provides a new lens to address the SRR problem through combinatorial design theory.",
      "authors": [
        "Hoang Ly and Emina Soljanin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T13:24:51+00:00",
          "link": "https://arxiv.org/abs/2506.16983v1",
          "size": "290kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T10:14:43+00:00",
          "link": "https://arxiv.org/abs/2506.16983v2",
          "size": "291kb",
          "version": "v2"
        }
      ],
      "title": "Maximal Achievable Service Rates of Codes and Connections to Combinatorial Designs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16983",
        "HTML": "https://arxiv.org/html/2506.16983v2",
        "PDF": "https://arxiv.org/pdf/2506.16983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with distributed storage systems and linear codes, without any mention of LLM training data processing or related data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03633",
      "abstract": "EEG signals capture brain activity with high temporal and low spatial resolution, supporting applications such as neurological diagnosis, cognitive monitoring, and brain-computer interfaces. However, effective analysis is hindered by limited labeled data, high dimensionality, and the absence of scalable models that fully capture spatiotemporal dependencies. Existing self-supervised learning (SSL) methods often focus on either spatial or temporal features, leading to suboptimal representations. To this end, we propose EEG-VJEPA, a novel adaptation of the Video Joint Embedding Predictive Architecture (V-JEPA) for EEG classification. By treating EEG as video-like sequences, EEG-VJEPA learns semantically meaningful spatiotemporal representations using joint embeddings and adaptive masking. To our knowledge, this is the first work that exploits V-JEPA for EEG classification and explores the visual concepts learned by the model. Evaluations on the publicly available Temple University Hospital (TUH) Abnormal EEG dataset show that EEG-VJEPA outperforms existing state-of-the-art models in classification accuracy. Beyond classification accuracy, EEG-VJEPA captures physiologically relevant spatial and temporal signal patterns, offering interpretable embeddings that may support human-AI collaboration in diagnostic workflows. These findings position EEG-VJEPA as a promising framework for scalable, trustworthy EEG analysis in real-world clinical settings.",
      "authors": [
        "Amirabbas Hojjati",
        "Lu Li",
        "Ibrahim Hameed",
        "Anis Yazidi",
        "Pedro G. Lind",
        "Rabindra Khadka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T15:01:34+00:00",
          "link": "https://arxiv.org/abs/2507.03633v1",
          "size": "5449kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T06:52:14+00:00",
          "link": "https://arxiv.org/abs/2507.03633v2",
          "size": "5449kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T15:43:06+00:00",
          "link": "https://arxiv.org/abs/2507.03633v3",
          "size": "5449kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T18:45:36+00:00",
          "link": "https://arxiv.org/abs/2507.03633v4",
          "size": "5451kb",
          "version": "v4"
        }
      ],
      "title": "From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03633",
        "HTML": "https://arxiv.org/html/2507.03633v4",
        "PDF": "https://arxiv.org/pdf/2507.03633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study applies joint embedding techniques for EEG signal analysis, focusing on capturing spatiotemporal dependencies. It does not engage with LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09331",
      "abstract": "Two-tower neural networks are a popular architecture for the retrieval stage in recommender systems. These models are typically trained with a softmax loss over the item catalog. However, in web-scale settings, the item catalog is often prohibitively large, making full softmax infeasible. A common solution is sampled softmax, which approximates the full softmax using a small number of sampled negatives.\n  One practical and widely adopted approach is to use in-batch negatives, where negatives are drawn from items in the current mini-batch. However, this introduces a bias: items that appear more frequently in the batch (i.e., popular items) are penalized more heavily.\n  To mitigate this issue, a popular industry technique known as logQ correction adjusts the logits during training by subtracting the log-probability of an item appearing in the batch. This correction is derived by analyzing the bias in the gradient and applying importance sampling, effectively twice, using the in-batch distribution as a proposal distribution. While this approach improves model quality, it does not fully eliminate the bias.\n  In this work, we revisit the derivation of logQ correction and show that it overlooks a subtle but important detail: the positive item in the denominator is not Monte Carlo-sampled - it is always present with probability 1. We propose a refined correction formula that accounts for this. Notably, our loss introduces an interpretable sample weight that reflects the model's uncertainty - the probability of misclassification under the current parameters. We evaluate our method on both public and proprietary datasets, demonstrating consistent improvements over the standard logQ correction.",
      "authors": [
        "Kirill Khrylchenko",
        "Vladimir Baikalov",
        "Sergei Makeev",
        "Artem Matveev",
        "Sergei Liamaev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:16:11+00:00",
          "link": "https://arxiv.org/abs/2507.09331v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09331",
        "HTML": "https://arxiv.org/html/2507.09331v1",
        "PDF": "https://arxiv.org/pdf/2507.09331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper revisits softmax corrections in model training, it involves modifying training procedures rather than focusing on LLM training data processing, collection, or generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09762",
      "abstract": "Hacker forums provide critical early warning signals for emerging cybersecurity threats, but extracting actionable intelligence from their unstructured and noisy content remains a significant challenge. This paper presents an unsupervised framework that automatically detects, clusters, and prioritizes security events discussed across hacker forum posts. Our approach leverages Transformer-based embeddings fine-tuned with contrastive learning to group related discussions into distinct security event clusters, identifying incidents like zero-day disclosures or malware releases without relying on predefined keywords. The framework incorporates a daily ranking mechanism that prioritizes identified events using quantifiable metrics reflecting timeliness, source credibility, information completeness, and relevance. Experimental evaluation on real-world hacker forum data demonstrates that our method effectively reduces noise and surfaces high-priority threats, enabling security analysts to mount proactive responses. By transforming disparate hacker forum discussions into structured, actionable intelligence, our work addresses fundamental challenges in automated threat detection and analysis.",
      "authors": [
        "Yasir Ech-Chammakhy",
        "Anas Motii",
        "Anass Rabii",
        "Jaafar Chbili"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:40:36+00:00",
          "link": "https://arxiv.org/abs/2507.09762v1",
          "size": "379kb",
          "version": "v1"
        }
      ],
      "title": "EventHunter: Dynamic Clustering and Ranking of Security Events from Hacker Forum Discussions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09762",
        "HTML": "https://arxiv.org/html/2507.09762v1",
        "PDF": "https://arxiv.org/pdf/2507.09762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the clustering and ranking of security events from hacker forums for threat detection, not focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09879",
      "abstract": "We consider the problem of covering multiple submodular constraints. Given a finite ground set $N$, a cost function $c: N \\rightarrow \\mathbb{R}_+$, $r$ monotone submodular functions $f_1,f_2,\\ldots,f_r$ over $N$ and requirements $b_1,b_2,\\ldots,b_r$ the goal is to find a minimum cost subset $S \\subseteq N$ such that $f_i(S) \\ge b_i$ for $1 \\le i \\le r$. When $r=1$ this is the well-known Submodular Set Cover problem. Previous work \\cite{chekuri2022covering} considered the setting when $r$ is large and developed bi-criteria approximation algorithms, and approximation algorithms for the important special case when each $f_i$ is a weighted coverage function. These are fairly general models and capture several concrete and interesting problems as special cases. The approximation ratios for these problem are at least $\\Omega(\\log r)$ which is unavoidable when $r$ is part of the input. In this paper, motivated by some recent applications, we consider the problem when $r$ is a \\emph{fixed constant} and obtain two main results. For covering multiple submodular constraints we obtain a randomized bi-criteria approximation algorithm that for any given integer $\\alpha \\ge 1$ outputs a set $S$ such that $f_i(S) \\ge$ $(1-1/e^\\alpha -\\epsilon)b_i$ for each $i \\in [r]$ and $\\mathbb{E}[c(S)] \\le (1+\\epsilon)\\alpha \\cdot \\sf{OPT}$. Second, when the $f_i$ are weighted coverage functions from a deletion-closed set system we obtain a $(1+\\epsilon)$ $(\\frac{e}{e-1})$ $(1+\\beta)$-approximation where $\\beta$ is the approximation ratio for the underlying set cover instances via the natural LP. These results show that one can obtain nearly as good an approximation for any fixed $r$ as what one would achieve for $r=1$. We mention some applications that follow easily from these general results and anticipate more in the future.",
      "authors": [
        "Tanvi Bajpai",
        "Chandra Chekuri",
        "Pooja Kulkarni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:32:42+00:00",
          "link": "https://arxiv.org/abs/2507.09879v1",
          "size": "64kb",
          "version": "v1"
        }
      ],
      "title": "Covering a Few Submodular Constraints and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09879",
        "HTML": "https://arxiv.org/html/2507.09879v1",
        "PDF": "https://arxiv.org/pdf/2507.09879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses algorithms for submodular constraints and related optimization problems, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10235",
      "abstract": "Modern robotic systems integrate multiple independent software and hardware components, each responsible for distinct functionalities such as perception, decision-making, and execution. These components interact extensively to accomplish complex end-to-end tasks. As a result, the overall system reliability depends not only on the correctness of individual components, but also on the correctness of their interactions. Failures often manifest at the boundaries between components, yet interaction-related reliability issues in robotics--referred to here as interaction bugs (iBugs)--remain underexplored.\n  This work presents an empirical study of iBugs within robotic systems built using the Robot Operating System (ROS), a widely adopted open-source robotics framework. A total of 121 iBugs were analyzed across ten actively maintained and representative ROS projects. The identified iBugs are categorized into three major types: intra-system iBugs, hardware iBugs, and environmental iBugs, covering a broad range of interaction scenarios in robotics. The analysis includes an examination of root causes, fixing strategies, and the impact of these bugs. Several findingsa are derived that shed light on the nature of iBugs and suggest directions for improving their prevention and detection. These insights aim to inform the design of more robust and safer robotic systems.",
      "authors": [
        "Zhixiang Chen",
        "Zhuangbin Chen",
        "Xingjie Cai",
        "Wei Li",
        "Zibin Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:56:24+00:00",
          "link": "https://arxiv.org/abs/2507.10235v1",
          "size": "493kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Study of Interaction Bugs in ROS-based Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10235",
        "HTML": "https://arxiv.org/html/2507.10235v1",
        "PDF": "https://arxiv.org/pdf/2507.10235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines interaction bugs in ROS-based software, focusing on robotics, not LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10461",
      "abstract": "Pansharpening refers to the process of integrating a high resolution panchromatic (PAN) image with a lower resolution multispectral (MS) image to generate a fused product, which is pivotal in remote sensing. Despite the effectiveness of CNNs in addressing this challenge, they are inherently constrained by the uniform application of convolutional kernels across all spatial positions, overlooking local content variations. To overcome this issue, we introduce RAPNet, a new architecture that leverages content-adaptive convolution. At its core, RAPNet employs the Receptive-field Adaptive Pansharpening Convolution (RAPConv), designed to produce spatially adaptive kernels responsive to local feature context, thereby enhancing the precision of spatial detail extraction. Additionally, the network integrates the Pansharpening Dynamic Feature Fusion (PAN-DFF) module, which incorporates an attention mechanism to achieve an optimal balance between spatial detail enhancement and spectral fidelity. Comprehensive evaluations on publicly available datasets confirm that RAPNet delivers superior performance compared to existing approaches, as demonstrated by both quantitative metrics and qualitative assessments. Ablation analyses further substantiate the effectiveness of the proposed adaptive components.",
      "authors": [
        "Tao Tang",
        "Chengxu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:39:14+00:00",
          "link": "https://arxiv.org/abs/2507.10461v1",
          "size": "2324kb",
          "version": "v1"
        }
      ],
      "title": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10461",
        "PDF": "https://arxiv.org/pdf/2507.10461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a new neural network architecture for pansharpening in remote sensing and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18409",
      "abstract": "Concurrent accesses to databases are typically grouped in transactions which define units of work that should be isolated from other concurrent computations and resilient to failures. Modern databases provide different levels of isolation for transactions that correspond to different trade-offs between consistency and throughput. Quite often, an application can use transactions with different isolation levels at the same time. In this work, we investigate the problem of testing isolation level implementations in databases, i.e., checking whether a given execution composed of multiple transactions adheres to the prescribed isolation level semantics. We particularly focus on transactions formed of SQL queries and the use of multiple isolation levels at the same time. We show that many restrictions of this problem are NP-complete and provide an algorithm which is exponential-time in the worst-case, polynomial-time in relevant cases, and practically efficient.",
      "authors": [
        "Ahmed Bouajjani",
        "Constantin Enea",
        "Enrique Rom\\'an-Calvo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T22:33:03+00:00",
          "link": "https://arxiv.org/abs/2505.18409v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:13:15+00:00",
          "link": "https://arxiv.org/abs/2505.18409v2",
          "size": "91kb",
          "version": "v2"
        }
      ],
      "title": "On the Complexity of Checking Mixed Isolation Levels for SQL Transactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18409",
        "HTML": "https://arxiv.org/html/2505.18409v2",
        "PDF": "https://arxiv.org/pdf/2505.18409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines SQL transaction isolation levels and does not involve LLM training data processing, creation, or any related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08965",
      "abstract": "Classifier-Free Guidance (CFG) is a widely used technique for conditional generation and improving sample quality in continuous diffusion models, and recent works have extended it to discrete diffusion. This paper theoretically analyzes CFG in the context of masked discrete diffusion, focusing on the role of guidance schedules. Our analysis shows that high guidance early in sampling (when inputs are heavily masked) harms generation quality, while late-stage guidance has a larger effect. These findings provide a theoretical explanation for empirical observations in recent studies on guidance schedules. The analysis also reveals an imperfection of the current CFG implementations. These implementations can unintentionally cause imbalanced transitions, such as unmasking too rapidly during the early stages of generation, which degrades the quality of the resulting samples. To address this, we draw insight from the analysis and propose a novel classifier-free guidance mechanism empirically applicable to any discrete diffusion. Intuitively, our method smoothens the transport between the data distribution and the initial (masked/uniform) distribution, which results in improved sample quality. Remarkably, our method is achievable via a simple one-line code change. The efficacy of our method is empirically demonstrated with experiments on ImageNet (masked discrete diffusion) and QM9 (uniform discrete diffusion).",
      "authors": [
        "Kevin Rojas",
        "Ye He",
        "Chieh-Hsin Lai",
        "Yuta Takida",
        "Yuki Mitsufuji",
        "Molei Tao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:48:29+00:00",
          "link": "https://arxiv.org/abs/2507.08965v1",
          "size": "21348kb",
          "version": "v1"
        }
      ],
      "title": "Theory-Informed Improvements to Classifier-Free Guidance for Discrete Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08965",
        "PDF": "https://arxiv.org/pdf/2507.08965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on improving sample quality in discrete diffusion models through classifier-free guidance, without any discussion on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09200",
      "abstract": "The rapid proliferation of video in applications such as autonomous driving, surveillance, and sports analytics necessitates robust methods for dynamic scene understanding. Despite advances in static scene graph generation and early attempts at video scene graph generation, previous methods often suffer from fragmented representations, failing to capture fine-grained spatial details and long-range temporal dependencies simultaneously. To address these limitations, we introduce the Temporal Hierarchical Cyclic Scene Graph (THYME) approach, which synergistically integrates hierarchical feature aggregation with cyclic temporal refinement to address these limitations. In particular, THYME effectively models multi-scale spatial context and enforces temporal consistency across frames, yielding more accurate and coherent scene graphs. In addition, we present AeroEye-v1.0, a novel aerial video dataset enriched with five types of interactivity that overcome the constraints of existing datasets and provide a comprehensive benchmark for dynamic scene graph generation. Empirically, extensive experiments on ASPIRe and AeroEye-v1.0 demonstrate that the proposed THYME approach outperforms state-of-the-art methods, offering improved scene understanding in ground-view and aerial scenarios.",
      "authors": [
        "Trong-Thuan Nguyen",
        "Pha Nguyen",
        "Jackson Cothren",
        "Alper Yilmaz",
        "Minh-Triet Tran",
        "Khoa Luu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:43:38+00:00",
          "link": "https://arxiv.org/abs/2507.09200v1",
          "size": "7649kb",
          "version": "v1"
        }
      ],
      "title": "THYME: Temporal Hierarchical-Cyclic Interactivity Modeling for Video Scene Graphs in Aerial Footage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09200",
        "HTML": "https://arxiv.org/html/2507.09200v1",
        "PDF": "https://arxiv.org/pdf/2507.09200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a novel dataset for scene graph generation but lacks emphasis on LLM training data processing. The contribution is more on the model architecture for video scene graphs rather than dataset creation focused on LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09592",
      "abstract": "We introduce the THOR (Transformer Heuristics for On-Demand Retrieval) Module, designed and implemented by eSapiens, a secure, scalable engine that transforms natural-language questions into verified, read-only SQL analytics for enterprise databases. The Text-to-SQL module follows a decoupled orchestration/execution architecture: a Supervisor Agent routes queries, Schema Retrieval dynamically injects table and column metadata, and a SQL Generation Agent emits single-statement SELECT queries protected by a read-only guardrail. An integrated Self-Correction & Rating loop captures empty results, execution errors, or low-quality outputs and triggers up to five LLM-driven regeneration attempts. Finally, a Result Interpretation Agent produces concise, human-readable insights and hands raw rows to the Insight & Intelligence engine for visualization or forecasting.\n  Smoke tests across finance, sales, and operations scenarios demonstrate reliable ad-hoc querying and automated periodic reporting. By embedding schema awareness, fault-tolerant execution, and compliance guardrails, the THOR Module empowers non-technical users to access live data with zero-SQL simplicity and enterprise-grade safety.",
      "authors": [
        "Isaac Shi and Zeyuan Li and Fan Liu and Wenli Wang and Lewei He and Yang Yang and Tianyu Shi "
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:48:24+00:00",
          "link": "https://arxiv.org/abs/2507.09592v1",
          "size": "1584kb",
          "version": "v1"
        }
      ],
      "title": "THOR: Transformer Heuristics for On-Demand Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09592",
        "HTML": "https://arxiv.org/html/2507.09592v1",
        "PDF": "https://arxiv.org/pdf/2507.09592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the THOR Module for transforming natural-language questions into SQL queries and optimizing query processing, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09825",
      "abstract": "This paper makes two main contributions. First, we present a pedagogical review of the derivation of the three-term recurrence relation for Legendre polynomials, without relying on the classical Legendre differential equation, Rodrigues' formula, or generating functions. This exposition is designed to be accessible to undergraduate students.\n  Second, we develop a computational framework for Karhunen-Lo\\`eve expansions of isotropic Gaussian random fields on hyper-rectangular domains. The framework leverages Legendre polynomials and their associated Gaussian quadrature, and it remains efficient even in higher spatial dimensions.\n  A covariance kernel is first approximated by a non-negative mixture of squared-exponentials, obtained via a Newton-optimized fit with a theoretically informed initialization. The resulting separable kernel enables a Legendre-Galerkin discretization in the form of a Kronecker product over single dimensions, with submatrices that exhibit even/odd parity structure. For assembly, we introduce a Duffy-type transformation followed by quadrature. These structural properties significantly reduce both memory usage and arithmetic cost compared to naive approaches. All algorithms and numerical experiments are provided in an open-source repository that reproduces every figure and table in this work.",
      "authors": [
        "Michal B\\'ere\\v{s}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:14:40+00:00",
          "link": "https://arxiv.org/abs/2507.09825v1",
          "size": "2613kb",
          "version": "v1"
        }
      ],
      "title": "Legendre Polynomials and Their Use for Karhunen-Lo\\`eve Expansion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09825",
        "HTML": "https://arxiv.org/html/2507.09825v1",
        "PDF": "https://arxiv.org/pdf/2507.09825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research involves a computational framework with Legendre polynomials for Karhunen-Lo\u00e8ve expansions, unrelated to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09846",
      "abstract": "As both model and dataset sizes continue to scale rapidly, conventional pretraining strategies with fixed compute budgets-such as cosine learning rate schedules-are increasingly inadequate for large-scale training. Recent alternatives, including warmup-stable-decay (WSD) schedules and weight averaging, offer greater flexibility. However, WSD relies on explicit decay phases to track progress, while weight averaging addresses this limitation at the cost of additional memory. In search of a more principled and scalable alternative, we revisit the Schedule-Free (SF) method [Defazio et al., 2024], which has shown strong empirical performance across diverse settings. We show that SF-AdamW effectively navigates the \"river\" structure of the loss landscape without decay phases or auxiliary averaging, making it particularly suitable for continuously scaling training workloads. To understand this behavior, we conduct a theoretical and empirical analysis of SF dynamics, revealing that it implicitly performs weight averaging without memory overhead. Guided by this analysis, we propose a refined variant of SF that improves robustness to momentum and performs better under large batch sizes, addressing key limitations of the original method. Together, these results establish SF as a practical, scalable, and theoretically grounded approach for language model training.",
      "authors": [
        "Minhak Song",
        "Beomhan Baek",
        "Kwangjun Ahn",
        "Chulhee Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:54:48+00:00",
          "link": "https://arxiv.org/abs/2507.09846v1",
          "size": "2163kb",
          "version": "v1"
        }
      ],
      "title": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09846",
        "HTML": "https://arxiv.org/html/2507.09846v1",
        "PDF": "https://arxiv.org/pdf/2507.09846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on training methodologies and the optimization of learning schedules for language model training but does not discuss training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10217",
      "abstract": "Recent diffusion models achieve personalization by learning specific subjects, allowing learned attributes to be integrated into generated images. However, personalized human image generation remains challenging due to the need for precise and consistent attribute preservation (e.g., identity, clothing details). Existing subject-driven image generation methods often require either (1) inference-time fine-tuning with few images for each new subject or (2) large-scale dataset training for generalization. Both approaches are computationally expensive and impractical for real-time applications. To address these limitations, we present Wardrobe Polyptych LoRA, a novel part-level controllable model for personalized human image generation. By training only LoRA layers, our method removes the computational burden at inference while ensuring high-fidelity synthesis of unseen subjects. Our key idea is to condition the generation on the subject's wardrobe and leverage spatial references to reduce information loss, thereby improving fidelity and consistency. Additionally, we introduce a selective subject region loss, which encourages the model to disregard some of reference images during training. Our loss ensures that generated images better align with text prompts while maintaining subject integrity. Notably, our Wardrobe Polyptych LoRA requires no additional parameters at the inference stage and performs generation using a single model trained on a few training samples. We construct a new dataset and benchmark tailored for personalized human image generation. Extensive experiments show that our approach significantly outperforms existing techniques in fidelity and consistency, enabling realistic and identity-preserving full-body synthesis.",
      "authors": [
        "Jeongho Kim",
        "Sunghyun Park",
        "Hyoungwoo Park",
        "Sungrack Yun",
        "Jaegul Choo",
        "Seokeon Cho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:34:25+00:00",
          "link": "https://arxiv.org/abs/2507.10217v1",
          "size": "11658kb",
          "version": "v1"
        }
      ],
      "title": "From Wardrobe to Canvas: Wardrobe Polyptych LoRA for Part-level Controllable Human Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10217",
        "HTML": "https://arxiv.org/html/2507.10217v1",
        "PDF": "https://arxiv.org/pdf/2507.10217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a model for image generation and mentions the creation of a new dataset, but the primary focus is on the model rather than on LLM training-data processing or significant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2204.08594",
      "abstract": "This paper introduces a cooperative and decentralized collision avoidance algorithm (CoDe) for small-scale UAV swarms consisting of up to three UAVs. CoDe improves energy efficiency of UAVs by achieving effective cooperation among UAVs. Moreover, CoDe is specifically tailored for UAV's operations by addressing the challenges faced by existing schemes, such as ineffectiveness in selecting actions from continuous action spaces and high computational complexity. CoDe is based on Multi-Agent Reinforcement Learning (MARL), and finds cooperative policies by incorporating a novel credit assignment scheme. The novel credit assignment scheme estimates the contribution of an individual by subtracting a baseline from the joint action value for the swarm. The credit assignment scheme in CoDe outperforms other benchmarks as the baseline takes into account not only the importance of a UAV's action but also the interrelation between UAVs. Furthermore, extensive experiments are conducted against existing MARL-based and conventional heuristic-based algorithms to demonstrate the advantages of the proposed algorithm.",
      "authors": [
        "Shuangyao Huang",
        "Haibo Zhang and Zhiyi Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2022-04-19T00:28:51+00:00",
          "link": "https://arxiv.org/abs/2204.08594v1",
          "size": "2193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:55:04+00:00",
          "link": "https://arxiv.org/abs/2204.08594v2",
          "size": "1073kb",
          "version": "v2"
        }
      ],
      "title": "CoDe: A Cooperative and Decentralized Collision Avoidance Algorithm for Small-Scale UAV Swarms Considering Energy Efficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2204.08594",
        "HTML": "https://arxiv.org/html/2204.08594v2",
        "PDF": "https://arxiv.org/pdf/2204.08594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a collision avoidance algorithm for UAV swarms using multi-agent reinforcement learning, lacking any contribution to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/otagocssystemsgroup/maca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.05137",
      "abstract": "Document Structured Extraction (DSE) aims to extract structured content from raw documents. Despite the emergence of numerous DSE systems, their unified evaluation remains inadequate, significantly hindering the field's advancement. This problem is largely attributed to existing benchmark paradigms, which exhibit fragmented and localized characteristics. To address these limitations and offer a thorough evaluation of DSE systems, we introduce a novel benchmark named READoc, which defines DSE as a realistic task of converting unstructured PDFs into semantically rich Markdown. The READoc dataset is derived from 3,576 diverse and real-world documents from arXiv, GitHub, and Zenodo. In addition, we develop a DSE Evaluation S$^3$uite comprising Standardization, Segmentation and Scoring modules, to conduct a unified evaluation of state-of-the-art DSE approaches. By evaluating a range of pipeline tools, expert visual models, and general VLMs, we identify the gap between current work and the unified, realistic DSE objective for the first time. We aspire that READoc will catalyze future research in DSE, fostering more comprehensive and practical solutions.",
      "authors": [
        "Zichao Li",
        "Aizier Abulaiti",
        "Yaojie Lu",
        "Xuanang Chen",
        "Jia Zheng",
        "Hongyu Lin",
        "Xianpei Han",
        "Le Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-08T15:42:48+00:00",
          "link": "https://arxiv.org/abs/2409.05137v1",
          "size": "2744kb",
          "version": "v1"
        },
        {
          "date": "2024-11-03T09:09:21+00:00",
          "link": "https://arxiv.org/abs/2409.05137v2",
          "size": "2744kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T05:31:12+00:00",
          "link": "https://arxiv.org/abs/2409.05137v3",
          "size": "2474kb",
          "version": "v3"
        }
      ],
      "title": "READoc: A Unified Benchmark for Realistic Document Structured Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05137",
        "HTML": "https://arxiv.org/html/2409.05137v3",
        "PDF": "https://arxiv.org/pdf/2409.05137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a benchmark and dataset (READoc) derived from documents, it primarily focuses on evaluation of Document Structured Extraction (DSE) rather than LLM training data processing specifically."
      },
      "datasets": [
        {
          "dataset_name": "lazyc/READoc",
          "downloads": "53",
          "likes": "2",
          "link": "https://huggingface.co/datasets/lazyc/READoc"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/icip-cas/READoc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.07151",
      "abstract": "Human-centric generative models are becoming increasingly popular, giving rise to various innovative tools and applications, such as talking face videos conditioned on text or audio prompts. The core of these capabilities lies in powerful pre-trained foundation models, trained on large-scale, high-quality datasets. However, many advanced methods rely on in-house data subject to various constraints, and other current studies fail to generate high-resolution face videos, which is mainly attributed to the significant lack of large-scale, high-quality face video datasets. In this paper, we introduce a human face video dataset, \\textbf{DH-FaceVid-1K}. Our collection spans 1,200 hours in total, encompassing 270,043 video clips from over 20,000 individuals. Each sample includes corresponding speech audio, facial keypoints, and text annotations. Compared to other publicly available datasets, ours distinguishes itself through its multi-ethnic coverage and high-quality, comprehensive individual attributes. We establish multiple face video generation models supporting tasks such as text-to-video and image-to-video generation. In addition, we develop comprehensive benchmarks to validate the scaling law when using different proportions of proposed dataset. Our primary aim is to contribute a face video dataset, particularly addressing the underrepresentation of Asian faces in existing curated datasets and thereby enriching the global spectrum of face-centric data and mitigating demographic biases. \\textbf{Project Page:} https://luna-ai-lab.github.io/DH-FaceVid-1K/",
      "authors": [
        "Donglin Di",
        "He Feng",
        "Wenzhang Sun",
        "Yongjia Ma",
        "Hao Li",
        "Wei Chen",
        "Lei Fan",
        "Tonghua Su",
        "Xun Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T07:27:02+00:00",
          "link": "https://arxiv.org/abs/2410.07151v1",
          "size": "11996kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T07:52:42+00:00",
          "link": "https://arxiv.org/abs/2410.07151v2",
          "size": "43807kb",
          "version": "v2"
        }
      ],
      "title": "DH-FaceVid-1K: A Large-Scale High-Quality Dataset for Face Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07151",
        "HTML": "https://arxiv.org/html/2410.07151v2",
        "PDF": "https://arxiv.org/pdf/2410.07151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new face video dataset with detailed data processing steps, aiming to improve the diversity and quality of face-centric data."
      },
      "tasks": [
        "Image Generation",
        "Unconditional Video Generation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04295",
      "abstract": "Effective feedback is essential for student learning but is time-intensive for teachers. We present LearnLens, a modular, LLM-based system that generates personalised, curriculum-aligned feedback in science education. LearnLens comprises three components: (1) an error-aware assessment module that captures nuanced reasoning errors; (2) a curriculum-grounded generation module that uses a structured, topic-linked memory chain rather than traditional similarity-based retrieval, improving relevance and reducing noise; and (3) an educator-in-the-loop interface for customisation and oversight. LearnLens addresses key challenges in existing systems, offering scalable, high-quality feedback that empowers both teachers and students.",
      "authors": [
        "Runcong Zhao",
        "Artem Bobrov",
        "Jiazheng Li",
        "Yulan He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T08:39:26+00:00",
          "link": "https://arxiv.org/abs/2507.04295v1",
          "size": "1802kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T18:21:09+00:00",
          "link": "https://arxiv.org/abs/2507.04295v2",
          "size": "1803kb",
          "version": "v2"
        }
      ],
      "title": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04295",
        "PDF": "https://arxiv.org/pdf/2507.04295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses a system that utilizes LLMs for educational feedback generation, mentioning components like topic-linked memory chains. However, it mainly focuses on the application rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08981",
      "abstract": "Human Mesh Recovery (HMR) from an image is a challenging problem because of the inherent ambiguity of the task. Existing HMR methods utilized either temporal information or kinematic relationships to achieve higher accuracy, but there is no method using both. Hence, we propose \"Video Inference for Human Mesh Recovery with Vision Transformer (HMR-ViT)\" that can take into account both temporal and kinematic information. In HMR-ViT, a Temporal-kinematic Feature Image is constructed using feature vectors obtained from video frames by an image encoder. When generating the feature image, we use a Channel Rearranging Matrix (CRM) so that similar kinematic features could be located spatially close together. The feature image is then further encoded using Vision Transformer, and the SMPL pose and shape parameters are finally inferred using a regression network. Extensive evaluation on the 3DPW and Human3.6M datasets indicates that our method achieves a competitive performance in HMR.",
      "authors": [
        "Hanbyel Cho",
        "Jaesung Ahn",
        "Yooshin Cho",
        "and Junmo Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:31:42+00:00",
          "link": "https://arxiv.org/abs/2507.08981v1",
          "size": "2811kb",
          "version": "v1"
        }
      ],
      "title": "Video Inference for Human Mesh Recovery with Vision Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08981",
        "HTML": "https://arxiv.org/html/2507.08981v1",
        "PDF": "https://arxiv.org/pdf/2507.08981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper develops a Vision Transformer method for Human Mesh Recovery, focusing on model architecture and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09134",
      "abstract": "The motion planning problem of generating dynamically feasible, collision-free trajectories in non-convex environments is a fundamental challenge for autonomous systems. Decomposing the problem into path planning and path tracking improves tractability, but integrating these components in a theoretically sound and computationally efficient manner is challenging. We propose the Path Feasibility Governor (PathFG), a framework for integrating path planners with nonlinear Model Predictive Control (MPC). The PathFG manipulates the reference passed to the MPC controller, guiding it along a path while ensuring constraint satisfaction, stability, and recursive feasibility. The PathFG is modular, compatible with replanning, and improves computational efficiency and reliability by reducing the need for long prediction horizons. We prove safety and asymptotic stability with a significantly expanded region of attraction, and validate its real-time performance through a simulated case study of quadrotor navigation in a cluttered environment.",
      "authors": [
        "Shu Zhang",
        "James Y. Z. Liu",
        "Dominic Liao-McPherson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:24:47+00:00",
          "link": "https://arxiv.org/abs/2507.09134v1",
          "size": "2142kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Planning and Predictive Control Using the Path Feasibility Governor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09134",
        "HTML": "https://arxiv.org/html/2507.09134v1",
        "PDF": "https://arxiv.org/pdf/2507.09134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses motion planning and control for autonomous systems using the Path Feasibility Governor framework and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09137",
      "abstract": "Accurately attributing user visits to specific Points of Interest (POIs) is a foundational task for mobility analytics, personalized services, marketing and urban planning. However, POI attribution remains challenging due to GPS inaccuracies, typically ranging from 2 to 20 meters in real-world settings, and the high spatial density of POIs in urban environments, where multiple venues can coexist within a small radius (e.g., over 50 POIs within a 100-meter radius in dense city centers). Relying on proximity is therefore often insufficient for determining which POI was actually visited. We introduce \\textsf{POIFormer}, a novel Transformer-based framework for accurate and efficient POI attribution. Unlike prior approaches that rely on limited spatiotemporal, contextual, or behavioral features, \\textsf{POIFormer} jointly models a rich set of signals, including spatial proximity, visit timing and duration, contextual features from POI semantics, and behavioral features from user mobility and aggregated crowd behavior patterns--using the Transformer's self-attention mechanism to jointly model complex interactions across these dimensions. By leveraging the Transformer to model a user's past and future visits (with the current visit masked) and incorporating crowd-level behavioral patterns through pre-computed KDEs, \\textsf{POIFormer} enables accurate, efficient attribution in large, noisy mobility datasets. Its architecture supports generalization across diverse data sources and geographic contexts while avoiding reliance on hard-to-access or unavailable data layers, making it practical for real-world deployment. Extensive experiments on real-world mobility datasets demonstrate significant improvements over existing baselines, particularly in challenging real-world settings characterized by spatial noise and dense POI clustering.",
      "authors": [
        "Nripsuta Ani Saxena",
        "Shang-Ling Hsu",
        "Mehul Shetty",
        "Omar Alkhadra",
        "Cyrus Shahabi",
        "Abigail L. Horn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T04:37:52+00:00",
          "link": "https://arxiv.org/abs/2507.09137v1",
          "size": "2234kb",
          "version": "v1"
        }
      ],
      "title": "POIFormer: A Transformer-Based Framework for Accurate and Scalable Point-of-Interest Attribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09137",
        "HTML": "https://arxiv.org/html/2507.09137v1",
        "PDF": "https://arxiv.org/pdf/2507.09137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a Transformer-based framework for Point-of-Interest Attribution and does not cover the collection, creation, or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09225",
      "abstract": "Visual metaphors of climate change (e.g., melting glaciers depicted as a melting ice grenade) are regarded as valuable tools for addressing the complexity of environmental challenges. However, few studies have examined their impact on communication, also due to scattered availability of material. Here, we present a novel database of Metaphors of Climate Change in Images (MetaClimage) https://doi.org/10.5281/zenodo.15861012, paired with literal images and enriched with human ratings. For each image, we collected values of difficulty, efficacy, artistic quality, and emotional arousal from human rating, as well as number of tags generated by participants to summarize the message. Semantic and emotion variables were further derived from the tags via Natural Language Processing. Visual metaphors were rated as more difficult to understand, yet more aesthetically pleasant than literal images, but did not differ in efficacy and arousal. The latter for visual metaphors, however, was higher in participants with higher Need For Cognition. Furthermore, visual metaphors received more tags, often referring to entities not depicted in the image, and elicited words with more positive valence and greater dominance than literal images. These results evidence the greater cognitive load of visual metaphors, which nevertheless might induce positive effects such as deeper cognitive elaboration and abstraction compared to literal stimuli. Furthermore, while they are not deemed as more effective and arousing, visual metaphors seem to generate superior aesthetic appreciation and a more positively valenced experience. Overall, this study contributes to understanding the impact of visual metaphors of climate change both by offering a database for future research and by elucidating a cost-benefit trade-off to take into account when shaping environmental communication.",
      "authors": [
        "Biagio Scalingi",
        "Chiara Barattieri di San Pietro",
        "Paolo Canal",
        "Valentina Bambini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:49:30+00:00",
          "link": "https://arxiv.org/abs/2507.09225v1",
          "size": "3445kb",
          "version": "v1"
        }
      ],
      "title": "MetaClimage: A novel database of visual metaphors related to Climate Change, with costs and benefits analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09225",
        "PDF": "https://arxiv.org/pdf/2507.09225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new database of visual metaphors, it primarily focuses on the analysis and effects of these metaphors rather than detailing data processing methods for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09794",
      "abstract": "We address the problem of optimal joint scheduling of deferrable and nondeferrable demand involving colocated stochastic supply. Deferrable demand can be delayed within its service deadline, whereas nondeferrable demand must be scheduled immediately. Under a finite-horizon stochastic dynamic programming formulation, we show that the optimal scheduling policy is a ``procrastination policy'' that delays scheduling as much as possible and is characterized by three procrastination parameters. Exploiting the low-dimensional parameterization of the optimal policy, we propose a Procrastination Threshold Reinforcement Learning algorithm. Numerical experiments based on real-world test data confirm that the threshold-learning algorithm closely approximates the optimal policy and outperforms standard benchmarks.",
      "authors": [
        "Minjae Jeon",
        "Lang Tong",
        "and Qing Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:15:11+00:00",
          "link": "https://arxiv.org/abs/2507.09794v1",
          "size": "2491kb",
          "version": "v1"
        }
      ],
      "title": "Joint Scheduling of Deferrable and Nondeferrable Demand with Colocated Stochastic Supply",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09794",
        "HTML": "https://arxiv.org/html/2507.09794v1",
        "PDF": "https://arxiv.org/pdf/2507.09794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses scheduling algorithms, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.11407",
      "abstract": "Multispectral point cloud (MPC) captures 3D spatial-spectral information from the observed scene, which can be used for scene understanding and has a wide range of applications. However, most of the existing classification methods were extensively tested on indoor datasets, and when applied to outdoor datasets they still face problems including sparse labeled targets, differences in land-covers scales, and long-tailed distributions. To address the above issues, an enhanced classification method based on adaptive multi-scale fusion for MPCs with long-tailed distributions is proposed. In the training set generation stage, a grid-balanced sampling strategy is designed to reliably generate training samples from sparse labeled datasets. In the feature learning stage, a multi-scale feature fusion module is proposed to fuse shallow features of land-covers at different scales, addressing the issue of losing fine features due to scale variations in land-covers. In the classification stage, an adaptive hybrid loss module is devised to utilize multi-classification heads with adaptive weights to balance the learning ability of different classes, improving the classification performance of small classes due to various-scales and long-tailed distributions in land-covers. Experimental results on three MPC datasets demonstrate the effectiveness of the proposed method compared with the state-of-the-art methods.",
      "authors": [
        "TianZhu Liu",
        "BangYan Hu",
        "YanFeng Gu",
        "Xian Li",
        "Aleksandra Pi\\v{z}urica"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T03:21:20+00:00",
          "link": "https://arxiv.org/abs/2412.11407v1",
          "size": "7704kb",
          "version": "v1"
        }
      ],
      "title": "An Enhanced Classification Method Based on Adaptive Multi-Scale Fusion for Long-tailed Multispectral Point Clouds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11407",
        "HTML": "https://arxiv.org/html/2412.11407",
        "PDF": "https://arxiv.org/pdf/2412.11407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for generating training samples from sparse labeled datasets using grid-balanced sampling, which is a data processing technique, but not in the context of LLM training."
      },
      "tasks": [
        "Classification",
        "Scene Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12720",
      "abstract": "Stereo images are fundamental to numerous applications, including extended reality (XR) devices, autonomous driving, and robotics. Unfortunately, acquiring high-quality stereo images remains challenging due to the precise calibration requirements of dual-camera setups and the complexity of obtaining accurate, dense disparity maps. Existing stereo image generation methods typically focus on either visual quality for viewing or geometric accuracy for matching, but not both. We introduce GenStereo, a diffusion-based approach, to bridge this gap. The method includes two primary innovations (1) conditioning the diffusion process on a disparity-aware coordinate embedding and a warped input image, allowing for more precise stereo alignment than previous methods, and (2) an adaptive fusion mechanism that intelligently combines the diffusion-generated image with a warped image, improving both realism and disparity consistency. Through extensive training on 11 diverse stereo datasets, GenStereo demonstrates strong generalization ability. GenStereo achieves state-of-the-art performance in both stereo image generation and unsupervised stereo matching tasks. Project page is available at https://qjizhi.github.io/genstereo.",
      "authors": [
        "Feng Qiao",
        "Zhexiao Xiong",
        "Eric Xing",
        "Nathan Jacobs"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T01:19:28+00:00",
          "link": "https://arxiv.org/abs/2503.12720v1",
          "size": "23378kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T03:07:24+00:00",
          "link": "https://arxiv.org/abs/2503.12720v2",
          "size": "3491kb",
          "version": "v2"
        }
      ],
      "title": "Towards Open-World Generation of Stereo Images and Unsupervised Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12720",
        "HTML": "https://arxiv.org/html/2503.12720v2",
        "PDF": "https://arxiv.org/pdf/2503.12720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on the generation of stereo images and includes a new method. However, it does not address LLM training data processing or creation specifically related to textual data."
      },
      "models": [
        {
          "model_path": "FQiao/GenStereo",
          "downloads": "23",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/FQiao/GenStereo"
        },
        {
          "model_path": "FQiao/GenStereo-sd2.1",
          "downloads": "19",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/FQiao/GenStereo-sd2.1"
        }
      ],
      "tasks": [
        "Autonomous Driving",
        "Image Generation",
        "Stereo Matching"
      ],
      "repo_urls": [
        "https://github.com/Qjizhi/GenStereo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09410",
      "abstract": "Camera traps have long been used by wildlife researchers to monitor and study animal behavior, population dynamics, habitat use, and species diversity in a non-invasive and efficient manner. While data collection from the field has increased with new tools and capabilities, methods to develop, process, and manage the data, especially the adoption of ML/AI tools, remain challenging. These challenges include the sheer volume of data generated, the need for accurate labeling and annotation, variability in environmental conditions affecting data quality, and the integration of ML/AI tools into existing workflows that often require domain-specific customization and computational resources. This paper provides a guide to a low-resource pipeline to process camera trap data on-premise, incorporating ML/AI capabilities tailored for small research groups with limited resources and computational expertise. By focusing on practical solutions, the pipeline offers accessible approaches for data transmission, inference, and evaluation, enabling researchers to discover meaningful insights from their ever-increasing camera trap datasets.",
      "authors": [
        "Bernie Boscoe",
        "Shawn Johnson",
        "Andrea Osborn",
        "Chandler Campbell",
        "Karen Mager"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T22:02:55+00:00",
          "link": "https://arxiv.org/abs/2507.09410v1",
          "size": "20217kb",
          "version": "v1"
        }
      ],
      "title": "GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09410",
        "HTML": "https://arxiv.org/html/2507.09410v1",
        "PDF": "https://arxiv.org/pdf/2507.09410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses data processing for camera traps, it is not related to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10155",
      "abstract": "Knowledge Distillation (KD) in general and feature distillation in particular are promising techniques for reducing the high computational demand of large language models (LLMs). However, traditional feature KD methods typically assume that the teacher and the student share the same hidden size, limiting the flexibility of the student's architecture. A common solution to this problem involves training a linear projector to align their feature spaces, but this introduces additional parameters that must be learned from scratch and often degrades performance on downstream tasks, especially in generative settings. To address this issue, in this work, we propose a novel task-based feature distillation method that enables knowledge transfer between teacher and student models with different hidden layer dimensions, without introducing any new parameters. Leveraging the insight that only a subset of LLM components contribute significantly to a specific downstream task, our approach identifies the most task-relevant hidden units in the teacher and directly distills their activations to the student. Our method is flexible and easily integrates with other distillation frameworks. Empirical results show consistent improvements over prior approaches across diverse tasks, including classification, instruction-following, and summarization, achieving up to a 3\\% performance gain over the linear projection baseline.",
      "authors": [
        "Khouloud Saadi and Di Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:10:02+00:00",
          "link": "https://arxiv.org/abs/2507.10155v1",
          "size": "12732kb",
          "version": "v1"
        }
      ],
      "title": "Task-Based Flexible Feature Distillation for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10155",
        "HTML": "https://arxiv.org/html/2507.10155v1",
        "PDF": "https://arxiv.org/pdf/2507.10155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a feature distillation method for knowledge transfer in LLMs, focusing on model architecture rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10156",
      "abstract": "AI has driven significant progress in the nutrition field, especially through multimedia-based automatic dietary assessment. However, existing automatic dietary assessment systems often overlook critical non-visual factors, such as recipe-specific ingredient substitutions that can significantly alter nutritional content, and rarely account for individual dietary needs, including allergies, restrictions, cultural practices, and personal preferences. In Switzerland, while food-related information is available, it remains fragmented, and no centralized repository currently integrates all relevant nutrition-related aspects within a Swiss context. To bridge this divide, we introduce the Swiss Food Knowledge Graph (SwissFKG), the first resource, to our best knowledge, to unite recipes, ingredients, and their substitutions with nutrient data, dietary restrictions, allergen information, and national nutrition guidelines under one graph. We establish a LLM-powered enrichment pipeline for populating the graph, whereby we further present the first benchmark of four off-the-shelf (<70 B parameter) LLMs for food knowledge augmentation. Our results demonstrate that LLMs can effectively enrich the graph with relevant nutritional information. Our SwissFKG goes beyond recipe recommendations by offering ingredient-level information such as allergen and dietary restriction information, and guidance aligned with nutritional guidelines. Moreover, we implement a Graph-RAG application to showcase how the SwissFKG's rich natural-language data structure can help LLM answer user-specific nutrition queries, and we evaluate LLM-embedding pairings by comparing user-query responses against predefined expected answers. As such, our work lays the foundation for the next generation of dietary assessment tools that blend visual, contextual, and cultural dimensions of eating.",
      "authors": [
        "Lubnaa Abdur Rahman",
        "Ioannis Papathanail",
        "Stavroula Mougiakakou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:12:30+00:00",
          "link": "https://arxiv.org/abs/2507.10156v1",
          "size": "1620kb",
          "version": "v1"
        }
      ],
      "title": "Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10156",
        "HTML": "https://arxiv.org/html/2507.10156v1",
        "PDF": "https://arxiv.org/pdf/2507.10156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses a LLM-powered enrichment pipeline for the Swiss Food Knowledge Graph, it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10213",
      "abstract": "Multimodal learning often encounters the under-optimized problem and may have worse performance than unimodal learning. Existing methods attribute this problem to the imbalanced learning between modalities and rebalance them through gradient modulation. However, they fail to explain why the dominant modality in multimodal models also underperforms that in unimodal learning. In this work, we reveal the optimization conflict between the modality encoder and modality fusion module in multimodal models. Specifically, we prove that the cross-modal fusion in multimodal models decreases the gradient passed back to each modality encoder compared with unimodal models. Consequently, the performance of each modality in the multimodal model is inferior to that in the unimodal model. To this end, we propose a disentangled gradient learning (DGL) framework to decouple the optimization of the modality encoder and modality fusion module in the multimodal model. DGL truncates the gradient back-propagated from the multimodal loss to the modality encoder and replaces it with the gradient from unimodal loss. Besides, DGL removes the gradient back-propagated from the unimodal loss to the modality fusion module. This helps eliminate the gradient interference between the modality encoder and modality fusion module while ensuring their respective optimization processes. Finally, extensive experiments on multiple types of modalities, tasks, and frameworks with dense cross-modal interaction demonstrate the effectiveness and versatility of the proposed DGL. Code is available at \\href{https://github.com/shicaiwei123/ICCV2025-GDL}{https://github.com/shicaiwei123/ICCV2025-GDL}",
      "authors": [
        "Shicai Wei",
        "Chunbo Luo",
        "Yang Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.10213v1",
          "size": "732kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Multimodal Learning via Disentangled Gradient Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10213",
        "HTML": "https://arxiv.org/html/2507.10213v1",
        "PDF": "https://arxiv.org/pdf/2507.10213"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving multimodal learning through disentangled gradient learning, focusing on optimization conflict solutions rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.05759",
      "abstract": "In low-light environments, the performance of computer vision algorithms often deteriorates significantly, adversely affecting key vision tasks such as segmentation, detection, and classification. With the rapid advancement of deep learning, its application to low-light image processing has attracted widespread attention and seen significant progress in recent years. However, there remains a lack of comprehensive surveys that systematically examine how recent deep-learning-based low-light image enhancement methods function and evaluate their effectiveness in enhancing downstream vision tasks. To address this gap, this review provides detailed elaboration on how various recent approaches (from 2020) operate and their enhancement mechanisms, supplemented with clear illustrations. It also investigates the impact of different enhancement techniques on subsequent vision tasks, critically analyzing their strengths and limitations. Our review found that image enhancement improved the performance of downstream vision tasks to varying degrees. Although supervised methods often produced images with high perceptual quality, they typically produced modest improvements in vision tasks. In contrast, zero-shot learning, despite achieving lower scores in image quality metrics, showed consistently boosted performance across various vision tasks. These suggest a disconnect between image quality metrics and those evaluating vision task performance. Additionally, unsupervised domain adaptation techniques demonstrated significant gains in segmentation tasks, highlighting their potential in practical low-light scenarios where labelled data is scarce. Observed limitations of existing studies are analyzed, and directions for future research are proposed. This review serves as a useful reference for determining low-light image enhancement techniques and optimizing vision task performance in low-light conditions.",
      "authors": [
        "Fangxue Liu and Lei Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T03:39:23+00:00",
          "link": "https://arxiv.org/abs/2505.05759v1",
          "size": "2013kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:31:12+00:00",
          "link": "https://arxiv.org/abs/2505.05759v2",
          "size": "2878kb",
          "version": "v2"
        }
      ],
      "title": "A review of advancements in low-light image enhancement using deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05759",
        "PDF": "https://arxiv.org/pdf/2505.05759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This is a review paper on advancements in low-light image enhancement using deep learning and does not address LLM training data processing or data engineering operations related to language models."
      },
      "tasks": [
        "Deep Learning",
        "Image Enhancement",
        "Low-Light Image Enhancement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08901",
      "abstract": "High-precision vectorized maps are indispensable for autonomous driving, yet traditional LiDAR-based creation is costly and slow, while single-vehicle perception methods lack accuracy and robustness, particularly in adverse conditions. This paper introduces EGC-VMAP, an end-to-end framework that overcomes these limitations by generating accurate, city-scale vectorized maps through the aggregation of data from crowdsourced vehicles. Unlike prior approaches, EGC-VMAP directly fuses multi-vehicle, multi-temporal map elements perceived onboard vehicles using a novel Trip-Aware Transformer architecture within a unified learning process. Combined with hierarchical matching for efficient training and a multi-objective loss, our method significantly enhances map accuracy and structural robustness compared to single-vehicle baselines. Validated on a large-scale, multi-city real-world dataset, EGC-VMAP demonstrates superior performance, enabling a scalable, cost-effective solution for city-wide mapping with a reported 90\\% reduction in manual annotation costs.",
      "authors": [
        "Zebang Feng",
        "Miao Fan",
        "Bao Liu",
        "Shengtong Xu",
        "Haoyi Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:04:08+00:00",
          "link": "https://arxiv.org/abs/2507.08901v1",
          "size": "1003kb",
          "version": "v1"
        }
      ],
      "title": "End-to-End Generation of City-Scale Vectorized Maps by Crowdsourced Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08901",
        "HTML": "https://arxiv.org/html/2507.08901v1",
        "PDF": "https://arxiv.org/pdf/2507.08901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for generating vectorized maps using crowdsourced vehicle data. It does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09087",
      "abstract": "Achieving fast and stable off-policy learning in deep reinforcement learning (RL) is challenging. Most existing methods rely on semi-gradient temporal-difference (TD) methods for their simplicity and efficiency, but are consequently susceptible to divergence. While more principled approaches like Gradient TD (GTD) methods have strong convergence guarantees, they have rarely been used in deep RL. Recent work introduced the Generalized Projected Bellman Error ($\\GPBE$), enabling GTD methods to work efficiently with nonlinear function approximation. However, this work is only limited to one-step methods, which are slow at credit assignment and require a large number of samples. In this paper, we extend the $\\GPBE$ objective to support multistep credit assignment based on the $\\lambda$-return and derive three gradient-based methods that optimize this new objective. We provide both a forward-view formulation compatible with experience replay and a backward-view formulation compatible with streaming algorithms. Finally, we evaluate the proposed algorithms and show that they outperform both PPO and StreamQ in MuJoCo and MinAtar environments, respectively. Code available at https://github.com/esraaelelimy/gtd\\_algos",
      "authors": [
        "Esraa Elelimy",
        "Brett Daley",
        "Andrew Patterson",
        "Marlos C. Machado",
        "Adam White",
        "Martha White"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:12:05+00:00",
          "link": "https://arxiv.org/abs/2507.09087v1",
          "size": "626kb",
          "version": "v1"
        }
      ],
      "title": "Deep Reinforcement Learning with Gradient Eligibility Traces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09087",
        "PDF": "https://arxiv.org/pdf/2507.09087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on reinforcement learning algorithms and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09923",
      "abstract": "Super-resolution (SR) has been a pivotal task in image processing, aimed at enhancing image resolution across various applications. Recently, look-up table (LUT)-based approaches have attracted interest due to their efficiency and performance. However, these methods are typically designed for fixed scale factors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing ASISR techniques often employ implicit neural representations, which come with considerable computational cost and memory demands. To address these limitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework that operates ASISR by learning to blend multiple interpolation functions to maximize their representational capacity. Specifically, we introduce IM-Net, a network trained to predict mixing weights for interpolation functions based on local image patterns and the target scale factor. To enhance efficiency of interpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are employed to replace computationally expensive operations, enabling lightweight and fast inference on CPUs while preserving reconstruction quality. Experimental results on several benchmark datasets demonstrate that IM-LUT consistently achieves a superior balance between image quality and efficiency compared to existing methods, highlighting its potential as a promising solution for resource-constrained applications.",
      "authors": [
        "Sejin Park",
        "Sangmin Lee",
        "Kyong Hwan Jin",
        "Seung-Won Jung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:02:57+00:00",
          "link": "https://arxiv.org/abs/2507.09923v1",
          "size": "24652kb",
          "version": "v1"
        }
      ],
      "title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09923",
        "HTML": "https://arxiv.org/html/2507.09923v1",
        "PDF": "https://arxiv.org/pdf/2507.09923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about image super-resolution using interpolation LUTs and has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10006",
      "abstract": "With the rapid advancement of UAV technology and its extensive application in various fields such as military reconnaissance, environmental monitoring, and logistics, achieving efficient and accurate Anti-UAV tracking has become essential. The importance of Anti-UAV tracking is increasingly prominent, especially in scenarios such as public safety, border patrol, search and rescue, and agricultural monitoring, where operations in complex environments can provide enhanced security. Current mainstream Anti-UAV tracking technologies are primarily centered around computer vision techniques, particularly those that integrate multi-sensor data fusion with advanced detection and tracking algorithms. This paper first reviews the characteristics and current challenges of Anti-UAV detection and tracking technologies. Next, it investigates and compiles several publicly available datasets, providing accessible links to support researchers in efficiently addressing related challenges. Furthermore, the paper analyzes the major vision-based and vision-fusion-based Anti-UAV detection and tracking algorithms proposed in recent years. Finally, based on the above research, this paper outlines future research directions, aiming to provide valuable insights for advancing the field.",
      "authors": [
        "Guanghai Ding",
        "Yihua Ren",
        "Yuting Liu",
        "Qijun Zhao",
        "and Shuiwang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:39:55+00:00",
          "link": "https://arxiv.org/abs/2507.10006v1",
          "size": "3288kb",
          "version": "v1"
        }
      ],
      "title": "Vision-Based Anti Unmanned Aerial Technology: Opportunities and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10006",
        "HTML": "https://arxiv.org/html/2507.10006v1",
        "PDF": "https://arxiv.org/pdf/2507.10006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses Anti-UAV detection and tracking technologies and mentions datasets, it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10113",
      "abstract": "Cell-Free Massive multiple-input multiple-output (MIMO) systems are investigated with the support of a reconfigurable intelligent surface (RIS). The RIS phase shifts are designed for improved channel estimation in the presence of spatial correlation. Specifically, we formulate the channel estimate and estimation error expressions using linear minimum mean square error (LMMSE) estimation for the aggregated channels. An optimization problem is then formulated to minimize the average normalized mean square error (NMSE) subject to practical phase shift constraints. To circumvent the problem of inherent nonconvexity, we then conceive an enhanced version of the differential evolution algorithm that is capable of avoiding local minima by introducing an augmentation operator applied to some high-performing Diffential Evolution (DE) individuals. Numerical results indicate that our proposed algorithm can significantly improve the channel estimation quality of the state-of-the-art benchmarks.",
      "authors": [
        "Trinh Van Chien and Nguyen Hoang Viet and Symeon Chatzinotas and Lajos Hanzo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:57:20+00:00",
          "link": "https://arxiv.org/abs/2507.10113v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Improved Differential Evolution for Enhancing the Aggregated Channel Estimation of RIS-Aided Cell-Free Massive MIMO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10113",
        "HTML": "https://arxiv.org/html/2507.10113v1",
        "PDF": "https://arxiv.org/pdf/2507.10113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on channel estimation for RIS-aided systems in MIMO networks, with no discussion on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09647",
      "abstract": "In recent years, the rampant spread of misinformation on social media has made accurate detection of multimodal fake news a critical research focus. However, previous research has not adequately understood the semantics of images, and models struggle to discern news authenticity with limited textual information. Meanwhile, treating all emotional types of news uniformly without tailored approaches further leads to performance degradation. Therefore, we propose a novel Knowledge Augmentation and Emotion Guidance Network (KEN). On the one hand, we effectively leverage LVLM's powerful semantic understanding and extensive world knowledge. For images, the generated captions provide a comprehensive understanding of image content and scenes, while for text, the retrieved evidence helps break the information silos caused by the closed and limited text and context. On the other hand, we consider inter-class differences between different emotional types of news through balanced learning, achieving fine-grained modeling of the relationship between emotional types and authenticity. Extensive experiments on two real-world datasets demonstrate the superiority of our KEN.",
      "authors": [
        "Peican Zhu",
        "Yubo Jing",
        "Le Cheng",
        "Keke Tang",
        "Yangming Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:28:20+00:00",
          "link": "https://arxiv.org/abs/2507.09647v1",
          "size": "1775kb",
          "version": "v1"
        }
      ],
      "title": "KEN: Knowledge Augmentation and Emotion Guidance Network for Multimodal Fake News Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09647",
        "HTML": "https://arxiv.org/html/2507.09647v1",
        "PDF": "https://arxiv.org/pdf/2507.09647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a network for multimodal fake news detection, leveraging semantic understanding and emotional type balancing, without a focus on creating or processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09797",
      "abstract": "LinkedIn, one of the world's largest platforms for professional networking and job seeking, encounters various modeling challenges in building recommendation systems for its job matching product, including cold-start, filter bubbles, and biases affecting candidate-job matching. To address these, we developed the STAR (Signal Integration for Talent And Recruiters) system, leveraging the combined strengths of Large Language Models (LLMs) and Graph Neural Networks (GNNs). LLMs excel at understanding textual data, such as member profiles and job postings, while GNNs capture intricate relationships and mitigate cold-start issues through network effects. STAR integrates diverse signals by uniting LLM and GNN capabilities with industrial-scale paradigms including adaptive sampling and version management. It provides an end-to-end solution for developing and deploying embeddings in large-scale recommender systems. Our key contributions include a robust methodology for building embeddings in industrial applications, a scalable GNN-LLM integration for high-performing recommendations, and practical insights for real-world model deployment.",
      "authors": [
        "Ping Liu",
        "Rajat Arora",
        "Xiao Shi",
        "Benjamin Le",
        "Qianqi Shen",
        "Jianqiang Shen",
        "Chengming Jiang",
        "Nikita Zhiltsov",
        "Priya Bannur",
        "Yidan Zhu",
        "Liming Dong",
        "Haichao Wei",
        "Qi Guo",
        "Luke Simon",
        "Liangjie Hong and Wenjing Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:23:37+00:00",
          "link": "https://arxiv.org/abs/2507.09797v1",
          "size": "154kb",
          "version": "v1"
        }
      ],
      "title": "A Scalable and Efficient Signal Integration System for Job Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09797",
        "HTML": "https://arxiv.org/html/2507.09797v1",
        "PDF": "https://arxiv.org/pdf/2507.09797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on integrating LLMs and GNNs for job matching systems, not directly related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10434",
      "abstract": "Self-supervised learning (SSL) is able to build latent representations that generalize well to unseen data. However, only a few SSL techniques exist for the online CL setting, where data arrives in small minibatches, the model must comply with a fixed computational budget, and task boundaries are absent. We introduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL that aligns the representations learned by the current model with past representations to mitigate forgetting. We found that our CLA is able to speed up the convergence of the training process in the online scenario, outperforming state-of-the-art approaches under the same computational budget. Surprisingly, we also discovered that using CLA as a pretraining protocol in the early stages of pretraining leads to a better final performance when compared to a full i.i.d. pretraining.",
      "authors": [
        "Giacomo Cignoni",
        "Andrea Cossu",
        "Alexandra Gomez-Villa",
        "Joost van de Weijer and Antonio Carta"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:23:39+00:00",
          "link": "https://arxiv.org/abs/2507.10434v1",
          "size": "467kb",
          "version": "v1"
        }
      ],
      "title": "CLA: Latent Alignment for Online Continual Self-Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10434",
        "HTML": "https://arxiv.org/html/2507.10434v1",
        "PDF": "https://arxiv.org/pdf/2507.10434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a self-supervised learning strategy for online continual learning and mentions pretraining protocols, but the focus is not primarily on LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18444",
      "abstract": "Identifier names are crucial components of code, serving as primary clues for developers to understand program behavior. This paper investigates the linguistic structure of identifier names by extending the concept of grammar patterns, which represent the part-of-speech (PoS) sequences underlying identifier phrases. The specific focus is on closed syntactic categories (e.g., prepositions, conjunctions, determiners), which are rarely studied in software engineering despite their central role in general natural language. To study these categories, the Closed Category Identifier Dataset (CCID), a new manually annotated dataset of 1,275 identifiers drawn from 30 open-source systems, is constructed and presented. The relationship between closed-category grammar patterns and program behavior is then analyzed using grounded-theory-inspired coding, statistical, and pattern analysis. The results reveal recurring structures that developers use to express concepts such as control flow, data transformation, temporal reasoning, and other behavioral roles through naming. This work contributes an empirical foundation for understanding how linguistic resources encode behavior in identifier names and supports new directions for research in naming, program comprehension, and education.",
      "authors": [
        "Christian D. Newman",
        "Anthony Peruma",
        "Eman Abdullah AlOmar",
        "Mahie Crabbe",
        "Syreen Banabilah",
        "Reem S. AlSuhaibani",
        "Michael J. Decker",
        "Farhad Akhbardeh",
        "Marcos Zampieri",
        "Mohamed Wiem Mkaouer",
        "Jonathan I. Maletic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T00:58:50+00:00",
          "link": "https://arxiv.org/abs/2505.18444v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T14:56:01+00:00",
          "link": "https://arxiv.org/abs/2505.18444v2",
          "size": "318kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T17:26:28+00:00",
          "link": "https://arxiv.org/abs/2505.18444v3",
          "size": "318kb",
          "version": "v3"
        }
      ],
      "title": "On the Structure and Semantics of Identifier Names Containing Closed Syntactic Category Words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18444",
        "HTML": "https://arxiv.org/html/2505.18444v3",
        "PDF": "https://arxiv.org/pdf/2505.18444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding linguistic structures in identifier names within software engineering, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12190",
      "abstract": "Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+/HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging.",
      "authors": [
        "Naomi Fridman",
        "Bubby Solway",
        "Tomer Fridman",
        "Itamar Barnea",
        "Anat Goldstein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T19:31:57+00:00",
          "link": "https://arxiv.org/abs/2506.12190v1",
          "size": "6044kb",
          "version": "v1"
        },
        {
          "date": "2025-06-20T17:29:37+00:00",
          "link": "https://arxiv.org/abs/2506.12190v2",
          "size": "3164kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T14:35:18+00:00",
          "link": "https://arxiv.org/abs/2506.12190v3",
          "size": "3164kb",
          "version": "v3"
        }
      ],
      "title": "BreastDCEDL: A Comprehensive Breast Cancer DCE-MRI Dataset and Transformer Implementation for Treatment Response Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12190",
        "HTML": "https://arxiv.org/html/2506.12190v3",
        "PDF": "https://arxiv.org/pdf/2506.12190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a curated medical imaging dataset with detailed processing steps. However, it primarily focuses on medical imaging and does not explicitly address LLM training data or data engineering specifically for LLMs."
      },
      "tasks": [
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09560",
      "abstract": "3D hand pose estimation has garnered great attention in recent years due to its critical applications in human-computer interaction, virtual reality, and related fields. The accurate estimation of hand joints is essential for high-quality hand pose estimation. However, existing methods neglect the importance of Distal Phalanx Tip (TIP) and Wrist in predicting hand joints overall and often fail to account for the phenomenon of error accumulation for distal joints in gesture estimation, which can cause certain joints to incur larger errors, resulting in misalignments and artifacts in the pose estimation and degrading the overall reconstruction quality. To address this challenge, we propose a novel segmented architecture for enhanced hand pose estimation (EHPE). We perform local extraction of TIP and wrist, thus alleviating the effect of error accumulation on TIP prediction and further reduce the predictive errors for all joints on this basis. EHPE consists of two key stages: In the TIP and Wrist Joints Extraction stage (TW-stage), the positions of the TIP and wrist joints are estimated to provide an initial accurate joint configuration; In the Prior Guided Joints Estimation stage (PG-stage), a dual-branch interaction network is employed to refine the positions of the remaining joints. Extensive experiments on two widely used benchmarks demonstrate that EHPE achieves state-of-the-arts performance. Code is available at https://github.com/SereinNout/EHPE.",
      "authors": [
        "Bolun Zheng",
        "Xinjie Liu",
        "Qianyu Zhang",
        "Canjin Wang",
        "Fangni Chen",
        "Mingen Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:09:23+00:00",
          "link": "https://arxiv.org/abs/2507.09560v1",
          "size": "1295kb",
          "version": "v1"
        }
      ],
      "title": "EHPE: A Segmented Architecture for Enhanced Hand Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09560",
        "HTML": "https://arxiv.org/html/2507.09560v1",
        "PDF": "https://arxiv.org/pdf/2507.09560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hand pose estimation techniques, specifically the architecture for estimating hand joints. There is no mention or implication of any LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09573",
      "abstract": "Artistic typography aims to stylize input characters with visual effects that are both creative and legible. Traditional approaches rely heavily on manual design, while recent generative models, particularly diffusion-based methods, have enabled automated character stylization. However, existing solutions remain limited in interactivity, lacking support for localized edits, iterative refinement, multi-character composition, and open-ended prompt interpretation. We introduce WordCraft, an interactive artistic typography system that integrates diffusion models to address these limitations. WordCraft features a training-free regional attention mechanism for precise, multi-region generation and a noise blending that supports continuous refinement without compromising visual quality. To support flexible, intent-driven generation, we incorporate a large language model to parse and structure both concrete and abstract user prompts. These components allow our framework to synthesize high-quality, stylized typography across single- and multi-character inputs across multiple languages, supporting diverse user-centered workflows. Our system significantly enhances interactivity in artistic typography synthesis, opening up creative possibilities for artists and designers.",
      "authors": [
        "Zhe Wang",
        "Jingbo Zhang",
        "Tianyi Wei",
        "Wanchao Su",
        "Can Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:49:09+00:00",
          "link": "https://arxiv.org/abs/2507.09573v1",
          "size": "38030kb",
          "version": "v1"
        }
      ],
      "title": "WordCraft: Interactive Artistic Typography with Attention Awareness and Noise Blending",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09573",
        "HTML": "https://arxiv.org/html/2507.09573v1",
        "PDF": "https://arxiv.org/pdf/2507.09573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an artistic typography system using diffusion models and LLMs for prompt interpretation, but it does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10347",
      "abstract": "In this paper, we design an algorithm to accelerate the diffusion process on the $SO(3)$ manifold. The inherently sequential nature of diffusion models necessitates substantial time for denoising perturbed data. To overcome this limitation, we proposed to adapt the numerical Picard iteration for the $SO(3)$ space. We demonstrate our algorithm on an existing method that employs diffusion models to address the pose ambiguity problem. Moreover, we show that this acceleration advantage occurs without any measurable degradation in task reward. The experiments reveal that our algorithm achieves a speed-up of up to 4.9$\\times$, significantly reducing the latency for generating a single sample.",
      "authors": [
        "Yan-Ting Chen",
        "Hao-Wei Chen",
        "Tsu-Ching Hsiao",
        "and Chun-Yi Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:51:02+00:00",
          "link": "https://arxiv.org/abs/2507.10347v1",
          "size": "2035kb",
          "version": "v1"
        }
      ],
      "title": "Parallel Sampling of Diffusion Models on $SO(3)$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10347",
        "HTML": "https://arxiv.org/html/2507.10347v1",
        "PDF": "https://arxiv.org/pdf/2507.10347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on accelerating the diffusion process and pose ambiguity resolution using diffusion models. It does not discuss LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.12429",
      "abstract": "Combining Vision Large Language Models (VLLMs) with diffusion models offers a powerful method for executing image editing tasks based on human language instructions. However, language instructions alone often fall short in accurately conveying user requirements, particularly when users want to add, replace elements in specific areas of an image. Luckily, masks can effectively indicate the exact locations or elements to be edited, while they require users to precisely draw the shapes at the desired locations, which is highly user-unfriendly. To address this, we propose FlexEdit, an end-to-end image editing method that leverages both free-shape masks and language instructions for Flexible Editing. Our approach employs a VLLM in comprehending the image content, mask, and user instructions. Additionally, we introduce the Mask Enhance Adapter (MEA) that fuses the embeddings of the VLLM with the image data, ensuring a seamless integration of mask information and model output embeddings. Furthermore, we construct FSMI-Edit, a benchmark specifically tailored for free-shape mask, including 8 types of free-shape mask. Extensive experiments show that our method achieves state-of-the-art (SOTA) performance in LLM-based image editing, and our simple prompting technique stands out in its effectiveness. The code and data can be found at https://github.com/A-new-b/flex_edit.",
      "authors": [
        "Tianshuo Yuan",
        "Yuxiang Lin",
        "Jue Wang",
        "Zhi-Qi Cheng",
        "Xiaolong Wang",
        "Jiao GH",
        "Wei Chen",
        "Xiaojiang Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T14:22:07+00:00",
          "link": "https://arxiv.org/abs/2408.12429v1",
          "size": "16110kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T14:38:31+00:00",
          "link": "https://arxiv.org/abs/2408.12429v2",
          "size": "9859kb",
          "version": "v2"
        }
      ],
      "title": "FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12429",
        "HTML": "https://arxiv.org/html/2408.12429v2",
        "PDF": "https://arxiv.org/pdf/2408.12429"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for image editing using Vision Large Language Models, but it does not contribute to processing or improving datasets for LLM training."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/a-new-b/flex_edit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08438",
      "abstract": "Diffusion generative models have demonstrated remarkable success in visual domains such as image and video generation. They have also recently emerged as a promising approach in robotics, especially in robot manipulations. Diffusion models leverage a probabilistic framework, and they stand out with their ability to model multi-modal distributions and their robustness to high-dimensional input and output spaces. This survey provides a comprehensive review of state-of-the-art diffusion models in robotic manipulation, including grasp learning, trajectory planning, and data augmentation. Diffusion models for scene and image augmentation lie at the intersection of robotics and computer vision for vision-based tasks to enhance generalizability and data scarcity. This paper also presents the two main frameworks of diffusion models and their integration with imitation learning and reinforcement learning. In addition, it discusses the common architectures and benchmarks and points out the challenges and advantages of current state-of-the-art diffusion-based methods.",
      "authors": [
        "Rosa Wolf",
        "Yitian Shi",
        "Sheng Liu",
        "Rania Rayyes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T11:01:11+00:00",
          "link": "https://arxiv.org/abs/2504.08438v1",
          "size": "1002kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:32:22+00:00",
          "link": "https://arxiv.org/abs/2504.08438v2",
          "size": "1831kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T11:02:41+00:00",
          "link": "https://arxiv.org/abs/2504.08438v3",
          "size": "1835kb",
          "version": "v3"
        }
      ],
      "title": "Diffusion Models for Robotic Manipulation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08438",
        "HTML": "https://arxiv.org/html/2504.08438v3",
        "PDF": "https://arxiv.org/pdf/2504.08438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the survey discusses diffusion models relevant to data augmentation in robotics, it does not primarily focus on LLM training data processing or the creation of datasets."
      },
      "tasks": [
        "Data Augmentation",
        "Image Augmentation",
        "Imitation Learning",
        "Survey",
        "Trajectory Planning",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09055",
      "abstract": "The rapid spread of health misinformation on online social networks (OSNs) during global crises such as the COVID-19 pandemic poses challenges to public health, social stability, and institutional trust. Centrality metrics have long been pivotal in understanding the dynamics of information flow, particularly in the context of health misinformation. However, the increasing complexity and dynamism of online networks, especially during crises, highlight the limitations of these traditional approaches. This study introduces and compares three novel centrality metrics: dynamic influence centrality (DIC), health misinformation vulnerability centrality (MVC), and propagation centrality (PC). These metrics incorporate temporal dynamics, susceptibility, and multilayered network interactions. Using the FibVID dataset, we compared traditional and novel metrics to identify influential nodes, propagation pathways, and misinformation influencers. Traditional metrics identified 29 influential nodes, while the new metrics uncovered 24 unique nodes, resulting in 42 combined nodes, an increase of 44.83%. Baseline interventions reduced health misinformation by 50%, while incorporating the new metrics increased this to 62.5%, an improvement of 25%. To evaluate the broader applicability of the proposed metrics, we validated our framework on a second dataset, Monant Medical Misinformation, which covers a diverse range of health misinformation discussions beyond COVID-19. The results confirmed that the advanced metrics generalised successfully, identifying distinct influential actors not captured by traditional methods. In general, the findings suggest that a combination of traditional and novel centrality measures offers a more robust and generalisable framework for understanding and mitigating the spread of health misinformation in different online network contexts.",
      "authors": [
        "Mkululi Sikosana",
        "Sean Maudsley-Barton",
        "Oluwaseun Ajao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T22:19:39+00:00",
          "link": "https://arxiv.org/abs/2507.09055v1",
          "size": "1153kb",
          "version": "v1"
        }
      ],
      "title": "Analysing Health Misinformation with Advanced Centrality Metrics in Online Social Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09055",
        "PDF": "https://arxiv.org/pdf/2507.09055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on measuring and mitigating health misinformation spread in online networks using novel centrality metrics, with no mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09063",
      "abstract": "Modern Large Language Model (LLM) agents promise end to end assistance with real-world software tasks, yet existing benchmarks evaluate LLM agents almost exclusively in pre-baked environments where every dependency is pre-installed. To fill this gap, we introduce SetupBench, a 93 instance benchmark that isolates the environment-bootstrap skill: starting from a bare Linux sandbox, an agent must install packages, resolve dependency conflicts, initialize databases, and configure background services. Our tasks span seven language ecosystems, five database engines, and multi-service orchestration scenarios, each accompanies by a natural language problem statement and a deterministic success command. Through evaluation of OpenHands, a state-of-the-art coding agent, we find low success rates across task categories, with particular challenges in repository setup (38.9-57.4%) and local database configuration (20.0-53.3%). Our analysis reveals systematic failure modes including incomplete development tooling installation, hallucinated task constraints, and non-persistent environment modifications that break agent-human collaboration workflows. We identify substantial inefficiencies in agent exploration strategies, with 38-89% of actions being unnecessary compared to optimal human behavior. These findings highlight gaps in current agents' practical environment-bootstrap capabilities. By targeting this critical yet under-evaluated capability, SetupBench provides a rigorous yard-stick for the next generation of software developer agents aiming to solve end to end real-wold tasks.",
      "authors": [
        "Avi Arora",
        "Jinu Jang",
        "Roshanak Zilouchian Moghaddam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T22:45:07+00:00",
          "link": "https://arxiv.org/abs/2507.09063v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09063",
        "PDF": "https://arxiv.org/pdf/2507.09063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark called SetupBench to evaluate software engineering agents, with no focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09406",
      "abstract": "Large language models (LLMs) aligned for safety through techniques like reinforcement learning from human feedback (RLHF) often exhibit emergent deceptive behaviors, where outputs appear compliant but subtly mislead or omit critical information. This paper introduces adversarial activation patching, a novel mechanistic interpretability framework that leverages activation patching as an adversarial tool to induce, detect, and mitigate such deception in transformer-based models. By sourcing activations from \"deceptive\" prompts and patching them into safe forward passes at specific layers, we simulate vulnerabilities and quantify deception rates. Through toy neural network simulations across multiple scenarios (e.g., 1000 trials per setup), we demonstrate that adversarial patching increases deceptive outputs to 23.9% from a 0% baseline, with layer-specific variations supporting our hypotheses. We propose six hypotheses, including transferability across models, exacerbation in multimodal settings, and scaling effects. An expanded literature review synthesizes over 20 key works in interpretability, deception, and adversarial attacks. Mitigation strategies, such as activation anomaly detection and robust fine-tuning, are detailed, alongside ethical considerations and future research directions. This work advances AI safety by highlighting patching's dual-use potential and provides a roadmap for empirical studies on large-scale models.",
      "authors": [
        "Santhosh Kumar Ravindran"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T21:29:49+00:00",
          "link": "https://arxiv.org/abs/2507.09406v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Activation Patching: A Framework for Detecting and Mitigating Emergent Deception in Safety-Aligned Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09406",
        "HTML": "https://arxiv.org/html/2507.09406v1",
        "PDF": "https://arxiv.org/pdf/2507.09406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on detecting and mitigating deceptive behaviors in LLMs through mechanistic interpretability, without addressing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09481",
      "abstract": "By integrating tools from external APIs, Large Language Models (LLMs) have expanded their promising capabilities in a diverse spectrum of complex real-world tasks. However, testing, evaluation, and analysis of LLM tool use remain in their early stages. Most existing benchmarks rely on manually collected test cases, many of which cannot be automatically checked for semantic correctness and instead depend on static methods such as string matching. Additionally, these benchmarks often overlook the complex interactions that occur between sequential API calls, which are common in real-world applications. To fill the gap, in this paper, we introduce StateGen, an automated framework designed to generate diverse coding tasks involving sequential API interactions. StateGen combines state-machine-based API constraint solving and validation, energy-based sampling, and control-flow injection to generate executable programs. These programs are then translated into human-like natural language task descriptions through a collaboration of two LLM agents. Utilizing StateGen, we construct StateEval, a benchmark encompassing 120 verified test cases spanning across three representative scenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental results confirm that StateGen can effectively generate challenging and realistic API-oriented tasks, highlighting areas for improvement in current LLMs incorporating APIs.",
      "authors": [
        "Yuheng Huang",
        "Da Song",
        "Zhenlan Ji",
        "Shuai Wang",
        "Lei Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:52:51+00:00",
          "link": "https://arxiv.org/abs/2507.09481v1",
          "size": "453kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating LLMs on Sequential API Call Through Automated Test Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09481",
        "HTML": "https://arxiv.org/html/2507.09481v1",
        "PDF": "https://arxiv.org/pdf/2507.09481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper introduces an automated framework for test generation and evaluation of API interactions, it does not focus on LLM training data processing. It touches on creating task descriptions but not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09541",
      "abstract": "Infrared small target detection plays a vital role in remote sensing, industrial monitoring, and various civilian applications. Despite recent progress powered by deep learning, many end-to-end convolutional models tend to pursue performance by stacking increasingly complex architectures, often at the expense of interpretability, parameter efficiency, and generalization. These models typically overlook the intrinsic sparsity prior of infrared small targets--an essential cue that can be explicitly modeled for both performance and efficiency gains. To address this, we revisit the model-based paradigm of Robust Principal Component Analysis (RPCA) and propose Dynamic RPCA Network (DRPCA-Net), a novel deep unfolding network that integrates the sparsity-aware prior into a learnable architecture. Unlike conventional deep unfolding methods that rely on static, globally learned parameters, DRPCA-Net introduces a dynamic unfolding mechanism via a lightweight hypernetwork. This design enables the model to adaptively generate iteration-wise parameters conditioned on the input scene, thereby enhancing its robustness and generalization across diverse backgrounds. Furthermore, we design a Dynamic Residual Group (DRG) module to better capture contextual variations within the background, leading to more accurate low-rank estimation and improved separation of small targets. Extensive experiments on multiple public infrared datasets demonstrate that DRPCA-Net significantly outperforms existing state-of-the-art methods in detection accuracy. Code is available at https://github.com/GrokCV/DRPCA-Net.",
      "authors": [
        "Zihao Xiong and Fei Zhou and Fengyi Wu and Shuai Yuan and Maixia Fu and Zhenming Peng and Jian Yang and Yimian Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:55:51+00:00",
          "link": "https://arxiv.org/abs/2507.09541v1",
          "size": "8081kb",
          "version": "v1"
        }
      ],
      "title": "DRPCA-Net: Make Robust PCA Great Again for Infrared Small Target Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09541",
        "HTML": "https://arxiv.org/html/2507.09541v1",
        "PDF": "https://arxiv.org/pdf/2507.09541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for improving infrared target detection using dynamic RPCA, which does not involve LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10340",
      "abstract": "Despite the success of diffusion models in image generation tasks such as text-to-image, the enormous computational complexity of diffusion models limits their use in resource-constrained environments. To address this, network quantization has emerged as a promising solution for designing efficient diffusion models. However, existing diffusion model quantization methods do not consider input conditions, such as text prompts, as an essential source of information for quantization. In this paper, we propose a novel quantization method dubbed Quantization of Language-to-Image diffusion models using text Prompts (QLIP). QLIP leverages text prompts to guide the selection of bit precision for every layer at each time step. In addition, QLIP can be seamlessly integrated into existing quantization methods to enhance quantization efficiency. Our extensive experiments demonstrate the effectiveness of QLIP in reducing computational complexity and improving the quality of the generated images across various datasets.",
      "authors": [
        "Hongjae Lee",
        "Myungjun Son",
        "Dongjea Kang",
        "Seung-Won Jung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:44:59+00:00",
          "link": "https://arxiv.org/abs/2507.10340v1",
          "size": "35980kb",
          "version": "v1"
        }
      ],
      "title": "Text Embedding Knows How to Quantize Text-Guided Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10340",
        "HTML": "https://arxiv.org/html/2507.10340v1",
        "PDF": "https://arxiv.org/pdf/2507.10340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a quantization method for diffusion models, which is unrelated to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10532",
      "abstract": "The reasoning capabilities of large language models (LLMs) have been a longstanding focus of research. Recent works have further enhanced these capabilities using reinforcement learning (RL), with many new methods claiming significant improvements with minimal or no external supervision. Surprisingly, some studies even suggest that random or incorrect reward signals can enhance reasoning performance. However, these breakthroughs are mostly reported on the Qwen2.5 model family and evaluated on well-known benchmarks such as MATH-500, AMC, and AIME, while failing to achieve similar gains on other models like Llama, which warrants further investigation. Our analysis shows that although Qwen2.5 achieves strong mathematical reasoning performance, its pretraining on large-scale web corpora makes it vulnerable to data contamination in popular benchmarks. As a result, results derived from these benchmarks may be unreliable. To address this, we introduce a generator that produces fully synthetic arithmetic problems of arbitrary length and difficulty, yielding a clean dataset we call RandomCalculation. Using these leakage-free datasets, we show that only accurate reward signals consistently improve performance, while noisy or incorrect signals do not. We advocate for evaluating RL methods on uncontaminated benchmarks and across diverse model families to ensure trustworthy conclusions.",
      "authors": [
        "Mingqi Wu",
        "Zhihao Zhang",
        "Qiaole Dong",
        "Zhiheng Xi",
        "Jun Zhao",
        "Senjie Jin",
        "Xiaoran Fan",
        "Yuhao Zhou",
        "Yanwei Fu",
        "Qin Liu",
        "Songyang Zhang",
        "Qi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:55:15+00:00",
          "link": "https://arxiv.org/abs/2507.10532v1",
          "size": "238kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10532",
        "HTML": "https://arxiv.org/html/2507.10532v1",
        "PDF": "https://arxiv.org/pdf/2507.10532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a generator to produce uncontaminated synthetic arithmetic datasets, addressing dataset contamination issues affecting LLM training data quality and evaluation reliability."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01758",
      "abstract": "Diffusion models have shown impressive performance in many visual generation and manipulation tasks. Many existing methods focus on training a model for a specific task, especially, text-to-video (T2V) generation, while many other works focus on finetuning the pretrained T2V model for image-to-video (I2V), video-to-video (V2V), image and video manipulation tasks, etc. However, training a strong T2V foundation model requires a large amount of high-quality annotations, which is very costly. In addition, many existing models can perform only one or several tasks. In this work, we introduce a unified framework, namely many-for-many, which leverages the available training data from many different visual generation and manipulation tasks to train a single model for those different tasks. Specifically, we design a lightweight adapter to unify the different conditions in different tasks, then employ a joint image-video learning strategy to progressively train the model from scratch. Our joint learning leads to a unified visual generation and manipulation model with improved video generation performance. In addition, we introduce depth maps as a condition to help our model better perceive the 3D space in visual generation. Two versions of our model are trained with different model sizes (8B and 2B), each of which can perform more than 10 different tasks. In particular, our 8B model demonstrates highly competitive performance in video generation tasks compared to open-source and even commercial engines. Our models and source codes are available at https://github.com/leeruibin/MfM.git.",
      "authors": [
        "Tao Yang",
        "Ruibin Li",
        "Yangming Shi",
        "Yuqi Zhang",
        "Qide Dong",
        "Haoran Cheng",
        "Weiguo Feng",
        "Shilei Wen",
        "Bingyue Peng",
        "Lei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T15:05:44+00:00",
          "link": "https://arxiv.org/abs/2506.01758v1",
          "size": "45312kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T09:00:34+00:00",
          "link": "https://arxiv.org/abs/2506.01758v2",
          "size": "43928kb",
          "version": "v2"
        }
      ],
      "title": "Many-for-Many: Unify the Training of Multiple Video and Image Generation and Manipulation Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01758",
        "PDF": "https://arxiv.org/pdf/2506.01758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a framework for training visual generation models using existing datasets, it focuses on model training rather than dataset processing or creation specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.16035",
      "abstract": "Retrieval-Augmented Generation (RAG) systems have revolutionized information retrieval and question answering, but traditional text-based chunking methods struggle with complex document structures, multi-page tables, embedded figures, and contextual dependencies across page boundaries. We present a novel multimodal document chunking approach that leverages Large Multimodal Models (LMMs) to process PDF documents in batches while maintaining semantic coherence and structural integrity. Our method processes documents in configurable page batches with cross-batch context preservation, enabling accurate handling of tables spanning multiple pages, embedded visual elements, and procedural content. We evaluate our approach on a curated dataset of PDF documents with manually crafted queries, demonstrating improvements in chunk quality and downstream RAG performance. Our vision-guided approach achieves better accuracy compared to traditional vanilla RAG systems, with qualitative analysis showing superior preservation of document structure and semantic coherence.",
      "authors": [
        "Vishesh Tripathi",
        "Tanmay Odapally",
        "Indraneel Das",
        "Uday Allu and Biddwan Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T05:11:43+00:00",
          "link": "https://arxiv.org/abs/2506.16035v1",
          "size": "247kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T19:52:49+00:00",
          "link": "https://arxiv.org/abs/2506.16035v2",
          "size": "247kb",
          "version": "v2"
        }
      ],
      "title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16035",
        "HTML": "https://arxiv.org/html/2506.16035v2",
        "PDF": "https://arxiv.org/pdf/2506.16035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a novel multimodal document chunking technique, which processes and improves document data for use in retrieval-augmented generation systems, directly contributing to LLM training data processing."
      },
      "tasks": [
        "All",
        "Chunking",
        "document understanding",
        "Information Retrieval",
        "Question Answering",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08812",
      "abstract": "This paper presents the rigorous mathematical construction and foundational properties of the Divergence-Free Radiant Transform (DFRT), a spectral transform specifically designed for divergence-free vector fields, with applications in incompressible fluid dynamics and other solenoidal systems. The DFRT basis functions are constructed using a curl-based formulation that ensures the divergence-free condition is satisfied identically. We define the forward and inverse transforms, prove the Parseval identity, and establish the completeness of the basis. The DFRT coefficient space is equipped with an algebraic structure via a spectral coboundary operator, defined using Wigner 3j and 6j symbols to encode angular momentum coupling. This cohomological structure, and its connection to the Geometric Refinement Transform (GRT), is developed in a companion paper using a bigraded cohomology framework. We derive a modal evolution equation for the incompressible Navier-Stokes equations in DFRT coordinates and introduce a persistent regularity class based on cohomological constraints. Finally, we present a variational argument showing that an entropy-maximizing energy distribution leads to exponential decay, offering a new perspective on regularity and singularity prevention in incompressible flows.",
      "authors": [
        "Zachary Mullaghy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T00:33:15+00:00",
          "link": "https://arxiv.org/abs/2507.08812v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "The Divergence-Free Radiant Transform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08812",
        "HTML": "https://arxiv.org/html/2507.08812v1",
        "PDF": "https://arxiv.org/pdf/2507.08812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is strictly about the mathematical foundation of the Divergence-Free Radiant Transform and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09651",
      "abstract": "Gas transport across cell membrane is a very important process in biochemistry which is essential for many crucial tasks, including cell respiration pH regulation in the cell. In the late 1990's, the suggestion that gasses are transported via preferred gas channels embedded into the cell membrane challenged the century old Overton's theory that gases pass through the lipid cell membrane by diffusing across the concentration gradient. Since experimental evidence alone does not provide enough evidence to favor one of the proposed mechanisms, mathematical models have been introduced to provide a context for the interpretation of laboratory measurement. Following up on previous work where the membrane permeability was estimated using particle filter, in this article we propose an algorithm based on dictionary learning for estimating cell membrane permeability. Computed examples illustrate that the novel approach, which can be applied when the properties of the membrane do not change in the course of the data collection process, is computationally much more efficient than particle filter.",
      "authors": [
        "Alberto Bocchinfuso and Daniela Calvetti and Erkki Somersalo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:34:31+00:00",
          "link": "https://arxiv.org/abs/2507.09651v1",
          "size": "336kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian dictionary learning estimation of cell membrane permeability from surface pH data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09651",
        "HTML": "https://arxiv.org/html/2507.09651v1",
        "PDF": "https://arxiv.org/pdf/2507.09651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered around estimating cell membrane permeability using Bayesian dictionary learning, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09883",
      "abstract": "eBPF is a technology that allows developers to safely extend kernel functionality without modifying kernel source code or developing loadable kernel modules. Since the kernel governs critical system operations and enforces isolation boundaries between user space and privileged data, any mechanism that modifies its behavior must meet the highest standards of safety and correctness. To this end, the eBPF toolchain includes a verifier, which statically checks safety properties such as memory access validity, bounded loops, and type correctness before loading the program into the kernel. However, the existing verifier is both overly conservative in some cases-rejecting valid programs-and unsound in others, permitting unsafe behavior that violates the intended semantics of the kernel interface.\n  To address these challenges, we introduce BeePL, a domain-specific language for eBPF with a formally verified type system. The BeePL type system, along with the language design, statically enforces key safety properties such as type-correct memory access, safe pointer usage, absence of unbounded loops, and structured control flow. These guarantees are backed by formal type soundness proofs, ensuring that well-typed programs satisfy the safety invariants required by the eBPF execution environment. BeePL also proves that well-typed source programs meet critical eBPF-specific properties related to memory safety, termination, and control flow, enabling high-level reasoning prior to compilation. For properties not fully enforceable statically-such as dynamic bounds and undefined behavior-BeePL inserts semantics-preserving runtime checks during compilation. We develop a verified compilation strategy that extends CompCert to generate BPF bytecode from BeePL programs, establishing a principled foundation for an end-to-end verifiable toolchain for safe kernel extensions.",
      "authors": [
        "Swarn Priya",
        "Fr\\'ed\\'eric Besson",
        "Connor Sughrue",
        "Tim Steenvoorden",
        "Jamie Fulford",
        "Freek Verbeek",
        "Binoy Ravindran"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.09883v1",
          "size": "315kb",
          "version": "v1"
        }
      ],
      "title": "BeePL: Correct-by-compilation kernel extensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09883",
        "HTML": "https://arxiv.org/html/2507.09883v1",
        "PDF": "https://arxiv.org/pdf/2507.09883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on kernel extensions using eBPF technology, specifically concerned with safety and correctness of kernel modifications, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09909",
      "abstract": "We formulate the swarming optimization problem as a weakly coupled, dissipative dynamical system governed by a controlled energy dissipation rate and initial velocities that adhere to the nonequilibrium Onsager principle. In this framework, agents' inertia, positions, and masses are dynamically coupled. To numerically solve the system, we develop a class of efficient, energy-stable algorithms that either preserve or enhance energy dissipation at the discrete level. At equilibrium, the system tends to converge toward one of the lowest local minima explored by the agents, thereby improving the likelihood of identifying the global minimum. Numerical experiments confirm the effectiveness of the proposed approach, demonstrating significant advantages over traditional swarm-based gradient descent methods, especially when operating with a limited number of agents.",
      "authors": [
        "Xuelong Gu and Qi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:30:43+00:00",
          "link": "https://arxiv.org/abs/2507.09909v1",
          "size": "5914kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Stable Swarm-Based Inertial Algorithms for Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09909",
        "HTML": "https://arxiv.org/html/2507.09909v1",
        "PDF": "https://arxiv.org/pdf/2507.09909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes new optimization algorithms for swarming systems without any mention of LLM training data processing or contribution to data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10201",
      "abstract": "The graph-based variational autoencoder represents an architecture that can handle the uncertainty of different geological scenarios, such as depositional or structural, through the concept of a lowerdimensional latent space. The main difference from recent studies is utilisation of a graph-based approach in reservoir modelling instead of the more traditional lattice-based deep learning methods. We provide a solution to implicitly control the geological realism through the latent variables of a generative model and Geodesic metrics. Our experiments of AHM with synthetic dataset that consists of 3D realisations of channelised geological representations with two distinct scenarios with one and two channels shows the viability of the approach. We offer in-depth analysis of the latent space using tools such as PCA, t-SNE, and TDA to illustrate its structure.",
      "authors": [
        "Gleb Shishaev",
        "Vasily Demyanov",
        "and Daniel Arnold"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:14:17+00:00",
          "link": "https://arxiv.org/abs/2507.10201v1",
          "size": "13818kb",
          "version": "v1"
        }
      ],
      "title": "History Matching under Uncertainty of Geological Scenarios with Implicit Geological Realism Control with Generative Deep Learning and Graph Convolutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10201",
        "HTML": "https://arxiv.org/html/2507.10201v1",
        "PDF": "https://arxiv.org/pdf/2507.10201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with geological scenario modeling and the use of generative models, without discussing LLM training data collection, processing, or optimization."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10401",
      "abstract": "We develop a novel framework for uncertainty quantification in operator learning, the Stochastic Operator Network (SON). SON combines the stochastic optimal control concepts of the Stochastic Neural Network (SNN) with the DeepONet. By formulating the branch net as an SDE and backpropagating through the adjoint BSDE, we replace the gradient of the loss function with the gradient of the Hamiltonian from Stohastic Maximum Principle in the SGD update. This allows SON to learn the uncertainty present in operators through its diffusion parameters. We then demonstrate the effectiveness of SON when replicating several noisy operators in 2D and 3D.",
      "authors": [
        "Ryan Bausback",
        "Jingqiao Tang",
        "Lu Lu",
        "Feng Bao",
        "Toan Huynh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:44:58+00:00",
          "link": "https://arxiv.org/abs/2507.10401v1",
          "size": "5928kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Operator Network: A Stochastic Maximum Principle Based Approach to Operator Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10401",
        "HTML": "https://arxiv.org/html/2507.10401v1",
        "PDF": "https://arxiv.org/pdf/2507.10401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for uncertainty quantification in operator learning, without mentioning any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10502",
      "abstract": "Artificial intelligence holds immense promise for transforming biology, yet a lack of standardized, cross domain, benchmarks undermines our ability to build robust, trustworthy models. Here, we present insights from a recent workshop that convened machine learning and computational biology experts across imaging, transcriptomics, proteomics, and genomics to tackle this gap. We identify major technical and systemic bottlenecks such as data heterogeneity and noise, reproducibility challenges, biases, and the fragmented ecosystem of publicly available resources and propose a set of recommendations for building benchmarking frameworks that can efficiently compare ML models of biological systems across tasks and data modalities. By promoting high quality data curation, standardized tooling, comprehensive evaluation metrics, and open, collaborative platforms, we aim to accelerate the development of robust benchmarks for AI driven Virtual Cells. These benchmarks are crucial for ensuring rigor, reproducibility, and biological relevance, and will ultimately advance the field toward integrated models that drive new discoveries, therapeutic insights, and a deeper understanding of cellular systems.",
      "authors": [
        "Elizabeth Fahsbender",
        "Alma Andersson",
        "Jeremy Ash",
        "Polina Binder",
        "Daniel Burkhardt",
        "Benjamin Chang",
        "Georg K. Gerber",
        "Anthony Gitter",
        "Patrick Godau",
        "Ankit Gupta",
        "Genevieve Haliburton",
        "Siyu He",
        "Trey Ideker",
        "Ivana Jelic",
        "Aly Khan",
        "Yang-Joon Kim",
        "Aditi Krishnapriyan",
        "Jon M. Laurent",
        "Tianyu Liu 28",
        "Emma Lundberg",
        "Shalin B. Mehta",
        "Rob Moccia",
        "Angela Oliveira Pisco",
        "Katherine S. Pollard",
        "Suresh Ramani",
        "Julio Saez-Rodriguez",
        "Yasin Senbabaoglu",
        "Elana Simon",
        "Srinivasan Sivanandan",
        "Gustavo Stolovitzky",
        "Marc Valer",
        "Bo Wang",
        "Xikun Zhang",
        "James Zou",
        "Katrina Kalantar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:25:28+00:00",
          "link": "https://arxiv.org/abs/2507.10502v1",
          "size": "279kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10502",
        "PDF": "https://arxiv.org/pdf/2507.10502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses data curation and benchmarking in biological models but does not primarily contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10540",
      "abstract": "The rapid advancement of large language models (LLMs) has created a vibrant ecosystem of diverse architectures, each with unique strengths due to differences in design, training data, and objectives. However, most applications still rely on a single backend model, limiting coverage of capabilities and leading to inefficiencies in performance and token cost when tackling complex tasks. We highlight an underexploited opportunity: LLM routing data, produced when hosting platforms route diverse queries to different models, which can reveal comparative strengths across tasks. To address this, we propose FusionBench, a comprehensive routing benchmark covering 14 tasks across five domains with 20 open-source LLMs (8B to 671B parameters), capturing 103M tokens and summarizing reusable thought templates from top models. Building on this, we introduce FusionFactory, a systematic fusion framework with three levels: (1) query-level fusion, tailoring routers for each query using both direct responses and reasoning-augmented outputs; (2) thought-level fusion, leveraging abstract templates derived from top-performing LLMs' answers to similar queries; and (3) model-level fusion, transferring capabilities between models via distillation, using top responses or highest judge scores as training data. Experiments show FusionFactory consistently outperforms the best individual LLM across all 14 benchmarks, with optimal fusion configurations varying by benchmark, demonstrating the value of systematic LLM fusion in harnessing complementary strengths and improving overall performance.",
      "authors": [
        "Tao Feng",
        "Haozhen Zhang",
        "Zijie Lei",
        "Pengrui Han",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Bryan Catanzaro",
        "Jiaxuan You"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.10540v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "Fusing LLM Capabilities with Routing Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10540",
        "HTML": "https://arxiv.org/html/2507.10540v1",
        "PDF": "https://arxiv.org/pdf/2507.10540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses routing of queries to various LLMs but does not primarily focus on processing training data, though it mentions capturing tokens and using outputs as training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.02419",
      "abstract": "Quantum machine learning (QML) requires significant quantum resources to address practical real-world problems. When the underlying quantum information exhibits hierarchical structures in the data, limitations persist in training complexity and generalization. Research should prioritize both the efficient design of quantum architectures and the development of learning strategies to optimize resource usage. We propose a framework called quantum curriculum learning (Q-CurL) for quantum data, where the curriculum introduces simpler tasks or data to the learning model before progressing to more challenging ones. Q-CurL exhibits robustness to noise and data limitations, which is particularly relevant for current and near-term noisy intermediate-scale quantum devices. We achieve this through a curriculum design based on quantum data density ratios and a dynamic learning schedule that prioritizes the most informative quantum data. Empirical evidence shows that Q-CurL significantly enhances training convergence and generalization for unitary learning and improves the robustness of quantum phase recognition tasks. Q-CurL is effective with physical learning applications in physics and quantum chemistry.",
      "authors": [
        "Quoc Hoan Tran",
        "Yasuhiro Endo",
        "and Hirotaka Oshima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-02T16:44:14+00:00",
          "link": "https://arxiv.org/abs/2407.02419v1",
          "size": "509kb",
          "version": "v1"
        },
        {
          "date": "2024-07-11T05:42:23+00:00",
          "link": "https://arxiv.org/abs/2407.02419v2",
          "size": "509kb",
          "version": "v2"
        },
        {
          "date": "2024-12-19T07:07:51+00:00",
          "link": "https://arxiv.org/abs/2407.02419v3",
          "size": "739kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T08:32:43+00:00",
          "link": "https://arxiv.org/abs/2407.02419v4",
          "size": "811kb",
          "version": "v4"
        }
      ],
      "title": "Quantum Curriculum Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02419",
        "HTML": "https://arxiv.org/html/2407.02419v4",
        "PDF": "https://arxiv.org/pdf/2407.02419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for quantum curriculum learning, a concept related to quantum machine learning but not LLM training data processing."
      },
      "tasks": [
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.14851",
      "abstract": "Recent years have witnessed the remarkable success of recommendation systems (RSs) in alleviating the information overload problem. As a new paradigm of RSs, session-based recommendation (SR) specializes in users' short-term preference capture and aims to provide a more dynamic and timely recommendation based on the ongoing interacted actions. In this survey, we will give a comprehensive overview of the recent works on SR. First, we clarify the definitions of various SR tasks and introduce the characteristics of session-based recommendation against other recommendation tasks. Then, we summarize the existing methods in two categories: sequential neural network based methods and graph neural network (GNN) based methods. The standard frameworks and technical are also introduced. Finally, we discuss the challenges of SR and new research directions in this area.",
      "authors": [
        "Zihao Li",
        "Chao Yang",
        "Yakun Chen",
        "Xianzhi Wang",
        "Hongxu Chen",
        "Guandong Xu",
        "Lina Yao",
        "Quan Z. Sheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-27T08:08:05+00:00",
          "link": "https://arxiv.org/abs/2408.14851v1",
          "size": "8737kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:57:39+00:00",
          "link": "https://arxiv.org/abs/2408.14851v2",
          "size": "8514kb",
          "version": "v2"
        }
      ],
      "title": "Graph and Sequential Neural Networks in Session-based Recommendation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14851",
        "HTML": "https://arxiv.org/html/2408.14851v2",
        "PDF": "https://arxiv.org/pdf/2408.14851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This is a survey on session-based recommendation systems, focusing on neural network architectures and methods, and does not address LLM training data processing."
      },
      "tasks": [
        "Graph Neural Network",
        "Recommendation Systems",
        "Session-Based Recommendations"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01221",
      "abstract": "For almost a century, the decidability of the Skolem Problem - that is, the problem of finding whether a given linear recurrence sequence (LRS) has a zero term - has remained open. A breakthrough in the 1980s established that the Skolem Problem is indeed decidable for algebraic LRS of order at most 3, and real algebraic LRS of order at most 4. However, for general algebraic LRS of order 4 the question of decidability has remained open. Our main contribution in this paper is to prove decidability for this last case, i.e. we show that the Skolem Problem is decidable for all algebraic LRS of order at most 4.",
      "authors": [
        "Piotr Bacik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T12:56:39+00:00",
          "link": "https://arxiv.org/abs/2409.01221v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-01-14T19:51:43+00:00",
          "link": "https://arxiv.org/abs/2409.01221v2",
          "size": "15kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T18:30:19+00:00",
          "link": "https://arxiv.org/abs/2409.01221v3",
          "size": "17kb",
          "version": "v3"
        }
      ],
      "title": "Completing the picture for the Skolem Problem on order-4 linear recurrence sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01221",
        "HTML": "https://arxiv.org/html/2409.01221v3",
        "PDF": "https://arxiv.org/pdf/2409.01221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the decidability of the Skolem Problem for linear recurrence sequences and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13667",
      "abstract": "Referring video object segmentation (RVOS) aims to segment objects in a video according to textual descriptions, which requires the integration of multimodal information and temporal dynamics perception. The Segment Anything Model 2 (SAM 2) has shown great effectiveness across various video segmentation tasks. However, its application to offline RVOS is challenged by the translation of the text into effective prompts and a lack of global context awareness. In this paper, we propose a novel RVOS framework, termed MPG-SAM 2, to address these challenges. Specifically, MPG-SAM 2 employs a unified multimodal encoder to jointly encode video and textual features, generating semantically aligned video and text embeddings, along with multimodal class tokens. A mask prior generator utilizes the video embeddings and class tokens to create pseudo masks of target objects and global context. These masks are fed into the prompt encoder as dense prompts along with multimodal class tokens as sparse prompts to generate accurate prompts for SAM 2. To provide the online SAM 2 with a global view, we introduce a hierarchical global-historical aggregator, which allows SAM 2 to aggregate global and historical information of target objects at both pixel and object levels, enhancing the target representation and temporal consistency. Extensive experiments on several RVOS benchmarks demonstrate the superiority of MPG-SAM 2 and the effectiveness of our proposed modules. The code is available at https://github.com/rongfu-dsb/MPG-SAM2.",
      "authors": [
        "Fu Rong",
        "Meng Lan",
        "Qian Zhang",
        "Lefei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T13:53:33+00:00",
          "link": "https://arxiv.org/abs/2501.13667v1",
          "size": "1884kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T11:56:33+00:00",
          "link": "https://arxiv.org/abs/2501.13667v2",
          "size": "1134kb",
          "version": "v2"
        },
        {
          "date": "2025-07-04T10:10:49+00:00",
          "link": "https://arxiv.org/abs/2501.13667v3",
          "size": "1917kb",
          "version": "v3"
        },
        {
          "date": "2025-07-12T16:24:41+00:00",
          "link": "https://arxiv.org/abs/2501.13667v4",
          "size": "1917kb",
          "version": "v4"
        }
      ],
      "title": "MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13667",
        "HTML": "https://arxiv.org/html/2501.13667v4",
        "PDF": "https://arxiv.org/pdf/2501.13667"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for video object segmentation using multimodal data and does not address LLM training data processing."
      },
      "tasks": [
        "Referring Expression Segmentation",
        "Referring Video Object Segmentation",
        "Semantic Segmentation",
        "Video Object Segmentation",
        "Video Segmentation",
        "Video Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.09873",
      "abstract": "Diffusion models have demonstrated remarkable success in image restoration tasks. However, their multi-step denoising process introduces significant computational overhead, limiting their practical deployment. Furthermore, existing methods struggle to effectively remove severe JPEG artifact, especially in highly compressed images. To address these challenges, we propose CODiff, a compression-aware one-step diffusion model for JPEG artifact removal. The core of CODiff is the compression-aware visual embedder (CaVE), which extracts and leverages JPEG compression priors to guide the diffusion model. We propose a dual learning strategy that combines explicit and implicit learning. Specifically, explicit learning enforces a quality prediction objective to differentiate low-quality images with different compression levels. Implicit learning employs a reconstruction objective that enhances the model's generalization. This dual learning allows for a deeper and more comprehensive understanding of JPEG compression. Experimental results demonstrate that CODiff surpasses recent leading methods in both quantitative and visual quality metrics. The code is released at https://github.com/jp-guo/CODiff.",
      "authors": [
        "Jinpei Guo",
        "Zheng Chen",
        "Wenbo Li",
        "Yong Guo",
        "and Yulun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T02:46:27+00:00",
          "link": "https://arxiv.org/abs/2502.09873v1",
          "size": "8779kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T21:00:01+00:00",
          "link": "https://arxiv.org/abs/2502.09873v2",
          "size": "8987kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T20:11:01+00:00",
          "link": "https://arxiv.org/abs/2502.09873v3",
          "size": "4650kb",
          "version": "v3"
        }
      ],
      "title": "Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09873",
        "HTML": "https://arxiv.org/html/2502.09873v3",
        "PDF": "https://arxiv.org/pdf/2502.09873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses image restoration using a new diffusion model for JPEG artifact removal, with no relation to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Denoising",
        "Image Restoration",
        "JPEG Artifact Removal"
      ],
      "repo_urls": [
        "https://github.com/jp-guo/codiff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02481",
      "abstract": "Registration of diffusion MRI tractography is an essential step for analyzing group similarities and variations in the brain's white matter (WM). Streamline-based registration approaches can leverage the 3D geometric information of fiber pathways to enable spatial alignment after registration. Existing methods usually rely on the optimization of the spatial distances to identify the optimal transformation. However, such methods overlook point connectivity patterns within the streamline itself, limiting their ability to identify anatomical correspondences across tractography datasets. In this work, we propose a novel unsupervised approach using deep learning to perform streamline-based dMRI tractography registration. The overall idea is to identify corresponding keypoint pairs across subjects for spatial alignment of tractography datasets. We model tractography as point clouds to leverage the graph connectivity along streamlines. We propose a novel keypoint detection method for streamlines, framed as a probabilistic classification task to identify anatomically consistent correspondences across unstructured streamline sets. In the experiments, we compare several existing methods and show highly effective and efficient tractography registration performance.",
      "authors": [
        "Junyi Wang",
        "Mubai Du",
        "Ye Wu",
        "Yijie Li",
        "William M. Wells III",
        "Lauren J. O'Donnell",
        "Fan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T10:47:10+00:00",
          "link": "https://arxiv.org/abs/2503.02481v1",
          "size": "7714kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T14:19:55+00:00",
          "link": "https://arxiv.org/abs/2503.02481v2",
          "size": "7713kb",
          "version": "v2"
        }
      ],
      "title": "A Novel Streamline-based diffusion MRI Tractography Registration Method with Probabilistic Keypoint Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02481",
        "HTML": "https://arxiv.org/html/2503.02481v2",
        "PDF": "https://arxiv.org/pdf/2503.02481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a streamline-based MRI tractography registration method and does not discuss LLM training data processing."
      },
      "tasks": [
        "Diffusion  MRI",
        "Keypoint Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20124",
      "abstract": "Modern reinforcement learning (RL) systems have demonstrated remarkable capabilities in complex environments, such as video games. However, they still fall short of achieving human-like sample efficiency and adaptability when learning new domains. Theory-based reinforcement learning (TBRL) is an algorithmic framework specifically designed to address this gap. Modeled on cognitive theories, TBRL leverages structured, causal world models - \"theories\" - as forward simulators for use in planning, generalization and exploration. Although current TBRL systems provide compelling explanations of how humans learn to play video games, they face several technical limitations: their theory languages are restrictive, and their planning algorithms are not scalable. To address these challenges, we introduce TheoryCoder, an instantiation of TBRL that exploits hierarchical representations of theories and efficient program synthesis methods for more powerful learning and planning. TheoryCoder equips agents with general-purpose abstractions (e.g., \"move to\"), which are then grounded in a particular environment by learning a low-level transition model (a Python program synthesized from observations by a large language model). A bilevel planning algorithm can exploit this hierarchical structure to solve large domains. We demonstrate that this approach can be successfully applied to diverse and challenging grid-world games, where approaches based on directly synthesizing a policy perform poorly. Ablation studies demonstrate the benefits of using hierarchical abstractions.",
      "authors": [
        "Zergham Ahmed",
        "Joshua B. Tenenbaum",
        "Christopher J. Bates",
        "Samuel J. Gershman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T00:10:01+00:00",
          "link": "https://arxiv.org/abs/2503.20124v1",
          "size": "593kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T15:33:21+00:00",
          "link": "https://arxiv.org/abs/2503.20124v2",
          "size": "964kb",
          "version": "v2"
        }
      ],
      "title": "Synthesizing world models for bilevel planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20124",
        "PDF": "https://arxiv.org/pdf/2503.20124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses leveraging structured, causal world models generated using a large language model, it primarily focuses on reinforcement learning systems, not directly on LLM training data processing."
      },
      "tasks": [
        "Large Language Model",
        "Program Synthesis",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09469",
      "abstract": "For precise, efficient, and safe drone landings, ground platforms should real-time, accurately locate descending drones and guide them to designated spots. While mmWave sensing combined with cameras improves localization accuracy, lower sampling frequency of traditional frame cameras compared to mmWave radar creates bottlenecks in system throughput. In this work, we upgrade traditional frame camera with event camera, a novel sensor that harmonizes in sampling frequency with mmWave radar within ground platform setup, and introduce mmE-Loc, a high-precision, low-latency ground localization system designed for precise drone landings. To fully exploit the \\textit{temporal consistency} and \\textit{spatial complementarity} between these two modalities, we propose two innovative modules: \\textit{(i)} the Consistency-instructed Collaborative Tracking module, which further leverages the drone's physical knowledge of periodic micro-motions and structure for accurate measurements extraction, and \\textit{(ii)} the Graph-informed Adaptive Joint Optimization module, which integrates drone motion information for efficient sensor fusion and drone localization. Real-world experiments conducted in landing scenarios with a drone delivery company demonstrate that mmE-Loc significantly outperforms state-of-the-art methods in both accuracy and latency.",
      "authors": [
        "Haoyang Wang",
        "Jingao Xu",
        "Xinyu Luo",
        "Ting Zhang",
        "Xuecheng Chen",
        "Ruiyang Duan",
        "Jialong Chen",
        "Yunhao Liu",
        "Jianfeng Zheng",
        "Weijie Hong",
        "Xinlei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:06:12+00:00",
          "link": "https://arxiv.org/abs/2507.09469v1",
          "size": "12798kb",
          "version": "v1"
        }
      ],
      "title": "mmE-Loc: Facilitating Accurate Drone Landing with Ultra-High-Frequency Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09469",
        "HTML": "https://arxiv.org/html/2507.09469v1",
        "PDF": "https://arxiv.org/pdf/2507.09469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes mmE-Loc, a localization system for drones using sensors, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09973",
      "abstract": "Large decoder-based language models have become the dominant architecture for reward modeling in reinforcement learning from human feedback (RLHF). However, as reward models are increasingly deployed in test-time strategies, their inference costs become a growing concern. We present TinyRM, a family of small, bidirectional masked language models (MLMs) with as few as 400 million parameters, that rival the capabilities of models over 175 times larger on reasoning and safety preference modeling tasks. TinyRM combines FLAN-style prompting, Directional Low-Rank Adaptation (DoRA), and layer freezing to achieve strong performance on RewardBench, despite using significantly fewer resources. Our experiments suggest that small models benefit from domain-specific tuning strategies, particularly in reasoning, where lightweight finetuning methods are especially effective. While challenges remain in building generalist models and conversational preference modeling, our preliminary results highlight the promise of lightweight bidirectional architectures as efficient, scalable alternatives for preference modeling.",
      "authors": [
        "Sarah Pan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:43:00+00:00",
          "link": "https://arxiv.org/abs/2507.09973v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "Tiny Reward Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09973",
        "HTML": "https://arxiv.org/html/2507.09973v1",
        "PDF": "https://arxiv.org/pdf/2507.09973"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses domain-specific tuning strategies for smaller models in reasoning tasks, but it primarily focuses on model architecture and performance rather than substantial training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10013",
      "abstract": "Recent advances in multimodal models have raised questions about whether vision-and-language models (VLMs) integrate cross-modal information in ways that reflect human cognition. One well-studied test case in this domain is the bouba-kiki effect, where humans reliably associate pseudowords like \"bouba\" with round shapes and \"kiki\" with jagged ones. Given the mixed evidence found in prior studies for this effect in VLMs, we present a comprehensive re-evaluation focused on two variants of CLIP, ResNet and Vision Transformer (ViT), given their centrality in many state-of-the-art VLMs. We apply two complementary methods closely modelled after human experiments: a prompt-based evaluation that uses probabilities as model preference, and we use Grad-CAM as a novel way to interpret visual attention in shape-word matching tasks. Our findings show that these models do not consistently exhibit the bouba-kiki effect. While ResNet shows a preference for round shapes, overall performance across both models lacks the expected associations. Moreover, direct comparison with prior human data on the same task shows that the models' responses fall markedly short of the robust, modality-integrated behaviour characteristic of human cognition. These results contribute to the ongoing debate about the extent to which VLMs truly understand cross-modal concepts, highlighting limitations in their internal representations and alignment with human intuitions.",
      "authors": [
        "Tom Kouwenhoven",
        "Kiana Shahrasbi",
        "Tessa Verhoef"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:48:54+00:00",
          "link": "https://arxiv.org/abs/2507.10013v1",
          "size": "5995kb",
          "version": "v1"
        }
      ],
      "title": "Cross-modal Associations in Vision and Language Models: Revisiting the bouba-kiki effect",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10013",
        "HTML": "https://arxiv.org/html/2507.10013v1",
        "PDF": "https://arxiv.org/pdf/2507.10013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes vision and language models' ability to capture cross-modal associations but does not contribute to LLM training data processing or create new datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10017",
      "abstract": "Interactions between two entities often occur at specific timestamps, which can be modeled as a temporal graph. Exploring the relationships between vertices based on temporal paths is one of the fundamental tasks. In this paper, we conduct the first research to propose and investigate the problem of generating the temporal simple path graph (tspG), which is the subgraph consisting of all temporal simple paths from the source vertex to the target vertex within the given time interval. Directly enumerating all temporal simple paths and constructing the tspG is computationally expensive. To accelerate the processing, we propose an efficient method named Verification in Upper-bound Graph. It first incorporates the temporal path constraint and simple path constraint to exclude unpromising edges from the original graph, which obtains a tight upper-bound graph as a high-quality approximation of the tspG in polynomial time. Then, an Escape Edges Verification algorithm is further applied in the upper-bound graph to construct the exact tspG without exhaustively enumerating all temporal simple paths between given vertices. Finally, comprehensive experiments on 10 real-world graphs are conducted to demonstrate the efficiency and effectiveness of the proposed techniques.",
      "authors": [
        "Zhiyang Tang",
        "Yanping Wu",
        "Xiangjun Zai",
        "Chen Chen",
        "Xiaoyang Wang",
        "Ying Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:53:26+00:00",
          "link": "https://arxiv.org/abs/2507.10017v1",
          "size": "1933kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Temporal Simple Path Graph Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10017",
        "HTML": "https://arxiv.org/html/2507.10017v1",
        "PDF": "https://arxiv.org/pdf/2507.10017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with generating temporal simple path graphs in the context of temporal graphs, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10273",
      "abstract": "Generative chemical language models (CLMs) have demonstrated strong capabilities in molecular design, yet their impact in drug discovery remains limited by the absence of reliable reward signals and the lack of interpretability in their outputs. We present SAFE-T, a generalist chemical modeling framework that conditions on biological context -- such as protein targets or mechanisms of action -- to prioritize and design molecules without relying on structural information or engineered scoring functions. SAFE-T models the conditional likelihood of fragment-based molecular sequences given a biological prompt, enabling principled scoring of molecules across tasks such as virtual screening, drug-target interaction prediction, and activity cliff detection. Moreover, it supports goal-directed generation by sampling from this learned distribution, aligning molecular design with biological objectives. In comprehensive zero-shot evaluations across predictive (LIT-PCBA, DAVIS, KIBA, ACNet) and generative (DRUG, PMO) benchmarks, SAFE-T consistently achieves performance comparable to or better than existing approaches while being significantly faster. Fragment-level attribution further reveals that SAFE-T captures known structure-activity relationships, supporting interpretable and biologically grounded design. Together with its computational efficiency, these results demonstrate that conditional generative CLMs can unify scoring and generation to accelerate early-stage drug discovery.",
      "authors": [
        "Lu Zhu and Emmanuel Noutahi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:42:39+00:00",
          "link": "https://arxiv.org/abs/2507.10273v1",
          "size": "7876kb",
          "version": "v1"
        }
      ],
      "title": "Conditional Chemical Language Models are Versatile Tools in Drug Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10273",
        "HTML": "https://arxiv.org/html/2507.10273v1",
        "PDF": "https://arxiv.org/pdf/2507.10273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses chemical language models for drug discovery, focusing on molecular design rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.19603",
      "abstract": "The use of attention-based deep learning models in stochastic filtering, e.g. transformers and deep Kalman filters, has recently come into focus; however, the potential for these models to solve stochastic filtering problems remains largely unknown. The paper provides an affirmative answer to this open problem in the theoretical foundations of machine learning by showing that a class of continuous-time transformer models, called \\textit{filterformers}, can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-time (possibly non-Gaussian) measurements. Our approximation guarantees hold uniformly over sufficiently regular compact subsets of continuous-time paths, where the worst-case 2-Wasserstein distance between the true optimal filter and our deep learning model quantifies the approximation error. Our construction relies on two new customizations of the standard attention mechanism: The first can losslessly adapt to the characteristics of a broad range of paths since we show that the attention mechanism implements bi-Lipschitz embeddings of sufficiently regular sets of paths into low-dimensional Euclidean spaces; thus, it incurs no ``dimension reduction error''. The latter attention mechanism is tailored to the geometry of Gaussian measures in the $2$-Wasserstein space. Our analysis relies on new stability estimates of robust optimal filters in the conditionally Gaussian setting.",
      "authors": [
        "Blanka Horvath",
        "Anastasis Kratsios",
        "Yannick Limmer",
        "Xuwei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Numerical Analysis (math.NA)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-30T14:58:12+00:00",
          "link": "https://arxiv.org/abs/2310.19603v1",
          "size": "274kb",
          "version": "v1"
        },
        {
          "date": "2024-12-27T23:53:30+00:00",
          "link": "https://arxiv.org/abs/2310.19603v2",
          "size": "274kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T17:43:25+00:00",
          "link": "https://arxiv.org/abs/2310.19603v3",
          "size": "296kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T13:17:47+00:00",
          "link": "https://arxiv.org/abs/2310.19603v4",
          "size": "299kb",
          "version": "v4"
        }
      ],
      "title": "Transformers Can Solve Non-Linear and Non-Markovian Filtering Problems in Continuous Time For Conditionally Gaussian Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.19603",
        "PDF": "https://arxiv.org/pdf/2310.19603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the theoretical aspects of transformers solving stochastic filtering problems, without any focus on processing or engineering training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.19700",
      "abstract": "This paper introduces Neuro-Activated Vision Explanations (NAVE), a method for extracting and visualizing the internal representations of vision model encoders. By clustering feature activations, NAVE provides insights into learned semantics without fine-tuning. Using object localization, we show that NAVE's concepts align with image semantics. Through extensive experiments, we analyze the impact of training strategies and architectures on encoder representation capabilities. Additionally, we apply NAVE to study training artifacts in vision transformers and reveal how weak training strategies and spurious correlations degrade model performance. Our findings establish NAVE as a valuable tool for post-hoc model inspection and improving transparency in vision models.",
      "authors": [
        "Ahc\\`ene Boubekki",
        "Samuel G. Fadel",
        "Sebastian Mair"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-29T13:42:10+00:00",
          "link": "https://arxiv.org/abs/2411.19700v1",
          "size": "13110kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T18:21:07+00:00",
          "link": "https://arxiv.org/abs/2411.19700v2",
          "size": "13111kb",
          "version": "v2"
        },
        {
          "date": "2025-03-23T17:37:14+00:00",
          "link": "https://arxiv.org/abs/2411.19700v3",
          "size": "9873kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T09:22:58+00:00",
          "link": "https://arxiv.org/abs/2411.19700v4",
          "size": "4602kb",
          "version": "v4"
        }
      ],
      "title": "Explaining the Impact of Training on Vision Models via Activation Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19700",
        "HTML": "https://arxiv.org/html/2411.19700v4",
        "PDF": "https://arxiv.org/pdf/2411.19700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for analyzing and visualizing internal representations of vision models, unrelated to LLM training data processing or engineering."
      },
      "tasks": [
        "Clustering",
        "Explainable artificial intelligence",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10660",
      "abstract": "Understanding the plausible upper bounds of extreme weather events is essential for risk assessment in a warming climate. Existing methods, based on large ensembles of physics-based models, are often computationally expensive or lack the fidelity needed to simulate rare, high-impact extremes. Here, we present a novel framework that leverages a differentiable hybrid climate model, NeuralGCM, to optimize initial conditions and generate physically consistent worst-case heatwave trajectories. Applied to the 2021 Pacific Northwest heatwave, our method produces heatwave intensity up to 3.7 $^\\circ$C above the most extreme member of a 75-member ensemble. These trajectories feature intensified atmospheric blocking and amplified Rossby wave patterns-hallmarks of severe heat events. Our results demonstrate that differentiable climate models can efficiently explore the upper tails of event likelihoods, providing a powerful new approach for constructing targeted storylines of extreme weather under climate change.",
      "authors": [
        "Tim Whittaker and Alejandro Di Luca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)",
        "Fluid Dynamics (physics.flu-dyn)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T12:50:38+00:00",
          "link": "https://arxiv.org/abs/2506.10660v1",
          "size": "13266kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:39:47+00:00",
          "link": "https://arxiv.org/abs/2506.10660v2",
          "size": "13301kb",
          "version": "v2"
        }
      ],
      "title": "Constructing Extreme Heatwave Storylines with Differentiable Climate Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10660",
        "HTML": "https://arxiv.org/html/2506.10660v2",
        "PDF": "https://arxiv.org/pdf/2506.10660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating heatwave storylines using a climate model and does not discuss LLM training data processing or related data-engineering tasks."
      },
      "tasks": [
        "Blocking"
      ],
      "repo_urls": [
        "https://github.com/timwhittaker/extremestorylines"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08833",
      "abstract": "Low-Rank Adaptation (LoRA) is one of the most widely used techniques for fine-tuning large language models (LLMs). By introducing a small number of trainable low-rank weight matrices, LoRA substantially reduces the number of parameters that need to be updated, offering significant advantages in memory consumption and computational efficiency compared to full fine-tuning. However, we observed that LoRA does not consistently provide speed improvements across all model architectures and training setups. Motivated by this inconsistency, we conduct a comprehensive analysis of LoRA's performance and investigate the underlying factors limiting its speedup. Based on our findings, we propose several methods for more efficient fine-tuning of LLMs. We empirically evaluate these methods and compare them to LoRA, demonstrating that our approach achieves comparable or superior performance while delivering more consistent training speed improvements. Our work offers valuable insights and practical guidelines for practitioners seeking to optimize LLM fine-tuning under resource constraints.",
      "authors": [
        "Seokmin Ko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T08:36:43+00:00",
          "link": "https://arxiv.org/abs/2507.08833v1",
          "size": "3251kb",
          "version": "v1"
        }
      ],
      "title": "LoRA Is Slower Than You Think",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08833",
        "HTML": "https://arxiv.org/html/2507.08833v1",
        "PDF": "https://arxiv.org/pdf/2507.08833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses LoRA and fine-tuning methods for LLMs but primarily from a model efficiency standpoint rather than focusing on data processing improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08868",
      "abstract": "Today, static cloud markets where consumers purchase services directly from providers are dominating. Thus, consumers neither negotiate the price nor the characteristics of the service. In recent years, providers have adopted more dynamic trading mechanisms, as e.g. Amazon's EC2 platform shows: In addition to the reservation marketspace and the on-demand marketspace, Amazon offers a spot marketspace where consumers can bid for virtual machines. This spot marketspace was extended with spot blocks, and recently Amazon reworked the bidding options. In addition, other cloud providers, such as Virtustream, adopt dynamic trading mechanisms. The scientific community envisions autonomous multi-round negotiations for realizing future cloud marketspaces. Consequently, consumers and providers exchange offers and counteroffers to reach an agreement. This helps providers increase the utilization of their datacenters, while consumers can purchase highly customized cloud services.\n  In the paper at hand, we present a survey on multi-round bilateral negotiation strategies for trading cloud resources. Thus, we analyzed peer-reviewed articles in order to identify trends, gaps, similarities, and the scope of such negotiation strategies. In addition, we surveyed the formalism that the scientific community uses to describe such strategies. Based on these findings, we derived recommendations for creating and documenting bilateral multi-round negotiation strategies to foster their implementation in the industry.",
      "authors": [
        "Benedikt Pittl",
        "Werner Mach",
        "Erich Schikuta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:34:16+00:00",
          "link": "https://arxiv.org/abs/2507.08868v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Bilateral Multi-Round Cloud-SLA Negotiation Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08868",
        "HTML": "https://arxiv.org/html/2507.08868v1",
        "PDF": "https://arxiv.org/pdf/2507.08868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys negotiation strategies for cloud service markets, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08890",
      "abstract": "This is the fifth year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human-annotated training labels available for both passage and document ranking tasks. We mostly repeated last year's design, to get another matching test set, based on the larger, cleaner, less-biased v2 passage and document set, with passage ranking as primary and document ranking as a secondary task (using labels inferred from passage). As we did last year, we sample from MS MARCO queries that were completely held out, unused in corpus construction, unlike the test queries in the first three years. This approach yields a more difficult test with more headroom for improvement. Alongside the usual MS MARCO (human) queries from MS MARCO, this year we generated synthetic queries using a fine-tuned T5 model and using a GPT-4 prompt.\n  The new headline result this year is that runs using Large Language Model (LLM) prompting in some way outperformed runs that use the \"nnlm\" approach, which was the best approach in the previous four years. Since this is the last year of the track, future iterations of prompt-based ranking can happen in other tracks. Human relevance assessments were applied to all query types, not just human MS MARCO queries. Evaluation using synthetic queries gave similar results to human queries, with system ordering agreement of $\\tau=0.8487$. However, human effort was needed to select a subset of the synthetic queries that were usable. We did not see clear evidence of bias, where runs using GPT-4 were favored when evaluated using synthetic GPT-4 queries, or where runs using T5 were favored when evaluated on synthetic T5 queries.",
      "authors": [
        "Nick Craswell",
        "Bhaskar Mitra",
        "Emine Yilmaz",
        "Hossein A. Rahmani",
        "Daniel Campos",
        "Jimmy Lin",
        "Ellen M. Voorhees and Ian Soboroff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:39:42+00:00",
          "link": "https://arxiv.org/abs/2507.08890v1",
          "size": "609kb",
          "version": "v1"
        }
      ],
      "title": "Overview of the TREC 2023 deep learning track",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08890",
        "HTML": "https://arxiv.org/html/2507.08890v1",
        "PDF": "https://arxiv.org/pdf/2507.08890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions generating synthetic queries using LLMs for evaluation but focuses more on the track overview rather than data processing improvements. Its main contribution is not in training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09627",
      "abstract": "Next-generation wireless technologies such as 6G aim to meet demanding requirements such as ultra-high data rates, low latency, and enhanced connectivity. Extremely Large-Scale MIMO (XL-MIMO) and Reconfigurable Intelligent Surface (RIS) are key enablers, with XL-MIMO boosting spectral and energy efficiency through numerous antennas, and RIS offering dynamic control over the wireless environment via passive reflective elements. However, realizing their full potential depends on accurate Channel State Information (CSI). Recent advances in deep learning have facilitated efficient cascaded channel estimation. However, the scalability and practical deployment of existing estimation models in XL-MIMO systems remain limited. The growing number of antennas and RIS elements introduces a significant barrier to real-time and efficient channel estimation, drastically increasing data volume, escalating computational complexity, requiring advanced hardware, and resulting in substantial energy consumption. To address these challenges, we propose a lightweight deep learning framework for efficient cascaded channel estimation in XL-MIMO systems, designed to minimize computational complexity and make it suitable for deployment on resource-constrained edge devices. Using spatial correlations in the channel, we introduce a patch-based training mechanism that reduces the dimensionality of input to patch-level representations while preserving essential information, allowing scalable training for large-scale systems. Simulation results under diverse conditions demonstrate that our framework significantly improves estimation accuracy and reduces computational complexity, regardless of the increasing number of antennas and RIS elements in XL-MIMO systems.",
      "authors": [
        "Muhammad Kamran Saeed",
        "Ashfaq Khokhar",
        "Shakil Ahmed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T13:42:42+00:00",
          "link": "https://arxiv.org/abs/2507.09627v1",
          "size": "6623kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Deep Learning-Based Channel Estimation for RIS-Aided Extremely Large-Scale MIMO Systems on Resource-Limited Edge Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09627",
        "HTML": "https://arxiv.org/html/2507.09627v1",
        "PDF": "https://arxiv.org/pdf/2507.09627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a lightweight deep learning framework for channel estimation in wireless systems, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09862",
      "abstract": "The rapid development of large-scale models has catalyzed significant breakthroughs in the digital human domain. These advanced methodologies offer high-fidelity solutions for avatar driving and rendering, leading academia to focus on the next major challenge: audio-visual dyadic interactive virtual human. To facilitate research in this emerging area, we present SpeakerVid-5M dataset, the first large-scale, high-quality dataset designed for audio-visual dyadic interactive virtual human generation. Totaling over 8,743 hours, SpeakerVid-5M contains more than 5.2 million video clips of human portraits. It covers diverse scales and interaction types, including monadic talking, listening, and dyadic conversations. Crucially, the dataset is structured along two key dimensions: interaction type and data quality. First, it is categorized into four types (dialogue branch, single branch, listening branch and multi-turn branch) based on the interaction scenario. Second, it is stratified into a large-scale pre-training subset and a curated, high-quality subset for Supervised Fine-Tuning (SFT). This dual structure accommodates a wide array of 2D virtual human tasks. In addition, we provide an autoregressive (AR)-based video chat baseline trained on this data, accompanied by a dedicated set of metrics and test data to serve as a benchmark VidChatBench for future work. Both the dataset and the corresponding data processing code will be publicly released. Project page: https://dorniwang.github.io/SpeakerVid-5M/",
      "authors": [
        "Youliang Zhang",
        "Zhaoyang Li",
        "Duomin Wang",
        "Jiahe Zhang",
        "Deyu Zhou",
        "Zixin Yin",
        "Xili Dai",
        "Gang Yu",
        "Xiu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:22:47+00:00",
          "link": "https://arxiv.org/abs/2507.09862v1",
          "size": "36699kb",
          "version": "v1"
        }
      ],
      "title": "SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual Dyadic Interactive Human Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09862",
        "HTML": "https://arxiv.org/html/2507.09862v1",
        "PDF": "https://arxiv.org/pdf/2507.09862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new large-scale dataset, SpeakerVid-5M, for audio-visual dyadic interactive human generation and details the structured data processing and curation process, emphasizing dataset creation and quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.04882",
      "abstract": "For a graph $G$, $ mp(G) $ is the multipacking number, and $\\gamma_b(G)$ is the broadcast domination number. It is known that $mp(G)\\leq \\gamma_b(G)$ and $\\gamma_b(G)\\leq 2mp(G)+3$ for any graph $G$, and it was shown that $\\gamma_b(G)-mp(G)$ can be arbitrarily large for connected graphs. It is conjectured that $\\gamma_b(G)\\leq 2mp(G)$ for any general graph $G$.\n  We show that, for any cactus graph $G$, $\\gamma_b(G)\\leq \\frac{3}{2}mp(G)+\\frac{11}{2}$. We also show that $\\gamma_b(G)-mp(G)$ can be arbitrarily large for cactus graphs and asteroidal triple-free graphs by constructing an infinite family of cactus graphs which are also asteroidal triple-free graphs such that the ratio $\\gamma_b(G)/mp(G)=4/3$, with $mp(G)$ arbitrarily large. This result shows that, for cactus graphs, the bound $\\gamma_b(G)\\leq \\frac{3}{2}mp(G)+\\frac{11}{2}$ cannot be improved to a bound in the form $\\gamma_b(G)\\leq c_1\\cdot mp(G)+c_2$, for any constant $c_1<4/3$ and $c_2$. Moreover, we provide an $O(n)$-time algorithm to construct a multipacking of cactus graph $G$ of size at least $ \\frac{2}{3}mp(G)-\\frac{11}{3} $, where $n$ is the number of vertices of the graph $G$. The hyperbolicity of the cactus graph class is unbounded. For $0$-hyperbolic graphs, $mp(G)=\\gamma_b(G)$. Moreover, $mp(G)=\\gamma_b(G)$ holds for the strongly chordal graphs which is a subclass of $\\frac{1}{2}$-hyperbolic graphs. Now it's a natural question: what is the minimum value of $\\delta$, for which we can say that the difference $ \\gamma_{b}(G) - mp(G) $ can be arbitrarily large for $\\delta$-hyperbolic graphs? We show that the minimum value of $\\delta$ is $\\frac{1}{2}$ using a construction of an infinite family of cactus graphs with hyperbolicity $\\frac{1}{2}$.",
      "authors": [
        "Sandip Das and Sk Samim Islam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-09T11:26:18+00:00",
          "link": "https://arxiv.org/abs/2308.04882v1",
          "size": "617kb",
          "version": "v1"
        },
        {
          "date": "2023-11-14T11:41:05+00:00",
          "link": "https://arxiv.org/abs/2308.04882v2",
          "size": "725kb",
          "version": "v2"
        },
        {
          "date": "2024-02-17T06:01:42+00:00",
          "link": "https://arxiv.org/abs/2308.04882v3",
          "size": "734kb",
          "version": "v3"
        },
        {
          "date": "2024-11-20T14:01:36+00:00",
          "link": "https://arxiv.org/abs/2308.04882v4",
          "size": "734kb",
          "version": "v4"
        },
        {
          "date": "2025-07-14T04:29:36+00:00",
          "link": "https://arxiv.org/abs/2308.04882v5",
          "size": "489kb",
          "version": "v5"
        }
      ],
      "title": "Multipacking and broadcast domination on cactus graph and its impact on hyperbolic graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.04882",
        "HTML": "https://arxiv.org/html/2308.04882v5",
        "PDF": "https://arxiv.org/pdf/2308.04882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on mathematical properties of graphs and does not address any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09488",
      "abstract": "Relevance judgments are crucial for evaluating information retrieval systems, but traditional human-annotated labels are time-consuming and expensive. As a result, many researchers turn to automatic alternatives to accelerate method development. Among these, Large Language Models (LLMs) provide a scalable solution by generating relevance labels directly through prompting. However, prompting an LLM for a relevance label without constraints often results in not only incorrect predictions but also outputs that are difficult for humans to interpret. We propose the Multi-Criteria framework for LLM-based relevance judgments, decomposing the notion of relevance into multiple criteria--such as exactness, coverage, topicality, and contextual fit--to improve the robustness and interpretability of retrieval evaluations compared to direct grading methods. We validate this approach on three datasets: the TREC Deep Learning tracks from 2019 and 2020, as well as LLMJudge (based on TREC DL 2023). Our results demonstrate that Multi-Criteria judgments enhance the system ranking/leaderboard performance. Moreover, we highlight the strengths and limitations of this approach relative to direct grading approaches, offering insights that can guide the development of future automatic evaluation frameworks in information retrieval.",
      "authors": [
        "Naghmeh Farzi",
        "Laura Dietz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:21:21+00:00",
          "link": "https://arxiv.org/abs/2507.09488v1",
          "size": "807kb",
          "version": "v1"
        }
      ],
      "title": "Criteria-Based LLM Relevance Judgments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09488",
        "HTML": "https://arxiv.org/html/2507.09488v1",
        "PDF": "https://arxiv.org/pdf/2507.09488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of LLMs for generating relevance judgments in information retrieval, emphasizing evaluation frameworks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10054",
      "abstract": "Large Language Models (LLMs) are increasingly used as code assistants, yet their behavior when explicitly asked to generate insecure code remains poorly understood. While prior research has focused on unintended vulnerabilities or adversarial prompting techniques, this study examines a more direct threat scenario: open-source LLMs generating vulnerable code when prompted either directly or indirectly. We propose a dual experimental design: (1) Dynamic Prompting, which systematically varies vulnerability type, user persona, and directness across structured templates; and (2) Reverse Prompting, which derives prompts from real vulnerable code samples to assess vulnerability reproduction accuracy. We evaluate three open-source 7B-parameter models (Qwen2, Mistral, and Gemma) using ESBMC static analysis to assess both the presence of vulnerabilities and the correctness of the generated vulnerability type. Results show all models frequently produce vulnerable outputs, with Qwen2 achieving highest correctness rates. User persona significantly affects success, where student personas achieved higher vulnerability rates than professional roles, while direct prompts were marginally more effective. Vulnerability reproduction followed an inverted-U pattern with cyclomatic complexity, peaking at moderate ranges. Our findings expose limitations of safety mechanisms in open-source models, particularly for seemingly benign educational requests.",
      "authors": [
        "Emir Bosnak",
        "Sahand Moslemi",
        "Mayasah Lami",
        "Anil Koyuncu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:36:26+00:00",
          "link": "https://arxiv.org/abs/2507.10054v1",
          "size": "4239kb",
          "version": "v1"
        }
      ],
      "title": "Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10054",
        "HTML": "https://arxiv.org/html/2507.10054v1",
        "PDF": "https://arxiv.org/pdf/2507.10054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates the generation of insecure code by LLMs and does not focus on processing LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10144",
      "abstract": "The Lanczos method is a fast and memory-efficient algorithm for solving large-scale symmetric eigenvalue problems. However, its rapid convergence can deteriorate significantly when computing clustered eigenvalues due to a lack of cluster robustness. A promising strategy to enhance cluster robustness -- without substantially compromising convergence speed or memory efficiency -- is to use a random small-block initial, where the block size is greater than one but still much smaller than the cluster size. This leads to the Randomized Small-Block Lanczos (RSBL) method. Despite its empirical effectiveness, RSBL lacks the comprehensive theoretical understanding already available for single-vector and large-block variants. In this paper, we develop a structural bound that supports the cluster robustness of RSBL by leveraging tools from matrix polynomials. We identify an intrinsic theoretical challenge stemming from the non-commuting nature of matrix multiplication. To provide further insight, we propose a conjectured probabilistic bound for cluster robustness and validate it through empirical experiments. Finally, we discuss how insights into cluster robustness can enhance our understanding of RSBL for both eigenvalue computation and low-rank approximation.",
      "authors": [
        "Nian Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:43:21+00:00",
          "link": "https://arxiv.org/abs/2507.10144v1",
          "size": "677kb",
          "version": "v1"
        }
      ],
      "title": "A structural bound for cluster robustness of randomized small-block Lanczos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10144",
        "HTML": "https://arxiv.org/html/2507.10144v1",
        "PDF": "https://arxiv.org/pdf/2507.10144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with cluster robustness in Lanczos methods for eigenvalue problems, unrelated to any aspect of LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10236",
      "abstract": "The rapid advancement of generative technologies presents both unprecedented creative opportunities and significant challenges, particularly in maintaining social trust and ensuring the integrity of digital information. Following these concerns, the challenge of AI-Generated Image Detection (AID) becomes increasingly critical. As these technologies become more sophisticated, the quality of AI-generated images has reached a level that can easily deceive even the most discerning observers. Our systematic evaluation highlights a critical weakness in current AI-Generated Image Detection models: while they perform exceptionally well on controlled benchmark datasets, they struggle significantly with real-world variations. To assess this, we introduce ITW-SM, a new dataset of real and AI-generated images collected from major social media platforms. In this paper, we identify four key factors that influence AID performance in real-world scenarios: backbone architecture, training data composition, pre-processing strategies and data augmentation combinations. By systematically analyzing these components, we shed light on their impact on detection efficacy. Our modifications result in an average AUC improvement of 26.87% across various AID models under real-world conditions.",
      "authors": [
        "Despina Konstantinidou",
        "Dimitrios Karageorgiou",
        "Christos Koutlis",
        "Olga Papadopoulou",
        "Emmanouil Schinas",
        "Symeon Papadopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:56:55+00:00",
          "link": "https://arxiv.org/abs/2507.10236v1",
          "size": "3782kb",
          "version": "v1"
        }
      ],
      "title": "Navigating the Challenges of AI-Generated Image Detection in the Wild: What Truly Matters?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10236",
        "HTML": "https://arxiv.org/html/2507.10236v1",
        "PDF": "https://arxiv.org/pdf/2507.10236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is the introduction of ITW-SM, a dataset of real and AI-generated images with detailed pre-processing strategies and training data composition, improving detection efficacy and data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10302",
      "abstract": "In video Multimodal Large Language Models (video MLLMs), the visual encapsulation process plays a pivotal role in converting video contents into representative tokens for LLM input. While linear projectors are widely employed for encapsulation, they introduce semantic indistinctness and temporal incoherence when applied to videos. Conversely, the structure of resamplers shows promise in tackling these challenges, but an effective solution remains unexplored. Drawing inspiration from resampler structures, we introduce DisCo, a novel visual encapsulation method designed to yield semantically distinct and temporally coherent visual tokens for video MLLMs. DisCo integrates two key components: (1) A Visual Concept Discriminator (VCD) module, assigning unique semantics for visual tokens by associating them in pair with discriminative concepts in the video. (2) A Temporal Focus Calibrator (TFC) module, ensuring consistent temporal focus of visual tokens to video elements across every video frame. Through extensive experiments on multiple video MLLM frameworks, we demonstrate that DisCo remarkably outperforms previous state-of-the-art methods across a variety of video understanding benchmarks, while also achieving higher token efficiency thanks to the reduction of semantic indistinctness. The code: https://github.com/ZJHTerry18/DisCo.",
      "authors": [
        "Jiahe Zhao",
        "Rongkun Zheng",
        "Yi Wang",
        "Helin Wang and Hengshuang Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:05:19+00:00",
          "link": "https://arxiv.org/abs/2507.10302v1",
          "size": "2112kb",
          "version": "v1"
        }
      ],
      "title": "DisCo: Towards Distinct and Coherent Visual Encapsulation in Video MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10302",
        "HTML": "https://arxiv.org/html/2507.10302v1",
        "PDF": "https://arxiv.org/pdf/2507.10302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions visual encapsulation methods for video MLLMs, it primarily focuses on model architecture innovations rather than detailed processing or creation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10306",
      "abstract": "Sign Language Translation (SLT) aims to convert sign language videos into spoken or written text. While early systems relied on gloss annotations as an intermediate supervision, such annotations are costly to obtain and often fail to capture the full complexity of continuous signing. In this work, we propose a two-phase, dual visual encoder framework for gloss-free SLT, leveraging contrastive visual-language pretraining. During pretraining, our approach employs two complementary visual backbones whose outputs are jointly aligned with each other and with sentence-level text embeddings via a contrastive objective. During the downstream SLT task, we fuse the visual features and input them into an encoder-decoder model. On the Phoenix-2014T benchmark, our dual encoder architecture consistently outperforms its single stream variants and achieves the highest BLEU-4 score among existing gloss-free SLT approaches.",
      "authors": [
        "Ozge Mercanoglu Sincan",
        "Richard Bowden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:09:36+00:00",
          "link": "https://arxiv.org/abs/2507.10306v1",
          "size": "909kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive Pretraining with Dual Visual Encoders for Gloss-Free Sign Language Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10306",
        "HTML": "https://arxiv.org/html/2507.10306v1",
        "PDF": "https://arxiv.org/pdf/2507.10306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses sign language translation using dual visual encoders but does not involve processing or improving LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2105.07906",
      "abstract": "Inflexible combined heat and power (CHP) plants and uncertain wind power production result in excess power in distribution networks, which leads to inverse power flow challenging grid operations. Power-to-X facilities such as electrolysers and electric boilers can offer extra flexibility to the integrated energy system. In this regard, we aim to jointly determine the optimal Power-to-X facility sizing and integrated energy system operations in this study. To account for wind power uncertainties, a distributionally robust chance-constrained model is developed to characterize wind power uncertainties using ambiguity sets. Linear decision rules are applied to analytically express real-time recourse actions when uncertainties are exposed, which allows the propagation of wind power uncertainties to gas and heat systems. Accordingly, the developed three-stage distributionally robust chance-constrained model is converted into a computationally tractable single-stage mixed-integer conic model. A case study validates the effectiveness of introducing the electrolyser and electric boiler into the integrated energy system, with respect to the decreased system cost, expanded CHP plant flexibility and reduced inverse power flow. The developed distributionally robust optimization model exhibits better effectiveness and robustness compared to a chance-constrained optimization model assuming wind forecast errors follow Gaussian distribution. Detailed profit analysis reveals that although the overall system cost is minimized, the profit is distributed unevenly across various stakeholders in the system.",
      "authors": [
        "Sen Zhan",
        "Peng Hou",
        "Guangya Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2021-05-17T14:36:13+00:00",
          "link": "https://arxiv.org/abs/2105.07906v1",
          "size": "1509kb",
          "version": "v1"
        }
      ],
      "title": "Distributionally Robust Chance-Constrained Flexibility Planning for Integrated Energy System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2105.07906",
        "PDF": "https://arxiv.org/pdf/2105.07906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robust chance-constrained models for energy systems, with no connection to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.07966",
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable progress in various multimodal tasks. To pursue higher intelligence in space, MLLMs require integrating multiple atomic spatial capabilities to handle complex and dynamic tasks. However, existing benchmarks struggle to comprehensively evaluate the spatial intelligence of common MLLMs from the atomic level to the compositional level. To fill this gap, we present SpaCE-10, a comprehensive benchmark for compositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial capabilities, which are combined to form 8 compositional capabilities. Based on these definitions, we propose a novel hierarchical annotation pipeline to generate high-quality and diverse question-answer (QA) pairs. With over 150+ hours of human expert effort, we obtain over 5k QA pairs for 811 real indoor scenes in SpaCE-10, which covers various evaluation settings like point cloud input and multi-choice QA. We conduct an extensive evaluation of common MLLMs on SpaCE-10 and find that even the most advanced MLLM still lags behind humans by large margins. Through our careful study, we also draw several significant findings that benefit the MLLM community. For example, we reveal that the shortcoming of counting capability greatly limits the compositional spatial capabilities of existing MLLMs. The evaluation code and benchmark datasets are available at https://github.com/Cuzyoung/SpaCE-10.",
      "authors": [
        "Ziyang Gong",
        "Wenhao Li",
        "Oliver Ma",
        "Songyuan Li",
        "Jiayi Ji",
        "Xue Yang",
        "Gen Luo",
        "Junchi Yan",
        "Rongrong Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:41:36+00:00",
          "link": "https://arxiv.org/abs/2506.07966v1",
          "size": "24835kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T08:35:40+00:00",
          "link": "https://arxiv.org/abs/2506.07966v2",
          "size": "28317kb",
          "version": "v2"
        }
      ],
      "title": "SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07966",
        "HTML": "https://arxiv.org/html/2506.07966v2",
        "PDF": "https://arxiv.org/pdf/2506.07966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper introduces a benchmark for MLLMs, it focuses on evaluating spatial intelligence and not on the data processing or creation for LLM training."
      },
      "models": [
        {
          "model_path": "remyxai/SpaceThinker-Qwen2.5VL-3B",
          "downloads": "3180",
          "likes": "24",
          "trending_score": "2.0",
          "link": "https://huggingface.co/remyxai/SpaceThinker-Qwen2.5VL-3B"
        },
        {
          "model_path": "remyxai/SpaceOm",
          "downloads": "1855",
          "likes": "11",
          "trending_score": "2.0",
          "link": "https://huggingface.co/remyxai/SpaceOm"
        },
        {
          "model_path": "remyxai/SpaceQwen2.5-VL-3B-Instruct",
          "downloads": "10896",
          "likes": "15",
          "trending_score": "1.0",
          "link": "https://huggingface.co/remyxai/SpaceQwen2.5-VL-3B-Instruct"
        },
        {
          "model_path": "mgonzs13/SpaceOm-GGUF",
          "downloads": "202",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mgonzs13/SpaceOm-GGUF"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Cusyoung/SpaCE-10",
          "downloads": "9",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Cusyoung/SpaCE-10"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/cuzyoung/space-10"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10521",
      "abstract": "Scientific discoveries increasingly rely on complex multimodal reasoning based on information-intensive scientific data and domain-specific expertise. Empowered by expert-level scientific benchmarks, scientific Multimodal Large Language Models (MLLMs) hold the potential to significantly enhance this discovery process in realistic workflows. However, current scientific benchmarks mostly focus on evaluating the knowledge understanding capabilities of MLLMs, leading to an inadequate assessment of their perception and reasoning abilities. To address this gap, we present the Scientists' First Exam (SFE) benchmark, designed to evaluate the scientific cognitive capacities of MLLMs through three interconnected levels: scientific signal perception, scientific attribute understanding, scientific comparative reasoning. Specifically, SFE comprises 830 expert-verified VQA pairs across three question types, spanning 66 multimodal tasks across five high-value disciplines. Extensive experiments reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08% and 26.52% on SFE, highlighting significant room for MLLMs to improve in scientific realms. We hope the insights obtained in SFE will facilitate further developments in AI-enhanced scientific discoveries.",
      "authors": [
        "Yuhao Zhou",
        "Yiheng Wang",
        "Xuming He",
        "Ruoyao Xiao",
        "Zhiwei Li",
        "Qiantai Feng",
        "Zijie Guo",
        "Yuejin Yang",
        "Hao Wu",
        "Wenxuan Huang",
        "Jiaqi Wei",
        "Dan Si",
        "Xiuqi Yao",
        "Jia Bu",
        "Haiwen Huang",
        "Tianfan Fu",
        "Shixiang Tang",
        "Ben Fei",
        "Dongzhan Zhou",
        "Fenghua Ling",
        "Yan Lu",
        "Siqi Sun",
        "Chenhui Li",
        "Guanjie Zheng",
        "Jiancheng Lv",
        "Wenlong Zhang",
        "Lei Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T09:29:16+00:00",
          "link": "https://arxiv.org/abs/2506.10521v1",
          "size": "14986kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T02:32:48+00:00",
          "link": "https://arxiv.org/abs/2506.10521v2",
          "size": "14986kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T14:13:38+00:00",
          "link": "https://arxiv.org/abs/2506.10521v3",
          "size": "14986kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T08:10:26+00:00",
          "link": "https://arxiv.org/abs/2506.10521v4",
          "size": "14987kb",
          "version": "v4"
        }
      ],
      "title": "Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10521",
        "PDF": "https://arxiv.org/pdf/2506.10521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a benchmark for evaluating scientific reasoning in multimodal language models rather than discussing any LLM training data processing aspects."
      },
      "datasets": [
        {
          "dataset_name": "PrismaX/SFE",
          "downloads": "5219",
          "likes": "10",
          "link": "https://huggingface.co/datasets/PrismaX/SFE"
        }
      ],
      "tasks": [
        "Attribute",
        "Multimodal Reasoning",
        "Visual Question Answering (VQA)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01853",
      "abstract": "The rapid advancement of Large Language Models (LLMs) has intensified the need for evaluation frameworks that address the requirements of linguistically diverse regions, such as India, and go beyond English-centric benchmarks. We introduce EKA-EVAL, a unified evaluation framework that integrates over 35+ benchmarks (including 10 Indic benchmarks) across nine major evaluation categories. The framework provides broader coverage than existing Indian language evaluation tools, offering 11 core capabilities through a modular architecture, seamless integration with Hugging Face and proprietary models, and plug-and-play usability. As the first end-to-end suite for scalable, multilingual LLM benchmarking, the framework combines extensive benchmarks, modular workflows, and dedicated support for low-resource Indian languages to enable inclusive assessment of LLM capabilities across diverse domains. We conducted extensive comparisons against five existing baselines, demonstrating that EKA-EVAL achieves the highest participant ratings in four out of five categories. The framework is open-source and publicly available at: https://github.com/lingo-iitgn/eka-eval.",
      "authors": [
        "Samridhi Raj Sinha",
        "Rajvee Sheth",
        "Abhishek Upperwal",
        "Mayank Singh"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T16:07:54+00:00",
          "link": "https://arxiv.org/abs/2507.01853v1",
          "size": "829kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T04:30:26+00:00",
          "link": "https://arxiv.org/abs/2507.01853v2",
          "size": "1485kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T05:20:11+00:00",
          "link": "https://arxiv.org/abs/2507.01853v3",
          "size": "1485kb",
          "version": "v3"
        }
      ],
      "title": "Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01853",
        "HTML": "https://arxiv.org/html/2507.01853v3",
        "PDF": "https://arxiv.org/pdf/2507.01853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluation frameworks for LLMs, particularly in linguistically diverse regions like India, without discussing any training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08834",
      "abstract": "Traditional numerical methods often struggle with the complexity and scale of modeling pollutant transport across vast and dynamic oceanic domains. This paper introduces a Physics-Informed Neural Network (PINN) framework to simulate the dispersion of pollutants governed by the 2D advection-diffusion equation. The model achieves physically consistent predictions by embedding physical laws and fitting to noisy synthetic data, generated via a finite difference method (FDM), directly into the neural network training process. This approach addresses challenges such as non-linear dynamics and the enforcement of boundary and initial conditions. Synthetic data sets, augmented with varying noise levels, are used to capture real-world variability. The training incorporates a hybrid loss function including PDE residuals, boundary/initial condition conformity, and a weighted data fit term. The approach takes advantage of the Julia language scientific computing ecosystem for high-performance simulations, offering a scalable and flexible alternative to traditional solvers",
      "authors": [
        "Karishma Battina",
        "Prathamesh Dinesh Joshi",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T04:21:09+00:00",
          "link": "https://arxiv.org/abs/2507.08834v1",
          "size": "1710kb",
          "version": "v1"
        }
      ],
      "title": "Physical Informed Neural Networks for modeling ocean pollutant",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08834",
        "HTML": "https://arxiv.org/html/2507.08834v1",
        "PDF": "https://arxiv.org/pdf/2507.08834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using physics-informed neural networks for modeling ocean pollutant dispersion, relying on synthetic data fitting rather than contributing new methods for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09043",
      "abstract": "Gaussian-based Probabilistic Generative Models (GPGMs) generate data by reversing a stochastic process that progressively corrupts samples with Gaussian noise. While these models have achieved state-of-the-art performance across diverse domains, their practical deployment remains constrained by the high computational cost of long generative trajectories, which often involve hundreds to thousands of steps during training and sampling. In this work, we introduce a theoretically grounded and empirically validated framework that improves generation efficiency without sacrificing training granularity or inference fidelity. Our key insight is that for certain data modalities, the noising process causes data to rapidly lose its identity and converge toward a Gaussian distribution. We analytically identify a characteristic step at which the data has acquired sufficient Gaussianity, and then replace the remaining generation trajectory with a closed-form Gaussian approximation. Unlike existing acceleration techniques that coarsening the trajectories by skipping steps, our method preserves the full resolution of learning dynamics while avoiding redundant stochastic perturbations between `Gaussian-like' distributions. Empirical results across multiple data modalities demonstrate substantial improvements in both sample quality and computational efficiency.",
      "authors": [
        "Jingxiang Qu",
        "Wenhan Gao",
        "and Yi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:39:32+00:00",
          "link": "https://arxiv.org/abs/2507.09043v1",
          "size": "535kb",
          "version": "v1"
        }
      ],
      "title": "Shortening the Trajectories: Identity-Aware Gaussian Approximation for Efficient 3D Molecular Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09043",
        "HTML": "https://arxiv.org/html/2507.09043v1",
        "PDF": "https://arxiv.org/pdf/2507.09043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for efficient 3D molecular generation using Gaussian-based models, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09108",
      "abstract": "High-quality labeled datasets are crucial for training and evaluating foundation models in software engineering, but creating them is often prohibitively expensive and labor-intensive. We introduce SPICE, a scalable, automated pipeline for labeling SWE-bench-style datasets with annotations for issue clarity, test coverage, and effort estimation. SPICE combines context-aware code navigation, rationale-driven prompting, and multi-pass consensus to produce labels that closely approximate expert annotations. SPICE's design was informed by our own experience and frustration in labeling more than 800 instances from SWE-Gym. SPICE achieves strong agreement with human-labeled SWE-bench Verified data while reducing the cost of labeling 1,000 instances from around $100,000 (manual annotation) to just $5.10. These results demonstrate SPICE's potential to enable cost-effective, large-scale dataset creation for SE-focused FMs. To support the community, we release both SPICE tool and SPICE Bench, a new dataset of 6,802 SPICE-labeled instances curated from 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench Verified).",
      "authors": [
        "Aaditya Bhatia",
        "Gustavo A. Oliva",
        "Gopi Krishnan Rajbahadur",
        "Haoxiang Zhang",
        "Yihao Chen",
        "Zhilong Chen",
        "Arthur Leung",
        "Dayi Lin",
        "Boyuan Chen",
        "Ahmed E. Hassan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T01:46:26+00:00",
          "link": "https://arxiv.org/abs/2507.09108v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09108",
        "HTML": "https://arxiv.org/html/2507.09108v1",
        "PDF": "https://arxiv.org/pdf/2507.09108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SPICE, an automated pipeline for labeling datasets, which is a direct contribution to LLM training data processing by enabling large-scale dataset creation with a clear explanation of data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09570",
      "abstract": "Pre-training methods have greatly improved the performance of sound event localization and detection (SELD). However, existing Transformer-based models still face high computational cost. To solve this problem, we present a stereo SELD system using a pre-trained PSELDnet and a bidirectional Mamba sequence model. Specifically, we replace the Conformer module with a BiMamba module. We also use asymmetric convolutions to better capture the time and frequency relationships in the audio signal. Test results on the DCASE2025 Task 3 development dataset show that our method performs better than both the baseline and the original PSELDnet with a Conformer decoder. In addition, the proposed model costs fewer computing resources than the baselines. These results show that the BiMamba architecture is effective for solving key challenges in SELD tasks. The source code is publicly accessible at https://github.com/ alexandergwm/DCASE2025 TASK3 Stereo PSELD Mamba.",
      "authors": [
        "Wenmiao Gao",
        "Han Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:38:24+00:00",
          "link": "https://arxiv.org/abs/2507.09570v1",
          "size": "218kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Stereo Sound Event Detection with BiMamba and Pretrained PSELDnet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09570",
        "HTML": "https://arxiv.org/html/2507.09570v1",
        "PDF": "https://arxiv.org/pdf/2507.09570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pre-training methods and model architecture for sound event localization and detection, but does not mention any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09834",
      "abstract": "Autoregressive next-token prediction with the Transformer decoder has become a de facto standard in large language models (LLMs), achieving remarkable success in Natural Language Processing (NLP) at scale. Extending this paradigm to audio poses unique challenges due to its inherently continuous nature. We research audio generation with a causal language model (LM) without discrete tokens. We leverage token-wise diffusion to model the continuous distribution of the next continuous-valued token. Our approach delivers significant improvements over previous discrete solution, AudioGen, achieving 20% and 40% relative gains on AudioCaps in Frechet Audio Distance (FAD) and Kullback-Leibler (KL) divergence, respectively. Additionally, we propose a novel masked next-token prediction task that incorporates masked prediction into the causal LM framework. On AudioCaps, the innovation yields 41% and 33% relative FAD improvements over AudioGen Base (285M) and AudioGen Large (1B) models, respectively, and is on par with the state-of-the-art (SOTA) diffusion models. Furthermore, we achieve these results with significantly fewer parameters -- 193M for our Base and 462M for our Large models.",
      "authors": [
        "Shu-wen Yang",
        "Byeonggeun Kim",
        "Kuan-Po Huang",
        "Qingming Tang",
        "Huy Phan",
        "Bo-Ru Lu",
        "Harsha Sundar",
        "Shalini Ghosh",
        "Hung-yi Lee",
        "Chieh-Chi Kao",
        "Chao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:14:54+00:00",
          "link": "https://arxiv.org/abs/2507.09834v1",
          "size": "1420kb",
          "version": "v1"
        }
      ],
      "title": "Generative Audio Language Modeling with Continuous-valued Tokens and Masked Next-Token Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09834",
        "PDF": "https://arxiv.org/pdf/2507.09834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audio generation with causal language models and does not discuss any LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10171",
      "abstract": "Concrete workability is essential for construction quality, with the slump test being the most common on-site method for its assessment. However, traditional slump testing is manual, time-consuming, and prone to inconsistency, limiting its applicability for real-time monitoring. To address these challenges, we propose SlumpGuard, an AI-powered, video-based system that automatically analyzes concrete flow from the truck chute to assess workability in real time. Our system enables full-batch inspection without manual intervention, improving both the accuracy and efficiency of quality control. We present the system design, a the construction of a dedicated dataset, and empirical results from real-world deployment, demonstrating the effectiveness of SlumpGuard as a practical solution for modern concrete quality assurance.",
      "authors": [
        "Youngmin Kim",
        "Giyeong Oh",
        "Kwangsoo Youm",
        "Youngjae Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:33:47+00:00",
          "link": "https://arxiv.org/abs/2507.10171v1",
          "size": "1257kb",
          "version": "v1"
        }
      ],
      "title": "SlumpGuard: An AI-Powered Real-Time System for Automated Concrete Slump Prediction via Video Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10171",
        "HTML": "https://arxiv.org/html/2507.10171v1",
        "PDF": "https://arxiv.org/pdf/2507.10171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes by constructing a dedicated dataset with clear data processing steps for real-time quality assessment, which is crucial in LLM training data contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.17127",
      "abstract": "P4TG is a hardware-based traffic generator (TG) running on the Intel Tofino 1 ASIC and was programmed using the programming language P4. In its initial version, P4TG could generate up to 10x100 Gb/s of traffic and directly measure rates, packet loss, and other metrics in the data plane. Many researchers and industrial partners requested new features to be incorporated into P4TG since its publication in 2023. With the recently added features, P4TG supports the generation of packets encapsulated with a customizable VLAN, QinQ, VxLAN, MPLS, and SRv6 header. Further, generation of IPv6 traffic is added and P4TG is ported to the Intel Tofino 2 platform enabling a generation capability of up to 10x400 Gb/s. The improvement in user experience focuses on ease of operation. Features like automated ARP replies, improved visualization, report generation, and automated testing based on the IMIX distribution and RFC 2544 are added. Future work on P4TG includes NDP to facilitate IPv6 traffic, and a NETCONF integration to further ease the configuration.",
      "authors": [
        "Fabian Ihle",
        "Etienne Zink",
        "Steffen Lindner",
        "Michael Menth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T18:16:36+00:00",
          "link": "https://arxiv.org/abs/2501.17127v1",
          "size": "433kb",
          "version": "v1"
        },
        {
          "date": "2025-02-13T15:06:02+00:00",
          "link": "https://arxiv.org/abs/2501.17127v2",
          "size": "378kb",
          "version": "v2"
        },
        {
          "date": "2025-03-19T13:58:34+00:00",
          "link": "https://arxiv.org/abs/2501.17127v3",
          "size": "378kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T14:13:40+00:00",
          "link": "https://arxiv.org/abs/2501.17127v4",
          "size": "78kb",
          "version": "v4"
        }
      ],
      "title": "Enhancements to P4TG: Protocols, Performance, and Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17127",
        "HTML": "https://arxiv.org/html/2501.17127v4",
        "PDF": "https://arxiv.org/pdf/2501.17127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses enhancements to a hardware-based traffic generator and does not involve LLM training data processing or engineering."
      },
      "repo_urls": [
        "https://github.com/uni-tue-kn/p4tg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01003",
      "abstract": "Recent studies have proposed interpreting the training process from an ergodic perspective. Building on this foundation, we present a unified framework for understanding and accelerating the training of deep neural networks via stochastic gradient descent (SGD). By analyzing the geometric landscape of the objective function we introduce a practical diagnostic, the running estimate of the largest Lyapunov exponent, which provably distinguishes genuine convergence toward stable minimizers from mere statistical stabilization near saddle points. We then propose a ghost category extension for standard classifiers that adds auxiliary ghost output nodes so the model gains extra descent directions that open a lateral corridor around narrow loss barriers and enable the optimizer to bypass poor basins during the early training phase. We show that this extension strictly reduces the approximation error and that after sufficient convergence the ghost dimensions collapse so that the extended model coincides with the original one and there exists a path in the enlarged parameter space along which the total loss does not increase. Taken together, these results provide a principled architecture level intervention that accelerates early stage trainability while preserving asymptotic behavior and simultaneously serves as an architecture-friendly regularizer.",
      "authors": [
        "Eun-Ji Park",
        "Sangwon Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T17:54:35+00:00",
          "link": "https://arxiv.org/abs/2507.01003v1",
          "size": "11kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T22:03:57+00:00",
          "link": "https://arxiv.org/abs/2507.01003v2",
          "size": "12kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T09:40:25+00:00",
          "link": "https://arxiv.org/abs/2507.01003v3",
          "size": "488kb",
          "version": "v3"
        }
      ],
      "title": "Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01003",
        "HTML": "https://arxiv.org/html/2507.01003v3",
        "PDF": "https://arxiv.org/pdf/2507.01003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for accelerating the training of deep neural networks by introducing a ghost category extension, without focusing on processing LLM training data or the creation of new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08563",
      "abstract": "Accurate vehicle trajectory prediction is essential for ensuring safety and efficiency in fully autonomous driving systems. While existing methods primarily focus on modeling observed motion patterns and interactions with other vehicles, they often neglect the potential risks posed by the uncertain or aggressive behaviors of surrounding vehicles. In this paper, we propose a novel spatial-temporal risk-attentive trajectory prediction framework that incorporates a risk potential field to assess perceived risks arising from behaviors of nearby vehicles. The framework leverages a spatial-temporal encoder and a risk-attentive feature fusion decoder to embed the risk potential field into the extracted spatial-temporal feature representations for trajectory prediction. A risk-scaled loss function is further designed to improve the prediction accuracy of high-risk scenarios, such as short relative spacing. Experiments on the widely used NGSIM and HighD datasets demonstrate that our method reduces average prediction errors by 4.8% and 31.2% respectively compared to state-of-the-art approaches, especially in high-risk scenarios. The proposed framework provides interpretable, risk-aware predictions, contributing to more robust decision-making for autonomous driving systems.",
      "authors": [
        "Xinyi Ning",
        "Zilin Bian",
        "Dachuan Zuo",
        "Semiha Ergan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:05:35+00:00",
          "link": "https://arxiv.org/abs/2507.08563v1",
          "size": "759kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:04:31+00:00",
          "link": "https://arxiv.org/abs/2507.08563v2",
          "size": "691kb",
          "version": "v2"
        }
      ],
      "title": "STRAP: Spatial-Temporal Risk-Attentive Vehicle Trajectory Prediction for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08563",
        "HTML": "https://arxiv.org/html/2507.08563v2",
        "PDF": "https://arxiv.org/pdf/2507.08563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for trajectory prediction in autonomous driving, unrelated to LLM training data processing or engineering efforts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08846",
      "abstract": "Although resource allocation is a well studied problem in computer science, until the prevalence of distributed systems, such as computing clouds and data centres, the question had been addressed predominantly for single resource type scenarios. At the beginning of the last decade, with the introuction of Dominant Resource Fairness, the studies of the resource allocation problem has finally extended to the multiple resource type scenarios. Dominant Resource Fairness is a solution, addressing the problem of fair allocation of multiple resource types, among users with heterogeneous demands. Based on Max-min Fairness, which is a well established algorithm in the literature for allocating resources in the single resource type scenarios, Dominant Resource Fairness generalises the scheme to the multiple resource case. It has a number of desirable properties that makes it preferable over alternatives, such as Sharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness, and as such, it is widely adopted in distributed systems. In the present study, we revisit the original study, and analyse the structure of the algorithm in closer view, to come up with an alternative algorithm, which approximates the Dominant Resource Fairness allocation in fewer steps. We name the new algorithm Precomputed Dominant Resource Fairness, after its main working principle.",
      "authors": [
        "Serdar Metin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:29:46+00:00",
          "link": "https://arxiv.org/abs/2507.08846v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Precomputed Dominant Resource Fairness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08846",
        "HTML": "https://arxiv.org/html/2507.08846v1",
        "PDF": "https://arxiv.org/pdf/2507.08846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses resource allocation algorithms in distributed systems, which does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09512",
      "abstract": "In this paper, we introduce the latest solution developed by our team, HFUT-VUT, for the Micro-gesture Online Recognition track of the IJCAI 2025 MiGA Challenge. The Micro-gesture Online Recognition task is a highly challenging problem that aims to locate the temporal positions and recognize the categories of multiple micro-gesture instances in untrimmed videos. Compared to traditional temporal action detection, this task places greater emphasis on distinguishing between micro-gesture categories and precisely identifying the start and end times of each instance. Moreover, micro-gestures are typically spontaneous human actions, with greater differences than those found in other human actions. To address these challenges, we propose hand-crafted data augmentation and spatial-temporal attention to enhance the model's ability to classify and localize micro-gestures more accurately. Our solution achieved an F1 score of 38.03, outperforming the previous state-of-the-art by 37.9%. As a result, our method ranked first in the Micro-gesture Online Recognition track.",
      "authors": [
        "Pengyu Liu",
        "Kun Li",
        "Fei Wang",
        "Yanyan Wei",
        "Junhui She",
        "Dan Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:38:17+00:00",
          "link": "https://arxiv.org/abs/2507.09512v1",
          "size": "508kb",
          "version": "v1"
        }
      ],
      "title": "Online Micro-gesture Recognition Using Data Augmentation and Spatial-Temporal Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09512",
        "HTML": "https://arxiv.org/html/2507.09512v1",
        "PDF": "https://arxiv.org/pdf/2507.09512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for micro-gesture recognition using data augmentation and attention mechanisms, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09885",
      "abstract": "Reconstructing hyperspectral images (HSI) from RGB images is a cost-effective solution for various vision-based applications. However, most existing learning-based hyperspectral reconstruction methods directly learn the RGB-to-HSI mapping using complex attention mechanisms, neglecting the inherent challenge of transitioning from low-dimensional to high-dimensional information. To address this limitation, we propose a two-stage approach, MCGA, which first learns spectral patterns before estimating the mapping. In the first stage, a multi-scale VQ-VAE learns representations from heterogeneous HSI datasets, extracting a Mixture of Codebooks (MoC). In the second stage, the RGB-to-HSI mapping is refined by querying features from the MoC to replace latent HSI representations, incorporating prior knowledge rather than forcing a direct high-dimensional transformation. To further enhance reconstruction quality, we introduce Grayscale-Aware Attention and Quantized Self-Attention, which adaptively adjust feature map intensities to meet hyperspectral reconstruction requirements. This physically motivated attention mechanism ensures lightweight and efficient HSI recovery. Moreover, we propose an entropy-based Test-Time Adaptation strategy to improve robustness in real-world scenarios. Extensive experiments demonstrate that our method, MCGA, achieves state-of-the-art performance. The code and models will be released at https://github.com/Fibonaccirabbit/MCGA",
      "authors": [
        "Zhanjiang Yang",
        "Lijun Sun",
        "Jiawei Dong",
        "Xiaoxin An",
        "Yang Liu",
        "Meng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:46:06+00:00",
          "link": "https://arxiv.org/abs/2507.09885v1",
          "size": "25047kb",
          "version": "v1"
        }
      ],
      "title": "MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09885",
        "HTML": "https://arxiv.org/html/2507.09885v1",
        "PDF": "https://arxiv.org/pdf/2507.09885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research pertains to hyperspectral image reconstruction from RGB images using attention mechanisms, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10207",
      "abstract": "The Low-Power Wake-Up Signal (LP-WUS) and Low-Power Synchronization Signal (LP-SS), introduced in 3GPP 5G-Advanced Release 19, represent a major step forward in enabling power-efficient IoT communications. This paper presents a comprehensive overview of the LP-WUS and LP-SS procedures in the RRC_IDLE and RRC_INACTIVE states, and outlines key physical layer design choices. The LP-WUS is designed to be detected by a low-power energy detector (ED), allowing the main radio (MR) to remain switched off. This architecture enables power savings of up to 80% compared to conventional 5G paging mechanisms.",
      "authors": [
        "Sebastian Wagner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:26:14+00:00",
          "link": "https://arxiv.org/abs/2507.10207v1",
          "size": "134kb",
          "version": "v1"
        }
      ],
      "title": "Low-Power Wake-Up Signal Design in 3GPP 5G-Advanced Release 19",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10207",
        "HTML": "https://arxiv.org/html/2507.10207v1",
        "PDF": "https://arxiv.org/pdf/2507.10207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses low-power signal design for 5G communications, which does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10541",
      "abstract": "Recent Large Reasoning Models (LRMs) have achieved remarkable progress on task-specific benchmarks, yet their evaluation methods remain constrained by isolated problem-solving paradigms. Existing benchmarks predominantly assess single-question reasoning through sequential testing, resulting critical limitations: (1) vulnerability to data contamination and less challenging (e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly and perpetual creation of new questions with large human efforts, (2) failure to evaluate models under multi-context pressure, a key requirement for real-world deployment. To bridge this gap, we present REST (Reasoning Evaluation through Simultaneous Testing), a stress-testing framework that concurrently exposes LRMs to multiple problems simultaneously. Beyond basic reasoning, REST specifically evaluates several under-tested capabilities: contextual priority allocation, cross-problem interference resistance, and dynamic cognitive load management. Our evaluation reveals several striking findings: Even state-of-the-art (SOTA) models like DeepSeek-R1 exhibit substantial performance degradation under stress testing. Crucially, REST demonstrates stronger discriminative power than existing benchmarks, revealing pronounced performance differences among models that exhibit similar, near-ceiling performance under single-question evaluations. Some key mechanistic insights emerge from our analysis: (1) the \"overthinking trap\" is a critical factor contributing to the performance degradation; (2) the models trained with \"long2short\" technique preserve more accuracy of their single-problem performance under REST, outperforming standard-trained counterparts. These results establish REST as a cost-efficient, future-proof evaluation paradigm that better reflects real-world reasoning demands while reducing reliance on continuous human annotation.",
      "authors": [
        "Zhuoshi Pan and Qizhi Pei and Yu Li and Qiyao Sun and Zinan Tang and H. Vicky Zhao and Conghui He and Lijun Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:58:47+00:00",
          "link": "https://arxiv.org/abs/2507.10541v1",
          "size": "1204kb",
          "version": "v1"
        }
      ],
      "title": "REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10541",
        "HTML": "https://arxiv.org/html/2507.10541v1",
        "PDF": "https://arxiv.org/pdf/2507.10541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents an evaluation framework for reasoning under stress but does not contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.12132",
      "abstract": "The Koopman framework proposes a linear representation of finite-dimensional nonlinear systems through a generally infinite-dimensional globally linear embedding. Originally, the Koopman formalism has been derived for autonomous systems. In applications for systems with inputs, generally a linear time invariant (LTI) form of the Koopman model is assumed, as it facilitates the use of control techniques such as linear quadratic regulation and model predictive control. However, it can be easily shown that this assumption is insufficient to capture the dynamics of the underlying nonlinear system. Proper theoretical extension for actuated continuous-time systems with a linear or a control-affine input has been worked out only recently, however extensions to discrete-time systems and general continuous-time systems have not been developed yet. In the present paper, we systematically investigate and analytically derive lifted forms under inputs for a rather wide class of nonlinear systems in both continuous and discrete time. We prove that the resulting lifted representations give Koopman models where the state transition is linear, but the input matrix becomes state-dependent (state and input-dependent in the discrete-time case), giving rise to a specially structured linear parameter-varying (LPV) description of the underlying system. We also provide error bounds on how much the dependency of the input matrix contributes to the resulting representation and how well the system behaviour can be approximated by an LTI Koopman representation. The introduced theoretical insight greatly helps for performing proper model structure selection in system identification with Koopman models as well as making a proper choice for LTI or LPV techniques for the control of nonlinear systems through the Koopman approach.",
      "authors": [
        "Lucian Cristian Iacob",
        "Roland T\\'oth and Maarten Schoukens"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-25T12:34:56+00:00",
          "link": "https://arxiv.org/abs/2207.12132v1",
          "size": "1702kb",
          "version": "v1"
        },
        {
          "date": "2023-12-15T16:21:35+00:00",
          "link": "https://arxiv.org/abs/2207.12132v2",
          "size": "2114kb",
          "version": "v2"
        }
      ],
      "title": "Koopman Form of Nonlinear Systems with Inputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.12132",
        "HTML": "https://arxiv.org/html/2207.12132",
        "PDF": "https://arxiv.org/pdf/2207.12132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on deriving Koopman forms for nonlinear systems, which pertains to system control theory rather than LLM training data processing."
      },
      "tasks": [
        "Form",
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.10872",
      "abstract": "Cropland maps are essential for remote sensing-based agricultural monitoring, providing timely insights without extensive field surveys. Machine learning enables large-scale mapping but depends on geo-referenced ground-truth data, which is costly to collect, motivating the use of global datasets in data-scarce regions. A key challenge is understanding how the quantity, quality, and proximity of the training data to the target region influences model performance. We evaluate this in Nigeria, using 1,827 manually labelled samples covering the whole country, and subsets of the Geowiki dataset: Nigeria-only, regional (Nigeria and neighbouring countries), and global. We extract pixel-wise multi-source time series arrays from Sentinel-1, Sentinel-2, ERA5 climate, and a digital elevation model using Google Earth Engine, comparing Random Forests with LSTMs, including a lightweight multi-headed LSTM variant. Results show local data significantly boosts performance, with accuracy gains up to 0.246 (RF) and 0.178 (LSTM). Nigeria-only or regional data outperformed global data despite the lower amount of labels, with the exception of the multi-headed LSTM, which benefited from global data when local samples were absent. Sentinel-1, climate, and topographic data are critical data sources, with their removal reducing F1-score by up to 0.593. Addressing class imbalance also improved LSTM accuracy by up to 0.071. Our top-performing model (Nigeria-only LSTM) achieved an F1-score of 0.814 and accuracy of 0.842, matching the best global land cover product while offering stronger recall, critical for food security. We release code, data, maps, and an interactive web app to support future work.",
      "authors": [
        "Joaquin Gajardo",
        "Michele Volpi",
        "Daniel Onwude and Thijs Defraeye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-18T01:23:22+00:00",
          "link": "https://arxiv.org/abs/2312.10872v1",
          "size": "5229kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T08:05:25+00:00",
          "link": "https://arxiv.org/abs/2312.10872v2",
          "size": "8459kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating the Role of Training Data Origin for Country-Scale Cropland Mapping in Data-Scarce Regions: A Case Study of Nigeria",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.10872",
        "HTML": "https://arxiv.org/html/2312.10872v2",
        "PDF": "https://arxiv.org/pdf/2312.10872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though it discusses training data for machine learning models in cropland mapping, it does not pertain to LLM training data processing or collection."
      },
      "tasks": [
        "Binary Classification"
      ],
      "repo_urls": [
        "https://github.com/joaquin-gajardo/nigeria-crop-mask"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.03493",
      "abstract": "Transformers have had tremendous impact for several sequence related tasks, largely due to their ability to retrieve from any part of the sequence via softmax based dot-product attention. This mechanism plays a crucial role in Transformer's performance. We analyze the gradients backpropagated through the softmax operation in the attention mechanism and observe that these gradients can often be small. This poor gradient signal backpropagation can lead to inefficient learning of parameters preceeding the attention operations. To this end, we introduce a new attention mechanism called LASER, which we analytically show to admit a larger gradient signal. We show that LASER attention can be implemented by making small modifications to existing attention implementations. We conduct experiments on autoregressive large language models (LLMs) with upto 7.7 billion parameters with an average improvement of upto 1.44% over standard attention on downstream evaluations and 1.65% finetuning improvements. Additionally, LASER demonstrates generalization performance improvement across a variety of tasks (vision, text and speech):Vision Transformer (ViT) on Imagenet, Conformer on the Librispeech speech-to-text and BERT with 2.2 billion parameters.",
      "authors": [
        "Sai Surya Duvvuri",
        "Inderjit S. Dhillon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T20:18:28+00:00",
          "link": "https://arxiv.org/abs/2411.03493v1",
          "size": "3743kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T21:20:50+00:00",
          "link": "https://arxiv.org/abs/2411.03493v2",
          "size": "1255kb",
          "version": "v2"
        }
      ],
      "title": "LASER: Attention with Exponential Transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03493",
        "HTML": "https://arxiv.org/html/2411.03493v2",
        "PDF": "https://arxiv.org/pdf/2411.03493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new attention mechanism, LASER, focusing on improvements in model architecture rather than LLM training data processing."
      },
      "tasks": [
        "Speech-to-Text"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06565",
      "abstract": "We present the Material Masked Autoencoder (MMAE), a self-supervised Vision Transformer pretrained on a large corpus of short-fiber composite images via masked image reconstruction. The pretrained MMAE learns latent representations that capture essential microstructural features and are broadly transferable across tasks. We demonstrate two key applications: (i) predicting homogenized stiffness components through fine-tuning on limited data, and (ii) inferring physically interpretable parameters by coupling MMAE with an interaction-based material network (IMN), thereby enabling extrapolation of nonlinear stress-strain responses. These results highlight the promise of microstructure foundation models and lay the groundwork for future extensions to more complex systems, such as 3D composites and experimental datasets.",
      "authors": [
        "Ting-Ju Wei and Chuin-Shan Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-10T19:06:25+00:00",
          "link": "https://arxiv.org/abs/2411.06565v1",
          "size": "5080kb",
          "version": "v1"
        },
        {
          "date": "2025-02-04T14:57:37+00:00",
          "link": "https://arxiv.org/abs/2411.06565v2",
          "size": "7690kb",
          "version": "v2"
        },
        {
          "date": "2025-04-08T19:00:34+00:00",
          "link": "https://arxiv.org/abs/2411.06565v3",
          "size": "7690kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T07:43:50+00:00",
          "link": "https://arxiv.org/abs/2411.06565v4",
          "size": "7150kb",
          "version": "v4"
        }
      ],
      "title": "Foundation Model for Composite Microstructures: Reconstruction, Stiffness, and Nonlinear Behavior Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06565",
        "HTML": "https://arxiv.org/html/2411.06565v4",
        "PDF": "https://arxiv.org/pdf/2411.06565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a model for predicting material behavior using visual data from composites. There is no mention of LLM training data processing or data engineering."
      },
      "tasks": [
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/berrywei/material_mask_autoencoder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10435",
      "abstract": "When detecting anomalous sounds in complex environments, one of the main difficulties is that trained models must be sensitive to subtle differences in monitored target signals, while many practical applications also require them to be insensitive to changes in acoustic domains. Examples of such domain shifts include changing the type of microphone or the location of acoustic sensors, which can have a much stronger impact on the acoustic signal than subtle anomalies themselves. Moreover, users typically aim to train a model only on source domain data, which they may have a relatively large collection of, and they hope that such a trained model will be able to generalize well to an unseen target domain by providing only a minimal number of samples to characterize the acoustic signals in that domain. In this work, we review and discuss recent publications focusing on this domain generalization problem for anomalous sound detection in the context of the DCASE challenges on acoustic machine condition monitoring.",
      "authors": [
        "Kevin Wilkinghoff",
        "Takuya Fujimura",
        "Keisuke Imoto",
        "Jonathan Le Roux",
        "Zheng-Hua Tan",
        "Tomoki Toda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T14:56:51+00:00",
          "link": "https://arxiv.org/abs/2503.10435v1",
          "size": "100kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T07:37:16+00:00",
          "link": "https://arxiv.org/abs/2503.10435v2",
          "size": "121kb",
          "version": "v2"
        }
      ],
      "title": "Handling Domain Shifts for Anomalous Sound Detection: A Review of DCASE-Related Work",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10435",
        "HTML": "https://arxiv.org/html/2503.10435v2",
        "PDF": "https://arxiv.org/pdf/2503.10435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews work on domain shifts in anomalous sound detection and does not discuss the creation or processing of LLM training data."
      },
      "tasks": [
        "Domain Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04370",
      "abstract": "In this paper, we introduce a new numerical algorithm for solving the Dirichlet problem for the real Monge--Ampere equation. The idea is to represent the non-linear Monge--Ampere operator as an infimum of a class of linear elliptic operators and use Bellman's principle to construct a numeric scheme for approximating the operator attaining this infimum.\n  Moreover, we prove convergence of the proposed algorithm (under suitable technical assumptions) and discuss its strengths and weaknesses. We also demonstrate the performance of the method on several examples with various degrees of regularity and degeneracy and compare the results to two existing methods. Our method runs considerably faster than the ones used for comparison, improving the running time by a factor of 3--10 for smooth, strictly convex examples, and by a factor of 20--100 or more for mildly degenerate examples.",
      "authors": [
        "Aleksandra Le and Frank Wikstr\\\"om"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T12:42:23+00:00",
          "link": "https://arxiv.org/abs/2505.04370v1",
          "size": "1081kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:15:10+00:00",
          "link": "https://arxiv.org/abs/2505.04370v2",
          "size": "1084kb",
          "version": "v2"
        }
      ],
      "title": "Fast Bellman algorithm for real Monge-Ampere equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04370",
        "HTML": "https://arxiv.org/html/2505.04370v2",
        "PDF": "https://arxiv.org/pdf/2505.04370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a numerical algorithm for solving the Monge\u2013Ampere equation. It is not related to LLM training data collection, processing, or creation of datasets for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08527",
      "abstract": "Source-free domain adaptation (SFDA) for segmentation aims at adapting a model trained in the source domain to perform well in the target domain with only the source model and unlabeled target data. Inspired by the recent success of Segment Anything Model (SAM) which exhibits the generality of segmenting images of various modalities and in different domains given human-annotated prompts like bounding boxes or points, we for the first time explore the potentials of Segment Anything Model for SFDA via automatedly finding an accurate bounding box prompt. We find that the bounding boxes directly generated with existing SFDA approaches are defective due to the domain gap. To tackle this issue, we propose a novel Dual Feature Guided (DFG) auto-prompting approach to search for the box prompt. Specifically, the source model is first trained in a feature aggregation phase, which not only preliminarily adapts the source model to the target domain but also builds a feature distribution well-prepared for box prompt search. In the second phase, based on two feature distribution observations, we gradually expand the box prompt with the guidance of the target model feature and the SAM feature to handle the class-wise clustered target features and the class-wise dispersed target features, respectively. To remove the potentially enlarged false positive regions caused by the over-confident prediction of the target model, the refined pseudo-labels produced by SAM are further postprocessed based on connectivity analysis. Experiments on 3D and 2D datasets indicate that our approach yields superior performance compared to conventional methods. Code is available at https://github.com/xmed-lab/DFG.",
      "authors": [
        "Zheang Huai",
        "Hui Tang",
        "Yi Li",
        "Zhuangzhuang Chen",
        "Xiaomeng Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T13:00:48+00:00",
          "link": "https://arxiv.org/abs/2505.08527v1",
          "size": "1856kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T02:43:13+00:00",
          "link": "https://arxiv.org/abs/2505.08527v2",
          "size": "1941kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T11:00:59+00:00",
          "link": "https://arxiv.org/abs/2505.08527v3",
          "size": "1929kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08527",
        "HTML": "https://arxiv.org/html/2505.08527v3",
        "PDF": "https://arxiv.org/pdf/2505.08527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on domain adaptation through model architecture and feature manipulation, without addressing any specific LLM training data processing tasks or contributions."
      },
      "tasks": [
        "Domain Adaptation",
        "Source-Free Domain Adaptation"
      ],
      "repo_urls": [
        "https://github.com/zheangh/dfg",
        "https://github.com/xmed-lab/dfg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04839",
      "abstract": "We introduce RIPE, an innovative reinforcement learning-based framework for weakly-supervised training of a keypoint extractor that excels in both detection and description tasks. In contrast to conventional training regimes that depend heavily on artificial transformations, pre-generated models, or 3D data, RIPE requires only a binary label indicating whether paired images represent the same scene. This minimal supervision significantly expands the pool of training data, enabling the creation of a highly generalized and robust keypoint extractor.\n  RIPE utilizes the encoder's intermediate layers for the description of the keypoints with a hyper-column approach to integrate information from different scales. Additionally, we propose an auxiliary loss to enhance the discriminative capability of the learned descriptors.\n  Comprehensive evaluations on standard benchmarks demonstrate that RIPE simplifies data preparation while achieving competitive performance compared to state-of-the-art techniques, marking a significant advancement in robust keypoint extraction and description. To support further research, we have made our code publicly available at https://github.com/fraunhoferhhi/RIPE.",
      "authors": [
        "Johannes K\\\"unzel",
        "Anna Hilsmann",
        "Peter Eisert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T10:01:30+00:00",
          "link": "https://arxiv.org/abs/2507.04839v1",
          "size": "21088kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:09:57+00:00",
          "link": "https://arxiv.org/abs/2507.04839v2",
          "size": "21088kb",
          "version": "v2"
        }
      ],
      "title": "RIPE: Reinforcement Learning on Unlabeled Image Pairs for Robust Keypoint Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04839",
        "HTML": "https://arxiv.org/html/2507.04839v2",
        "PDF": "https://arxiv.org/pdf/2507.04839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper addresses a keypoint extraction framework using reinforcement learning, it does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08838",
      "abstract": "Improving the reasoning capabilities of diffusion-based large language models (dLLMs) through reinforcement learning (RL) remains an open problem. The intractability of dLLMs likelihood function necessitates approximating the current, old, and reference policy likelihoods at each policy optimization step. This reliance introduces additional computational overhead and lead to potentially large bias -- particularly when approximation errors occur in the denominator of policy ratios used for importance sampling. To mitigate these issues, we introduce $\\mathtt{wd1}$, a novel policy optimization approach that reformulates the objective as a weighted likelihood, requiring only a single approximation for the current parametrized policy likelihood. Experiments on widely used reasoning benchmarks demonstrate that $\\mathtt{wd1}$, without supervised fine-tuning (SFT) or any supervised data, outperforms existing RL methods for dLLMs, achieving up to 16% higher accuracy. $\\mathtt{wd1}$ delivers additional computational gains, including reduced training time and fewer function evaluations (NFEs) per gradient step. These findings, combined with the simplicity of method's implementation and R1-Zero-like training (no SFT), position $\\mathtt{wd1}$ as a more effective and efficient method for applying RL to dLLMs reasoning.",
      "authors": [
        "Xiaohang Tang",
        "Rares Dolga",
        "Sangwoong Yoon",
        "Ilija Bogunovic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T21:27:25+00:00",
          "link": "https://arxiv.org/abs/2507.08838v1",
          "size": "622kb",
          "version": "v1"
        }
      ],
      "title": "wd1: Weighted Policy Optimization for Reasoning in Diffusion Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08838",
        "HTML": "https://arxiv.org/html/2507.08838v1",
        "PDF": "https://arxiv.org/pdf/2507.08838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a new policy optimization approach for improving reasoning in diffusion-based LLMs, but it does not focus on training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09115",
      "abstract": "This study presents the modeling, control design, and performance analysis of a DC-DC buck converter using state-space averaging techniques. Buck converters are essential in modern power electronics for regulating DC voltages in renewable energy and electric vehicle systems. The paper first introduces the basic operation of buck converters and emphasizes the need for voltage regulation through closed-loop control systems. A state-space averaged model is derived to simplify the nonlinear switched dynamics, enabling a more effective analysis and controller design. The small-signal transfer function from the duty cycle to the output voltage is obtained to support control development. In addition, the Proportional-Integral (PI) control based on the frequency-domain method was explored. The PI controller was tuned to achieve various phase margins and is evaluated through Bode plots, step responses, and performance metrics, revealing trade-offs between overshoot, settling time, and steady-state error. A complete simulation of the controlled buck converter verifies its ability to maintain a stable output voltage across wide input voltage variations. The results validate the effectiveness of state-space averaging in control design and highlight the robustness of feedback systems in power electronic converters.",
      "authors": [
        "Sampson E. Nwachukwu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:11:42+00:00",
          "link": "https://arxiv.org/abs/2507.09115v1",
          "size": "953kb",
          "version": "v1"
        }
      ],
      "title": "Modelling and Control of a Buck Converter Using State-Space Averaging and Classical Feedback Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09115",
        "PDF": "https://arxiv.org/pdf/2507.09115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on modeling and control of a buck converter in power electronics, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09194",
      "abstract": "The hitting set problem is a fundamental problem in computer science and mathematics. Given a family of sets over a universe of elements, a minimal hitting set is a subset-minimal collection of elements that intersects each set in the family. Enumerating all minimal hitting sets is crucial in various real-world applications.\n  In this paper, we address the full enumeration of all minimal hitting sets for a given family of sets. We formulate the problem using Answer Set Programming (ASP) and leverage existing ASP solvers for efficient enumeration. We propose an ASP-based tool, MinHit-ASP, and our empirical evaluation shows that it effectively enumerates minimal hitting sets across benchmarks from diverse problem domains.",
      "authors": [
        "Mohimenul Kabir",
        "Kuldeep S Meel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.09194v1",
          "size": "388kb",
          "version": "v1"
        }
      ],
      "title": "A Simple and Effective ASP-Based Tool for Enumerating Minimal Hitting Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09194",
        "HTML": "https://arxiv.org/html/2507.09194v1",
        "PDF": "https://arxiv.org/pdf/2507.09194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the hitting set problem using ASP, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09500",
      "abstract": "Vision-language models (VLMs) exhibit remarkable zero-shot capabilities but struggle with distribution shifts in downstream tasks when labeled data is unavailable, which has motivated the development of Test-Time Adaptation (TTA) to improve VLMs' performance during inference without annotations. Among various TTA approaches, cache-based methods show promise by preserving historical knowledge from low-entropy samples in a dynamic cache and fostering efficient adaptation. However, these methods face two critical reliability challenges: (1) entropy often becomes unreliable under distribution shifts, causing error accumulation in the cache and degradation in adaptation performance; (2) the final predictions may be unreliable due to inflexible decision boundaries that fail to accommodate large downstream shifts. To address these challenges, we propose a Reliable Test-time Adaptation (ReTA) method that integrates two complementary strategies to enhance reliability from two perspectives. First, to mitigate the unreliability of entropy as a sample selection criterion for cache construction, we introduce Consistency-aware Entropy Reweighting (CER), which incorporates consistency constraints to weight entropy during cache updating. While conventional approaches rely solely on low entropy for cache prioritization and risk introducing noise, our method leverages predictive consistency to maintain a high-quality cache and facilitate more robust adaptation. Second, we present Diversity-driven Distribution Calibration (DDC), which models class-wise text embeddings as multivariate Gaussian distributions, enabling adaptive decision boundaries for more accurate predictions across visually diverse content. Extensive experiments demonstrate that ReTA consistently outperforms state-of-the-art methods, particularly under challenging real-world distribution shifts.",
      "authors": [
        "Yiwen Liang",
        "Hui Chen",
        "Yizhe Xiong",
        "Zihan Zhou",
        "Mengyao Lyu",
        "Zijia Lin",
        "Shuaicheng Niu",
        "Sicheng Zhao",
        "Jungong Han",
        "Guiguang Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:37:33+00:00",
          "link": "https://arxiv.org/abs/2507.09500v1",
          "size": "683kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09500",
        "HTML": "https://arxiv.org/html/2507.09500v1",
        "PDF": "https://arxiv.org/pdf/2507.09500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses Test-Time Adaptation (TTA) for vision-language models to handle distribution shifts in downstream tasks. It does not discuss the creation or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09843",
      "abstract": "Incomplete multiview clustering is of high recent interest, fueled by the advancement of common information-based deep multiview learning. The practical scenarios where unpaired multiview data with missing values have wide applications in generative learning, cross-modal retrieval, and wireless device identification problems. Following the perspective that the shared information between the incomplete multiview data aligns with the cluster targets, recent works have generalized the well-known common information frameworks in information theory multiview learning problems, with improved performance reported. Different from previous works, we extend the frameworks to incomplete multiview clustering problems and propose an efficient solver: Wyner Incomplete MultiView Clustering (WyIMVC). Interestingly, the common randomness in WyIMVC allows for joint clustering and missing value inference in contrast to the compared methods in the literature. Moreover, leveraging the difference-of-convex structure of the formulated problems, we propose an efficient solver with a convergence guarantee independent of initialization. Empirically, our solver outperforms the state-of-the-art solvers in a range of incomplete multiview datasets with varying numbers of views and dimensions.",
      "authors": [
        "AbdAlRahman Odeh",
        "Teng-Hui Huang",
        "Hesham El Gamal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:50:58+00:00",
          "link": "https://arxiv.org/abs/2507.09843v1",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "title": "Incomplete Multiview Learning via Wyner Common Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09843",
        "HTML": "https://arxiv.org/html/2507.09843v1",
        "PDF": "https://arxiv.org/pdf/2507.09843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses clustering in incomplete multiview learning and does not involve LLM training data processing techniques or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09937",
      "abstract": "Large language models are susceptible to memorizing repeated sequences, posing privacy and copyright concerns. A popular mitigation strategy is to remove memorized information from specific neurons post-hoc. However, such approaches have shown limited success so far. In a controlled setting, we show that the memorization of natural sequences (those that resemble linguistically plausible text) become mechanistically entangled with general language abilities, thereby becoming challenging to remove post-hoc. In this work, we put forward a new paradigm of MemSinks that promotes isolation of memorization by design. We leverage a sequence identifier that activates a unique set of memorization neurons for each sequence across repetitions. By analyzing the dynamics of learning and forgetting, we argue that MemSinks facilitates isolation of memorized content, making it easier to remove without compromising general language capabilities. We implement MemSinks at the billion-parameter and billion-token scale, and observe both effective isolation and strong generalization. To our knowledge, this is the first proof-of-concept on real data demonstrating that simultaneous generalization and isolation is achievable. We open-source our code at http://github.com/grghosal/MemSinks.",
      "authors": [
        "Gaurav R. Ghosal",
        "Pratyush Maini",
        "Aditi Raghunathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:23:27+00:00",
          "link": "https://arxiv.org/abs/2507.09937v1",
          "size": "820kb",
          "version": "v1"
        }
      ],
      "title": "Memorization Sinks: Isolating Memorization during LLM Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09937",
        "HTML": "https://arxiv.org/html/2507.09937v1",
        "PDF": "https://arxiv.org/pdf/2507.09937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses MemSinks as a method to isolate memorization during LLM training, which is closely related to LLM data processing. However, it primarily deals with neural representation issues rather than specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10099",
      "abstract": "ReDemon UI synthesizes React applications from user demonstrations, enabling designers and non-expert programmers to create UIs that integrate with standard UI prototyping workflows. Users provide a static mockup sketch with event handler holes and demonstrate desired runtime behaviors by interacting with the rendered mockup and editing the sketch. ReDemon UI identifies reactive data and synthesizes a React program with correct state update logic. We utilize enumerative synthesis for simple UIs and LLMs for more complex UIs.",
      "authors": [
        "Jay Lee",
        "Gyuhyeok Oh",
        "Joongwon Ahn",
        "Xiaokang Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:34:33+00:00",
          "link": "https://arxiv.org/abs/2507.10099v1",
          "size": "1088kb",
          "version": "v1"
        }
      ],
      "title": "ReDemon UI: Reactive Synthesis by Demonstration for Web UI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10099",
        "HTML": "https://arxiv.org/html/2507.10099v1",
        "PDF": "https://arxiv.org/pdf/2507.10099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes synthesizing React applications from user demonstrations, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10394",
      "abstract": "Earth observation satellites (EOS) play a pivotal role in capturing and analyzing planetary phenomena, ranging from natural disasters to societal development. The EOS scheduling problem (EOSSP), which optimizes the schedule of EOS, is often solved with respect to nadir-directional EOS systems, thus restricting the observation time of targets and, consequently, the effectiveness of each EOS. This paper leverages state-of-the-art constellation reconfigurability to develop the reconfigurable EOS scheduling problem (REOSSP), wherein EOS are assumed to be maneuverable, forming a more optimal constellation configuration at multiple opportunities during a schedule. This paper develops a novel mixed-integer linear programming formulation for the REOSSP to optimally solve the scheduling problem for given parameters. Additionally, since the REOSSP can be computationally expensive for large-scale problems, a rolling horizon procedure (RHP) solution method is developed. The performance of the REOSSP is benchmarked against the EOSSP, which serves as a baseline, through a set of random instances where problem characteristics are varied and a case study in which Hurricane Sandy is used to demonstrate realistic performance. These experiments demonstrate the value of constellation reconfigurability in its application to the EOSSP, yielding solutions that improve performance, while the RHP enhances computational runtime for large-scale REOSSP instances.",
      "authors": [
        "Brycen D. Pearl",
        "Joseph M. Miller",
        "Hang Woon Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:36:27+00:00",
          "link": "https://arxiv.org/abs/2507.10394v1",
          "size": "3529kb",
          "version": "v1"
        }
      ],
      "title": "The Reconfigurable Earth Observation Satellite Scheduling Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10394",
        "HTML": "https://arxiv.org/html/2507.10394v1",
        "PDF": "https://arxiv.org/pdf/2507.10394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on scheduling problems for Earth observation satellites, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10468",
      "abstract": "Online platforms struggle to curb hate speech without over-censoring legitimate discourse. Early bidirectional transformer encoders made big strides, but the arrival of ultra-large autoregressive LLMs promises deeper context-awareness. Whether this extra scale actually improves practical hate-speech detection on real-world text remains unverified. Our study puts this question to the test by benchmarking both model families, classic encoders and next-generation LLMs, on curated corpora of online interactions for hate-speech detection (Hate or No Hate).",
      "authors": [
        "Ariadna Mon",
        "Sa\\'ul Fenollosa",
        "Jon Lecumberri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:46:30+00:00",
          "link": "https://arxiv.org/abs/2507.10468v1",
          "size": "2251kb",
          "version": "v1"
        }
      ],
      "title": "From BERT to Qwen: Hate Detection across architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10468",
        "HTML": "https://arxiv.org/html/2507.10468v1",
        "PDF": "https://arxiv.org/pdf/2507.10468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study compares model families for hate speech detection but does not primarily focus on data processing techniques relevant to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10542",
      "abstract": "Generating high-fidelity real-time animated sequences of photorealistic 3D head avatars is important for many graphics applications, including immersive telepresence and movies. This is a challenging problem particularly when rendering digital avatar close-ups for showing character's facial microfeatures and expressions. To capture the expressive, detailed nature of human heads, including skin furrowing and finer-scale facial movements, we propose to couple locally-defined facial expressions with 3D Gaussian splatting to enable creating ultra-high fidelity, expressive and photorealistic 3D head avatars. In contrast to previous works that operate on a global expression space, we condition our avatar's dynamics on patch-based local expression features and synthesize 3D Gaussians at a patch level. In particular, we leverage a patch-based geometric 3D face model to extract patch expressions and learn how to translate these into local dynamic skin appearance and motion by coupling the patches with anchor points of Scaffold-GS, a recent hierarchical scene representation. These anchors are then used to synthesize 3D Gaussians on-the-fly, conditioned by patch-expressions and viewing direction. We employ color-based densification and progressive training to obtain high-quality results and faster convergence for high resolution 3K training images. By leveraging patch-level expressions, ScaffoldAvatar consistently achieves state-of-the-art performance with visually natural motion, while encompassing diverse facial expressions and styles in real time.",
      "authors": [
        "Shivangi Aneja and Sebastian Weiss and Irene Baeza and Prashanth Chandran and Gaspard Zoss and Matthias Nie{\\ss}ner and Derek Bradley"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:59:03+00:00",
          "link": "https://arxiv.org/abs/2507.10542v1",
          "size": "43976kb",
          "version": "v1"
        }
      ],
      "title": "ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10542",
        "HTML": "https://arxiv.org/html/2507.10542v1",
        "PDF": "https://arxiv.org/pdf/2507.10542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating photorealistic 3D avatars using patch-based local expression features and 3D Gaussian splatting. It does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.07202",
      "abstract": "Diffusion models have recently emerged as a powerful tool for planning. However, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally improves with inference-time computation scaling-standard diffusion-based planners offer only limited avenues for the scalability. In this paper, we introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates the generative strength of diffusion models with the adaptive search capabilities of MCTS. Our method reconceptualizes denoising as a tree-structured process, allowing partially denoised plans to be iteratively evaluated, pruned, and refined. By selectively expanding promising trajectories while retaining the flexibility to revisit and improve suboptimal branches, MCTD achieves the benefits of MCTS such as controlling exploration-exploitation trade-offs within the diffusion framework. Empirical results on challenging long-horizon tasks show that MCTD outperforms diffusion baselines, yielding higher-quality solutions as inference-time computation increases.",
      "authors": [
        "Jaesik Yoon",
        "Hyeonseo Cho",
        "Doojin Baek",
        "Yoshua Bengio and Sungjin Ahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T02:51:42+00:00",
          "link": "https://arxiv.org/abs/2502.07202v1",
          "size": "10069kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T00:14:32+00:00",
          "link": "https://arxiv.org/abs/2502.07202v2",
          "size": "10069kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T00:37:56+00:00",
          "link": "https://arxiv.org/abs/2502.07202v3",
          "size": "10102kb",
          "version": "v3"
        },
        {
          "date": "2025-06-11T01:22:31+00:00",
          "link": "https://arxiv.org/abs/2502.07202v4",
          "size": "2524kb",
          "version": "v4"
        },
        {
          "date": "2025-07-07T06:30:41+00:00",
          "link": "https://arxiv.org/abs/2502.07202v5",
          "size": "2522kb",
          "version": "v5"
        },
        {
          "date": "2025-07-13T08:21:39+00:00",
          "link": "https://arxiv.org/abs/2502.07202v6",
          "size": "2522kb",
          "version": "v6"
        }
      ],
      "title": "Monte Carlo Tree Diffusion for System 2 Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07202",
        "HTML": "https://arxiv.org/html/2502.07202",
        "PDF": "https://arxiv.org/pdf/2502.07202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a planning framework using diffusion models and MCTS, focusing on planning efficiency and not discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15902",
      "abstract": "Large Language Models (LLMs) have attained human-level fluency in text generation, which complicates the distinction between human-written and LLM-generated texts. This increases the risk of misuse and highlights the need for reliable detectors. Yet, existing detectors exhibit poor robustness on out-of-distribution (OOD) data and attacked data, which is critical for real-world scenarios. Also, they struggle to provide interpretable evidence to support their decisions, thus undermining the reliability. In light of these challenges, we propose IPAD (Inverse Prompt for AI Detection), a novel framework consisting of a Prompt Inverter that identifies predicted prompts that could have generated the input text, and two Distinguishers that examine the probability that the input texts align with the predicted prompts. Empirical evaluations demonstrate that IPAD outperforms the strongest baselines by 9.05% (Average Recall) on in-distribution data, 12.93% (AUROC) on out-of-distribution (OOD) data, and 5.48% (AUROC) on attacked data. IPAD also performs robustly on structured datasets. Furthermore, an interpretability assessment is conducted to illustrate that IPAD enhances the AI detection trustworthiness by allowing users to directly examine the decision-making evidence, which provides interpretable support for its state-of-the-art detection results.",
      "authors": [
        "Zheng Chen",
        "Yushi Feng",
        "Changyang He",
        "Yue Deng",
        "Hongxi Pu",
        "Bo Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T19:41:32+00:00",
          "link": "https://arxiv.org/abs/2502.15902v1",
          "size": "3975kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T08:34:03+00:00",
          "link": "https://arxiv.org/abs/2502.15902v2",
          "size": "753kb",
          "version": "v2"
        }
      ],
      "title": "IPAD: Inverse Prompt for AI Detection -- A Robust and Explainable LLM-Generated Text Detector",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15902",
        "HTML": "https://arxiv.org/html/2502.15902v2",
        "PDF": "https://arxiv.org/pdf/2502.15902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI detection and robustness of detection methods for LLM-generated texts, but does not address LLM training data processing or dataset creation."
      },
      "tasks": [
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/Bellafc/IPAD-Inver-Prompt-for-AI-Detection-"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09290",
      "abstract": "Subspace codes, and in particular cyclic subspace codes, have gained significant attention in recent years due to their applications in error correction for random network coding. In this paper, we introduce a new technique for constructing cyclic subspace codes with large cardinality and prescribed minimum distance. Using this new method, we provide new constructions of cyclic subspace codes in the Grassmannian $\\mathcal{G}_q(n,k)$ of all $k$-dimensional $\\mathbb{F}_q$-subspaces of an $n$-dimensional vector space over $\\mathbb{F}_q$, when $k\\mid n$ and $n/k$ is a composite number, with minimum distance $2k-2$ and large size. We prove that the resulting codes have sizes larger than those obtained from previously known constructions with the same parameters. Furthermore, we show that our constructions of cyclic subspace codes asymptotically reach the Johnson type bound II for infinite values of $n/k$.",
      "authors": [
        "Chiara Castello and Paolo Santonastaso"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:00:11+00:00",
          "link": "https://arxiv.org/abs/2507.09290v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotically optimal cyclic subspace codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09290",
        "HTML": "https://arxiv.org/html/2507.09290v1",
        "PDF": "https://arxiv.org/pdf/2507.09290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on constructing subspace codes for error correction in network coding, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09459",
      "abstract": "We propose SegVec3D, a novel framework for 3D point cloud instance segmentation that integrates attention mechanisms, embedding learning, and cross-modal alignment. The approach builds a hierarchical feature extractor to enhance geometric structure modeling and enables unsupervised instance segmentation via contrastive clustering. It further aligns 3D data with natural language queries in a shared semantic space, supporting zero-shot retrieval. Compared to recent methods like Mask3D and ULIP, our method uniquely unifies instance segmentation and multimodal understanding with minimal supervision and practical deployability.",
      "authors": [
        "Zhihan Kang",
        "Boyu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:54:55+00:00",
          "link": "https://arxiv.org/abs/2507.09459v1",
          "size": "2946kb",
          "version": "v1"
        }
      ],
      "title": "SegVec3D: A Method for Vector Embedding of 3D Objects Oriented Towards Robot manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09459",
        "HTML": "https://arxiv.org/html/2507.09459v1",
        "PDF": "https://arxiv.org/pdf/2507.09459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on 3D point cloud instance segmentation and multimodal understanding, without any discussion on LLM training data processing or relevant dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10397",
      "abstract": "This paper seeks to advance CVRP research by addressing the challenge of understanding the nuanced relationships between instance characteristics and metaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a valuable tool that allows for a new perspective on the field. By combining the ISA methodology with a dataset from the DIMACS 12th Implementation Challenge on Vehicle Routing, our research enabled the identification of 23 relevant instance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages, which employ dimensionality reduction and machine learning methods, allowed us to create a two-dimensional projection of the instance space to understand how the structure of instances affect the behavior of MHs. A key contribution of our work is that we provide a projection matrix, which makes it straightforward to incorporate new instances into this analysis and allows for a new method for instance analysis in the CVRP field.",
      "authors": [
        "Alessandra M. M. M. Gouv\\^ea",
        "Nuno Paulos",
        "Eduardo Uchoa e Mari\\'a C. V. Nascimento"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:37:55+00:00",
          "link": "https://arxiv.org/abs/2507.10397v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "Instance space analysis of the capacitated vehicle routing problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10397",
        "HTML": "https://arxiv.org/html/2507.10397v1",
        "PDF": "https://arxiv.org/pdf/2507.10397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on analyzing the capacitated vehicle routing problem and does not involve LLM training data processing or improvements in data quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.03158",
      "abstract": "Predicting loan eligibility with high accuracy remains a significant challenge in the finance sector. Accurate predictions enable financial institutions to make informed decisions, mitigate risks, and effectively adapt services to meet customer needs. However, the complexity and the high-dimensional nature of financial data have always posed significant challenges to achieving this level of precision. To overcome these issues, we propose a novel approach that employs Quantum Machine Learning (QML) for Loan Eligibility Prediction using Quantum Neural Networks (LEP-QNN). Our innovative approach achieves an accuracy of 98% in predicting loan eligibility from a single, comprehensive dataset. This performance boost is attributed to the strategic implementation of a dropout mechanism within the quantum circuit, aimed at minimizing overfitting and thereby improving the model's predictive reliability. In addition, our exploration of various optimizers leads to identifying the most efficient setup for our LEP-QNN framework, optimizing its performance. We also rigorously evaluate the resilience of LEP-QNN under different quantum noise scenarios, ensuring its robustness and dependability for quantum computing environments. This research showcases the potential of QML in financial predictions and establishes a foundational guide for advancing QML technologies, marking a step towards developing advanced, quantum-driven financial decision-making tools.",
      "authors": [
        "Nouhaila Innan",
        "Alberto Marchisio",
        "Mohamed Bennai",
        "and Muhammad Shafique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T09:35:03+00:00",
          "link": "https://arxiv.org/abs/2412.03158v1",
          "size": "4074kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T04:25:24+00:00",
          "link": "https://arxiv.org/abs/2412.03158v2",
          "size": "4167kb",
          "version": "v2"
        }
      ],
      "title": "LEP-QNN: Loan Eligibility Prediction using Quantum Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03158",
        "HTML": "https://arxiv.org/html/2412.03158v2",
        "PDF": "https://arxiv.org/pdf/2412.03158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using Quantum Neural Networks for loan eligibility prediction, which involves model architecture improvements rather than any LLM training data processing."
      },
      "tasks": [
        "Prediction",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08947",
      "abstract": "We demonstrate that separating beamforming (i.e., downlink precoding and uplink combining) and channel estimation in multi-user MIMO wireless systems incurs no loss of optimality under general conditions that apply to a wide variety of models in the literature, including canonical reciprocity-based cellular and cell-free massive MIMO system models. Specifically, we provide conditions under which optimal processing in terms of ergodic achievable rates can be decomposed into minimum mean-square error (MMSE) channel estimation followed by MMSE beamforming, for both centralized and distributed architectures. Applications of our results are illustrated in terms of concrete examples and numerical simulations.",
      "authors": [
        "Lorenzo Miretti",
        "Slawomir Sta\\'nczak",
        "Giuseppe Caire"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T18:10:52+00:00",
          "link": "https://arxiv.org/abs/2507.08947v1",
          "size": "422kb",
          "version": "v1"
        }
      ],
      "title": "A joint channel estimation and beamforming separation principle for massive MIMO systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08947",
        "HTML": "https://arxiv.org/html/2507.08947v1",
        "PDF": "https://arxiv.org/pdf/2507.08947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is related to channel estimation and beamforming in MIMO systems and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09090",
      "abstract": "Large Language Models (LLMs) demonstrate strong conversational abilities. In this Working Paper, we study them in the context of debating in two ways: their ability to perform in a structured debate along with a dataset of arguments to use and their ability to evaluate utterances throughout the debate. We deploy six leading publicly available models from three providers for the Retrieval-Augmented Debate and Evaluation. The evaluation is performed by measuring four key metrics: Quality, Quantity, Manner, and Relation. Throughout this task, we found that although LLMs perform well in debates when given related arguments, they tend to be verbose in responses yet consistent in evaluation. The accompanying source code for this paper is located at https://github.com/dsgt-arc/touche-2025-rad.",
      "authors": [
        "Anthony Miyaguchi",
        "Conor Johnston",
        "Aaryan Potdar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:20:00+00:00",
          "link": "https://arxiv.org/abs/2507.09090v1",
          "size": "191kb",
          "version": "v1"
        }
      ],
      "title": "DS@GT at Touch\\'e: Large Language Models for Retrieval-Augmented Debate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09090",
        "HTML": "https://arxiv.org/html/2507.09090v1",
        "PDF": "https://arxiv.org/pdf/2507.09090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper studies LLMs in the context of debating using a dataset of arguments; however, it does not make significant contributions to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09097",
      "abstract": "Large Vision-Language Models (LVLMs) have demonstrated promising performance in chest X-ray (CXR) analysis. To enhance human-computer interaction, several studies have incorporated radiologists' eye gaze, typically through heatmaps or textual prompts. However, these methods often overlook the sequential order of eye movements, which could provide valuable insights by highlighting both the areas of interest and the order in which they are examined. In this work, we propose a novel approach called RadEyeVideo that integrates radiologists' eye-fixation data as a video sequence, capturing both the temporal and spatial dynamics of their gaze. We evaluate this method in CXR report generation and disease diagnosis using three general-domain, open-source LVLMs with video input capabilities. When prompted with eye-gaze videos, model performance improves by up to 24.6% in the report generation task and on average 15.2% for both tasks using scaled evaluation metrics. Notably, RadEyeVideo enhanced an open-domain LVLM model, LLaVA-OneVision, to surpass task-specific medical LVLMs such as MAIRA-2 and CheXagent, trained on large Chest X-ray data. This work highlights that domain expert's knowledge (eye-gaze information in this case), when effectively integrated with LVLMs, can significantly enhance general-domain models' capabilities in clinical tasks. RadEyeVideo is a step toward a scalable human-centered approach of utilizing LVLMs in medical image analytics.",
      "authors": [
        "Yunsoo Kim",
        "Jinge Wu",
        "Honghan Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T00:45:38+00:00",
          "link": "https://arxiv.org/abs/2507.09097v1",
          "size": "354kb",
          "version": "v1"
        }
      ],
      "title": "RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09097",
        "HTML": "https://arxiv.org/html/2507.09097v1",
        "PDF": "https://arxiv.org/pdf/2507.09097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing model performance by integrating eye-gaze data into LVLMs for medical imaging, without making technical contributions to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10045",
      "abstract": "This paper investigates whether state-of-the-art Large Language Models (LLMs) can automatically translate SPARQL between popular Knowledge Graph (KG) schemas. We focus on translations between the DBpedia and Wikidata KG, and later on DBLP and OpenAlex KG. This study addresses a notable gap in KG interoperability research by rigorously evaluating LLM performance on SPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first align 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100 DBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic KGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and Mistral-Large-Instruct-2407 are selected based on their sizes and architectures and tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs were compared with gold answers, and resulting errors were categorized. We find that the performance varies markedly across models and prompting strategies, and that translations for Wikidata to DBpedia work far better than translations for DBpedia to Wikidata.",
      "authors": [
        "Malte Christian Bartels",
        "Debayan Banerjee",
        "Ricardo Usbeck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:23:25+00:00",
          "link": "https://arxiv.org/abs/2507.10045v1",
          "size": "661kb",
          "version": "v1"
        }
      ],
      "title": "Automating SPARQL Query Translations between DBpedia and Wikidata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10045",
        "HTML": "https://arxiv.org/html/2507.10045v1",
        "PDF": "https://arxiv.org/pdf/2507.10045"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates SPARQL query translations and tests LLMs' performance on such tasks, with no focus on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10467",
      "abstract": "We introduce the notion of colorful minors, which generalizes the classical concept of rooted minors in graphs. $q$-colorful graph is defined as a pair $(G, \\chi),$ where $G$ is a graph and $\\chi$ assigns to each vertex a (possibly empty) subset of at most $q$ colors. The colorful minor relation enhances the classical minor relation by merging color sets at contracted edges and allowing the removal of colors from vertices. This framework naturally models algorithmic problems involving graphs with (possibly overlapping) annotated vertex sets. We develop a structural theory for colorful minors by establishing several theorems characterizing $\\mathcal{H}$-colorful minor-free graphs, where $\\mathcal{H}$ consists either of a clique or a grid with all vertices assigned all colors, or of grids with colors segregated and ordered on the outer face. Leveraging our structural insights, we provide a complete classification - parameterized by the number $q$ of colors - of all colorful graphs that exhibit the Erd\\H{o}s-P\\'osa property with respect to colorful minors. On the algorithmic side, we provide a fixed-parameter tractable algorithm for colorful minor testing and a variant of the $k$-disjoint paths problem. Together with the fact that the colorful minor relation forms a well-quasi-order, this implies that every colorful minor-monotone parameter on colorful graphs admits a fixed-parameter algorithm. Furthermore, we derive two algorithmic meta-theorems (AMTs) whose structural conditions are linked to extensions of treewidth and Hadwiger number on colorful graphs. Our results suggest how known AMTs can be extended to incorporate not only the structure of the input graph but also the way the colored vertices are distributed in it.",
      "authors": [
        "Evangelos Protopapas",
        "Dimitrios M. Thilikos",
        "Sebastian Wiederrecht"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:46:29+00:00",
          "link": "https://arxiv.org/abs/2507.10467v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "Colorful Minors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10467",
        "HTML": "https://arxiv.org/html/2507.10467v1",
        "PDF": "https://arxiv.org/pdf/2507.10467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses graph theory related to colorful minors and does not address any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2109.04567",
      "abstract": "We study the problem of finding a minimum homology basis, that is, a lightest set of cycles that generates the $1$-dimensional homology classes with $\\mathbb{Z}_2$ coefficients in a given simplicial complex $K$. This problem has been extensively studied in the last few years. For general complexes, the current best deterministic algorithm, by Dey et al., runs in $O(N m^{\\omega-1} + n m g)$ time, where $N$ denotes the total number of simplices in $K$, $m$ denotes the number of edges in $K$, $n$ denotes the number of vertices in $K$, $g$ denotes the rank of the $1$-homology group of $K$, and $\\omega$ denotes the exponent of matrix multiplication. In this paper, we present three conceptually simple randomized algorithms that compute a minimum homology basis of a general simplicial complex $K$. The first algorithm runs in $\\tilde{O}(m^\\omega)$ time, the second algorithm runs in $O(N m^{\\omega-1})$ time and the third algorithm runs in $\\tilde{O}(N^2 g + N m g{^2} + m g{^3})$ time which is nearly quadratic time when $g=O(1)$. We also study the problem of finding a minimum cycle basis in an undirected graph $G$ with $n$ vertices and $m$ edges. The best known algorithm for this problem runs in $O(m^\\omega)$ time. Our algorithm, which has a simpler high-level description, but is slightly more expensive, runs in $\\tilde{O}(m^\\omega)$ time.\n  We also provide a practical implementation of computing the minimum homology basis for general weighted complexes. The implementation is broadly based on the algorithmic ideas described in this paper, differing in its use of practical subroutines. Of these subroutines, the more costly step makes use of a parallel implementation, thus potentially addressing the issue of scale. We compare results against the currently known state of the art implementation (ShortLoop).",
      "authors": [
        "Amritendu Dhar",
        "Vijay Natarajan",
        "Abhishek Rathod"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-09T21:39:49+00:00",
          "link": "https://arxiv.org/abs/2109.04567v1",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T18:36:44+00:00",
          "link": "https://arxiv.org/abs/2109.04567v2",
          "size": "17394kb",
          "version": "v2"
        }
      ],
      "title": "Fast Algorithms for Minimum Homology Basis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.04567",
        "HTML": "https://arxiv.org/html/2109.04567",
        "PDF": "https://arxiv.org/pdf/2109.04567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents algorithms for computing a minimum homology basis in simplicial complexes and graphs, without any mention of LLM training data processing or dataset engineering."
      },
      "repo_urls": [
        "https://bitbucket.org/vgl_iisc/fastloop"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.07152",
      "abstract": "Achieving optimal statistical performance while ensuring the privacy of personal data is a challenging yet crucial objective in modern data analysis. However, characterizing the optimality, particularly the minimax lower bound, under privacy constraints is technically difficult. To address this issue, we propose a novel approach called the score attack, which provides a lower bound on the differential-privacy-constrained minimax risk of parameter estimation. The score attack method is based on the tracing attack concept in differential privacy and can be applied to any statistical model with a well-defined score statistic. It can optimally lower bound the minimax risk of estimating unknown model parameters, up to a logarithmic factor, while ensuring differential privacy for a range of statistical problems. We demonstrate the effectiveness and optimality of this general method in various examples, such as the generalized linear model in both classical and high-dimensional sparse settings, the Bradley-Terry-Luce model for pairwise comparisons, and non-parametric regression over the Sobolev class.",
      "authors": [
        "T. Tony Cai",
        "Yichen Wang",
        "Linjun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-13T14:26:27+00:00",
          "link": "https://arxiv.org/abs/2303.07152v1",
          "size": "753kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T21:42:34+00:00",
          "link": "https://arxiv.org/abs/2303.07152v2",
          "size": "61kb",
          "version": "v2"
        }
      ],
      "title": "Score Attack: A Lower Bound Technique for Optimal Differentially Private Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.07152",
        "HTML": "https://arxiv.org/html/2303.07152v2",
        "PDF": "https://arxiv.org/pdf/2303.07152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a technique for handling privacy in data analysis, which is not directly related to LLM training data processing."
      },
      "tasks": [
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.18311",
      "abstract": "Neural radiance fields (NeRFs) have achieved impressive view synthesis results by learning an implicit volumetric representation from multi-view images. To project the implicit representation into an image, NeRF employs volume rendering that approximates the continuous integrals of rays as an accumulation of the colors and densities of the sampled points. Although this approximation enables efficient rendering, it ignores the direction information in point intervals, resulting in ambiguous features and limited reconstruction quality. In this paper, we propose an anisotropic neural representation learning method that utilizes learnable view-dependent features to improve scene representation and reconstruction. We model the volumetric function as spherical harmonic (SH)-guided anisotropic features, parameterized by multilayer perceptrons, facilitating ambiguity elimination while preserving the rendering efficiency. To achieve robust scene reconstruction without anisotropy overfitting, we regularize the energy of the anisotropic features during training. Our method is flexiable and can be plugged into NeRF-based frameworks. Extensive experiments show that the proposed representation can boost the rendering quality of various NeRFs and achieve state-of-the-art rendering performance on both synthetic and real-world scenes.",
      "authors": [
        "Y.Wang",
        "J. Xu",
        "Y. Zeng and Y. Gong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-30T07:29:30+00:00",
          "link": "https://arxiv.org/abs/2311.18311v1",
          "size": "27432kb",
          "version": "v1"
        },
        {
          "date": "2024-03-11T02:22:50+00:00",
          "link": "https://arxiv.org/abs/2311.18311v2",
          "size": "15133kb",
          "version": "v2"
        }
      ],
      "title": "Anisotropic Neural Representation Learning for High-Quality Neural Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.18311",
        "HTML": "https://arxiv.org/html/2311.18311",
        "PDF": "https://arxiv.org/pdf/2311.18311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with neural representation learning for high-quality neural rendering, which is outside the scope of LLM training data processing."
      },
      "tasks": [
        "NeRF",
        "Neural Rendering",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04850",
      "abstract": "Collaborative learning enables multiple participants to learn a single global model by exchanging focused updates instead of sharing data. One of the core challenges in collaborative learning is ensuring that participants are rewarded fairly for their contributions, which entails two key sub-problems: contribution assessment and reward allocation. This work focuses on fair reward allocation, where the participants are incentivized through model rewards - differentiated final models whose performance is commensurate with the contribution. In this work, we leverage the concept of slimmable neural networks to collaboratively learn a shared global model whose performance degrades gracefully with a reduction in model width. We also propose a post-training fair allocation algorithm that determines the model width for each participant based on their contributions. We theoretically study the convergence of our proposed approach and empirically validate it using extensive experiments on different datasets and architectures. We also extend our approach to enable training-time model reward allocation.",
      "authors": [
        "Nurbek Tastan",
        "Samuel Horvath",
        "Karthik Nandakumar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T11:39:27+00:00",
          "link": "https://arxiv.org/abs/2502.04850v1",
          "size": "127kb",
          "version": "v1"
        },
        {
          "date": "2025-07-13T02:51:38+00:00",
          "link": "https://arxiv.org/abs/2502.04850v2",
          "size": "149kb",
          "version": "v2"
        }
      ],
      "title": "Aequa: Fair Model Rewards in Collaborative Learning via Slimmable Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04850",
        "HTML": "https://arxiv.org/html/2502.04850v2",
        "PDF": "https://arxiv.org/pdf/2502.04850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses fair reward allocation in collaborative learning using slimmable networks but does not focus on LLM training data processing."
      },
      "tasks": [
        "Contribution Assessment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04840",
      "abstract": "Even from an early age, humans naturally adapt between exocentric (Exo) and egocentric (Ego) perspectives to understand daily procedural activities. Inspired by this cognitive ability, we propose a novel Unsupervised Ego-Exo Dense Procedural Activity Captioning (UE$^{2}$DPAC) task, which aims to transfer knowledge from the labeled source view to predict the time segments and descriptions of action sequences for the target view without annotations. Despite previous works endeavoring to address the fully-supervised single-view or cross-view dense video captioning, they lapse in the proposed task due to the significant inter-view gap caused by temporal misalignment and irrelevant object interference. Hence, we propose a Gaze Consensus-guided Ego-Exo Adaptation Network (GCEAN) that injects the gaze information into the learned representations for the fine-grained Ego-Exo alignment. Specifically, we propose a Score-based Adversarial Learning Module (SALM) that incorporates a discriminative scoring network and compares the scores of distinct views to learn unified view-invariant representations from a global level. Then, the Gaze Consensus Construction Module (GCCM) utilizes the gaze to progressively calibrate the learned representations to highlight the regions of interest and extract the corresponding temporal contexts. Moreover, we adopt hierarchical gaze-guided consistency losses to construct gaze consensus for the explicit temporal and spatial adaptation between the source and target views. To support our research, we propose a new EgoMe-UE$^{2}$DPAC benchmark, and extensive experiments demonstrate the effectiveness of our method, which outperforms many related methods by a large margin. Code is available at https://github.com/ZhaofengSHI/GCEAN.",
      "authors": [
        "Zhaofeng Shi",
        "Heqian Qiu",
        "Lanxiao Wang",
        "Qingbo Wu",
        "Fanman Meng",
        "and Hongliang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T08:51:11+00:00",
          "link": "https://arxiv.org/abs/2504.04840v1",
          "size": "11780kb",
          "version": "v1"
        },
        {
          "date": "2025-04-12T04:16:24+00:00",
          "link": "https://arxiv.org/abs/2504.04840v2",
          "size": "11930kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T09:23:01+00:00",
          "link": "https://arxiv.org/abs/2504.04840v3",
          "size": "12462kb",
          "version": "v3"
        }
      ],
      "title": "Unsupervised Ego- and Exo-centric Dense Procedural Activity Captioning via Gaze Consensus Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04840",
        "HTML": "https://arxiv.org/html/2504.04840v3",
        "PDF": "https://arxiv.org/pdf/2504.04840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel task related to procedural activity captioning and mentions a new benchmark, but it does not discuss the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10015",
      "abstract": "Foundation multi-modal models are often designed by stitching of multiple existing pretrained uni-modal models: for example, an image classifier with an autoregressive text model. This stitching process is performed by training a connector module that aims to align the representation-representation or representation-input spaces of these uni-modal models. However, given the complexity of training such connectors on large scale web-based datasets coupled with the ever-increasing number of available pretrained uni-modal models, the task of uni-modal models selection and subsequent connector module training becomes computationally demanding. To address this under-studied critical problem, we propose Hypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimal uni-modal model selection and connector training by leveraging hypernetworks. Specifically, our framework utilizes the parameter prediction capability of a hypernetwork to obtain jointly trained connector modules for $N \\times M$ combinations of uni-modal models. In our experiments, Hyma reduces the optimal uni-modal model pair search cost by $10\\times$ (averaged across all experiments), while matching the ranking and trained connector performance obtained via grid search across a suite of diverse multi-modal benchmarks.",
      "authors": [
        "Jaisidh Singh",
        "Diganta Misra",
        "Boris Knyazev",
        "Antonio Orvieto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:51:01+00:00",
          "link": "https://arxiv.org/abs/2507.10015v1",
          "size": "464kb",
          "version": "v1"
        }
      ],
      "title": "(Almost) Free Modality Stitching of Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10015",
        "HTML": "https://arxiv.org/html/2507.10015v1",
        "PDF": "https://arxiv.org/pdf/2507.10015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses modality stitching of foundation models and the computational demands of training connector modules, but it does not primarily focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10185",
      "abstract": "Quasi-cyclic (QC) low-density parity-check (LDPC) codes are a class of LDPC codes with a simple construction facilitating hardware implementation while achieving excellent performance. In this paper, we introduce an algorithm that constructs QC spatially-coupled (SC) LDPC codes with large girth while keeping the constraint length small. The algorithm offers a \"protograph to basegraph\" construction, focusing on finding small lifting sizes of QC codes while avoiding short cycles. This work extends the hierarchical quasi-cyclic (HQC) construction for block LDPC codes proposed by Wang et al. to the spatially coupled case. The construction is based on the cycle relevant matrix (CRM) derived from the periodic structure of time-invariant SC-LDPC codes. Numerical results show that the proposed algorithm effectively achieves the target girth with a small lifting factor, enabling low-complexity SC code construction.",
      "authors": [
        "Haizheng Li",
        "Sisi Miao",
        "and Laurent Schmalen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:50:59+00:00",
          "link": "https://arxiv.org/abs/2507.10185v1",
          "size": "90kb",
          "version": "v1"
        }
      ],
      "title": "High Girth Spatially-Coupled LDPC Codes with Hierarchical Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10185",
        "HTML": "https://arxiv.org/html/2507.10185v1",
        "PDF": "https://arxiv.org/pdf/2507.10185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the construction of LDPC codes, focusing on algorithms for designing such codes without mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.06877",
      "abstract": "Test collections are information-retrieval tools that allow researchers to quickly and easily evaluate ranking algorithms. While test collections have become an integral part of IR research, the process of data creation involves significant manual-annotation effort, which often makes it very expensive and time-consuming. Consequently, test collections can become too small when the budget is limited, which may lead to unstable evaluations. As a cheaper alternative, recent studies have proposed using large language models (LLMs) to completely replace human assessors. However, while LLMs correlate to some extent with human judgments, their predictions are not perfect and often show bias. Thus, a complete replacement with LLMs is considered too risky and not fully reliable.\n  In this paper, we propose LLM-Assisted Relevance Assessments (LARA), an effective method to balance manual annotations with LLM annotations, helping build a rich and reliable test collection even under a low budget. We use the LLM's predicted relevance probabilities to select the most profitable documents for manual annotation under a budget constraint. Guided by theoretical reasoning, LARA actively learns to calibrate the LLM's predicted relevance probabilities, directing the human-annotation process. Then, using the calibration model learned from the limited manual annotations, LARA debiases the LLM predictions to annotate the remaining non-assessed data. Experiments on TREC-7 Ad Hoc, TREC-8 Ad Hoc, TREC Robust 2004, and TREC-COVID datasets show that LARA outperforms alternative solutions under almost any budget constraint. While the community debates humans versus LLMs in relevance assessments, we contend that, given the same amount of human effort, it is reasonable to leverage LLMs.",
      "authors": [
        "Rikiya Takehi",
        "Ellen M. Voorhees",
        "Tetsuya Sakai",
        "Ian Soboroff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T11:17:35+00:00",
          "link": "https://arxiv.org/abs/2411.06877v1",
          "size": "1216kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T07:50:44+00:00",
          "link": "https://arxiv.org/abs/2411.06877v2",
          "size": "2142kb",
          "version": "v2"
        },
        {
          "date": "2025-05-08T06:40:02+00:00",
          "link": "https://arxiv.org/abs/2411.06877v3",
          "size": "2143kb",
          "version": "v3"
        },
        {
          "date": "2025-06-13T06:52:31+00:00",
          "link": "https://arxiv.org/abs/2411.06877v4",
          "size": "2067kb",
          "version": "v4"
        }
      ],
      "title": "LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06877",
        "HTML": "https://arxiv.org/html/2411.06877",
        "PDF": "https://arxiv.org/pdf/2411.06877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a method for integrating LLMs in the relevance assessment process of test collections, which involves using and processing LLM outputs to reduce human annotation efforts, enhancing data quality and efficiency in data collection."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "repo_urls": [
        "https://github.com/RikiyaT/LARA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09025",
      "abstract": "We propose Lizard, a linearization framework that transforms pretrained Transformer-based Large Language Models (LLMs) into flexible, subquadratic architectures for infinite-context generation. Transformer-based LLMs face significant memory and computational bottlenecks as context lengths increase, due to the quadratic complexity of softmax attention and the growing key-value (KV) cache. Lizard addresses these limitations by introducing a subquadratic attention mechanism that closely approximates softmax attention while preserving the output quality. Unlike previous linearization methods, which are often limited by fixed model structures and therefore exclude gating mechanisms, Lizard incorporates a gating module inspired by recent state-of-the-art linear models. This enables adaptive memory control, supports constant-memory inference, offers strong length generalization, and allows more flexible model design. Lizard combines gated linear attention for global context compression with sliding window attention enhanced by meta memory, forming a hybrid mechanism that captures both long-range dependencies and fine-grained local interactions. Moreover, we introduce a hardware-aware algorithm that accelerates the training speed of our models. Extensive experiments show that Lizard achieves near-lossless recovery of the teacher model's performance across standard language modeling tasks, while significantly outperforming previous linearization methods. On the 5-shot MMLU benchmark, Lizard improves over prior models by 18 points and shows significant improvements on associative recall tasks.",
      "authors": [
        "Chien Van Nguyen",
        "Ruiyi Zhang",
        "Hanieh Deilamsalehy",
        "Puneet Mathur",
        "Viet Dac Lai",
        "Haoliang Wang",
        "Jayakumar Subramanian",
        "Ryan A. Rossi",
        "Trung Bui",
        "Nikos Vlassis",
        "Franck Dernoncourt",
        "Thien Huu Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:19:18+00:00",
          "link": "https://arxiv.org/abs/2507.09025v1",
          "size": "369kb",
          "version": "v1"
        }
      ],
      "title": "Lizard: An Efficient Linearization Framework for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09025",
        "HTML": "https://arxiv.org/html/2507.09025v1",
        "PDF": "https://arxiv.org/pdf/2507.09025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the architecture and optimization of a linearization framework for LLMs, specifically addressing subquadratic attention and memory management. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10069",
      "abstract": "Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components -- combined with complex inference pipelines and heterogeneous workloads -- introduce significant inference overhead. Therefore, efficiently serving MLLMs remains a major challenge. Current tightly coupled serving architectures struggle to distinguish between mixed request types or adapt parallelism strategies to different inference stages, leading to increased time-to-first-token (TTFT) latency and poor resource utilization. To address this, we propose Elastic Multimodal Parallelism (EMP), a new serving paradigm that elastically adapts to resource heterogeneity across request types and inference stages. Building upon EMP, we develop ElasticMM, an MLLM serving system that (1) separates requests into independent modality groups with dynamic resource allocation via a modality-aware load balancer; (2) decouples inference stages and enables parallelism adjustment and adaptive scaling via elastic partition scheduling; and (3) improves inference efficiency through unified multimodal prefix caching and non-blocking encoding. Experiments on diverse real-world datasets show that ElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by up to 4.2x and achieving 3.2-4.5x higher throughput while meeting service-level objectives (SLOs).",
      "authors": [
        "Zedong Liu",
        "Shenggan Cheng",
        "Guangming Tan",
        "Yang You",
        "and Dingwen Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:53:48+00:00",
          "link": "https://arxiv.org/abs/2507.10069v1",
          "size": "1700kb",
          "version": "v1"
        }
      ],
      "title": "ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10069",
        "HTML": "https://arxiv.org/html/2507.10069v1",
        "PDF": "https://arxiv.org/pdf/2507.10069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on serving multimodal LLMs efficiently rather than processing or creating datasets for training these models."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Networking and Internet Architecture (cs.NI)",
    "Optimization and Control (math.OC)",
    "Computation and Language (cs.CL)",
    "Artificial Intelligence (cs.AI)",
    "Computational Complexity (cs.CC)",
    "Social and Information Networks (cs.SI)",
    "Machine Learning (stat.ML)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Hardware Architecture (cs.AR)",
    "Software Engineering (cs.SE)",
    "Machine Learning (cs.LG)",
    "Numerical Analysis (math.NA)",
    "Computer Science and Game Theory (cs.GT)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Cryptography and Security (cs.CR)",
    "Trading and Market Microstructure (q-fin.TR)",
    "Computers and Society (cs.CY)",
    "Human-Computer Interaction (cs.HC)",
    "Geophysics (physics.geo-ph)",
    "Methodology (stat.ME)",
    "Robotics (cs.RO)",
    "Systems and Control (eess.SY)",
    "Systems and Control (cs.SY)",
    "Information Theory (math.IT)",
    "Information Theory (cs.IT)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Signal Processing (eess.SP)",
    "Physics and Society (physics.soc-ph)",
    "Combinatorics (math.CO)",
    "Information Retrieval (cs.IR)",
    "Logic (math.LO)",
    "Computation (stat.CO)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Image and Video Processing (eess.IV)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "High Energy Physics - Theory (hep-th)",
    "High Energy Physics - Lattice (hep-lat)",
    "Graphics (cs.GR)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Computational Physics (physics.comp-ph)",
    "Multimedia (cs.MM)",
    "Sound (cs.SD)",
    "Audio and Speech Processing (eess.AS)",
    "Functional Analysis (math.FA)",
    "Statistics Theory (stat.TH)",
    "Discrete Mathematics (cs.DM)",
    "Statistics Theory (math.ST)",
    "Programming Languages (cs.PL)",
    "Mathematical Software (cs.MS)",
    "Databases (cs.DB)",
    "Analysis of PDEs (math.AP)",
    "Emerging Technologies (cs.ET)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Dynamical Systems (math.DS)",
    "Populations and Evolution (q-bio.PE)",
    "Number Theory (math.NT)",
    "Quantum Physics (quant-ph)",
    "Mathematical Physics (math.MP)",
    "Mathematical Physics (math-ph)",
    "Rings and Algebras (math.RA)",
    "Algebraic Geometry (math.AG)",
    "Applications (stat.AP)",
    "Statistical Finance (q-fin.ST)",
    "General Economics (econ.GN)",
    "Economics (q-fin.EC)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Quantitative Methods (q-bio.QM)",
    "Biomolecules (q-bio.BM)",
    "Neurons and Cognition (q-bio.NC)",
    "Probability (math.PR)",
    "Commutative Algebra (math.AC)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Performance (cs.PF)",
    "Chaotic Dynamics (nlin.CD)",
    "Molecular Networks (q-bio.MN)",
    "Risk Management (q-fin.RM)",
    "Operating Systems (cs.OS)",
    "Tissues and Organs (q-bio.TO)",
    "Genomics (q-bio.GN)",
    "Computational Finance (q-fin.CP)",
    "Classical Physics (physics.class-ph)",
    "Algebraic Topology (math.AT)",
    "History and Overview (math.HO)",
    "Symbolic Computation (cs.SC)",
    "Geometric Topology (math.GT)",
    "Chemical Physics (physics.chem-ph)",
    "Metric Geometry (math.MG)",
    "Computational Geometry (cs.CG)",
    "Differential Geometry (math.DG)",
    "Optics (physics.optics)",
    "Econometrics (econ.EM)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Biological Physics (physics.bio-ph)",
    "Plasma Physics (physics.plasm-ph)",
    "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
    "General Topology (math.GN)",
    "Portfolio Management (q-fin.PM)",
    "Mathematical Finance (q-fin.MF)",
    "Spectral Theory (math.SP)",
    "Digital Libraries (cs.DL)",
    "Other Statistics (stat.OT)",
    "Classical Analysis and ODEs (math.CA)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "High Energy Physics - Experiment (hep-ex)",
    "Applied Physics (physics.app-ph)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to LLM performance. You are a computer science expert specializing in data engineering for large language model (LLM) training data. Your task is to analyze a set of arXiv papers and identify those that focus on processing LLM training data.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it makes a technical contribution to **LLM training data processing**. In particular, focus on papers that involve **training-data processing** , including but not limited to:\n\n1. **Data processing during pretraining or fine-tuning**\n   * Preparation of data for LLM pretraining, instruction tuning, supervised fine-tuning (SFT), alignment tuning, etc.\n2. **training-data processing**\n   * Common data engineering operations, including data collection, data generation, data deduplication, data filtering, etc.\n   * Any methods or techniques that significantly improve data quality.\n   * Creation of a new dataset **with clear, detailed data processing steps.**\n\n**Note:** Ignore papers that merely use existing training datasets for downstream tasks (e.g., QA, reasoning), propose new model architectures, or conduct evaluation benchmarks\u2014unless they also **substantively modify or process the training data itself**.\n\n---\n\n### **Relevance Level Classification**\n\n* **`core`**: The paper\u2019s primary contribution lies in processing or creating LLM training data, or in constructing a higher-quality dataset from existing data\u2014e.g., dataset creation, data generation or synthesis, pipeline design, filtering methods, or other data\u2011engineering operations that improve data quality.\n* **`partial`**: The paper briefly mentions training data or standard preprocessing (e.g., using a standard dataset or tokenization, it focuses on model architecture, tasks, evaluation, prompting methods) but does **not** focus primarily on data processing.\n* **`irrelevant`**: The paper does **not** discuss any aspect of LLM training data collection, processing, or engineering.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper ID>\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing the key part of the abstract or methodology that justifies your classification\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "partial": 203,
    "irrelevant": 1239,
    "core": 90
  },
  "arxiv_update_date": "2025-07-15",
  "updated_at": "2025-07-15 14:02:08"
}