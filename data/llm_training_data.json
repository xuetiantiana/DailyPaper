{
  "data": [
    {
      "id": "2507.08217",
      "abstract": "Quantum federated learning (QFL) has been recently introduced to enable a distributed privacy-preserving quantum machine learning (QML) model training across quantum processors (clients). Despite recent research efforts, existing QFL frameworks predominantly focus on unimodal systems, limiting their applicability to real-world tasks that often naturally involve multiple modalities. To fill this significant gap, we present for the first time a novel multimodal approach specifically tailored for the QFL setting with the intermediate fusion using quantum entanglement. Furthermore, to address a major bottleneck in multimodal QFL, where the absence of certain modalities during training can degrade model performance, we introduce a Missing Modality Agnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring stable training without corrupted states. Simulation results demonstrate that the proposed multimodal QFL method with MMA yields an improvement in accuracy of 6.84% in independent and identically distributed (IID) and 7.25% in non-IID data distributions compared to the state-of-the-art methods.",
      "authors": [
        "Atit Pokharel",
        "Ratun Rahman",
        "Thomas Morris and Dinh C. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:33:58+00:00",
          "link": "https://arxiv.org/abs/2507.08217v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08217",
        "HTML": "https://arxiv.org/html/2507.08217v1",
        "PDF": "https://arxiv.org/pdf/2507.08217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on quantum federated learning and multimodal approaches without specific focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08255",
      "abstract": "Missing data presents a critical challenge in real-world datasets, significantly degrading the performance of machine learning models. While Large Language Models (LLMs) have recently demonstrated remarkable capabilities in tabular data imputation, exemplified by frameworks like UnIMP, their reliance on classical embedding methods often limits their ability to capture complex, non-linear correlations, particularly in mixed-type data scenarios encompassing numerical, categorical, and textual features. This paper introduces Quantum-UnIMP, a novel framework that integrates shallow quantum circuits into an LLM-based imputation architecture. Our core innovation lies in replacing conventional classical input embeddings with quantum feature maps generated by an Instantaneous Quantum Polynomial (IQP) circuit. This approach enables the model to leverage quantum phenomena such as superposition and entanglement, thereby learning richer, more expressive representations of data and enhancing the recovery of intricate missingness patterns. Our experiments on benchmark mixed-type datasets demonstrate that Quantum-UnIMP reduces imputation error by up to 15.2% for numerical features (RMSE) and improves classification accuracy by 8.7% for categorical features (F1-Score) compared to state-of-the-art classical and LLM-based methods. These compelling results underscore the profound potential of quantum-enhanced representations for complex data imputation tasks, even with near-term quantum hardware.",
      "authors": [
        "Hossein Jamali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:00:06+00:00",
          "link": "https://arxiv.org/abs/2507.08255v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "Quantum-Accelerated Neural Imputation with Large Language Models (LLMs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08255",
        "HTML": "https://arxiv.org/html/2507.08255v1",
        "PDF": "https://arxiv.org/pdf/2507.08255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces Quantum-UnIMP for data imputation, which uses LLMs, its primary focus is on enhancing imputation with quantum features rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.17561",
      "abstract": "Deep learning, a branch of artificial intelligence, is a data-driven method that uses multiple layers of interconnected units or neurons to learn intricate patterns and representations directly from raw input data. Empowered by this learning capability, it has become a powerful tool for solving complex problems and is the core driver of many groundbreaking technologies and innovations. Building a deep learning model is challenging due to the algorithm's complexity and the dynamic nature of real-world problems. Several studies have reviewed deep learning concepts and applications. However, the studies mostly focused on the types of deep learning models and convolutional neural network architectures, offering limited coverage of the state-of-the-art deep learning models and their applications in solving complex problems across different domains. Therefore, motivated by the limitations, this study aims to comprehensively review the state-of-the-art deep learning models in computer vision, natural language processing, time series analysis and pervasive computing, and robotics. We highlight the key features of the models and their effectiveness in solving the problems within each domain. Furthermore, this study presents the fundamentals of deep learning, various deep learning model types and prominent convolutional neural network architectures. Finally, challenges and future directions in deep learning research are discussed to offer a broader perspective for future researchers.",
      "authors": [
        "Mohd Halim Mohd Noor and Ayokunle Olalekan Ige"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-26T10:10:53+00:00",
          "link": "https://arxiv.org/abs/2403.17561v1",
          "size": "1990kb",
          "version": "v1"
        },
        {
          "date": "2024-03-31T03:02:10+00:00",
          "link": "https://arxiv.org/abs/2403.17561v2",
          "size": "1990kb",
          "version": "v2"
        },
        {
          "date": "2024-05-16T12:00:29+00:00",
          "link": "https://arxiv.org/abs/2403.17561v3",
          "size": "1932kb",
          "version": "v3"
        },
        {
          "date": "2024-09-14T01:58:17+00:00",
          "link": "https://arxiv.org/abs/2403.17561v4",
          "size": "1951kb",
          "version": "v4"
        },
        {
          "date": "2024-11-15T14:30:43+00:00",
          "link": "https://arxiv.org/abs/2403.17561v5",
          "size": "1879kb",
          "version": "v5"
        },
        {
          "date": "2025-03-16T03:23:46+00:00",
          "link": "https://arxiv.org/abs/2403.17561v6",
          "size": "2020kb",
          "version": "v6"
        },
        {
          "date": "2025-05-18T05:07:11+00:00",
          "link": "https://arxiv.org/abs/2403.17561v7",
          "size": "2020kb",
          "version": "v7"
        },
        {
          "date": "2025-07-11T01:15:31+00:00",
          "link": "https://arxiv.org/abs/2403.17561v8",
          "size": "2020kb",
          "version": "v8"
        }
      ],
      "title": "A Survey on State-of-the-art Deep Learning Applications and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17561",
        "HTML": "https://arxiv.org/html/2403.17561",
        "PDF": "https://arxiv.org/pdf/2403.17561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey reviews deep learning applications and challenges, focusing on models and architectures rather than training data collection or processing for LLMs."
      },
      "tasks": [
        "Deep Learning",
        "Time Series Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08701",
      "abstract": "There is an imperative need to provide quality of life to a growing population of older adults living independently. Personalised solutions that focus on the person and take into consideration their preferences and context are key. In this work, we introduce a framework for representing and reasoning about the Activities of Daily Living of older adults living independently at home. The framework integrates data from sensors and contextual information that aggregates semi-structured interviews, home layouts and sociological observations from the participants. We use these data to create formal models, personalised for each participant according to their preferences and context. We formulate requirements that are specific to each individual as properties encoded in Linear Temporal Logic and use a model checker to verify whether each property is satisfied by the model. When a property is violated, a counterexample is generated giving the cause of the violation. We demonstrate the framework's generalisability by applying it to different participants, highlighting its potential to enhance the safety and well-being of older adults ageing in place.",
      "authors": [
        "Ricardo Contreras",
        "Filip Smola",
        "Nu\\v{s}a Fari\\v{c}",
        "Jiawei Zheng",
        "Jane Hillston and Jacques D. Fleuriot"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:53:15+00:00",
          "link": "https://arxiv.org/abs/2507.08701v1",
          "size": "2074kb",
          "version": "v1"
        }
      ],
      "title": "A Personalised Formal Verification Framework for Monitoring Activities of Daily Living of Older Adults Living Independently in Their Homes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08701",
        "HTML": "https://arxiv.org/html/2507.08701v1",
        "PDF": "https://arxiv.org/pdf/2507.08701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for monitoring activities of daily living of older adults, involving sensor data and personalized models, but does not focus on processing or generating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08743",
      "abstract": "Digital Twins (DT) have the potential to transform traffic management and operations by creating dynamic, virtual representations of transportation systems that sense conditions, analyze operations, and support decision-making. A key component for DT of the transportation system is dynamic roadway geometry sensing. However, existing approaches often rely on static maps or costly sensors, limiting scalability and adaptability. Additionally, large-scale DTs that collect and analyze data from multiple sources face challenges in privacy, communication, and computational efficiency. To address these challenges, we introduce Geo-ORBIT (Geometrical Operational Roadway Blueprint with Integrated Twin), a unified framework that combines real-time lane detection, DT synchronization, and federated meta-learning. At the core of Geo-ORBIT is GeoLane, a lightweight lane detection model that learns lane geometries from vehicle trajectory data using roadside cameras. We extend this model through Meta-GeoLane, which learns to personalize detection parameters for local entities, and FedMeta-GeoLane, a federated learning strategy that ensures scalable and privacy-preserving adaptation across roadside deployments. Our system is integrated with CARLA and SUMO to create a high-fidelity DT that renders highway scenarios and captures traffic flows in real-time. Extensive experiments across diverse urban scenes show that FedMeta-GeoLane consistently outperforms baseline and meta-learning approaches, achieving lower geometric error and stronger generalization to unseen locations while drastically reducing communication overhead. This work lays the foundation for flexible, context-aware infrastructure modeling in DTs. The framework is publicly available at https://github.com/raynbowy23/FedMeta-GeoLane.git.",
      "authors": [
        "Rei Tamaru",
        "Pei Li",
        "and Bin Ran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:45:59+00:00",
          "link": "https://arxiv.org/abs/2507.08743v1",
          "size": "11911kb",
          "version": "v1"
        }
      ],
      "title": "Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08743",
        "HTML": "https://arxiv.org/html/2507.08743v1",
        "PDF": "https://arxiv.org/pdf/2507.08743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the Geo-ORBIT framework for digital twins in transportation systems, focusing on lane geometry detection without relevant contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.17907",
      "abstract": "We propose Amortized Posterior Sampling (APS), a novel variational inference approach for efficient posterior sampling in inverse problems. Our method trains a conditional flow model to minimize the divergence between the variational distribution and the posterior distribution implicitly defined by the diffusion model. This results in a powerful, amortized sampler capable of generating diverse posterior samples with a single neural function evaluation, generalizing across various measurements. Unlike existing methods, our approach is unsupervised, requires no paired training data, and is applicable to both Euclidean and non-Euclidean domains. We demonstrate its effectiveness on a range of tasks, including image restoration, manifold signal reconstruction, and climate data imputation. APS significantly outperforms existing approaches in computational efficiency while maintaining competitive reconstruction quality, enabling real-time, high-quality solutions to inverse problems across diverse domains.",
      "authors": [
        "Abbas Mammadov",
        "Hyungjin Chung",
        "Jong Chul Ye"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-25T09:53:12+00:00",
          "link": "https://arxiv.org/abs/2407.17907v1",
          "size": "19980kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T04:01:19+00:00",
          "link": "https://arxiv.org/abs/2407.17907v2",
          "size": "29816kb",
          "version": "v2"
        }
      ],
      "title": "Amortized Posterior Sampling with Diffusion Prior Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17907",
        "HTML": "https://arxiv.org/html/2407.17907v2",
        "PDF": "https://arxiv.org/pdf/2407.17907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a posterior sampling technique for inverse problems and does not involve processing or engineering LLM training data."
      },
      "tasks": [
        "Variational Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15286",
      "abstract": "Automatic counting soybean pods and seeds in outdoor fields allows for rapid yield estimation before harvesting, while indoor laboratory counting offers greater accuracy. Both methods can significantly accelerate the breeding process. However, it remains challenging for accurately counting pods and seeds in outdoor fields, and there are still no accurate enough tools for counting pods and seeds in laboratories. In this study, we developed efficient deep learning models for counting soybean pods and seeds in both outdoor fields and indoor laboratories. For outdoor fields, annotating not only visible seeds but also occluded seeds makes YOLO have the ability to estimate the number of soybean seeds that are occluded. Moreover, we enhanced YOLO architecture by integrating it with HQ-SAM (YOLO-SAM), and domain adaptation techniques (YOLO-DA), to improve model robustness and generalization across soybean images taken in outdoor fields. Testing on soybean images from the outdoor field, we achieved a mean absolute error (MAE) of 6.13 for pod counting and 10.05 for seed counting. For the indoor setting, we utilized Mask-RCNN supplemented with a Swin Transformer module (Mask-RCNN-Swin), models were trained exclusively on synthetic training images generated from a small set of labeled data. This approach resulted in near-perfect accuracy, with an MAE of 1.07 for pod counting and 1.33 for seed counting across actual laboratory images from two distinct studies.",
      "authors": [
        "Tianyou Jiang",
        "Mingshun Shao",
        "Tianyi Zhang",
        "Xiaoyu Liu",
        "Qun Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T08:26:42+00:00",
          "link": "https://arxiv.org/abs/2502.15286v1",
          "size": "998kb",
          "version": "v1"
        }
      ],
      "title": "Soybean pod and seed counting in both outdoor fields and indoor laboratories using unions of deep neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15286",
        "PDF": "https://arxiv.org/pdf/2502.15286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops deep learning models for counting soybean pods and seeds, which is unrelated to LLM training data processing or engineering for language models."
      },
      "tasks": [
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08473",
      "abstract": "Sparse autoencoders (SAEs) and transcoders have become important tools for machine learning interpretability. However, measuring how interpretable they are remains challenging, with weak consensus about which benchmarks to use. Most evaluation procedures start by producing a single-sentence explanation for each latent. These explanations are then evaluated based on how well they enable an LLM to predict the activation of a latent in new contexts. This method makes it difficult to disentangle the explanation generation and evaluation process from the actual interpretability of the latents discovered. In this work, we adapt existing methods to assess the interpretability of sparse coders, with the advantage that they do not require generating natural language explanations as an intermediate step. This enables a more direct and potentially standardized assessment of interpretability. Furthermore, we compare the scores produced by our interpretability metrics with human evaluations across similar tasks and varying setups, offering suggestions for the community on improving the evaluation of these techniques.",
      "authors": [
        "Gon\\c{c}alo Paulo",
        "Nora Belrose"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:31:53+00:00",
          "link": "https://arxiv.org/abs/2507.08473v1",
          "size": "794kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating SAE interpretability without explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08473",
        "HTML": "https://arxiv.org/html/2507.08473v1",
        "PDF": "https://arxiv.org/pdf/2507.08473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the interpretability of sparse autoencoders and transcoders, with no mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08423",
      "abstract": "Facial recognition systems have achieved remarkable success by leveraging deep neural networks, advanced loss functions, and large-scale datasets. However, their performance often deteriorates in real-world scenarios involving low-quality facial images. Such degradations, common in surveillance footage or standoff imaging include low resolution, motion blur, and various distortions, resulting in a substantial domain gap from the high-quality data typically used during training. While existing approaches attempt to address robustness by modifying network architectures or modeling global spatial transformations, they frequently overlook local, non-rigid deformations that are inherently present in real-world settings. In this work, we introduce \\textbf{DArFace}, a \\textbf{D}eformation-\\textbf{A}ware \\textbf{r}obust \\textbf{Face} recognition framework that enhances robustness to such degradations without requiring paired high- and low-quality training samples. Our method adversarially integrates both global transformations (e.g., rotation, translation) and local elastic deformations during training to simulate realistic low-quality conditions. Moreover, we introduce a contrastive objective to enforce identity consistency across different deformed views. Extensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and IJB-C demonstrate that DArFace surpasses state-of-the-art methods, with significant gains attributed to the inclusion of local deformation modeling.",
      "authors": [
        "Sadaf Gulshad and Abdullah Aldahlawi Thakaa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T10:35:57+00:00",
          "link": "https://arxiv.org/abs/2505.08423v1",
          "size": "1124kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:25:11+00:00",
          "link": "https://arxiv.org/abs/2505.08423v2",
          "size": "1124kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T08:31:38+00:00",
          "link": "https://arxiv.org/abs/2505.08423v3",
          "size": "1124kb",
          "version": "v3"
        }
      ],
      "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08423",
        "HTML": "https://arxiv.org/html/2505.08423v3",
        "PDF": "https://arxiv.org/pdf/2505.08423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework to improve facial recognition robustness through deformation modeling, not dealing with LLM training data processing."
      },
      "tasks": [
        "Face Recognition",
        "Robust Face Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.06489",
      "abstract": "What features neural networks learn, and how, remains an open question. In this paper, we introduce Alternating Gradient Flows (AGF), an algorithmic framework that describes the dynamics of feature learning in two-layer networks trained from small initialization. Prior works have shown that gradient flow in this regime exhibits a staircase-like loss curve, alternating between plateaus where neurons slowly align to useful directions and sharp drops where neurons rapidly grow in norm. AGF approximates this behavior as an alternating two-step process: maximizing a utility function over dormant neurons and minimizing a cost function over active ones. AGF begins with all neurons dormant. At each round, a dormant neuron activates, triggering the acquisition of a feature and a drop in the loss. AGF quantifies the order, timing, and magnitude of these drops, matching experiments across architectures. We show that AGF unifies and extends existing saddle-to-saddle analyses in fully connected linear networks and attention-only linear transformers, where the learned features are singular modes and principal components, respectively. In diagonal linear networks, we prove AGF converges to gradient flow in the limit of vanishing initialization. Applying AGF to quadratic networks trained to perform modular addition, we give the first complete characterization of the training dynamics, revealing that networks learn Fourier features in decreasing order of coefficient magnitude. Altogether, AGF offers a promising step towards understanding feature learning in neural networks.",
      "authors": [
        "Daniel Kunin",
        "Giovanni Luca Marchetti",
        "Feng Chen",
        "Dhruva Karkada",
        "James B. Simon",
        "Michael R. DeWeese",
        "Surya Ganguli",
        "Nina Miolane"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T19:29:13+00:00",
          "link": "https://arxiv.org/abs/2506.06489v1",
          "size": "2455kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:26:05+00:00",
          "link": "https://arxiv.org/abs/2506.06489v2",
          "size": "1609kb",
          "version": "v2"
        }
      ],
      "title": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06489",
        "HTML": "https://arxiv.org/html/2506.06489v2",
        "PDF": "https://arxiv.org/pdf/2506.06489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the dynamics of feature learning in neural networks and does not discuss training data processing or enhancement specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07633",
      "abstract": "Recent advances in video generation techniques have given rise to an emerging paradigm of generative video coding, aiming to achieve semantically accurate reconstructions in Ultra-Low Bitrate (ULB) scenarios by leveraging strong generative priors. However, most existing methods are limited by domain specificity (e.g., facial or human videos) or an excessive dependence on high-level text guidance, which often fails to capture motion details and results in unrealistic reconstructions. To address these challenges, we propose a Trajectory-Guided Generative Video Coding framework (dubbed T-GVC). T-GVC employs a semantic-aware sparse motion sampling pipeline to effectively bridge low-level motion tracking with high-level semantic understanding by extracting pixel-wise motion as sparse trajectory points based on their semantic importance, not only significantly reducing the bitrate but also preserving critical temporal semantic information. In addition, by incorporating trajectory-aligned loss constraints into diffusion processes, we introduce a training-free latent space guidance mechanism to ensure physically plausible motion patterns without sacrificing the inherent capabilities of generative models. Experimental results demonstrate that our framework outperforms both traditional codecs and state-of-the-art end-to-end video compression methods under ULB conditions. Furthermore, additional experiments confirm that our approach achieves more precise motion control than existing text-guided methods, paving the way for a novel direction of generative video coding guided by geometric motion modeling.",
      "authors": [
        "Zhitao Wang",
        "Hengyu Man",
        "Wenrui Li",
        "Xingtao Wang",
        "Xiaopeng Fan",
        "Debin Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.07633v1",
          "size": "8953kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:42:15+00:00",
          "link": "https://arxiv.org/abs/2507.07633v2",
          "size": "8953kb",
          "version": "v2"
        }
      ],
      "title": "T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07633",
        "HTML": "https://arxiv.org/html/2507.07633v2",
        "PDF": "https://arxiv.org/pdf/2507.07633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for generative video coding and motion tracking in video compression, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06292",
      "abstract": "Joint optimization of poses and features has been extensively studied and demonstrated to yield more accurate results in feature-based SLAM problems. However, research on jointly optimizing poses and non-feature-based maps remains limited. Occupancy maps are widely used non-feature-based environment representations because they effectively classify spaces into obstacles, free areas, and unknown regions, providing robots with spatial information for various tasks. In this paper, we propose Occupancy-SLAM, a novel optimization-based SLAM method that enables the joint optimization of robot trajectory and the occupancy map through a parameterized map representation. The key novelty lies in optimizing both robot poses and occupancy values at different cell vertices simultaneously, a significant departure from existing methods where the robot poses need to be optimized first before the map can be estimated. Evaluations using simulations and practical 2D laser datasets demonstrate that the proposed approach can robustly obtain more accurate robot trajectories and occupancy maps than state-of-the-art techniques with comparable computational time. Preliminary results in the 3D case further confirm the potential of the proposed method in practical 3D applications, achieving more accurate results than existing methods.",
      "authors": [
        "Yingyu Wang",
        "Liang Zhao",
        "Shoudong Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T09:33:18+00:00",
          "link": "https://arxiv.org/abs/2502.06292v1",
          "size": "20448kb",
          "version": "v1"
        },
        {
          "date": "2025-02-14T10:14:38+00:00",
          "link": "https://arxiv.org/abs/2502.06292v2",
          "size": "20448kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T06:07:15+00:00",
          "link": "https://arxiv.org/abs/2502.06292v3",
          "size": "19866kb",
          "version": "v3"
        }
      ],
      "title": "Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously Optimizing Robot Poses and Occupancy Map",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06292",
        "HTML": "https://arxiv.org/html/2502.06292",
        "PDF": "https://arxiv.org/pdf/2502.06292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Occupancy-SLAM proposes an optimization method for robot mapping, not related to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/WANGYINGYU/Occupancy-SLAM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09166",
      "abstract": "In the creative practice of text-to-image generation (TTI), images are generated from text prompts. However, TTI models are trained to always yield an output, even if the prompt contains unknown terms. In this case, the model may generate what we call \"default images\": images that closely resemble each other across many unrelated prompts. We argue studying default images is valuable for designing better solutions for TTI and prompt engineering. In this paper, we provide the first investigation into default images on Midjourney, a popular image generator. We describe our systematic approach to create input prompts triggering default images, and present the results of our initial experiments and several small-scale ablation studies. We also report on a survey study investigating how default images affect user satisfaction. Our work lays the foundation for understanding default images in TTI and highlights challenges and future research directions.",
      "authors": [
        "Hannu Simonen",
        "Atte Kiviniemi",
        "Jonas Oppenlaender"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T05:59:23+00:00",
          "link": "https://arxiv.org/abs/2505.09166v1",
          "size": "21659kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T13:02:43+00:00",
          "link": "https://arxiv.org/abs/2505.09166v2",
          "size": "4316kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T10:01:02+00:00",
          "link": "https://arxiv.org/abs/2505.09166v3",
          "size": "4313kb",
          "version": "v3"
        }
      ],
      "title": "An Exploration of Default Images in Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09166",
        "HTML": "https://arxiv.org/html/2505.09166v3",
        "PDF": "https://arxiv.org/pdf/2505.09166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the phenomenon of default images in TTI models and prompt engineering, without addressing LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "Prompt Engineering",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08363",
      "abstract": "The stability of communities - whether biological, social, economic, technological or ecological depends on the balance between cooperation and cheating. While cooperation strengthens communities, selfish individuals, or \"cheaters,\" exploit collective benefits without contributing. If cheaters become too prevalent, they can trigger the collapse of cooperation and of the community, often in an abrupt manner. A key challenge is determining whether the risk of such a collapse can be detected in advance. To address this, we use a combination of evolutionary graph theory and machine learning to examine how one can predict the unravel of cooperation on complex networks. By introducing few cheaters into a structured population, we employ machine learning to detect and anticipate the spreading of cheaters and cooperation collapse. Using temporal and structural data, the presented results show that prediction accuracy improves with stronger selection strength and larger observation windows, with CNN-Seq-LSTM and Seq-LSTM best performing models. Moreover, the accuracy for the predictions depends crucially on the type of game played between cooperators and cheaters (i.e., accuracy improves when it is more advantageous to defect) and on the community structure. Overall, this work introduces a machine learning approach into detecting abrupt shifts in evolutionary graph theory and offer potential strategies for anticipating and preventing cooperation collapse in complex social networks.",
      "authors": [
        "Guoli Yang",
        "Matteo Cavaliere",
        "Mingtao Zhang",
        "Giovanni Masala",
        "Adam Miles",
        "Mengzhu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:26:00+00:00",
          "link": "https://arxiv.org/abs/2507.08363v1",
          "size": "3139kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning for Evolutionary Graph Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08363",
        "HTML": "https://arxiv.org/html/2507.08363v1",
        "PDF": "https://arxiv.org/pdf/2507.08363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It explores evolutionary graph theory using machine learning for predicting cooperation collapse, which is unrelated to processing or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08606",
      "abstract": "We introduce DocPolarBERT, a layout-aware BERT model for document understanding that eliminates the need for absolute 2D positional embeddings. We extend self-attention to take into account text block positions in relative polar coordinate system rather than the Cartesian one. Despite being pre-trained on a dataset more than six times smaller than the widely used IIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results demonstrate that a carefully designed attention mechanism can compensate for reduced pre-training data, offering an efficient and effective alternative for document understanding.",
      "authors": [
        "Benno Uthayasooriyar",
        "Antoine Ly",
        "Franck Vermet",
        "Caio Corro"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:00:56+00:00",
          "link": "https://arxiv.org/abs/2507.08606v1",
          "size": "813kb",
          "version": "v1"
        }
      ],
      "title": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08606",
        "HTML": "https://arxiv.org/html/2507.08606v1",
        "PDF": "https://arxiv.org/pdf/2507.08606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses pre-training DocPolarBERT, it focuses primarily on model architecture and attention mechanisms rather than on detailed training data processing or datasets creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.14407",
      "abstract": "High-dimensional planted problems, such as finding a hidden dense subgraph within a random graph, often exhibit a gap between statistical and computational feasibility. While recovering the hidden structure may be statistically possible, it is conjectured to be computationally intractable in certain parameter regimes. A powerful approach to understanding this hardness involves proving lower bounds on the efficacy of low-degree polynomial algorithms. We introduce new techniques for establishing such lower bounds, leading to novel results across diverse settings: planted submatrix, planted dense subgraph, the spiked Wigner model, and the stochastic block model. Notably, our results address the estimation task -- whereas most prior work is limited to hypothesis testing -- and capture sharp phase transitions such as the \"BBP\" transition in the spiked Wigner model (named for Baik, Ben Arous, and P\\'{e}ch\\'{e}) and the Kesten-Stigum threshold in the stochastic block model. Existing work on estimation either falls short of achieving these sharp thresholds or is limited to polynomials of very low (constant or logarithmic) degree. In contrast, our results rule out estimation with polynomials of degree $n^{\\delta}$ where $n$ is the dimension and $\\delta > 0$ is a constant, and in some cases we pin down the optimal constant $\\delta$. Our work resolves open problems posed by Hopkins & Steurer (2017) and Schramm & Wein (2022), and provides rigorous support within the low-degree framework for conjectures by Abbe & Sandon (2018) and Lelarge & Miolane (2019).",
      "authors": [
        "Youngtak Sohn",
        "Alexander S. Wein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)",
        "Probability (math.PR)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T09:48:26+00:00",
          "link": "https://arxiv.org/abs/2502.14407v1",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:46:37+00:00",
          "link": "https://arxiv.org/abs/2502.14407v2",
          "size": "77kb",
          "version": "v2"
        }
      ],
      "title": "Sharp Phase Transitions in Estimation with Low-Degree Polynomials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14407",
        "HTML": "https://arxiv.org/html/2502.14407v2",
        "PDF": "https://arxiv.org/pdf/2502.14407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computational feasibility of high-dimensional estimation problems, specifically lower bounds on polynomial algorithms, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13792",
      "abstract": "Quantization is widely applied in machine learning to reduce computational and storage costs for both data and models. Considering that classification tasks are fundamental to the field, it is crucial to investigate how quantization impacts classification performance. Traditional research has focused on quantization errors, assuming that larger errors generally lead to lower classification accuracy. However, this assumption lacks a solid theoretical foundation and often contradicts empirical observations. For example, despite introducing significant errors, $\\{0,1\\}$-binary and $\\{0, \\pm1\\}$-ternary quantized data have sometimes achieved classification accuracy comparable or even superior to full-precision data. To reasonably explain this phenomenon, a more accurate evaluation of classification performance is required. To achieve this, we propose a direct analysis of the feature discrimination of quantized data, instead of focusing on quantization errors. Our analysis reveals that both binary and ternary quantization can potentially enhance, rather than degrade, the feature discrimination of the original data. This finding is supported by classification experiments conducted on both synthetic and real data.",
      "authors": [
        "Weizhi Lu",
        "Mingrui Chen",
        "Weiyu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T16:44:12+00:00",
          "link": "https://arxiv.org/abs/2504.13792v1",
          "size": "4664kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:23:54+00:00",
          "link": "https://arxiv.org/abs/2504.13792v2",
          "size": "3056kb",
          "version": "v2"
        }
      ],
      "title": "Binary and Ternary Quantization Can Enhance Feature Discrimination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13792",
        "HTML": "https://arxiv.org/html/2504.13792v2",
        "PDF": "https://arxiv.org/pdf/2504.13792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While quantization impacts data processing, this paper primarily investigates the effects of quantization on feature discrimination of data, not specifically LLM training data processing techniques."
      },
      "tasks": [
        "Classification",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08297",
      "abstract": "We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model developed to address the overthinking problem in reasoning-intensive tasks, where an automatic thinking training paradigm is proposed to dynamically switch between reasoning and non-reasoning modes based on task complexity. Specifically, first, we construct the dual-regime dataset based on a novel tagging pipeline and a multi-agent synthesis strategy, and then we apply Multi-Token Prediction (MTP)-enhanced knowledge distillation, enabling efficient and fine-grained reasoning transfer with minimal pretraining cost. Besides, we implement a cold-start initialization strategy that introduces mode-selection priors using majority-vote signals and intent-aware prompting. Finally, we propose Step-SRPO, a reinforcement learning algorithm that incorporates intermediate supervision into the GRPO framework, offering structured guidance over both reasoning-mode selection and response accuracy. Extensive experiments across multiple benchmarks demonstrate that KAT consistently matches or even outperforms current state-of-the-art models, including DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of reasoning-intensive tasks while reducing token usage by up to approximately 30\\%. Beyond academic evaluation, KAT has been successfully deployed in Kwaipilot (i.e., Kuaishou's internal coding assistant), and improves real-world development workflows with high accuracy, efficiency, and controllable reasoning behaviors. Moreover, we are actively training a 200B Mixture-of-Experts (MoE) with 40B activation parameters, where the early-stage results already demonstrate promising improvements in performance and efficiency, further showing the scalability of the AutoThink paradigm.",
      "authors": [
        "Zizheng Zhan",
        "Ken Deng",
        "Huaixi Tang",
        "Wen Xiang",
        "Kun Wu",
        "Weihao Li",
        "Wenqiang Zhu",
        "Jingxuan Xu",
        "Lecheng Huang",
        "Zongxian Feng",
        "Shaojie Wang",
        "Shangpeng Yan",
        "Jiaheng Liu",
        "Zhongyuan Peng",
        "Zuchen Gao",
        "Haoyang Huang",
        "Ziqi Zhan",
        "Yanan Wu",
        "Yuanxing Zhang",
        "Jian Yang",
        "Guang Chen",
        "Haotian Zhang",
        "Bin Chen",
        "Bing Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:07:10+00:00",
          "link": "https://arxiv.org/abs/2507.08297v1",
          "size": "14313kb",
          "version": "v1"
        }
      ],
      "title": "KAT-V1: Kwai-AutoThink Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08297",
        "HTML": "https://arxiv.org/html/2507.08297v1",
        "PDF": "https://arxiv.org/pdf/2507.08297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the construction of a dual-regime dataset and a novel tagging pipeline for a large language model, which constitutes significant processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08400",
      "abstract": "This work presents PanMatch, a versatile foundation model for robust correspondence matching. Unlike previous methods that rely on task-specific architectures and domain-specific fine-tuning to support tasks like stereo matching, optical flow or feature matching, our key insight is that any two-frame correspondence matching task can be addressed within a 2D displacement estimation framework using the same model weights. Such a formulation eliminates the need for designing specialized unified architectures or task-specific ensemble models. Instead, it achieves multi-task integration by endowing displacement estimation algorithms with unprecedented generalization capabilities. To this end, we highlight the importance of a robust feature extractor applicable across multiple domains and tasks, and propose the feature transformation pipeline that leverage all-purpose features from Large Vision Models to endow matching baselines with zero-shot cross-view matching capabilities. Furthermore, we assemble a cross-domain dataset with near 1.8 million samples from stereo matching, optical flow, and feature matching domains to pretrain PanMatch. We demonstrate the versatility of PanMatch across a wide range of domains and downstream tasks using the same model weights. Our model outperforms UniMatch and Flow-Anything on cross-task evaluations, and achieves comparable performance to most state-of-the-art task-specific algorithms on task-oriented benchmarks. Additionally, PanMatch presents unprecedented zero-shot performance in abnormal scenarios, such as rainy day and satellite imagery, where most existing robust algorithms fail to yield meaningful results.",
      "authors": [
        "Yongjian Zhang",
        "Longguang Wang",
        "Kunhong Li",
        "Ye Zhang",
        "Yun Wang",
        "Liang Lin",
        "Yulan Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:18:52+00:00",
          "link": "https://arxiv.org/abs/2507.08400v1",
          "size": "14943kb",
          "version": "v1"
        }
      ],
      "title": "PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08400",
        "HTML": "https://arxiv.org/html/2507.08400v1",
        "PDF": "https://arxiv.org/pdf/2507.08400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces PanMatch, a model for correspondence matching using cross-domain datasets, it mainly focuses on model formulation and application, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08597",
      "abstract": "Machine learning models are commonly used for malware classification; however, they suffer from performance degradation over time due to concept drift. Adapting these models to changing data distributions requires frequent updates, which rely on costly ground truth annotations. While active learning can reduce the annotation burden, leveraging unlabeled data through semi-supervised learning remains a relatively underexplored approach in the context of malware detection. In this research, we introduce \\texttt{ADAPT}, a novel pseudo-labeling semi-supervised algorithm for addressing concept drift. Our model-agnostic method can be applied to various machine learning models, including neural networks and tree-based algorithms. We conduct extensive experiments on five diverse malware detection datasets spanning Android, Windows, and PDF domains. The results demonstrate that our method consistently outperforms baseline models and competitive benchmarks. This work paves the way for more effective adaptation of machine learning models to concept drift in malware detection.",
      "authors": [
        "Md Tanvirul Alam",
        "Aritran Piplai",
        "Nidhi Rastogi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:47:07+00:00",
          "link": "https://arxiv.org/abs/2507.08597v1",
          "size": "5248kb",
          "version": "v1"
        }
      ],
      "title": "ADAPT: A Pseudo-labeling Approach to Combat Concept Drift in Malware Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08597",
        "HTML": "https://arxiv.org/html/2507.08597v1",
        "PDF": "https://arxiv.org/pdf/2507.08597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is primarily concerned with malware detection using a pseudo-labeling approach to address concept drift, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07469",
      "abstract": "We introduce Galerkin-ARIMA, a novel time-series forecasting framework that integrates Galerkin projection techniques with the classical ARIMA model to capture potentially nonlinear dependencies in lagged observations. By replacing the fixed linear autoregressive component with a spline-based basis expansion, Galerkin-ARIMA flexibly approximates the underlying relationship among past values via ordinary least squares, while retaining the moving-average structure and Gaussian innovation assumptions of ARIMA. We derive closed-form solutions for both the AR and MA components using two-stage Galerkin projections, establish conditions for asymptotic unbiasedness and consistency, and analyze the bias-variance trade-off under basis-size growth. Complexity analysis reveals that, for moderate basis dimensions, our approach can substantially reduce computational cost compared to maximum-likelihood ARIMA estimation. Through extensive simulations on four synthetic processes-including noisy ARMA, seasonal, trend-AR, and nonlinear recursion series-we demonstrate that Galerkin-ARIMA matches or closely approximates ARIMA's forecasting accuracy while achieving orders-of-magnitude speedups in rolling forecasting tasks. These results suggest that Galerkin-ARIMA offers a powerful, efficient alternative for modeling complex time series dynamics in high-volume or real-time applications.",
      "authors": [
        "Haojie Liu",
        "Zihan Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:53:18+00:00",
          "link": "https://arxiv.org/abs/2507.07469v1",
          "size": "1768kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T06:27:42+00:00",
          "link": "https://arxiv.org/abs/2507.07469v2",
          "size": "1769kb",
          "version": "v2"
        }
      ],
      "title": "Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07469",
        "HTML": "https://arxiv.org/html/2507.07469v2",
        "PDF": "https://arxiv.org/pdf/2507.07469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Galerkin-ARIMA for time-series forecasting and does not discuss any aspects related to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08202",
      "abstract": "Quantum neural networks (QNN) hold immense potential for the future of quantum machine learning (QML). However, QNN security and robustness remain largely unexplored. In this work, we proposed novel Trojan attacks based on the quantum computing properties in a QNN-based binary classifier. Our proposed Quantum Properties Trojans (QuPTs) are based on the unitary property of quantum gates to insert noise and Hadamard gates to enable superposition to develop Trojans and attack QNNs. We showed that the proposed QuPTs are significantly stealthier and heavily impact the quantum circuits' performance, specifically QNNs. The most impactful QuPT caused a deterioration of 23% accuracy of the compromised QNN under the experimental setup. To the best of our knowledge, this is the first work on the Trojan attack on a fully quantum neural network independent of any hybrid classical-quantum architecture.",
      "authors": [
        "Sounak Bhowmik",
        "Travis S. Humble",
        "Himanshu Thapliyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:23:30+00:00",
          "link": "https://arxiv.org/abs/2507.08202v1",
          "size": "1061kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08202",
        "HTML": "https://arxiv.org/html/2507.08202v1",
        "PDF": "https://arxiv.org/pdf/2507.08202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses security concerns in quantum neural networks, specifically focusing on Trojan attacks, without any mention of data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.07835",
      "abstract": "This work focuses on sequential locally recoverable codes (SLRCs), a special family of locally repairable codes, capable of correcting multiple code symbol erasures, which are commonly used for distributed storage systems. First, we construct an extended $q$-ary family of non-binary SLRCs using code products with a novel maximum number of recoverable erasures $t$ and a minimal repair alternativity $A$. Second, we study how MDS and BCH codes can be used to construct $q$-ary SLRCs. Finally, we compare our codes to other LRCs.",
      "authors": [
        "Akram Baghban",
        "Marc Newman",
        "Anna-Lena Horlemann",
        "Mehdi Ghiyasvand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-15T17:02:15+00:00",
          "link": "https://arxiv.org/abs/2401.07835v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:54:39+00:00",
          "link": "https://arxiv.org/abs/2401.07835v2",
          "size": "97kb",
          "version": "v2"
        }
      ],
      "title": "$q$-ary Sequential Locally Recoverable Codes from the Product Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.07835",
        "HTML": "https://arxiv.org/html/2401.07835v2",
        "PDF": "https://arxiv.org/pdf/2401.07835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on erasure correction in distributed storage systems with sequential locally recoverable codes, not on any aspect related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02857",
      "abstract": "We present a novel approach to reconstruct gas and dark matter projected density maps of galaxy clusters using score-based generative modeling. Our diffusion model takes in mock SZ and X-ray images as conditional inputs, and generates realizations of corresponding gas and dark matter maps by sampling from a learned data posterior. We train and validate the performance of our model by using mock data from a cosmological simulation. The model accurately reconstructs both the mean and spread of the radial density profiles in the spatial domain, indicating that the model is able to distinguish between clusters of different mass sizes. In the spectral domain, the model achieves close-to-unity values for the bias and cross-correlation coefficients, indicating that the model can accurately probe cluster structures on both large and small scales. Our experiments demonstrate the ability of score models to learn a strong, nonlinear, and unbiased mapping between input observables and fundamental density distributions of galaxy clusters. These diffusion models can be further fine-tuned and generalized to not only take in additional observables as inputs, but also real observations and predict unknown density distributions of galaxy clusters.",
      "authors": [
        "Alan Hsu",
        "Matthew Ho",
        "Joyce Lin",
        "Carleen Markey",
        "Michelle Ntampaka",
        "Hy Trac",
        "Barnab\\'as P\\'oczos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T18:00:03+00:00",
          "link": "https://arxiv.org/abs/2410.02857v1",
          "size": "2337kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T21:03:29+00:00",
          "link": "https://arxiv.org/abs/2410.02857v2",
          "size": "2994kb",
          "version": "v2"
        }
      ],
      "title": "Reconstructing Galaxy Cluster Mass Maps using Score-based Generative Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02857",
        "HTML": "https://arxiv.org/html/2410.02857v2",
        "PDF": "https://arxiv.org/pdf/2410.02857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents score-based generative modeling for reconstructing galaxy cluster maps, focusing on cosmological simulations; it does not address LLM training data processing."
      },
      "tasks": [
        "Unity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08303",
      "abstract": "Humanoid robots show significant potential in daily tasks. However, reinforcement learning-based motion policies often suffer from robustness degradation due to the sim-to-real dynamics gap, thereby affecting the agility of real robots. In this work, we propose a novel robust adversarial training paradigm designed to enhance the robustness of humanoid motion policies in real worlds. The paradigm introduces a learnable adversarial attack network that precisely identifies vulnerabilities in motion policies and applies targeted perturbations, forcing the motion policy to enhance its robustness against perturbations through dynamic adversarial training. We conduct experiments on the Unitree G1 humanoid robot for both perceptive locomotion and whole-body control tasks. The results demonstrate that our proposed method significantly enhances the robot's motion robustness in real world environments, enabling successful traversal of challenging terrains and highly agile whole-body trajectory tracking.",
      "authors": [
        "Yang Zhang",
        "Zhanxiang Cao",
        "Buqing Nie",
        "Haoyang Li and Yue Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:32:07+00:00",
          "link": "https://arxiv.org/abs/2507.08303v1",
          "size": "7236kb",
          "version": "v1"
        }
      ],
      "title": "Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08303",
        "HTML": "https://arxiv.org/html/2507.08303v1",
        "PDF": "https://arxiv.org/pdf/2507.08303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial training for humanoid robots, not on LLM training data processing or improvements in data quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08472",
      "abstract": "Optimizers play a decisive role in reducing pre-training times for LLMs and achieving better-performing models. In this study, we compare three major variants: the de-facto standard AdamW, the simpler Lion, developed through an evolutionary search, and the second-order optimizer Sophia. For better generalization, we train with two different base architectures and use a single- and a multiple-epoch approach while keeping the number of tokens constant. Using the Maximal Update Parametrization and smaller proxy models, we tune relevant hyperparameters separately for each combination of base architecture and optimizer. We found that while the results from all three optimizers were in approximately the same range, Sophia exhibited the lowest training and validation loss, Lion was fastest in terms of training GPU hours but AdamW led to the best downstream evaluation results.",
      "authors": [
        "Joel Schlotthauer",
        "Christian Kroos",
        "Chris Hinze",
        "Viktor Hangya",
        "Luzian Hahn",
        "Fabian K\\\"uch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:29:04+00:00",
          "link": "https://arxiv.org/abs/2507.08472v1",
          "size": "1989kb",
          "version": "v1"
        }
      ],
      "title": "Pre-Training LLMs on a budget: A comparison of three optimizers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08472",
        "HTML": "https://arxiv.org/html/2507.08472v1",
        "PDF": "https://arxiv.org/pdf/2507.08472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper compares optimizers for LLM pre-training efficiency but does not focus on data processing techniques or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08793",
      "abstract": "Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies that minimise the likelihood of rare and catastrophic constraint violations caused by an environment's inherent randomness. In general, risk-aversion leads to conservative exploration of the environment which typically results in converging to sub-optimal policies that fail to adequately maximise reward or, in some cases, fail to achieve the goal. In this paper, we propose an exploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic (ORAC), which constructs an exploratory policy by maximising a local upper confidence bound of the state-action reward value function whilst minimising a local lower confidence bound of the risk-averse state-action cost value function. Specifically, at each step, the weighting assigned to the cost value is increased or decreased if it exceeds or falls below the safety constraint value. This way the policy is encouraged to explore uncertain regions of the environment to discover high reward states whilst still satisfying the safety constraints. Our experimental results demonstrate that the ORAC approach prevents convergence to sub-optimal policies and improves significantly the reward-cost trade-off in various continuous control tasks such as Safety-Gymnasium and a complex building energy management environment CityLearn.",
      "authors": [
        "James McCarthy",
        "Radu Marinescu",
        "Elizabeth Daly",
        "Ivana Dusparic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:54:54+00:00",
          "link": "https://arxiv.org/abs/2507.08793v1",
          "size": "2225kb",
          "version": "v1"
        }
      ],
      "title": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08793",
        "HTML": "https://arxiv.org/html/2507.08793v1",
        "PDF": "https://arxiv.org/pdf/2507.08793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on risk-averse exploration in reinforcement learning, proposing a novel policy optimization approach. It does not tackle LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08311",
      "abstract": "Large language models have been widely adopted across different tasks, but their auto-regressive generation nature often leads to inefficient resource utilization during inference. While batching is commonly used to increase throughput, performance gains plateau beyond a certain batch size, especially with smaller models, a phenomenon that existing literature typically explains as a shift to the compute-bound regime. In this paper, through an in-depth GPU-level analysis, we reveal that large-batch inference remains memory-bound, with most GPU compute capabilities underutilized due to DRAM bandwidth saturation as the primary bottleneck. To address this, we propose a Batching Configuration Advisor (BCA) that optimizes memory allocation, reducing GPU memory requirements with minimal impact on throughput. The freed memory and underutilized GPU compute capabilities can then be leveraged by concurrent workloads. Specifically, we use model replication to improve serving throughput and GPU utilization. Our findings challenge conventional assumptions about LLM inference, offering new insights and practical strategies for improving resource utilization, particularly for smaller language models. The code is publicly available at https://github.com/FerranAgulloLopez/vLLMBatchingMemoryGap.",
      "authors": [
        "Pol G. Recasens",
        "Ferran Agullo",
        "Yue Zhu",
        "Chen Wang",
        "Eun Kyung Lee",
        "Olivier Tardieu",
        "Jordi Torres",
        "Josep Ll. Berral"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T11:21:35+00:00",
          "link": "https://arxiv.org/abs/2503.08311v1",
          "size": "1376kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:23:16+00:00",
          "link": "https://arxiv.org/abs/2503.08311v2",
          "size": "315kb",
          "version": "v2"
        }
      ],
      "title": "Mind the Memory Gap: Unveiling GPU Bottlenecks in Large-Batch LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08311",
        "HTML": "https://arxiv.org/html/2503.08311v2",
        "PDF": "https://arxiv.org/pdf/2503.08311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on optimizing GPU memory allocation for LLM inference, tackling resource utilization challenges, which do not relate to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.18397",
      "abstract": "A multi-agent AI system (MAS) is composed of multiple autonomous agents that interact, exchange information, and make decisions based on internal generative models. Recent advances in large language models and tool-using agents have made MAS increasingly practical in areas like scientific discovery and collaborative automation. However, key questions remain: When are MAS more effective than single-agent systems? What new safety risks arise from agent interactions? And how should we evaluate their reliability and structure? This paper outlines a formal framework for analyzing MAS, focusing on two core aspects: effectiveness and safety. We explore whether MAS truly improve robustness, adaptability, and performance, or merely repackage known techniques like ensemble learning. We also study how inter-agent dynamics may amplify or suppress system vulnerabilities. While MAS are relatively new to the signal processing community, we envision them as a powerful abstraction that extends classical tools like distributed estimation and sensor fusion to higher-level, policy-driven inference. Through experiments on data science automation, we highlight the potential of MAS to reshape how signal processing systems are designed and trusted.",
      "authors": [
        "Fangqiao Tian",
        "An Luo",
        "Jin Du",
        "Xun Xian",
        "Robert Specht",
        "Ganghua Wang",
        "Xuan Bi",
        "Jiawei Zhou",
        "Ashish Kundu",
        "Jayanth Srinivasa",
        "Charles Fleming",
        "Rui Zhang",
        "Zirui Liu",
        "Mingyi Hong",
        "Jie Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T22:05:19+00:00",
          "link": "https://arxiv.org/abs/2505.18397v1",
          "size": "566kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:11:24+00:00",
          "link": "https://arxiv.org/abs/2505.18397v2",
          "size": "611kb",
          "version": "v2"
        }
      ],
      "title": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18397",
        "PDF": "https://arxiv.org/pdf/2505.18397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses multi-agent AI systems and their effectiveness, without mentioning LLM training data processing or related data engineering techniques."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08121",
      "abstract": "Physics-informed neural networks have shown promise in solving partial differential equations (PDEs) by integrating physical constraints into neural network training, but their performance is sensitive to the sampling of points. Based on the impressive performance of quasi Monte-Carlo methods in high dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of random points directly from the domain. Theoretically, QRPINNs have been proven to have a better convergence rate than PINNs. Empirically, experiments demonstrate that QRPINNs significantly outperform PINNs and some representative adaptive sampling methods, especially in high-dimensional PDEs. Furthermore, combining QRPINNs with adaptive sampling can further improve the performance.",
      "authors": [
        "Tianchi Yu",
        "Ivan Oseledets"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:15:43+00:00",
          "link": "https://arxiv.org/abs/2507.08121v1",
          "size": "7652kb",
          "version": "v1"
        }
      ],
      "title": "Quasi-Random Physics-informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08121",
        "HTML": "https://arxiv.org/html/2507.08121v1",
        "PDF": "https://arxiv.org/pdf/2507.08121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Quasi-Random Physics-Informed Neural Networks focusing on sampling methods for PDE solving rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08134",
      "abstract": "The rapid growth of Internet paths in heterogeneity, scale, and dynamics has made existing emulators increasingly insufficient in flexibility, scalability, and usability. To address these limitations, we present Rattan, an extensible and scalable software network path emulator for modern Internet conditions. Rattan's core innovation lies in its cell-based architecture: by splitting emulation functions into modular \"cells\" with well-documented asynchronous interfaces, users are allowed to easily compose different cells by hierarchically linking them and easily construct new cells by using standard cell interfaces. This design enables: (1) scalability, supporting hundreds of concurrent gigabit-level paths on a single machine and cluster-level experiments composed of multiple machines; (2) extensibility, simulating new network conditions by constructing new cells. Rattan empowers developers and researchers to efficiently and confidently evaluate, validate, and diagnose diverse network transport innovations for online services.",
      "authors": [
        "Minhu Wang",
        "Yixin Shen",
        "Bo Wang",
        "Haixuan Tong",
        "Yutong Xie",
        "Yixuan Gao",
        "Yan Liu",
        "Li Chen",
        "Mingwei Xu",
        "Jianping Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:55:25+00:00",
          "link": "https://arxiv.org/abs/2507.08134v1",
          "size": "2895kb",
          "version": "v1"
        }
      ],
      "title": "Rattan: An Extensible and Scalable Modular Internet Path Emulator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08134",
        "HTML": "https://arxiv.org/html/2507.08134v1",
        "PDF": "https://arxiv.org/pdf/2507.08134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on network emulation and does not address any aspect related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08499",
      "abstract": "This paper presents our system for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection (Track A), which focuses on multi-label emotion detection in short texts. We propose a feature-centric framework that dynamically adapts document representations and learning algorithms to optimize language-specific performance. Our study evaluates three key components: document representation, dimensionality reduction, and model training in 28 languages, highlighting five for detailed analysis. The results show that TF-IDF remains highly effective for low-resource languages, while contextual embeddings like FastText and transformer-based document representations, such as those produced by Sentence-BERT, exhibit language-specific strengths. Principal Component Analysis (PCA) reduces training time without compromising performance, particularly benefiting FastText and neural models such as Multi-Layer Perceptrons (MLP). Computational efficiency analysis underscores the trade-off between model complexity and processing cost. Our framework provides a scalable solution for multilingual emotion detection, addressing the challenges of linguistic diversity and resource constraints.",
      "authors": [
        "Ziyi Huang and Xia Cui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:21:18+00:00",
          "link": "https://arxiv.org/abs/2507.08499v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08499",
        "HTML": "https://arxiv.org/html/2507.08499v1",
        "PDF": "https://arxiv.org/pdf/2507.08499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses multi-emotion detection in multilingual texts and optimizes language-specific performance, but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.09626",
      "abstract": "Visual diffusion models achieve remarkable progress, yet they are typically trained at limited resolutions due to the lack of high-resolution data and constrained computation resources, hampering their ability to generate high-fidelity images or videos at higher resolutions. Recent efforts have explored tuning-free strategies to exhibit the untapped potential higher-resolution visual generation of pre-trained models. However, these methods are still prone to producing low-quality visual content with repetitive patterns. The key obstacle lies in the inevitable increase in high-frequency information when the model generates visual content exceeding its training resolution, leading to undesirable repetitive patterns deriving from the accumulated errors. To tackle this challenge, we propose FreeScale, a tuning-free inference paradigm to enable higher-resolution visual generation via scale fusion. Specifically, FreeScale processes information from different receptive scales and then fuses it by extracting desired frequency components. Extensive experiments validate the superiority of our paradigm in extending the capabilities of higher-resolution visual generation for both image and video models. Notably, compared with previous best-performing methods, FreeScale unlocks the 8k-resolution text-to-image generation for the first time.",
      "authors": [
        "Haonan Qiu",
        "Shiwei Zhang",
        "Yujie Wei",
        "Ruihang Chu",
        "Hangjie Yuan",
        "Xiang Wang",
        "Yingya Zhang",
        "Ziwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T18:59:59+00:00",
          "link": "https://arxiv.org/abs/2412.09626v1",
          "size": "17102kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:08:46+00:00",
          "link": "https://arxiv.org/abs/2412.09626v2",
          "size": "22219kb",
          "version": "v2"
        }
      ],
      "title": "FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09626",
        "HTML": "https://arxiv.org/html/2412.09626v2",
        "PDF": "https://arxiv.org/pdf/2412.09626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a technique called FreeScale for higher-resolution visual generation in diffusion models, but it does not address LLM training data processing."
      },
      "tasks": [
        "8k"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.06897",
      "abstract": "This paper presents MedSegFactory, a versatile medical synthesis framework that generates high-quality paired medical images and segmentation masks across modalities and tasks. It aims to serve as an unlimited data repository, supplying image-mask pairs to enhance existing segmentation tools. The core of MedSegFactory is a dual-stream diffusion model, where one stream synthesizes medical images and the other generates corresponding segmentation masks. To ensure precise alignment between image-mask pairs, we introduce Joint Cross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic cross-conditioning between streams. This bidirectional interaction allows both representations to guide each other's generation, enhancing consistency between generated pairs. MedSegFactory unlocks on-demand generation of paired medical images and segmentation masks through user-defined prompts that specify the target labels, imaging modalities, anatomical regions, and pathological conditions, facilitating scalable and high-quality data generation. This new paradigm of medical image synthesis enables seamless integration into diverse medical imaging workflows, enhancing both efficiency and accuracy. Extensive experiments show that MedSegFactory generates data of superior quality and usability, achieving competitive or state-of-the-art performance in 2D and 3D segmentation tasks while addressing data scarcity and regulatory constraints.",
      "authors": [
        "Jiawei Mao",
        "Yuhan Wang",
        "Yucheng Tang",
        "Daguang Xu",
        "Kang Wang",
        "Yang Yang",
        "Zongwei Zhou",
        "Yuyin Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T13:56:05+00:00",
          "link": "https://arxiv.org/abs/2504.06897v1",
          "size": "4949kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:02:58+00:00",
          "link": "https://arxiv.org/abs/2504.06897v2",
          "size": "4948kb",
          "version": "v2"
        }
      ],
      "title": "MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06897",
        "HTML": "https://arxiv.org/html/2504.06897v2",
        "PDF": "https://arxiv.org/pdf/2504.06897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces MedSegFactory, a framework for medical image-mask pair generation, which involves data synthesis, it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08106",
      "abstract": "In this work, we aimed to replicate and extend the results presented in the DiffFluid paper[1]. The DiffFluid model showed that diffusion models combined with Transformers are capable of predicting fluid dynamics. It uses a denoising diffusion probabilistic model (DDPM) framework to tackle Navier-Stokes and Darcy flow equations. Our goal was to validate the reproducibility of the methods in the DiffFluid paper while testing its viability for other simulation types, particularly the Lattice Boltzmann method. Despite our computational limitations and time constraints, this work provides evidence of the flexibility and potential of the model as a general-purpose solver for fluid dynamics. Our results show both the potential and challenges of applying diffusion models to complex fluid dynamics problems. This work highlights the opportunities for future research in optimizing the computational efficiency and scaling such models in broader domains.",
      "authors": [
        "Yannick Gachnang",
        "Vismay Churiwala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:47:41+00:00",
          "link": "https://arxiv.org/abs/2507.08106v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "Predicting Flow Dynamics using Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08106",
        "HTML": "https://arxiv.org/html/2507.08106v1",
        "PDF": "https://arxiv.org/pdf/2507.08106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates predicting fluid dynamics using diffusion models and does not discuss processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08240",
      "abstract": "In this paper, we investigate the applicability of the CLIP-EBC framework, originally designed for crowd counting, to car object counting using the CARPK dataset. Experimental results show that our model achieves second-best performance compared to existing methods. In addition, we propose a K-means weighted clustering method to estimate object positions based on predicted density maps, indicating the framework's potential extension to localization tasks.",
      "authors": [
        "Seoik Jung",
        "Taekyung Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:58:54+00:00",
          "link": "https://arxiv.org/abs/2507.08240v1",
          "size": "6384kb",
          "version": "v1"
        }
      ],
      "title": "Car Object Counting and Position Estimation via Extension of the CLIP-EBC Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08240",
        "HTML": "https://arxiv.org/html/2507.08240v1",
        "PDF": "https://arxiv.org/pdf/2507.08240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on car counting and position estimation using an existing dataset and clustering methods, without relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08546",
      "abstract": "Medical image retrieval is a valuable field for supporting clinical decision-making, yet current methods primarily support 2D images and require fully annotated queries, limiting clinical flexibility. To address this, we propose RadiomicsRetrieval, a 3D content-based retrieval framework bridging handcrafted radiomics descriptors with deep learning-based embeddings at the tumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploits volumetric data to leverage richer spatial context in medical images. We employ a promptable segmentation model (e.g., SAM) to derive tumor-specific image embeddings, which are aligned with radiomics features extracted from the same tumor via contrastive learning. These representations are further enriched by anatomical positional embedding (APE). As a result, RadiomicsRetrieval enables flexible querying based on shape, location, or partial feature sets. Extensive experiments on both lung CT and brain MRI public datasets demonstrate that radiomics features significantly enhance retrieval specificity, while APE provides global anatomical context essential for location-based searches. Notably, our framework requires only minimal user prompts (e.g., a single point), minimizing segmentation overhead and supporting diverse clinical scenarios. The capability to query using either image embeddings or selected radiomics attributes highlights its adaptability, potentially benefiting diagnosis, treatment planning, and research on large-scale medical imaging repositories. Our code is available at https://github.com/nainye/RadiomicsRetrieval.",
      "authors": [
        "Inye Na",
        "Nejung Rue",
        "Jiwon Chung",
        "Hyunjin Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:48:25+00:00",
          "link": "https://arxiv.org/abs/2507.08546v1",
          "size": "9696kb",
          "version": "v1"
        }
      ],
      "title": "RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08546",
        "HTML": "https://arxiv.org/html/2507.08546v1",
        "PDF": "https://arxiv.org/pdf/2507.08546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for medical image retrieval, which does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08590",
      "abstract": "Image-text matching (ITM) aims to address the fundamental challenge of aligning visual and textual modalities, which inherently differ in their representations, continuous, high-dimensional image features vs. discrete, structured text. We propose a novel framework that bridges the modality gap by leveraging multimodal large language models (MLLMs) as visual semantic parsers. By generating rich Visual Semantic Descriptions (VSD), MLLMs provide semantic anchor that facilitate cross-modal alignment. Our approach combines: (1) Instance-level alignment by fusing visual features with VSD to enhance the linguistic expressiveness of image representations, and (2) Prototype-level alignment through VSD clustering to ensure category-level consistency. These modules can be seamlessly integrated into existing ITM models. Extensive experiments on Flickr30K and MSCOCO demonstrate substantial performance improvements. The approach also exhibits remarkable zero-shot generalization to cross-domain tasks, including news and remote sensing ITM. The code and model checkpoints are available at https://github.com/Image-Text-Matching/VSD.",
      "authors": [
        "Junyu Chen",
        "Yihua Gao and Mingyong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:38:01+00:00",
          "link": "https://arxiv.org/abs/2507.08590v1",
          "size": "7493kb",
          "version": "v1"
        }
      ],
      "title": "Visual Semantic Description Generation with MLLMs for Image-Text Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08590",
        "HTML": "https://arxiv.org/html/2507.08590v1",
        "PDF": "https://arxiv.org/pdf/2507.08590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on image-text matching using multimodal LLMs but primarily discusses semantic descriptions for cross-modal alignment rather than specific LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.02004",
      "abstract": "We consider the aggregation of distributed energy resources (DERs) by a profit-seeking aggregator participating directly in wholesale market under distribution network access constraints. We propose a competitive DER aggregator (DERA) model that maximizes the DERA's profit while ensuring each aggregated customer gains no less surplus and pays no higher energy cost than under the regulated retail tariff. The DERA participates in wholesale electricity market as virtual storage with optimized generation offers and consumption bids derived from our competitive aggregation model. Also derived are DERA's bid curves for the distribution network access and DERA's profitability when competing with the regulated retail tariff. We show that, with the same distribution network access, the proposed DERA's wholesale market participation achieves the same welfare-maximizing outcome as when its customers participate directly in the wholesale market. Numerical studies compare the proposed DERA with existing methods in terms of customer surplus and DERA profit. We empirically evaluate how many DERAs can survive in the competition at long-run equilibrium, and assess the impacts of DER adoption levels and distribution network access on short-run market outcomes.",
      "authors": [
        "Cong Chen",
        "Ahmed S. Alahmed",
        "Timothy D. Mount",
        "Lang Tong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-05T03:29:31+00:00",
          "link": "https://arxiv.org/abs/2307.02004v1",
          "size": "1548kb",
          "version": "v1"
        },
        {
          "date": "2024-01-08T03:00:21+00:00",
          "link": "https://arxiv.org/abs/2307.02004v2",
          "size": "1254kb",
          "version": "v2"
        },
        {
          "date": "2024-06-23T15:51:15+00:00",
          "link": "https://arxiv.org/abs/2307.02004v3",
          "size": "768kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T05:51:42+00:00",
          "link": "https://arxiv.org/abs/2307.02004v4",
          "size": "828kb",
          "version": "v4"
        }
      ],
      "title": "Wholesale Market Participation of DERA: Competitive DER Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.02004",
        "HTML": "https://arxiv.org/html/2307.02004v4",
        "PDF": "https://arxiv.org/pdf/2307.02004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with DER aggregation for market participation, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.18246",
      "abstract": "Fine-tuning Large Language Models (LLMs) on multi-turn reasoning datasets requires N (number of turns) separate forward passes per conversation due to reasoning token visibility constraints, as reasoning tokens for a turn are discarded in subsequent turns. We propose duplicating response tokens along with a custom attention mask to enable single-pass processing of entire conversations. We prove our method produces identical losses to the N-pass approach while reducing time complexity from $O\\bigl(N^{3}\\bigl)$ to $O\\bigl(N^{2}\\bigl)$ and maintaining the same memory complexity for a transformer based model. Our approach achieves significant training speedup while preserving accuracy. Our implementation is available online (https://github.com/devrev/One-Pass-to-Reason).",
      "authors": [
        "Ritesh Goru",
        "Shanay Mehta",
        "Prateek Jain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T10:46:56+00:00",
          "link": "https://arxiv.org/abs/2504.18246v1",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:43:08+00:00",
          "link": "https://arxiv.org/abs/2504.18246v2",
          "size": "427kb",
          "version": "v2"
        }
      ],
      "title": "One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18246",
        "HTML": "https://arxiv.org/html/2504.18246v2",
        "PDF": "https://arxiv.org/pdf/2504.18246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a method to speed up the fine-tuning process of LLMs by duplicating response tokens and using custom attention masks, which relates indirectly to data processing during fine-tuning but does not focus on the training data processing itself."
      },
      "datasets": [
        {
          "dataset_name": "devrev-research/MathChatSync-reasoning",
          "downloads": "150",
          "likes": "1",
          "link": "https://huggingface.co/datasets/devrev-research/MathChatSync-reasoning"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07104",
      "abstract": "Building state-of-the-art Vision-Language Models (VLMs) with strong captioning capabilities typically necessitates training on billions of high-quality image-text pairs, requiring millions of GPU hours. This paper introduces the Vision-Language-Vision (VLV) auto-encoder framework, which strategically leverages key pretrained components: a vision encoder, the decoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large Language Model (LLM). Specifically, we establish an information bottleneck by regularizing the language representation space, achieved through freezing the pretrained T2I diffusion decoder. Our VLV pipeline effectively distills knowledge from the text-conditioned diffusion model using continuous embeddings, demonstrating comprehensive semantic understanding via high-quality reconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the intermediate language representations into detailed descriptions, we construct a state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o and Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and significantly reduces data requirements; by primarily utilizing single-modal images for training and maximizing the utility of existing pretrained models (image encoder, T2I diffusion model, and LLM), it circumvents the need for massive paired image-text datasets, keeping the total training expenditure under $1,000 USD.",
      "authors": [
        "Tiezheng Zhang",
        "Yitong Li",
        "Yu-cheng Chou",
        "Jieneng Chen",
        "Alan Yuille",
        "Chen Wei",
        "Junfei Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:59:04+00:00",
          "link": "https://arxiv.org/abs/2507.07104v1",
          "size": "12217kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:43:50+00:00",
          "link": "https://arxiv.org/abs/2507.07104v2",
          "size": "12210kb",
          "version": "v2"
        }
      ],
      "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07104",
        "HTML": "https://arxiv.org/html/2507.07104v2",
        "PDF": "https://arxiv.org/pdf/2507.07104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though it discusses a vision-language model framework, the focus is on using existing models efficiently rather than on processing or preparing data specifically for LLM training."
      },
      "models": [
        {
          "model_path": "lambertxiao/Vision-Language-Vision-Captioner-Qwen2.5-3B",
          "downloads": "13",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/lambertxiao/Vision-Language-Vision-Captioner-Qwen2.5-3B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "ccvl/LAION-High-Qualtiy-Pro-6M-VLV",
          "downloads": "5197",
          "likes": "1",
          "link": "https://huggingface.co/datasets/ccvl/LAION-High-Qualtiy-Pro-6M-VLV"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2005.03120",
      "abstract": "Coordination between heat and electricity markets is essential to achieve a cost-effective and efficient operation of the energy system. In the current sequential market practice, the heat market is cleared before the electricity market and has no insight into the impacts of heat dispatch on the electricity market. While preserving this sequential practice, this paper introduces an electricity-aware bid format for the coordination of heat and electricity systems. This novel market mechanism defines heat bids conditionally on the day-ahead electricity prices. Prior to clearing heat and electricity markets, the proposed bid selection mechanism selects the valid bids which minimize the heat system operating cost while anticipating heat and electricity market clearing. This mechanism is modeled as a trilevel optimization problem, which we recast as a mixed-integer linear program using a lexicographic function. We use a realistic case study based on the Danish electricity and heat system and show that the proposed bid selection mechanism yields a 4.5% reduction in the total operating cost of heat and electricity systems compared to the existing market-clearing procedure while reducing the financial losses of combined heat and power plants and heat pumps due to invalid bids by up to 20.3 million euros.",
      "authors": [
        "Lesia Mitridati",
        "Jalal Kazempour",
        "Pascal Van Hentenryck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2020-05-06T20:12:53+00:00",
          "link": "https://arxiv.org/abs/2005.03120v1",
          "size": "8990kb",
          "version": "v1"
        },
        {
          "date": "2021-06-05T09:11:15+00:00",
          "link": "https://arxiv.org/abs/2005.03120v2",
          "size": "14225kb",
          "version": "v2"
        },
        {
          "date": "2022-01-25T21:01:04+00:00",
          "link": "https://arxiv.org/abs/2005.03120v3",
          "size": "7244kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T04:50:18+00:00",
          "link": "https://arxiv.org/abs/2005.03120v4",
          "size": "4114kb",
          "version": "v4"
        }
      ],
      "title": "Electricity-Aware Bid Format for Coordinated Heat and Electricity Market Clearing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2005.03120",
        "HTML": "https://arxiv.org/html/2005.03120v4",
        "PDF": "https://arxiv.org/pdf/2005.03120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a bid format for coordinated heat and electricity market clearing, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08028",
      "abstract": "This paper introduces a SSSUMO, semi-supervised deep learning approach for submovement decomposition that achieves state-of-the-art accuracy and speed. While submovement analysis offers valuable insights into motor control, existing methods struggle with reconstruction accuracy, computational cost, and validation, due to the difficulty of obtaining hand-labeled data. We address these challenges using a semi-supervised learning framework. This framework learns from synthetic data, initially generated from minimum-jerk principles and then iteratively refined through adaptation to unlabeled human movement data. Our fully convolutional architecture with differentiable reconstruction significantly surpasses existing methods on both synthetic and diverse human motion datasets, demonstrating robustness even in high-noise conditions. Crucially, the model operates in real-time (less than a millisecond per input second), a substantial improvement over optimization-based techniques. This enhanced performance facilitates new applications in human-computer interaction, rehabilitation medicine, and motor control studies. We demonstrate the model's effectiveness across diverse human-performed tasks such as steering, rotation, pointing, object moving, handwriting, and mouse-controlled gaming, showing notable improvements particularly on challenging datasets where traditional methods largely fail. Training and benchmarking source code, along with pre-trained model weights, are made publicly available at https://github.com/dolphin-in-a-coma/sssumo.",
      "authors": [
        "Evgenii Rudakov",
        "Jonathan Shock",
        "Otto Lappi",
        "Benjamin Ultan Cowley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:26:25+00:00",
          "link": "https://arxiv.org/abs/2507.08028v1",
          "size": "4552kb",
          "version": "v1"
        }
      ],
      "title": "SSSUMO: Real-Time Semi-Supervised Submovement Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08028",
        "HTML": "https://arxiv.org/html/2507.08028v1",
        "PDF": "https://arxiv.org/pdf/2507.08028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a semi-supervised learning approach for submovement decomposition and its application to motor control data, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08208",
      "abstract": "We introduce the LLM-Nash framework, a game-theoretic model where agents select reasoning prompts to guide decision-making via Large Language Models (LLMs). Unlike classical games that assume utility-maximizing agents with full rationality, this framework captures bounded rationality by modeling the reasoning process explicitly. Equilibrium is defined over the prompt space, with actions emerging as the behavioral output of LLM inference. This approach enables the study of cognitive constraints, mindset expressiveness, and epistemic learning. Through illustrative examples, we show how reasoning equilibria can diverge from classical Nash outcomes, offering a new foundation for strategic interaction in LLM-enabled systems.",
      "authors": [
        "Quanyan Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:43:00+00:00",
          "link": "https://arxiv.org/abs/2507.08208v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08208",
        "HTML": "https://arxiv.org/html/2507.08208v1",
        "PDF": "https://arxiv.org/pdf/2507.08208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a game-theoretic framework utilizing LLMs for decision-making, focusing on prompts and reasoning equilibria rather than training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08310",
      "abstract": "This paper examines the impact of Generative Artificial Intelligence (GenAI) on scientific practices, conducting a qualitative review of selected literature to explore its applications, benefits, and challenges. The review draws on the OpenAlex publication database, using a Boolean search approach to identify scientific literature related to GenAI (including large language models and ChatGPT). Thirty-nine highly cited papers and commentaries are reviewed and qualitatively coded. Results are categorized by GenAI applications in science, scientific writing, medical practice, and education and training. The analysis finds that while there is a rapid adoption of GenAI in science and science practice, its long-term implications remain unclear, with ongoing uncertainties about its use and governance. The study provides early insights into GenAI's growing role in science and identifies questions for future research in this evolving field.",
      "authors": [
        "Ryan Harries",
        "Cornelia Lawson",
        "and Philip Shapira"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:02:24+00:00",
          "link": "https://arxiv.org/abs/2507.08310v1",
          "size": "371kb",
          "version": "v1"
        }
      ],
      "title": "Generative AI in Science: Applications, Challenges, and Emerging Questions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08310",
        "PDF": "https://arxiv.org/pdf/2507.08310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a qualitative review on the impact of GenAI applications, lacking any substantive focus on processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08729",
      "abstract": "The multi-camera vehicle tracking (MCVT) framework holds significant potential for smart city applications, including anomaly detection, traffic density estimation, and suspect vehicle tracking. However, current publicly available datasets exhibit limitations, such as overly simplistic scenarios, low-resolution footage, and insufficiently diverse conditions, creating a considerable gap between academic research and real-world scenario. To fill this gap, we introduce RoundaboutHD, a comprehensive, high-resolution multi-camera vehicle tracking benchmark dataset specifically designed to represent real-world roundabout scenarios. RoundaboutHD provides a total of 40 minutes of labelled video footage captured by four non-overlapping, high-resolution (4K resolution, 15 fps) cameras. In total, 512 unique vehicle identities are annotated across different camera views, offering rich cross-camera association data. RoundaboutHD offers temporal consistency video footage and enhanced challenges, including increased occlusions and nonlinear movement inside the roundabout. In addition to the full MCVT dataset, several subsets are also available for object detection, single camera tracking, and image-based vehicle re-identification (ReID) tasks. Vehicle model information and camera modelling/ geometry information are also included to support further analysis. We provide baseline results for vehicle detection, single-camera tracking, image-based vehicle re-identification, and multi-camera tracking. The dataset and the evaluation code are publicly available at: https://github.com/siri-rouser/RoundaboutHD.git",
      "authors": [
        "Yuqiang Lin",
        "Sam Lockyer",
        "Mingxuan Sui",
        "Li Gan",
        "Florian Stanek",
        "Markus Zarbock",
        "Wenbin Li",
        "Adrian Evans",
        "Nic Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:30:27+00:00",
          "link": "https://arxiv.org/abs/2507.08729v1",
          "size": "1297kb",
          "version": "v1"
        }
      ],
      "title": "RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08729",
        "HTML": "https://arxiv.org/html/2507.08729v1",
        "PDF": "https://arxiv.org/pdf/2507.08729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces RoundaboutHD, a dataset for multi-camera vehicle tracking, focusing on smart city applications rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08741",
      "abstract": "Hierarchical land cover and land use (LCLU) classification aims to assign pixel-wise labels with multiple levels of semantic granularity to remote sensing (RS) imagery. However, existing deep learning-based methods face two major challenges: 1) They predominantly adopt a flat classification paradigm, which limits their ability to generate end-to-end multi-granularity hierarchical predictions aligned with tree-structured hierarchies used in practice. 2) Most cross-domain studies focus on performance degradation caused by sensor or scene variations, with limited attention to transferring LCLU models to cross-domain tasks with heterogeneous hierarchies (e.g., LCLU to crop classification). These limitations hinder the flexibility and generalization of LCLU models in practical applications. To address these challenges, we propose HieraRS, a novel hierarchical interpretation paradigm that enables multi-granularity predictions and supports the efficient transfer of LCLU models to cross-domain tasks with heterogeneous tree-structured hierarchies. We introduce the Bidirectional Hierarchical Consistency Constraint Mechanism (BHCCM), which can be seamlessly integrated into mainstream flat classification models to generate hierarchical predictions, while improving both semantic consistency and classification accuracy. Furthermore, we present TransLU, a dual-branch cross-domain transfer framework comprising two key components: Cross-Domain Knowledge Sharing (CDKS) and Cross-Domain Semantic Alignment (CDSA). TransLU supports dynamic category expansion and facilitates the effective adaptation of LCLU models to heterogeneous hierarchies. In addition, we construct MM-5B, a large-scale multi-modal hierarchical land use dataset featuring pixel-wise annotations. The code and MM-5B dataset will be released at: https://github.com/AI-Tianlong/HieraRS.",
      "authors": [
        "Tianlong Ai",
        "Tianzhu Liu",
        "Haochen Jiang",
        "and Yanfeng Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:44:01+00:00",
          "link": "https://arxiv.org/abs/2507.08741v1",
          "size": "36805kb",
          "version": "v1"
        }
      ],
      "title": "HieraRS: A Hierarchical Segmentation Paradigm for Remote Sensing Enabling Multi-Granularity Interpretation and Cross-Domain Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08741",
        "HTML": "https://arxiv.org/html/2507.08741v1",
        "PDF": "https://arxiv.org/pdf/2507.08741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces MM-5B, a large-scale multi-modal hierarchical land use dataset with pixel-wise annotations, with detailed data processing steps for constructing the dataset, making a core contribution to data creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.12169",
      "abstract": "We propose a globally consistent semantic SLAM system (GCSLAM) and a semantic-fusion localization subsystem (SF-Loc), which achieves accurate semantic mapping and robust localization in complex parking lots. Visual cameras (front-view and surround-view), IMU, and wheel encoder form the input sensor configuration of our system. The first part of our work is GCSLAM. GCSLAM introduces a semantic-constrained factor graph for the optimization of poses and semantic map, which incorporates innovative error terms based on multi-sensor data and BEV (bird's-eye view) semantic information. Additionally, GCSLAM integrates a Global Slot Management module that stores and manages parking slot observations. SF-Loc is the second part of our work, which leverages the semantic map built by GCSLAM to conduct map-based localization. SF-Loc integrates registration results and odometry poses with a novel factor graph. Our system demonstrates superior performance over existing SLAM on two real-world datasets, showing excellent capabilities in robust global localization and precise semantic mapping.",
      "authors": [
        "Yichen Sha",
        "Siting Zhu",
        "Hekui Guo",
        "Zhong Wang",
        "and Hesheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T02:17:07+00:00",
          "link": "https://arxiv.org/abs/2410.12169v1",
          "size": "7799kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:19:27+00:00",
          "link": "https://arxiv.org/abs/2410.12169v2",
          "size": "2803kb",
          "version": "v2"
        }
      ],
      "title": "Towards Autonomous Indoor Parking: A Globally Consistent Semantic SLAM System and A Semantic Localization Subsystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12169",
        "HTML": "https://arxiv.org/html/2410.12169v2",
        "PDF": "https://arxiv.org/pdf/2410.12169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces semantic SLAM and localization systems for autonomous indoor parking but does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.09395",
      "abstract": "In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a large variety of objects and goals. When confronted with an unexpected or unwanted outcome, we take corrective actions and try again until achieving the desired result. The reasoning performed to identify a cause of the observed outcome and to select an appropriate corrective action is a crucial aspect of human reasoning for successful task execution. Central to this reasoning is the assumption that a factor is responsible for producing the observed outcome. In this paper, we investigate the use of probabilistic actual causation to determine whether a factor is the cause of an observed undesired outcome. Furthermore, we show how the actual causation probabilities can be used to find alternative actions to change the outcome. We apply the probabilistic actual causation analysis to a robot pouring task. When spillage occurs, the analysis indicates whether a task parameter is the cause and how it should be changed to avoid spillage. The analysis requires a causal graph of the task and the corresponding conditional probability distributions. To fulfill these requirements, we perform a complete causal modeling procedure (i.e., task analysis, definition of variables, determination of the causal graph structure, and estimation of conditional probability distributions) using data from a realistic simulation of the robot pouring task, covering a large combinatorial space of task parameters. Based on the results, we discuss the implications of the variables' representation and how the alternative actions suggested by the actual causation analysis would compare to the alternative solutions proposed by a human observer. The practical use of the analysis of probabilistic actual causation to select alternative action parameters is demonstrated.",
      "authors": [
        "Jaime Maldonado",
        "Jonas Krumme",
        "Christoph Zetzsche",
        "Vanessa Didelez",
        "Kerstin Schill"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T15:16:52+00:00",
          "link": "https://arxiv.org/abs/2502.09395v1",
          "size": "2060kb",
          "version": "v1"
        },
        {
          "date": "2025-04-24T15:25:56+00:00",
          "link": "https://arxiv.org/abs/2502.09395v2",
          "size": "2133kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T14:21:40+00:00",
          "link": "https://arxiv.org/abs/2502.09395v3",
          "size": "2154kb",
          "version": "v3"
        }
      ],
      "title": "Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09395",
        "HTML": "https://arxiv.org/html/2502.09395",
        "PDF": "https://arxiv.org/pdf/2502.09395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on probabilistic causation in robot pouring tasks, which does not involve the processing of LLM training data or dataset creation for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.17546",
      "abstract": "The behavior of multivariate dynamical processes is often governed by underlying structural connections that relate the components of the system. For example, brain activity, which is often measured via time series is determined by an underlying structural graph, where nodes represent neurons or brain regions and edges cortical connectivity. Existing methods for inferring structural connections from observed dynamics, such as correlation-based or spectral techniques, may fail to fully capture complex relationships in high-dimensional time series in an interpretable way. Here, we propose the use of path signatures, a mathematical framework that encodes geometric and temporal properties of continuous paths, to address this problem. Path signatures provide a reparametrization-invariant characterization of dynamical data and can be used to compute the lead matrix, which reveals lead-lag phenomena. We showcase our approach on time series from coupled oscillators in the Kuramoto model defined on a stochastic block model graph, termed the Kuramoto Stochastic Block Model (KSBM). Using mean-field theory and Gaussian approximations, we analytically derive reduced models of KSBM dynamics in different temporal regimes and theoretically characterize the lead matrix in these settings. Leveraging these insights, we propose a novel signature-based community detection algorithm, achieving exact recovery of structural communities from observed time series in multiple KSBM instances. We also explored the performance of our community detection on a stochastic variant of the KSBM as well as on real neuropixels of cortical recordings to demonstrate applicability on real-world data. Our results demonstrate that path signatures provide a novel perspective on analyzing complex neural data and other high-dimensional systems, explicitly exploiting temporal functional relationships to infer underlying structure.",
      "authors": [
        "T\\^am Johan Nguy\\^en",
        "Darrick Lee",
        "Bernadette Jana Stolz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Neurons and Cognition (q-bio.NC)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T21:41:48+00:00",
          "link": "https://arxiv.org/abs/2503.17546v1",
          "size": "9252kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T14:02:42+00:00",
          "link": "https://arxiv.org/abs/2503.17546v2",
          "size": "9252kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T12:23:34+00:00",
          "link": "https://arxiv.org/abs/2503.17546v3",
          "size": "17576kb",
          "version": "v3"
        }
      ],
      "title": "Communities in the Kuramoto Model: Dynamics and Detection via Path Signatures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17546",
        "HTML": "https://arxiv.org/html/2503.17546v3",
        "PDF": "https://arxiv.org/pdf/2503.17546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the Kuramoto model and path signatures for community detection, with no discussion of LLM training data processing or dataset construction."
      },
      "tasks": [
        "Community Detection",
        "Stochastic Block Model",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/arthurion98/KSBM-path-signatures"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.01531",
      "abstract": "Accurate predictions of spatio-temporal systems are crucial for tasks such as system management, control, and crisis prevention. However, the inherent time variance of many spatio-temporal systems poses challenges to achieving accurate predictions whenever stationarity is not granted. In order to address non-stationarity, we propose a Distribution and Relation Adaptive Network (DRAN) capable of dynamically adapting to relation and distribution changes over time. While temporal normalization and de-normalization are frequently used techniques to adapt to distribution shifts, this operation is not suitable for the spatio-temporal context as temporal normalization scales the time series of nodes and possibly disrupts the spatial relations among nodes. In order to address this problem, a Spatial Factor Learner (SFL) module is developed that enables the normalization and de-normalization process. To adapt to dynamic changes in spatial relationships among sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that effectively integrates features learned from both dynamic and static relations through an adaptive fusion ratio mechanism. Furthermore, we introduce a Stochastic Learner to capture the noisy components of spatio-temporal representations. Our approach outperforms state-of-the-art methods on weather prediction and traffic flow forecasting tasks.Experimental results show that our SFL efficiently preserves spatial relationships across various temporal normalization operations. Visualizations of the learned dynamic and static relations demonstrate that DSFL can capture both local and distant relationships between nodes.",
      "authors": [
        "Xiaobei Zou",
        "Luolin Xiong",
        "Kexuan Zhang",
        "Cesare Alippi",
        "Yang Tang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T09:18:43+00:00",
          "link": "https://arxiv.org/abs/2504.01531v1",
          "size": "16572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T13:56:41+00:00",
          "link": "https://arxiv.org/abs/2504.01531v2",
          "size": "2349kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T06:55:22+00:00",
          "link": "https://arxiv.org/abs/2504.01531v3",
          "size": "2349kb",
          "version": "v3"
        }
      ],
      "title": "DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01531",
        "HTML": "https://arxiv.org/html/2504.01531v3",
        "PDF": "https://arxiv.org/pdf/2504.01531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a network for spatio-temporal forecasting with specific modules for relation and distribution adaptation; it does not involve LLM training data processing techniques."
      },
      "tasks": [
        "Relation",
        "Spatio-Temporal Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08114",
      "abstract": "The biclique partition number of a graph \\(G\\), denoted \\( \\operatorname{bp}(G)\\), is the minimum number of biclique subgraphs that partition the edge set of \\(G\\). The Graham-Pollak theorem states that the complete graph on \\( n \\) vertices cannot be partitioned into fewer than \\( n-1 \\) bicliques. In this note, we show that for any split graph \\( G \\), the biclique partition number satisfies \\( \\operatorname{bp}(G) = \\operatorname{mc}(G^c) - 1 \\), where \\( \\operatorname{mc}(G^c) \\) denotes the number of maximal cliques in the complement of \\( G \\). This extends the celebrated Graham-Pollak theorem to a broader class of graphs.",
      "authors": [
        "Anand Babu",
        "Ashwin Jacob"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:55:02+00:00",
          "link": "https://arxiv.org/abs/2507.08114v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "Exact Biclique Partition number of Split Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08114",
        "HTML": "https://arxiv.org/html/2507.08114v1",
        "PDF": "https://arxiv.org/pdf/2507.08114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses graph theory and biclique partition numbers, extending a theorem to split graphs without any relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08607",
      "abstract": "Vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition but degrade significantly under \\textit{temporally evolving distribution shifts} common in real-world scenarios (e.g., gradual illumination or seasonal changes). Existing continual test-time adaptation (CTTA) methods are typically built around sudden and severe distribution shifts and neglect temporal continuity, leading to three core defects: limited memory cache restricts long-range distribution modeling, causing catastrophic forgetting; entropy-based confidence becomes unreliable under temporal drift, worsening error accumulation; and static visual representations misalign with evolving inputs. We formalize this practical problem as \\textit{Continual-Temporal Test-Time Adaptation (CT-TTA)}, where test distributions evolve gradually over time. To address it, we propose \\textit{BayesTTA}, a Bayesian adaptation framework that enforces temporally consistent predictions and dynamically aligns visual representations. Specifically, BayesTTA incrementally estimates class-conditional Gaussian mixture distributions without storing raw data, adaptively selects covariance structures through statistical hypothesis testing, and performs calibrated inference using Gaussian discriminant analysis (GDA). These calibrated predictions supervise self-paced adaptation of normalization layers, ensuring efficient and stable representation alignment. We establish a comprehensive CT-TTA benchmark across four temporally evolving datasets and further evaluate generalization on ten standard TTA datasets. Extensive experiments show that BayesTTA consistently outperforms state-of-the-art methods, achieving significant gains while maintaining efficiency. Code is available at \\href{https://github.com/cuishuang99/BayesTTA}{https://github.com/cuishuang99/BayesTTA}.",
      "authors": [
        "Shuang Cui",
        "Jinglin Xu",
        "Yi Li",
        "Xiongxin Tang",
        "Jiangmeng Li",
        "Jiahuan Zhou",
        "Fanjiang Xu",
        "Fuchun Sun",
        "Hui Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:02:54+00:00",
          "link": "https://arxiv.org/abs/2507.08607v1",
          "size": "9834kb",
          "version": "v1"
        }
      ],
      "title": "BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08607",
        "HTML": "https://arxiv.org/html/2507.08607v1",
        "PDF": "https://arxiv.org/pdf/2507.08607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on adaptation strategies for Vision-Language Models under distribution shifts rather than processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18247",
      "abstract": "Quantifying and propagating modeling uncertainties is crucial for reliability analysis, robust optimization, and other model-based algorithmic processes in engineering design and control. Now, physics-informed machine learning (PIML) methods have emerged in recent years as a new alternative to traditional computational modeling and surrogate modeling methods, offering a balance between computing efficiency, modeling accuracy, and interpretability. However, their ability to predict and propagate modeling uncertainties remains mostly unexplored. In this paper, a promising class of auto-differentiable hybrid PIML architectures that combine partial physics and neural networks or ANNs (for input transformation or adaptive parameter estimation) is integrated with Bayesian Neural networks (replacing the ANNs); this is done with the goal to explore whether BNNs can successfully provision uncertainty propagation capabilities in the PIML architectures as well, further supported by the auto-differentiability of these architectures. A two-stage training process is used to alleviate the challenges traditionally encountered in training probabilistic ML models. The resulting BNN-integrated PIML architecture is evaluated on an analytical benchmark problem and flight experiments data for a fixed-wing RC aircraft, with prediction performance observed to be slightly worse or at par with purely data-driven ML and original PIML models. Moreover, Monte Carlo sampling of probabilistic BNN weights was found to be most effective in propagating uncertainty in the BNN-integrated PIML architectures.",
      "authors": [
        "Manaswin Oddiraju",
        "Bharath Varma Penumatsa",
        "Divyang Amin",
        "Michael Piedmonte",
        "Souma Chowdhury"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T02:32:20+00:00",
          "link": "https://arxiv.org/abs/2506.18247v1",
          "size": "1201kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:48:06+00:00",
          "link": "https://arxiv.org/abs/2506.18247v2",
          "size": "1201kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Efficient Quantification of Modeling Uncertainties with Differentiable Physics-Informed Machine Learning Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18247",
        "HTML": "https://arxiv.org/html/2506.18247v2",
        "PDF": "https://arxiv.org/pdf/2506.18247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses physics-informed machine learning architectures for uncertainty quantification, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08334",
      "abstract": "Concept Bottleneck Models (CBMs) provide interpretable and controllable generative modeling by routing generation through explicit, human-understandable concepts. However, previous generative CBMs often rely on auxiliary visual cues at the bottleneck to compensate for information not captured by the concepts, which undermines interpretability and compositionality. We propose CoCo-Bot, a post-hoc, composable concept bottleneck generative model that eliminates the need for auxiliary cues by transmitting all information solely through explicit concepts. Guided by diffusion-based energy functions, CoCo-Bot supports robust post-hoc interventions-such as concept composition and negation-across arbitrary concepts. Experiments using StyleGAN2 pre-trained on CelebA-HQ show that CoCo-Bot improves concept-level controllability and interpretability, while maintaining competitive visual quality.",
      "authors": [
        "Sangwon Kim and In-su Jang and Pyongkun Kim and Kwang-Ju Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.08334v1",
          "size": "1992kb",
          "version": "v1"
        }
      ],
      "title": "CoCo-Bot: Energy-based Composable Concept Bottlenecks for Interpretable Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08334",
        "HTML": "https://arxiv.org/html/2507.08334v1",
        "PDF": "https://arxiv.org/pdf/2507.08334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a generative model with concept bottlenecks to improve interpretability and controllability, which does not make contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.02523",
      "abstract": "Solving partial differential equations with the finite element method leads to large linear systems of equations that must be solved. When these systems have a natural block structure due to multiple field variables, using iterative solvers with carefully designed preconditioning strategies that exploit the underlying physical structure becomes necessary for an efficient and scalable solution process. FEniCSx Preconditioning Tools (FEniCSx-pctools) is a software package that eases the specification of PETSc (Portable, Extensible Toolkit for Scientific Computation) block preconditioning strategies on linear systems assembled using the DOLFINx finite element solver of the FEniCS Project. The package automatically attaches all necessary metadata so that preconditioning strategies can be applied via PETSc's standard options-based configuration system. The documented examples include a simple mixed Poisson system and more complex pressure convection-diffusion approach to preconditioning the Navier-Stokes equations. We show weak parallel scaling on a fully coupled temperature-Navier-Stokes system up to 8192 MPI (Message Passing Interface) processes, demonstrating the applicability of the approach to large-scale problems.",
      "authors": [
        "Martin \\v{R}eho\\v{r} and Jack S. Hale"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Mathematical Software (cs.MS)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-04T15:11:04+00:00",
          "link": "https://arxiv.org/abs/2402.02523v1",
          "size": "462kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T21:45:45+00:00",
          "link": "https://arxiv.org/abs/2402.02523v2",
          "size": "388kb",
          "version": "v2"
        }
      ],
      "title": "FEniCSx-pctools: Tools for PETSc block linear algebra preconditioning in FEniCSx",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02523",
        "HTML": "https://arxiv.org/html/2402.02523v2",
        "PDF": "https://arxiv.org/pdf/2402.02523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on preconditioning strategies for solving linear systems in finite element methods, which is not related to LLM training data processing."
      },
      "repo_urls": [
        "https://gitlab.com/rafinex-external-rifle/fenicsx-pctools"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07668",
      "abstract": "We give a deterministic algorithm that, given a composite number $N$ and a target order $D \\ge N^{1/6}$, runs in time $D^{1/2+o(1)}$ and finds either an element $a \\in \\mathbb{Z}_N^*$ of multiplicative order at least $D$, or a nontrivial factor of $N$. Our algorithm improves upon an algorithm of Hittmeir (arXiv:1608.08766), who designed a similar algorithm under the stronger assumption $D \\ge N^{2/5}$. Hittmeir's algorithm played a crucial role in the recent breakthrough deterministic integer factorization algorithms of Hittmeir and Harvey (arXiv:2006.16729, arXiv:2010.05450, arXiv:2105.11105). When $N$ is assumed to have an $r$-power divisor with $r\\ge 2$, our algorithm provides the same guarantees assuming $D \\ge N^{1/6r}$.",
      "authors": [
        "Ziv Oznovich",
        "Ben Lee Volk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T11:39:47+00:00",
          "link": "https://arxiv.org/abs/2506.07668v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:48:50+00:00",
          "link": "https://arxiv.org/abs/2506.07668v2",
          "size": "18kb",
          "version": "v2"
        }
      ],
      "title": "On Deterministically Finding an Element of High Order Modulo a Composite",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07668",
        "HTML": "https://arxiv.org/html/2506.07668v2",
        "PDF": "https://arxiv.org/pdf/2506.07668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a deterministic algorithm for finding elements of high order modulo a composite, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08216",
      "abstract": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to process the input entities, while relying on a reasoner based on First-Order Logic to represent and process more complex relationships among the entities. A fundamental role for these methods is played by the process of logic grounding, which determines the relevant substitutions for the logic rules using a (sub)set of entities. Some NeSy methods use an exhaustive derivation of all possible substitutions, preserving the full expressive power of the logic knowledge. This leads to a combinatorial explosion in the number of ground formulas to consider and, therefore, strongly limits their scalability. Other methods rely on heuristic-based selective derivations, which are generally more computationally efficient, but lack a justification and provide no guarantees of preserving the information provided to and returned by the reasoner. Taking inspiration from multi-hop symbolic reasoning, this paper proposes a parametrized family of grounding methods generalizing classic Backward Chaining. Different selections within this family allow us to obtain commonly employed grounding methods as special cases, and to control the trade-off between expressiveness and scalability of the reasoner. The experimental results show that the selection of the grounding criterion is often as important as the NeSy method itself.",
      "authors": [
        "Rodrigo Castellano Ontiveros",
        "Francesco Giannini",
        "Marco Gori",
        "Giuseppe Marra and Michelangelo Diligenti"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:29:15+00:00",
          "link": "https://arxiv.org/abs/2507.08216v1",
          "size": "1657kb",
          "version": "v1"
        }
      ],
      "title": "Grounding Methods for Neural-Symbolic AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08216",
        "HTML": "https://arxiv.org/html/2507.08216v1",
        "PDF": "https://arxiv.org/pdf/2507.08216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses grounding methods in Neural-Symbolic AI, focusing on logic reasoning processes rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08286",
      "abstract": "Open banking framework enables third party providers to access financial data across banking institutions, leading to unprecedented innovations in the financial sector. However, some open banking standards remain susceptible to severe technological risks, including unverified data sources, inconsistent data integrity, and lack of immutability. In this paper, we propose a layered architecture that provides assurance in data trustworthiness with three distinct levels of trust, covering source validation, data-level authentication, and tamper-proof storage. The first layer guarantees the source legitimacy using decentralized identity and verifiable presentation, while the second layer verifies data authenticity and consistency using cryptographic signing. Lastly, the third layer guarantees data immutability through the Tangle, a directed acyclic graph distributed ledger. We implemented a proof-of-concept implementation of our solution to evaluate its performance, where the results demonstrate that the system scales linearly with a stable throughput, exhibits a 100% validation rate, and utilizes under 35% of CPU and 350 MiB memory. Compared to a real-world open banking implementation, our solution offers significantly reduced latency and stronger data integrity assurance. Overall, our solution offers a practical and efficient system for secure data sharing in financial ecosystems while maintaining regulatory compliance.",
      "authors": [
        "Aufa Nasywa Rahman",
        "Bimo Sunarfri Hantono",
        "Guntur Dharma Putra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:19:44+00:00",
          "link": "https://arxiv.org/abs/2507.08286v1",
          "size": "287kb",
          "version": "v1"
        }
      ],
      "title": "TruChain: A Multi-Layer Architecture for Trusted, Verifiable, and Immutable Open Banking Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08286",
        "HTML": "https://arxiv.org/html/2507.08286v1",
        "PDF": "https://arxiv.org/pdf/2507.08286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses open banking data architecture, focusing on data trustworthiness and integrity, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08671",
      "abstract": "While comments are essential for enhancing code readability and maintainability in modern software projects, developers are often motivated to update code but not comments, leading to outdated or inconsistent documentation that hinders future understanding and maintenance. Recent approaches such as CUP and HebCup have attempted automatic comment updating using neural sequence-to-sequence models and heuristic rules, respectively. However, these methods can miss or misinterpret crucial information during comment updating, resulting in inaccurate comments, and they often struggle with complex update scenarios. Given these challenges, a promising direction lies in leveraging large language models (LLMs), which have shown impressive performance in software engineering tasks such as comment generation, code synthesis, and program repair. This suggests their strong potential to capture the logic behind code modifications - an ability that is crucial for the task of comment updating. Nevertheless, selecting an appropriate prompt strategy for an LLM on each update case remains challenging. To address this, we propose a novel comment updating framework, LLMCup, which first uses multiple prompt strategies to provide diverse candidate updated comments via an LLM, and then employs a ranking model, CupRank, to select the best candidate as final updated comment. Experimental results demonstrate the effectiveness of LLMCup, with improvements over state-of-the-art baselines (CUP and HebCup) by 49.0%-116.9% in Accuracy, 10.8%-20% in BLEU-4, 4.6% in METEOR, 0.9%-1.9% in F1, and 2.1%-3.4% in SentenceBert similarity. Furthermore, a user study shows that comments updated by LLMCup sometimes surpass human-written updates, highlighting the importance of incorporating human evaluation in comment quality assessment.",
      "authors": [
        "Hua Ge",
        "Juan Zhai",
        "Minxue Pan",
        "Fusen He",
        "Ziyue Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:11:27+00:00",
          "link": "https://arxiv.org/abs/2507.08671v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "LLMCup: Ranking-Enhanced Comment Updating with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08671",
        "HTML": "https://arxiv.org/html/2507.08671v1",
        "PDF": "https://arxiv.org/pdf/2507.08671"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses comment updating in software projects using LLMs, with no focus on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07532",
      "abstract": "While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI.",
      "authors": [
        "Berkant Turan",
        "Suhrab Asadulla",
        "David Steinmann",
        "Wolfgang Stammer",
        "Sebastian Pokutta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:28:46+00:00",
          "link": "https://arxiv.org/abs/2507.07532v1",
          "size": "675kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T10:29:39+00:00",
          "link": "https://arxiv.org/abs/2507.07532v2",
          "size": "675kb",
          "version": "v2"
        }
      ],
      "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07532",
        "HTML": "https://arxiv.org/html/2507.07532v2",
        "PDF": "https://arxiv.org/pdf/2507.07532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses using Neural Concept Verifier frameworks for nonlinear classification and interpretable concepts, but does not focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07930",
      "abstract": "Background: Public speaking is a vital professional skill, yet it remains a source of significant anxiety for many individuals. Traditional training relies heavily on expert coaching, but recent advances in AI has led to novel types of commercial automated public speaking feedback tools. However, most research has focused on prototypes rather than commercial applications, and little is known about how public speaking experts perceive these tools.\n  Objectives: This study aims to evaluate expert opinions on the efficacy and design of commercial AI-based public speaking training tools and to propose guidelines for their improvement.\n  Methods: The research involved 16 semi-structured interviews and 2 focus groups with public speaking experts. Participants discussed their views on current commercial tools, their potential integration into traditional coaching, and suggestions for enhancing these systems.\n  Results and Conclusions: Experts acknowledged the value of AI tools in handling repetitive, technical aspects of training, allowing coaches to focus on higher-level skills. However they found key issues in current tools, emphasising the need for personalised, understandable, carefully selected feedback and clear instructional design. Overall, they supported a hybrid model combining traditional coaching with AI-supported exercises.",
      "authors": [
        "Nesrine Fourati",
        "Alisa Barkar",
        "Marion Drag\\'ee",
        "Liv Danthon-Lefebvre",
        "Mathieu Chollet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:09:21+00:00",
          "link": "https://arxiv.org/abs/2507.07930v1",
          "size": "118kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T08:22:41+00:00",
          "link": "https://arxiv.org/abs/2507.07930v2",
          "size": "118kb",
          "version": "v2"
        }
      ],
      "title": "Probing Experts' Perspectives on AI-Assisted Public Speaking Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07930",
        "HTML": "https://arxiv.org/html/2507.07930v2",
        "PDF": "https://arxiv.org/pdf/2507.07930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI tools for public speaking feedback but focuses on expert opinions and tool design rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08064",
      "abstract": "As multimedia content expands, the demand for unified multimodal retrieval (UMR) in real-world applications increases. Recent work leverages multimodal large language models (MLLMs) to tackle this task. However, their large parameter size results in high training costs and low inference efficiency. To address this, we propose PUMA: a Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning. Our approach improves UMR from both structural and learning perspectives. (1) Structurally, we propose Layer-Pruned Self-Distillation, which prunes MLLMs by keeping only shallow layers while distilling features from dropped deep layers as teacher signals. This reduces parameters and preserves representation capability. (2) On the learning side, we introduce Modality-Adaptive Contrastive Learning Loss (MAC-Loss), which separates in-batch negatives into harder intra-modality and easier inter-modality groups based on the target modality, assigning different temperature strategies to enhance learning efficiency. Experiments show our method significantly reduces resource usage while maintaining strong performance.",
      "authors": [
        "Yibo Lyu",
        "Rui Shao",
        "Gongwei Chen",
        "Yijie Zhu",
        "Weili Guan",
        "Liqiang Nie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:47:25+00:00",
          "link": "https://arxiv.org/abs/2507.08064v1",
          "size": "8510kb",
          "version": "v1"
        }
      ],
      "title": "PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08064",
        "HTML": "https://arxiv.org/html/2507.08064v1",
        "PDF": "https://arxiv.org/pdf/2507.08064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on improving multimodal retrieval efficiency through a language model architecture and learning techniques; it does not primarily address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08068",
      "abstract": "Aligning large language models with pointwise absolute rewards has so far required online, on-policy algorithms such as PPO and GRPO. In contrast, simpler methods that can leverage offline or off-policy data, such as DPO and REBEL, are limited to learning from preference pairs or relative signals. To bridge this gap, we introduce \\emph{Quantile Reward Policy Optimization} (QRPO), which learns from pointwise absolute rewards while preserving the simplicity and offline applicability of DPO-like methods. QRPO uses quantile rewards to enable regression to the closed-form solution of the KL-regularized RL objective. This reward yields an analytically tractable partition function, removing the need for relative signals to cancel this term. Moreover, QRPO scales with increased compute to estimate quantile rewards, opening a new dimension for pre-computation scaling. Empirically, QRPO consistently achieves top performance on chat and coding evaluations -- reward model scores, AlpacaEval 2, and LeetCode -- compared to DPO, REBEL, and SimPO across diverse datasets and 8B-scale models. Finally, we find that training with robust rewards instead of converting them to preferences induces less length bias.",
      "authors": [
        "Simon Matrenok",
        "Skander Moalla",
        "Caglar Gulcehre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:56:24+00:00",
          "link": "https://arxiv.org/abs/2507.08068v1",
          "size": "6082kb",
          "version": "v1"
        }
      ],
      "title": "Quantile Reward Policy Optimization: Alignment with Pointwise Regression and Exact Partition Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08068",
        "HTML": "https://arxiv.org/html/2507.08068v1",
        "PDF": "https://arxiv.org/pdf/2507.08068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a policy optimization method for aligning LLMs with rewards, focusing on optimization and evaluation techniques rather than data processing for training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08368",
      "abstract": "Parameter control and dynamic algorithm configuration study how to dynamically choose suitable configurations of a parametrized algorithm during the optimization process. Despite being an intensively researched topic in evolutionary computation, optimal control policies are known only for very few cases, limiting the development of automated approaches to achieve them.\n  With this work we propose four new benchmarks for which we derive optimal or close-to-optimal control policies. More precisely, we consider the optimization of the \\LeadingOnes function via RLS$_{k}$, a local search algorithm allowing for a dynamic choice of the mutation strength $k$. The benchmarks differ in which information the algorithm can exploit to set its parameters and to select offspring. In existing running time results, the exploitable information is typically limited to the quality of the current-best solution. In this work, we consider how additional information about the current state of the algorithm can help to make better choices of parameters, and how these choices affect the performance. Namely, we allow the algorithm to use information about the current \\OneMax value, and we find that it allows much better parameter choices, especially in marginal states. Although those states are rarely visited by the algorithm, such policies yield a notable speed-up in terms of expected runtime. This makes the proposed benchmarks a challenging, but promising testing ground for analysis of parameter control methods in rich state spaces and of their ability to find optimal policies by catching the performance improvements yielded by correct parameter choices.",
      "authors": [
        "Gianluca Covini",
        "Denis Antipov",
        "Carola Doerr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:31:48+00:00",
          "link": "https://arxiv.org/abs/2507.08368v1",
          "size": "473kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Parameter Control Policies with State Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08368",
        "HTML": "https://arxiv.org/html/2507.08368v1",
        "PDF": "https://arxiv.org/pdf/2507.08368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses parameter control policies in evolutionary computation, without addressing any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08501",
      "abstract": "Structured reasoning over natural language inputs remains a core challenge in artificial intelligence, as it requires bridging the gap between unstructured linguistic expressions and formal logical representations. In this paper, we propose a novel \\textbf{bi-level framework} that maps language to logic through a two-stage process: high-level task abstraction and low-level logic generation. At the upper level, a large language model (LLM) parses natural language queries into intermediate structured representations specifying the problem type, objectives, decision variables, and symbolic constraints. At the lower level, the LLM uses these representations to generate symbolic workflows or executable reasoning programs for accurate and interpretable decision making. The framework supports modular reasoning, enforces explicit constraints, and generalizes across domains such as mathematical problem solving, question answering, and logical inference. We further optimize the framework with an end-to-end {bi-level} optimization approach that jointly refines both the high-level abstraction and low-level logic generation stages. Experiments on multiple realistic reasoning benchmarks demonstrate that our approach significantly outperforms existing baselines in accuracy, with accuracy gains reaching as high as 40\\%. Moreover, the bi-level design enhances transparency and error traceability, offering a promising step toward trustworthy and systematic reasoning with LLMs.",
      "authors": [
        "Keying Yang",
        "Hao Wang",
        "Kai Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:24:09+00:00",
          "link": "https://arxiv.org/abs/2507.08501v1",
          "size": "421kb",
          "version": "v1"
        }
      ],
      "title": "From Language to Logic: A Bi-Level Framework for Structured Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08501",
        "HTML": "https://arxiv.org/html/2507.08501v1",
        "PDF": "https://arxiv.org/pdf/2507.08501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for structured reasoning using LLMs but does not focus on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08520",
      "abstract": "Occluded person re-identification aims to retrieve holistic images based on occluded ones. Existing methods often rely on aligning visible body parts, applying occlusion augmentation, or complementing missing semantics using holistic images. However, they face challenges in handling diverse occlusion scenarios not seen during training and the issue of feature contamination from holistic images. To address these limitations, we propose Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation (OGFR), which simultaneously mitigates these challenges. OGFR adopts a teacher-student distillation architecture that effectively incorporates diverse occlusion patterns into feature representation while transferring the purified discriminative holistic knowledge from the holistic to the occluded branch through reinforced knowledge distillation. Specifically, an Occlusion-Aware Vision Transformer is designed to leverage learnable occlusion pattern embeddings to explicitly model such diverse occlusion types, thereby guiding occlusion-aware robust feature representation. Moreover, we devise a Feature Erasing and Purification Module within the holistic branch, in which an agent is employed to identify low-quality patch tokens of holistic images that contain noisy negative information via deep reinforcement learning, and substitute these patch tokens with learnable embedding tokens to avoid feature contamination and further excavate identity-related discriminative clues. Afterward, with the assistance of knowledge distillation, the student branch effectively absorbs the purified holistic knowledge to precisely learn robust representation regardless of the interference of occlusions.",
      "authors": [
        "Yufei Zheng and Wenjun Wang and Wenjun Gan and Jiawei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:05:30+00:00",
          "link": "https://arxiv.org/abs/2507.08520v1",
          "size": "1328kb",
          "version": "v1"
        }
      ],
      "title": "Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08520",
        "HTML": "https://arxiv.org/html/2507.08520v1",
        "PDF": "https://arxiv.org/pdf/2507.08520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on occlusion-guided feature purification for person re-identification, using knowledge distillation, without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08759",
      "abstract": "We present a novel dependent linear type theory in which the multiplicity of some variable - i.e., the number of times the variable can be used in a program - can depend on other variables. This allows us to give precise resource annotations to many higher-order functions that cannot be adequately typed in any other system. Inspired by the Dialectica translation, our typing discipline is obtained by embedding linear logic into dependent type theory and specifying how the embedded logic interacts with the host theory. We can then use a standard natural numbers type to obtain a quantitative typing system with dependent multiplicities. We characterise the semantics for our theory as a combination of standard models of dependent type theory and linear logic. Our system can be added to any dependently typed language, which we demonstrate with an implementation in Agda.",
      "authors": [
        "Maximilian Dor\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:12:11+00:00",
          "link": "https://arxiv.org/abs/2507.08759v1",
          "size": "119kb",
          "version": "v1"
        }
      ],
      "title": "Dependent Multiplicities in Dependent Linear Type Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08759",
        "PDF": "https://arxiv.org/pdf/2507.08759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new type theory for precise resource annotations, but it does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08335",
      "abstract": "The Patent-Based Idea Generation task asks systems to turn real patents into product ideas viable within three years. We propose MK2, a prompt-centric pipeline: Gemini 2.5 drafts and iteratively edits a prompt, grafting useful fragments from weaker outputs; GPT-4.1 then uses this prompt to create one idea per patent, and an Elo loop judged by Qwen3-8B selects the best prompt-all without extra training data. Across three domains, two evaluator types, and six criteria, MK2 topped the automatic leaderboard and won 25 of 36 tests. Only the materials-chemistry track lagged, indicating the need for deeper domain grounding; yet, the results show that lightweight prompt engineering has already delivered competitive, commercially relevant ideation from patents.",
      "authors": [
        "Yuzheng Xu",
        "Tosho Hirasawa",
        "Seiya Kawano",
        "Shota Kato",
        "and Tadashi Kozuno"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:27:42+00:00",
          "link": "https://arxiv.org/abs/2507.08335v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "MK2 at PBIG Competition: A Prompt Generation Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08335",
        "HTML": "https://arxiv.org/html/2507.08335v1",
        "PDF": "https://arxiv.org/pdf/2507.08335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a prompt generation solution for ideation tasks, focusing on prompt engineering rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08379",
      "abstract": "Quantum Machine Learning (QML) represents a promising frontier at the intersection of quantum computing and artificial intelligence, aiming to leverage quantum computational advantages to enhance data-driven tasks. This review explores the potential of QML to address the computational bottlenecks of classical machine learning, particularly in processing complex datasets. We introduce the theoretical foundations of QML, including quantum data encoding, quantum learning theory and optimization techniques, while categorizing QML approaches based on data type and computational architecture. It is well-established that quantum computational advantages are problem-dependent, and so potentially useful directions for QML need to be systematically identified. Key developments, such as Quantum Principal Component Analysis, quantum-enhanced sensing and applications in material science, are critically evaluated for their theoretical speed-ups and practical limitations. The challenges posed by Noisy Intermediate-Scale Quantum (NISQ) devices, including hardware noise, scalability constraints and data encoding overheads, are discussed in detail. We also outline future directions, emphasizing the need for quantum-native algorithms, improved error correction, and realistic benchmarks to bridge the gap between theoretical promise and practical deployment. This comprehensive analysis underscores that while QML has significant potential for specific applications such as quantum chemistry and sensing, its broader utility in real-world scenarios remains contingent on overcoming technological and methodological hurdles.",
      "authors": [
        "Samarth Kashyap",
        "Rohit K Ramakrishnan",
        "Kumari Jyoti and Apoorva D Patel"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.08379v1",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "title": "Advances in Machine Learning: Where Can Quantum Techniques Help?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08379",
        "HTML": "https://arxiv.org/html/2507.08379v1",
        "PDF": "https://arxiv.org/pdf/2507.08379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Quantum Machine Learning and explores its theoretical foundations and challenges but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03631",
      "abstract": "Discovering governing equations that describe complex chaotic systems remains a fundamental challenge in physics and neuroscience. Here, we introduce the PEM-UDE method, which combines the prediction-error method with universal differential equations to extract interpretable mathematical expressions from chaotic dynamical systems, even with limited or noisy observations. This approach succeeds where traditional techniques fail by smoothing optimization landscapes and removing the chaotic properties during the fitting process without distorting optimal parameters. We demonstrate its efficacy by recovering hidden states in the Rossler system and reconstructing dynamics from noise-corrupted electrical circuit data, where the correct functional form of the dynamics is recovered even when one of the observed time series is corrupted by noise 5x the magnitude of the true signal. We demonstrate that this method is capable of recovering the correct dynamics, whereas direct symbolic regression methods, such as SINDy, fail to do so with the given amount of data and noise. Importantly, when applied to neural populations, our method derives novel governing equations that respect biological constraints such as network sparsity - a constraint necessary for cortical information processing yet not captured in next-generation neural mass models - while preserving microscale neuronal parameters. These equations predict an emergent relationship between connection density and both oscillation frequency and synchrony in neural circuits. We validate these predictions using three intracranial electrode recording datasets from the medial entorhinal cortex, prefrontal cortex, and orbitofrontal cortex. Our work provides a pathway to develop mechanistic, multi-scale brain models that generalize across diverse neural architectures, bridging the gap between single-neuron dynamics and macroscale brain activity.",
      "authors": [
        "Anthony G. Chesebro",
        "David Hofmann",
        "Vaibhav Dixit",
        "Earl K. Miller",
        "Richard H. Granger",
        "Alan Edelman",
        "Christopher V. Rackauckas",
        "Lilianne R. Mujica-Parodi",
        "and Helmut H. Strey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Chaotic Dynamics (nlin.CD)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T14:57:58+00:00",
          "link": "https://arxiv.org/abs/2507.03631v1",
          "size": "8723kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T21:26:10+00:00",
          "link": "https://arxiv.org/abs/2507.03631v2",
          "size": "8723kb",
          "version": "v2"
        }
      ],
      "title": "Scientific Machine Learning of Chaotic Systems Discovers Governing Equations for Neural Populations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03631",
        "HTML": "https://arxiv.org/html/2507.03631v2",
        "PDF": "https://arxiv.org/pdf/2507.03631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for discovering governing equations in chaotic systems and neural populations, focusing on physics and neuroscience modeling rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08716",
      "abstract": "Scaling laws have achieved success in LLM and foundation models. To explore their potential in ISAC research, we propose Great-X. This single-engine multimodal data twin platform reconstructs the ray-tracing computation of Sionna within Unreal Engine and is deeply integrated with autonomous driving tools. This enables efficient and synchronized simulation of multimodal data, including CSI, RGB, Radar, and LiDAR. Based on this platform, we construct an open-source, large-scale, low-altitude UAV multimodal synaesthesia dataset named Great-MSD, and propose a baseline CSI-based UAV 3D localization algorithm, demonstrating its feasibility and generalizability across different CSI simulation engines. The related code and dataset are publicly available at: https://github.com/hkw-xg/Great-MCD.",
      "authors": [
        "Kongwu Huang",
        "Shiyi Mu",
        "Jun Jiang",
        "Yuan Gao",
        "Shugong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:16:06+00:00",
          "link": "https://arxiv.org/abs/2507.08716v1",
          "size": "21175kb",
          "version": "v1"
        }
      ],
      "title": "Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08716",
        "HTML": "https://arxiv.org/html/2507.08716v1",
        "PDF": "https://arxiv.org/pdf/2507.08716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper details the creation of a multimodal dataset for UAV 3D localization and describes the data simulation process, thus making a significant contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08801",
      "abstract": "Autoregressive large language models (LLMs) have unified a vast range of language tasks, inspiring preliminary efforts in autoregressive video generation. Existing autoregressive video generators either diverge from standard LLM architectures, depend on bulky external text encoders, or incur prohibitive latency due to next-token decoding. In this paper, we introduce Lumos-1, an autoregressive video generator that retains the LLM architecture with minimal architectural modifications. To inject spatiotemporal correlations in LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its imbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE scheme that preserves the original textual RoPE while providing comprehensive frequency spectra and scaled 3D positions for modeling multimodal spatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy that obeys intra-frame bidirectionality and inter-frame temporal causality. Based on this dependency strategy, we identify the issue of frame-wise loss imbalance caused by spatial information redundancy and solve it by proposing Autoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal tube masking during training with a compatible inference-time masking policy to avoid quality degradation. By using memory-efficient training techniques, we pre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on GenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code and models are available at https://github.com/alibaba-damo-academy/Lumos.",
      "authors": [
        "Hangjie Yuan",
        "Weihua Chen",
        "Jun Cen",
        "Hu Yu",
        "Jingyun Liang",
        "Shuning Chang",
        "Zhihui Lin",
        "Tao Feng",
        "Pengwei Liu",
        "Jiazheng Xing",
        "Hao Luo",
        "Jiasheng Tang",
        "Fan Wang",
        "Yi Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.08801v1",
          "size": "13417kb",
          "version": "v1"
        }
      ],
      "title": "Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08801",
        "HTML": "https://arxiv.org/html/2507.08801v1",
        "PDF": "https://arxiv.org/pdf/2507.08801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on autoregressive video generation using existing LLM architectures, not on modifying or processing LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.01945",
      "abstract": "Contraction$^*$-depth is a matroid depth parameter analogous to tree-depth of graphs. We establish the matroid analogue of the classical graph theory result asserting that the tree-depth of a graph $G$ is the minimum height of a rooted forest whose closure contains $G$ by proving the following for every matroid $M$ (except the trivial case when $M$ consists of loops and coloops only): the contraction$^*$-depth of $M$ plus one is equal to the minimum contraction-depth of a matroid containing $M$ as a restriction.",
      "authors": [
        "Marcin Brianski and Daniel Kral and Ander Lamaison"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-03T14:35:59+00:00",
          "link": "https://arxiv.org/abs/2311.01945v1",
          "size": "138kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T05:18:27+00:00",
          "link": "https://arxiv.org/abs/2311.01945v2",
          "size": "151kb",
          "version": "v2"
        }
      ],
      "title": "Closure property of contraction-depth of matroids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.01945",
        "HTML": "https://arxiv.org/html/2311.01945v2",
        "PDF": "https://arxiv.org/pdf/2311.01945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a mathematical property related to matroids, specifically contraction-depth, without mentioning LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.09832",
      "abstract": "In this paper, assuming a natural strengthening of the low-degree conjecture, we provide evidence of computational hardness for two problems: (1) the (partial) matching recovery problem in the sparse correlated Erd\\H{o}s-R\\'enyi graphs $\\mathcal G(n,q;\\rho)$ when the edge-density $q=n^{-1+o(1)}$ and the correlation $\\rho<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{DDL23+}; (2) the detection problem between the correlated sparse stochastic block model $\\mathcal S(n,\\tfrac{\\lambda}{n};k,\\epsilon;s)$ and a pair of independent stochastic block models $\\mathcal S(n,\\tfrac{\\lambda s}{n};k,\\epsilon)$ when $\\epsilon^2 \\lambda s<1$ lies below the Kesten-Stigum (KS) threshold and $s<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{CDGL24+}.\n  One of the main ingredient in our proof is to derive certain forms of \\emph{algorithmic contiguity} between two probability measures based on bounds on their low-degree advantage. To be more precise, consider the high-dimensional hypothesis testing problem between two probability measures $\\mathbb{P}$ and $\\mathbb{Q}$ based on the sample $\\mathsf Y$. We show that if the low-degree advantage $\\mathsf{Adv}_{\\leq D} \\big( \\frac{\\mathrm{d}\\mathbb{P}}{\\mathrm{d}\\mathbb{Q}} \\big)=O(1)$, then (assuming the low-degree conjecture) there is no efficient algorithm $\\mathcal A$ such that $\\mathbb{Q}(\\mathcal A(\\mathsf Y)=0)=1-o(1)$ and $\\mathbb{P}(\\mathcal A(\\mathsf Y)=1)=\\Omega(1)$. This framework provides a useful tool for performing reductions between different inference tasks.",
      "authors": [
        "Zhangsong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T00:24:51+00:00",
          "link": "https://arxiv.org/abs/2502.09832v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2025-04-20T00:32:19+00:00",
          "link": "https://arxiv.org/abs/2502.09832v2",
          "size": "36kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T01:56:58+00:00",
          "link": "https://arxiv.org/abs/2502.09832v3",
          "size": "37kb",
          "version": "v3"
        }
      ],
      "title": "Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09832",
        "HTML": "https://arxiv.org/html/2502.09832v3",
        "PDF": "https://arxiv.org/pdf/2502.09832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses computational hardness assumptions related to correlated random graphs and high-dimensional hypothesis testing, with no mention of LLM training data processing."
      },
      "tasks": [
        "Stochastic Block Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08153",
      "abstract": "Traffic accidents are rare, yet high-impact events that require long-context multimodal reasoning for accurate risk forecasting. In this paper, we introduce ALCo-FM, a unified adaptive long-context foundation model that computes a volatility pre-score to dynamically select context windows for input data and encodes and fuses these multimodal data via shallow cross attention. Following a local GAT layer and a BigBird-style sparse global transformer over H3 hexagonal grids, coupled with Monte Carlo dropout for confidence, the model yields superior, well-calibrated predictions. Trained on data from 15 US cities with a class-weighted loss to counter label imbalance, and fine-tuned with minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in large-scale urban risk prediction. Code and dataset are available at: https://github.com/PinakiPrasad12/ALCo-FM",
      "authors": [
        "Pinaki Prasad Guha Neogi",
        "Ahmad Mohammadshirazi",
        "Rajiv Ramnath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:22:26+00:00",
          "link": "https://arxiv.org/abs/2507.08153v1",
          "size": "1481kb",
          "version": "v1"
        }
      ],
      "title": "ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08153",
        "HTML": "https://arxiv.org/html/2507.08153v1",
        "PDF": "https://arxiv.org/pdf/2507.08153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper outlines the development of a model for urban risk prediction, focusing on adaptive long-context models and evaluation, without discussing explicit LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08603",
      "abstract": "End-to-end Large Speech Language Models~(\\textbf{LSLMs}) demonstrate strong potential in response latency and speech comprehension capabilities, showcasing general intelligence across speech understanding tasks. However, the ability to follow speech instructions has not been fully realized due to the lack of datasets and heavily biased training tasks. Leveraging the rich ASR datasets, previous approaches have used Large Language Models~(\\textbf{LLMs}) to continue the linguistic information of speech to construct speech instruction datasets. Yet, due to the gap between LLM-generated results and real human responses, the continuation methods further amplify these shortcomings. Given the high costs of collecting and annotating speech instruction datasets by humans, using speech synthesis to construct large-scale speech instruction datasets has become a balanced and robust alternative. Although modern Text-To-Speech~(\\textbf{TTS}) models have achieved near-human-level synthesis quality, it is challenging to appropriately convert out-of-distribution text instruction to speech due to the limitations of the training data distribution in TTS models. To address this issue, we propose a query rewriting framework with multi-LLM knowledge fusion, employing multiple agents to annotate and validate the synthesized speech, making it possible to construct high-quality speech instruction datasets without relying on human annotation. Experiments show that this method can transform text instructions into distributions more suitable for TTS models for speech synthesis through zero-shot rewriting, increasing data usability from 72\\% to 93\\%. It also demonstrates unique advantages in rewriting tasks that require complex knowledge and context-related abilities.",
      "authors": [
        "Yonghua Hei",
        "Yibo Yan",
        "Shuliang Liu",
        "Huiyu Zhou",
        "Linfeng Zhang",
        "Xuming Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:55:45+00:00",
          "link": "https://arxiv.org/abs/2507.08603v1",
          "size": "2744kb",
          "version": "v1"
        }
      ],
      "title": "Unlocking Speech Instruction Data Potential with Query Rewriting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08603",
        "HTML": "https://arxiv.org/html/2507.08603v1",
        "PDF": "https://arxiv.org/pdf/2507.08603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution involves creating high-quality speech instruction datasets using query rewriting and multi-LLM knowledge fusion, thereby focusing directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08696",
      "abstract": "Guessing random additive noise decoding (GRAND) is a universal decoding paradigm that decodes by repeatedly testing error patterns until identifying a codeword, where the ordering of tests is generated by the received channel values. On one hand, while testing error patterns in a descending order of posterior probabilities leads to maximum likelihood decoding, its implementation complexity is prohibitive. On the other hand, testing error patterns with a prescribed set of error patterns permuted by the ranking among magnitudes of log-likelihood ratios (i.e., ordered reliability bits, ORB) enables efficient implementation, but results in performance loss for finite-length codes. Aiming at harnessing the strengths of these two approaches, this work proposes a fine-tuning method to improve ORBGRAND, adjusting the ordering of tests with the aid of very few exact channel soft values. This method is based on a metric for assessing the ``well-orderedness'' of error patterns. The metric is studied via the lens of the asymptotic theory of integer partitioning, which provides highly accurate estimation in numerical experiments. The metric then leads to an effective identification of fine-tuning to conduct, at the cost of a negligible increment of complexity. Numerical experiments demonstrate that the proposed fine-tuning method achieves a substantial performance enhancement compared with ORBGRAND.",
      "authors": [
        "Li Wan",
        "Huarui Yin",
        "Wenyi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:49:49+00:00",
          "link": "https://arxiv.org/abs/2507.08696v1",
          "size": "301kb",
          "version": "v1"
        }
      ],
      "title": "Fine-tuning ORBGRAND with Very Few Channel Soft Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08696",
        "HTML": "https://arxiv.org/html/2507.08696v1",
        "PDF": "https://arxiv.org/pdf/2507.08696"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work discusses a fine-tuning method for decoding in error pattern testing and has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08104",
      "abstract": "Social media has amplified the reach of financial influencers known as \"finfluencers,\" who share stock recommendations on platforms like YouTube. Understanding their influence requires analyzing multimodal signals like tone, delivery style, and facial expressions, which extend beyond text-based financial analysis. We introduce VideoConviction, a multimodal dataset with 6,000+ expert annotations, produced through 457 hours of human effort, to benchmark multimodal large language models (MLLMs) and text-based large language models (LLMs) in financial discourse. Our results show that while multimodal inputs improve stock ticker extraction (e.g., extracting Apple's ticker AAPL), both MLLMs and LLMs struggle to distinguish investment actions and conviction--the strength of belief conveyed through confident delivery and detailed reasoning--often misclassifying general commentary as definitive recommendations. While high-conviction recommendations perform better than low-conviction ones, they still underperform the popular S\\&P 500 index fund. An inverse strategy--betting against finfluencer recommendations--outperforms the S\\&P 500 by 6.8\\% in annual returns but carries greater risk (Sharpe ratio of 0.41 vs. 0.65). Our benchmark enables a diverse evaluation of multimodal tasks, comparing model performance on both full video and segmented video inputs. This enables deeper advancements in multimodal financial research. Our code, dataset, and evaluation leaderboard are available under the CC BY-NC 4.0 license.",
      "authors": [
        "Michael Galarnyk",
        "Veer Kejriwal",
        "Agam Shah",
        "Yash Bhardwaj",
        "Nicholas Meyer",
        "Anand Krishnan",
        "Sudheer Chava"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T21:58:50+00:00",
          "link": "https://arxiv.org/abs/2507.08104v1",
          "size": "6126kb",
          "version": "v1"
        }
      ],
      "title": "VideoConviction: A Multimodal Benchmark for Human Conviction and Stock Market Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08104",
        "HTML": "https://arxiv.org/html/2507.08104v1",
        "PDF": "https://arxiv.org/pdf/2507.08104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new multimodal dataset for benchmarking but focuses on evaluating multimodal models for financial discourse rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08169",
      "abstract": "News outlets are well known to have political associations, and many national outlets cultivate political biases to cater to different audiences. Journalists working for these news outlets have a big impact on the stories they cover. In this work, we present a methodology to analyze the role of journalists, affiliated with popular news outlets, in propagating their bias using some form of propaganda-like language. We introduce JMBX(Journalist Media Bias on X), a systematically collected and annotated dataset of 1874 tweets from Twitter (now known as X). These tweets are authored by popular journalists from 10 news outlets whose political biases range from extreme left to extreme right. We extract several insights from the data and conclude that journalists who are affiliated with outlets with extreme biases are more likely to use propaganda-like language in their writings compared to those who are affiliated with outlets with mild political leans. We compare eight different Large Language Models (LLM) by OpenAI and Google. We find that LLMs generally performs better when detecting propaganda in social media and news article compared to BERT-based model which is fine-tuned for propaganda detection. While the performance improvements of using large language models (LLMs) are significant, they come at a notable monetary and environmental cost. This study provides an analysis of both the financial costs, based on token usage, and the environmental impact, utilizing tools that estimate carbon emissions associated with LLM operations.",
      "authors": [
        "Vivek Sharma",
        "Mohammad Mahdi Shokri",
        "Sarah Ita Levitan",
        "Elena Filatova",
        "Shweta Jain"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:00:29+00:00",
          "link": "https://arxiv.org/abs/2507.08169v1",
          "size": "813kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of Propaganda in Tweets From Politically Biased Sources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08169",
        "HTML": "https://arxiv.org/html/2507.08169v1",
        "PDF": "https://arxiv.org/pdf/2507.08169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of LLMs in detecting propaganda but does not involve processing or modifying LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08320",
      "abstract": "The increasing energy footprint of artificial intelligence systems urges alternative computational models that are both efficient and scalable. Neuromorphic Computing (NC) addresses this challenge by empowering event-driven algorithms that operate with minimal power requirements through biologically inspired spiking dynamics. We present the NeurOptimiser, a fully spike-based optimisation framework that materialises the neuromorphic-based metaheuristic paradigm through a decentralised NC system. The proposed approach comprises a population of Neuromorphic Heuristic Units (NHUs), each combining spiking neuron dynamics with spike-triggered perturbation heuristics to evolve candidate solutions asynchronously. The NeurOptimiser's coordination arises through native spiking mechanisms that support activity propagation, local information sharing, and global state updates without external orchestration. We implement this framework on Intel's Lava platform, targeting the Loihi 2 chip, and evaluate it on the noiseless BBOB suite up to 40 dimensions. We deploy several NeurOptimisers using different configurations, mainly considering dynamic systems such as linear and Izhikevich models for spiking neural dynamics, and fixed and Differential Evolution mutation rules for spike-triggered heuristics. Although these configurations are implemented as a proof of concept, we document and outline further extensions and improvements to the framework implementation. Results show that the proposed approach exhibits structured population dynamics, consistent convergence, and milliwatt-level power feasibility. They also position spike-native MHs as a viable path toward real-time, low-energy, and decentralised optimisation.",
      "authors": [
        "Jorge Mario Cruz-Duarte",
        "El-Ghazali Talbi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:18:13+00:00",
          "link": "https://arxiv.org/abs/2507.08320v1",
          "size": "26508kb",
          "version": "v1"
        }
      ],
      "title": "NeurOptimisation: The Spiking Way to Evolve",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08320",
        "HTML": "https://arxiv.org/html/2507.08320v1",
        "PDF": "https://arxiv.org/pdf/2507.08320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a spiking neural optimization framework, focusing on neuromorphic computing, which does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05640",
      "abstract": "In this paper, we describe a parameterized quantum circuit that can be considered as convolutional and pooling layers for graph neural networks. The circuit incorporates the parameterized quantum Fourier circuit where the qubit connections for the controlled gates derived from the Laplacian operator. Specifically, we show that the eigenspace of the Laplacian operator of a graph can be approximated by using QFT based circuit whose connections are determined from the adjacency matrix. For an $N\\times N$ Laplacian, this approach yields an approximate polynomial-depth circuit requiring only $n=log(N)$ qubits. These types of circuits can eliminate the expensive classical computations for approximating the learnable functions of the Laplacian through Chebyshev polynomial or Taylor expansions.\n  Using this circuit as a convolutional layer provides an $n-$ dimensional probability vector that can be considered as the filtered and compressed graph signal. Therefore, the circuit along with the measurement can be considered a very efficient convolution plus pooling layer that transforms an $N$-dimensional signal input into $n-$dimensional signal with an exponential compression. We then apply a classical neural network prediction head to the output of the circuit to construct a complete graph neural network. Since the circuit incorporates geometric structure through its graph connection-based approach, we present graph classification results for the benchmark datasets listed in TUDataset library. Using only [1-100] learnable parameters for the quantum circuit and minimal classical layers (1000-5000 parameters) in a generic setting, the obtained results are comparable to and in some cases better than many of the baseline results, particularly for the cases when geometric structure plays a significant role.",
      "authors": [
        "Ammar Daskin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:36:40+00:00",
          "link": "https://arxiv.org/abs/2507.05640v1",
          "size": "775kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.05640v2",
          "size": "775kb",
          "version": "v2"
        }
      ],
      "title": "Learnable quantum spectral filters for hybrid graph neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05640",
        "HTML": "https://arxiv.org/html/2507.05640v2",
        "PDF": "https://arxiv.org/pdf/2507.05640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes quantum circuit techniques for implementing graph neural networks, with no focus on data engineering processes for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08036",
      "abstract": "Medical Visual Question Answering (MedVQA) is a promising tool to assist radiologists by automating medical image interpretation through question answering. Despite advances in models and datasets, MedVQA's integration into clinical workflows remains limited. This study systematically reviews 68 publications (2018-2024) and surveys 50 clinicians from India and Thailand to examine MedVQA's practical utility, challenges, and gaps. Following the Arksey and O'Malley scoping review framework, we used a two-pronged approach: (1) reviewing studies to identify key concepts, advancements, and research gaps in radiology workflows, and (2) surveying clinicians to capture their perspectives on MedVQA's clinical relevance. Our review reveals that nearly 60% of QA pairs are non-diagnostic and lack clinical relevance. Most datasets and models do not support multi-view, multi-resolution imaging, EHR integration, or domain knowledge, features essential for clinical diagnosis. Furthermore, there is a clear mismatch between current evaluation metrics and clinical needs. The clinician survey confirms this disconnect: only 29.8% consider MedVQA systems highly useful. Key concerns include the absence of patient history or domain knowledge (87.2%), preference for manually curated datasets (51.1%), and the need for multi-view image support (78.7%). Additionally, 66% favor models focused on specific anatomical regions, and 89.4% prefer dialogue-based interactive systems. While MedVQA shows strong potential, challenges such as limited multimodal analysis, lack of patient context, and misaligned evaluation approaches must be addressed for effective clinical integration.",
      "authors": [
        "Deepali Mishra",
        "Chaklam Silpasuwanchai",
        "Ashutosh Modi",
        "Madhumita Sushil",
        "Sorayouth Chumnanvej"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:51:20+00:00",
          "link": "https://arxiv.org/abs/2507.08036v1",
          "size": "7151kb",
          "version": "v1"
        }
      ],
      "title": "Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08036",
        "PDF": "https://arxiv.org/pdf/2507.08036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews integration challenges of MedVQA into radiology workflows and discusses clinical relevance and gaps, ignoring any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08135",
      "abstract": "Room Impulse Responses (RIRs) accurately characterize acoustic properties of indoor environments and play a crucial role in applications such as speech enhancement, speech recognition, and audio rendering in augmented reality (AR) and virtual reality (VR). Existing blind estimation methods struggle to achieve practical accuracy. To overcome this challenge, we propose the dynamic audio-room acoustic synthesis (DARAS) model, a novel deep learning framework that is explicitly designed for blind RIR estimation from monaural reverberant speech signals. First, a dedicated deep audio encoder effectively extracts relevant nonlinear latent space features. Second, the Mamba-based self-supervised blind room parameter estimation (MASS-BRPE) module, utilizing the efficient Mamba state space model (SSM), accurately estimates key room acoustic parameters and features. Third, the system incorporates a hybrid-path cross-attention feature fusion module, enhancing deep integration between audio and room acoustic features. Finally, our proposed dynamic acoustic tuning (DAT) decoder adaptively segments early reflections and late reverberation to improve the realism of synthesized RIRs. Experimental results, including a MUSHRA-based subjective listening study, demonstrate that DARAS substantially outperforms existing baseline models, providing a robust and effective solution for practical blind RIR estimation in real-world acoustic environments.",
      "authors": [
        "Chunxi Wang",
        "Maoshen Jia",
        "Wenyu Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:55:47+00:00",
          "link": "https://arxiv.org/abs/2507.08135v1",
          "size": "8191kb",
          "version": "v1"
        }
      ],
      "title": "DARAS: Dynamic Audio-Room Acoustic Synthesis for Blind Room Impulse Response Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08135",
        "HTML": "https://arxiv.org/html/2507.08135v1",
        "PDF": "https://arxiv.org/pdf/2507.08135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audio-room acoustic synthesis and blind room impulse response estimation, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08226",
      "abstract": "In this paper we introduce and analyze, for two and three dimensions, a finite element method to approximate the natural frequencies of a flow system governed by the Stokes-Brinkman equations. Here, the fluid presents the capability of being within a porous media. Taking advantage of the Stokes regularity results for the solution, and considering inf-sup stable families of finite elements, we prove convergence together with a priori and a posteriori error estimates for the eigenvalues and eigenfunctions with the aid of the compact operators theory. We report a series of numerical tests in order to confirm the developed theory.",
      "authors": [
        "Felipe Lepe and Gonzalo Rivera and Jesus Vellojin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:22:21+00:00",
          "link": "https://arxiv.org/abs/2507.08226v1",
          "size": "32140kb",
          "version": "v1"
        }
      ],
      "title": "A Stokes-Brinkman-type formulation for the eigenvalue problem in porous media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08226",
        "HTML": "https://arxiv.org/html/2507.08226v1",
        "PDF": "https://arxiv.org/pdf/2507.08226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a finite element method for fluid dynamics in porous media. It doesn't involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08658",
      "abstract": "A new set of hardware merge sort devices are introduced here, which merge multiple sorted input lists into a single sorted output list in a fast and efficient manner. In each merge sorter, the values from the sorted input lists are arranged in an input 2-D setup array, but with the order of each sorted input list offset from the order of each of the other sorted input lists. In these new devices, called List Offset Merge Sorters (LOMS), a minimal set of column sort stages alternating with row sort stages process the input setup array into a final output array, now in the defined sorted order. LOMS 2-way sorters, which merge 2 sorted input lists, require only 2 merge stages and are significantly faster than Kenneth Batcher's previous state-of-the-art 2-way merge devices, Bitonic Merge Sorters and Odd-Even Merge Sorters. LOMS 2-way sorters utilize the recently-introduced Single-Stage 2-way Merge Sorters (S2MS) in their first stage. Both LOMS and S2MS devices can merge any mixture of input list sizes, while Batcher's merge sorters are difficult to design unless the 2 input lists are equal, and a power-of-2. By themselves, S2MS devices are the fastest 2-way merge sorters when implemented in this study's target FPGA devices, but they tend to use a large number of LUT resources. LOMS 2-way devices use fewer resources than comparable S2MS devices, enabling some large LOMS devices to be implemented in a given FPGA when comparable S2MS devices cannot fit in that FPGA. A List Offset 2-way sorter merges 2 lists, each with 32 values, into a sorted output list of those 64 values in 2.24 nS, a speedup of 2.63 versus a comparable Batcher device. A LOMS 3-way merge sorter, merging 3 sorted input lists with 7 values, fully merges the 21 values in 3.4 nS, a speedup of 1.36 versus the comparable state-of-the-art 3-way merge device.",
      "authors": [
        "Robert B. Kent and Marios S. Pattichis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Data Structures and Algorithms (cs.DS)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:00:21+00:00",
          "link": "https://arxiv.org/abs/2507.08658v1",
          "size": "3818kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Efficient Merge of Sorted Input Lists in Hardware Using List Offset Merge Sorters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08658",
        "HTML": "https://arxiv.org/html/2507.08658v1",
        "PDF": "https://arxiv.org/pdf/2507.08658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces hardware merge sort devices focused on efficient data merging, unrelated to LLM training data processing tasks like dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08710",
      "abstract": "We propose a novel embedding-based captioning metric termed as L-CLIPScore that can be used for efficiently evaluating caption quality and training captioning model. L-CLIPScore is calculated from a lightweight CLIP (L-CLIP), which is a dual-encoder architecture compressed and distilled from CLIP. To compress, we apply two powerful techniques which are weight multiplexing and matrix decomposition for reducing the parameters of encoders and word embedding matrix, respectively. To distill, we design a novel multi-modal Similarity Regulator (SR) loss to transfer more vision-language alignment knowledge. Specifically, SR loss amplifies the multi-modal embedding similarity if the given image-text pair is matched and diminishes the similarity if the pair is non-matched. By compressing and distilling by this novel SR loss, our L-CLIP achieves comparable multi-modal alignment ability to the original CLIP while it requires fewer computation resources and running time. We carry out exhaustive experiments to validate the efficiency and effectiveness of L-CLIPScore when using it as the judge to evaluate caption quality. We also discover that when using L-CLIPScore as the supervisor to train the captioning model, it should be mixed up by an n-gram-based metric and meanwhile analyze why using L-CLIPScore only will cause fail training.",
      "authors": [
        "Li Li",
        "Yingzhe Peng",
        "Xu Yang",
        "Ruoxi Cheng",
        "Haiyang Xu",
        "Ming Yan",
        "Fei Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:08:12+00:00",
          "link": "https://arxiv.org/abs/2507.08710v1",
          "size": "441kb",
          "version": "v1"
        }
      ],
      "title": "L-CLIPScore: a Lightweight Embedding-based Captioning Metric for Evaluating and Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08710",
        "HTML": "https://arxiv.org/html/2507.08710v1",
        "PDF": "https://arxiv.org/pdf/2507.08710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel evaluation metric for captioning but does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08239",
      "abstract": "Estimating the score function (or other population-density-dependent functions) is a fundamental component of most generative models. However, such function estimation is computationally and statistically challenging. Can we avoid function estimation for data generation? We propose an estimation-free generative method: A set of points whose locations are deterministically updated with (inverse) gradient descent can transport a uniform distribution to arbitrary data distribution, in the mean field regime, without function estimation, training neural networks, and even noise injection. The proposed method is built upon recent advances in the physics of interacting particles. We show, both theoretically and experimentally, that these advances can be leveraged to develop novel generative methods.",
      "authors": [
        "Hadi Daneshmand and Ashkan Soleymani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:51:12+00:00",
          "link": "https://arxiv.org/abs/2507.08239v1",
          "size": "1281kb",
          "version": "v1"
        }
      ],
      "title": "Data Generation without Function Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08239",
        "HTML": "https://arxiv.org/html/2507.08239v1",
        "PDF": "https://arxiv.org/pdf/2507.08239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a novel generative method without using function estimation, mentioning data generation processes but does not delve into LLM\u2011specific training data handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08306",
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs), particularly through Reinforcement Learning with Verifiable Rewards (RLVR), have significantly enhanced their reasoning abilities. However, a critical gap persists: these models struggle with dynamic spatial interactions, a capability essential for real-world applications. To bridge this gap, we introduce M2-Reasoning-7B, a model designed to excel in both general and spatial reasoning. Our approach integrates two key innovations: (1) a novel data pipeline that generates 294.2K high-quality data samples (168K for cold-start fine-tuning and 126.2K for RLVR), which feature logically coherent reasoning trajectories and have undergone comprehensive assessment; and (2) a dynamic multi-task training strategy with step-wise optimization to mitigate conflicts between data, and task-specific rewards for delivering tailored incentive signals. This combination of curated data and advanced training allows M2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks, showcasing superior performance in both general and spatial reasoning domains.",
      "authors": [
        "Inclusion AI: Fudong Wang",
        "Jiajia Liu",
        "Jingdong Chen",
        "Jun Zhou",
        "Kaixiang Ji",
        "Lixiang Ru",
        "Qingpei Guo",
        "Ruobing Zheng",
        "Tianqi Li",
        "Yi Yuan",
        "Yifan Mao",
        "Yuting Xiao",
        "Ziping Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:44:07+00:00",
          "link": "https://arxiv.org/abs/2507.08306v1",
          "size": "6342kb",
          "version": "v1"
        }
      ],
      "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08306",
        "PDF": "https://arxiv.org/pdf/2507.08306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a data pipeline generating high-quality data samples for MLLMs, detailing significant processing which improves data quality for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08460",
      "abstract": "F3-Net is a foundation model designed to overcome persistent challenges in clinical medical image segmentation, including reliance on complete multimodal inputs, limited generalizability, and narrow task specificity. Through flexible synthetic modality training, F3-Net maintains robust performance even in the presence of missing MRI sequences, leveraging a zero-image strategy to substitute absent modalities without relying on explicit synthesis networks, thereby enhancing real-world applicability. Its unified architecture supports multi-pathology segmentation across glioma, metastasis, stroke, and white matter lesions without retraining, outperforming CNN-based and transformer-based models that typically require disease-specific fine-tuning. Evaluated on diverse datasets such as BraTS 2021, BraTS 2024, and ISLES 2022, F3-Net demonstrates strong resilience to domain shifts and clinical heterogeneity. On the whole pathology dataset, F3-Net achieves average Dice Similarity Coefficients (DSCs) of 0.94 for BraTS-GLI 2024, 0.82 for BraTS-MET 2024, 0.94 for BraTS 2021, and 0.79 for ISLES 2022. This positions it as a versatile, scalable solution bridging the gap between deep learning research and practical clinical deployment.",
      "authors": [
        "Seyedeh Sahar Taheri Otaghsara",
        "Reza Rahmanzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:03:23+00:00",
          "link": "https://arxiv.org/abs/2507.08460v1",
          "size": "1581kb",
          "version": "v1"
        }
      ],
      "title": "F3-Net: Foundation Model for Full Abnormality Segmentation of Medical Images with Flexible Input Modality Requirement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08460",
        "HTML": "https://arxiv.org/html/2507.08460v1",
        "PDF": "https://arxiv.org/pdf/2507.08460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on medical image segmentation using a foundation model, F3-Net, but does not discuss any aspects of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08543",
      "abstract": "This paper considers the projection-free sparse convex optimization problem for the vector domain and the matrix domain, which covers a large number of important applications in machine learning and data science. For the vector domain $\\mathcal{D} \\subset \\mathbb{R}^d$, we propose two quantum algorithms for sparse constraints that finds a $\\varepsilon$-optimal solution with the query complexity of $O(\\sqrt{d}/\\varepsilon)$ and $O(1/\\varepsilon)$ by using the function value oracle, reducing a factor of $O(\\sqrt{d})$ and $O(d)$ over the best classical algorithm, respectively, where $d$ is the dimension. For the matrix domain $\\mathcal{D} \\subset \\mathbb{R}^{d\\times d}$, we propose two quantum algorithms for nuclear norm constraints that improve the time complexity to $\\tilde{O}(rd/\\varepsilon^2)$ and $\\tilde{O}(\\sqrt{r}d/\\varepsilon^3)$ for computing the update step, reducing at least a factor of $O(\\sqrt{d})$ over the best classical algorithm, where $r$ is the rank of the gradient matrix. Our algorithms show quantum advantages in projection-free sparse convex optimization problems as they outperform the optimal classical methods in dependence on the dimension $d$.",
      "authors": [
        "Jianhao He",
        "John C.S. Lui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:43:58+00:00",
          "link": "https://arxiv.org/abs/2507.08543v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Algorithms for Projection-Free Sparse Convex Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08543",
        "HTML": "https://arxiv.org/html/2507.08543v1",
        "PDF": "https://arxiv.org/pdf/2507.08543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum algorithms for sparse convex optimization, without discussing any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08624",
      "abstract": "This paper introduces the Ambient Intelligence Rehabilitation Support (AIRS) framework, an advanced artificial intelligence-based solution tailored for home rehabilitation environments. AIRS integrates cutting-edge technologies, including Real-Time 3D Reconstruction (RT-3DR), intelligent navigation, and large Vision-Language Models (VLMs), to create a comprehensive system for machine-guided physical rehabilitation. The general AIRS framework is demonstrated in rehabilitation scenarios following total knee replacement (TKR), utilizing a database of 263 video recordings for evaluation. A smartphone is employed within AIRS to perform RT-3DR of living spaces and has a body-matched avatar to provide visual feedback about the excercise. This avatar is necessary in (a) optimizing exercise configurations, including camera placement, patient positioning, and initial poses, and (b) addressing privacy concerns and promoting compliance with the AI Act. The system guides users through the recording process to ensure the collection of properly recorded videos. AIRS employs two feedback mechanisms: (i) visual 3D feedback, enabling direct comparisons between prerecorded clinical exercises and patient home recordings and (ii) VLM-generated feedback, providing detailed explanations and corrections for exercise errors. The framework also supports people with visual and hearing impairments. It also features a modular design that can be adapted to broader rehabilitation contexts. AIRS software components are available for further use and customization.",
      "authors": [
        "G\\'abor Baranyi",
        "Zsolt Csibi",
        "Kristian Fenech",
        "\\'Aron F\\'othi",
        "Zs\\'ofia Ga\\'al",
        "Joul Skaf",
        "Andr\\'as L\\H{o}rincz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:27:06+00:00",
          "link": "https://arxiv.org/abs/2507.08624v1",
          "size": "16053kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08624",
        "HTML": "https://arxiv.org/html/2507.08624v1",
        "PDF": "https://arxiv.org/pdf/2507.08624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for rehabilitation assistance using Ambient Intelligence but does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.22589",
      "abstract": "This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",
      "authors": [
        "Adam Breuer",
        "Bryce J. Dietrich",
        "Michael H. Crespin",
        "Matthew Butler",
        "J.A. Pryse",
        "and Kosuke Imai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T16:36:23+00:00",
          "link": "https://arxiv.org/abs/2503.22589v1",
          "size": "1064kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:59:47+00:00",
          "link": "https://arxiv.org/abs/2503.22589v2",
          "size": "626kb",
          "version": "v2"
        }
      ],
      "title": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22589",
        "HTML": "https://arxiv.org/html/2503.22589v2",
        "PDF": "https://arxiv.org/pdf/2503.22589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes by creating a large dataset of US presidential campaign advertisements and describes a pipeline that processes videos, which involves preparing, transcribing, and summarizing data, pertinent to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/adambreuer/ai-summarizevid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08371",
      "abstract": "Language models are prone to hallucination - generating text that is factually incorrect. Finetuning models on high-quality factual information can potentially reduce hallucination, but concerns remain; obtaining factual gold data can be expensive and training on correct but unfamiliar data may potentially lead to even more downstream hallucination. What data should practitioners finetune on to mitigate hallucinations in language models? In this work, we study the relationship between the factuality of finetuning data and the prevalence of hallucinations in long-form generation tasks. Counterintuitively, we find that finetuning on factual gold data is not as helpful as finetuning on model-generated data that models believe to be factual. Next, we evaluate filtering strategies applied on both factual gold data and model-generated data, and find that finetuning on model-generated data that is filtered by models' own internal judgments often leads to better overall factuality compared to other configurations: training on gold data filtered by models' judgments, training on gold data alone, or training on model-generated data that is supported by gold data. These factuality improvements transfer across three domains we study, suggesting that a models' own beliefs can provide a powerful signal for factuality.",
      "authors": [
        "Benjamin Newman",
        "Abhilasha Ravichander",
        "Jaehun Jung",
        "Rui Xin",
        "Hamish Ivison",
        "Yegor Kuznetsov",
        "Pang Wei Koh",
        "Yejin Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:34:34+00:00",
          "link": "https://arxiv.org/abs/2507.08371v1",
          "size": "1174kb",
          "version": "v1"
        }
      ],
      "title": "The Curious Case of Factuality Finetuning: Models' Internal Beliefs Can Improve Factuality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08371",
        "HTML": "https://arxiv.org/html/2507.08371v1",
        "PDF": "https://arxiv.org/pdf/2507.08371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on filtering strategies for finetuning data in order to improve factual quality in language models, specifically using model-generated data that models believe to be factual as a method to improve data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2210.07496",
      "abstract": "We address the maximum size of binary codes and binary constant weight codes with few distances. Previous works established a number of bounds for these quantities as well as the exact values for a range of small code lengths. As our main results, we determine the exact size of maximal binary codes with two distances for all lengths $n\\ge 6$ as well as the exact size of maximal binary constant weight codes with 2,3, and 4 distances for several values of the weight and for all but small lengths.",
      "authors": [
        "Alexander Barg",
        "Alexey Glazyrin",
        "Wei-Jiun Kao",
        "Ching-Yi Lai",
        "Pin-Chieh Tseng",
        "Wei-Hsuan Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-14T03:49:15+00:00",
          "link": "https://arxiv.org/abs/2210.07496v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "On the size of maximal binary codes with 2, 3, and 4 distances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.07496",
        "PDF": "https://arxiv.org/pdf/2210.07496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on determining the size of maximal binary codes and their properties, with no mention of LLM training data processing, collection, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02827",
      "abstract": "The primary objective of human activity recognition (HAR) is to infer ongoing human actions from sensor data, a task that finds broad applications in health monitoring, safety protection, and sports analysis. Despite proliferating research, HAR still faces key challenges, including the scarcity of labeled samples for rare activities, insufficient extraction of high-level features, and suboptimal model performance on lightweight devices. To address these issues, this paper proposes a comprehensive optimization approach centered on multi-attention interaction mechanisms. First, an unsupervised, statistics-guided diffusion model is employed to perform data augmentation, thereby alleviating the problems of labeled data scarcity and severe class imbalance. Second, a multi-branch spatio-temporal interaction network is designed, which captures multi-scale features of sequential data through parallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels. Simultaneously, temporal attention mechanisms are incorporated to identify critical time points, while spatial attention enhances inter-sensor interactions. A cross-branch feature fusion unit is further introduced to improve the overall feature representation capability. Finally, an adaptive multi-loss function fusion strategy is integrated, allowing for dynamic adjustment of loss weights and overall model optimization. Experimental results on three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the proposed unsupervised data augmentation spatio-temporal attention diffusion network (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively, significantly outperforming existing approaches. Furthermore, practical deployment on embedded devices verifies the efficiency and feasibility of the proposed method.",
      "authors": [
        "Hang Xiao",
        "Ying Yu",
        "Jiarui Li",
        "Zhifan Yang",
        "Haotian Tang",
        "Hanyu Liu",
        "Chao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:38:44+00:00",
          "link": "https://arxiv.org/abs/2507.02827v1",
          "size": "7511kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:13:39+00:00",
          "link": "https://arxiv.org/abs/2507.02827v2",
          "size": "6279kb",
          "version": "v2"
        }
      ],
      "title": "USAD: End-to-End Human Activity Recognition via Diffusion Model with Spatiotemporal Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02827",
        "HTML": "https://arxiv.org/html/2507.02827v2",
        "PDF": "https://arxiv.org/pdf/2507.02827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses a diffusion model for data augmentation in human activity recognition, which involves data processing but is not directly related to LLM training data preparation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08013",
      "abstract": "Recent advances in natural language processing (NLP) have been driven bypretrained language models like BERT, RoBERTa, T5, and GPT. Thesemodels excel at understanding complex texts, but biomedical literature, withits domain-specific terminology, poses challenges that models likeWord2Vec and bidirectional long short-term memory (Bi-LSTM) can't fullyaddress. GPT and T5, despite capturing context, fall short in tasks needingbidirectional understanding, unlike BERT. Addressing this, we proposedMedicalBERT, a pretrained BERT model trained on a large biomedicaldataset and equipped with domain-specific vocabulary that enhances thecomprehension of biomedical terminology. MedicalBERT model is furtheroptimized and fine-tuned to address diverse tasks, including named entityrecognition, relation extraction, question answering, sentence similarity, anddocument classification. Performance metrics such as the F1-score,accuracy, and Pearson correlation are employed to showcase the efficiencyof our model in comparison to other BERT-based models such as BioBERT,SciBERT, and ClinicalBERT. MedicalBERT outperforms these models onmost of the benchmarks, and surpasses the general-purpose BERT model by5.67% on average across all the tasks evaluated respectively. This work alsounderscores the potential of leveraging pretrained BERT models for medicalNLP tasks, demonstrating the effectiveness of transfer learning techniques incapturing domain-specific information.\n  (PDF) MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model. Available from: https://www.researchgate.net/publication/392489050_MedicalBERT_enhancing_biomedical_natural_language_processing_using_pretrained_BERT-based_model [accessed Jul 06 2025].",
      "authors": [
        "K. Sahit Reddy",
        "N. Ragavenderan",
        "Vasanth K.",
        "Ganesh N. Naik",
        "Vishalakshi Prabhu",
        "Nagaraja G. S"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T03:38:05+00:00",
          "link": "https://arxiv.org/abs/2507.08013v1",
          "size": "807kb",
          "version": "v1"
        }
      ],
      "title": "MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08013",
        "PDF": "https://arxiv.org/pdf/2507.08013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "MedicalBERT focuses on fine-tuning a pretrained model for biomedical NLP tasks, with no substantial contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13201",
      "abstract": "Flooding remains a major global challenge, worsened by climate change and urbanization, demanding advanced solutions for effective disaster management. While traditional 2D flood mapping techniques provide limited insights, 3D flood mapping, powered by deep learning (DL), offers enhanced capabilities by integrating flood extent and depth. This paper presents a comprehensive survey of deep learning-based 3D flood mapping, emphasizing its advancements over 2D maps by integrating flood extent and depth for effective disaster management and urban planning. The survey categorizes deep learning techniques into task decomposition and end-to-end approaches, applicable to both static and dynamic flood features. We compare key DL architectures, highlighting their respective roles in enhancing prediction accuracy and computational efficiency. Additionally, this work explores diverse data sources such as digital elevation models, satellite imagery, rainfall, and simulated data, outlining their roles in 3D flood mapping. The applications reviewed range from real-time flood prediction to long-term urban planning and risk assessment. However, significant challenges persist, including data scarcity, model interpretability, and integration with traditional hydrodynamic models. This survey concludes by suggesting future directions to address these limitations, focusing on enhanced datasets, improved models, and policy implications for flood management. This survey aims to guide researchers and practitioners in leveraging DL techniques for more robust and reliable 3D flood mapping, fostering improved flood management strategies.",
      "authors": [
        "Wenfeng Jia",
        "Bin Liang",
        "Yuxi Liu",
        "Muhammad Arif Khan",
        "Lihong Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T08:06:18+00:00",
          "link": "https://arxiv.org/abs/2506.13201v1",
          "size": "1036kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13201",
        "HTML": "https://arxiv.org/html/2506.13201",
        "PDF": "https://arxiv.org/pdf/2506.13201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses 3D flood mapping using deep learning techniques without focusing on LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Deep Learning",
        "Management",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08319",
      "abstract": "The construction of high-quality datasets is a cornerstone of modern text-to-speech (TTS) systems. However, the increasing scale of available data poses significant challenges, including storage constraints. To address these issues, we propose a TTS corpus construction method based on active learning. Unlike traditional feed-forward and model-agnostic corpus construction approaches, our method iteratively alternates between data collection and model training, thereby focusing on acquiring data that is more informative for model improvement. This approach enables the construction of a data-efficient corpus. Experimental results demonstrate that the corpus constructed using our method enables higher-quality speech synthesis than corpora of the same size.",
      "authors": [
        "Kentaro Seki",
        "Shinnosuke Takamichi",
        "Takaaki Saeki",
        "Hiroshi Saruwatari"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:11:03+00:00",
          "link": "https://arxiv.org/abs/2507.08319v1",
          "size": "2308kb",
          "version": "v1"
        }
      ],
      "title": "Active Learning for Text-to-Speech Synthesis with Informative Sample Collection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08319",
        "HTML": "https://arxiv.org/html/2507.08319v1",
        "PDF": "https://arxiv.org/pdf/2507.08319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a TTS corpus construction method using active learning to improve data quality and efficiency during model training, which directly relates to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.17256",
      "abstract": "Large language models (LLMs) are vulnerable to jailbreak attacks - resulting in harmful, unethical, or biased text generations. However, existing jailbreaking methods are computationally costly. In this paper, we propose the weak-to-strong jailbreaking attack, an efficient inference time attack for aligned LLMs to produce harmful text. Our key intuition is based on the observation that jailbroken and aligned models only differ in their initial decoding distributions. The weak-to-strong attack's key technical insight is using two smaller models (a safe and an unsafe one) to adversarially modify a significantly larger safe model's decoding probabilities. We evaluate the weak-to-strong attack on 5 diverse open-source LLMs from 3 organizations. The results show our method can increase the misalignment rate to over 99% on two datasets with just one forward pass per example. Our study exposes an urgent safety issue that needs to be addressed when aligning LLMs. As an initial attempt, we propose a defense strategy to protect against such attacks, but creating more advanced defenses remains challenging. The code for replicating the method is available at https://github.com/XuandongZhao/weak-to-strong",
      "authors": [
        "Xuandong Zhao",
        "Xianjun Yang",
        "Tianyu Pang",
        "Chao Du",
        "Lei Li",
        "Yu-Xiang Wang",
        "William Yang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-30T18:48:37+00:00",
          "link": "https://arxiv.org/abs/2401.17256v1",
          "size": "559kb",
          "version": "v1"
        },
        {
          "date": "2024-02-05T18:19:46+00:00",
          "link": "https://arxiv.org/abs/2401.17256v2",
          "size": "2147kb",
          "version": "v2"
        },
        {
          "date": "2025-06-12T17:32:02+00:00",
          "link": "https://arxiv.org/abs/2401.17256v3",
          "size": "277kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T16:36:46+00:00",
          "link": "https://arxiv.org/abs/2401.17256v4",
          "size": "277kb",
          "version": "v4"
        }
      ],
      "title": "Weak-to-Strong Jailbreaking on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.17256",
        "PDF": "https://arxiv.org/pdf/2401.17256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on jailbreaking attacks and safety issues in large language models without addressing training data collection, processing, or engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/xuandongzhao/weak-to-strong"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.15220",
      "abstract": "Quantitative mass spectrometry has revolutionized proteomics by enabling simultaneous quantification of thousands of proteins. Pooling patient-derived data from multiple institutions enhances statistical power but raises significant privacy concerns. Here we introduce FedProt, the first privacy-preserving tool for collaborative differential protein abundance analysis of distributed data, which utilizes federated learning and additive secret sharing. In the absence of a multicenter patient-derived dataset for evaluation, we created two, one at five centers from LFQ E.coli experiments and one at three centers from TMT human serum. Evaluations using these datasets confirm that FedProt achieves accuracy equivalent to DEqMS applied to pooled data, with completely negligible absolute differences no greater than $\\text{$4 \\times 10^{-12}$}$. In contrast, -log10(p-values) computed by the most accurate meta-analysis methods diverged from the centralized analysis results by up to 25-27. FedProt is available as a web tool with detailed documentation as a FeatureCloud App.",
      "authors": [
        "Yuliya Burankova",
        "Miriam Abele",
        "Mohammad Bakhtiari",
        "Christine von T\\\"orne",
        "Teresa Barth",
        "Lisa Schweizer",
        "Pieter Giesbertz",
        "Johannes R. Schmidt",
        "Stefan Kalkhof",
        "Janina M\\\"uller-Deile",
        "Peter A van Veelen",
        "Yassene Mohammed",
        "Elke Hammer",
        "Lis Arend",
        "Klaudia Adamowicz",
        "Tanja Laske",
        "Anne Hartebrodt",
        "Tobias Frisch",
        "Chen Meng",
        "Julian Matschinske",
        "Julian Sp\\\"ath",
        "Richard R\\\"ottger",
        "Veit Schw\\\"ammle",
        "Stefanie M. Hauck",
        "Stefan Lichtenthaler",
        "Axel Imhof",
        "Matthias Mann",
        "Christina Ludwig",
        "Bernhard Kuster",
        "Jan Baumbach",
        "Olga Zolotareva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-21T17:09:20+00:00",
          "link": "https://arxiv.org/abs/2407.15220v1",
          "size": "2506kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Multi-Center Differential Protein Abundance Analysis with FedProt",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.15220",
        "PDF": "https://arxiv.org/pdf/2407.15220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses privacy-preserving differential protein abundance analysis with FedProt using federated learning, with no focus on LLM training data processing."
      },
      "tasks": [
        "Federated Learning",
        "Privacy Preserving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08290",
      "abstract": "In recent years, continuous improvements in SAR resolution have significantly benefited applications such as urban monitoring and target detection. However, the improvement in resolution leads to increased discrepancies in scattering characteristics, posing challenges to the generalization ability of target detection models. While domain adaptation technology is a potential solution, the inevitable discrepancies caused by resolution differences often lead to blind feature adaptation and unreliable semantic propagation, ultimately degrading the domain adaptation performance. To address these challenges, this paper proposes a novel SAR target detection method (termed CR-Net), that incorporates structure priors and evidential learning theory into the detection model, enabling reliable domain adaptation for cross-resolution detection. To be specific, CR-Net integrates Structure-induced Hierarchical Feature Adaptation (SHFA) and Reliable Structural Adjacency Alignment (RSAA). SHFA module is introduced to establish structural correlations between targets and achieve structure-aware feature adaptation, thereby enhancing the interpretability of the feature adaptation process. Afterwards, the RSAA module is proposed to enhance reliable semantic alignment, by leveraging the secure adjacency set to transfer valuable discriminative knowledge from the source domain to the target domain. This further improves the discriminability of the detection model in the target domain. Based on experimental results from different-resolution datasets,the proposed CR-Net significantly enhances cross-resolution adaptation by preserving intra-domain structures and improving discriminability. It achieves state-of-the-art (SOTA) performance in cross-resolution SAR target detection.",
      "authors": [
        "Jiang Qin",
        "Bin Zou",
        "Haolin Li",
        "Lamei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:35:57+00:00",
          "link": "https://arxiv.org/abs/2507.08290v1",
          "size": "6952kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08290",
        "HTML": "https://arxiv.org/html/2507.08290v1",
        "PDF": "https://arxiv.org/pdf/2507.08290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on SAR target detection and domain adaptation, not on processing LLM training data or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08396",
      "abstract": "Subject-consistent generation (SCG)-aiming to maintain a consistent subject identity across diverse scenes-remains a challenge for text-to-image (T2I) models. Existing training-free SCG methods often achieve consistency at the cost of layout and pose diversity, hindering expressive visual storytelling. To address the limitation, we propose subject-Consistent and pose-Diverse T2I framework, dubbed as CoDi, that enables consistent subject generation with diverse pose and layout. Motivated by the progressive nature of diffusion, where coarse structures emerge early and fine details are refined later, CoDi adopts a two-stage strategy: Identity Transport (IT) and Identity Refinement (IR). IT operates in the early denoising steps, using optimal transport to transfer identity features to each target image in a pose-aware manner. This promotes subject consistency while preserving pose diversity. IR is applied in the later denoising steps, selecting the most salient identity features to further refine subject details. Extensive qualitative and quantitative results on subject consistency, pose diversity, and prompt fidelity demonstrate that CoDi achieves both better visual perception and stronger performance across all metrics. The code is provided in https://github.com/NJU-PCALab/CoDi.",
      "authors": [
        "Zhanxin Gao",
        "Beier Zhu",
        "Liang Yao",
        "Jian Yang",
        "Ying Tai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:15:56+00:00",
          "link": "https://arxiv.org/abs/2507.08396v1",
          "size": "37077kb",
          "version": "v1"
        }
      ],
      "title": "Subject-Consistent and Pose-Diverse Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08396",
        "HTML": "https://arxiv.org/html/2507.08396v1",
        "PDF": "https://arxiv.org/pdf/2507.08396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a text-to-image generation framework that deals with maintaining subject consistency and pose diversity, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2205.07249",
      "abstract": "Deep generative models have achieved tremendous success in designing novel drug molecules in recent years. A new thread of works have shown the great potential in advancing the specificity and success rate of in silico drug design by considering the structure of protein pockets. This setting posts fundamental computational challenges in sampling new chemical compounds that could satisfy multiple geometrical constraints imposed by pockets. Previous sampling algorithms either sample in the graph space or only consider the 3D coordinates of atoms while ignoring other detailed chemical structures such as bond types and functional groups. To address the challenge, we develop Pocket2Mol, an E(3)-equivariant generative network composed of two modules: 1) a new graph neural network capturing both spatial and bonding relationships between atoms of the binding pockets and 2) a new efficient algorithm which samples new drug candidates conditioned on the pocket representations from a tractable distribution without relying on MCMC. Experimental results demonstrate that molecules sampled from Pocket2Mol achieve significantly better binding affinity and other drug properties such as druglikeness and synthetic accessibility.",
      "authors": [
        "Xingang Peng",
        "Shitong Luo",
        "Jiaqi Guan",
        "Qi Xie",
        "Jian Peng",
        "Jianzhu Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-15T10:23:07+00:00",
          "link": "https://arxiv.org/abs/2205.07249v1",
          "size": "6360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:52:42+00:00",
          "link": "https://arxiv.org/abs/2205.07249v2",
          "size": "6161kb",
          "version": "v2"
        }
      ],
      "title": "Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.07249",
        "HTML": "https://arxiv.org/html/2205.07249v2",
        "PDF": "https://arxiv.org/pdf/2205.07249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on molecular sampling based on 3D protein pockets, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Drug Design",
        "Graph Neural Network",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/guanjq/targetdiff",
        "https://github.com/pengxingang/pocket2mol",
        "https://github.com/luost26/3d-generative-sbdd",
        "https://github.com/yanliang3612/nucleusdiff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17642",
      "abstract": "Large language model (LLM)-based AI delegates are increasingly utilized to act on behalf of users, assisting them with a wide range of tasks through conversational interfaces. Despite their advantages, concerns arise regarding the potential risk of privacy leaks, particularly in scenarios involving social interactions. While existing research has focused on protecting privacy by limiting the access of AI delegates to sensitive user information, many social scenarios require disclosing private details to achieve desired social goals, necessitating a balance between privacy protection and disclosure. To address this challenge, we first conduct a pilot study to investigate user perceptions of AI delegates across various social relations and task scenarios, and then propose a novel AI delegate system that enables privacy-conscious self-disclosure. Our user study demonstrates that the proposed AI delegate strategically protects privacy, pioneering its use in diverse and dynamic social interactions.",
      "authors": [
        "Zhiyang Zhang",
        "Xi Chen",
        "Fangkai Yang",
        "Xiaoting Qin",
        "Chao Du",
        "Xi Cheng",
        "Hangxin Liu",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T08:45:15+00:00",
          "link": "https://arxiv.org/abs/2409.17642v1",
          "size": "798kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T06:29:54+00:00",
          "link": "https://arxiv.org/abs/2409.17642v2",
          "size": "798kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T01:49:24+00:00",
          "link": "https://arxiv.org/abs/2409.17642v3",
          "size": "639kb",
          "version": "v3"
        }
      ],
      "title": "AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17642",
        "HTML": "https://arxiv.org/html/2409.17642v3",
        "PDF": "https://arxiv.org/pdf/2409.17642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI delegates with a focus on privacy and self-disclosure strategies in social interactions, not LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.24204",
      "abstract": "Recent 3D Gaussian Splatting (3DGS) representations have demonstrated remarkable performance in novel view synthesis; further, material-lighting disentanglement on 3DGS warrants relighting capabilities and its adaptability to broader applications. While the general approach to the latter operation lies in integrating differentiable physically-based rendering (PBR) techniques to jointly recover BRDF materials and environment lighting, achieving a precise disentanglement remains an inherently difficult task due to the challenge of accurately modeling light transport. Existing approaches typically approximate Gaussian points' normals, which constitute an implicit geometric constraint. However, they usually suffer from inaccuracies in normal estimation that subsequently degrade light transport, resulting in noisy material decomposition and flawed relighting results. To address this, we propose GeoSplatting, a novel approach that augments 3DGS with explicit geometry guidance for precise light transport modeling. By differentiably constructing a surface-grounded 3DGS from an optimizable mesh, our approach leverages well-defined mesh normals and the opaque mesh surface, and additionally facilitates the use of mesh-based ray tracing techniques for efficient, occlusion-aware light transport calculations. This enhancement ensures precise material decomposition while preserving the efficiency and high-quality rendering capabilities of 3DGS. Comprehensive evaluations across diverse datasets demonstrate the effectiveness of GeoSplatting, highlighting its superior efficiency and state-of-the-art inverse rendering performance. The project page can be found at https://pku-vcl-geometry.github.io/GeoSplatting/.",
      "authors": [
        "Kai Ye",
        "Chong Gao",
        "Guanbin Li",
        "Wenzheng Chen",
        "Baoquan Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T17:57:07+00:00",
          "link": "https://arxiv.org/abs/2410.24204v1",
          "size": "36143kb",
          "version": "v1"
        },
        {
          "date": "2024-11-01T16:31:22+00:00",
          "link": "https://arxiv.org/abs/2410.24204v2",
          "size": "36256kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T07:54:35+00:00",
          "link": "https://arxiv.org/abs/2410.24204v3",
          "size": "5791kb",
          "version": "v3"
        }
      ],
      "title": "GeoSplatting: Towards Geometry Guided Gaussian Splatting for Physically-based Inverse Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.24204",
        "HTML": "https://arxiv.org/html/2410.24204v3",
        "PDF": "https://arxiv.org/pdf/2410.24204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on geometry and light transport modeling in 3D Gaussian Splatting, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "3DGS",
        "Disentanglement",
        "Inverse Rendering",
        "Novel View Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01076",
      "abstract": "Small-step and big-step operational semantics are two fundamental styles of structural operational semantics (SOS), extensively used in practice. The former one is more fine-grained and is usually regarded as primitive, as it only defines a one-step reduction relation between a given program and its direct descendant under an ambient evaluation strategy. The latter one implements, in a self-contained manner, such a strategy directly by relating a program to the net result of the evaluation process. The agreement between these two styles of semantics is one of the key pillars in operational reasoning on programs; however, such agreement is typically proven from scratch every time on a case-by-case basis. A general, abstract mathematical argument behind this agreement is up till now missing. We cope with this issue within the framework of higher-order mathematical operational semantics by providing an abstract categorical notion of big-step SOS, complementing the existing notion of abstract higher-order GSOS. Moreover, we introduce a general construction for deriving the former from the latter, and prove an abstract equivalence result between the two.",
      "authors": [
        "Sergey Goncharov and Pouya Partow and Stelios Tsampas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-01T16:26:01+00:00",
          "link": "https://arxiv.org/abs/2506.01076v1",
          "size": "99kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T18:25:27+00:00",
          "link": "https://arxiv.org/abs/2506.01076v2",
          "size": "66kb",
          "version": "v2"
        }
      ],
      "title": "Big Steps in Higher-Order Mathematical Operational Semantics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01076",
        "PDF": "https://arxiv.org/pdf/2506.01076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical operational semantics, focusing on small-step and big-step operational semantics, without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08038",
      "abstract": "Autonomous agents built on language models (LMs) are showing increasing popularity in many fields, including scientific research. AI co-scientists aim to support or automate parts of the research process using these agents. A key component of empirical AI research is the design of ablation experiments. To this end, we introduce AblationBench, a benchmark suite for evaluating agents on ablation planning tasks in empirical AI research. It includes two tasks: AuthorAblation, which helps authors propose ablation experiments based on a method section and contains 83 instances, and ReviewerAblation, which helps reviewers find missing ablations in a full paper and contains 350 instances. For both tasks, we develop LM-based judges that serve as an automatic evaluation framework. Our experiments with frontier LMs show that these tasks remain challenging, with the best-performing LM system identifying only 29% of the original ablations on average. Lastly, we analyze the limitations of current LMs on these tasks, and find that chain-of-thought prompting outperforms the currently existing agent-based approach.",
      "authors": [
        "Talor Abramovich and Gal Chechik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:07:38+00:00",
          "link": "https://arxiv.org/abs/2507.08038v1",
          "size": "1760kb",
          "version": "v1"
        }
      ],
      "title": "AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08038",
        "PDF": "https://arxiv.org/pdf/2507.08038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a benchmark for evaluating automated planning tasks, including data support for ablation experiments, but its primary focus is not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08045",
      "abstract": "Efficient state restoration in multi-turn conversations with large language models (LLMs) remains a critical challenge, primarily due to the overhead of recomputing or loading full key-value (KV) caches for all historical tokens. To address this, existing approaches compress KV caches across adjacent layers with highly similar attention patterns. However, these methods often apply a fixed compression scheme across all conversations, selecting the same layer pairs for compression without considering conversation-specific attention dynamics. This static strategy overlooks variability in attention pattern similarity across different conversations, which can lead to noticeable accuracy degradation.\n  We present Krul, a multi-turn LLM inference system that enables accurate and efficient KV cache restoration. Krul dynamically selects compression strategies based on attention similarity across layer pairs and uses a recomputation-loading pipeline to restore the KV cache. It introduces three key innovations: 1) a preemptive compression strategy selector to preserve critical context for future conversation turns and selects a customized strategy for the conversation; 2) a token-wise heterogeneous attention similarity estimator to mitigate the attention similarity computation and storage overhead during model generation; 3) a bubble-free restoration scheduler to reduce potential bubbles brought by the imbalance of recomputing and loading stream due to compressed KV caches. Empirical evaluations on real-world tasks demonstrate that Krul achieves a 1.5x-2.68x reduction in time-to-first-token (TTFT) and a 1.33x-2.35x reduction in KV cache storage compared to state-of-the-art methods without compromising generation quality.",
      "authors": [
        "Junyi Wen and Junyuan Liang and Zicong Hong and Wuhui Chen and Zibin Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:51:17+00:00",
          "link": "https://arxiv.org/abs/2507.08045v1",
          "size": "846kb",
          "version": "v1"
        }
      ],
      "title": "Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08045",
        "HTML": "https://arxiv.org/html/2507.08045v1",
        "PDF": "https://arxiv.org/pdf/2507.08045"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on efficient state restoration for LLM inference in multi-turn conversations, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08644",
      "abstract": "Multi-view camera-based 3D perception can be conducted using bird's eye view (BEV) features obtained through perspective view-to-BEV transformations. Several studies have shown that the performance of these 3D perception methods can be further enhanced by combining sequential BEV features obtained from multiple camera frames. However, even after compensating for the ego-motion of an autonomous agent, the performance gain from temporal aggregation is limited when combining a large number of image frames. This limitation arises due to dynamic changes in BEV features over time caused by object motion. In this paper, we introduce a novel temporal 3D perception method called OnlineBEV, which combines BEV features over time using a recurrent structure. This structure increases the effective number of combined features with minimal memory usage. However, it is critical to spatially align the features over time to maintain strong performance. OnlineBEV employs the Motion-guided BEV Fusion Network (MBFNet) to achieve temporal feature alignment. MBFNet extracts motion features from consecutive BEV frames and dynamically aligns historical BEV features with current ones using these motion features. To enforce temporal feature alignment explicitly, we use Temporal Consistency Learning Loss, which captures discrepancies between historical and target BEV features. Experiments conducted on the nuScenes benchmark demonstrate that OnlineBEV achieves significant performance gains over the current best method, SOLOFusion. OnlineBEV achieves 63.9% NDS on the nuScenes test set, recording state-of-the-art performance in the camera-only 3D object detection task.",
      "authors": [
        "Junho Koh",
        "Youngwoo Lee",
        "Jungho Kim",
        "Dongyoung Lee",
        "Jun Won Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:48:59+00:00",
          "link": "https://arxiv.org/abs/2507.08644v1",
          "size": "19727kb",
          "version": "v1"
        }
      ],
      "title": "OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08644",
        "HTML": "https://arxiv.org/html/2507.08644v1",
        "PDF": "https://arxiv.org/pdf/2507.08644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on improving 3D perception from multi-camera images using BEV features and temporal fusion techniques, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03190",
      "abstract": "Algorithms are the engine for reproducible problem-solving. We present a framework automating algorithm discovery by conceptualizing them as sequences of operations, represented as tokens. These computational tokens are chained using a grammar, enabling the formation of increasingly sophisticated procedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement learning (RL) explores token chaining and drives the creation of new tokens. This methodology rediscovers, improves, and generates new algorithms that substantially outperform existing methods for strongly NP-hard combinatorial optimization problems and foundational quantum computing approaches such as Grover's and Quantum Approximate Optimization Algorithm. Operating at the computational rather than code-generation level, our framework produces algorithms that can be tailored specifically to problem instances, not merely classes.",
      "authors": [
        "Theo Bourdais",
        "Abeynaya Gnanasekaran",
        "Houman Owhadi",
        "Tuhin Sahai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T21:45:17+00:00",
          "link": "https://arxiv.org/abs/2507.03190v1",
          "size": "3405kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:55:14+00:00",
          "link": "https://arxiv.org/abs/2507.03190v2",
          "size": "3404kb",
          "version": "v2"
        }
      ],
      "title": "Discovering Algorithms with Computational Language Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03190",
        "PDF": "https://arxiv.org/pdf/2507.03190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a framework for algorithm discovery, focusing on computational tokens and algorithm generation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08137",
      "abstract": "We introduce a novel framework for reconstructing dynamic human-object interactions from monocular video that overcomes challenges associated with occlusions and temporal inconsistencies. Traditional 3D reconstruction methods typically assume static objects or full visibility of dynamic subjects, leading to degraded performance when these assumptions are violated-particularly in scenarios where mutual occlusions occur. To address this, our framework leverages amodal completion to infer the complete structure of partially obscured regions. Unlike conventional approaches that operate on individual frames, our method integrates temporal context, enforcing coherence across video sequences to incrementally refine and stabilize reconstructions. This template-free strategy adapts to varying conditions without relying on predefined models, significantly enhancing the recovery of intricate details in dynamic scenes. We validate our approach using 3D Gaussian Splatting on challenging monocular videos, demonstrating superior precision in handling occlusions and maintaining temporal stability compared to existing techniques.",
      "authors": [
        "Hyungjun Doh",
        "Dong In Lee",
        "Seunggeun Chi",
        "Pin-Hao Huang",
        "Kwonjoon Lee",
        "Sangpil Kim",
        "Karthik Ramani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:56:10+00:00",
          "link": "https://arxiv.org/abs/2507.08137v1",
          "size": "27876kb",
          "version": "v1"
        }
      ],
      "title": "Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08137",
        "HTML": "https://arxiv.org/html/2507.08137v1",
        "PDF": "https://arxiv.org/pdf/2507.08137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for reconstructing dynamic human-object interactions from monocular video, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08362",
      "abstract": "Efficient planning, resource management, and consistent operations often rely on converting textual process documents into formal Business Process Model and Notation (BPMN) models. However, this conversion process remains time-intensive and costly. Existing approaches, whether rule-based or machine-learning-based, still struggle with writing styles and often fail to identify parallel structures in process descriptions.\n  This paper introduces an automated pipeline for extracting BPMN models from text, leveraging the use of machine learning and large language models. A key contribution of this work is the introduction of a newly annotated dataset, which significantly enhances the training process. Specifically, we augment the PET dataset with 15 newly annotated documents containing 32 parallel gateways for model training, a critical feature often overlooked in existing datasets. This addition enables models to better capture parallel structures, a common but complex aspect of process descriptions. The proposed approach demonstrates adequate performance in terms of reconstruction accuracy, offering a promising foundation for organizations to accelerate BPMN model creation.",
      "authors": [
        "Phuong Nam L\\^e and Charlotte Schneider-Depr\\'e and Alexandre Goossens and Alexander Stevens and Aur\\'elie Leribaux and Johannes De Smedt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:25:55+00:00",
          "link": "https://arxiv.org/abs/2507.08362v1",
          "size": "958kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Machine Learning and Enhanced Parallelism Detection for BPMN Model Generation from Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08362",
        "HTML": "https://arxiv.org/html/2507.08362v1",
        "PDF": "https://arxiv.org/pdf/2507.08362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a newly annotated dataset for BPMN model generation from text, detailing how these additions enhance the training process of machine learning models, directly contributing to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08416",
      "abstract": "Humans can naturally identify and mentally complete occluded objects in cluttered environments. However, imparting similar cognitive ability to robotics remains challenging even with advanced reconstruction techniques, which models scenes as undifferentiated wholes and fails to recognize complete object from partial observations. In this paper, we propose InstaScene, a new paradigm towards holistic 3D perception of complex scenes with a primary goal: decomposing arbitrary instances while ensuring complete reconstruction. To achieve precise decomposition, we develop a novel spatial contrastive learning by tracing rasterization of each instance across views, significantly enhancing semantic supervision in cluttered scenes. To overcome incompleteness from limited observations, we introduce in-situ generation that harnesses valuable observations and geometric cues, effectively guiding 3D generative models to reconstruct complete instances that seamlessly align with the real world. Experiments on scene decomposition and object completion across complex real-world and synthetic scenes demonstrate that our method achieves superior decomposition accuracy while producing geometrically faithful and visually intact objects.",
      "authors": [
        "Zesong Yang and Bangbang Yang and Wenqi Dong and Chenxuan Cao and Liyuan Cui and Yuewen Ma and Zhaopeng Cui and Hujun Bao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.08416v1",
          "size": "18339kb",
          "version": "v1"
        }
      ],
      "title": "InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08416",
        "HTML": "https://arxiv.org/html/2507.08416v1",
        "PDF": "https://arxiv.org/pdf/2507.08416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D instance decomposition and reconstruction within cluttered scenes, which is unrelated to LLM training data processing. The emphasis is on spatial contrastive learning and in-situ generation for scene perception."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08584",
      "abstract": "Large language models (LLMs) are increasingly deployed in agentic frameworks, in which prompts trigger complex tool-based analysis in pursuit of a goal. While these frameworks have shown promise across multiple domains including in finance, they typically lack a principled model-building step, relying instead on sentiment- or trend-based analysis. We address this gap by developing an agentic system that uses LLMs to iteratively discover stochastic differential equations for financial time series. These models generate risk metrics which inform daily trading decisions. We evaluate our system in both traditional backtests and using a market simulator, which introduces synthetic but causally plausible price paths and news events. We find that model-informed trading strategies outperform standard LLM-based agents, improving Sharpe ratios across multiple equities. Our results show that combining LLMs with agentic model discovery enhances market risk estimation and enables more profitable trading decisions.",
      "authors": [
        "Dimitrios Emmanoulopoulos",
        "Ollie Olby",
        "Justin Lyon",
        "Namid R. Stillman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Multiagent Systems (cs.MA)",
        "Computational Finance (q-fin.CP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:29:32+00:00",
          "link": "https://arxiv.org/abs/2507.08584v1",
          "size": "7754kb",
          "version": "v1"
        }
      ],
      "title": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08584",
        "HTML": "https://arxiv.org/html/2507.08584v1",
        "PDF": "https://arxiv.org/pdf/2507.08584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study develops an agentic system that discovers models for financial analysis, indicating a use case for LLMs but not focusing on processing LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08724",
      "abstract": "In this paper, we introduce a trajectory planning problem for a marsupial robotics system consisting of a ground robot, a drone, and a taut tether of bounded length connecting the two robots. This problem can be framed within the context of a pursuit-evasion game. Using a geometric modeling approach, we present an optimal algorithm to compute a minimum-link path for the pursuer (ground robot), given the known path of the evader (drone). Furthermore, we address and solve three related geometric optimization problems, leveraging the intrinsic connections between them.",
      "authors": [
        "Aurelio Barrera-Vicent",
        "Jos\\'e Miguel D\\'iaz-B\\'a\\~nez",
        "Fabio Rodr\\'iguez and Vanesa S\\'anchez-Canales"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:24:23+00:00",
          "link": "https://arxiv.org/abs/2507.08724v1",
          "size": "290kb",
          "version": "v1"
        }
      ],
      "title": "Computing optimal trajectories for a tethered pursuer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08724",
        "HTML": "https://arxiv.org/html/2507.08724v1",
        "PDF": "https://arxiv.org/pdf/2507.08724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a trajectory planning problem in robotics, which does not include any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08163",
      "abstract": "We propose Adaptive Diffusion Denoised Smoothing, a method for certifying the predictions of a vision model against adversarial examples, while adapting to the input. Our key insight is to reinterpret a guided denoising diffusion model as a long sequence of adaptive Gaussian Differentially Private (GDP) mechanisms refining a pure noise sample into an image. We show that these adaptive mechanisms can be composed through a GDP privacy filter to analyze the end-to-end robustness of the guided denoising process, yielding a provable certification that extends the adaptive randomized smoothing analysis. We demonstrate that our design, under a specific guiding strategy, can improve both certified accuracy and standard accuracy on ImageNet for an $\\ell_2$ threat model.",
      "authors": [
        "Frederick Shpilevskiy",
        "Saiyue Lyu",
        "Krishnamurthy Dj Dvijotham",
        "Mathias L\\'ecuyer",
        "Pierre-Andr\\'e No\\\"el"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:52:22+00:00",
          "link": "https://arxiv.org/abs/2507.08163v1",
          "size": "8435kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08163",
        "HTML": "https://arxiv.org/html/2507.08163v1",
        "PDF": "https://arxiv.org/pdf/2507.08163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on certifying robustness against adversarial examples in vision models, with no substantive discussion or contribution related to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15488",
      "abstract": "Due to the multidisciplinary nature of wearable technology, the industry faces potential limitations in innovation. The wearable technology industry is still in its infancy and increased applicable use faces stagnation despite the plethora of technologies that have been largely wrist worn. This could be a result of the lack of multidisciplinary expert knowledge disseminating through the industry. Unlike other technologies which have standardizations and processes for how they are developed, wearable technologies exist in a realm of perpetual change as given the various materials and subcomponents that continue to be developed. It is essential that expert opinions form a collaborative foundation, and even more so that intelligent systems foster that collaboration. The caveat though, is likeliness of these artificial intelligence (AI) collaboration tools to be utilized by industry experts. Mental model development for AI tool usage could be applied to wearable technology innovation in this regard, thus the goal of this paper and focus of research.",
      "authors": [
        "Andrew M. Lydner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T00:34:48+00:00",
          "link": "https://arxiv.org/abs/2503.15488v1",
          "size": "827kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T23:45:24+00:00",
          "link": "https://arxiv.org/abs/2503.15488v2",
          "size": "804kb",
          "version": "v2"
        }
      ],
      "title": "Human-AI Collaboration for Wearable Technology Component Standardization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15488",
        "PDF": "https://arxiv.org/pdf/2503.15488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores collaboration in wearable technology and does not address aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07031",
      "abstract": "As AI models become ubiquitous in our daily lives, there has been an increasing demand for transparency in ML services. However, the model owner does not want to reveal the weights, as they are considered trade secrets. To solve this problem, researchers have turned to zero-knowledge proofs of ML model inference. These proofs convince the user that the ML model output is correct, without revealing the weights of the model to the user. Past work on these provers can be placed into two categories. The first method compiles the ML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The second method uses custom cryptographic protocols designed only for a specific class of models. Unfortunately, the first method is highly inefficient, making it impractical for the large models used today, and the second method does not generalize well, making it difficult to update in the rapidly changing field of machine learning. To solve this, we propose ZKTorch, an open source end-to-end proving system that compiles ML models into base cryptographic operations called basic blocks, each proved using specialized protocols. ZKTorch is built on top of a novel parallel extension to the Mira accumulation scheme, enabling succinct proofs with minimal accumulation overhead. These contributions allow ZKTorch to achieve at least a $3\\times$ reduction in the proof size compared to specialized protocols and up to a $6\\times$ speedup in proving time over a general-purpose ZKML framework.",
      "authors": [
        "Bing-Jyue Chen and Lilia Tang and Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:03:21+00:00",
          "link": "https://arxiv.org/abs/2507.07031v1",
          "size": "225kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T23:50:39+00:00",
          "link": "https://arxiv.org/abs/2507.07031v2",
          "size": "225kb",
          "version": "v2"
        }
      ],
      "title": "ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07031",
        "HTML": "https://arxiv.org/html/2507.07031v2",
        "PDF": "https://arxiv.org/pdf/2507.07031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses zero-knowledge proofs for ML model inference, particularly in compiling ML models, without delving into LLM training data processing methods or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08721",
      "abstract": "Encountering shifted data at test time is a ubiquitous challenge when deploying predictive models. Test-time adaptation (TTA) methods address this issue by continuously adapting a deployed model using only unlabeled test data. While TTA can extend the model's lifespan, it is only a temporary solution. Eventually the model might degrade to the point that it must be taken offline and retrained. To detect such points of ultimate failure, we propose pairing TTA with risk monitoring frameworks that track predictive performance and raise alerts when predefined performance criteria are violated. Specifically, we extend existing monitoring tools based on sequential testing with confidence sequences to accommodate scenarios in which the model is updated at test time and no test labels are available to estimate the performance metrics of interest. Our extensions unlock the application of rigorous statistical risk monitoring to TTA, and we demonstrate the effectiveness of our proposed TTA monitoring framework across a representative set of datasets, distribution shift types, and TTA methods.",
      "authors": [
        "Mona Schirmer and Metod Jazbec and Christian A. Naesseth and Eric Nalisnick"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:21:33+00:00",
          "link": "https://arxiv.org/abs/2507.08721v1",
          "size": "5015kb",
          "version": "v1"
        }
      ],
      "title": "Monitoring Risks in Test-Time Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08721",
        "HTML": "https://arxiv.org/html/2507.08721v1",
        "PDF": "https://arxiv.org/pdf/2507.08721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses monitoring risks during test-time adaptation and does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.14371",
      "abstract": "Monocular facial performance capture in-the-wild is challenging due to varied capture conditions, face shapes, and expressions. Most current methods rely on linear 3D Morphable Models, which represent facial expressions independently of identity at the vertex displacement level. We propose SEREP (Semantic Expression Representation), a model that disentangles expression from identity at the semantic level. We start by learning an expression representation from high-quality 3D data of unpaired facial expressions. Then, we train a model to predict expression from monocular images relying on a novel semi-supervised scheme using low quality synthetic data. In addition, we introduce MultiREX, a benchmark addressing the lack of evaluation resources for the expression capture task. Our experiments show that SEREP outperforms state-of-the-art methods, capturing challenging expressions and transferring them to new identities.",
      "authors": [
        "Arthur Josi",
        "Luiz Gustavo Hafemann",
        "Abdallah Dib",
        "Emeline Got",
        "Rafael M. O. Cruz",
        "and Marc-Andre Carbonneau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T22:12:28+00:00",
          "link": "https://arxiv.org/abs/2412.14371v1",
          "size": "34940kb",
          "version": "v1"
        },
        {
          "date": "2024-12-20T21:57:01+00:00",
          "link": "https://arxiv.org/abs/2412.14371v2",
          "size": "34940kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T15:57:22+00:00",
          "link": "https://arxiv.org/abs/2412.14371v3",
          "size": "45778kb",
          "version": "v3"
        }
      ],
      "title": "SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14371",
        "HTML": "https://arxiv.org/html/2412.14371v3",
        "PDF": "https://arxiv.org/pdf/2412.14371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SEREP focuses on semantic facial expression representation for facial capture and retargeting, which does not include LLM training data processing."
      },
      "tasks": [
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08241",
      "abstract": "Pain is an inherent part of human existence, manifesting as both physical and emotional experiences, and can be categorized as either acute or chronic. Over the years, extensive research has been conducted to understand the causes of pain and explore potential treatments, with contributions from various scientific disciplines. However, earlier studies often overlooked the role of gender in pain experiences. In this study, we utilized Natural Language Processing (NLP) to analyze and gain deeper insights into individuals' pain experiences, with a particular focus on gender differences. We successfully classified posts into male and female corpora using the Hidden Attribute Model-Convolutional Neural Network (HAM-CNN), achieving an F1 score of 0.86 by aggregating posts based on usernames. Our analysis revealed linguistic differences between genders, with female posts tending to be more emotionally focused. Additionally, the study highlighted that conditions such as migraine and sinusitis are more prevalent among females and explored how pain medication affects individuals differently based on gender.",
      "authors": [
        "Ancita Maria Andrade",
        "Tanvi Banerjee",
        "Ramakrishna Mundugar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:11:06+00:00",
          "link": "https://arxiv.org/abs/2507.08241v1",
          "size": "253kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Gender Differences in Chronic Pain Discussions on Reddit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08241",
        "HTML": "https://arxiv.org/html/2507.08241v1",
        "PDF": "https://arxiv.org/pdf/2507.08241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing gender differences in pain experiences using NLP on Reddit data, but does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08261",
      "abstract": "Batch normalization (BN) is a ubiquitous operation in deep neural networks used primarily to achieve stability and regularization during network training. BN involves feature map centering and scaling using sample means and variances, respectively. Since these statistics are being estimated across the feature maps within a batch, this problem is ideally suited for the application of Stein's shrinkage estimation, which leads to a better, in the mean-squared-error sense, estimate of the mean and variance of the batch. In this paper, we prove that the Stein shrinkage estimator for the mean and variance dominates over the sample mean and variance estimators in the presence of adversarial attacks when modeling these attacks using sub-Gaussian distributions. This facilitates and justifies the application of Stein shrinkage to estimate the mean and variance parameters in BN and use it in image classification (segmentation) tasks with and without adversarial attacks. We present SOTA performance results using this Stein corrected batch norm in a standard ResNet architecture applied to the task of image classification using CIFAR-10 data, 3D CNN on PPMI (neuroimaging) data and image segmentation using HRNet on Cityscape data with and without adversarial attacks.",
      "authors": [
        "Sofia Ivolgina",
        "P. Thomas Fletcher",
        "Baba C. Vemuri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:13:42+00:00",
          "link": "https://arxiv.org/abs/2507.08261v1",
          "size": "155kb",
          "version": "v1"
        }
      ],
      "title": "Admissibility of Stein Shrinkage for Batch Normalization in the Presence of Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08261",
        "HTML": "https://arxiv.org/html/2507.08261v1",
        "PDF": "https://arxiv.org/pdf/2507.08261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying Stein shrinkage to batch normalization during adversarial attacks, primarily in image classification tasks. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08557",
      "abstract": "Text-to-audio (T2A) generation has achieved promising results with the recent advances in generative models. However, because of the limited quality and quantity of temporally-aligned audio-text pairs, existing T2A methods struggle to handle the complex text prompts that contain precise timing control, e.g., \"owl hooted at 2.4s-5.2s\". Recent works have explored data augmentation techniques or introduced timing conditions as model inputs to enable timing-conditioned 10-second T2A generation, while their synthesis quality is still limited. In this work, we propose a novel training-free timing-controlled T2A framework, FreeAudio, making the first attempt to enable timing-controlled long-form T2A generation, e.g., \"owl hooted at 2.4s-5.2s and crickets chirping at 0s-24s\". Specifically, we first employ an LLM to plan non-overlapping time windows and recaption each with a refined natural language description, based on the input text and timing prompts. Then we introduce: 1) Decoupling and Aggregating Attention Control for precise timing control; 2) Contextual Latent Composition for local smoothness and Reference Guidance for global consistency. Extensive experiments show that: 1) FreeAudio achieves state-of-the-art timing-conditioned T2A synthesis quality among training-free methods and is comparable to leading training-based methods; 2) FreeAudio demonstrates comparable long-form generation quality with training-based Stable Audio and paves the way for timing-controlled long-form T2A synthesis. Demo samples are available at: https://freeaudio.github.io/FreeAudio/",
      "authors": [
        "Yuxuan Jiang",
        "Zehua Chen",
        "Zeqian Ju",
        "Chang Li",
        "Weibei Dou",
        "Jun Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:57:51+00:00",
          "link": "https://arxiv.org/abs/2507.08557v1",
          "size": "2548kb",
          "version": "v1"
        }
      ],
      "title": "FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08557",
        "HTML": "https://arxiv.org/html/2507.08557v1",
        "PDF": "https://arxiv.org/pdf/2507.08557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves a novel timing-controlled text-to-audio framework and employs an LLM to refine text prompts, but its focus is on audio generation rather than LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08648",
      "abstract": "Common knowledge indicates that the process of constructing image datasets usually depends on the time-intensive and inefficient method of manual collection and annotation. Large models offer a solution via data generation. Nonetheless, real-world data are obviously more valuable comparing to artificially intelligence generated data, particularly in constructing image datasets. For this reason, we propose a novel method for auto-constructing datasets from real-world images by a multiagent collaborative system, named as DatasetAgent. By coordinating four different agents equipped with Multi-modal Large Language Models (MLLMs), as well as a tool package for image optimization, DatasetAgent is able to construct high-quality image datasets according to user-specified requirements. In particular, two types of experiments are conducted, including expanding existing datasets and creating new ones from scratch, on a variety of open-source datasets. In both cases, multiple image datasets constructed by DatasetAgent are used to train various vision models for image classification, object detection, and image segmentation.",
      "authors": [
        "Haoran Sun",
        "Haoyu Bian",
        "Shaoning Zeng",
        "Yunbo Rao",
        "Xu Xu",
        "Lin Mei",
        "Jianping Gou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:51:33+00:00",
          "link": "https://arxiv.org/abs/2507.08648v1",
          "size": "21614kb",
          "version": "v1"
        }
      ],
      "title": "DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08648",
        "HTML": "https://arxiv.org/html/2507.08648v1",
        "PDF": "https://arxiv.org/pdf/2507.08648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel system for auto-constructing datasets from real-world images using a multi-agent system, explicitly focusing on creating high-quality datasets, which falls under LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.06445",
      "abstract": "A connected graph, on four or more vertices, is matching covered (aka 1-extendable) if every edge is present in some perfect matching. An ear decomposition theorem exists for bipartite matching covered graphs due to Hetyei. From the results and proofs of Lov\\'asz and Plummer, that rely on Hetyei's theorem, one may deduce that any minimal bipartite matching covered graph has at least $2(m-n+2)$ vertices of degree two (where minimal means that deleting any edge results in a graph that is not matching covered); such a graph is said to be extremal if it attains the stated lower bound.\n  In this paper, we provide a complete characterization of the class of extremal minimal bipartite matching covered graphs. In particular, we prove that every such graph $G$ is obtained from two copies of a tree devoid of degree two vertices, say $T$ and $T'$, by adding edges -- each of which joins a leaf of $T$ with the corresponding leaf of $T'$.\n  Apart from the aforementioned bound, there are four other bounds that appear in, or may be deduced from, the work of Lov\\'asz and Plummer. Each of these bounds leads to a notion of extremality. In this paper, we obtain a complete characterization of all of these extremal classes and also establish relationships between them. Two of our characterizations are in the same spirit as the one stated above. For the remaining two extremal classes, we reduce each of them to one of the already characterized extremal classes using standard matching theoretic operations.\n  A connected graph is k-extendable if it has a matching of cardinality $k$ and each such matching extends to a perfect matching. We also discuss bounds proved by Lou (1999) for minimal k-extendable bipartite graphs. We conjecture stronger bounds and provide evidence for our conjectures by constructing tight examples that are straightforward generalizations of the ones that appear in the 1-extendable case.",
      "authors": [
        "Amit Kumar Mallik",
        "Ajit A. Diwan and Nishad Kothari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-09T16:47:42+00:00",
          "link": "https://arxiv.org/abs/2404.06445v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2024-04-11T11:50:15+00:00",
          "link": "https://arxiv.org/abs/2404.06445v2",
          "size": "32kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T16:39:33+00:00",
          "link": "https://arxiv.org/abs/2404.06445v3",
          "size": "45kb",
          "version": "v3"
        }
      ],
      "title": "Extremal minimal bipartite matching covered graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.06445",
        "PDF": "https://arxiv.org/pdf/2404.06445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses graph theory concepts and minimal bipartite matching covered graphs, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02899",
      "abstract": "Vectorized maps are indispensable for precise navigation and the safe operation of autonomous vehicles. Traditional methods for constructing these maps fall into two categories: offline techniques, which rely on expensive, labor-intensive LiDAR data collection and manual annotation, and online approaches that use onboard cameras to reduce costs but suffer from limited performance, especially at complex intersections. To bridge this gap, we introduce MRC-VMap, a cost-effective, vision-centric, end-to-end neural network designed to generate high-definition vectorized maps directly at intersections. Leveraging existing roadside surveillance cameras, MRC-VMap directly converts time-aligned, multi-directional images into vectorized map representations. This integrated solution lowers the need for additional intermediate modules--such as separate feature extraction and Bird's-Eye View (BEV) conversion steps--thus reducing both computational overhead and error propagation. Moreover, the use of multiple camera views enhances mapping completeness, mitigates occlusions, and provides robust performance under practical deployment constraints. Extensive experiments conducted on 4,000 intersections across 4 major metropolitan areas in China demonstrate that MRC-VMap not only outperforms state-of-the-art online methods but also achieves accuracy comparable to high-cost LiDAR-based approaches, thereby offering a scalable and efficient solution for modern autonomous navigation systems.",
      "authors": [
        "Quanxin Zheng",
        "Miao Fan",
        "Shengtong Xu",
        "Linghe Kong",
        "Haoyi Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T04:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.02899v1",
          "size": "2027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:00:04+00:00",
          "link": "https://arxiv.org/abs/2507.02899v2",
          "size": "2026kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T05:01:20+00:00",
          "link": "https://arxiv.org/abs/2507.02899v3",
          "size": "2026kb",
          "version": "v3"
        }
      ],
      "title": "Learning to Generate Vectorized Maps at Intersections with Multiple Roadside Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02899",
        "HTML": "https://arxiv.org/html/2507.02899v3",
        "PDF": "https://arxiv.org/pdf/2507.02899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a neural network for generating vectorized maps using roadside cameras, focusing on autonomous navigation system challenges, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08328",
      "abstract": "Hypergraphs, increasingly utilised to model complex and diverse relationships in modern networks, have gained significant attention for representing intricate higher-order interactions. Among various challenges, cohesive subgraph discovery is one of the fundamental problems and offers deep insights into these structures, yet the task of selecting appropriate parameters is an open question. To address this question, we aim to design an efficient indexing structure to retrieve cohesive subgraphs in an online manner. The main idea is to enable the discovery of corresponding structures within a reasonable time without the need for exhaustive graph traversals. Our method enables faster and more effective retrieval of cohesive structures, which supports decision-making in applications that require online analysis of large-scale hypergraphs. Through extensive experiments on real-world networks, we demonstrate the superiority of our proposed indexing technique.",
      "authors": [
        "Dahee Kim",
        "Hyewon Kim",
        "Song Kim",
        "Minseok Kim",
        "Junghoon Kim",
        "Yeon-Chang Lee",
        "Sungsu Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:39:05+00:00",
          "link": "https://arxiv.org/abs/2507.08328v1",
          "size": "2587kb",
          "version": "v1"
        }
      ],
      "title": "Uncovering High-Order Cohesive Structures: Efficient (k,g)-Core Computation and Decomposition for Large Hypergraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08328",
        "HTML": "https://arxiv.org/html/2507.08328v1",
        "PDF": "https://arxiv.org/pdf/2507.08328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses cohesive subgraph discovery in hypergraphs and efficient indexing for subgraph retrieval, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08343",
      "abstract": "Deep hiding has been exploring the hiding capability of deep learning-based models, aiming to conceal image-level messages into cover images and reveal them from generated stego images. Existing schemes are easily detected by steganalyzers due to their large payloads and their limitation to feature extraction based solely on either pure convolution or pure transformer operators within a single range, as well as pixel-level loss constraints. To address the issue, in this paper, we introduce generation-based adversarial attacks into color JPEG image deep hiding and propose a multi-range representations-driven adversarial stego generation framework called MRAG from a steganalysis perspective. Specifically, we integrate the local-range neighbor reception characteristic of the convolution and the global-range dependency modeling of the transformer to construct MRAG. Meanwhile, we use the transformed images obtained through coarse-grained and fine-grained frequency decomposition as inputs, introducing multi-grained information. Furthermore, a features angle-norm disentanglement loss is designed to constrain the generated stegos closer to covers in the angle and norm space of the steganalyzer's classified features. Consequently, small yet effective adversarial perturbations can be injected into the process of generating stegos, ensuring that stegos maintain favorable secret restorability and imperceptibility. Extensive experiments demonstrate that MRAG can achieve state-of-the-art performance.",
      "authors": [
        "Junxue Yang",
        "Xin Liao",
        "Weixuan Tang",
        "Jianhua Yang",
        "Zheng Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:45:07+00:00",
          "link": "https://arxiv.org/abs/2507.08343v1",
          "size": "1684kb",
          "version": "v1"
        }
      ],
      "title": "Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08343",
        "HTML": "https://arxiv.org/html/2507.08343v1",
        "PDF": "https://arxiv.org/pdf/2507.08343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses image hiding techniques using adversarial stego generation and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12546",
      "abstract": "Plaintiffs and defendants in copyright lawsuits over generative AI often make sweeping, opposing claims about the extent to which large language models (LLMs) have memorized plaintiffs' protected expression. Drawing on adversarial ML and copyright law, we show that these polarized positions dramatically oversimplify the relationship between memorization and copyright. To do so, we leverage a recent probabilistic extraction technique to extract pieces of the Books3 dataset from 17 open-weight LLMs. Through numerous experiments, we show that it's possible to extract substantial parts of at least some books from different LLMs. This is evidence that these LLMs have memorized the extracted text; this memorized content is copied inside the model parameters. But the results are complicated: the extent of memorization varies both by model and by book. With our specific experiments, we find that the largest LLMs don't memorize most books--either in whole or in part. However, we also find that Llama 3.1 70B memorizes some books, like Harry Potter and the Sorcerer's Stone and 1984, almost entirely. In fact, Harry Potter is so memorized that, using a seed prompt consisting of just the first line of chapter 1, we can deterministically generate the entire book near-verbatim. We discuss why our results have significant implications for copyright cases, though not ones that unambiguously favor either side.",
      "authors": [
        "A. Feder Cooper and Aaron Gokaslan and Ahmed Ahmed and Amy B. Cyphert and Christopher De Sa and Mark A. Lemley and Daniel E. Ho and Percy Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-18T21:06:32+00:00",
          "link": "https://arxiv.org/abs/2505.12546v1",
          "size": "23851kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T23:16:43+00:00",
          "link": "https://arxiv.org/abs/2505.12546v2",
          "size": "22989kb",
          "version": "v2"
        }
      ],
      "title": "Extracting memorized pieces of (copyrighted) books from open-weight language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12546",
        "PDF": "https://arxiv.org/pdf/2505.12546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates copyright issues and memorization within LLMs, focusing on adversarial ML techniques and extraction, without discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Memorization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08019",
      "abstract": "This study investigates whether large language models (LLMs) exhibit consistent behavior (signal) or random variation (noise) when screening resumes against job descriptions, and how their performance compares to human experts. Using controlled datasets, we tested three LLMs (Claude, GPT, and Gemini) across contexts (No Company, Firm1 [MNC], Firm2 [Startup], Reduced Context) with identical and randomized resumes, benchmarked against three human recruitment experts. Analysis of variance revealed significant mean differences in four of eight LLM-only conditions and consistently significant differences between LLM and human evaluations (p < 0.01). Paired t-tests showed GPT adapts strongly to company context (p < 0.001), Gemini partially (p = 0.038 for Firm1), and Claude minimally (p > 0.1), while all LLMs differed significantly from human experts across contexts. Meta-cognition analysis highlighted adaptive weighting patterns that differ markedly from human evaluation approaches. Findings suggest LLMs offer interpretable patterns with detailed prompts but diverge substantially from human judgment, informing their deployment in automated hiring systems.",
      "authors": [
        "Aryan Varshney and Venkat Ram Reddy Ganuthula"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T01:34:21+00:00",
          "link": "https://arxiv.org/abs/2507.08019v1",
          "size": "294kb",
          "version": "v1"
        }
      ],
      "title": "Signal or Noise? Evaluating Large Language Models in Resume Screening Across Contextual Variations and Human Expert Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08019",
        "PDF": "https://arxiv.org/pdf/2507.08019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates the performance of LLMs in resume screening against human experts, focusing on testing using existing datasets rather than processing or engineering the training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08119",
      "abstract": "Rail-optimized network fabrics have become the de facto datacenter scale-out fabric for large-scale ML training. However, the use of high-radix electrical switches to provide all-to-all connectivity in rails imposes massive power, cost, and complexity overheads. We propose a rethinking of the rail abstraction by retaining its communication semantics, but realizing it using optical circuit switches. The key challenge is that optical switches support only one-to-one connectivity at a time, limiting the fan-out of traffic in ML workloads using hybrid parallelisms. We introduce parallelism-driven rail reconfiguration as a solution that leverages the sequential ordering between traffic from different parallelisms. We design a control plane, Opus, to enable time-multiplexed emulation of electrical rail switches using optical switches. More broadly, our work discusses a new research agenda: datacenter fabrics that co-evolve with the model parallelism dimensions within each job, as opposed to the prevailing mindset of reconfiguring networks before a job begins.",
      "authors": [
        "Eric Ding",
        "Chuhan Ouyang",
        "Rachee Singh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:14:16+00:00",
          "link": "https://arxiv.org/abs/2507.08119v1",
          "size": "244kb",
          "version": "v1"
        }
      ],
      "title": "Photonic Rails in ML Datacenters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08119",
        "HTML": "https://arxiv.org/html/2507.08119v1",
        "PDF": "https://arxiv.org/pdf/2507.08119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses rail-optimized network fabrics in datacenters using optical circuit switches for ML workloads, focusing on network infrastructure rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.13347",
      "abstract": "This manuscript develops edge-averaged virtual element (EAVE) methodologies to address convection-diffusion problems effectively in the convection-dominated regime. It introduces a variant of EAVE that ensures monotonicity (producing an $M$-matrix) on Voronoi polygonal meshes, provided their duals are Delaunay triangulations with acute angles. Furthermore, the study outlines a comprehensive framework for EAVE methodologies, introducing another variant that integrates with the stiffness matrix derived from the lowest-order virtual element method for the Poisson equation. Numerical experiments confirm the theoretical advantages of the monotonicity property and demonstrate an optimal convergence rate across various mesh configurations.",
      "authors": [
        "Shuhao Cao",
        "Long Chen",
        "Seulip Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-20T19:48:14+00:00",
          "link": "https://arxiv.org/abs/2402.13347v1",
          "size": "993kb",
          "version": "v1"
        }
      ],
      "title": "Edge-averaged virtual element methods for convection-diffusion and convection-dominated problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13347",
        "PDF": "https://arxiv.org/pdf/2402.13347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on edge-averaged virtual element methodologies for addressing convection-diffusion problems, with no mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05550",
      "abstract": "Score-based diffusion generative models have recently emerged as a powerful tool for modelling complex data distributions. These models aim at learning the score function, which defines a map from a known probability distribution to the target data distribution via deterministic or stochastic differential equations (SDEs). The score function is typically estimated from data using a variety of approximation techniques, such as denoising or sliced score matching, Hyv\\\"arien's method, or Schr\\\"odinger bridges. In this paper, we derive an exact, closed form, expression for the score function for a broad class of nonlinear diffusion generative models. Our approach combines modern stochastic analysis tools such as Malliavin derivatives and their adjoint operators (Skorokhod integrals or Malliavin Divergence) with a new Bismut-type formula. The resulting expression for the score function can be written entirely in terms of the first and second variation processes, with all Malliavin derivatives systematically eliminated, thereby enhancing its practical applicability. The theoretical framework presented in this work offers a principled foundation for advancing score estimation methods in generative modelling, enabling the design of new sampling algorithms for complex probability distributions. Our results can be extended to broader classes of stochastic differential equations, opening new directions for the development of score-based diffusion generative models.",
      "authors": [
        "Ehsan Mirafzali",
        "Frank Proske",
        "Utkarsh Gupta",
        "Daniele Venturi",
        "Razvan Marinescu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T00:20:57+00:00",
          "link": "https://arxiv.org/abs/2507.05550v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:14:03+00:00",
          "link": "https://arxiv.org/abs/2507.05550v2",
          "size": "91kb",
          "version": "v2"
        }
      ],
      "title": "A Malliavin calculus approach to score functions in diffusion generative models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05550",
        "HTML": "https://arxiv.org/html/2507.05550v2",
        "PDF": "https://arxiv.org/pdf/2507.05550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores mathematical techniques in score-based diffusion generative models using stochastic analysis and Malliavin calculus, focusing on model operations rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08316",
      "abstract": "In the Cumulative Vehicle Routing Problem (Cu-VRP), we need to find a feasible itinerary for a capacitated vehicle located at the depot to satisfy customers' demand, as in the well-known Vehicle Routing Problem (VRP), but the goal is to minimize the cumulative cost of the vehicle, which is based on the vehicle's load throughout the itinerary. If the demand of each customer is unknown until the vehicle visits it, the problem is called Cu-VRP with Stochastic Demands (Cu-VRPSD). Assume that the approximation ratio of metric TSP is $1.5$. In this paper, we propose a randomized $3.456$-approximation algorithm for Cu-VRPSD, improving the best-known approximation ratio of $6$ (Discret. Appl. Math. 2020). Since VRP with Stochastic Demands (VRPSD) is a special case of Cu-VRPSD, as a corollary, we also obtain a randomized $3.25$-approximation algorithm for VRPSD, improving the best-known approximation ratio of $3.5$ (Oper. Res. 2012). For Cu-VRP, we give a randomized $3.194$-approximation algorithm, improving the best-known approximation ratio of $4$ (Oper. Res. Lett. 2013). Moreover, if each customer is allowed to be satisfied by using multiple tours, we obtain further improvements for Cu-VRPSD and Cu-VRP.",
      "authors": [
        "Jingyang Zhao and Mingyu Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:05:54+00:00",
          "link": "https://arxiv.org/abs/2507.08316v1",
          "size": "184kb",
          "version": "v1"
        }
      ],
      "title": "Approximation Algorithms for the Cumulative Vehicle Routing Problem with Stochastic Demands",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08316",
        "HTML": "https://arxiv.org/html/2507.08316v1",
        "PDF": "https://arxiv.org/pdf/2507.08316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses approximation algorithms for vehicle routing problems, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08623",
      "abstract": "Quantum Machine Learning (QML) systems inherit vulnerabilities from classical machine learning while introducing new attack surfaces rooted in the physical and algorithmic layers of quantum computing. Despite a growing body of research on individual attack vectors - ranging from adversarial poisoning and evasion to circuit-level backdoors, side-channel leakage, and model extraction - these threats are often analyzed in isolation, with unrealistic assumptions about attacker capabilities and system environments. This fragmentation hampers the development of effective, holistic defense strategies. In this work, we argue that QML security requires more structured modeling of the attack surface, capturing not only individual techniques but also their relationships, prerequisites, and potential impact across the QML pipeline. We propose adapting kill chain models, widely used in classical IT and cybersecurity, to the quantum machine learning context. Such models allow for structured reasoning about attacker objectives, capabilities, and possible multi-stage attack paths - spanning reconnaissance, initial access, manipulation, persistence, and exfiltration. Based on extensive literature analysis, we present a detailed taxonomy of QML attack vectors mapped to corresponding stages in a quantum-aware kill chain framework that is inspired by the MITRE ATLAS for classical machine learning. We highlight interdependencies between physical-level threats (like side-channel leakage and crosstalk faults), data and algorithm manipulation (such as poisoning or circuit backdoors), and privacy attacks (including model extraction and training data inference). This work provides a foundation for more realistic threat modeling and proactive security-in-depth design in the emerging field of quantum machine learning.",
      "authors": [
        "Pascal Debus",
        "Maximilian Wendlinger",
        "Kilian Tscharke",
        "Daniel Herr",
        "Cedric Br\\\"ugmann",
        "Daniel Ohl de Mello",
        "Juris Ulmanis",
        "Alexander Erhard",
        "Arthur Schmidt",
        "Fabian Petsch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:25:36+00:00",
          "link": "https://arxiv.org/abs/2507.08623v1",
          "size": "371kb",
          "version": "v1"
        }
      ],
      "title": "Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08623",
        "HTML": "https://arxiv.org/html/2507.08623v1",
        "PDF": "https://arxiv.org/pdf/2507.08623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses security aspects of Quantum Machine Learning systems and proposes a unified kill chain model for quantum machine learning security but does not focus on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08040",
      "abstract": "The standard conditional probability definition formula is derived as a consequence of the Insufficient Reason Principle expressed as the Maximum Relative Divergence Principle for grading (order-comonotonic) functions on a totally ordered set.",
      "authors": [
        "Alexander Dukhovny"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:04:03+00:00",
          "link": "https://arxiv.org/abs/2507.08040v1",
          "size": "3kb",
          "version": "v1"
        }
      ],
      "title": "Conditional Probability formula as a consequence of the Insufficient Reason Principle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08040",
        "HTML": "https://arxiv.org/html/2507.08040v1",
        "PDF": "https://arxiv.org/pdf/2507.08040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deriving a conditional probability formula based on the Insufficient Reason Principle, without discussing any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08605",
      "abstract": "Rice cultivation consumes 24-30% of global freshwater, creating critical water management challenges in major rice-producing regions. Sustainable irrigation practices like direct seeded rice (DSR) and alternate wetting and drying (AWD) can reduce water use by 20-40% while maintaining yields, helping secure long-term agricultural productivity as water scarcity intensifies - a key component of the Zero Hunger Sustainable Development Goal. However, limited data on adoption rates of these practices prevents evidence-based policymaking and targeted resource allocation. We developed a novel remote sensing framework to monitor sustainable water management practices at scale in Punjab, India - a region facing severe groundwater depletion of 41.6 cm/year. To collect essential ground truth data, we partnered with the Nature Conservancy's Promoting Regenerative and No-burn Agriculture (PRANA) program, which trained approximately 1,400 farmers on water-saving techniques while documenting their field-level practices. Using this data, we created a classification system with Sentinel-1 satellite imagery that separates water management along sowing and irrigation dimensions. Our approach achieved a 78% F1-score in distinguishing DSR from traditional puddled transplanted rice without requiring prior knowledge of planting dates. We demonstrated scalability by mapping DSR adoption across approximately 3 million agricultural plots in Punjab, with district-level predictions showing strong correlation (Pearson=0.77, RBO= 0.77) with government records. This study provides policymakers with a powerful tool to track sustainable water management adoption, target interventions, and measure program impacts at scale.",
      "authors": [
        "Ando Shah",
        "Rajveer Singh",
        "Akram Zaytar",
        "Girmaw Abebe Tadesse",
        "Caleb Robinson",
        "Negar Tafti",
        "Stephen A. Wood",
        "Rahul Dodhia",
        "Juan M. Lavista Ferres"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:00:43+00:00",
          "link": "https://arxiv.org/abs/2507.08605v1",
          "size": "32288kb",
          "version": "v1"
        }
      ],
      "title": "Remote Sensing Reveals Adoption of Sustainable Rice Farming Practices Across Punjab, India",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08605",
        "HTML": "https://arxiv.org/html/2507.08605v1",
        "PDF": "https://arxiv.org/pdf/2507.08605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on sustainable farming practices using remote sensing data and does not deal with LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08762",
      "abstract": "We are interested in the (relative) conditioning of the linear problem $y_0\\mapsto \\mathrm{e}^{tA}y_0$, i.e. the conditioning of the action of the matrix exponential $\\mathrm{e}^{tA}$ on a vector with respect to perturbations of this vector. The present paper is a qualitative study of the long-time behavior of this conditioning. In other words, we are interested to study the propagation to the solution $y(t)$ of perturbations of the initial value for a linear ODE $y^\\prime(t)=Ay(t)$, by measuring these perturbations with relative errors instead of absolute errors. We introduce three condition numbers: the first considers a specific initial value and a specific direction of perturbation; the second considers a specific initial value and the worst case by varying the direction of perturbation; and the third considers the worst case by varying both the initial value and the direction of perturbation. The long-time behaviors of these three condition numbers are studied.",
      "authors": [
        "Stefano Maset"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:18:43+00:00",
          "link": "https://arxiv.org/abs/2507.08762v1",
          "size": "695kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotic condition numbers for linear ODEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08762",
        "HTML": "https://arxiv.org/html/2507.08762v1",
        "PDF": "https://arxiv.org/pdf/2507.08762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the behavior of condition numbers in linear ODEs which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.00948",
      "abstract": "The performance of large language models (LLMs) has recently improved to the point where models can perform well on many language tasks. We show here that--for the first time--the models can also generate valid metalinguistic analyses of language data. We outline a research program where the behavioral interpretability of LLMs on these tasks is tested via prompting. LLMs are trained primarily on text--as such, evaluating their metalinguistic abilities improves our understanding of their general capabilities and sheds new light on theoretical models in linguistics. We show that OpenAI's (2024) o1 vastly outperforms other models on tasks involving drawing syntactic trees and phonological generalization. We speculate that OpenAI o1's unique advantage over other models may result from the model's chain-of-thought mechanism, which mimics the structure of human reasoning used in complex cognitive tasks, such as linguistic analysis.",
      "authors": [
        "Ga\\v{s}per Begu\\v{s} and Maksymilian D\\k{a}bkowski and Ryan Rhodes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-01T17:09:33+00:00",
          "link": "https://arxiv.org/abs/2305.00948v1",
          "size": "240kb",
          "version": "v1"
        },
        {
          "date": "2023-08-21T16:52:29+00:00",
          "link": "https://arxiv.org/abs/2305.00948v2",
          "size": "226kb",
          "version": "v2"
        },
        {
          "date": "2025-02-04T02:46:10+00:00",
          "link": "https://arxiv.org/abs/2305.00948v3",
          "size": "412kb",
          "version": "v3"
        },
        {
          "date": "2025-05-19T16:21:18+00:00",
          "link": "https://arxiv.org/abs/2305.00948v4",
          "size": "361kb",
          "version": "v4"
        }
      ],
      "title": "Large Linguistic Models: Investigating LLMs' metalinguistic abilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.00948",
        "PDF": "https://arxiv.org/pdf/2305.00948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the metalinguistic abilities of LLMs, focusing on their linguistic analysis capabilities, without addressing any aspect of training data processing."
      },
      "tasks": [
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08248",
      "abstract": "Accurate identification of fungi species presents a unique challenge in computer vision due to fine-grained inter-species variation and high intra-species variation. This paper presents our approach for the FungiCLEF 2025 competition, which focuses on few-shot fine-grained visual categorization (FGVC) using the FungiTastic Few-Shot dataset. Our team (DS@GT) experimented with multiple vision transformer models, data augmentation, weighted sampling, and incorporating textual information. We also explored generative AI models for zero-shot classification using structured prompting but found them to significantly underperform relative to vision-based models. Our final model outperformed both competition baselines and highlighted the effectiveness of domain specific pretraining and balanced sampling strategies. Our approach ranked 35/74 on the private test set in post-completion evaluation, this suggests additional work can be done on metadata selection and domain-adapted multi-modal learning. Our code is available at https://github.com/dsgt-arc/fungiclef-2025.",
      "authors": [
        "Jason Kahei Tam",
        "Murilo Gustineli",
        "Anthony Miyaguchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:21:21+00:00",
          "link": "https://arxiv.org/abs/2507.08248v1",
          "size": "1220kb",
          "version": "v1"
        }
      ],
      "title": "Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08248",
        "PDF": "https://arxiv.org/pdf/2507.08248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions data augmentation and domain-specific pretraining as part of their approach, but focuses primarily on computer vision models and fungi classification rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08329",
      "abstract": "Craniofacial reconstruction in forensic science is crucial for the identification of the victims of crimes and disasters. The objective is to map a given skull to its corresponding face in a corpus of faces with known identities using recent advancements in computer vision, such as deep learning. In this paper, we presented a framework for the identification of a person given the X-ray image of a skull using convolutional Siamese networks for cross-domain identity representation. Siamese networks are twin networks that share the same architecture and can be trained to discover a feature space where nearby observations that are similar are grouped and dissimilar observations are moved apart. To do this, the network is exposed to two sets of comparable and different data. The Euclidean distance is then minimized between similar pairs and maximized between dissimilar ones. Since getting pairs of skull and face images are difficult, we prepared our own dataset of 40 volunteers whose front and side skull X-ray images and optical face images were collected. Experiments were conducted on the collected cross-domain dataset to train and validate the Siamese networks. The experimental results provide satisfactory results on the identification of a person from the given skull.",
      "authors": [
        "Ravi Shankar Prasad",
        "Dinesh Singh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:49:12+00:00",
          "link": "https://arxiv.org/abs/2507.08329v1",
          "size": "10231kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Domain Identity Representation for Skull to Face Matching with Benchmark DataSet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08329",
        "HTML": "https://arxiv.org/html/2507.08329v1",
        "PDF": "https://arxiv.org/pdf/2507.08329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on craniofacial identification using Siamese networks with a dataset of skull and face images, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08616",
      "abstract": "Large-language models (LLMs) have demonstrated powerful problem-solving capabilities, in particular when organized in multi-agent systems. However, the advent of such systems also raises several questions on the ability of a complex network of agents to effectively self-organize and collaborate. While measuring performance on standard reasoning benchmarks indicates how well multi-agent systems can solve reasoning tasks, it is unclear whether these systems are able to leverage their topology effectively. Here, we propose AgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration from classical problems in distributed systems and graph theory, AgentsNet measures the ability of multi-agent systems to collaboratively form strategies for problem-solving, self-organization, and effective communication given a network topology. We evaluate a variety of baseline methods on AgentsNet including homogeneous networks of agents which first have to agree on basic protocols for organization and communication. We find that some frontier LLMs are already demonstrating strong performance for small networks but begin to fall off once the size of the network scales. While existing multi-agent benchmarks cover at most 2-5 agents, AgentsNet is practically unlimited in size and can scale with new generations of LLMs. As such, we also probe frontier models in a setup with up to 100 agents.",
      "authors": [
        "Florian Gr\\\"otschla",
        "Luis M\\\"uller",
        "Jan T\\\"onshoff",
        "Mikhail Galkin",
        "Bryan Perozzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.08616v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08616",
        "HTML": "https://arxiv.org/html/2507.08616v1",
        "PDF": "https://arxiv.org/pdf/2507.08616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the performance of multi-agent LLM systems on reasoning benchmarks, focusing on agent collaboration, rather than on any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.14023",
      "abstract": "As large language models (LLMs) become an important way of information access, there have been increasing concerns that LLMs may intensify the spread of unethical content, including implicit bias that hurts certain populations without explicit harmful words. In this paper, we conduct a rigorous evaluation of LLMs' implicit bias towards certain demographics by attacking them from a psychometric perspective to elicit agreements to biased viewpoints. Inspired by psychometric principles in cognitive and social psychology, we propose three attack approaches, i.e., Disguise, Deception, and Teaching. Incorporating the corresponding attack instructions, we built two benchmarks: (1) a bilingual dataset with biased statements covering four bias types (2.7K instances) for extensive comparative analysis, and (2) BUMBLE, a larger benchmark spanning nine common bias types (12.7K instances) for comprehensive evaluation. Extensive evaluation of popular commercial and open-source LLMs shows that our methods can elicit LLMs' inner bias more effectively than competitive baselines. Our attack methodology and benchmarks offer an effective means of assessing the ethical risks of LLMs, driving progress toward greater accountability in their development. Our code, data, and benchmarks are available at https://yuchenwen1.github.io/ImplicitBiasEvaluation/.",
      "authors": [
        "Yuchen Wen",
        "Keping Bi",
        "Wei Chen",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-20T06:42:08+00:00",
          "link": "https://arxiv.org/abs/2406.14023v1",
          "size": "471kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T03:37:38+00:00",
          "link": "https://arxiv.org/abs/2406.14023v2",
          "size": "1004kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T07:25:26+00:00",
          "link": "https://arxiv.org/abs/2406.14023v3",
          "size": "1004kb",
          "version": "v3"
        },
        {
          "date": "2025-06-13T08:04:19+00:00",
          "link": "https://arxiv.org/abs/2406.14023v4",
          "size": "1007kb",
          "version": "v4"
        },
        {
          "date": "2025-07-11T04:26:11+00:00",
          "link": "https://arxiv.org/abs/2406.14023v5",
          "size": "1007kb",
          "version": "v5"
        }
      ],
      "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14023",
        "HTML": "https://arxiv.org/html/2406.14023v5",
        "PDF": "https://arxiv.org/pdf/2406.14023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper creates evaluation benchmarks for LLMs, its primary focus is assessing implicit bias rather than data processing. It mentions data creation but doesn't deeply explore technical contributions to improve or synthesize LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/wen112358/implicitbiaspsychometricevaluation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08227",
      "abstract": "Automatic speaker verification (ASV) systems are often affected by spoofing attacks. Recent transformer-based models have improved anti-spoofing performance by learning strong feature representations. However, these models usually need high computing power. To address this, we introduce RawTFNet, a lightweight CNN model designed for audio signals. The RawTFNet separates feature processing along time and frequency dimensions, which helps to capture the fine-grained details of synthetic speech. We tested RawTFNet on the ASVspoof 2021 LA and DF evaluation datasets. The results show that RawTFNet reaches comparable performance to that of the state-of-the-art models, while also using fewer computing resources. The code and models will be made publicly available.",
      "authors": [
        "Yang Xiao",
        "Ting Dang",
        "Rohan Kumar Das"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:24:47+00:00",
          "link": "https://arxiv.org/abs/2507.08227v1",
          "size": "1050kb",
          "version": "v1"
        }
      ],
      "title": "RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08227",
        "HTML": "https://arxiv.org/html/2507.08227v1",
        "PDF": "https://arxiv.org/pdf/2507.08227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a CNN model for speech anti-spoofing and discusses its performance. It does not cover LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.01077",
      "abstract": "Jailbreaking techniques trick Large Language Models (LLMs) into producing restricted output, posing a potential threat. One line of defense is to use another LLM as a Judge to evaluate the harmfulness of generated text. However, we reveal that these Judge LLMs are vulnerable to token segmentation bias, an issue that arises when delimiters alter the tokenization process, splitting words into smaller sub-tokens. This alters the embeddings of the entire sequence, reducing detection accuracy and allowing harmful content to be misclassified as safe. In this paper, we introduce Emoji Attack, a novel strategy that amplifies existing jailbreak prompts by exploiting token segmentation bias. Our method leverages in-context learning to systematically insert emojis into text before it is evaluated by a Judge LLM, inducing embedding distortions that significantly lower the likelihood of detecting unsafe content. Unlike traditional delimiters, emojis also introduce semantic ambiguity, making them particularly effective in this attack. Through experiments on state-of-the-art Judge LLMs, we demonstrate that Emoji Attack substantially reduces the unsafe prediction rate, bypassing existing safeguards.",
      "authors": [
        "Zhipeng Wei",
        "Yuqi Liu",
        "N. Benjamin Erichson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T23:18:32+00:00",
          "link": "https://arxiv.org/abs/2411.01077v1",
          "size": "4226kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T17:57:26+00:00",
          "link": "https://arxiv.org/abs/2411.01077v2",
          "size": "3993kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T19:12:23+00:00",
          "link": "https://arxiv.org/abs/2411.01077v3",
          "size": "2689kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T05:39:08+00:00",
          "link": "https://arxiv.org/abs/2411.01077v4",
          "size": "3059kb",
          "version": "v4"
        }
      ],
      "title": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01077",
        "HTML": "https://arxiv.org/html/2411.01077v4",
        "PDF": "https://arxiv.org/pdf/2411.01077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a strategy (Emoji Attack) that affects token segmentation, which may indirectly pertain to data processing in terms of LLM vulnerability, but it does not focus on improving LLM training data quality."
      },
      "tasks": [
        "Few-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/zhipeng-wei/EmojiAttack"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02367",
      "abstract": "We propose Electrostatic Field Matching (EFM), a novel method that is suitable for both generative modeling and distribution transfer tasks. Our approach is inspired by the physics of an electrical capacitor. We place source and target distributions on the capacitor plates and assign them positive and negative charges, respectively. We then learn the electrostatic field of the capacitor using a neural network approximator. To map the distributions to each other, we start at one plate of the capacitor and move the samples along the learned electrostatic field lines until they reach the other plate. We theoretically justify that this approach provably yields the distribution transfer. In practice, we demonstrate the performance of our EFM in toy and image data experiments.",
      "authors": [
        "Alexander Kolesov",
        "Manukhov Stepan",
        "Vladimir V. Palyulin",
        "Alexander Korotin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T14:50:16+00:00",
          "link": "https://arxiv.org/abs/2502.02367v1",
          "size": "2788kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:36:28+00:00",
          "link": "https://arxiv.org/abs/2502.02367v2",
          "size": "3000kb",
          "version": "v2"
        }
      ],
      "title": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02367",
        "HTML": "https://arxiv.org/html/2502.02367v2",
        "PDF": "https://arxiv.org/pdf/2502.02367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for distribution transfer tasks using electrostatic field matching, but does not explicitly focus on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08183",
      "abstract": "In the field of quantum machine learning (QML), parametrized quantum circuits (PQCs) -- constructed using a combination of fixed and tunable quantum gates -- provide a promising hybrid framework for tackling complex machine learning problems. Despite numerous proposed applications, there remains limited exploration of datasets relevant to quantum chemistry. In this study, we investigate the potential benefits and limitations of PQCs on two chemically meaningful datasets: (1) the BSE49 dataset, containing bond separation energies for 49 different classes of chemical bonds, and (2) a dataset of water conformations, where coupled-cluster singles and doubles (CCSD) wavefunctions are predicted from lower-level electronic structure methods using the data-driven coupled-cluster (DDCC) approach. We construct a comprehensive set of 168 PQCs by combining 14 data encoding strategies with 12 variational ans{\\\"a}tze, and evaluate their performance on circuits with 5 and 16 qubits. Our initial analysis examines the impact of circuit structure on model performance using state-vector simulations. We then explore how circuit depth and training set size influence model performance. Finally, we assess the performance of the best-performing PQCs on current quantum hardware, using both noisy simulations (\"fake\" backends) and real quantum devices. Our findings underscore the challenges of applying PQCs to chemically relevant problems that are straightforward for classical machine learning methods but remain non-trivial for quantum approaches.",
      "authors": [
        "Grier M. Jones",
        "Viki Kumar Prasad",
        "Ulrich Fekl",
        "and Hans-Arno Jacobsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:35:33+00:00",
          "link": "https://arxiv.org/abs/2507.08183v1",
          "size": "12252kb",
          "version": "v1"
        }
      ],
      "title": "Parametrized Quantum Circuit Learning for Quantum Chemical Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08183",
        "HTML": "https://arxiv.org/html/2507.08183v1",
        "PDF": "https://arxiv.org/pdf/2507.08183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores quantum machine learning applications using parametrized quantum circuits but does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08283",
      "abstract": "The rise of LLM has enabled natural language-based table assistants, but existing systems assume users already have a well-formed table, neglecting the challenge of table discovery in large-scale table pools. To address this, we introduce TableCopilot, an LLM-powered assistant for interactive, precise, and personalized table discovery and analysis. We define a novel scenario, nlcTD, where users provide both a natural language condition and a query table, enabling intuitive and flexible table discovery for users of all expertise levels. To handle this, we propose Crofuma, a cross-fusion-based approach that learns and aggregates single-modal and cross-modal matching scores. Experimental results show Crofuma outperforms SOTA single-input methods by at least 12% on NDCG@5. We also release an instructional video, codebase, datasets, and other resources on GitHub to encourage community contributions. TableCopilot sets a new standard for interactive table assistants, making advanced table discovery accessible and integrated.",
      "authors": [
        "Lingxi Cui",
        "Guanyu Jiang",
        "Huan Li",
        "Ke Chen",
        "Lidan Shou",
        "Gang Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:16:55+00:00",
          "link": "https://arxiv.org/abs/2507.08283v1",
          "size": "771kb",
          "version": "v1"
        }
      ],
      "title": "TableCopilot: A Table Assistant Empowered by Natural Language Conditional Table Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08283",
        "HTML": "https://arxiv.org/html/2507.08283v1",
        "PDF": "https://arxiv.org/pdf/2507.08283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving table discovery using natural language conditions, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08530",
      "abstract": "Generating expressive audio performances from music scores requires models to capture both instrument acoustics and human interpretation. Traditional music performance synthesis pipelines follow a two-stage approach, first generating expressive performance MIDI from a score, then synthesising the MIDI into audio. However, the synthesis models often struggle to generalise across diverse MIDI sources, musical styles, and recording environments. To address these challenges, we propose MIDI-VALLE, a neural codec language model adapted from the VALLE framework, which was originally designed for zero-shot personalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio synthesis, we improve the architecture to condition on a reference audio performance and its corresponding MIDI. Unlike previous TTS-based systems that rely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens, facilitating a more consistent and robust modelling of piano performances. Furthermore, the model's generalisation ability is enhanced by training on an extensive and diverse piano performance dataset. Evaluation results show that MIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving over 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the listening test, MIDI-VALLE received 202 votes compared to 58 for the baseline, demonstrating improved synthesis quality and generalisation across diverse performance MIDI inputs.",
      "authors": [
        "Jingjing Tang",
        "Xin Wang",
        "Zhe Zhang",
        "Junichi Yamagishi",
        "Geraint Wiggins",
        "George Fazekas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:28:20+00:00",
          "link": "https://arxiv.org/abs/2507.08530v1",
          "size": "1369kb",
          "version": "v1"
        }
      ],
      "title": "MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08530",
        "HTML": "https://arxiv.org/html/2507.08530v1",
        "PDF": "https://arxiv.org/pdf/2507.08530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses music synthesis using neural codec language modeling, with improvements in MIDI-to-audio synthesis, but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.24240",
      "abstract": "This paper examines the relationship between system imbalance and several explanatory variables within the French electricity system. The factors considered include lagged imbalance values, observations of renewable energy sources (RES) generation and consumption, and forecasts for RES generation and consumption. The study analyzes the distribution of system imbalance in relation to these variables. Additionally, an HGBR machine-learning model is employed to assess the predictability of imbalances and the explanatory power of the input variables studied.\n  The results indicate no clear correlation between RES generation or consumption and the observed imbalances. However, it is possible to predict the imbalance adequately using forecasts available a few hours before real-time, along with the lagged values of the imbalance. Predicting the imbalance a day in advance proves to be complex with the variables examined; however, the extreme quantiles of the imbalance used for reserve sizing and contracting can be predicted with sufficient accuracy.",
      "authors": [
        "Jonathan Dumas",
        "S\\'ebastien Finet",
        "Nathalie Grisey",
        "Ibtissam Hamdane",
        "Paul Plessiez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T15:53:47+00:00",
          "link": "https://arxiv.org/abs/2503.24240v1",
          "size": "2846kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of the French system imbalance paving the way for a novel operating reserve sizing approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.24240",
        "HTML": "https://arxiv.org/html/2503.24240",
        "PDF": "https://arxiv.org/pdf/2503.24240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes system imbalance in the French electricity system using machine learning models, which is not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.01762",
      "abstract": "The quality of simplex mesh is crucial for the stability and accuracy of numerical simulations in finite element analysis and computational geometry. However, the presence of sliver elements in 3D simplex mesh can severely impact the results. This paper presents a novel method based on a radius ratio energy function to optimize the quality of simplex mesh elements. This method can effectively eliminate sliver elements, thereby enhancing mesh quality.The gradient of the proposed energy function can be decomposed into a matrix-vector product. With minor processing, the matrix becomes symmetric positive definite, and this symmetric positive definite matrix can serve as a preconditioner to significantly accelerate the optimization process. Experimental results demonstrate that this method has significant advantages in eliminating sliver elements and improving mesh quality.",
      "authors": [
        "Dong Wang",
        "Chunyu Chen and Huayi Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T14:45:35+00:00",
          "link": "https://arxiv.org/abs/2507.01762v1",
          "size": "6896kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:25:59+00:00",
          "link": "https://arxiv.org/abs/2507.01762v2",
          "size": "6896kb",
          "version": "v2"
        }
      ],
      "title": "Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01762",
        "HTML": "https://arxiv.org/html/2507.01762v2",
        "PDF": "https://arxiv.org/pdf/2507.01762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for optimizing simplex mesh quality, aimed at eliminating sliver elements for better numerical simulations. It does not pertain to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.08846",
      "abstract": "Automatic Speech Recognition (ASR) has transformed daily tasks from video transcription to workplace hiring. ASR systems' growing use warrants robust and standardized auditing approaches to ensure automated transcriptions of high and equitable quality. This is especially critical for people with speech and language disorders (such as aphasia) who may disproportionately depend on ASR systems to navigate everyday life. In this work, we identify three pitfalls in existing standard ASR auditing procedures, and demonstrate how addressing them impacts audit results via a case study of six popular ASR systems' performance for aphasia speakers. First, audits often adhere to a single method of text standardization during data pre-processing, which (a) masks variability in ASR performance from applying different standardization methods, and (b) may not be consistent with how users - especially those from marginalized speech communities - would want their transcriptions to be standardized. Second, audits often display high-level demographic findings without further considering performance disparities among (a) more nuanced demographic subgroups, and (b) relevant covariates capturing acoustic information from the input audio. Third, audits often rely on a single gold-standard metric -- the Word Error Rate -- which does not fully capture the extent of errors arising from generative AI models, such as transcription hallucinations. We propose a more holistic auditing framework that accounts for these three pitfalls, and exemplify its results in our case study, finding consistently worse ASR performance for aphasia speakers relative to a control group. We call on practitioners to implement these robust ASR auditing practices that remain flexible to the rapidly changing ASR landscape.",
      "authors": [
        "Katelyn Xiaoying Mei",
        "Anna Seo Gyeong Choi",
        "Hilke Schellmann",
        "Mona Sloane",
        "and Allison Koenecke"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T14:34:36+00:00",
          "link": "https://arxiv.org/abs/2506.08846v1",
          "size": "170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:20:23+00:00",
          "link": "https://arxiv.org/abs/2506.08846v2",
          "size": "173kb",
          "version": "v2"
        }
      ],
      "title": "Addressing Pitfalls in Auditing Practices of Automatic Speech Recognition Technologies: A Case Study of People with Aphasia",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08846",
        "HTML": "https://arxiv.org/html/2506.08846v2",
        "PDF": "https://arxiv.org/pdf/2506.08846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on auditing practices of ASR technologies with a case study on people with aphasia, without mentioning processing or creation of LLM training data."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Automatic Speech Recognition (ASR)",
        "Navigate",
        "speech-recognition",
        "Speech Recognition"
      ],
      "repo_urls": [
        "https://github.com/koenecke/auditing_asr_aphasia"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.14765",
      "abstract": "This study presents a deep learning-based framework for predicting emergency department (ED) boarding counts six hours in advance using only operational and contextual data, without patient-level information. Data from ED tracking systems, inpatient census, weather, holidays, and local events were aggregated hourly and processed with comprehensive feature engineering. The mean ED boarding count was 28.7 (standard deviation = 11.2). Multiple deep learning models, including ResNetPlus, TSTPlus, and TSiTPlus, were trained and optimized using Optuna, with TSTPlus achieving the best results (mean absolute error = 4.30, mean squared error = 29.47, R2 = 0.79). The framework accurately forecasted boarding counts, including during extreme periods, and demonstrated that broader input features improve predictive accuracy. This approach supports proactive hospital management and offers a practical method for mitigating ED overcrowding.",
      "authors": [
        "Orhun Vural",
        "Bunyamin Ozaydin",
        "James Booth",
        "Brittany F. Lindsey",
        "Abdulaziz Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T17:35:47+00:00",
          "link": "https://arxiv.org/abs/2505.14765v1",
          "size": "584kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T22:47:00+00:00",
          "link": "https://arxiv.org/abs/2505.14765v2",
          "size": "705kb",
          "version": "v2"
        }
      ],
      "title": "Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14765",
        "PDF": "https://arxiv.org/pdf/2505.14765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study applies deep learning to predict ED boarding counts based on contextual data without discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Feature Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08197",
      "abstract": "This paper develops a neural jamming phase diagram that interprets the emergence of consciousness in large language models as a critical phenomenon in high-dimensional disordered systems.By establishing analogies with jamming transitions in granular matter and other complex systems, we identify three fundamental control parameters governing the phase behavior of neural networks: temperature, volume fraction, and stress.The theory provides a unified physical explanation for empirical scaling laws in artificial intelligence, demonstrating how computational cooling, density optimization, and noise reduction collectively drive systems toward a critical jamming surface where generalized intelligence emerges. Remarkably, the same thermodynamic principles that describe conventional jamming transitions appear to underlie the emergence of consciousness in neural networks, evidenced by shared critical signatures including divergent correlation lengths and scaling exponents.Our work explains neural language models' critical scaling through jamming physics, suggesting consciousness is a jamming phase that intrinsically connects knowledge components via long-range correlations.",
      "authors": [
        "Kaichen Ouyang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:07:06+00:00",
          "link": "https://arxiv.org/abs/2507.08197v1",
          "size": "699kb",
          "version": "v1"
        }
      ],
      "title": "Consciousness as a Jamming Phase",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08197",
        "HTML": "https://arxiv.org/html/2507.08197v1",
        "PDF": "https://arxiv.org/pdf/2507.08197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interpreting the emergence of consciousness in LLMs through a physics-based framework, which is unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.01403",
      "abstract": "Traditional sparse and dense retrieval methods struggle to leverage general world knowledge and often fail to capture the nuanced features of queries and products. With the advent of large language models (LLMs), industrial search systems have started to employ LLMs to generate identifiers for product retrieval. Commonly used identifiers include (1) static/semantic IDs and (2) product term sets. The first approach requires creating a product ID system from scratch, missing out on the world knowledge embedded within LLMs. While the second approach leverages this general knowledge, the significant difference in word distribution between queries and products means that product-based identifiers often do not align well with user search queries, leading to missed product recalls. Furthermore, when queries contain numerous attributes, these algorithms generate a large number of identifiers, making it difficult to assess their quality, which results in low overall recall efficiency.\n  To address these challenges, this paper introduces a novel e-commerce retrieval paradigm: the Generative Retrieval and Alignment Model (GRAM). GRAM employs joint training on text information from both queries and products to generate shared text identifier codes, effectively bridging the gap between queries and products. This approach not only enhances the connection between queries and products but also improves inference efficiency. The model uses a co-alignment strategy to generate codes optimized for maximizing retrieval efficiency. Additionally, it introduces a query-product scoring mechanism to compare product values across different codes, further boosting retrieval efficiency. Extensive offline and online A/B testing demonstrates that GRAM significantly outperforms traditional models and the latest generative retrieval models, confirming its effectiveness and practicality.",
      "authors": [
        "Ming Pang",
        "Chunyuan Yuan",
        "Xiaoyu He",
        "Zheng Fang",
        "Donghao Xie",
        "Fanyi Qu",
        "Xue Jiang",
        "Changping Peng",
        "Zhangang Lin",
        "Ching Law",
        "Jingping Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T06:40:09+00:00",
          "link": "https://arxiv.org/abs/2504.01403v1",
          "size": "486kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:49:25+00:00",
          "link": "https://arxiv.org/abs/2504.01403v2",
          "size": "487kb",
          "version": "v2"
        }
      ],
      "title": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01403",
        "HTML": "https://arxiv.org/html/2504.01403v2",
        "PDF": "https://arxiv.org/pdf/2504.01403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on e-commerce retrieval through the Generative Retrieval and Alignment Model, optimizing product and query alignment; there is no mention of LLM training data processing."
      },
      "tasks": [
        "General Knowledge",
        "Retrieval",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05520",
      "abstract": "Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.",
      "authors": [
        "Cecil Pang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T19:06:06+00:00",
          "link": "https://arxiv.org/abs/2506.05520v1",
          "size": "1030kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:49:26+00:00",
          "link": "https://arxiv.org/abs/2506.05520v2",
          "size": "1014kb",
          "version": "v2"
        }
      ],
      "title": "Toward Data Systems That Are Business Semantic Centric and AI Agents Assisted",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05520",
        "PDF": "https://arxiv.org/pdf/2506.05520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes the Business Semantics Centric, AI Agents Assisted Data System (BSDS), describing efficient data pipelines and curated data, indicating a significant contribution to data system design which can relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08109",
      "abstract": "The advent of language models (LMs) has the potential to dramatically accelerate tasks that may be cast to text-processing; however, real-world adoption is hindered by concerns regarding safety, explainability, and bias. How can we responsibly leverage LMs in a transparent, auditable manner -- minimizing risk and allowing human experts to focus on informed decision-making rather than data-processing or prompt engineering? In this work, we propose a framework for declaring statically typed, LM-powered subroutines (i.e., callable, function-like procedures) for use within conventional asynchronous code -- such that sparse feedback from human experts is used to improve the performance of each subroutine online (i.e., during use). In our implementation, all LM-produced artifacts (i.e., prompts, inputs, outputs, and data-dependencies) are recorded and exposed to audit on demand. We package this framework as a library to support its adoption and continued development. While this framework may be applicable across several real-world decision workflows (e.g., in healthcare and legal fields), we evaluate it in the context of public comment processing as mandated by the 1969 National Environmental Protection Act (NEPA): Specifically, we use this framework to develop \"CommentNEPA,\" an application that compiles, organizes, and summarizes a corpus of public commentary submitted in response to a project requiring environmental review. We quantitatively evaluate the application by comparing its outputs (when operating without human feedback) to historical ``ground-truth'' data as labelled by human annotators during the preparation of official environmental impact statements.",
      "authors": [
        "Reilly Raab",
        "Mike Parker",
        "Dan Nally",
        "Sadie Montgomery",
        "Anastasia Bernat",
        "Sai Munikoti",
        "Sameera Horawalavithana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:52:09+00:00",
          "link": "https://arxiv.org/abs/2507.08109v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Audit, Alignment, and Optimization of LM-Powered Subroutines with Application to Public Comment Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08109",
        "HTML": "https://arxiv.org/html/2507.08109v1",
        "PDF": "https://arxiv.org/pdf/2507.08109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a framework for using LMs in public comment processing and emphasizes recording LM-produced artifacts for audit, it primarily focuses on LM usage, not on training-data engineering or preprocessing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08355",
      "abstract": "Recent advances in sequencing technologies have enabled researchers to explore cellular heterogeneity at single-cell resolution. Meanwhile, interpretability has gained prominence parallel to the rapid increase in the complexity and performance of deep learning models. In recent years, topic models have been widely used for interpretable single-cell embedding learning and clustering analysis, which we refer to as single-cell embedded topic models. However, previous studies evaluated the interpretability of the models mainly through qualitative analysis, and these single-cell embedded topic models suffer from the potential problem of interpretation collapse. Furthermore, their neglect of external biological knowledge constrains analytical performance. Here, we present scE2TM, an external knowledge-guided single-cell embedded topic model that provides a high-quality cell embedding and strong interpretation, contributing to comprehensive scRNA-seq data analysis. Our comprehensive evaluation across 20 scRNA-seq datasets demonstrates that scE2TM achieves significant clustering performance gains compared to 7 state-of-the-art methods. In addition, we propose a new interpretability evaluation benchmark that introduces 10 metrics to quantitatively assess the interpretability of single-cell embedded topic models. The results show that the interpretation provided by scE2TM performs encouragingly in terms of diversity and consistency with the underlying biological signals, contributing to a better revealing of the underlying biological mechanisms.",
      "authors": [
        "Hegang Chen",
        "Yuyin Lu",
        "Zhiming Dai",
        "Fu Lee Wang",
        "Qing Li",
        "Yanghui Rao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:15:13+00:00",
          "link": "https://arxiv.org/abs/2507.08355v1",
          "size": "11946kb",
          "version": "v1"
        }
      ],
      "title": "scE$^2$TM: Toward Interpretable Single-Cell Embedding via Topic Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08355",
        "HTML": "https://arxiv.org/html/2507.08355v1",
        "PDF": "https://arxiv.org/pdf/2507.08355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on single-cell embedding and clustering using topic models and does not involve LLM training data processing or any related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08411",
      "abstract": "Scaled relative graphs have been originally introduced in the context of convex optimization and have recently gained attention in the control systems community for the graphical analysis of nonlinear systems. Of particular interest in stability analysis of feedback systems is the scaled graph, a special case of the scaled relative graph. In many ways, scaled graphs can be seen as a generalization of the classical Nyquist plot for linear time-invariant systems, and facilitate a powerful graphical tool for analyzing nonlinear feedback systems. In their current formulation, however, scaled graphs require characterizing the input-output behaviour of a system for an uncountable number of inputs. This poses a practical bottleneck in obtaining the scaled graph of a nonlinear system, and currently limits its use. This paper presents a framework grounded in dissipativity for efficiently computing the scaled graph of several important classes of systems, including multivariable linear time-invariant systems, impulsive systems, and piecewise linear systems. The proposed approach leverages novel connections between linear matrix inequalities, integral quadratic constraints, and scaled graphs, and is shown to be exact for specific linear time-invariant systems. The results are accompanied by several examples illustrating the potential and effectiveness of the presented framework.",
      "authors": [
        "Timo de Groot",
        "Maurice heemels",
        "Sebastiaan van den Eijnden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:47:07+00:00",
          "link": "https://arxiv.org/abs/2507.08411v1",
          "size": "2018kb",
          "version": "v1"
        }
      ],
      "title": "A Dissipativity Framework for Constructing Scaled Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08411",
        "HTML": "https://arxiv.org/html/2507.08411v1",
        "PDF": "https://arxiv.org/pdf/2507.08411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a dissipativity framework for scaled graphs in nonlinear systems analysis, which is unrelated to LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08433",
      "abstract": "The publication of social graphs must be preceded by a rigorous analysis of privacy threats against social graph users. When the threat comes from inside the social network itself, the threat is called an active attack, and the de-facto privacy measure used to quantify the resistance to such an attack is the $(k,\\ell)$-anonymity. The original formulation of $(k,\\ell)$-anonymity represents the adversary's knowledge as a vector of distances to the set of attacker nodes. In this article, we argue that such adversary is too strong when it comes to counteracting active attacks. We, instead, propose a new formulation where the adversary's knowledge is the multiset of distances to the set of attacker nodes. The goal of this article is to study the $(k,\\ell)$-multiset anonymity from a graph theoretical point of view, while establishing its relationship to $(k,\\ell)$-anonymity in one hand, and considering the $k$-multiset antiresolving sets as its theoretical frame, in a second one. That is, we prove properties of some graph families in relation to whether they contain a set of attacker nodes that breaks the $(k,\\ell)$-multiset anonymity. From a practical point of view, we develop a linear programming formulation of the $k$-multiset antiresolving sets that allows us to calculate the resistance of social graphs against active attacks. This is useful for analysts who wish to know the level of privacy offered by a graph.",
      "authors": [
        "Alejandro Estrada-Moreno",
        "Elena Fern\\'andez",
        "Dorota Kuziak",
        "Manuel Mu\\~noz-M\\'arquez",
        "Rolando Trujillo-Rasua",
        "Ismael G. Yero"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:19:58+00:00",
          "link": "https://arxiv.org/abs/2507.08433v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "On the $(k,\\ell)$-multiset anonymity measure for social graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08433",
        "HTML": "https://arxiv.org/html/2507.08433v1",
        "PDF": "https://arxiv.org/pdf/2507.08433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy measures for social graph publication and active attacks but does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08537",
      "abstract": "In reinforcement learning (RL), aligning agent behavior with specific objectives typically requires careful design of the reward function, which can be challenging when the desired objectives are complex. In this work, we propose an alternative approach for flexible behavior alignment that eliminates the need to modify the reward function by selecting appropriate reward aggregation functions. By introducing an algebraic perspective on Markov decision processes (MDPs), we show that the Bellman equations naturally emerge from the recursive generation and aggregation of rewards, allowing for the generalization of the standard discounted sum to other recursive aggregations, such as discounted max and Sharpe ratio. Our approach applies to both deterministic and stochastic settings and integrates seamlessly with value-based and actor-critic algorithms. Experimental results demonstrate that our approach effectively optimizes diverse objectives, highlighting its versatility and potential for real-world applications.",
      "authors": [
        "Yuting Tang",
        "Yivan Zhang",
        "Johannes Ackermann",
        "Yu-Jie Zhang",
        "Soichiro Nishimori",
        "Masashi Sugiyama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:37:20+00:00",
          "link": "https://arxiv.org/abs/2507.08537v1",
          "size": "2697kb",
          "version": "v1"
        }
      ],
      "title": "Recursive Reward Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08537",
        "PDF": "https://arxiv.org/pdf/2507.08537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reward aggregation in reinforcement learning and does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.17285",
      "abstract": "A/B testing has become the gold standard for policy evaluation in modern technological industries. Motivated by the widespread use of switchback experiments in A/B testing, this paper conducts a comprehensive comparative analysis of various switchback designs in Markovian environments. Unlike many existing works which derive the optimal design based on specific and relatively simple estimators, our analysis covers a range of state-of-the-art estimators developed in the reinforcement learning (RL) literature. It reveals that the effectiveness of different switchback designs depends crucially on (i) the size of the carryover effect and (ii) the auto-correlations among reward errors over time. Meanwhile, these findings are estimator-agnostic, i.e., they apply to most RL estimators. Based on these insights, we provide a workflow to offer guidelines for practitioners on designing switchback experiments in A/B testing.",
      "authors": [
        "Qianglin Wen",
        "Chengchun Shi",
        "Yang Ying",
        "Niansheng Tang and Hongtu Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-26T00:25:32+00:00",
          "link": "https://arxiv.org/abs/2403.17285v1",
          "size": "8252kb",
          "version": "v1"
        },
        {
          "date": "2024-10-05T04:24:18+00:00",
          "link": "https://arxiv.org/abs/2403.17285v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-05-29T12:21:30+00:00",
          "link": "https://arxiv.org/abs/2403.17285v3",
          "size": "16822kb",
          "version": "v3"
        },
        {
          "date": "2025-06-19T01:39:49+00:00",
          "link": "https://arxiv.org/abs/2403.17285v4",
          "size": "24395kb",
          "version": "v4"
        },
        {
          "date": "2025-07-11T05:19:33+00:00",
          "link": "https://arxiv.org/abs/2403.17285v5",
          "size": "26592kb",
          "version": "v5"
        }
      ],
      "title": "Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17285",
        "HTML": "https://arxiv.org/html/2403.17285v5",
        "PDF": "https://arxiv.org/pdf/2403.17285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study discusses switchback experiments and A/B testing in policy evaluation without any aspects related to LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18355",
      "abstract": "This paper studies the problem of using a robot arm to manipulate a uniformly rotating chain with its bottom end fixed. Existing studies have investigated ideal rotational shapes for practical applications, yet they do not discuss how these shapes can be consistently achieved through manipulation planning. Our work presents a manipulation strategy for stable and consistent shape transitions. We find that the configuration space of such a chain is homeomorphic to a three-dimensional cube. Using this property, we suggest a strategy to manipulate the chain into different configurations, specifically from one rotation mode to another, while taking stability and feasibility into consideration. We demonstrate the effectiveness of our strategy in physical experiments by successfully transitioning from rest to the first two rotation modes. The concepts explored in our work have critical applications in ensuring safety and efficiency of drill string and yarn spinning operations.",
      "authors": [
        "Qi Jing Chen",
        "Shilin Shan",
        "and Quang-Cuong Pham"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T07:31:04+00:00",
          "link": "https://arxiv.org/abs/2506.18355v1",
          "size": "3159kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:20:16+00:00",
          "link": "https://arxiv.org/abs/2506.18355v2",
          "size": "3159kb",
          "version": "v2"
        }
      ],
      "title": "Robotic Manipulation of a Rotating Chain with Bottom End Fixed",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18355",
        "HTML": "https://arxiv.org/html/2506.18355v2",
        "PDF": "https://arxiv.org/pdf/2506.18355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies robotic manipulation strategies, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20893",
      "abstract": "In this work, we introduce an output-reweighting unlearning method, RWFT, a lightweight technique that erases an entire class from a trained classifier without full retraining. Forgetting specific classes from trained models is essential for enforcing user deletion rights and mitigating harmful or biased predictions. The full retraining is costly and existing unlearning methods fail to replicate the behavior of the retrained models when predicting samples from the unlearned class. We prove this failure by designing a variant of membership inference attacks, MIA-NN that successfully reveals the unlearned class for any of these methods. We propose a simple redistribution of the probability mass for the prediction on the samples in the forgotten class which is robust to MIA-NN. We also introduce a new metric based on the total variation (TV) distance of the prediction probabilities to quantify residual leakage to prevent future methods from susceptibility to the new attack. Through extensive experiments with state of the art baselines in machine unlearning, we show that our approach matches the results of full retraining in both metrics used for evaluation by prior work and the new metric we propose in this work. Compare to state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45% in our new TV-based metric over the best existing method.",
      "authors": [
        "Yian Wang",
        "Ali Ebrahimpour-Boroojeny",
        "and Hari Sundaram"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T23:53:56+00:00",
          "link": "https://arxiv.org/abs/2506.20893v1",
          "size": "487kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T22:55:52+00:00",
          "link": "https://arxiv.org/abs/2506.20893v2",
          "size": "487kb",
          "version": "v2"
        }
      ],
      "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20893",
        "HTML": "https://arxiv.org/html/2506.20893v2",
        "PDF": "https://arxiv.org/pdf/2506.20893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a technique for output distribution reweighting to facilitate class unlearning but does not specifically focus on LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.03366",
      "abstract": "In classification tasks, softmax functions are ubiquitously used as output activations to produce predictive probabilities. Such outputs only capture aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian inference methods have been proposed. We develop a common formalism to describe such methods, which we view as outputting Gaussian distributions over the logit space. Predictives are then obtained as the expectations of the Gaussian distributions pushed forward through the softmax. However, such softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC) approximations can be costly and noisy. We propose to replace the softmax activation by element-wise normCDF or sigmoid, which allows for the accurate sampling-free approximation of predictives. This also enables the approximation of the Gaussian pushforwards by Dirichlet distributions with moment matching. This approach entirely eliminates the runtime and memory overhead associated with MC sampling. We evaluate it combined with several approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and small-scale datasets (ImageNet, CIFAR-100, CIFAR-10), demonstrating improved uncertainty quantification capabilities compared to softmax MC sampling.",
      "authors": [
        "B\\'alint Mucs\\'anyi",
        "Natha\\\"el Da Costa",
        "Philipp Hennig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T17:03:49+00:00",
          "link": "https://arxiv.org/abs/2502.03366v1",
          "size": "3224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:06:51+00:00",
          "link": "https://arxiv.org/abs/2502.03366v2",
          "size": "3336kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Approximate Gaussian Inference in Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03366",
        "HTML": "https://arxiv.org/html/2502.03366v2",
        "PDF": "https://arxiv.org/pdf/2502.03366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Gaussian inference methods for uncertainty quantification in classification tasks, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06565",
      "abstract": "Large-language models turn writing into a live exchange between humans and software. We capture this new medium with a discursive-network model that treats people and LLMs as equal nodes and tracks how their statements circulate. Broadening the focus from isolated hallucinations, we define invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. A general mathematical model of discursive networks is developed to provide valuable insights: A network governed only by drift and self-repair stabilizes at a modest error rate; adding fabrication reproduces the high rates seen in current LLMs. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a configurable loop in which any set of agents critique one another while a harmoniser merges their verdicts. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from wiring imperfect ones into networks that keep each other honest.",
      "authors": [
        "Juan B. Guti\\'errez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.06565v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:34:51+00:00",
          "link": "https://arxiv.org/abs/2507.06565v2",
          "size": "742kb",
          "version": "v2"
        }
      ],
      "title": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06565",
        "HTML": "https://arxiv.org/html/2507.06565v2",
        "PDF": "https://arxiv.org/pdf/2507.06565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily addresses a framework for assessing LLM outputs within a network of human and machine nodes but does not directly focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08015",
      "abstract": "This work evaluates FinGPT, a financial domain-specific language model, across six key natural language processing (NLP) tasks: Sentiment Analysis, Text Classification, Named Entity Recognition, Financial Question Answering, Text Summarization, and Stock Movement Prediction. The evaluation uses finance-specific datasets to assess FinGPT's capabilities and limitations in real-world financial applications. The results show that FinGPT performs strongly in classification tasks such as sentiment analysis and headline categorization, often achieving results comparable to GPT-4. However, its performance is significantly lower in tasks that involve reasoning and generation, such as financial question answering and summarization. Comparisons with GPT-4 and human benchmarks highlight notable performance gaps, particularly in numerical accuracy and complex reasoning. Overall, the findings indicate that while FinGPT is effective for certain structured financial tasks, it is not yet a comprehensive solution. This research provides a useful benchmark for future research and underscores the need for architectural improvements and domain-specific optimization in financial language models.",
      "authors": [
        "Prudence Djagba and Chimezie A. Odinakachukwu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T20:02:08+00:00",
          "link": "https://arxiv.org/abs/2507.08015v1",
          "size": "1478kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08015",
        "HTML": "https://arxiv.org/html/2507.08015v1",
        "PDF": "https://arxiv.org/pdf/2507.08015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on evaluating FinGPT using finance-specific datasets for various NLP tasks without discussing any processing or engineering of the training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08506",
      "abstract": "The downward continuation of potential fields from the Earth's surface into the subsurface is a critical task in gravity exploration, as it helps to identify the sources of gravity anomalies. This problem is often addressed by solving a first-kind integral equation using regularization techniques to stabilize an inherently unstable process. A similar approach is used in our work, where the continued field is represented as the potential of a simple layer or its vertical derivative. The constancy of the density sign of this equivalent simple layer preserves the sign of anomalies, provided that the layer's surface encloses all anomalous sources. This constraint is a key feature of our algorithm for the downward continuation of potential fields. To enforce, for instance, non-negativity in the simple layer density, we employ the NNLS (Non-Negative Least Squares) method. The efficiency of the proposed method is demonstrated on model examples.",
      "authors": [
        "D. K. Ivanov",
        "L. N. Temirbekova",
        "P. N. Vabishchevich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:36:18+00:00",
          "link": "https://arxiv.org/abs/2507.08506v1",
          "size": "755kb",
          "version": "v1"
        }
      ],
      "title": "Computational algorithm for downward continuation of gravity anomalies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08506",
        "HTML": "https://arxiv.org/html/2507.08506v1",
        "PDF": "https://arxiv.org/pdf/2507.08506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on gravity exploration techniques and does not discuss LLM training data processing or any data engineering operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.14679",
      "abstract": "Domain adaptation for object detection (DAOD) has become essential to counter performance degradation caused by distribution shifts between training and deployment domains. However, a critical factor influencing DAOD - context bias resulting from learned foreground-background (FG-BG) associations - has remained underexplored. We address three key questions regarding FG BG associations in object detection: are FG-BG associations encoded during the training, is there a causal relationship between FG-BG associations and detection performance, and is there an effect of FG-BG association on DAOD. To examine how models capture FG BG associations, we analyze class-wise and feature-wise performance degradation using background masking and feature perturbation, measured via change in accuracies (defined as drop rate). To explore the causal role of FG-BG associations, we apply do-calculus on FG-BG pairs guided by class activation mapping (CAM). To quantify the causal influence of FG-BG associations across domains, we propose a novel metric - domain association gradient - defined as the ratio of drop rate to maximum mean discrepancy (MMD). Through systematic experiments involving background masking, feature-level perturbations, and CAM, we reveal that convolution-based object detection models encode FG-BG associations. Our results demonstrate that context bias not only exists but causally undermines the generalization capabilities of object detection models across domains. Furthermore, we validate these findings across multiple models and datasets, including state-of-the-art architectures such as ALDI++. This study highlights the necessity of addressing context bias explicitly in DAOD frameworks, providing insights that pave the way for developing more robust and generalizable object detection systems.",
      "authors": [
        "Hojun Son",
        "Asma Almutairi and Arpan Kusari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T03:01:50+00:00",
          "link": "https://arxiv.org/abs/2409.14679v1",
          "size": "13719kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T15:50:40+00:00",
          "link": "https://arxiv.org/abs/2409.14679v2",
          "size": "15231kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T16:23:12+00:00",
          "link": "https://arxiv.org/abs/2409.14679v3",
          "size": "21325kb",
          "version": "v3"
        }
      ],
      "title": "Quantifying Context Bias in Domain Adaptation for Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14679",
        "HTML": "https://arxiv.org/html/2409.14679v3",
        "PDF": "https://arxiv.org/pdf/2409.14679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses context bias in domain adaptation for object detection, focusing on FG-BG associations and their impacts, not on LLM training data."
      },
      "tasks": [
        "Domain Adaptation",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08021",
      "abstract": "The evolution of large models has witnessed the emergence of In-Context Learning (ICL) capabilities. In Natural Language Processing (NLP), numerous studies have demonstrated the effectiveness of ICL. Inspired by the success of Large Language Models (LLMs), researchers have developed Large Multimodal Models (LMMs) with ICL capabilities. However, explorations of demonstration configuration for multimodal ICL remain preliminary. Additionally, the controllability of In-Context Examples (ICEs) provides an efficient and cost-effective means to observe and analyze the inference characteristics of LMMs under varying inputs. This paper conducts a comprehensive external and internal investigation of multimodal in-context learning on the image captioning task. Externally, we explore demonstration configuration strategies through three dimensions: shot number, image retrieval, and caption assignment. We employ multiple metrics to systematically and thoroughly evaluate and summarize key findings. Internally, we analyze typical LMM attention characteristics and develop attention-based metrics to quantify model behaviors. We also conduct auxiliary experiments to explore the feasibility of attention-driven model acceleration and compression. We further compare performance variations between LMMs with identical model design and pretraining strategies and explain the differences from the angles of pre-training data features. Our study reveals both how ICEs configuration strategies impact model performance through external experiments and characteristic typical patterns through internal inspection, providing dual perspectives for understanding multimodal ICL in LMMs. Our method of combining external and internal analysis to investigate large models, along with our newly proposed metrics, can be applied to broader research areas.",
      "authors": [
        "Li Li",
        "Yongliang Wu",
        "Jingze Zhu",
        "Jiawei Peng",
        "Jianfei Cai",
        "Xu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:07:57+00:00",
          "link": "https://arxiv.org/abs/2507.08021v1",
          "size": "2814kb",
          "version": "v1"
        }
      ],
      "title": "Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08021",
        "HTML": "https://arxiv.org/html/2507.08021v1",
        "PDF": "https://arxiv.org/pdf/2507.08021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on demonstration configuration strategies for multimodal in-context learning but does not primarily focus on training data processing or improvement for LLMs. It is more about model evaluation and performance analysis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08311",
      "abstract": "Clustering is a critical component of decision-making in todays data-driven environments. It has been widely used in a variety of fields such as bioinformatics, social network analysis, and image processing. However, clustering accuracy remains a major challenge in large datasets. This paper presents a comprehensive overview of strategies for selecting the optimal value of k in clustering, with a focus on achieving a balance between clustering precision and computational efficiency in complex data environments. In addition, this paper introduces improvements to clustering techniques for text and image data to provide insights into better computational performance and cluster validity. The proposed approach is based on the Condensed Silhouette method, along with statistical methods such as Local Structures, Gap Statistics, Class Consistency Ratio, and a Cluster Overlap Index CCR and COIbased algorithm to calculate the best value of k for K-Means clustering. The results of comparative experiments show that the proposed approach achieves up to 99 percent faster execution times on high-dimensional datasets while retaining both precision and scalability, making it highly suitable for real time clustering needs or scenarios demanding efficient clustering with minimal resource utilization.",
      "authors": [
        "Krishnendu Das",
        "Sumit Gupta",
        "Awadhesh Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:03:16+00:00",
          "link": "https://arxiv.org/abs/2507.08311v1",
          "size": "3380kb",
          "version": "v1"
        }
      ],
      "title": "CAS Condensed and Accelerated Silhouette: An Efficient Method for Determining the Optimal K in K-Means Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08311",
        "HTML": "https://arxiv.org/html/2507.08311v1",
        "PDF": "https://arxiv.org/pdf/2507.08311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses clustering techniques and improvements without any connection to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08429",
      "abstract": "The integration of unmanned aerial vehicles (UAVs) with Internet of Things (IoT) networks offers promising solutions for efficient data collection. However, the limited energy capacity of UAVs remains a significant challenge. In this case, laser beam directors (LBDs) have emerged as an effective technology for wireless charging of UAVs during operation, thereby enabling sustained data collection without frequent returns to charging stations (CSs). In this work, we investigate the age of information (AoI) optimization in LBD-powered UAV-assisted IoT networks, where multiple UAVs collect data from distributed IoTs while being recharged by laser beams. We formulate a joint optimization problem that aims to minimize the peak AoI while determining optimal UAV trajectories and laser charging strategies. This problem is particularly challenging due to its non-convex nature, complex temporal dependencies, and the need to balance data collection efficiency with energy consumption constraints. To address these challenges, we propose a novel multi-agent proximal policy optimization with temporal memory and multi-agent coordination (MAPPO-TM) framework. Specifically, MAPPO-TM incorporates temporal memory mechanisms to capture the dynamic nature of UAV operations and facilitates effective coordination among multiple UAVs through decentralized learning while considering global system objectives. Simulation results demonstrate that the proposed MAPPO-TM algorithm outperforms conventional approaches in terms of peak AoI minimization and energy efficiency. Ideally, the proposed algorithm achieves up to 15.1% reduction in peak AoI compared to conventional multi-agent deep reinforcement learning (MADRL) methods.",
      "authors": [
        "Geng Sun",
        "Likun Zhang",
        "Jiahui Li",
        "Jing Wu",
        "Jiacheng Wang",
        "Zemin Sun",
        "Changyuan Zhao",
        "Victor C.M. Leung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.08429v1",
          "size": "906kb",
          "version": "v1"
        }
      ],
      "title": "Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08429",
        "HTML": "https://arxiv.org/html/2507.08429v1",
        "PDF": "https://arxiv.org/pdf/2507.08429"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses data collection optimization in IoT networks using UAVs, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08636",
      "abstract": "This study evaluates the recently proposed Document Attention Network (DAN) for extracting key-value information from Uruguayan birth certificates, handwritten in Spanish. We investigate two annotation strategies for automatically transcribing handwritten documents, fine-tuning DAN with minimal training data and annotation effort. Experiments were conducted on two datasets containing the same images (201 scans of birth certificates written by more than 15 different writers) but with different annotation methods. Our findings indicate that normalized annotation is more effective for fields that can be standardized, such as dates and places of birth, whereas diplomatic annotation performs much better for fields containing names and surnames, which can not be standardized.",
      "authors": [
        "Natalia Bottaioli (Universit\\'e Paris-Saclay",
        "ENS Paris-Saclay",
        "CNRS",
        "Centre Borelli",
        "France",
        "Facultad de Ingenier\\'ia",
        "Universidad de la Rep\\'ublica",
        "Montevideo",
        "Uruguay",
        "Digital Sense",
        "Montevideo",
        "Uruguay) Sol\\`ene Tarride (TEKLIA",
        "Paris",
        "France) J\\'er\\'emy Anger (Universit\\'e Paris-Saclay",
        "ENS Paris-Saclay",
        "CNRS",
        "Centre Borelli",
        "France) Seginus Mowlavi (Universit\\'e Paris-Saclay",
        "ENS Paris-Saclay",
        "CNRS",
        "Centre Borelli",
        "France) Marina Gardella (IMPA",
        "Rio de Janeiro",
        "Brazil) Antoine Tadros (Universit\\'e Paris-Saclay",
        "ENS Paris-Saclay",
        "CNRS",
        "Centre Borelli",
        "France) Gabriele Facciolo (Universit\\'e Paris-Saclay",
        "ENS Paris-Saclay",
        "CNRS",
        "Centre Borelli",
        "France) Rafael Grompone von Gioi (Universit\\'e Paris-Saclay",
        "ENS Paris-Saclay",
        "CNRS",
        "Centre Borelli",
        "France) Christopher Kermorvant (TEKLIA",
        "Paris",
        "France) Jean-Michel Morel (City University of Hong Kong",
        "Hong Kong) Javier Preciozzi (Facultad de Ingenier\\'ia",
        "Universidad de la Rep\\'ublica",
        "Montevideo",
        "Uruguay",
        "Digital Sense",
        "Montevideo",
        "Uruguay)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:40:07+00:00",
          "link": "https://arxiv.org/abs/2507.08636v1",
          "size": "1112kb",
          "version": "v1"
        }
      ],
      "title": "Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08636",
        "HTML": "https://arxiv.org/html/2507.08636v1",
        "PDF": "https://arxiv.org/pdf/2507.08636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses different annotation strategies and their effectiveness in transcribing handwritten documents but does not primarily focus on LLM training data processing; it briefly touches on data annotation methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.10657",
      "abstract": "Large language models (LLMs) can be leveraged to help with writing formulas in spreadsheets, but resources on these formulas are scarce, impacting both the base performance of pre-trained models and limiting the ability to fine-tune them. Given a corpus of formulas, we can use a(nother) model to generate synthetic natural language utterances for fine-tuning. However, it is important to validate whether the NL generated by the LLM is indeed accurate to be beneficial for fine-tuning. In this paper, we provide empirical results on the impact of validating these synthetic training examples with surrogate objectives that evaluate the accuracy of the synthetic annotations. We demonstrate that validation improves performance over raw data across four models (2 open and 2 closed weight). Interestingly, we show that although validation tends to prune more challenging examples, it increases the complexity of problems that models can solve after being fine-tuned on validated data.",
      "authors": [
        "Usneek Singh",
        "Jos\\'e Cambronero",
        "Sumit Gulwani",
        "Aditya Kanade",
        "Anirudh Khatry",
        "Vu Le",
        "Mukul Singh",
        "Gust Verbruggen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-15T12:16:33+00:00",
          "link": "https://arxiv.org/abs/2407.10657v1",
          "size": "227kb",
          "version": "v1"
        },
        {
          "date": "2024-07-23T09:41:50+00:00",
          "link": "https://arxiv.org/abs/2407.10657v2",
          "size": "226kb",
          "version": "v2"
        },
        {
          "date": "2024-11-03T12:44:42+00:00",
          "link": "https://arxiv.org/abs/2407.10657v3",
          "size": "368kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T12:24:45+00:00",
          "link": "https://arxiv.org/abs/2407.10657v4",
          "size": "449kb",
          "version": "v4"
        }
      ],
      "title": "An Empirical Study of Validating Synthetic Data for Formula Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.10657",
        "HTML": "https://arxiv.org/html/2407.10657v4",
        "PDF": "https://arxiv.org/pdf/2407.10657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on validating synthetic data generated for fine-tuning LLMs, providing empirical results and insights into improving data quality for LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.00708",
      "abstract": "We study the minimum \\emph{Monitoring Edge Geodetic Set} (\\megset) problem introduced in [Foucaud et al., CALDAM'23]: given a graph $G$, we say that an edge is monitored by a pair $u,v$ of vertices if \\emph{all} shortest paths between $u$ and $v$ traverse $e$; the goal of the problem consists in finding a subset $M$ of vertices of $G$ such that each edge of $G$ is monitored by at least one pair of vertices in $M$, and $|M|$ is minimized.\n  In this paper, we prove that all polynomial-time approximation algorithms for the minimum \\megset problem must have an approximation ratio of $\\Omega(\\log n)$, unless \\p = \\np. To the best of our knowledge, this is the first non-constant inapproximability result known for this problem. We also strengthen the known \\np-hardness of the problem on $2$-apex graphs by showing that the same result holds for $1$-apex graphs. This leaves open the problem of determining whether the problem remains \\np-hard on planar (i.e., $0$-apex) graphs.\n  On the positive side, we design an algorithm that computes good approximate solutions for hereditary graph classes that admit efficiently computable balanced separators of truly sublinear size. This immediately results in polynomial-time approximation algorithms achieving an approximation ratio of $O(n^{\\frac{1}{4}} \\sqrt{\\log n})$ on planar graphs, graphs with bounded genus, and $k$-apex graphs with $k=O(n^{\\frac{1}{4}})$. On graphs with bounded treewidth, we obtain an approximation ratio of $O(\\log^{3/2} n)$ for any constant $\\varepsilon > 0$. This compares favorably with the best-known approximation algorithm for general graphs, which achieves an approximation ratio of $O(\\sqrt{n \\log n})$ via a simple reduction to the \\textsc{Set Cover} problem.",
      "authors": [
        "Davide Bil\\`o",
        "Giordano Colli",
        "Luca Forlizzi",
        "Stefano Leucci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T12:10:38+00:00",
          "link": "https://arxiv.org/abs/2507.00708v1",
          "size": "147kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:32:31+00:00",
          "link": "https://arxiv.org/abs/2507.00708v2",
          "size": "147kb",
          "version": "v2"
        }
      ],
      "title": "On the (In)Approximability of the Monitoring Edge Geodetic Set Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00708",
        "HTML": "https://arxiv.org/html/2507.00708v2",
        "PDF": "https://arxiv.org/pdf/2507.00708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper covers algorithms for approximating the Monitoring Edge Geodetic Set problem in graph theory. It does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08406",
      "abstract": "As transistor counts in a single chip exceed tens of billions, the complexity of RTL-level simulation and verification has grown exponentially, often extending simulation campaigns to several months. In industry practice, RTL simulation is divided into two phases: functional debug and system validation. While system validation demands high simulation speed and is typically accelerated using FPGAs, functional debug relies on rapid compilation-rendering multi-core CPUs the primary choice. However, the limited simulation speed of CPUs has become a major bottleneck. To address this challenge, we propose CCSS, a scalable multi-core RTL simulation platform that achieves both fast compilation and high simulation throughput. CCSS accelerates combinational logic computation and sequential logic synchronization through specialized architecture and compilation strategies. It employs a balanced DAG partitioning method and efficient boolean computation cores for combinational logic, and adopts a low-latency network-on-chip (NoC) design to synchronize sequential states across cores efficiently. Experimental results show that CCSS delivers up to 12.9x speedup over state-of-the-art multi-core simulators.",
      "authors": [
        "Weigang Feng",
        "Yijia Zhang",
        "Zekun Wang",
        "Zhengyang Wang",
        "Yi Wang",
        "Peijun Ma",
        "Ningyi Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:27:32+00:00",
          "link": "https://arxiv.org/abs/2507.08406v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "CCSS: Hardware-Accelerated RTL Simulation with Fast Combinational Logic Computing and Sequential Logic Synchronization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08406",
        "HTML": "https://arxiv.org/html/2507.08406v1",
        "PDF": "https://arxiv.org/pdf/2507.08406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a scalable multi-core RTL simulation platform for hardware acceleration, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08456",
      "abstract": "Transformers excel when dealing with sequential data. Generalizing transformer models to geometric domains, such as manifolds, we encounter the problem of not having a well-defined global order. We propose a solution with attention heads following a space-filling curve. As a first experimental example, we present the Spiroformer, a transformer that follows a polar spiral on the $2$-sphere.",
      "authors": [
        "M. Maurin",
        "M.\\'A. Evangelista-Alvarado",
        "P. Su\\'arez-Serrato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Differential Geometry (math.DG)",
        "Dynamical Systems (math.DS)",
        "Symplectic Geometry (math.SG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:56:15+00:00",
          "link": "https://arxiv.org/abs/2507.08456v1",
          "size": "2686kb",
          "version": "v1"
        }
      ],
      "title": "Space filling positionality and the Spiroformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08456",
        "HTML": "https://arxiv.org/html/2507.08456v1",
        "PDF": "https://arxiv.org/pdf/2507.08456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a geometric adaptation of transformer models for spatial domains using space-filling curves, without mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08553",
      "abstract": "Gazetteers typically store data on place names, place types and the associated coordinates. They play an essential role in disambiguating place names in online geographical information retrieval systems for navigation and mapping, detecting and disambiguating place names in text, and providing coordinates. Currently there are many gazetteers in use derived from many sources, with no commonly accepted standard for encoding the data. Most gazetteers are also very limited in the extent to which they represent the multiple facets of the named places yet they have potential to assist user search for locations with specific physical, commercial, social or cultural characteristics. With a view to understanding digital gazetteer technologies and advancing their future effectiveness for information retrieval, we provide a review of data sources, components, software and data management technologies, data quality and volunteered data, and methods for matching sources that refer to the same real-world places. We highlight the need for future work on richer representation of named places, the temporal evolution of place identity and location, and the development of more effective methods for data integration.",
      "authors": [
        "Kalana Wijegunarathna",
        "Kristin Stock",
        "Christopher B. Jones"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:56:17+00:00",
          "link": "https://arxiv.org/abs/2507.08553v1",
          "size": "2248kb",
          "version": "v1"
        }
      ],
      "title": "Digital gazetteers: review and prospects for place name knowledge bases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08553",
        "HTML": "https://arxiv.org/html/2507.08553v1",
        "PDF": "https://arxiv.org/pdf/2507.08553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though the paper discusses data management technologies for digital gazetteers, it does not cover LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08575",
      "abstract": "Millions of biological sample records collected in the last few centuries archived in natural history collections are un-georeferenced. Georeferencing complex locality descriptions associated with these collection samples is a highly labour-intensive task collection agencies struggle with. None of the existing automated methods exploit maps that are an essential tool for georeferencing complex relations. We present preliminary experiments and results of a novel method that exploits multi-modal capabilities of recent Large Multi-Modal Models (LMM). This method enables the model to visually contextualize spatial relations it reads in the locality description. We use a grid-based approach to adapt these auto-regressive models for this task in a zero-shot setting. Our experiments conducted on a small manually annotated dataset show impressive results for our approach ($\\sim$1 km Average distance error) compared to uni-modal georeferencing with Large Language Models and existing georeferencing tools. The paper also discusses the findings of the experiments in light of an LMM's ability to comprehend fine-grained maps. Motivated by these results, a practical framework is proposed to integrate this method into a georeferencing workflow.",
      "authors": [
        "Kalana Wijegunarathna",
        "Kristin Stock",
        "Christopher B. Jones"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:23:25+00:00",
          "link": "https://arxiv.org/abs/2507.08575v1",
          "size": "3069kb",
          "version": "v1"
        }
      ],
      "title": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08575",
        "HTML": "https://arxiv.org/html/2507.08575v1",
        "PDF": "https://arxiv.org/pdf/2507.08575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of recent multi-modal models for georeferencing, implying some level of training data adaptation but does not focus primarily on detailed LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08693",
      "abstract": "We study minimum cost constraint satisfaction problems (MinCostCSP) through the algebraic lens. We show that for any constraint language $\\Gamma$ which has the dual discriminator operation as a polymorphism, there exists a $|D|$-approximation algorithm for MinCostCSP$(\\Gamma)$ where $D$ is the domain. Complementing our algorithmic result, we show that any constraint language $\\Gamma$ where MinCostCSP$(\\Gamma)$ admits a constant-factor approximation must have a \\emph{near-unanimity} (NU) polymorphism unless P = NP, extending a similar result by Dalmau et al. on MinCSPs. These results imply a dichotomy of constant-factor approximability for constraint languages that contain all permutation relations (a natural generalization for Boolean CSPs that allow variable negation): either MinCostCSP$(\\Gamma)$ has an NU polymorphism and is $|D|$-approximable, or it does not have any NU polymorphism and is NP-hard to approximate within any constant factor. Finally, we present a constraint language which has a majority polymorphism, but is nonetheless NP-hard to approximate within any constant factor assuming the Unique Games Conjecture, showing that the condition of having an NU polymorphism is in general not sufficient unless UGC fails.",
      "authors": [
        "Ian DeHaan",
        "Neng Huang",
        "Euiwoong Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.08693v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "On the Constant-Factor Approximability of Minimum Cost Constraint Satisfaction Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08693",
        "HTML": "https://arxiv.org/html/2507.08693v1",
        "PDF": "https://arxiv.org/pdf/2507.08693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on the algorithmic analysis of constraint satisfaction problems and approximation methods, without any relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.09150",
      "abstract": "Most dataset distillation methods struggle to accommodate large-scale datasets due to their substantial computational and memory requirements. Recent research has begun to explore scalable disentanglement methods. However, there are still performance bottlenecks and room for optimization in this direction. In this paper, we present a curriculum-based dataset distillation framework aiming to harmonize performance and scalability. This framework strategically distills synthetic images, adhering to a curriculum that transitions from simple to complex. By incorporating curriculum evaluation, we address the issue of previous methods generating images that tend to be homogeneous and simplistic, doing so at a manageable computational cost. Furthermore, we introduce adversarial optimization towards synthetic images to further improve their representativeness and safeguard against their overfitting to the neural network involved in distilling. This enhances the generalization capability of the distilled images across various neural network architectures and also increases their robustness to noise. Extensive experiments demonstrate that our framework sets new benchmarks in large-scale dataset distillation, achieving substantial improvements of 11.1\\% on Tiny-ImageNet, 9.0\\% on ImageNet-1K, and 7.3\\% on ImageNet-21K. Our distilled datasets and code are available at https://github.com/MIV-XJTU/CUDD.",
      "authors": [
        "Zhiheng Ma",
        "Anjia Cao",
        "Funing Yang",
        "Yihong Gong",
        "Xing Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-15T07:27:14+00:00",
          "link": "https://arxiv.org/abs/2405.09150v1",
          "size": "3811kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:10:14+00:00",
          "link": "https://arxiv.org/abs/2405.09150v2",
          "size": "3983kb",
          "version": "v2"
        }
      ],
      "title": "Curriculum Dataset Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09150",
        "PDF": "https://arxiv.org/pdf/2405.09150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a curriculum-based dataset distillation framework aimed at improving dataset quality through synthetic image generation, curriculum evaluation, and adversarial optimization\u2014all of which relate directly to data processing for model training."
      },
      "tasks": [
        "Dataset Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09874",
      "abstract": "Recent advances in Text-to-Speech (TTS) have enabled highly natural speech synthesis, yet integrating speech with complex background environments remains challenging. We introduce UmbraTTS, a flow-matching based TTS model that jointly generates both speech and environmental audio, conditioned on text and acoustic context. Our model allows fine-grained control over background volume and produces diverse, coherent, and context-aware audio scenes. A key challenge is the lack of data with speech and background audio aligned in natural context. To overcome the lack of paired training data, we propose a self-supervised framework that extracts speech, background audio, and transcripts from unannotated recordings. Extensive evaluations demonstrate that UmbraTTS significantly outperformed existing baselines, producing natural, high-quality, environmentally aware audios.",
      "authors": [
        "Neta Glazer",
        "Aviv Navon",
        "Yael Segal",
        "Aviv Shamsian",
        "Hilit Segev",
        "Asaf Buchnick",
        "Menachem Pirchi",
        "Gil Hetz",
        "Joseph Keshet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T15:43:08+00:00",
          "link": "https://arxiv.org/abs/2506.09874v1",
          "size": "3149kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:47:47+00:00",
          "link": "https://arxiv.org/abs/2506.09874v2",
          "size": "2698kb",
          "version": "v2"
        }
      ],
      "title": "UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09874",
        "HTML": "https://arxiv.org/html/2506.09874v2",
        "PDF": "https://arxiv.org/pdf/2506.09874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a self-supervised framework that extracts speech, background audio, and transcripts from unannotated recordings, which involves significant data processing and creation for training models."
      },
      "tasks": [
        "Speech Synthesis",
        "text-to-speech",
        "Text to Speech"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.19703",
      "abstract": "The resilience of critical infrastructure networks (CINs) after disruptions, such as those caused by natural hazards, depends on both the speed of restoration and the extent to which operational functionality can be regained. Allocating resources for restoration is a combinatorial optimal planning problem that involves determining which crews will repair specific network nodes and in what order. This paper presents a novel graph-based formulation that merges two interconnected graphs, representing crew and transportation nodes and power grid nodes, into a single heterogeneous graph. To enable efficient planning, graph reinforcement learning (GRL) is integrated with bigraph matching. GRL is utilized to design the incentive function for assigning crews to repair tasks based on the graph-abstracted state of the environment, ensuring generalization across damage scenarios. Two learning techniques are employed: a graph neural network trained using Proximal Policy Optimization and another trained via Neuroevolution. The learned incentive functions inform a bipartite graph that links crews to repair tasks, enabling weighted maximum matching for crew-to-task allocations. An efficient simulation environment that pre-computes optimal node-to-node path plans is used to train the proposed restoration planning methods. An IEEE 8500-bus power distribution test network coupled with a 21 square km transportation network is used as the case study, with scenarios varying in terms of numbers of damaged nodes, depots, and crews. Results demonstrate the approach's generalizability and scalability across scenarios, with learned policies providing 3-fold better performance than random policies, while also outperforming optimization-based solutions in both computation time (by several orders of magnitude) and power restored.",
      "authors": [
        "Nathan Maurer",
        "Harshal Kaushik",
        "Roshni Anna Jacob",
        "Jie Zhang",
        "and Souma Chowdhury"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T15:12:45+00:00",
          "link": "https://arxiv.org/abs/2506.19703v1",
          "size": "1908kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:51:51+00:00",
          "link": "https://arxiv.org/abs/2506.19703v2",
          "size": "1908kb",
          "version": "v2"
        }
      ],
      "title": "Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19703",
        "HTML": "https://arxiv.org/html/2506.19703v2",
        "PDF": "https://arxiv.org/pdf/2506.19703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents algorithms for infrastructure restoration planning using graph reinforcement learning and bigraph matching. There is no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08034",
      "abstract": "This paper deals with improving querying large language models (LLMs). It is well-known that without relevant contextual information, LLMs can provide poor quality responses or tend to hallucinate. Several initiatives have proposed integrating LLMs with external tools to provide them with up-to-date data to improve accuracy. In this paper, we propose a framework to integrate external tools to enhance the capabilities of LLMs in answering queries in educational settings. Precisely, we develop a framework that allows accessing external APIs to request additional relevant information. Integrated tools can also provide computational capabilities such as calculators or calendars. The proposed framework has been evaluated using datasets from the Multi-Modal Language Understanding (MMLU) collection. The data consists of questions on mathematical and scientific reasoning. Results compared to state-of-the-art language models show that the proposed approach significantly improves performance. Our Athena framework achieves 83% accuracy in mathematical reasoning and 88% in scientific reasoning, substantially outperforming all tested models including GPT-4o, LLaMA-Large, Mistral-Large, Phi-Large, and GPT-3.5, with the best baseline model (LLaMA-Large) achieving only 67% and 79% respectively. These promising results open the way to creating complex computing ecosystems around LLMs to make their use more natural to support various tasks and activities.",
      "authors": [
        "Nripesh Niketan",
        "Hadj Batatia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:09:59+00:00",
          "link": "https://arxiv.org/abs/2507.08034v1",
          "size": "402kb",
          "version": "v1"
        }
      ],
      "title": "Integrating External Tools with Large Language Models to Improve Accuracy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08034",
        "HTML": "https://arxiv.org/html/2507.08034v1",
        "PDF": "https://arxiv.org/pdf/2507.08034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating external tools with LLMs for query accuracy improvements, specifically for answering queries, and does not discuss training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08382",
      "abstract": "Cluster analysis is a fundamental research issue in statistics and machine learning. In many modern clustering methods, we need to determine whether two subsets of samples come from the same cluster. Since these subsets are usually generated by certain clustering procedures, the deployment of classic two-sample tests in this context would yield extremely smaller p-values, leading to inflated Type-I error rate. To overcome this bias, we formally introduce the two-cluster test issue and argue that it is a totally different significance testing issue from conventional two-sample test. Meanwhile, we present a new method based on the boundary points between two subsets to derive an analytical p-value for the purpose of significance quantification. Experiments on both synthetic and real data sets show that the proposed test is able to significantly reduce the Type-I error rate, in comparison with several classic two-sample testing methods. More importantly, the practical usage of such two-cluster test is further verified through its applications in tree-based interpretable clustering and significance-based hierarchical clustering.",
      "authors": [
        "Xinying Liu",
        "Lianyu Hu",
        "Mudi Jiang",
        "Simen Zhang",
        "Jun Lou",
        "and Zengyou He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:54:16+00:00",
          "link": "https://arxiv.org/abs/2507.08382v1",
          "size": "1068kb",
          "version": "v1"
        }
      ],
      "title": "Two-cluster test",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08382",
        "HTML": "https://arxiv.org/html/2507.08382v1",
        "PDF": "https://arxiv.org/pdf/2507.08382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for cluster analysis, which is unrelated to LLM training data processing, focusing instead on statistical tests for clustering significance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08690",
      "abstract": "Magnetic resonance imaging (MRI) enables non-invasive, high-resolution analysis of muscle structures. However, automated segmentation remains limited by high computational costs, reliance on large training datasets, and reduced accuracy in segmenting smaller muscles. Convolutional neural network (CNN)-based methods, while powerful, often suffer from substantial computational overhead, limited generalizability, and poor interpretability across diverse populations. This study proposes a training-free segmentation approach based on keypoint tracking, which integrates keypoint selection with Lucas-Kanade optical flow. The proposed method achieves a mean Dice similarity coefficient (DSC) ranging from 0.6 to 0.7, depending on the keypoint selection strategy, performing comparably to state-of-the-art CNN-based models while substantially reducing computational demands and enhancing interpretability. This scalable framework presents a robust and explainable alternative for muscle segmentation in clinical and research applications.",
      "authors": [
        "Mengyuan Liu",
        "Jeongkyu Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:39:28+00:00",
          "link": "https://arxiv.org/abs/2507.08690v1",
          "size": "1487kb",
          "version": "v1"
        }
      ],
      "title": "An Efficient Approach for Muscle Segmentation and 3D Reconstruction Using Keypoint Tracking in MRI Scan",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08690",
        "HTML": "https://arxiv.org/html/2507.08690v1",
        "PDF": "https://arxiv.org/pdf/2507.08690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a training-free approach for muscle segmentation in MRI scans and does not contribute to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08491",
      "abstract": "There are currently two main paradigms for evaluating large language models (LLMs), reference-based evaluation and preference-based evaluation. The first, carried over from the evaluation of machine learning models in general, relies on pre-defined task instances, for which reference task executions are available. The second, best exemplified by the LM-arena, relies on (often self-selected) users bringing their own intents to a site that routes these to several models in parallel, among whose responses the user then selects their most preferred one. The former paradigm hence excels at control over what is tested, while the latter comes with higher ecological validity, testing actual use cases interactively. Recently, a third complementary paradigm has emerged that combines some of the strengths of these approaches, offering control over multi-turn, reference-free, repeatable interactions, while stressing goal-directedness: dialogue game based evaluation. While the utility of this approach has been shown by several projects, its adoption has been held back by the lack of a mature, easily re-usable implementation. In this paper, we present clembench, which has been in continuous development since 2023 and has in its latest release been optimized for ease of general use. We describe how it can be used to benchmark one's own models (using a provided set of benchmark game instances in English), as well as how easily the benchmark itself can be extended with new, tailor-made targeted tests.",
      "authors": [
        "David Schlangen",
        "Sherzod Hakimov",
        "Jonathan Jordan",
        "Philipp Sadler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:16:01+00:00",
          "link": "https://arxiv.org/abs/2507.08491v1",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "title": "A Third Paradigm for LLM Evaluation: Dialogue Game-Based Evaluation using clembench",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08491",
        "HTML": "https://arxiv.org/html/2507.08491v1",
        "PDF": "https://arxiv.org/pdf/2507.08491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new paradigm for LLM evaluation using dialogue game-based approaches, but does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08711",
      "abstract": "Multiple Instance Learning (MIL) offers a natural solution for settings where only coarse, bag-level labels are available, without having access to instance-level annotations. This is usually the case in digital pathology, which consists of gigapixel sized images. While deterministic attention-based MIL approaches achieve strong bag-level performance, they often overlook the uncertainty inherent in instance relevance. In this paper, we address the lack of uncertainty quantification in instance-level attention scores by introducing \\textbf{SGPMIL}, a new probabilistic attention-based MIL framework grounded in Sparse Gaussian Processes (SGP). By learning a posterior distribution over attention scores, SGPMIL enables principled uncertainty estimation, resulting in more reliable and calibrated instance relevance maps. Our approach not only preserves competitive bag-level performance but also significantly improves the quality and interpretability of instance-level predictions under uncertainty. SGPMIL extends prior work by introducing feature scaling in the SGP predictive mean function, leading to faster training, improved efficiency, and enhanced instance-level performance. Extensive experiments on multiple well-established digital pathology datasets highlight the effectiveness of our approach across both bag- and instance-level evaluations. Our code will be made publicly available.",
      "authors": [
        "Andreas Lolos",
        "Stergios Christodoulidis",
        "Maria Vakalopoulou",
        "Jose Dolz",
        "Aris Moustakas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:10:27+00:00",
          "link": "https://arxiv.org/abs/2507.08711v1",
          "size": "14927kb",
          "version": "v1"
        }
      ],
      "title": "SGPMIL: Sparse Gaussian Process Multiple Instance Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08711",
        "HTML": "https://arxiv.org/html/2507.08711v1",
        "PDF": "https://arxiv.org/pdf/2507.08711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for quantifying uncertainty in multiple-instance learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08718",
      "abstract": "Policy Mirror Descent (PMD) has emerged as a unifying framework in reinforcement learning (RL) by linking policy gradient methods with a first-order optimization method known as mirror descent. At its core, PMD incorporates two key regularization components: (i) a distance term that enforces a trust region for stable policy updates and (ii) an MDP regularizer that augments the reward function to promote structure and robustness. While PMD has been extensively studied in theory, empirical investigations remain scarce. This work provides a large-scale empirical analysis of the interplay between these two regularization techniques, running over 500k training seeds on small RL environments. Our results demonstrate that, although the two regularizers can partially substitute each other, their precise combination is critical for achieving robust performance. These findings highlight the potential for advancing research on more robust algorithms in RL, particularly with respect to hyperparameter sensitivity.",
      "authors": [
        "Jan Felix Kleuker",
        "Aske Plaat and Thomas Moerland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:19:45+00:00",
          "link": "https://arxiv.org/abs/2507.08718v1",
          "size": "818kb",
          "version": "v1"
        }
      ],
      "title": "On the Effect of Regularization in Policy Mirror Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08718",
        "HTML": "https://arxiv.org/html/2507.08718v1",
        "PDF": "https://arxiv.org/pdf/2507.08718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores regularization in reinforcement learning methods, without covering aspects related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20547",
      "abstract": "For $m \\ge 1,$ let $P_m =1^m,$ the binary string of $m$ ones. Further define the infinite sequence $s_m$ by $s_{m,n} = 1$ iff the number of (possibly overlapping) occurrences of $P_m$ in the binary representation of $n$ is odd, $n \\ge 0.$ For $m=1,2$ respectively $s_m$ is the Thue-Morse and Rudin-Shapiro sequences. This paper shows that for each $m\\ge 1,$ (i) $s_m$ is automatic; (ii) the minimal, DFA (deterministic finite automata) accepting $s_m$ has $2m$ states; (iii) it suffices to use prefixes of length $2^{m-1}$ to distinguish all sequences in the 2-kernel of $s_m$; and (iv) the characteristic function of the length $2^{m-1}$ prefix of the 2-kernel sequences of $s_m$ can be formulated using the Vile and Jacobsthal sequences. The proofs are based on a correspondence between binary strings under concatenation and integers under addition and multiplication. Both Mathematica and Walnut are employed for exploratory analysis of patterns. The paper presents results about maximal runs, palindromes, order of squares, and borders in $s_m,$ generalizing similar results for $s_1$ and $s_2.$ In the conclusion we suggest that families of automatic sequences is a fruitful concept and a useful group of sequences extending automatic sequences similar to the regular and synchronized sequences.",
      "authors": [
        "Russell Jay Hendel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T22:21:16+00:00",
          "link": "https://arxiv.org/abs/2505.20547v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T21:32:30+00:00",
          "link": "https://arxiv.org/abs/2505.20547v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T00:05:53+00:00",
          "link": "https://arxiv.org/abs/2505.20547v3",
          "size": "32kb",
          "version": "v3"
        }
      ],
      "title": "A Family of Sequences Generalizing the Thue Morse and Rudin Shapiro Sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20547",
        "HTML": "https://arxiv.org/html/2505.20547v3",
        "PDF": "https://arxiv.org/pdf/2505.20547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on sequences and automata theory, and it does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08698",
      "abstract": "We study the rent-or-buy variant of the online Steiner forest problem on node- and edge-weighted graphs. For $n$-node graphs with at most $\\bar{n}$ non-zero node-weights, and at most $\\tilde{k}$ different arriving terminal pairs, we obtain a deterministic, $O(\\log n \\log \\bar{n})$-competitive algorithm. This improves on the previous best, $O(\\log^4 n)$-competitive algorithm obtained by the black-box reduction from (Bartal et al. 2021) combined with the previously best deterministic algorithms for the simpler 'buy-only' setting. We also obtain a deterministic, $O(\\bar{n}\\log \\tilde{k})$-competitive algorithm. This generalizes the $O(\\log \\tilde{k})$-competitive algorithm for the purely edge-weighted setting from (Umboh 2015). We also obtain a randomized, $O(\\log \\tilde{k} \\log \\bar{n})$-competitive algorithm. All previous approaches were based on the randomized, black-box reduction from~\\cite{AwerbuchAzarBartal96} that achieves a $O(\\log \\tilde{k} \\log n)$-competitive ratio when combined with an algorithm for the 'buy-only' setting. Our key technical ingredient is a novel charging scheme to an instance of \\emph{online prize-collecting set cover}. This allows us to extend the witness-technique of (Umboh 2015) to the node-weighted setting and obtain refined guarantees with respect to $\\bar{n}$, already in the much simpler 'buy-only' setting.",
      "authors": [
        "Sander Borst",
        "Moritz Venzin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:51:15+00:00",
          "link": "https://arxiv.org/abs/2507.08698v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "To buy or not to buy: deterministic rent-or-buy problems on node-weighted graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08698",
        "HTML": "https://arxiv.org/html/2507.08698v1",
        "PDF": "https://arxiv.org/pdf/2507.08698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deterministic algorithms for a variant of the online Steiner forest problem and does not relate to LLM training data processing or any aspect of data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.18594",
      "abstract": "We study the construction and convergence of decoupling multistep schemes of higher order using the backward differentiation formulae for an elliptic-parabolic problem, which includes multiple-network poroelasticity as a special case. These schemes were first introduced in [Altmann, Maier, Unger, BIT Numer. Math., 64:20, 2024], where a convergence proof for the second-order case is presented. Here, we present a slightly modified version of these schemes using a different construction of related time delay systems. We present a novel convergence proof relying on concepts from G-stability applicable for any order and providing a sharper characterization of the required weak coupling condition. The key tool for the convergence analysis is the construction of a weighted norm enabling a telescoping argument for the sum of the errors.",
      "authors": [
        "Robert Altmann and Abdullah Mujahid and Benjamin Unger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-26T08:29:12+00:00",
          "link": "https://arxiv.org/abs/2407.18594v1",
          "size": "107kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:41:57+00:00",
          "link": "https://arxiv.org/abs/2407.18594v2",
          "size": "115kb",
          "version": "v2"
        }
      ],
      "title": "Decoupling multistep schemes for elliptic-parabolic problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.18594",
        "PDF": "https://arxiv.org/pdf/2407.18594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multistep schemes for elliptic-parabolic problems using numerical methods, lacking any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03942",
      "abstract": "Deep neural networks for medical image segmentation are often overconfident, compromising both reliability and clinical utility. In this work, we propose differentiable formulations of marginal L1 Average Calibration Error (mL1-ACE) as an auxiliary loss that can be computed on a per-image basis. We compare both hard- and soft-binning approaches to directly improve pixel-wise calibration. Our experiments on four datasets (ACDC, AMOS, KiTS, BraTS) demonstrate that incorporating mL1-ACE significantly reduces calibration errors, particularly Average Calibration Error (ACE) and Maximum Calibration Error (MCE), while largely maintaining high Dice Similarity Coefficients (DSCs). We find that the soft-binned variant yields the greatest improvements in calibration, over the Dice plus cross-entropy loss baseline, but often compromises segmentation performance, with hard-binned mL1-ACE maintaining segmentation performance, albeit with weaker calibration improvement. To gain further insight into calibration performance and its variability across an imaging dataset, we introduce dataset reliability histograms, an aggregation of per-image reliability diagrams. The resulting analysis highlights improved alignment between predicted confidences and true accuracies. Overall, our approach not only enhances the trustworthiness of segmentation predictions but also shows potential for safer integration of deep learning methods into clinical workflows. We share our code here: https://github.com/cai4cai/Average-Calibration-Losses",
      "authors": [
        "Theodore Barfoot",
        "Luis C. Garcia-Peraza-Herrera",
        "Samet Akcay",
        "Ben Glocker",
        "and Tom Vercauteren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T13:32:07+00:00",
          "link": "https://arxiv.org/abs/2506.03942v1",
          "size": "441kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:35:23+00:00",
          "link": "https://arxiv.org/abs/2506.03942v2",
          "size": "441kb",
          "version": "v2"
        }
      ],
      "title": "Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03942",
        "HTML": "https://arxiv.org/html/2506.03942v2",
        "PDF": "https://arxiv.org/pdf/2506.03942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the calibration of deep neural networks for medical image segmentation, mentioning datasets but primarily focusing on model performance and uncertainty tasks, not training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08139",
      "abstract": "The Erd\\H{o}s-Ginzburg-Ziv theorem states that for any sequence of $2n-1$ integers, there exists a subsequence of $n$ elements whose sum is divisible by $n$. In this article, we provide a simple, practical $O(n\\log\\log n)$ algorithm and a theoretical $O(n\\log\\log\\log n)$ algorithm, both of which improve upon the best previously known $O(n\\log n)$ approach. This shows that a specific variant of boolean convolution can be implemented in time faster than the usual $O(n\\log n)$ expected from FFT-based methods.",
      "authors": [
        "Yui Hin Arvin Leung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:56:34+00:00",
          "link": "https://arxiv.org/abs/2507.08139v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "Finding a solution to the Erd\\H{o}s-Ginzburg-Ziv theorem in $O(n\\log\\log\\log n)$ time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08139",
        "HTML": "https://arxiv.org/html/2507.08139v1",
        "PDF": "https://arxiv.org/pdf/2507.08139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving algorithms related to the Erd\u0151s-Ginzburg-Ziv theorem, without any discussion on LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08193",
      "abstract": "The lack of high-quality public cyber incident data limits empirical research and predictive modeling for cyber risk assessment. This challenge persists due to the reluctance of companies to disclose incidents that could damage their reputation or investor confidence. Therefore, from an actuarial perspective, potential resolutions conclude two aspects: the enhancement of existing cyber incident datasets and the implementation of advanced modeling techniques to optimize the use of the available data. A review of existing data-driven methods highlights a significant lack of entity-specific organizational features in publicly available datasets. To address this gap, we propose a novel InsurTech framework that enriches cyber incident data with entity-specific attributes. We develop various machine learning (ML) models: a multilabel classification model to predict the occurrence of cyber incident types (e.g., Privacy Violation, Data Breach, Fraud and Extortion, IT Error, and Others) and a multioutput regression model to estimate their annual frequencies. While classifier and regressor chains are implemented to explore dependencies among cyber incident types as well, no significant correlations are observed in our datasets. Besides, we apply multiple interpretable ML techniques to identify and cross-validate potential risk factors developed by InsurTech across ML models. We find that InsurTech empowered features enhance prediction occurrence and frequency estimation robustness compared to only using conventional risk factors. The framework generates transparent, entity-specific cyber risk profiles, supporting customized underwriting and proactive cyber risk mitigation. It provides insurers and organizations with data-driven insights to support decision-making and compliance planning.",
      "authors": [
        "Jiayi Guo",
        "Zhiyun Quan",
        "and Linfeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:04:00+00:00",
          "link": "https://arxiv.org/abs/2507.08193v1",
          "size": "4323kb",
          "version": "v1"
        }
      ],
      "title": "Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08193",
        "HTML": "https://arxiv.org/html/2507.08193v1",
        "PDF": "https://arxiv.org/pdf/2507.08193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for enriching cyber incident data with InsurTech empowered risk factors, focusing on predictive modeling rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08525",
      "abstract": "Reinforcement learning with verifiable outcome rewards (RLVR) has effectively scaled up chain-of-thought (CoT) reasoning in large language models (LLMs). Yet, its efficacy in training vision-language model (VLM) agents for goal-directed action reasoning in visual environments is less established. This work investigates this problem through extensive experiments on complex card games, such as 24 points, and embodied tasks from ALFWorld. We find that when rewards are based solely on action outcomes, RL fails to incentivize CoT reasoning in VLMs, instead leading to a phenomenon we termed thought collapse, characterized by a rapid loss of diversity in the agent's thoughts, state-irrelevant and incomplete reasoning, and subsequent invalid actions, resulting in negative rewards. To counteract thought collapse, we highlight the necessity of process guidance and propose an automated corrector that evaluates and refines the agent's reasoning at each RL step. This simple and scalable GTR (Guided Thought Reinforcement) framework trains reasoning and action simultaneously without the need for dense, per-step human labeling. Our experiments demonstrate that GTR significantly enhances the performance and generalization of the LLaVA-7b model across various visual environments, achieving 3-5 times higher task success rates compared to SoTA models with notably smaller model sizes.",
      "authors": [
        "Tong Wei",
        "Yijun Yang",
        "Junliang Xing",
        "Yuanchun Shi",
        "Zongqing Lu",
        "Deheng Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T15:17:02+00:00",
          "link": "https://arxiv.org/abs/2503.08525v1",
          "size": "2080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T08:36:40+00:00",
          "link": "https://arxiv.org/abs/2503.08525v2",
          "size": "2756kb",
          "version": "v2"
        }
      ],
      "title": "GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08525",
        "HTML": "https://arxiv.org/html/2503.08525v2",
        "PDF": "https://arxiv.org/pdf/2503.08525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study centers around reinforcement learning and preventing thought collapse in vision-language model training, focusing on reasoning and action strategies without discussing LLM training data processing."
      },
      "tasks": [
        "Card Games"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08020",
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across domains such as healthcare, education, and cybersecurity. However, this openness also introduces significant security risks, particularly through embedding space poisoning, which is a subtle attack vector where adversaries manipulate the internal semantic representations of input data to bypass safety alignment mechanisms. While previous research has investigated universal perturbation methods, the dynamics of LLM safety alignment at the embedding level remain insufficiently understood. Consequently, more targeted and accurate adversarial perturbation techniques, which pose significant threats, have not been adequately studied.\n  In this work, we propose ETTA (Embedding Transformation Toxicity Attenuation), a novel framework that identifies and attenuates toxicity-sensitive dimensions in embedding space via linear transformations. ETTA bypasses model refusal behaviors while preserving linguistic coherence, without requiring model fine-tuning or access to training data. Evaluated on five representative open-source LLMs using the AdvBench benchmark, ETTA achieves a high average attack success rate of 88.61%, outperforming the best baseline by 11.34%, and generalizes to safety-enhanced models (e.g., 77.39% ASR on instruction-tuned defenses). These results highlight a critical vulnerability in current alignment strategies and underscore the need for embedding-aware defenses.",
      "authors": [
        "Zhibo Zhang",
        "Yuxi Li",
        "Kailong Wang",
        "Shuai Yuan",
        "Ling Shi",
        "Haoyu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:01:00+00:00",
          "link": "https://arxiv.org/abs/2507.08020v1",
          "size": "3277kb",
          "version": "v1"
        }
      ],
      "title": "Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08020",
        "PDF": "https://arxiv.org/pdf/2507.08020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for modifying embedding spaces to attenuate toxicity, which indirectly relates to alignment-tuning but does not focus on processing training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08103",
      "abstract": "Agriculture contributes trillions of dollars to the US economy each year. Digital technologies are disruptive forces in agriculture. The open source movement is beginning to emerge in agriculture technology and has dramatic implications for the future of farming and agriculture digital technologies. The convergence of open source and agriculture digital technology is observable in scientific research, but the implications of open source ideals related to agriculture technology have yet to be explored. This study explores open agriculture digital technology through a systematic mapping of available open agriculture digital technology research. The study contributes to Information Systems research by illuminating current trends and future research opportunities.",
      "authors": [
        "Kevin Lumbard",
        "Vinod Kumar Ahuja",
        "and Matt Cantu Snell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:40:45+00:00",
          "link": "https://arxiv.org/abs/2507.08103v1",
          "size": "1336kb",
          "version": "v1"
        }
      ],
      "title": "A Systematic Mapping Study on Open Source Agriculture Technology Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08103",
        "PDF": "https://arxiv.org/pdf/2507.08103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores open agriculture digital technology through systematic mapping, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08610",
      "abstract": "Image captioning is an important problem in developing various AI systems, and these tasks require large volumes of annotated images to train the models. Since all existing labelled datasets are already used for training the large Vision Language Models (VLMs), it becomes challenging to improve the performance of the same. Considering this, it is essential to consider the unsupervised image captioning performance, which remains relatively under-explored. To that end, we propose LoGIC (Lewis Communication Game for Image Captioning), a Multi-agent Reinforcement Learning game. The proposed method consists of two agents, a 'speaker' and a 'listener', with the objective of learning a strategy for communicating in natural language. We train agents in the cooperative common-reward setting using the GRPO algorithm and show that improvement in image captioning performance emerges as a consequence of the agents learning to play the game. We show that using pre-trained VLMs as the 'speaker' and Large Language Model (LLM) for language understanding in the 'listener', we achieved a $46$ BLEU score after fine-tuning using LoGIC without additional labels, a $2$ units advantage in absolute metrics compared to the $44$ BLEU score of the vanilla VLM. Additionally, we replace the VLM from the 'speaker' with lightweight components: (i) a ViT for image perception and (ii) a GPT2 language generation, and train them from scratch using LoGIC, obtaining a $31$ BLEU score in the unsupervised setting, a $10$ points advantage over existing unsupervised image-captioning methods.",
      "authors": [
        "Parag Dutta and Ambedkar Dukkipati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:08:36+00:00",
          "link": "https://arxiv.org/abs/2507.08610v1",
          "size": "6221kb",
          "version": "v1"
        }
      ],
      "title": "Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08610",
        "HTML": "https://arxiv.org/html/2507.08610v1",
        "PDF": "https://arxiv.org/pdf/2507.08610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper improves image captioning using communication games and existing pre-trained models but does not primarily contribute new techniques or datasets for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.11050",
      "abstract": "Ransomware attacks have caused billions of dollars in damages in recent years, and are expected to cause billions more in the future. Consequently, significant effort has been devoted to ransomware detection and mitigation. Behavioral-based ransomware detection approaches have garnered considerable attention recently. These behavioral detectors typically rely on process-based behavioral profiles to identify malicious behaviors. However, with an increasing body of literature highlighting the vulnerability of such approaches to evasion attacks, a comprehensive solution to the ransomware problem remains elusive. This paper presents Minerva, a novel, robust approach to ransomware detection. Minerva is engineered to be robust by design against evasion attacks, with architectural and feature selection choices informed by their resilience to adversarial manipulation. We conduct a comprehensive analysis of Minerva across a diverse spectrum of ransomware types, encompassing unseen ransomware as well as variants designed specifically to evade Minerva. Our evaluation showcases the ability of Minerva to accurately identify ransomware, generalize to unseen threats, and withstand evasion attacks. Furthermore, over 99% of detected ransomware are identified within 0.52sec of activity, enabling the adoption of data loss prevention techniques with near-zero overhead.",
      "authors": [
        "Dorjan Hitaj",
        "Giulio Pagnotta",
        "Fabio De Gaspari",
        "Lorenzo De Carli",
        "Luigi V. Mancini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-26T11:47:10+00:00",
          "link": "https://arxiv.org/abs/2301.11050v1",
          "size": "509kb",
          "version": "v1"
        },
        {
          "date": "2024-04-16T10:31:27+00:00",
          "link": "https://arxiv.org/abs/2301.11050v2",
          "size": "882kb",
          "version": "v2"
        },
        {
          "date": "2025-03-29T09:07:43+00:00",
          "link": "https://arxiv.org/abs/2301.11050v3",
          "size": "1726kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T08:48:55+00:00",
          "link": "https://arxiv.org/abs/2301.11050v4",
          "size": "651kb",
          "version": "v4"
        }
      ],
      "title": "Minerva: A File-Based Ransomware Detector",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.11050",
        "HTML": "https://arxiv.org/html/2301.11050v4",
        "PDF": "https://arxiv.org/pdf/2301.11050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a ransomware detection methodology that is unrelated to processing or creating training data for large language models."
      },
      "tasks": [
        "feature selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.20289",
      "abstract": "Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian regression technique of rising fame. It is a sum-of-decision-trees model, and is in some sense the Bayesian version of boosting. In the limit of infinite trees, it becomes equivalent to Gaussian process (GP) regression. This limit is known but has not yet led to any useful analysis or application. For the first time, I derive and compute the exact BART prior covariance function. With it I implement the infinite trees limit of BART as GP regression. Through empirical tests, I show that this limit is worse than standard BART in a fixed configuration, but also that tuning its hyperparameters in the natural GP way makes it competitive with BART. The advantage of using a GP surrogate of BART is the analytical likelihood, which simplifies model building and sidesteps the complex BART MCMC algorithm. More generally, this study opens new ways to understand and develop BART and GP regression. The implementation of BART as GP is available in the Python package lsqfitgp.",
      "authors": [
        "Giacomo Petrillo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T23:18:33+00:00",
          "link": "https://arxiv.org/abs/2410.20289v1",
          "size": "1202kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:27:24+00:00",
          "link": "https://arxiv.org/abs/2410.20289v2",
          "size": "1695kb",
          "version": "v2"
        }
      ],
      "title": "On the Gaussian process limit of Bayesian Additive Regression Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20289",
        "HTML": "https://arxiv.org/html/2410.20289v2",
        "PDF": "https://arxiv.org/pdf/2410.20289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a regression technique and its relationship to Gaussian process regression, focusing on model properties rather than LLM training data processing."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19334",
      "abstract": "Machine learning is increasingly used in government programs to identify and support the most vulnerable individuals, prioritizing assistance for those at greatest risk over optimizing aggregate outcomes. This paper examines the welfare impacts of prediction in equity-driven contexts, and how they compare to other policy levers, such as expanding bureaucratic capacity. Through mathematical models and a real-world case study on long-term unemployment amongst German residents, we develop a comprehensive understanding of the relative effectiveness of prediction in surfacing the worst-off. Our findings provide clear analytical frameworks and practical, data-driven tools that empower policymakers to make principled decisions when designing these systems.",
      "authors": [
        "Unai Fischer-Abaigar and Christoph Kern and Juan Carlos Perdomo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T17:34:53+00:00",
          "link": "https://arxiv.org/abs/2501.19334v1",
          "size": "3179kb",
          "version": "v1"
        },
        {
          "date": "2025-02-13T09:47:38+00:00",
          "link": "https://arxiv.org/abs/2501.19334v2",
          "size": "3179kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T17:08:45+00:00",
          "link": "https://arxiv.org/abs/2501.19334v3",
          "size": "2433kb",
          "version": "v3"
        }
      ],
      "title": "The Value of Prediction in Identifying the Worst-Off",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19334",
        "HTML": "https://arxiv.org/html/2501.19334v3",
        "PDF": "https://arxiv.org/pdf/2501.19334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines prediction impact in identifying worst-off individuals using ML models in government programs but lacks relevance to LLM training data processing."
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08175",
      "abstract": "We investigate the feasibility of inferring emotional states exclusively from physiological signals, thereby presenting a privacy-preserving alternative to conventional facial recognition techniques. We conduct a performance comparison of classical machine learning algorithms and hybrid quantum machine learning (QML) methods with a quantum kernel-based model. Our results indicate that the quantum-enhanced SVM surpasses classical counterparts in classification performance across all emotion categories, even when trained on limited datasets. The F1 scores over all classes are over 80% with around a maximum of 36% improvement in the recall values. The integration of wearable sensor data with quantum machine learning not only enhances accuracy and robustness but also facilitates unobtrusive emotion recognition. This methodology holds promise for populations with impaired communication abilities, such as individuals with Alzheimer's Disease and Related Dementias (ADRD) and veterans with Post-Traumatic Stress Disorder (PTSD). The findings establish an early foundation for passive emotional monitoring in clinical and assisted living conditions.",
      "authors": [
        "Md. Saif Hassan Onim",
        "Travis S. Humble and Himanshu Thapliyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:12:12+00:00",
          "link": "https://arxiv.org/abs/2507.08175v1",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "title": "Emotion Recognition in Older Adults with Quantum Machine Learning and Wearable Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08175",
        "HTML": "https://arxiv.org/html/2507.08175v1",
        "PDF": "https://arxiv.org/pdf/2507.08175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work examines emotion recognition with quantum machine learning methods using sensor data, without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.12463",
      "abstract": "The study of spoken languages comprises phonology, morphology, and grammar. The languages can be classified as root languages, inflectional languages, and stem languages. In addition, languages continually change over time and space by picking isoglosses, as speakers move from region to/through region. All these factors lead to the formation of vocabulary, which has commonality/similarity across languages as well as distinct and subtle differences among them. Comparison of vocabularies across languages and detailed analysis has led to the hypothesis of language families. In particular, in the view of Western linguists, Vedic Sanskrit is a daughter language, part of the Indo-Iranian branch of the Indo-European Language family, and Dravidian Languages belong to an entirely different family. These and such conclusions are reexamined in this paper. Based on our study and analysis, we propose an Ecosystem Model for Linguistic Development with Sanskrit at the core, in place of the widely accepted family tree model. To that end, we leverage the Paninian system of sounds to construct a phonetic map. Then we represent words across languages as state transitions on the phonetic map and construct corresponding Morphological Finite Automata (MFA) that accept groups of words. Regardless of whether the contribution of this paper is significant or minor, it is an important step in challenging policy-driven research that has plagued this field.",
      "authors": [
        "Shreekanth M Prabhu and Abhisek Midya"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-29T15:22:10+00:00",
          "link": "https://arxiv.org/abs/2301.12463v1",
          "size": "1254kb",
          "version": "v1"
        },
        {
          "date": "2024-04-16T14:19:58+00:00",
          "link": "https://arxiv.org/abs/2301.12463v2",
          "size": "1467kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T12:49:25+00:00",
          "link": "https://arxiv.org/abs/2301.12463v3",
          "size": "1651kb",
          "version": "v3"
        }
      ],
      "title": "Comparing Spoken Languages using Paninian System of Sounds and Finite State Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12463",
        "PDF": "https://arxiv.org/pdf/2301.12463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on language comparison using phonological and morphological finite state machines, which is unrelated to the processing of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08033",
      "abstract": "Aiming to reduce the computational cost of numerical simulations, a convolutional neural network (CNN) and a multi-layer perceptron (MLP) are introduced to build a surrogate model to approximate radiative heat transfer solutions in a 2-D walled domain with participative gases. The originality of this work lays in the adaptation of the inputs of the problem (gas and wall properties) in order to fit with the CNN architecture, more commonly used for image processing. Two precision datasets have been created with the classical solver, ICARUS2D, that uses the discrete transfer radiation method with the statistical narrow bands model. The performance of the CNN architecture is compared to a more classical MLP architecture in terms of speed and accuracy. Thanks to Optuna, all results are obtained using the optimized hyper parameters networks. The results show a significant speedup with industrially acceptable relative errors compared to the classical solver for both architectures. Additionally, the CNN outperforms the MLP in terms of precision and is more robust and stable to changes in hyper-parameters. A performance analysis on the dataset size of the samples have also been carried out to gain a deeper understanding of the model behavior.",
      "authors": [
        "Axel TahmasebiMoradi",
        "Vincent Ren",
        "Benjamin Le-Creurer",
        "Chetra Mang and Mouadh Yagoubi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T14:06:44+00:00",
          "link": "https://arxiv.org/abs/2506.08033v1",
          "size": "1408kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T10:14:50+00:00",
          "link": "https://arxiv.org/abs/2506.08033v2",
          "size": "1408kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T10:50:22+00:00",
          "link": "https://arxiv.org/abs/2506.08033v3",
          "size": "1408kb",
          "version": "v3"
        }
      ],
      "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08033",
        "HTML": "https://arxiv.org/html/2506.08033v3",
        "PDF": "https://arxiv.org/pdf/2506.08033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves creating datasets with a classical solver to train models, but it does not focus on LLM training data processing specifically."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07030",
      "abstract": "The rapid advancement of conversational search systems revolutionizes how information is accessed by enabling the multi-turn interaction between the user and the system. Existing conversational search systems are usually built with two different models. This separation restricts the system from leveraging the intrinsic knowledge of the models simultaneously, which cannot ensure the effectiveness of retrieval benefiting the generation. The existing studies for developing unified models cannot fully address the aspects of understanding conversational context, managing retrieval independently, and generating responses. In this paper, we explore how to unify dense retrieval and response generation for large language models in conversation. We conduct joint fine-tuning with different objectives and design two mechanisms to reduce the inconsistency risks while mitigating data discrepancy. The evaluations on five conversational search datasets demonstrate that our unified model can mutually improve both tasks and outperform the existing baselines.",
      "authors": [
        "Fengran Mo",
        "Yifan Gao",
        "Chuan Meng",
        "Xin Liu",
        "Zhuofeng Wu",
        "Kelong Mao",
        "Zhengyang Wang",
        "Pei Chen",
        "Zheng Li",
        "Xian Li",
        "Bing Yin",
        "Meng Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:02:40+00:00",
          "link": "https://arxiv.org/abs/2507.07030v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07030",
        "HTML": "https://arxiv.org/html/2507.07030",
        "PDF": "https://arxiv.org/pdf/2507.07030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is centered on unifying retrieval and response generation for conversational language models, and while it mentions tuning and objectives, it does not include substantial focus on data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.07337",
      "abstract": "We study efficient risk sharing among risk-averse agents in an economy with a large, finite number of states. Following a random shock to an initial agreement, agents may renegotiate. If they require a minimal utility improvement to accept a new deal, we show the probability of finding a mutually acceptable allocation vanishes exponentially as the state space grows. This holds regardless of agents' degree of risk aversion. In a two-agent multiple-priors model, we find that the potential for Pareto-improving trade requires that at least one agent's set of priors has a vanishingly small measure. Our results hinge on the ``shape does not matter'' message of high-dimensional isoperimetric inequalities.",
      "authors": [
        "Federico Echenique and Farzad Pourbabaee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-14T18:04:24+00:00",
          "link": "https://arxiv.org/abs/2401.07337v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2024-02-14T22:15:08+00:00",
          "link": "https://arxiv.org/abs/2401.07337v2",
          "size": "25kb",
          "version": "v2"
        },
        {
          "date": "2024-06-25T23:38:29+00:00",
          "link": "https://arxiv.org/abs/2401.07337v3",
          "size": "27kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T00:21:58+00:00",
          "link": "https://arxiv.org/abs/2401.07337v4",
          "size": "36kb",
          "version": "v4"
        }
      ],
      "title": "Individual and Collective Welfare in Risk Sharing with Many States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.07337",
        "HTML": "https://arxiv.org/html/2401.07337v4",
        "PDF": "https://arxiv.org/pdf/2401.07337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses risk-sharing among agents and does not focus on LLM training data processing, data engineering operations, or dataset quality improvement."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.13216",
      "abstract": "Music codecs are a vital aspect of audio codec research, and ultra low-bitrate compression holds significant importance for music transmission and generation. Due to the complexity of music backgrounds and the richness of vocals, solely relying on modeling semantic or acoustic information cannot effectively reconstruct music with both vocals and backgrounds. To address this issue, we propose MuCodec, specifically targeting music compression and reconstruction tasks at ultra low bitrates. MuCodec employs MuEncoder to extract both acoustic and semantic features, discretizes them with RVQ, and obtains Mel-VAE features via flow-matching. The music is then reconstructed using a pre-trained MEL-VAE decoder and HiFi-GAN. MuCodec can reconstruct high-fidelity music at ultra low (0.35kbps) or high bitrates (1.35kbps), achieving the best results to date in both subjective and objective metrics. Code and Demo: https://xuyaoxun.github.io/MuCodec_demo/.",
      "authors": [
        "Yaoxun Xu",
        "Hangting Chen",
        "Jianwei Yu",
        "Wei Tan",
        "Rongzhi Gu",
        "Shun Lei",
        "Zhiwei Lin",
        "Zhiyong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-20T05:06:49+00:00",
          "link": "https://arxiv.org/abs/2409.13216v1",
          "size": "1148kb",
          "version": "v1"
        },
        {
          "date": "2024-09-29T02:04:16+00:00",
          "link": "https://arxiv.org/abs/2409.13216v2",
          "size": "1148kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T13:26:59+00:00",
          "link": "https://arxiv.org/abs/2409.13216v3",
          "size": "589kb",
          "version": "v3"
        }
      ],
      "title": "MuCodec: Ultra Low-Bitrate Music Codec",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13216",
        "HTML": "https://arxiv.org/html/2409.13216v3",
        "PDF": "https://arxiv.org/pdf/2409.13216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a music codec tailored for ultra low-bitrate compression, which is unrelated to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08142",
      "abstract": "Unreal Engine is a platform that has influenced immersive storytelling and virtual reality (VR) through its advanced features and diverse applications. This paper provides an in-depth technical review of Unreal Engine. It analyzes its key innovations in creating hyper-realistic environments and emotionally engaging narratives, with significant applications in gaming, virtual production, education, cultural preservation, and healthcare. The findings of this article highlight Unreal Engine's transformative impact across industries, demonstrating its ability to merge storytelling with cutting-edge technologies. Case studies illustrate how Unreal Engine facilitates seamless visuals, audio, and interactivity integration to create compelling experiences. Additionally, this study identifies Unreal Engine's versatility in applications ranging from procedural content generation and AI-driven workflows to smart city simulations and VR-based rehabilitation programs.\n  While Unreal Engine sets new benchmarks for visual fidelity and interactivity, this paper underscores critical challenges, including its high hardware demands, limited accessibility, and ethical concerns related to over-immersion and data privacy. Addressing these challenges through cloud-based rendering, inclusive design, and ethical practices is essential for broader adoption and sustainability. This review concludes that Unreal Engine is suitable for innovation and interdisciplinary collaboration. Its ability to empower creators, redefine workflows, and push the boundaries of immersive storytelling positions Unreal Engine as pivotal in shaping the future of virtual reality and interactive media.",
      "authors": [
        "Oleksandra Sobchyshak",
        "Santiago Berrezueta-Guzman",
        "Stefan Wagner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:02:53+00:00",
          "link": "https://arxiv.org/abs/2507.08142v1",
          "size": "7313kb",
          "version": "v1"
        }
      ],
      "title": "Pushing the Boundaries of Immersion and Storytelling: A Technical Review of Unreal Engine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08142",
        "HTML": "https://arxiv.org/html/2507.08142v1",
        "PDF": "https://arxiv.org/pdf/2507.08142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a technical review of Unreal Engine\u2019s impact on storytelling and VR, without mentioning any LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08196",
      "abstract": "Over the past decade, remarkable progress has been made in adopting deep neural networks to enhance the performance of conventional reinforcement learning. A notable milestone was the development of Deep Q-Networks (DQN), which achieved human-level performance across a range of Atari games, demonstrating the potential of deep learning to stabilise and scale reinforcement learning. Subsequently, extensions to continuous control algorithms paved the way for a new paradigm in control, one that has attracted broader attention than any classical control approach in recent literature. These developments also demonstrated strong potential for advancing data-driven, model-free algorithms for control and for achieving higher levels of autonomy. However, the application of these methods has remained largely confined to simulated and gaming environments, with ongoing efforts to extend them to real-world applications. Before such deployment can be realised, a solid and quantitative understanding of their performance on applied control problems is necessary. This paper conducts a comparative analysis of these approaches on four diverse benchmark problems with implementation results. This analysis offers a scrutinising and systematic evaluation to shed light on the real-world capabilities and limitations of deep reinforcement learning methods in applied control settings.",
      "authors": [
        "Klinsmann Agyei",
        "Pouria Sarhadi",
        "Daniel Polani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.08196v1",
          "size": "2997kb",
          "version": "v1"
        }
      ],
      "title": "Deep Reinforcement Learning in Applied Control: Challenges, Analysis, and Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08196",
        "HTML": "https://arxiv.org/html/2507.08196v1",
        "PDF": "https://arxiv.org/pdf/2507.08196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes deep reinforcement learning for applied control challenges and does not discuss LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08655",
      "abstract": "Purpose: Ultra-high-field 7T MRI offers improved resolution and contrast over standard clinical field strengths (1.5T, 3T). However, 7T scanners are costly, scarce, and introduce additional challenges such as susceptibility artifacts. We propose an efficient transformer-based model (7T-Restormer) to synthesize 7T-quality T1-maps from routine 1.5T or 3T T1-weighted (T1W) images. Methods: Our model was validated on 35 1.5T and 108 3T T1w MRI paired with corresponding 7T T1 maps of patients with confirmed MS. A total of 141 patient cases (32,128 slices) were randomly divided into 105 (25; 80) training cases (19,204 slices), 19 (5; 14) validation cases (3,476 slices), and 17 (5; 14) test cases (3,145 slices) where (X; Y) denotes the patients with 1.5T and 3T T1W scans, respectively. The synthetic 7T T1 maps were compared against the ResViT and ResShift models. Results: The 7T-Restormer model achieved a PSNR of 26.0 +/- 4.6 dB, SSIM of 0.861 +/- 0.072, and NMSE of 0.019 +/- 0.011 for 1.5T inputs, and 25.9 +/- 4.9 dB, and 0.866 +/- 0.077 for 3T inputs, respectively. Using 10.5 M parameters, our model reduced NMSE by 64 % relative to 56.7M parameter ResShift (0.019 vs 0.052, p = <.001 and by 41 % relative to 70.4M parameter ResViT (0.019 vs 0.032, p = <.001) at 1.5T, with similar advantages at 3T (0.021 vs 0.060 and 0.033; p < .001). Training with a mixed 1.5 T + 3 T corpus was superior to single-field strategies. Restricting the model to 1.5T increased the 1.5T NMSE from 0.019 to 0.021 (p = 1.1E-3) while training solely on 3T resulted in lower performance on input 1.5T T1W MRI. Conclusion: We propose a novel method for predicting quantitative 7T MP2RAGE maps from 1.5T and 3T T1W scans with higher quality than existing state-of-the-art methods. Our approach makes the benefits of 7T MRI more accessible to standard clinical workflows.",
      "authors": [
        "Zach Eidex",
        "Mojtaba Safari",
        "Tonghe Wang",
        "Vanessa Wildman",
        "David S. Yu",
        "Hui Mao",
        "Erik Middlebrooks",
        "Aparna Kesewala",
        "and Xiaofeng Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:59:27+00:00",
          "link": "https://arxiv.org/abs/2507.08655v1",
          "size": "806kb",
          "version": "v1"
        }
      ],
      "title": "Generalizable 7T T1-map Synthesis from 1.5T and 3T T1 MRI with an Efficient Transformer Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08655",
        "PDF": "https://arxiv.org/pdf/2507.08655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses synthesizing 7T-quality T1 maps from lower field images using a transformer model, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06515",
      "abstract": "Most recently, researchers have started building large language models (LLMs) powered data systems that allow users to analyze unstructured text documents like working with a database because LLMs are very effective in extracting attributes from documents. In such systems, LLM-based extraction operations constitute the performance bottleneck of query execution due to the high monetary cost and slow LLM inference. Existing systems typically borrow the query optimization principles popular in relational databases to produce query execution plans, which unfortunately are ineffective in minimizing LLM cost. To fill this gap, we propose QUEST, which features a bunch of novel optimization strategies for unstructured document analysis. First, we introduce an index-based strategy to minimize the cost of each extraction operation. With this index, QUEST quickly retrieves the text segments relevant to the target attributes and only feeds them to LLMs. Furthermore, we design an evidence-augmented retrieval strategy to reduce the possibility of missing relevant segments. Moreover, we develop an instance-optimized query execution strategy: because the attribute extraction cost could vary significantly document by document, QUEST produces different plans for different documents. For each document, QUEST produces a plan to minimize the frequency of attribute extraction. The innovations include LLM cost-aware operator ordering strategies and an optimized join execution approach that transforms joins into filters. Extensive experiments on 3 real-world datasets demonstrate the superiority of QUEST, achieving 30%-6x cost savings while improving the F1 score by 10% -27% compared with state-of-the-art baselines.",
      "authors": [
        "Zhaoze Sun",
        "Qiyan Deng",
        "Chengliang Chai",
        "Kaisen Jin",
        "Xinyu Guo",
        "Han Han",
        "Ye Yuan",
        "Guoren Wang",
        "Lei Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:30:09+00:00",
          "link": "https://arxiv.org/abs/2507.06515v1",
          "size": "6066kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:50:12+00:00",
          "link": "https://arxiv.org/abs/2507.06515v2",
          "size": "6066kb",
          "version": "v2"
        }
      ],
      "title": "QUEST: Query Optimization in Unstructured Document Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06515",
        "HTML": "https://arxiv.org/html/2507.06515v2",
        "PDF": "https://arxiv.org/pdf/2507.06515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces QUEST, which focuses on optimizing LLM-based unstructured document analysis by developing novel data processing strategies, such as index-based retrieval and evidence-augmented retrieval, which significantly enhance performance and cost-efficiency."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08189",
      "abstract": "Background: CT imaging is vital for lung cancer management, offering detailed visualization for AI-based prognosis. However, supervised learning SL models require large labeled datasets, limiting their real-world application in settings with scarce annotations.\n  Methods: We analyzed CT scans from 977 patients across 12 datasets extracting 1218 radiomics features using Laplacian of Gaussian and wavelet filters via PyRadiomics Dimensionality reduction was applied with 56 feature selection and extraction algorithms and 27 classifiers were benchmarked A semi supervised learning SSL framework with pseudo labeling utilized 478 unlabeled and 499 labeled cases Model sensitivity was tested in three scenarios varying labeled data in SL increasing unlabeled data in SSL and scaling both from 10 percent to 100 percent SHAP analysis was used to interpret predictions Cross validation and external testing in two cohorts were performed.\n  Results: SSL outperformed SL, improving overall survival prediction by up to 17 percent. The top SSL model, Random Forest plus XGBoost classifier, achieved 0.90 accuracy in cross-validation and 0.88 externally. SHAP analysis revealed enhanced feature discriminability in both SSL and SL, especially for Class 1 survival greater than 4 years. SSL showed strong performance with only 10 percent labeled data, with more stable results compared to SL and lower variance across external testing, highlighting SSL's robustness and cost effectiveness.\n  Conclusion: We introduced a cost-effective, stable, and interpretable SSL framework for CT-based survival prediction in lung cancer, improving performance, generalizability, and clinical readiness by integrating SHAP explainability and leveraging unlabeled data.",
      "authors": [
        "Mohammad R. Salmanpour",
        "Amir Hossein Pouria",
        "Sonia Falahati",
        "Shahram Taeb",
        "Somayeh Sadat Mehrnia",
        "Ali Fathi Jouzdani",
        "Mehrdad Oveisi",
        "Ilker Hacihaliloglu",
        "Arman Rahmim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:57:15+00:00",
          "link": "https://arxiv.org/abs/2507.08189v1",
          "size": "1122kb",
          "version": "v1"
        }
      ],
      "title": "Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08189",
        "PDF": "https://arxiv.org/pdf/2507.08189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a semi-supervised learning framework for CT image analysis in lung cancer prognosis, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.11767",
      "abstract": "Rerankers, typically cross-encoders, are computationally intensive but are frequently used because they are widely assumed to outperform cheaper initial IR systems. We challenge this assumption by measuring reranker performance for full retrieval, not just re-scoring first-stage retrieval. To provide a more robust evaluation, we prioritize strong first-stage retrieval using modern dense embeddings and test rerankers on a variety of carefully chosen, challenging tasks, including internally curated datasets to avoid contamination, and out-of-domain ones. Our empirical results reveal a surprising trend: the best existing rerankers provide initial improvements when scoring progressively more documents, but their effectiveness gradually declines and can even degrade quality beyond a certain limit. We hope that our findings will spur future research to improve reranking.",
      "authors": [
        "Mathew Jacob",
        "Erik Lindgren",
        "Matei Zaharia",
        "Michael Carbin",
        "Omar Khattab",
        "Andrew Drozdov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T17:46:32+00:00",
          "link": "https://arxiv.org/abs/2411.11767v1",
          "size": "3561kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2411.11767v2",
          "size": "600kb",
          "version": "v2"
        }
      ],
      "title": "Drowning in Documents: Consequences of Scaling Reranker Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11767",
        "HTML": "https://arxiv.org/html/2411.11767v2",
        "PDF": "https://arxiv.org/pdf/2411.11767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates rerankers and retrieval systems, concentrating on their performance rather than making contributions to LLM training data processing or dataset preparation."
      },
      "tasks": [
        "Reranking",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08046",
      "abstract": "The paper presents our system developed for table question answering (TQA). TQA tasks face challenges due to the characteristics of real-world tabular data, such as large size, incomplete column semantics, and entity ambiguity. To address these issues, we propose a large language model (LLM)-powered and programming-based table reasoning framework, named TableReasoner. It models a table using the schema that combines structural and semantic representations, enabling holistic understanding and efficient processing of large tables. We design a multi-step schema linking plan to derive a focused table schema that retains only query-relevant information, eliminating ambiguity and alleviating hallucinations. This focused table schema provides precise and sufficient table details for query refinement and programming. Furthermore, we integrate the reasoning workflow into an iterative thinking architecture, allowing incremental cycles of thinking, reasoning and reflection. Our system achieves first place in both subtasks of SemEval-2025 Task 8.",
      "authors": [
        "Sishi Xiong",
        "Dakai Wang",
        "Yu Zhao",
        "Jie Zhang",
        "Changzai Pan",
        "Haowei He",
        "Xiangyu Li",
        "Wenhan Chang",
        "Zhongjiang He",
        "Shuangyong Song",
        "Yongxiang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:16:51+00:00",
          "link": "https://arxiv.org/abs/2507.08046v1",
          "size": "1172kb",
          "version": "v1"
        }
      ],
      "title": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08046",
        "PDF": "https://arxiv.org/pdf/2507.08046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a table reasoning framework using LLMs, focusing on semantic representation and reasoning efficiencies but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1909.10303",
      "abstract": "Near-term quantum computers are likely to have small depths due to short coherence time and noisy gates, and thus a potential way to use these quantum devices is using a hybrid scheme that interleaves them with classical computers. For example, the quantum Fourier transform can be implemented by a hybrid of logarithmic-depth quantum circuits and a classical polynomial-time algorithm. Along the line, it seems possible that a general quantum computer may only be polynomially faster than a hybrid quantum-classical computer. Jozsa raised the question of whether $BQP = BPP^{BQNC}$ and conjectured that they are equal, where $BQNC$ means $polylog$-depth quantum circuits. Nevertheless, Aaronson conjectured an oracle separation for these two classes and gave a candidate. In this work, we prove Aaronson's conjecture for a different but related oracle problem. Our result also proves that Jozsa's conjecture fails relative to an oracle.",
      "authors": [
        "Nai-Hui Chia",
        "Kai-Min Chung",
        "and Ching-Yi Lai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2019-09-23T11:50:13+00:00",
          "link": "https://arxiv.org/abs/1909.10303v1",
          "size": "557kb",
          "version": "v1"
        },
        {
          "date": "2020-09-12T20:51:15+00:00",
          "link": "https://arxiv.org/abs/1909.10303v2",
          "size": "445kb",
          "version": "v2"
        }
      ],
      "title": "On the Need for Large Quantum Depth",
      "links": {
        "Abstract": "https://arxiv.org/abs/1909.10303",
        "PDF": "https://arxiv.org/pdf/1909.10303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum computing and classical computer hybrid schemes, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08366",
      "abstract": "Reliable satellite attitude control is essential for the success of space missions, particularly as satellites increasingly operate autonomously in dynamic and uncertain environments. Reaction wheels (RWs) play a pivotal role in attitude control, and maintaining control resilience during RW faults is critical to preserving mission objectives and system stability. However, traditional Proportional Derivative (PD) controllers and existing deep reinforcement learning (DRL) algorithms such as TD3, PPO, and A2C often fall short in providing the real time adaptability and fault tolerance required for autonomous satellite operations. This study introduces a DRL-based control strategy designed to improve satellite resilience and adaptability under fault conditions. Specifically, the proposed method integrates Twin Delayed Deep Deterministic Policy Gradient (TD3) with Hindsight Experience Replay (HER) and Dimension Wise Clipping (DWC) referred to as TD3-HD to enhance learning in sparse reward environments and maintain satellite stability during RW failures. The proposed approach is benchmarked against PD control and leading DRL algorithms. Experimental results show that TD3-HD achieves significantly lower attitude error, improved angular velocity regulation, and enhanced stability under fault conditions. These findings underscore the proposed method potential as a powerful, fault tolerant, onboard AI solution for autonomous satellite attitude control.",
      "authors": [
        "Ghaith El-Dalahmeh",
        "Mohammad Reza Jabbarpour",
        "Bao Quoc Vo",
        "Ryszard Kowalczyk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:28:16+00:00",
          "link": "https://arxiv.org/abs/2507.08366v1",
          "size": "1897kb",
          "version": "v1"
        }
      ],
      "title": "Intelligent Control of Spacecraft Reaction Wheel Attitude Using Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08366",
        "PDF": "https://arxiv.org/pdf/2507.08366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on spacecraft attitude control using DRL, emphasizing control strategies rather than LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08758",
      "abstract": "Fairness has emerged as a formidable challenge in data-driven decisions. Many of the data problems, such as creating compact data summaries for approximate query processing, can be effectively tackled using concepts from computational geometry, such as $\\varepsilon$-nets. However, these powerful tools have yet to be examined from the perspective of fairness. To fill this research gap, we add fairness to classical geometric approximation problems of $\\varepsilon$-net, $\\varepsilon$-sample, and geometric hitting set. We introduce and address two notions of group fairness: demographic parity, which requires preserving group proportions from the input distribution, and custom-ratios fairness, which demands satisfying arbitrary target ratios. We develop two algorithms to enforce fairness: one based on sampling and another on discrepancy theory. The sampling-based algorithm is faster and computes a fair $\\varepsilon$-net of size which is only larger by a $\\log(k)$ factor compared to the standard (unfair) $\\varepsilon$-net, where $k$ is the number of demographic groups. The discrepancy-based algorithm is slightly slower (for bounded VC dimension), but it computes a smaller fair $\\varepsilon$-net. Notably, we reduce the fair geometric hitting set problem to finding fair $\\varepsilon$-nets. This results in a $O(\\log \\mathsf{OPT} \\times \\log k)$ approximation of a fair geometric hitting set. Additionally, we show that under certain input distributions, constructing fair $\\varepsilon$-samples can be infeasible, highlighting limitations in fair sampling. Beyond the theoretical guarantees, our experimental results validate the practical effectiveness of the proposed algorithms. In particular, we achieve zero unfairness with only a modest increase in output size compared to the unfair setting.",
      "authors": [
        "Mohsen Dehghankar",
        "Stavros Sintos",
        "Abolfazl Asudeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:11:54+00:00",
          "link": "https://arxiv.org/abs/2507.08758v1",
          "size": "1617kb",
          "version": "v1"
        }
      ],
      "title": "On Fair Epsilon Net and Geometric Hitting Set",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08758",
        "HTML": "https://arxiv.org/html/2507.08758v1",
        "PDF": "https://arxiv.org/pdf/2507.08758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on geometric algorithms for fairness in data summaries, but it does not discuss LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.08054",
      "abstract": "The conventional BIM authoring process typically requires designers to master complex and tedious modeling commands in order to materialize their design intentions within BIM authoring tools. This additional cognitive burden complicates the design process and hinders the adoption of BIM and model-based design in the AEC (Architecture, Engineering, and Construction) industry. To facilitate the expression of design intentions more intuitively, we propose Text2BIM, an LLM-based multi-agent framework that can generate 3D building models from natural language instructions. This framework orchestrates multiple LLM agents to collaborate and reason, transforming textual user input into imperative code that invokes the BIM authoring tool's APIs, thereby generating editable BIM models with internal layouts, external envelopes, and semantic information directly in the software. Furthermore, a rule-based model checker is introduced into the agentic workflow, utilizing predefined domain knowledge to guide the LLM agents in resolving issues within the generated models and iteratively improving model quality. Extensive experiments were conducted to compare and analyze the performance of three different LLMs under the proposed framework. The evaluation results demonstrate that our approach can effectively generate high-quality, structurally rational building models that are aligned with the abstract concepts specified by user input. Finally, an interactive software prototype was developed to integrate the framework into the BIM authoring software Vectorworks, showcasing the potential of modeling by chatting. The code is available at: https://github.com/dcy0577/Text2BIM",
      "authors": [
        "Changyu Du",
        "Sebastian Esser",
        "Stavros Nousias",
        "Andr\\'e Borrmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-15T09:48:45+00:00",
          "link": "https://arxiv.org/abs/2408.08054v1",
          "size": "7648kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:40:10+00:00",
          "link": "https://arxiv.org/abs/2408.08054v2",
          "size": "13910kb",
          "version": "v2"
        }
      ],
      "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.08054",
        "HTML": "https://arxiv.org/html/2408.08054v2",
        "PDF": "https://arxiv.org/pdf/2408.08054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The framework leverages LLMs to generate 3D building models, discussing the generation and reasoning process, but the focus is on model creation rather than on LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/dcy0577/Text2BIM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12690",
      "abstract": "A critical bottleneck for scientific progress is the costly nature of computer simulations for complex systems. Surrogate models provide an appealing solution: such models are trained on simulator evaluations, then used to emulate and quantify uncertainty on the expensive simulator at unexplored inputs. In many applications, one often has available data on related systems. For example, in designing a new jet turbine, there may be existing studies on turbines with similar configurations. A key question is how information from such ``source'' systems can be transferred for effective surrogate training on the ``target'' system of interest. We thus propose a new LOcal transfer Learning Gaussian Process (LOL-GP) model, which leverages a carefully-designed Gaussian process to transfer such information for surrogate modeling. The key novelty of the LOL-GP is a latent regularization model, which identifies regions where transfer should be performed and regions where it should be avoided. Such a ``local transfer'' property is present in many scientific systems: at certain parameters, systems may behave similarly and thus transfer is beneficial; at other parameters, they may behave differently and thus transfer is detrimental. By accounting for local transfer, the LOL-GP can temper the risk of ``negative transfer'', i.e., the risk of worsening predictive performance from information transfer. We derive a Gibbs sampling algorithm for efficient posterior predictive sampling on the LOL-GP, for both the multi-source and multi-fidelity transfer settings. We then show, via a suite of numerical experiments and an application for jet turbine design, the improved surrogate performance of the LOL-GP over existing methods.",
      "authors": [
        "Xinming Wang",
        "Simon Mak",
        "John Miller",
        "Jianguo Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T15:50:57+00:00",
          "link": "https://arxiv.org/abs/2410.12690v1",
          "size": "7266kb",
          "version": "v1"
        },
        {
          "date": "2024-10-17T01:53:56+00:00",
          "link": "https://arxiv.org/abs/2410.12690v2",
          "size": "6829kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T02:48:36+00:00",
          "link": "https://arxiv.org/abs/2410.12690v3",
          "size": "6375kb",
          "version": "v3"
        }
      ],
      "title": "Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12690",
        "HTML": "https://arxiv.org/html/2410.12690v3",
        "PDF": "https://arxiv.org/pdf/2410.12690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on surrogate modeling using local transfer learning for Gaussian processes, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08360",
      "abstract": "Information Retrieval (IR) models are often trained on static datasets, making them vulnerable to performance degradation as web content evolves. The DS@GT competition team participated in the Longitudinal Evaluation of Model Performance (LongEval) lab at CLEF 2025, which evaluates IR systems across temporally distributed web snapshots. Our analysis of the Qwant web dataset includes exploratory data analysis with topic modeling over time. The two-phase retrieval system employs sparse keyword searches, utilizing query expansion and document reranking. Our best system achieves an average NDCG@10 of 0.296 across the entire training and test dataset, with an overall best score of 0.395 on 2023-05. The accompanying source code for this paper is at https://github.com/dsgt-arc/longeval-2025",
      "authors": [
        "Anthony Miyaguchi",
        "Imran Afrulbasha",
        "Aleksandar Pramov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:23:08+00:00",
          "link": "https://arxiv.org/abs/2507.08360v1",
          "size": "2694kb",
          "version": "v1"
        }
      ],
      "title": "DS@GT at LongEval: Evaluating Temporal Performance in Web Search Systems and Topics with Two-Stage Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08360",
        "HTML": "https://arxiv.org/html/2507.08360v1",
        "PDF": "https://arxiv.org/pdf/2507.08360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract discusses the evaluation of IR systems using temporally distributed web snapshots, but does not primarily focus on LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08390",
      "abstract": "Discrete diffusion models have emerged as a powerful paradigm for language modeling, rivaling auto-regressive models by training-time scaling. However, inference-time scaling in discrete diffusion models remains relatively under-explored. In this work, we study sampling-based approaches for achieving high-quality text generation from discrete diffusion models in reward-guided settings. We introduce a novel inference-time scaling approach based on particle Gibbs sampling for discrete diffusion models. The particle Gibbs sampling algorithm iteratively refines full diffusion trajectories using conditional Sequential Monte Carlo as its transition mechanism. This process ensures that the updated samples progressively improve and move closer to the reward-weighted target distribution. Unlike existing inference-time scaling methods, which are often limited to single diffusion trajectories, our approach leverages iterative refinement across multiple trajectories. Within this framework, we further analyze the trade-offs between four key axes for inference-time scaling under fixed compute budgets: particle Gibbs iterations, particle count, denoising steps, and reward estimation cost. Empirically, our method consistently outperforms prior inference-time strategies on reward-guided text generation tasks, achieving significant improvement in accuracy under varying compute budgets.",
      "authors": [
        "Meihua Dang",
        "Jiaqi Han",
        "Minkai Xu",
        "Kai Xu",
        "Akash Srivastava",
        "Stefano Ermon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:00:47+00:00",
          "link": "https://arxiv.org/abs/2507.08390v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Inference-Time Scaling of Diffusion Language Models with Particle Gibbs Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08390",
        "HTML": "https://arxiv.org/html/2507.08390v1",
        "PDF": "https://arxiv.org/pdf/2507.08390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper studies inference-time sampling methods for discrete diffusion models and focuses on scaling techniques rather than substantial modifications to training data or preprocessing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08751",
      "abstract": "Symbolic accelerators are increasingly used for symbolic data processing in domains such as genomics, NLP, and cybersecurity. However, these accelerators face scalability issues due to excessive memory use and routing complexity, especially when targeting a large set. We present AutoSlim, a machine learning-based graph simplification framework designed to reduce the complexity of symbolic accelerators built on Non-deterministic Finite Automata (NFA) deployed on FPGA-based overlays such as NAPOLY+. AutoSlim uses Random Forest classification to prune low-impact transitions based on edge scores and structural features, significantly reducing automata graph density while preserving semantic correctness. Unlike prior tools, AutoSlim targets automated score-aware simplification with weighted transitions, enabling efficient ranking-based sequence analysis. We evaluated data sets (1K to 64K nodes) in NAPOLY+ and conducted performance measurements including latency, throughput, and resource usage. AutoSlim achieves up to 40 percent reduction in FPGA LUTs and over 30 percent pruning in transitions, while scaling to graphs an order of magnitude larger than existing benchmarks. Our results also demonstrate how hardware interconnection (fanout) heavily influences hardware cost and that AutoSlim's pruning mitigates resource blowup.",
      "authors": [
        "Tiffany Yu",
        "Rye Stahle-Smith",
        "Darssan Eswaramoorthi",
        "Rasha Karakchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:02:33+00:00",
          "link": "https://arxiv.org/abs/2507.08751v1",
          "size": "384kb",
          "version": "v1"
        }
      ],
      "title": "ML-Based Automata Simplification for Symbolic Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08751",
        "HTML": "https://arxiv.org/html/2507.08751v1",
        "PDF": "https://arxiv.org/pdf/2507.08751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a framework for automata simplification in symbolic accelerators using machine learning, which is focused on hardware and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.05066",
      "abstract": "Large language models (LLMs) can perform a new task by merely conditioning on task instructions and a few input-output examples, without optimizing any parameters. This is called In-Context Learning (ICL). In-context Information Extraction (IE) has recently garnered attention in the research community. However, the performance of In-context IE generally lags behind the state-of-the-art supervised expert models. We highlight a key reason for this shortfall: underspecified task description. The limited-length context struggles to thoroughly express the intricate IE task instructions and various edge cases, leading to misalignment in task comprehension with humans. In this paper, we propose a Guideline Learning (GL) framework for In-context IE which reflectively learns and follows guidelines. During the learning phrase, GL automatically synthesizes a set of guidelines based on a few error cases, and during inference, GL retrieves helpful guidelines for better ICL. Moreover, we propose a self-consistency-based active learning method to enhance the efficiency of GL. Experiments on event extraction and relation extraction show that GL can significantly improve the performance of in-context IE.",
      "authors": [
        "Chaoxu Pang",
        "Yixuan Cao",
        "Qiang Ding",
        "Ping Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-08T08:25:16+00:00",
          "link": "https://arxiv.org/abs/2310.05066v1",
          "size": "1239kb",
          "version": "v1"
        },
        {
          "date": "2023-10-21T10:21:48+00:00",
          "link": "https://arxiv.org/abs/2310.05066v2",
          "size": "1282kb",
          "version": "v2"
        }
      ],
      "title": "Guideline Learning for In-context Information Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.05066",
        "PDF": "https://arxiv.org/pdf/2310.05066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses on Guideline Learning for improving in-context IE, it mentions synthesizing guidelines based on error cases, which implies some data synthesis, but the primary contribution does not involve comprehensive LLM training data processing."
      },
      "tasks": [
        "Active Learning",
        "Event Extraction",
        "In-Context Learning",
        "Relation Extraction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08427",
      "abstract": "Current knowledge editing methods for large language models (LLMs) struggle to maintain logical consistency when propagating ripple effects to associated facts. We propose ChainEdit, a framework that synergizes knowledge graph-derived logical rules with LLM logical reasoning capabilities to enable systematic chain updates. By automatically extracting logical patterns from structured knowledge bases and aligning them with LLMs' internal logics, ChainEdit dynamically generates and edits logically connected knowledge clusters. Experiments demonstrate an improvement of more than 30% in logical generalization over baselines while preserving editing reliability and specificity. We further address evaluation biases in existing benchmarks through knowledge-aware protocols that disentangle external dependencies. This work establishes new state-of-the-art performance on ripple effect while ensuring internal logical consistency after knowledge editing.",
      "authors": [
        "Zilu Dong",
        "Xiangqing Shen",
        "Zinong Yang",
        "Rui Xia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:13:29+00:00",
          "link": "https://arxiv.org/abs/2507.08427v1",
          "size": "7678kb",
          "version": "v1"
        }
      ],
      "title": "ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08427",
        "HTML": "https://arxiv.org/html/2507.08427v1",
        "PDF": "https://arxiv.org/pdf/2507.08427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving logical consistency in knowledge editing within LLMs without addressing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.20496",
      "abstract": "Software development depends on the use of libraries whose specifications constrain the client's code and impose obligations on the implementation. It follows that any approach to verification at scale must also be modular, while permitting specification of both behavior and cost. Hoare's notion of an abstraction function provides an elegant and effective methodology for such verifications, separating the implementation from the abstraction, and using an abstraction function to demonstrate the behavioral correctness of the former relative to the latter.\n  For all of its influence, much of the Hoare methodology remains informal in that it relies on conventional separation between implementation and abstraction, and provides no linguistic support for ensuring that these conventions are obeyed. The purpose of this paper is to propose a synthetic account of Hoare's methodology within univalent dependent type theory based on the principle that all types have abstract and concrete aspects by regarding abstraction functions as types, and thus enjoy the full range of typing constructs found in dependent type theory. Achieving this relies crucially on the notion of a phase distinction in type theory which gives rise to modalities that isolate, or fracture, a type into its concrete and abstract parts, and that permit the definition of a type given these aspects using a technique called gluing. Moreover, this approach scales to permit the specification and verification of the cost of programs, as well as their behavior, allowing clients to verify their own cost relative to these specifications and permit the implementor to realize them with tighter bounds. The resulting theory supports modular development of programs and proofs in a manner that hides technical details of no concern to clients while permitting precise specifications of both the cost and behavior of programs.",
      "authors": [
        "Harrison Grodin (1)",
        "Runming Li (1)",
        "and Robert Harper (1) ((1) Carnegie Mellon University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T20:02:17+00:00",
          "link": "https://arxiv.org/abs/2502.20496v1",
          "size": "77kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:51:12+00:00",
          "link": "https://arxiv.org/abs/2502.20496v2",
          "size": "79kb",
          "version": "v2"
        }
      ],
      "title": "Abstraction Functions as Types",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20496",
        "PDF": "https://arxiv.org/pdf/2502.20496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper covers verification methodology using abstraction functions within type theory, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08494",
      "abstract": "This work presents a unified, fully differentiable model for multi-people tracking that learns to associate detections into trajectories without relying on pre-computed tracklets. The model builds a dynamic spatiotemporal graph that aggregates spatial, contextual, and temporal information, enabling seamless information propagation across entire sequences. To improve occlusion handling, the graph can also encode scene-specific information. We also introduce a new large-scale dataset with 25 partially overlapping views, detailed scene reconstructions, and extensive occlusions. Experiments show the model achieves state-of-the-art performance on public benchmarks and the new dataset, with flexibility across diverse conditions. Both the dataset and approach will be publicly released to advance research in multi-people tracking.",
      "authors": [
        "Martin Engilberge",
        "Ivan Vrkic",
        "Friedrich Wilke Grosche",
        "Julien Pilet",
        "Engin Turetken",
        "and Pascal Fua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:17:25+00:00",
          "link": "https://arxiv.org/abs/2507.08494v1",
          "size": "20711kb",
          "version": "v1"
        }
      ],
      "title": "Unified People Tracking with Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08494",
        "HTML": "https://arxiv.org/html/2507.08494v1",
        "PDF": "https://arxiv.org/pdf/2507.08494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a model for multi-people tracking using graph neural networks and introduces a dataset for tracking. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.14710",
      "abstract": "Training machine learning models for fair decisions faces two key challenges: The \\emph{fairness-accuracy trade-off} results from enforcing fairness which weakens its predictive performance in contrast to an unconstrained model. The incompatibility of different fairness metrics poses another trade-off -- also known as the \\emph{impossibility theorem}. Recent work identifies the bias within the observed data as a possible root cause and shows that fairness and predictive performance are in fact in accord when predictive performance is measured on unbiased data. We offer a causal explanation for these findings using the framework of the FiND (fictitious and normatively desired) world, a \"fair\" world, where protected attributes have no causal effects on the target variable. We show theoretically that (i) classical fairness metrics deemed to be incompatible are naturally satisfied in the FiND world, while (ii) fairness aligns with high predictive performance. We extend our analysis by suggesting how one can benefit from these theoretical insights in practice, using causal pre-processing methods that approximate the FiND world. Additionally, we propose a method for evaluating the approximation of the FiND world via pre-processing in practical use cases where we do not have access to the FiND world. In simulations and empirical studies, we demonstrate that these pre-processing methods are successful in approximating the FiND world and resolve both trade-offs. Our results provide actionable solutions for practitioners to achieve fairness and high predictive performance simultaneously.",
      "authors": [
        "Charlotte Leininger",
        "Simon Rittel",
        "Ludwig Bothmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T18:33:18+00:00",
          "link": "https://arxiv.org/abs/2501.14710v1",
          "size": "984kb",
          "version": "v1"
        }
      ],
      "title": "Overcoming Fairness Trade-offs via Pre-processing: A Causal Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14710",
        "HTML": "https://arxiv.org/html/2501.14710",
        "PDF": "https://arxiv.org/pdf/2501.14710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses preprocessing methods to achieve fairness in ML models; however, it focuses on fairness rather than processing LLM training data."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06361",
      "abstract": "We present an instance of utility-grade quantum computation by calculating the ground-state energy of a 125-site flat Kagome lattice under the antiferromagnetic Heisenberg model (KAFH), with IBM's Heron r1 and Heron r2 quantum processors. For spin-1/2 KAFH, our best per-site ground-state energy estimate arrives at -0.417J, and after applying open-boundary corrections, it closely approaches the established thermodynamic value of -0.438J. To achieve this, we propose a hybrid approach that splits the variational quantum eigensolver (VQE) into local (classical) and global (quantum) components for efficient hardware utilization. We further introduce a Hamiltonian engineering strategy that increases coupling on defect triangles to mimic loop-flip dynamics, allowing us to simplify the ansatz while retaining physical accuracy. Using a single-repetition, hardware-efficient ansatz, we entangle up to 103 qubits with high fidelity to determine the Hamiltonian's lowest eigenvalue. This work demonstrates the scalability of VQE for frustrated 2D systems and lays the foundation for future studies using deeper ansatz circuits and larger lattices.",
      "authors": [
        "Muhammad Ahsan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:49:17+00:00",
          "link": "https://arxiv.org/abs/2507.06361v1",
          "size": "7365kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:13:43+00:00",
          "link": "https://arxiv.org/abs/2507.06361v2",
          "size": "7439kb",
          "version": "v2"
        }
      ],
      "title": "Experimental Ground-State Energy of a 125-Site Flat Kagome Antiferromagnet via Hamiltonian Engineering on Quantum Computer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06361",
        "HTML": "https://arxiv.org/html/2507.06361v2",
        "PDF": "https://arxiv.org/pdf/2507.06361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum computation and Hamiltonian engineering for simulating quantum systems, without involving any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08091",
      "abstract": "Fine-tuning large foundation models presents significant memory challenges due to stateful optimizers like AdamW, often requiring several times more GPU memory than inference. While memory-efficient methods like parameter-efficient fine-tuning (e.g., LoRA) and optimizer state compression exist, recent approaches like GaLore bridge these by using low-rank gradient projections and subspace moment accumulation. However, such methods may struggle with fixed subspaces or computationally costly offline resampling (e.g., requiring full-matrix SVDs). We propose Momentum Factorized SGD (MoFaSGD), which maintains a dynamically updated low-rank SVD representation of the first-order momentum, closely approximating its full-rank counterpart throughout training. This factorization enables a memory-efficient fine-tuning method that adaptively updates the optimization subspace at each iteration. Crucially, MoFaSGD leverages the computed low-rank momentum factors to perform efficient spectrally normalized updates, offering an alternative to subspace moment accumulation. We establish theoretical convergence guarantees for MoFaSGD, proving it achieves an optimal rate for non-convex stochastic optimization under standard assumptions. Empirically, we demonstrate MoFaSGD's effectiveness on large language model alignment benchmarks, achieving a competitive trade-off between memory reduction (comparable to LoRA) and performance compared to state-of-the-art low-rank optimization methods. Our implementation is available at https://github.com/pmahdavi/MoFaSGD.",
      "authors": [
        "Pouria Mahdavinia",
        "Mehrdad Mahdavi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:04:52+00:00",
          "link": "https://arxiv.org/abs/2507.08091v1",
          "size": "1159kb",
          "version": "v1"
        }
      ],
      "title": "Low-rank Momentum Factorization for Memory Efficient Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08091",
        "HTML": "https://arxiv.org/html/2507.08091v1",
        "PDF": "https://arxiv.org/pdf/2507.08091"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses memory-efficient methods for fine-tuning, it is centered on optimization techniques rather than data processing or engineering for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08475",
      "abstract": "The essence of a chemical reaction lies in the redistribution and reorganization of electrons, which is often manifested through electron transfer or the migration of electron pairs. These changes are inherently discrete and abrupt in the physical world, such as alterations in the charge states of atoms or the formation and breaking of chemical bonds. To model the transition of states, we propose SynBridge, a bidirectional flow-based generative model to achieve multi-task reaction prediction. By leveraging a graph-to-graph transformer network architecture and discrete flow bridges between any two discrete distributions, SynBridge captures bidirectional chemical transformations between graphs of reactants and products through the bonds' and atoms' discrete states. We further demonstrate the effectiveness of our method through extensive experiments on three benchmark datasets (USPTO-50K, USPTO-MIT, Pistachio), achieving state-of-the-art performance in both forward and retrosynthesis tasks. Our ablation studies and noise scheduling analysis reveal the benefits of structured diffusion over discrete spaces for reaction prediction.",
      "authors": [
        "Haitao Lin",
        "Junjie Wang",
        "Zhifeng Gao",
        "Xiaohong Ji",
        "Rong Zhu",
        "Linfeng Zhang",
        "Guolin Ke",
        "Weinan E"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:35:13+00:00",
          "link": "https://arxiv.org/abs/2507.08475v1",
          "size": "992kb",
          "version": "v1"
        }
      ],
      "title": "SynBridge: Bridging Reaction States via Discrete Flow for Bidirectional Reaction Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08475",
        "HTML": "https://arxiv.org/html/2507.08475v1",
        "PDF": "https://arxiv.org/pdf/2507.08475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses chemical reaction prediction using a bidirectional model, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08660",
      "abstract": "Speaker attribution from speech transcripts is the task of identifying a speaker from the transcript of their speech based on patterns in their language use. This task is especially useful when the audio is unavailable (e.g. deleted) or unreliable (e.g. anonymized speech). Prior work in this area has primarily focused on the feasibility of attributing speakers using transcripts produced by human annotators. However, in real-world settings, one often only has more errorful transcripts produced by automatic speech recognition (ASR) systems. In this paper, we conduct what is, to our knowledge, the first comprehensive study of the impact of automatic transcription on speaker attribution performance. In particular, we study the extent to which speaker attribution performance degrades in the face of transcription errors, as well as how properties of the ASR system impact attribution. We find that attribution is surprisingly resilient to word-level transcription errors and that the objective of recovering the true transcript is minimally correlated with attribution performance. Overall, our findings suggest that speaker attribution on more errorful transcripts produced by ASR is as good, if not better, than attribution based on human-transcribed data, possibly because ASR transcription errors can capture speaker-specific features revealing of speaker identity.",
      "authors": [
        "Cristina Aggazzotti",
        "Matthew Wiesner",
        "Elizabeth Allyn Smith",
        "Nicholas Andrews"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:00:32+00:00",
          "link": "https://arxiv.org/abs/2507.08660v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "The Impact of Automatic Speech Transcription on Speaker Attribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08660",
        "PDF": "https://arxiv.org/pdf/2507.08660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on speaker attribution from transcripts produced by automatic speech recognition systems; it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04501",
      "abstract": "We propose a public key encryption cryptosystem based on solutions of linear equation systems with predefinition of input parameters through shared secret computation for factorizable substitutions. The existence of multiple equivalent solutions for an underdetermined system of linear equations determines the impossibility of its resolution by a cryptanalyst in polynomial time. The completion of input parameters of the equation system is implemented through secret homomorphic matrix transformation for substitutions factorized over the basis of a vector space of dimension m over the field F2. Encryption is implemented through computation of substitutions that are one-way functions on an elementary abelian 2-group of order 2\"m. Decryption is implemented through completion of input parameters of the equation system. Homomorphic transformations are constructed based on matrix computations. Matrix computations enable the implementation of high security and low computational overhead for homomorphic transformations.",
      "authors": [
        "Gennady Khalimov and Yevgen Kotukh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T18:38:04+00:00",
          "link": "https://arxiv.org/abs/2507.04501v1",
          "size": "774kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T18:39:18+00:00",
          "link": "https://arxiv.org/abs/2507.04501v2",
          "size": "936kb",
          "version": "v2"
        }
      ],
      "title": "LINE: Public-key encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04501",
        "PDF": "https://arxiv.org/pdf/2507.04501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a public key encryption system based on linear equations, focusing on cryptographic security rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08317",
      "abstract": "Accurate workload prediction and advanced resource reservation are indispensably crucial for managing dynamic cloud services. Traditional neural networks and deep learning models frequently encounter challenges with diverse, high-dimensional workloads, especially during sudden resource demand changes, leading to inefficiencies. This issue arises from their limited optimization during training, relying only on parametric (inter-connection weights) adjustments using conventional algorithms. To address this issue, this work proposes a novel Comprehensively Adaptive Architectural Optimization-based Variable Quantum Neural Network (CA-QNN), which combines the efficiency of quantum computing with complete structural and qubit vector parametric learning. The model converts workload data into qubits, processed through qubit neurons with Controlled NOT-gated activation functions for intuitive pattern recognition. In addition, a comprehensive architecture optimization algorithm for networks is introduced to facilitate the learning and propagation of the structure and parametric values in variable-sized QNNs. This algorithm incorporates quantum adaptive modulation and size-adaptive recombination during training process. The performance of CA-QNN model is thoroughly investigated against seven state-of-the-art methods across four benchmark datasets of heterogeneous cloud workloads. The proposed model demonstrates superior prediction accuracy, reducing prediction errors by up to 93.40% and 91.27% compared to existing deep learning and QNN-based approaches.",
      "authors": [
        "Jitendra Kumar",
        "Deepika Saxena",
        "Kishu Gupta",
        "Satyam Kumar",
        "Ashutosh Kumar Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:07:21+00:00",
          "link": "https://arxiv.org/abs/2507.08317v1",
          "size": "6827kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensively Adaptive Architectural Optimization-Ingrained Quantum Neural Network Model for Cloud Workloads Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08317",
        "PDF": "https://arxiv.org/pdf/2507.08317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on architectural optimization for quantum neural networks to predict cloud workloads, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08333",
      "abstract": "Audio inpainting refers to the task of reconstructing missing segments in corrupted audio recordings. While prior approaches-including waveform and spectrogram-based diffusion models-have shown promising results for short gaps, they often degrade in quality when gaps exceed 100 milliseconds (ms). In this work, we introduce a novel inpainting method based on discrete diffusion modeling, which operates over tokenized audio representations produced by a pre-trained audio tokenizer. Our approach models the generative process directly in the discrete latent space, enabling stable and semantically coherent reconstruction of missing audio. We evaluate the method on the MusicNet dataset using both objective and perceptual metrics across gap durations up to 300 ms. We further evaluated our approach on the MTG dataset, extending the gap duration to 500 ms. Experimental results demonstrate that our method achieves competitive or superior performance compared to existing baselines, particularly for longer gaps, offering a robust solution for restoring degraded musical recordings. Audio examples of our proposed method can be found at https://iftach21.github.io/",
      "authors": [
        "Tali Dror",
        "Iftach Shoham",
        "Moshe Buchris",
        "Oren Gal",
        "Haim Permuter",
        "Gilad Katz",
        "Eliya Nachmani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:25:49+00:00",
          "link": "https://arxiv.org/abs/2507.08333v1",
          "size": "1036kb",
          "version": "v1"
        }
      ],
      "title": "Audio Inpanting using Discrete Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08333",
        "HTML": "https://arxiv.org/html/2507.08333v1",
        "PDF": "https://arxiv.org/pdf/2507.08333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for audio inpainting using discrete diffusion models and tokenized audio representations, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08478",
      "abstract": "The detection and classification of intersections between triangles are crucial tasks in a wide range of applications within Computer Graphics and Geometry Processing, including mesh Arrangements, mesh Booleans, and generic mesh processing and fixing tasks. Existing methods are hard-coded and deeply integrated into specific algorithms, and significant efforts are usually required to integrate them into new pipelines or to extend them to different numerical representations. This paper presents a versatile and exhaustive algorithm to identify and classify intersections between triangles with either floating points, rational numbers, or implicit representations. The proposed tool is implemented as a C++ templated and header-only code that is generic and easy to integrate into further algorithms requiring the triangle-triangle intersection detection step. The developed tool has been tested and compared with a state-of-the-art approach, and it is shared with the Geometry Processing community with an Open Source license.",
      "authors": [
        "Luca Garau and Gianmarco Cherchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:40:16+00:00",
          "link": "https://arxiv.org/abs/2507.08478v1",
          "size": "1536kb",
          "version": "v1"
        }
      ],
      "title": "A Robust Approach to Detect Intersections between Triangles with Different Numerical Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08478",
        "HTML": "https://arxiv.org/html/2507.08478v1",
        "PDF": "https://arxiv.org/pdf/2507.08478"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an algorithm for detecting intersections between triangles, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08704",
      "abstract": "Knowledge graphs (KGs) play a critical role in enhancing large language models (LLMs) by introducing structured and grounded knowledge into the learning process. However, most existing KG-enhanced approaches rely on parameter-intensive fine-tuning, which risks catastrophic forgetting and degrades the pretrained model's generalization. Moreover, they exhibit limited adaptability to real-time knowledge updates due to their static integration frameworks. To address these issues, we introduce the first test-time KG-augmented framework for LLMs, built around a dedicated knowledge graph-guided attention (KGA) module that enables dynamic knowledge fusion without any parameter updates. The proposed KGA module augments the standard self-attention mechanism with two synergistic pathways: outward and inward aggregation. Specifically, the outward pathway dynamically integrates external knowledge into input representations via input-driven KG fusion. This inward aggregation complements the outward pathway by refining input representations through KG-guided filtering, suppressing task-irrelevant signals and amplifying knowledge-relevant patterns. Importantly, while the outward pathway handles knowledge fusion, the inward path selects the most relevant triples and feeds them back into the fusion process, forming a closed-loop enhancement mechanism. By synergistically combining these two pathways, the proposed method supports real-time knowledge fusion exclusively at test-time, without any parameter modification. Extensive experiments on five benchmarks verify the comparable knowledge fusion performance of KGA.",
      "authors": [
        "Songlin Zhai",
        "Guilin Qi",
        "Yuan Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:57:37+00:00",
          "link": "https://arxiv.org/abs/2507.08704v1",
          "size": "345kb",
          "version": "v1"
        }
      ],
      "title": "KG-Attention: Knowledge Graph-Guided Attention at Test-Time via Bidirectional Information Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08704",
        "PDF": "https://arxiv.org/pdf/2507.08704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper introduces a test-time KG-augmented framework for enhancing LLMs, it focuses more on model adaptation rather than on LLM training data processing or improving training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14745",
      "abstract": "In this paper, we introduce the Union-Intersection Union-Find (UIUF) algorithm for decoding depolarizing errors in topological codes, combining the strengths of iterative and standard Union-Find (UF) decoding. While iterative UF improves performance at moderate error rates, it lacks an error correction guarantee. To address this, we develop UIUF, which maintains the enhanced performance of iterative UF while ensuring error correction up to half the code distance. Through simulations under code capacity, phenomenological, and biased noise models, we show that UIUF significantly outperforms UF, reducing the logical error rate by over an order of magnitude (at around $10^{-5}$). Moreover, UIUF achieves lower logical error rates than the Minimum Weight Perfect Matching (MWPM) decoder on rotated surface codes under both the code capacity and phenomenological noise models, while preserving efficient linear-time complexity.",
      "authors": [
        "Tzu-Hao Lin and Ching-Yi Lai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T17:30:14+00:00",
          "link": "https://arxiv.org/abs/2506.14745v1",
          "size": "5412kb",
          "version": "v1"
        }
      ],
      "title": "Union-Intersection Union-Find for Decoding Depolarizing Errors in Topological Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14745",
        "HTML": "https://arxiv.org/html/2506.14745",
        "PDF": "https://arxiv.org/pdf/2506.14745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an algorithm for decoding errors in topological codes, not related to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07505",
      "abstract": "With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work.",
      "authors": [
        "Varin Sikka and Vishal Sikka"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.07505v1",
          "size": "211kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:03:49+00:00",
          "link": "https://arxiv.org/abs/2507.07505v2",
          "size": "213kb",
          "version": "v2"
        }
      ],
      "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07505",
        "PDF": "https://arxiv.org/pdf/2507.07505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the limitations of transformer-based models in terms of computational complexity and hallucinations, but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08309",
      "abstract": "Multimodal Large Language Models (MLLMs) have shown strong performance in document image tasks, especially Optical Character Recognition (OCR). However, they struggle with Document Image Machine Translation (DIMT), which requires handling both cross-modal and cross-lingual challenges. Previous efforts to enhance DIMT capability through Supervised Fine-Tuning (SFT) on the DIMT dataset often result in the forgetting of the model's existing monolingual abilities, such as OCR. To address these challenges, we introduce a novel fine-tuning paradigm, named Synchronously Self-Reviewing (SSR) its OCR proficiency, inspired by the concept \"Bilingual Cognitive Advantage\". Specifically, SSR prompts the model to generate OCR text before producing translation text, which allows the model to leverage its strong monolingual OCR ability while learning to translate text across languages. Comprehensive experiments demonstrate the proposed SSR learning helps mitigate catastrophic forgetting, improving the generalization ability of MLLMs on both OCR and DIMT tasks.",
      "authors": [
        "Yupu Liang",
        "Yaping Zhang",
        "Zhiyang Zhang",
        "Zhiyuan Chen",
        "Yang Zhao",
        "Lu Xiang",
        "Chengqing Zong",
        "Yu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:02:06+00:00",
          "link": "https://arxiv.org/abs/2507.08309v1",
          "size": "10079kb",
          "version": "v1"
        }
      ],
      "title": "Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08309",
        "PDF": "https://arxiv.org/pdf/2507.08309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a novel fine-tuning paradigm, it primarily focuses on DIMT and OCR tasks rather than on broader LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08432",
      "abstract": "Shapes Constraint Language (SHACL) is a powerful language for validating RDF data. Given the recent industry attention to Knowledge Graphs (KGs), more users need to validate linked data properly. However, traditional SHACL validation engines often provide terse reports in English that are difficult for non-technical users to interpret and act upon. This paper presents xpSHACL, an explainable SHACL validation system that addresses this issue by combining rule-based justification trees with retrieval-augmented generation (RAG) and large language models (LLMs) to produce detailed, multilanguage, human-readable explanations for constraint violations. A key feature of xpSHACL is its usage of a Violation KG to cache and reuse explanations, improving efficiency and consistency.",
      "authors": [
        "Gustavo Correa Publio and Jos\\'e Emilio Labra Gayo"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:18:41+00:00",
          "link": "https://arxiv.org/abs/2507.08432v1",
          "size": "361kb",
          "version": "v1"
        }
      ],
      "title": "xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08432",
        "HTML": "https://arxiv.org/html/2507.08432v1",
        "PDF": "https://arxiv.org/pdf/2507.08432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an explainable validation system for RDF data using SHACL, but it does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08050",
      "abstract": "The labor-intensive nature of medical data annotation presents a significant challenge for respiratory disease diagnosis, resulting in a scarcity of high-quality labeled datasets in resource-constrained settings. Moreover, patient privacy concerns complicate the direct sharing of local medical data across institutions, and existing centralized data-driven approaches, which rely on amounts of available data, often compromise data privacy. This study proposes a federated few-shot learning framework with privacy-preserving mechanisms to address the issues of limited labeled data and privacy protection in diagnosing respiratory diseases. In particular, a meta-stochastic gradient descent algorithm is proposed to mitigate the overfitting problem that arises from insufficient data when employing traditional gradient descent methods for neural network training. Furthermore, to ensure data privacy against gradient leakage, differential privacy noise from a standard Gaussian distribution is integrated into the gradients during the training of private models with local data, thereby preventing the reconstruction of medical images. Given the impracticality of centralizing respiratory disease data dispersed across various medical institutions, a weighted average algorithm is employed to aggregate local diagnostic models from different clients, enhancing the adaptability of a model across diverse scenarios. Experimental results show that the proposed method yields compelling results with the implementation of differential privacy, while effectively diagnosing respiratory diseases using data from different structures, categories, and distributions.",
      "authors": [
        "Ming Wang",
        "Zhaoyang Duan",
        "Dong Xue",
        "Fangzhou Liu",
        "Zhongheng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:47:58+00:00",
          "link": "https://arxiv.org/abs/2507.08050v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08050",
        "HTML": "https://arxiv.org/html/2507.08050v1",
        "PDF": "https://arxiv.org/pdf/2507.08050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated few-shot learning with privacy-preserving mechanisms for respiratory disease diagnosis, which involves model training with existing data but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08548",
      "abstract": "Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks and has become the state-of-the-art for visual object tracking. The model stores information from previous frames in a memory bank, enabling temporal consistency across video sequences. Recent methods augment SAM 2 with hand-crafted update rules to better handle distractors, occlusions, and object motion. We propose a fundamentally different approach using reinforcement learning for optimizing memory updates in SAM 2 by framing memory control as a sequential decision-making problem. In an overfitting setup with a separate agent per video, our method achieves a relative improvement over SAM 2 that exceeds by more than three times the gains of existing heuristics. These results reveal the untapped potential of the memory bank and highlight reinforcement learning as a powerful alternative to hand-crafted update rules for memory control in visual object tracking.",
      "authors": [
        "Alen Adamyan",
        "Tom\\'a\\v{s} \\v{C}\\'i\\v{z}ek",
        "Matej Straka",
        "Klara Janouskova",
        "Martin Schmid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:53:19+00:00",
          "link": "https://arxiv.org/abs/2507.08548v1",
          "size": "10244kb",
          "version": "v1"
        }
      ],
      "title": "SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08548",
        "HTML": "https://arxiv.org/html/2507.08548v1",
        "PDF": "https://arxiv.org/pdf/2507.08548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores reinforcement learning for memory control in object segmentation models, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15577",
      "abstract": "The adoption of Machine Learning Operations (MLOps) enables automation and reliable model deployments across industries. However, differing MLOps lifecycle frameworks and maturity models proposed by industry, academia, and organizations have led to confusion regarding standard adoption practices. This paper introduces a unified MLOps lifecycle framework, further incorporating Large Language Model Operations (LLMOps), to address this gap. Additionally, we outlines key roles, tools, and costs associated with MLOps adoption at various maturity levels. By providing a standardized framework, we aim to help organizations clearly define and allocate the resources needed to implement MLOps effectively.",
      "authors": [
        "Jasper Stone",
        "Raj Patel",
        "Farbod Ghiasi",
        "Sudip Mittal",
        "and Shahram Rahimi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T13:20:14+00:00",
          "link": "https://arxiv.org/abs/2503.15577v1",
          "size": "327kb",
          "version": "v1"
        }
      ],
      "title": "Navigating MLOps: Insights into Maturity, Lifecycle, Tools, and Careers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15577",
        "HTML": "https://arxiv.org/html/2503.15577",
        "PDF": "https://arxiv.org/pdf/2503.15577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on MLOps and LLMOps lifecycle frameworks and does not discuss processing of LLM training data or data engineering methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08096",
      "abstract": "Accurate estimation of building heights using very high resolution (VHR) synthetic aperture radar (SAR) imagery is crucial for various urban applications. This paper introduces a Deep Learning (DL)-based methodology for automated building height estimation from single VHR COSMO-SkyMed images: an object-based regression approach based on bounding box detection followed by height estimation. This model was trained and evaluated on a unique multi-continental dataset comprising eight geographically diverse cities across Europe, North and South America, and Asia, employing a cross-validation strategy to explicitly assess out-of-distribution (OOD) generalization. The results demonstrate highly promising performance, particularly on European cities where the model achieves a Mean Absolute Error (MAE) of approximately one building story (2.20 m in Munich), significantly outperforming recent state-of-the-art methods in similar OOD scenarios. Despite the increased variability observed when generalizing to cities in other continents, particularly in Asia with its distinct urban typologies and prevalence of high-rise structures, this study underscores the significant potential of DL for robust cross-city and cross-continental transfer learning in building height estimation from single VHR SAR data.",
      "authors": [
        "Babak Memar",
        "Luigi Russo",
        "Silvia Liberata Ullo",
        "and Paolo Gamba"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:16:16+00:00",
          "link": "https://arxiv.org/abs/2507.08096v1",
          "size": "6014kb",
          "version": "v1"
        }
      ],
      "title": "An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08096",
        "HTML": "https://arxiv.org/html/2507.08096v1",
        "PDF": "https://arxiv.org/pdf/2507.08096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on deep learning approaches for estimating building heights from SAR images, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08177",
      "abstract": "As cyber-physical systems grow increasingly interconnected and spatially distributed, ensuring their resilience against evolving cyberattacks has become a critical priority. Spatio-Temporal Anomaly detection plays an important role in ensuring system security and operational integrity. However, current data-driven approaches, largely driven by black-box deep learning, face challenges in interpretability, adaptability to distribution shifts, and robustness under evolving system dynamics. In this paper, we advocate for a causal learning perspective to advance anomaly detection in spatially distributed infrastructures that grounds detection in structural cause-effect relationships. We identify and formalize three key directions: causal graph profiling, multi-view fusion, and continual causal graph learning, each offering distinct advantages in uncovering dynamic cause-effect structures across time and space. Drawing on real-world insights from systems such as water treatment infrastructures, we illustrate how causal models provide early warning signals and root cause attribution, addressing the limitations of black-box detectors. Looking ahead, we outline the future research agenda centered on multi-modality, generative AI-driven, and scalable adaptive causal frameworks. Our objective is to lay a new research trajectory toward scalable, adaptive, explainable, and spatially grounded anomaly detection systems. We hope to inspire a paradigm shift in cybersecurity research, promoting causality-driven approaches to address evolving threats in interconnected infrastructures.",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Haoyue Bai",
        "Xinyuan Wang",
        "Anjali Kaushik",
        "Dongjie Wang",
        "Yanjie Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:19:28+00:00",
          "link": "https://arxiv.org/abs/2507.08177v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08177",
        "HTML": "https://arxiv.org/html/2507.08177v1",
        "PDF": "https://arxiv.org/pdf/2507.08177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on causal learning for anomaly detection in cybersecurity contexts with no linkage to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.14003",
      "abstract": "Automatic question answering is an important yet challenging task in E-commerce given the millions of questions posted by users about the product that they are interested in purchasing. Hence, there is a great demand for automatic answer generation systems that provide quick responses using related information about the product. There are three sources of knowledge available for answering a user posted query, they are reviews, duplicate or similar questions, and specifications. Effectively utilizing these information sources will greatly aid us in answering complex questions. However, there are two main challenges present in exploiting these sources: (i) The presence of irrelevant information and (ii) the presence of ambiguity of sentiment present in reviews and similar questions. Through this work we propose a novel pipeline (MSQAP) that utilizes the rich information present in the aforementioned sources by separately performing relevancy and ambiguity prediction before generating a response.\n  Experimental results show that our relevancy prediction model (BERT-QA) outperforms all other variants and has an improvement of 12.36% in F1 score compared to the BERT-base baseline. Our generation model (T5-QA) outperforms the baselines in all content preservation metrics such as BLEU, ROUGE and has an average improvement of 35.02% in ROUGE and 198.75% in BLEU compared to the highest performing baseline (HSSC-q). Human evaluation of our pipeline shows us that our method has an overall improvement in accuracy of 30.7% over the generation model (T5-QA), resulting in our full pipeline-based approach (MSQAP) providing more accurate answers. To the best of our knowledge, this is the first work in the e-commerce domain that automatically generates natural language answers combining the information present in diverse sources such as specifications, similar questions, and reviews data.",
      "authors": [
        "Anand A. Rajasekar",
        "Nikesh Garera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-27T23:19:49+00:00",
          "link": "https://arxiv.org/abs/2111.14003v1",
          "size": "208kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:13:57+00:00",
          "link": "https://arxiv.org/abs/2111.14003v2",
          "size": "104kb",
          "version": "v2"
        }
      ],
      "title": "Answer Generation for Questions With Multiple Information Sources in E-Commerce",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.14003",
        "HTML": "https://arxiv.org/html/2111.14003v2",
        "PDF": "https://arxiv.org/pdf/2111.14003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses automatic answer generation using existing information sources and a novel pipeline but does not focus on LLM training data processing or creation."
      },
      "tasks": [
        "Answer Generation",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.05739",
      "abstract": "Speech clarity and spatial audio immersion are the two most critical factors in enhancing remote conferencing experiences. Existing methods are often limited: either due to the lack of spatial information when using only one microphone, or because their performance is highly dependent on the accuracy of direction-of-arrival estimation when using microphone array. To overcome this issue, we introduce an end-to-end deep learning framework that has the capacity of mapping multi-channel noisy and reverberant signals to clean and spatialized binaural speech directly. This framework unifies source extraction, noise suppression, and binaural rendering into one network. In this framework, a novel magnitude-weighted interaural level difference loss function is proposed that aims to improve the accuracy of spatial rendering. Extensive evaluations show that our method outperforms established baselines in terms of both speech quality and spatial fidelity.",
      "authors": [
        "Cheng Chi",
        "Xiaoyu Li",
        "Yuxuan Ke",
        "Qunping Ni",
        "Yao Ge",
        "Xiaodong Li",
        "Chengshi Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T06:55:35+00:00",
          "link": "https://arxiv.org/abs/2410.05739v1",
          "size": "458kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:44:12+00:00",
          "link": "https://arxiv.org/abs/2410.05739v2",
          "size": "280kb",
          "version": "v2"
        }
      ],
      "title": "End-to-end multi-channel speaker extraction and binaural speech synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05739",
        "HTML": "https://arxiv.org/html/2410.05739v2",
        "PDF": "https://arxiv.org/pdf/2410.05739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses speech clarity and spatial audio immersion using a deep learning framework but doesn't discuss LLM training data processing or dataset creation."
      },
      "tasks": [
        "Audio Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08014",
      "abstract": "As large language models (LLMs) become increasingly deployed, understanding the complexity and evolution of jailbreaking strategies is critical for AI safety.\n  We present a mass-scale empirical analysis of jailbreak complexity across over 2 million real-world conversations from diverse platforms, including dedicated jailbreaking communities and general-purpose chatbots. Using a range of complexity metrics spanning probabilistic measures, lexical diversity, compression ratios, and cognitive load indicators, we find that jailbreak attempts do not exhibit significantly higher complexity than normal conversations. This pattern holds consistently across specialized jailbreaking communities and general user populations, suggesting practical bounds on attack sophistication. Temporal analysis reveals that while user attack toxicity and complexity remains stable over time, assistant response toxicity has decreased, indicating improving safety mechanisms. The absence of power-law scaling in complexity distributions further points to natural limits on jailbreak development.\n  Our findings challenge the prevailing narrative of an escalating arms race between attackers and defenders, instead suggesting that LLM safety evolution is bounded by human ingenuity constraints while defensive measures continue advancing. Our results highlight critical information hazards in academic jailbreak disclosure, as sophisticated attacks exceeding current complexity baselines could disrupt the observed equilibrium and enable widespread harm before defensive adaptation.",
      "authors": [
        "Aldan Creo",
        "Raul Castro Fernandez",
        "Manuel Cebrian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T08:41:30+00:00",
          "link": "https://arxiv.org/abs/2507.08014v1",
          "size": "650kb",
          "version": "v1"
        }
      ],
      "title": "Mass-Scale Analysis of In-the-Wild Conversations Reveals Complexity Bounds on LLM Jailbreaking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08014",
        "HTML": "https://arxiv.org/html/2507.08014v1",
        "PDF": "https://arxiv.org/pdf/2507.08014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper conducts a mass-scale analysis of conversation complexity regarding LLM jailbreak attempts, not focusing on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08164",
      "abstract": "The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts.",
      "authors": [
        "Yun Tang",
        "Mengbang Zou",
        "Zeinab Nezami",
        "Syed Ali Raza Zaidi",
        "Weisi Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:54:36+00:00",
          "link": "https://arxiv.org/abs/2507.08164v1",
          "size": "1347kb",
          "version": "v1"
        }
      ],
      "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08164",
        "HTML": "https://arxiv.org/html/2507.08164v1",
        "PDF": "https://arxiv.org/pdf/2507.08164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a network knowledge system for agentic network intelligence, lacking contributions to LLM training data processing or creation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08492",
      "abstract": "Document image dewarping remains a challenging task in the deep learning era. While existing methods have improved by leveraging text line awareness, they typically focus only on a single horizontal dimension. In this paper, we propose a fine-grained deformation perception model that focuses on Dual Dimensions of document horizontal-vertical-lines to improve document Dewarping called D2Dewarp. It can perceive distortion trends in different directions across document details. To combine the horizontal and vertical granularity features, an effective fusion module based on X and Y coordinate is designed to facilitate interaction and constraint between the two dimensions for feature complementarity. Due to the lack of annotated line features in current public dewarping datasets, we also propose an automatic fine-grained annotation method using public document texture images and an automatic rendering engine to build a new large-scale distortion training dataset. The code and dataset will be publicly released. On public Chinese and English benchmarks, both quantitative and qualitative results show that our method achieves better rectification results compared with the state-of-the-art methods. The dataset will be publicly available at https://github.com/xiaomore/DocDewarpHV",
      "authors": [
        "Heng Li",
        "Qingcai Chen and Xiangping Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:16:58+00:00",
          "link": "https://arxiv.org/abs/2507.08492v1",
          "size": "3593kb",
          "version": "v1"
        }
      ],
      "title": "Dual Dimensions Geometric Representation Learning Based Document Dewarping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08492",
        "HTML": "https://arxiv.org/html/2507.08492v1",
        "PDF": "https://arxiv.org/pdf/2507.08492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a new dataset for document dewarping, which involves automatic fine-grained annotation; however, this dataset pertains to document image processing rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.10964",
      "abstract": "Online Feedback Optimization (OFO) is a control approach to drive a dynamical plant to an optimal steady state. By interconnecting optimization algorithms with real-time plant measurements, OFO provides all the benefits of feedback control, yet without requiring exact knowledge of plant dynamics for computing a setpoint. On the downside, existing stability guarantees for OFO require the controller to evolve on a sufficiently slower timescale than the plant, possibly affecting transient performance and responsiveness to disturbances. In this paper, we prove that, under suitable conditions, OFO ensures stability without any timescale separation. In particular, the condition we propose is independent of the time constant of the plant, hence it is scaling-invariant. Our analysis leverages a composite Lyapunov function, which is the $\\max$ of plant-related and controller-related components. We corroborate our theoretical results with numerical examples.",
      "authors": [
        "Mattia Bianchi",
        "Florian D\\\"orfler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-14T20:51:26+00:00",
          "link": "https://arxiv.org/abs/2412.10964v1",
          "size": "333kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:09:12+00:00",
          "link": "https://arxiv.org/abs/2412.10964v2",
          "size": "257kb",
          "version": "v2"
        }
      ],
      "title": "A Stability Condition for Online Feedback Optimization without Timescale Separation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10964",
        "HTML": "https://arxiv.org/html/2412.10964v2",
        "PDF": "https://arxiv.org/pdf/2412.10964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a stability condition for online feedback optimization without timescale separation, but it does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.10660",
      "abstract": "This note considers the blind free deconvolution problems of sparse spectral measures from one-parameter families. These problems pose significant challenges since they involve nonlinear sparse recovery. The main technical tool is the eigenmatrix method for solving unstructured sparse recovery problems. The key idea is to turn the nonlinear inverse problem into a linear inverse problem by leveraging the R-transform for free addition and the S-transform for free product. The resulting linear problem is solved with the eigenmatrix method tailored to the domain of the parametric family. Numerical results are provided for both the additive and multiplicative free deconvolutions.",
      "authors": [
        "Lexing Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-18T05:40:23+00:00",
          "link": "https://arxiv.org/abs/2501.10660v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T21:00:27+00:00",
          "link": "https://arxiv.org/abs/2501.10660v2",
          "size": "55kb",
          "version": "v2"
        }
      ],
      "title": "Blind free deconvolution over one-parameter sparse families via eigenmatrix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10660",
        "HTML": "https://arxiv.org/html/2501.10660v2",
        "PDF": "https://arxiv.org/pdf/2501.10660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on solving unstructured sparse recovery problems using eigenmatrix methods but does not mention LLM training data or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05044",
      "abstract": "This study introduces a hybrid machine learning-based scale-bridging framework for predicting the permeability of fibrous textile structures. By addressing the computational challenges inherent to multiscale modeling, the proposed approach evaluates the efficiency and accuracy of different scale-bridging methodologies combining traditional surrogate models and even integrating physics-informed neural networks (PINNs) with numerical solvers, enabling accurate permeability predictions across micro- and mesoscales. Four methodologies were evaluated: Single Scale Method (SSM), Simple Upscaling Method (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM, the simplest method, neglects microscale permeability and exhibited permeability values deviating by up to 150\\% of the FRM model, which was taken as ground truth at an equivalent lower fiber volume content. SUM improved predictions by considering uniform microscale permeability, yielding closer values under similar conditions, but still lacked structural variability. The SBM method, incorporating segment-based microscale permeability assignments, showed significant enhancements, achieving almost equivalent values while maintaining computational efficiency and modeling runtimes of ~45 minutes per simulation. In contrast, FRM, which provides the highest fidelity by fully resolving microscale and mesoscale geometries, required up to 270 times more computational time than SSM, with model files exceeding 300 GB. Additionally, a hybrid dual-scale solver incorporating PINNs has been developed and shows the potential to overcome generalization errors and the problem of data scarcity of the data-driven surrogate approaches. The hybrid framework advances permeability modelling by balancing computational cost and prediction reliability, laying the foundation for further applications in fibrous composite manufacturing.",
      "authors": [
        "Denis Korolev",
        "Tim Schmidt",
        "Dinesh K. Natarajan",
        "Stefano Cassola",
        "David May",
        "Miro Duhovic",
        "Michael Hinterm\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T16:09:25+00:00",
          "link": "https://arxiv.org/abs/2502.05044v1",
          "size": "5789kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T20:48:05+00:00",
          "link": "https://arxiv.org/abs/2502.05044v2",
          "size": "3392kb",
          "version": "v2"
        }
      ],
      "title": "Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05044",
        "HTML": "https://arxiv.org/html/2502.05044v2",
        "PDF": "https://arxiv.org/pdf/2502.05044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a hybrid machine learning framework for permeability prediction in fibrous structures, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Hybrid Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08330",
      "abstract": "Deep learning has driven significant advances in medical image analysis, yet its adoption in clinical practice remains constrained by the large size and lack of transparency in modern models. Advances in interpretability techniques such as DL-Backtrace, Layer-wise Relevance Propagation, and Integrated Gradients make it possible to assess the contribution of individual components within neural networks trained on medical imaging tasks. In this work, we introduce an interpretability-guided pruning framework that reduces model complexity while preserving both predictive performance and transparency. By selectively retaining only the most relevant parts of each layer, our method enables targeted compression that maintains clinically meaningful representations. Experiments across multiple medical image classification benchmarks demonstrate that this approach achieves high compression rates with minimal loss in accuracy, paving the way for lightweight, interpretable models suited for real-world deployment in healthcare settings.",
      "authors": [
        "Nikita Malik",
        "Pratinav Seth",
        "Neeraj Kumar Singh",
        "Chintan Chitroda",
        "Vinay Kumar Sankarapu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:58:22+00:00",
          "link": "https://arxiv.org/abs/2507.08330v1",
          "size": "3762kb",
          "version": "v1"
        }
      ],
      "title": "Interpretability-Aware Pruning for Efficient Medical Image Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08330",
        "HTML": "https://arxiv.org/html/2507.08330v1",
        "PDF": "https://arxiv.org/pdf/2507.08330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The interpretability-guided pruning framework proposed focuses on model efficiency and transparency in medical image analysis, not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08339",
      "abstract": "Recently, the development of large language models (LLMs) and reasoning large language models (RLLMs) have gained considerable attention from many researchers. RLLMs enhance the reasoning capabilities of LLMs through Long Chain-of-Thought (Long CoT) processes, significantly improving the performance of LLMs in addressing complex problems. However, there are few works that systematically explore what methods can fully unlock the performance of LLMs and RLLMs within the financial domain. To investigate the impact of various methods on LLMs and RLLMs, we utilize five LLMs and three RLLMs to assess the effects of prompting methods, agentic frameworks, and multilingual alignment methods on financial question-answering tasks. Our research findings indicate: (1) Current prompting methods and agent frameworks enhance the performance of LLMs in financial question answering by simulating Long CoT; (2) RLLMs possess inherent Long CoT capabilities, which limits the effectiveness of conventional methods in further enhancing their performance; (3) Current advanced multilingual alignment methods primarily improve the multilingual performance of LLMs by extending the reasoning length, which yields minimal benefits for RLLMs. We hope that this study can serve as an important reference for LLMs and RLLMs in the field of financial question answering.",
      "authors": [
        "Peng Wang",
        "Xuesi Hu",
        "Jiageng Wu",
        "Yuntao Zou",
        "Qiancheng Zhang",
        "Dagang Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:37:44+00:00",
          "link": "https://arxiv.org/abs/2507.08339v1",
          "size": "248kb",
          "version": "v1"
        }
      ],
      "title": "What Factors Affect LLMs and RLLMs in Financial Question Answering?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08339",
        "HTML": "https://arxiv.org/html/2507.08339v1",
        "PDF": "https://arxiv.org/pdf/2507.08339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating and improving performance for financial question-answering using existing LLM and RLLM architectures, primarily through prompt engineering and multilingual alignment methods. It does not contribute directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08340",
      "abstract": "Deep learning has shown remarkable performance in integrating multimodal data for survival prediction. However, existing multimodal methods mainly focus on single cancer types and overlook the challenge of generalization across cancers. In this work, we are the first to reveal that multimodal prognosis models often generalize worse than unimodal ones in cross-cancer scenarios, despite the critical need for such robustness in clinical practice. To address this, we propose a new task: Cross-Cancer Single Domain Generalization for Multimodal Prognosis, which evaluates whether models trained on a single cancer type can generalize to unseen cancers. We identify two key challenges: degraded features from weaker modalities and ineffective multimodal integration. To tackle these, we introduce two plug-and-play modules: Sparse Dirac Information Rebalancer (SDIR) and Cancer-aware Distribution Entanglement (CADE). SDIR mitigates the dominance of strong features by applying Bernoulli-based sparsification and Dirac-inspired stabilization to enhance weaker modality signals. CADE, designed to synthesize the target domain distribution, fuses local morphological cues and global gene expression in latent space. Experiments on a four-cancer-type benchmark demonstrate superior generalization, laying the foundation for practical, robust cross-cancer multimodal prognosis. Code is available at https://github.com/HopkinsKwong/MCCSDG",
      "authors": [
        "Jia-Xuan Jiang",
        "Jiashuai Liu",
        "Hongtao Wu",
        "Yifeng Wu",
        "Zhong Wang",
        "Qi Bi",
        "Yefeng Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:37:48+00:00",
          "link": "https://arxiv.org/abs/2507.08340v1",
          "size": "5001kb",
          "version": "v1"
        }
      ],
      "title": "Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08340",
        "HTML": "https://arxiv.org/html/2507.08340v1",
        "PDF": "https://arxiv.org/pdf/2507.08340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses model generalization for multimodal cancer prognosis but does not discuss the collection, creation, or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.17156",
      "abstract": "The use of large language models (LLMs) for relevance assessment in information retrieval has gained significant attention, with recent studies suggesting that LLM-based judgments provide comparable evaluations to human judgments. Notably, based on TREC 2024 data, Upadhyay et al. make a bold claim that LLM-based relevance assessments, such as those generated by the UMBRELA system, can fully replace traditional human relevance assessments in TREC-style evaluations. This paper critically examines this claim, highlighting practical and theoretical limitations that undermine the validity of this conclusion. First, we question whether the evidence provided by Upadhyay et al. really supports their claim, particularly if a test collection is used asa benchmark for future improvements. Second, through a submission deliberately intended to do so, we demonstrate the ease with which automatic evaluation metrics can be subverted, showing that systems designed to exploit these evaluations can achieve artificially high scores. Theoretical challenges -- such as the inherent narcissism of LLMs, the risk of overfitting to LLM-based metrics, and the potential degradation of future LLM performance -- must be addressed before LLM-based relevance assessments can be considered a viable replacement for human judgments.",
      "authors": [
        "Charles L. A. Clarke",
        "Laura Dietz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-22T20:45:15+00:00",
          "link": "https://arxiv.org/abs/2412.17156v1",
          "size": "987kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T02:27:49+00:00",
          "link": "https://arxiv.org/abs/2412.17156v2",
          "size": "1455kb",
          "version": "v2"
        }
      ],
      "title": "LLM-based relevance assessment still can't replace human relevance assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17156",
        "HTML": "https://arxiv.org/html/2412.17156",
        "PDF": "https://arxiv.org/pdf/2412.17156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the accuracy of LLM-based relevance assessments compared to human assessments in information retrieval, highlighting limitations without discussing any processes or methodologies related to LLM training data processing."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06740",
      "abstract": "Accurate prediction of surrounding road users' trajectories is essential for safe and efficient autonomous driving. While deep learning models have improved performance, challenges remain in preventing off-road predictions and ensuring kinematic feasibility. Existing methods incorporate road-awareness modules and enforce kinematic constraints but lack plausibility guarantees and often introduce trade-offs in complexity and flexibility. This paper proposes a novel framework that formulates trajectory prediction as a constrained regression guided by permissible driving directions and their boundaries. Using the agent's current state and an HD map, our approach defines the valid boundaries and ensures on-road predictions by training the network to learn superimposed paths between left and right boundary polylines. To guarantee feasibility, the model predicts acceleration profiles that determine the vehicle's travel distance along these paths while adhering to kinematic constraints. We evaluate our approach on the Argoverse-2 dataset against the HPTR baseline. Our approach shows a slight decrease in benchmark metrics compared to HPTR but notably improves final displacement error and eliminates infeasible trajectories. Moreover, the proposed approach has superior generalization to less prevalent maneuvers and unseen out-of-distribution scenarios, reducing the off-road rate under adversarial attacks from 66% to just 1%. These results highlight the effectiveness of our approach in generating feasible and robust predictions.",
      "authors": [
        "Ahmed Abouelazm",
        "Mianzhi Liu",
        "Christian Hubschneider",
        "Yin Wu",
        "Daniel Slieter",
        "and J. Marius Z\\\"ollner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-10T19:21:00+00:00",
          "link": "https://arxiv.org/abs/2505.06740v1",
          "size": "2306kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:18:48+00:00",
          "link": "https://arxiv.org/abs/2505.06740v2",
          "size": "2306kb",
          "version": "v2"
        }
      ],
      "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06740",
        "HTML": "https://arxiv.org/html/2505.06740v2",
        "PDF": "https://arxiv.org/pdf/2505.06740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for trajectory prediction in autonomous driving, focusing on road awareness and physical feasibility but not on LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08207",
      "abstract": "As large language models (LLMs) are increasingly deployed in critical applications, the challenge of jailbreaking, where adversaries manipulate the models to bypass safety mechanisms, has become a significant concern. This paper presents a dynamic Stackelberg game framework to model the interactions between attackers and defenders in the context of LLM jailbreaking. The framework treats the prompt-response dynamics as a sequential extensive-form game, where the defender, as the leader, commits to a strategy while anticipating the attacker's optimal responses. We propose a novel agentic AI solution, the \"Purple Agent,\" which integrates adversarial exploration and defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple Agent actively simulates potential attack trajectories and intervenes proactively to prevent harmful outputs. This approach offers a principled method for analyzing adversarial dynamics and provides a foundation for mitigating the risk of jailbreaking.",
      "authors": [
        "Zhengye Han and Quanyan Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:37:47+00:00",
          "link": "https://arxiv.org/abs/2507.08207v1",
          "size": "721kb",
          "version": "v1"
        }
      ],
      "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08207",
        "HTML": "https://arxiv.org/html/2507.08207v1",
        "PDF": "https://arxiv.org/pdf/2507.08207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a dynamic framework for defending against LLM jailbreaking, focusing on prompt-response dynamics and adversarial strategies, not on training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08285",
      "abstract": "Drag-based editing allows precise object manipulation through point-based control, offering user convenience. However, current methods often suffer from a geometric inconsistency problem by focusing exclusively on matching user-defined points, neglecting the broader geometry and leading to artifacts or unstable edits. We propose FlowDrag, which leverages geometric information for more accurate and coherent transformations. Our approach constructs a 3D mesh from the image, using an energy function to guide mesh deformation based on user-defined drag points. The resulting mesh displacements are projected into 2D and incorporated into a UNet denoising process, enabling precise handle-to-target point alignment while preserving structural integrity. Additionally, existing drag-editing benchmarks provide no ground truth, making it difficult to assess how accurately the edits match the intended transformations. To address this, we present VFD (VidFrameDrag) benchmark dataset, which provides ground-truth frames using consecutive shots in a video dataset. FlowDrag outperforms existing drag-based editing methods on both VFD Bench and DragBench.",
      "authors": [
        "Gwanhyeong Koo",
        "Sunjae Yoon",
        "Younghwan Lee",
        "Ji Woo Hong",
        "Chang D. Yoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:18:52+00:00",
          "link": "https://arxiv.org/abs/2507.08285v1",
          "size": "11303kb",
          "version": "v1"
        }
      ],
      "title": "FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08285",
        "HTML": "https://arxiv.org/html/2507.08285v1",
        "PDF": "https://arxiv.org/pdf/2507.08285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with geometric image editing techniques and benchmark creation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08325",
      "abstract": "In e-commerce private-domain channels such as instant messaging and e-mail, merchants engage customers directly as part of their Customer Relationship Management (CRM) programmes to drive retention and conversion. While a few top performers excel at crafting outbound messages, most merchants struggle to write persuasive copy because they lack both expertise and scalable tools. We introduce CRMAgent, a multi-agent system built on large language models (LLMs) that generates high-quality message templates and actionable writing guidance through three complementary modes. First, group-based learning enables the agent to learn from a merchant's own top-performing messages within the same audience segment and rewrite low-performing ones. Second, retrieval-and-adaptation fetches templates that share the same audience segment and exhibit high similarity in voucher type and product category, learns their successful patterns, and adapts them to the current campaign. Third, a rule-based fallback provides a lightweight zero-shot rewrite when no suitable references are available. Extensive experiments show that CRMAgent consistently outperforms merchants' original templates, delivering significant gains in both audience-match and marketing-effectiveness metrics.",
      "authors": [
        "Yinzhu Quan",
        "Xinrui Li",
        "Ying Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:31:35+00:00",
          "link": "https://arxiv.org/abs/2507.08325v1",
          "size": "3683kb",
          "version": "v1"
        }
      ],
      "title": "CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08325",
        "HTML": "https://arxiv.org/html/2507.08325v1",
        "PDF": "https://arxiv.org/pdf/2507.08325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating message templates using a multi-agent LLM system and does not discuss processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08664",
      "abstract": "AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to perform interpretation and inference in text and image tasks without post-training, where LLMs and MLLMs play the most critical role and determine the initial ability and limitations of AI Agents. Usually, AI Agents utilize sophisticated prompt engineering and external reasoning framework to obtain a promising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought and Image-of-Thought. However, they are still constrained by the inherent limitations of LLM in understanding natural language, and the iterative reasoning process will generate a large amount of inference cost. To this end, we propose a novel AI Agent Reasoning Framework with Introspection of Thought (INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute programmatic dialogue reasoning processes following the code in prompt. Therefore, self-denial and reflection occur within LLM instead of outside LLM, which can reduce token cost effectively. Through our experiments on six benchmarks for three different tasks, the effectiveness of INoT is verified, with an average improvement of 7.95\\% in performance, exceeding the baselines. Furthermore, the token cost of INoT is lower on average than the best performing method at baseline by 58.3\\%. In addition, we demonstrate the versatility of INoT in image interpretation and inference through verification experiments.",
      "authors": [
        "Haoran Sun",
        "Shaoning Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:03:17+00:00",
          "link": "https://arxiv.org/abs/2507.08664v1",
          "size": "6610kb",
          "version": "v1"
        }
      ],
      "title": "Introspection of Thought Helps AI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08664",
        "HTML": "https://arxiv.org/html/2507.08664v1",
        "PDF": "https://arxiv.org/pdf/2507.08664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses prompting methods and reasoning frameworks in AI agents utilizing LLMs, without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06759",
      "abstract": "Deep neural networks for medical image segmentation often produce overconfident results misaligned with empirical observations. Such miscalibration, challenges their clinical translation. We propose to use marginal L1 average calibration error (mL1-ACE) as a novel auxiliary loss function to improve pixel-wise calibration without compromising segmentation quality. We show that this loss, despite using hard binning, is directly differentiable, bypassing the need for approximate but differentiable surrogate or soft binning approaches. Our work also introduces the concept of dataset reliability histograms which generalises standard reliability diagrams for refined visual assessment of calibration in semantic segmentation aggregated at the dataset level. Using mL1-ACE, we reduce average and maximum calibration error by 45% and 55% respectively, maintaining a Dice score of 87% on the BraTS 2021 dataset. We share our code here: https://github.com/cai4cai/ACE-DLIRIS",
      "authors": [
        "Theodore Barfoot and Luis Garcia-Peraza-Herrera and Ben Glocker and Tom Vercauteren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T14:31:03+00:00",
          "link": "https://arxiv.org/abs/2403.06759v1",
          "size": "238kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T14:15:56+00:00",
          "link": "https://arxiv.org/abs/2403.06759v2",
          "size": "441kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T09:36:10+00:00",
          "link": "https://arxiv.org/abs/2403.06759v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06759",
        "PDF": "https://arxiv.org/pdf/2403.06759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving reliability in image segmentation via a differentiable loss function and doesn't address LLM training data processing."
      },
      "tasks": [
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/cai4cai/ace-dliris"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17224",
      "abstract": "Vision Large Language Models (VLLMs) exhibit promising potential for multi-modal understanding, yet their application to video-based emotion recognition remains limited by insufficient spatial and contextual awareness. Traditional approaches, which prioritize isolated facial features, often neglect critical non-verbal cues such as body language, environmental context, and social interactions, leading to reduced robustness in real-world scenarios. To address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel framework that enhances zero-shot emotion recognition by integrating spatial annotations (e.g., bounding boxes, facial landmarks), physiological signals (facial action units), and contextual cues (body posture, scene dynamics, others' emotions) into a unified prompting strategy. SoVTP preserves holistic scene information while enabling fine-grained analysis of facial muscle movements and interpersonal dynamics. Extensive experiments show that SoVTP achieves substantial improvements over existing visual prompting methods, demonstrating its effectiveness in enhancing VLLMs' video emotion recognition capabilities.",
      "authors": [
        "Zhifeng Wang and Qixuan Zhang and Peter Zhang and Wenjia Niu and Kaihao Zhang and Ramesh Sankaranarayana and Sabrina Caldwell and Tom Gedeon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T03:26:30+00:00",
          "link": "https://arxiv.org/abs/2504.17224v1",
          "size": "7141kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T02:47:07+00:00",
          "link": "https://arxiv.org/abs/2504.17224v2",
          "size": "6169kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T05:44:57+00:00",
          "link": "https://arxiv.org/abs/2504.17224v3",
          "size": "5793kb",
          "version": "v3"
        }
      ],
      "title": "Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17224",
        "HTML": "https://arxiv.org/html/2504.17224v3",
        "PDF": "https://arxiv.org/pdf/2504.17224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a new framework for emotion recognition in multimodal models, mentioning prompting strategies. However, it primarily seeks to improve model performance rather than focusing on processing of LLM training data."
      },
      "tasks": [
        "Emotion Recognition",
        "Video Emotion Recognition",
        "Visual Prompting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08107",
      "abstract": "We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples.",
      "authors": [
        "Sebastian Walter",
        "Hannah Bast"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:50:05+00:00",
          "link": "https://arxiv.org/abs/2507.08107v1",
          "size": "110kb",
          "version": "v1"
        }
      ],
      "title": "GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08107",
        "HTML": "https://arxiv.org/html/2507.08107v1",
        "PDF": "https://arxiv.org/pdf/2507.08107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes using a large language model to generate SPARQL queries across knowledge graphs without fine-tuning, but it does not focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08112",
      "abstract": "Obstacle avoidance is crucial for mobile robots' navigation in both known and unknown environments. This research designs, trains, and tests two custom Convolutional Neural Networks (CNNs), using color and depth images from a depth camera as inputs. Both networks adopt sensor fusion to produce an output: the mobile robot's angular velocity, which serves as the robot's steering command. A newly obtained visual dataset for navigation was collected in diverse environments with varying lighting conditions and dynamic obstacles. During data collection, a communication link was established over Wi-Fi between a remote server and the robot, using Robot Operating System (ROS) topics. Velocity commands were transmitted from the server to the robot, enabling synchronized recording of visual data and the corresponding steering commands. Various evaluation metrics, such as Mean Squared Error, Variance Score, and Feed-Forward time, provided a clear comparison between the two networks and clarified which one to use for the application.",
      "authors": [
        "Lamiaa H. Zain",
        "Hossam H. Ammar",
        "Raafat E. Shalaby"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:53:44+00:00",
          "link": "https://arxiv.org/abs/2507.08112v1",
          "size": "3367kb",
          "version": "v1"
        }
      ],
      "title": "Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08112",
        "HTML": "https://arxiv.org/html/2507.08112v1",
        "PDF": "https://arxiv.org/pdf/2507.08112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes imitation learning for obstacle avoidance using CNNs, which involves sensor fusion and collected datasets in robotic environments, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08118",
      "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical constraints into the loss function. However, standard optimizers such as Adam often struggle to balance competing loss terms, particularly in stiff or ill-conditioned systems. In this work, we propose a PDE-aware optimizer that adapts parameter updates based on the variance of per-sample PDE residual gradients. This method addresses gradient misalignment without incurring the heavy computational costs of second-order optimizers such as SOAP. We benchmark the PDE-aware optimizer against Adam and SOAP on 1D Burgers', Allen-Cahn and Korteweg-de Vries(KdV) equations. Across both PDEs, the PDE-aware optimizer achieves smoother convergence and lower absolute errors, particularly in regions with sharp gradients. Our results demonstrate the effectiveness of PDE residual-aware adaptivity in enhancing stability in PINNs training. While promising, further scaling on larger architectures and hardware accelerators remains an important direction for future research.",
      "authors": [
        "Hardik Shukla",
        "Manurag Khullar",
        "Vismay Churiwala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:07:55+00:00",
          "link": "https://arxiv.org/abs/2507.08118v1",
          "size": "3065kb",
          "version": "v1"
        }
      ],
      "title": "PDE-aware Optimizer for Physics-informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08118",
        "HTML": "https://arxiv.org/html/2507.08118v1",
        "PDF": "https://arxiv.org/pdf/2507.08118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a PDE-aware optimizer for Physics-informed Neural Networks, focusing on optimization methods rather than processing or generating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08540",
      "abstract": "The proliferation of software vulnerabilities presents a significant challenge to cybersecurity, necessitating more effective detection methodologies. We introduce White-Basilisk, a novel approach to vulnerability detection that demonstrates superior performance while challenging prevailing assumptions in AI model scaling. Utilizing an innovative architecture that integrates Mamba layers, linear self-attention, and a Mixture of Experts framework, White-Basilisk achieves state-of-the-art results in vulnerability detection tasks with a parameter count of only 200M. The model's capacity to process sequences of unprecedented length enables comprehensive analysis of extensive codebases in a single pass, surpassing the context limitations of current Large Language Models (LLMs). White-Basilisk exhibits robust performance on imbalanced, real-world datasets, while maintaining computational efficiency that facilitates deployment across diverse organizational scales. This research not only establishes new benchmarks in code security but also provides empirical evidence that compact, efficiently designed models can outperform larger counterparts in specialized tasks, potentially redefining optimization strategies in AI development for domain-specific applications.",
      "authors": [
        "Ioannis Lamprou",
        "Alexander Shevtsov",
        "Ioannis Arapakis",
        "Sotiris Ioannidis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.08540v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08540",
        "HTML": "https://arxiv.org/html/2507.08540v1",
        "PDF": "https://arxiv.org/pdf/2507.08540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for code vulnerability detection, focusing on model architecture without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08581",
      "abstract": "Formally specifying, let alone verifying, properties of systems involving multiple programming languages is inherently challenging. We introduce Heterogeneous Dynamic Logic (HDL), a framework for combining reasoning principles from distinct (dynamic) program logics in a modular and compositional way. HDL mirrors the architecture of satisfiability modulo theories (SMT): Individual dynamic logics, along with their calculi, are treated as dynamic theories that can be flexibly combined to reason about heterogeneous systems whose components are verified using different program logics. HDL provides two key operations: Lifting extends an individual dynamic theory with new program constructs (e.g., the havoc operation or regular programs) and automatically augments its calculus with sound reasoning principles for the new constructs; and Combination enables cross-language reasoning in a single modality via Heterogeneous Dynamic Theories, facilitating the reuse of existing proof infrastructure. We formalize dynamic theories, their lifting and combination in Isabelle, and prove the soundness of all proof rules. We also prove relative completeness theorems for lifting and combination: Under common assumptions, reasoning about lifted or combined theories is no harder than reasoning about the constituent dynamic theories and their common first-order structure (i.e., the \"data theory\"). We demonstrate HDL's utility by verifying an automotive case study in which a Java controller (formalized in Java dynamic logic) steers a plant model (formalized in differential dynamic logic).",
      "authors": [
        "Samuel Teuber and Mattias Ulbrich and Andr\\'e Platzer and Bernhard Beckert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:26:53+00:00",
          "link": "https://arxiv.org/abs/2507.08581v1",
          "size": "127kb",
          "version": "v1"
        }
      ],
      "title": "Heterogeneous Dynamic Logic: Provability Modulo Program Theories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08581",
        "HTML": "https://arxiv.org/html/2507.08581v1",
        "PDF": "https://arxiv.org/pdf/2507.08581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for combining reasoning principles from distinct dynamic logics, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22511",
      "abstract": "The visible light reflectance data from geostationary satellites is crucial for meteorological observations and plays an important role in weather monitoring and forecasting. However, due to the lack of visible light at night, it is impossible to conduct continuous all-day weather observations using visible light reflectance data. This study pioneers the use of generative diffusion models to address this limitation. Based on the multi-band thermal infrared brightness temperature data from the Advanced Geostationary Radiation Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we developed a high-precision visible light reflectance generative model, called Reflectance Diffusion (RefDiff), which enables 0.47~\\mu\\mathrm{m}, 0.65~\\mu\\mathrm{m}, and 0.825~\\mu\\mathrm{m} bands visible light reflectance generation at night. Compared to the classical models, RefDiff not only significantly improves accuracy through ensemble averaging but also provides uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90, with particularly significant improvements in areas with complex cloud structures and thick clouds. The model's nighttime generation capability was validated using VIIRS nighttime product, demonstrating comparable performance to its daytime counterpart. In summary, this research has made substantial progress in the ability to generate visible light reflectance at night, with the potential to expand the application of nighttime visible light data.",
      "authors": [
        "Tingting Zhou",
        "Feng Zhang",
        "Haoyang Fu",
        "Baoxiang Pan",
        "Renhe Zhang",
        "Feng Lu",
        "Zhixin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T03:21:08+00:00",
          "link": "https://arxiv.org/abs/2506.22511v1",
          "size": "6359kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:03:06+00:00",
          "link": "https://arxiv.org/abs/2506.22511v2",
          "size": "6356kb",
          "version": "v2"
        }
      ],
      "title": "Lighting the Night with Generative Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22511",
        "PDF": "https://arxiv.org/pdf/2506.22511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study develops a generative model for visible light reflectance at night, using generative diffusion models. Although related to data generation techniques, it does not specifically address LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08746",
      "abstract": "We introduce the Partitioned Hybrid Quantum Fourier Neural Operator (PHQFNO), a generalization of the Quantum Fourier Neural Operator (QFNO) for scientific machine learning. PHQFNO partitions the Fourier operator computation across classical and quantum resources, enabling tunable quantum-classical hybridization and distributed execution across quantum and classical devices. The method extends QFNOs to higher dimensions and incorporates a message-passing framework to distribute data across different partitions. Input data are encoded into quantum states using unary encoding, and quantum circuit parameters are optimized using a variational scheme. We implement PHQFNO using PennyLane with PyTorch integration and evaluate it on Burgers' equation, incompressible and compressible Navier-Stokes equations. We show that PHQFNO recovers classical FNO accuracy. On incompressible Navier-Stokes, PHQFNO achieves higher accuracy than its classical counterparts. Finally, we perform a sensitivity analysis under input noise, confirming improved stability of PHQFNO over classical baselines.",
      "authors": [
        "Paolo Marcandelli",
        "Yuanchun He",
        "Stefano Mariani",
        "Martina Siena",
        "Stefano Markidis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.08746v1",
          "size": "2642kb",
          "version": "v1"
        }
      ],
      "title": "Partitioned Hybrid Quantum Fourier Neural Operators for Scientific Quantum Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08746",
        "PDF": "https://arxiv.org/pdf/2507.08746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a hybrid quantum-classical neural operator but focuses on scientific machine learning and the execution across quantum and classical devices, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.03538",
      "abstract": "With the advancement of vision-based autonomous driving technology, pedestrian detection have become an important component for improving traffic safety and driving system robustness. Nevertheless, in complex traffic scenarios, conventional pose estimation approaches frequently fail to accurately reconstruct occluded keypoints, primarily due to obstructions caused by vehicles, vegetation, or architectural elements. To address this issue, we propose a novel real-time occluded pedestrian pose completion framework termed Separation and Dimensionality Reduction-based Generative Adversarial Imputation Nets (SDR-GAIN). Unlike previous approaches that train visual models to distinguish occlusion patterns, SDR-GAIN aims to learn human pose directly from the numerical distribution of keypoint coordinates and interpolate missing positions. It employs a self-supervised adversarial learning paradigm to train lightweight generators with residual structures for the imputation of missing pose keypoints. Additionally, it integrates multiple pose standardization techniques to alleviate the difficulty of the learning process. Experiments conducted on the COCO and JAAD datasets demonstrate that SDR-GAIN surpasses conventional machine learning and Transformer-based missing data interpolation algorithms in accurately recovering occluded pedestrian keypoints, while simultaneously achieving microsecond-level real-time inference.",
      "authors": [
        "Honghao Fu",
        "Yongli Gu",
        "Yidong Yan",
        "Yilang Shen",
        "Yiwen Wu",
        "Libo Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-06T09:35:56+00:00",
          "link": "https://arxiv.org/abs/2306.03538v1",
          "size": "1534kb",
          "version": "v1"
        },
        {
          "date": "2023-06-10T15:31:04+00:00",
          "link": "https://arxiv.org/abs/2306.03538v2",
          "size": "1647kb",
          "version": "v2"
        },
        {
          "date": "2023-06-28T18:02:51+00:00",
          "link": "https://arxiv.org/abs/2306.03538v3",
          "size": "1660kb",
          "version": "v3"
        },
        {
          "date": "2023-08-25T07:34:42+00:00",
          "link": "https://arxiv.org/abs/2306.03538v4",
          "size": "1659kb",
          "version": "v4"
        },
        {
          "date": "2025-07-11T04:48:14+00:00",
          "link": "https://arxiv.org/abs/2306.03538v5",
          "size": "5042kb",
          "version": "v5"
        }
      ],
      "title": "SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.03538",
        "HTML": "https://arxiv.org/html/2306.03538v5",
        "PDF": "https://arxiv.org/pdf/2306.03538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pedestrian pose completion using a novel framework and does not contribute to processing of LLM training data."
      },
      "tasks": [
        "Autonomous Driving",
        "Dimensionality Reduction",
        "Imputation",
        "Pedestrian Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07656",
      "abstract": "End-to-end autonomous driving (E2E-AD) has emerged as a trend in the field of autonomous driving, promising a data-driven, scalable approach to system design. However, existing E2E-AD methods usually adopt the sequential paradigm of perception-prediction-planning, which leads to cumulative errors and training instability. The manual ordering of tasks also limits the system`s ability to leverage synergies between tasks (for example, planning-aware perception and game-theoretic interactive prediction and planning). Moreover, the dense BEV representation adopted by existing methods brings computational challenges for long-range perception and long-term temporal fusion. To address these challenges, we present DriveTransformer, a simplified E2E-AD framework for the ease of scaling up, characterized by three key features: Task Parallelism (All agent, map, and planning queries direct interact with each other at each block), Sparse Representation (Task queries direct interact with raw sensor features), and Streaming Processing (Task queries are stored and passed as history information). As a result, the new framework is composed of three unified operations: task self-attention, sensor cross-attention, temporal cross-attention, which significantly reduces the complexity of system and leads to better training stability. DriveTransformer achieves state-of-the-art performance in both simulated closed-loop benchmark Bench2Drive and real world open-loop benchmark nuScenes with high FPS.",
      "authors": [
        "Xiaosong Jia",
        "Junqi You",
        "Zhiyuan Zhang",
        "Junchi Yan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T11:41:18+00:00",
          "link": "https://arxiv.org/abs/2503.07656v1",
          "size": "5728kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T08:15:30+00:00",
          "link": "https://arxiv.org/abs/2503.07656v2",
          "size": "5316kb",
          "version": "v2"
        }
      ],
      "title": "DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07656",
        "HTML": "https://arxiv.org/html/2503.07656v2",
        "PDF": "https://arxiv.org/pdf/2503.07656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a unified transformer framework for end-to-end autonomous driving, emphasizing model architecture improvements rather than LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Bench2Drive"
      ],
      "repo_urls": [
        "https://github.com/thinklab-sjtu/drivetransformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08480",
      "abstract": "With the increasing utilization of multilingual text information, Cross-Lingual Information Retrieval (CLIR) has become a crucial research area. However, the impact of training data composition on both CLIR and Mono-Lingual Information Retrieval (IR) performance remains under-explored. To systematically investigate this data-centric aspect, we construct linguistically parallel Korean-English datasets and train retrieval models with various language combinations. Our experiments reveal that the language composition of training data significantly influences IR performance, exhibiting important inter-lingual correlations: CLIR performance improves with specific language pairs, while Mono-Lingual IR performance declines. Our work demonstrates that Model Merging can effectively mitigate this trade-off, achieving strong CLIR results while preserving Mono-Lingual IR capabilities. Our findings underscore the effects of linguistic configuration of training data on both CLIR and Mono-Lingual IR, and present Model Merging as a viable strategy to optimize performance across these tasks.",
      "authors": [
        "Youngjoon Jang",
        "Junyoung Son",
        "Taemin Lee",
        "Seongtae Hong",
        "Heuiseok Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:44:09+00:00",
          "link": "https://arxiv.org/abs/2507.08480v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "Improving Korean-English Cross-Lingual Retrieval: A Data-Centric Study of Language Composition and Model Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08480",
        "HTML": "https://arxiv.org/html/2507.08480v1",
        "PDF": "https://arxiv.org/pdf/2507.08480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines how training data composition affects cross-lingual retrieval performance but does not focus on LLM-specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.13384",
      "abstract": "Object-oriented programming (OOP) is one of the most popular paradigms used for building software systems. However, despite its industrial and academic popularity, OOP is still missing a formal apparatus similar to $\\lambda$-calculus, which functional programming is based on. There were a number of attempts to formalize OOP, but none of them managed to cover all the features available in modern OO programming languages, such as C++ or Java. We have made yet another attempt and created $\\varphi$-calculus. We also created EOLANG (also called EO), an experimental programming language based on $\\varphi$-calculus.",
      "authors": [
        "Yegor Bugayenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-26T09:42:45+00:00",
          "link": "https://arxiv.org/abs/2111.13384v1",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "2022-01-05T05:51:13+00:00",
          "link": "https://arxiv.org/abs/2111.13384v2",
          "size": "64kb",
          "version": "v2"
        },
        {
          "date": "2022-06-09T14:11:10+00:00",
          "link": "https://arxiv.org/abs/2111.13384v3",
          "size": "74kb",
          "version": "v3"
        },
        {
          "date": "2022-08-01T18:02:09+00:00",
          "link": "https://arxiv.org/abs/2111.13384v4",
          "size": "83kb",
          "version": "v4"
        },
        {
          "date": "2024-03-01T10:41:48+00:00",
          "link": "https://arxiv.org/abs/2111.13384v5",
          "size": "73kb",
          "version": "v5"
        },
        {
          "date": "2025-07-11T05:00:58+00:00",
          "link": "https://arxiv.org/abs/2111.13384v6",
          "size": "102kb",
          "version": "v6"
        }
      ],
      "title": "EOLANG and $\\varphi$-calculus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.13384",
        "PDF": "https://arxiv.org/pdf/2111.13384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes $\\varphi$-calculus for object-oriented programming and a new language called EOLANG, neither of which relate to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/cqfn/eo",
        "https://github.com/objectionary/eo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2205.09622",
      "abstract": "A growing body of literature in fairness-aware machine learning (fairML) aims to mitigate machine learning (ML)-related unfairness in automated decision-making (ADM) by defining metrics that measure fairness of an ML model and by proposing methods to ensure that trained ML models achieve low scores on these metrics. However, the underlying concept of fairness, i.e., the question of what fairness is, is rarely discussed, leaving a significant gap between centuries of philosophical discussion and the recent adoption of the concept in the ML community. In this work, we try to bridge this gap by formalizing a consistent concept of fairness and by translating the philosophical considerations into a formal framework for the training and evaluation of ML models in ADM systems. We argue that fairness problems can arise even without the presence of protected attributes (PAs), and point out that fairness and predictive performance are not irreconcilable opposites, but that the latter is necessary to achieve the former. Furthermore, we argue why and how causal considerations are necessary when assessing fairness in the presence of PAs by proposing a fictitious, normatively desired (FiND) world in which PAs have no causal effects. In practice, this FiND world must be approximated by a warped world in which the causal effects of the PAs are removed from the real-world data. Finally, we achieve greater linguistic clarity in the discussion of fairML. We outline algorithms for practical applications and present illustrative experiments on COMPAS data.",
      "authors": [
        "Ludwig Bothmann",
        "Kristina Peters",
        "Bernd Bischl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-19T15:37:26+00:00",
          "link": "https://arxiv.org/abs/2205.09622v1",
          "size": "396kb",
          "version": "v1"
        },
        {
          "date": "2023-01-30T09:34:39+00:00",
          "link": "https://arxiv.org/abs/2205.09622v2",
          "size": "403kb",
          "version": "v2"
        },
        {
          "date": "2023-05-08T08:16:58+00:00",
          "link": "https://arxiv.org/abs/2205.09622v3",
          "size": "448kb",
          "version": "v3"
        },
        {
          "date": "2024-01-31T09:51:15+00:00",
          "link": "https://arxiv.org/abs/2205.09622v4",
          "size": "496kb",
          "version": "v4"
        },
        {
          "date": "2024-06-03T08:02:04+00:00",
          "link": "https://arxiv.org/abs/2205.09622v5",
          "size": "344kb",
          "version": "v5"
        },
        {
          "date": "2024-11-29T16:01:31+00:00",
          "link": "https://arxiv.org/abs/2205.09622v6",
          "size": "366kb",
          "version": "v6"
        }
      ],
      "title": "What Is Fairness? On the Role of Protected Attributes and Fictitious Worlds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.09622",
        "HTML": "https://arxiv.org/html/2205.09622",
        "PDF": "https://arxiv.org/pdf/2205.09622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with fairness-aware ML in automated decision-making, focusing on philosophical concepts, not LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08659",
      "abstract": "Prolonged sitting is a health risk leading to metabolic and cardiovascular diseases. To combat this, various \"nudging\" strategies encourage stand-ups. Behavior change triggers use explicit prompts such as smartphone push notifications or light controls. However, comparisons of the effects of such interactions, discomfort, and user context have not yet been performed. The present study evaluated these methods in a mixed design experiment with 15 college students. Three intervention methods (none, push notifications, and light dimming) and three user task contexts (computer work, video calls, and reading) were tested. The frequency of standing up and comfort were assessed after each ten-minute session. Results showed that dimming resulted in slightly more breaks (1.4 \\pm 1.55) than push notification (1.2 \\pm 1.08), but caused discomfort for 66.7% of participants, compared to 20% for notification. The results were influenced by task context. Dimming was most effective during video calls and reading, while push notifications were more effective during computer work. These findings suggest adaptive nudging systems should tailor interventions based on context and individual preferences.",
      "authors": [
        "Sohshi Yoshida and Ko Watanabe and Andreas Dengel and Shoya Ishimaru and Shingo Ata and Manato Fujimoto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:00:23+00:00",
          "link": "https://arxiv.org/abs/2507.08659v1",
          "size": "7751kb",
          "version": "v1"
        }
      ],
      "title": "Push or Light: Nudging Standing to Break Prolonged Sitting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08659",
        "HTML": "https://arxiv.org/html/2507.08659v1",
        "PDF": "https://arxiv.org/pdf/2507.08659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates nudging strategies to encourage behavior change to reduce sitting time, which does not involve processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08765",
      "abstract": "Due to the excellent performance in yielding high-quality, zero-shot segmentation, Segment Anything Model (SAM) and its variants have been widely applied in diverse scenarios such as healthcare and intelligent manufacturing. Therefore, effectively compressing SAMs has become an increasingly pressing practical need. In this study, we propose Birkhoff, a novel data-free compression algorithm for SAM and its variants. Unlike quantization, pruning, distillation, and other compression methods, Birkhoff embodies versatility across model types, agility in deployment, faithfulness to the original model, and compactness in model size. Specifically, Birkhoff introduces a novel compression algorithm: Hyper-Compression, whose core principle is to find a dense trajectory to turn a high-dimensional parameter vector into a low-dimensional scalar. Furthermore, Birkhoff designs a dedicated linear layer operator, HyperLinear, to fuse decompression and matrix multiplication to significantly accelerate inference of the compressed SAMs. Extensive experiments on 18 SAMs in the COCO, LVIS, and SA-1B datasets show that Birkhoff performs consistently and competitively in compression time, compression ratio, post-compression performance, and inference speed. For example, Birkhoff can achieve a compression ratio of 5.17x on SAM2-B, with less than 1% performance drop without using any fine-tuning data. Moreover, the compression is finished within 60 seconds for all models.",
      "authors": [
        "Juntong Fan",
        "Zhiwei Hao",
        "Jianqiang Shen",
        "Shang-Ling Jui",
        "Yi Zhang",
        "Jing-Xiao Liao",
        "Feng-Lei Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:21:06+00:00",
          "link": "https://arxiv.org/abs/2507.08765v1",
          "size": "6179kb",
          "version": "v1"
        }
      ],
      "title": "Compress Any Segment Anything Model (SAM)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08765",
        "HTML": "https://arxiv.org/html/2507.08765v1",
        "PDF": "https://arxiv.org/pdf/2507.08765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on compressing Segment Anything Models (SAMs) and does not discuss the processing of LLM training data or data engineering operations related to LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2001.03976",
      "abstract": "Given that approximate quantum error-correcting (AQEC) codes have a potentially better performance than perfect quantum error correction codes, it is pertinent to quantify their performance. While quantum weight enumerators establish some of the best upper bounds on the minimum distance of quantum error-correcting codes, these bounds do not directly apply to AQEC codes. Herein, we introduce quantum weight enumerators for amplitude damping (AD) errors and work within the framework of approximate quantum error correction. In particular, we introduce an auxiliary exact weight enumerator that is intrinsic to a code space and moreover, we establish a linear relationship between the quantum weight enumerators for AD errors and this auxiliary exact weight enumerator. This allows us to establish a linear program that is infeasible only when AQEC AD codes with corresponding parameters do not exist. To illustrate our linear program, we numerically rule out the existence of three-qubit AD codes that are capable of correcting an arbitrary AD error.",
      "authors": [
        "Yingkai Ouyang and Ching-Yi Lai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2020-01-12T18:46:59+00:00",
          "link": "https://arxiv.org/abs/2001.03976v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Linear programming bounds for quantum amplitude damping codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2001.03976",
        "PDF": "https://arxiv.org/pdf/2001.03976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on quantum error-correcting codes and linear programming bounds, which do not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08434",
      "abstract": "Radiance field methods, such as Neural Radiance Field or 3D Gaussian Splatting, have emerged as seminal 3D representations for synthesizing realistic novel views. For practical applications, there is ongoing research on flexible scene editing techniques, among which object removal is a representative task. However, removing objects exposes occluded regions, often leading to unnatural appearances. Thus, studies have employed image inpainting techniques to replace such regions with plausible content - a task referred to as 3D scene inpainting. However, image inpainting methods produce one of many plausible completions for each view, leading to inconsistencies between viewpoints. A widely adopted approach leverages perceptual cues to blend inpainted views smoothly. However, it is prone to detail loss and can fail when there are perceptual inconsistencies across views. In this paper, we propose a novel 3D scene inpainting method that reliably produces realistic and perceptually consistent results even for complex scenes by leveraging a reference view. Given the inpainted reference view, we estimate the inpainting similarity of the other views to adjust their contribution in constructing an accurate geometry tailored to the reference. This geometry is then used to warp the reference inpainting to other views as pseudo-ground truth, guiding the optimization to match the reference appearance. Comparative evaluation studies have shown that our approach improves both the geometric fidelity and appearance consistency of inpainted scenes.",
      "authors": [
        "Ji Hyun Seo",
        "Byounhyun Yoo",
        "Gerard Jounghyun Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:26:07+00:00",
          "link": "https://arxiv.org/abs/2507.08434v1",
          "size": "47247kb",
          "version": "v1"
        }
      ],
      "title": "RePaintGS: Reference-Guided Gaussian Splatting for Realistic and View-Consistent 3D Scene Inpainting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08434",
        "HTML": "https://arxiv.org/html/2507.08434v1",
        "PDF": "https://arxiv.org/pdf/2507.08434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Discusses 3D scene inpainting techniques for realistic view synthesis, which does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08458",
      "abstract": "Many document types use intrinsic, convention-driven structures that serve to encode precise and structured information, such as the conventions governing engineering drawings. However, state-of-the-art approaches treat document recognition as a mere computer vision problem, neglecting these underlying document-type-specific structural properties, making them dependent on sub-optimal heuristic post-processing and rendering many less frequent or more complicated document types inaccessible to modern document recognition. We suggest a novel perspective that frames document recognition as a transcription task from a document to a record. This implies a natural grouping of documents based on the intrinsic structure inherent in their transcription, where related document types can be treated (and learned) similarly. We propose a method to design structure-specific inductive biases for the underlying machine-learned end-to-end document recognition systems, and a respective base transformer architecture that we successfully adapt to different structures. We demonstrate the effectiveness of the so-found inductive biases in extensive experiments with progressively complex record structures from monophonic sheet music, shape drawings, and simplified engineering drawings. By integrating an inductive bias for unrestricted graph structures, we train the first-ever successful end-to-end model to transcribe engineering drawings to their inherently interlinked information. Our approach is relevant to inform the design of document recognition systems for document types that are less well understood than standard OCR, OMR, etc., and serves as a guide to unify the design of future document foundation models.",
      "authors": [
        "Benjamin Meyer",
        "Lukas Tuggener",
        "Sascha H\\\"anzi",
        "Daniel Schmid",
        "Erdal Ayfer",
        "Benjamin F. Grewe",
        "Ahmed Abdulkadir",
        "Thilo Stadelmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:02:08+00:00",
          "link": "https://arxiv.org/abs/2507.08458v1",
          "size": "2310kb",
          "version": "v1"
        }
      ],
      "title": "A document is worth a structured record: Principled inductive bias design for document recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08458",
        "HTML": "https://arxiv.org/html/2507.08458v1",
        "PDF": "https://arxiv.org/pdf/2507.08458"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper involves transcribing documents into structured records, suggesting novel inductive biases for machine learning systems. It outlines methods to design and learn from these structures, contributing significantly to data processing for end-to-end document recognition."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.07111",
      "abstract": "In this paper, we explore the application of semidefinite programming to the realm of quantum codes, specifically focusing on codeword stabilized (CWS) codes with entanglement assistance. Notably, we utilize the isotropic subgroup of the CWS group and the set of word operators of a CWS-type quantum code to derive an upper bound on the minimum distance. Furthermore, this characterization can be incorporated into the associated distance enumerators, enabling us to construct semidefinite constraints that lead to SDP bounds on the minimum distance or size of CWS-type quantum codes. We illustrate several instances where SDP bounds outperform LP bounds, and there are even cases where LP fails to yield meaningful results, while SDP consistently provides tighter and relevant bounds. Finally, we also provide interpretations of the Shor-Laflamme weight enumerators and shadow enumerators for codeword stabilized codes, enhancing our understanding of quantum codes.",
      "authors": [
        "Ching-Yi Lai and Pin-Chieh Tseng and Wei-Hsuan Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-13T07:01:58+00:00",
          "link": "https://arxiv.org/abs/2311.07111v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2024-08-02T14:49:32+00:00",
          "link": "https://arxiv.org/abs/2311.07111v2",
          "size": "28kb",
          "version": "v2"
        }
      ],
      "title": "Semidefinite programming bounds on the size of entanglement-assisted codeword stabilized quantum codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.07111",
        "HTML": "https://arxiv.org/html/2311.07111",
        "PDF": "https://arxiv.org/pdf/2311.07111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on using semidefinite programming for quantum codes and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.01163",
      "abstract": "Prompt optimization aims to search for effective prompts that enhance the performance of large language models (LLMs). Although existing prompt optimization methods have discovered effective prompts, they often differ from sophisticated prompts carefully designed by human experts. Prompt design strategies, representing best practices for improving prompt performance, can be key to improving prompt optimization. Recently, a method termed the Autonomous Prompt Engineering Toolbox (APET) has incorporated various prompt design strategies into the prompt optimization process. In APET, the LLM is needed to implicitly select and apply the appropriate strategies because prompt design strategies can have negative effects. This implicit selection may be suboptimal due to the limited optimization capabilities of LLMs. This paper introduces Optimizing Prompts with sTrategy Selection (OPTS), which implements explicit selection mechanisms for prompt design. We propose three mechanisms, including a Thompson sampling-based approach, and integrate them into EvoPrompt, a well-known prompt optimizer. Experiments optimizing prompts for two LLMs, Llama-3-8B-Instruct and GPT-4o mini, were conducted using BIG-Bench Hard. Our results show that the selection of prompt design strategies improves the performance of EvoPrompt, and the Thompson sampling-based mechanism achieves the best overall results. Our experimental code is provided at https://github.com/shiralab/OPTS .",
      "authors": [
        "Rin Ashizawa",
        "Yoichi Hirose",
        "Nozomu Yoshinari",
        "Kento Uchida",
        "Shinichi Shirakawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T04:24:04+00:00",
          "link": "https://arxiv.org/abs/2503.01163v1",
          "size": "130kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:56:05+00:00",
          "link": "https://arxiv.org/abs/2503.01163v2",
          "size": "93kb",
          "version": "v2"
        }
      ],
      "title": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01163",
        "HTML": "https://arxiv.org/html/2503.01163v2",
        "PDF": "https://arxiv.org/pdf/2503.01163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a method for optimizing prompts by selecting prompt design strategies to improve LLM performance, which includes processing strategies directly related to LLM training data."
      },
      "tasks": [
        "Prompt Engineering",
        "Thompson Sampling"
      ],
      "repo_urls": [
        "https://github.com/shiralab/opts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21940",
      "abstract": "We present a novel meta learning framework called Sculpture that explicitly conditions the Fubini Study metric tensor of parameterized quantum circuits to mitigate barren plateaus in variational quantum algorithms. Our theoretical analysis identifies the logarithmic condition number of the Fubini Study metric as a critical geometric quantity governing trainability, optimization dynamics, and generalization. Sculpture uses a classical meta model trained to generate data dependent quantum circuit initializations that minimize the logarithmic condition number, thereby promoting an isotropic and well conditioned parameter space.\n  Empirical results show that meta training reduces the logarithmic condition number from approximately 1.47 to 0.64 by significantly increasing the minimum eigenvalue and slightly decreasing the maximum eigenvalue of the metric, effectively alleviating barren plateaus. This improved conditioning generalizes well to unseen data, consistently producing well conditioned quantum circuit initializations. In a downstream hybrid quantum classical classification task on the Kaggle diabetes dataset, increasing the meta scaling coefficient accelerates convergence, reduces training loss and gradient norms, and crucially improves generalization, with test accuracy increasing from about 0.68 to over 0.78. These findings demonstrate that sculpting the quantum landscape via meta learning serves as a principled geometric regularizer, substantially enhancing trainability, optimization, and generalization of parameterized quantum circuits and enabling more robust and efficient variational quantum algorithms.",
      "authors": [
        "Marwan Ait Haddou and Mohamed Bennai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:30:33+00:00",
          "link": "https://arxiv.org/abs/2506.21940v1",
          "size": "300kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T16:53:45+00:00",
          "link": "https://arxiv.org/abs/2506.21940v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T10:21:05+00:00",
          "link": "https://arxiv.org/abs/2506.21940v3",
          "size": "378kb",
          "version": "v3"
        }
      ],
      "title": "Sculpting Quantum Landscapes: Fubini-Study Metric Conditioning for Geometry Aware Learning in Parameterized Quantum Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21940",
        "HTML": "https://arxiv.org/html/2506.21940v3",
        "PDF": "https://arxiv.org/pdf/2506.21940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a meta learning framework for parameterized quantum circuits to mitigate barren plateaus, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08059",
      "abstract": "The remarkable results for denoising in computer vision using diffusion models given in \\cite{SDWMG,HJA,HHG} yield a robust mathematical justification for algorithms based on crucial properties of a sequence of Gaussian independent $N(0,1)$ random variables. In particular the derivations use the fact that a Gaussian distribution is determined by its mean and variance and that the sum of two Gaussians is another Gaussian.\n  \\bigskip\n  The issue raised in this short note is the following: suppose we use the algorithm without any changes but replace the nature of the noise and use, for instance, uniformly distributed noise or noise with a Beta distribution, or noise which is a random superposition of two Gaussians with very different variances. One could, of course, try to modify the algorithm keeping in mind the nature of the noise, but this is not what we do. Instead we study the performance of the algorithm when used with noise that is very far in nature from the Gaussian case, where it is designed to work well.\n  Usually these algorithms are implemented on very powerful computers. Our experiments are all carried out on a small laptop and for the smallest possible image size. Exploring how our observations are confirmed or changed when dealing in different situations remains an interesting challenge.",
      "authors": [
        "F. Alberto Gr\\\"unbaum and Tondgi Xu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:51:39+00:00",
          "link": "https://arxiv.org/abs/2507.08059v1",
          "size": "5kb",
          "version": "v1"
        }
      ],
      "title": "The relative importance of being Gaussian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08059",
        "HTML": "https://arxiv.org/html/2507.08059v1",
        "PDF": "https://arxiv.org/pdf/2507.08059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This note explores the performance of existing denoising algorithms with different noise types. It does not discuss LLM training data processing or involve engineering operations for improving LLM training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08108",
      "abstract": "\\textit{Mallows model} is a widely-used probabilistic framework for learning from ranking data, with applications ranging from recommendation systems and voting to aligning language models with human preferences~\\cite{chen2024mallows, kleinberg2021algorithmic, rafailov2024direct}. Under this model, observed rankings are noisy perturbations of a central ranking $\\sigma$, with likelihood decaying exponentially in distance from $\\sigma$, i.e, $P (\\pi) \\propto \\exp\\big(-\\beta \\cdot d(\\pi, \\sigma)\\big),$ where $\\beta > 0$ controls dispersion and $d$ is a distance function.\n  Existing methods mainly focus on fixed distances (such as Kendall's $\\tau$ distance), with no principled approach to learning the distance metric directly from data. In practice, however, rankings naturally vary by context; for instance, in some sports we regularly see long-range swaps (a low-rank team beating a high-rank one), while in others such events are rare. Motivated by this, we propose a generalization of Mallows model that learns the distance metric directly from data. Specifically, we focus on $L_\\alpha$ distances: $d_\\alpha(\\pi,\\sigma):=\\sum_{i=1} |\\pi(i)-\\sigma(i)|^\\alpha$.\n  For any $\\alpha\\geq 1$ and $\\beta>0$, we develop a Fully Polynomial-Time Approximation Scheme (FPTAS) to efficiently generate samples that are $\\epsilon$- close (in total variation distance) to the true distribution. Even in the special cases of $L_1$ and $L_2$, this generalizes prior results that required vanishing dispersion ($\\beta\\to0$). Using this sampling algorithm, we propose an efficient Maximum Likelihood Estimation (MLE) algorithm that jointly estimates the central ranking, the dispersion parameter, and the optimal distance metric. We prove strong consistency results for our estimators (for any values of $\\alpha$ and $\\beta$), and we validate our approach empirically using datasets from sports rankings.",
      "authors": [
        "Yeganeh Alimohammadi",
        "Kiana Asgari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:52:09+00:00",
          "link": "https://arxiv.org/abs/2507.08108v1",
          "size": "706kb",
          "version": "v1"
        }
      ],
      "title": "Mallows Model with Learned Distance Metrics: Sampling and Maximum Likelihood Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08108",
        "HTML": "https://arxiv.org/html/2507.08108v1",
        "PDF": "https://arxiv.org/pdf/2507.08108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on probabilistic modeling and ranking data, specifically adapting the Mallows model with learned distance metrics, which does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08236",
      "abstract": "The BirdCLEF+ 2025 challenge requires classifying 206 species, including birds, mammals, insects, and amphibians, from soundscape recordings under a strict 90-minute CPU-only inference deadline, making many state-of-the-art deep learning approaches impractical. To address this constraint, the DS@GT BirdCLEF team explored two strategies. First, we establish competitive baselines by optimizing pre-trained models from the Bioacoustics Model Zoo for CPU inference. Using TFLite, we achieved a nearly 10x inference speedup for the Perch model, enabling it to run in approximately 16 minutes and achieve a final ROC-AUC score of 0.729 on the public leaderboard post-competition and 0.711 on the private leaderboard. The best model from the zoo was BirdSetEfficientNetB1, with a public score of 0.810 and a private score of 0.778. Second, we introduce a novel, lightweight pipeline named Spectrogram Token Skip-Gram (STSG) that treats bioacoustics as a sequence modeling task. This method converts audio into discrete \"spectrogram tokens\" by clustering Mel-spectrograms using Faiss K-means and then learns high-quality contextual embeddings for these tokens in an unsupervised manner with a Word2Vec skip-gram model. For classification, embeddings within a 5-second window are averaged and passed to a linear model. With a projected inference time of 6 minutes for a 700-minute test set, the STSG approach achieved a final ROC-AUC public score of 0.559 and a private score of 0.520, demonstrating the viability of fast tokenization approaches with static embeddings for bioacoustic classification. Supporting code for this paper can be found at https://github.com/dsgt-arc/birdclef-2025.",
      "authors": [
        "Anthony Miyaguchi",
        "Murilo Gustineli",
        "and Adrian Cheung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:47:08+00:00",
          "link": "https://arxiv.org/abs/2507.08236v1",
          "size": "7852kb",
          "version": "v1"
        }
      ],
      "title": "Distilling Spectrograms into Tokens: Fast and Lightweight Bioacoustic Classification for BirdCLEF+ 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08236",
        "HTML": "https://arxiv.org/html/2507.08236v1",
        "PDF": "https://arxiv.org/pdf/2507.08236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about bioacoustic classification and optimization for inference speed using audio data tokenization, with no focus on LLM training data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08523",
      "abstract": "Modern software systems generate massive volumes of runtime logs, necessitating efficient and accurate log parsing to enable critical downstream tasks such as anomaly detection and root cause analysis. Recently, large language models (LLMs) have achieved advanced accuracy on log parsing, but their deployment in production environments faces two major limitations: (1) the privacy risks associated with commercial LLMs, driving the adoption of local deployment, and (2) the stringent latency and throughput requirements imposed by high-volume log streams, which existing LLM-based parsers fail to meet. Although recent efforts have reduced the number of LLM queries, they overlook the high latency of the LLM invocations, where concurrent log parsing requests can cause serve performance degradation of LLM inference system.\n  In this study, we present InferLog, the first LLM inference optimization method for online log parsing. Our key insight is that the inference efficiency emerges as the vital bottleneck in LLM-based online log parsing, rather than parsing accuracy. InferLog accelerates inference by designing (1) A Prefix-aware ICL Refinement policy to refine the examples and permutation of in-context learning to improve the prefix caching efficiency. (2) A rapid and task-specific configuration tuning pipeline based on meta-learning to find the optimal LLM scheduling-related configuration for dynamic log parsing workloads. The experimental results based on Loghub dataset and vLLM demonstrate that InferLog significantly outperforms existing inference optimization methods and markedly accelerates the state-of-the-art LLM-based log parser without compromising parsing accuracy.",
      "authors": [
        "Yilun Wang and Pengfei Chen and Haiyu Huang and Zilong He and Gou Tan and Chuanfu Zhang and Jingkai He and Zibin Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:21:29+00:00",
          "link": "https://arxiv.org/abs/2507.08523v1",
          "size": "1235kb",
          "version": "v1"
        }
      ],
      "title": "InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08523",
        "HTML": "https://arxiv.org/html/2507.08523v1",
        "PDF": "https://arxiv.org/pdf/2507.08523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses optimizing LLM inference for log parsing, it does not focus on training data processing. It mentions configuration tuning and caching efficiencies but not substantive data processing improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12822",
      "abstract": "Gradually typed programming languages, which allow for soundly mixing static and dynamically typed programming styles, present a strong challenge for metatheorists. Even the simplest sound gradually typed languages feature at least recursion and errors, with realistic languages featuring furthermore runtime allocation of memory locations and dynamic type tags. Further, the desired metatheoretic properties of gradually typed languages have become increasingly sophisticated: validity of type-based equational reasoning as well as the relational property known as graduality. Many recent works have tackled verifying these properties, but the resulting mathematical developments are highly repetitive and tedious, with few reusable theorems persisting across different developments.\n  In this work, we present a new denotational semantics for gradual typing developed using guarded domain theory. Guarded domain theory combines the generality of step-indexed logical relations for modeling advanced programming features with the modularity and reusability of denotational semantics. We demonstrate the feasibility of this approach with a model of a simple gradually typed lambda calculus and prove the validity of beta-eta equality and the graduality theorem for the denotational model. This model should provide the basis for a reusable mathematical theory of gradually typed program semantics. Finally, we have mechanized most of the core theorems of our development in Guarded Cubical Agda, a recent extension of Agda with support for the guarded recursive constructions we use.",
      "authors": [
        "Eric Giovannini",
        "Tingting Ding",
        "Max S. New"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-19T19:18:31+00:00",
          "link": "https://arxiv.org/abs/2411.12822v1",
          "size": "182kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T22:01:07+00:00",
          "link": "https://arxiv.org/abs/2411.12822v2",
          "size": "107kb",
          "version": "v2"
        }
      ],
      "title": "Denotational Semantics of Gradual Typing using Synthetic Guarded Domain Theory (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12822",
        "PDF": "https://arxiv.org/pdf/2411.12822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the denotational semantics of gradual typing using synthetic guarded domain theory, which does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.11868",
      "abstract": "Accurately analyzing the motion parts and their motion attributes in dynamic environments is crucial for advancing key areas such as embodied intelligence. Addressing the limitations of existing methods that rely on dense multi-view images or detailed part-level annotations, we propose an innovative framework that can analyze 3D mobility from monocular videos in a zero-shot manner. This framework can precisely parse motion parts and motion attributes only using a monocular video, completely eliminating the need for annotated training data. Specifically, our method first constructs the scene geometry and roughly analyzes the motion parts and their initial motion attributes combining depth estimation, optical flow analysis and point cloud registration method, then employs 2D Gaussian splatting for scene representation. Building on this, we introduce an end-to-end dynamic scene optimization algorithm specifically designed for articulated objects, refining the initial analysis results to ensure the system can handle 'rotation', 'translation', and even complex movements ('rotation+translation'), demonstrating high flexibility and versatility. To validate the robustness and wide applicability of our method, we created a comprehensive dataset comprising both simulated and real-world scenarios. Experimental results show that our framework can effectively analyze articulated object motions in an annotation-free manner, showcasing its significant potential in future embodied intelligence applications.",
      "authors": [
        "Hongyi Zhou",
        "Yulan Guo",
        "Xiaogang Wang",
        "Kai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-17T06:21:05+00:00",
          "link": "https://arxiv.org/abs/2505.11868v1",
          "size": "6748kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T15:40:28+00:00",
          "link": "https://arxiv.org/abs/2505.11868v2",
          "size": "6746kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T13:35:00+00:00",
          "link": "https://arxiv.org/abs/2505.11868v3",
          "size": "6750kb",
          "version": "v3"
        }
      ],
      "title": "MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11868",
        "HTML": "https://arxiv.org/html/2505.11868v3",
        "PDF": "https://arxiv.org/pdf/2505.11868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for zero-shot 3D mobility analysis using monocular videos without annotated training data but does not focus on LLM training data processing or dataset creation."
      },
      "tasks": [
        "Depth Estimation",
        "Optical Flow Estimation",
        "Point Cloud Registration",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.24360",
      "abstract": "Sparse autoencoders are a promising new approach for decomposing language model activations for interpretation and control. They have been applied successfully to vision transformer image encoders and to small-scale diffusion models. Inference-Time Decomposition of Activations (ITDA) is a recently proposed variant of dictionary learning that takes the dictionary to be a set of data points from the activation distribution and reconstructs them with gradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large text-to-image diffusion model, Flux 1, and consider the interpretability of embeddings of both by introducing a visual automated interpretation pipeline. We find that SAEs accurately reconstruct residual stream embeddings and beat MLP neurons on interpretability. We are able to use SAE features to steer image generation through activation addition. We find that ITDA has comparable interpretability to SAEs.",
      "authors": [
        "Stepan Shabalin",
        "Ayush Panda",
        "Dmitrii Kharlapenko",
        "Abdur Raheem Ali",
        "Yixiong Hao",
        "Arthur Conmy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T08:53:27+00:00",
          "link": "https://arxiv.org/abs/2505.24360v1",
          "size": "9554kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T02:01:33+00:00",
          "link": "https://arxiv.org/abs/2505.24360v2",
          "size": "9555kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T23:59:56+00:00",
          "link": "https://arxiv.org/abs/2505.24360v3",
          "size": "9555kb",
          "version": "v3"
        }
      ],
      "title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24360",
        "PDF": "https://arxiv.org/pdf/2505.24360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although it mentions text-to-image diffusion models, the paper is centered on interpreting model activations, not on processing or creating LLM training data."
      },
      "tasks": [
        "Dictionary Learning",
        "Image Generation",
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/kisate/flux-saes-gpu"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08001",
      "abstract": "With the advancement of science and technology, the philosophy of creativity has undergone significant reinterpretation. This paper investigates contemporary research in the fields of psychology, cognitive neuroscience, and the philosophy of creativity, particularly in the context of the development of artificial intelligence (AI) techniques. It aims to address the central question: Can AI exhibit creativity? The paper reviews the historical perspectives on the philosophy of creativity and explores the influence of psychological advancements on the study of creativity. Furthermore, it analyzes various definitions of creativity and examines the responses of naturalism and cognitive neuroscience to the concept of creativity.",
      "authors": [
        "Shengyi Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T17:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.08001v1",
          "size": "326kb",
          "version": "v1"
        }
      ],
      "title": "Human Creativity and AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08001",
        "PDF": "https://arxiv.org/pdf/2507.08001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the philosophy and psychology of creativity in AI but does not focus on or discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08288",
      "abstract": "Watermarking technology has gained significant attention due to the increasing importance of intellectual property (IP) rights, particularly with the growing deployment of large language models (LLMs) on billions resource-constrained edge devices. To counter the potential threats of IP theft by malicious users, this paper introduces a robust watermarking scheme without retraining or fine-tuning for transformer models. The scheme generates a unique key for each user and derives a stable watermark value by solving linear constraints constructed from model invariants. Moreover, this technology utilizes noise mechanism to hide watermark locations in multi-user scenarios against collusion attack. This paper evaluates the approach on three popular models (Llama3, Phi3, Gemma), and the experimental results confirm the strong robustness across a range of attack methods (fine-tuning, pruning, quantization, permutation, scaling, reversible matrix and collusion attacks).",
      "authors": [
        "Qingxiao Guo",
        "Xinjie Zhu",
        "Yilong Ma",
        "Hui Jin",
        "Yunhao Wang",
        "Weifeng Zhang",
        "Xiaobing Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:24:47+00:00",
          "link": "https://arxiv.org/abs/2507.08288v1",
          "size": "1331kb",
          "version": "v1"
        }
      ],
      "title": "Invariant-based Robust Weights Watermark for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08288",
        "HTML": "https://arxiv.org/html/2507.08288v1",
        "PDF": "https://arxiv.org/pdf/2507.08288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on watermarking LLMs for IP protection, not on the processing or improvement of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08752",
      "abstract": "We investigate the propagation of initial value perturbations along the solution of a linear ODE \\( y'(t) = Ay(t) \\). This propagation is analized using the relative error rather than the absolute error. Our focus is on the long-term behavior of this relative error, which differs significantly from that of the absolute error. Understanding this long-term behavior provides insights into the growth of the relative error over all times, not just at large times. Therefore, it represents a crucial and fundamental aspect of the conditioning of linear ODEs, with applications in, for example, non-normal dynamics. The author hopes that this paper will stimulate attention to the role of relative error in dynamic contexts.",
      "authors": [
        "Stefano Maset"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:05:01+00:00",
          "link": "https://arxiv.org/abs/2507.08752v1",
          "size": "1999kb",
          "version": "v1"
        }
      ],
      "title": "Long-time relative error analysis for linear ODEs with perturbed initial value",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08752",
        "HTML": "https://arxiv.org/html/2507.08752v1",
        "PDF": "https://arxiv.org/pdf/2507.08752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on error analysis propagation in linear ODEs and does not discuss LLM training data or related processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.16710",
      "abstract": "Signal source localization has been a problem of interest in the multi-robot systems domain given its applications in search & rescue and hazard localization in various industrial and outdoor settings. A variety of multi-robot search algorithms exist that usually formulate and solve the associated autonomous motion planning problem as a heuristic model-free or belief model-based optimization process. Most of these algorithms however remains tested only in simulation, thereby losing the opportunity to generate knowledge about how such algorithms would compare/contrast in a real physical setting in terms of search performance and real-time computing performance. To address this gap, this paper presents a new lab-scale physical setup and associated open-source software pipeline to evaluate and benchmark multi-robot search algorithms. The presented physical setup innovatively uses an acoustic source (that is safe and inexpensive) and small ground robots (e-pucks) operating in a standard motion-capture environment. This setup can be easily recreated and used by most robotics researchers. The acoustic source also presents interesting uncertainty in terms of its noise-to-signal ratio, which is useful to assess sim-to-real gaps. The overall software pipeline is designed to readily interface with any multi-robot search algorithm with minimal effort and is executable in parallel asynchronous form. This pipeline includes a framework for distributed implementation of multi-robot or swarm search algorithms, integrated with a ROS (Robotics Operating System)-based software stack for motion capture supported localization. The utility of this novel setup is demonstrated by using it to evaluate two state-of-the-art multi-robot search algorithms, based on swarm optimization and batch-Bayesian Optimization (called Bayes-Swarm), as well as a random walk baseline.",
      "authors": [
        "Aditya Bhatt",
        "Mary Katherine Corra",
        "Franklin Merlo",
        "Prajit KrisshnaKumar and Souma Chowdhury"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T03:06:43+00:00",
          "link": "https://arxiv.org/abs/2506.16710v1",
          "size": "7139kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T22:01:07+00:00",
          "link": "https://arxiv.org/abs/2506.16710v2",
          "size": "7139kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T17:47:54+00:00",
          "link": "https://arxiv.org/abs/2506.16710v3",
          "size": "7139kb",
          "version": "v3"
        }
      ],
      "title": "Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16710",
        "HTML": "https://arxiv.org/html/2506.16710v3",
        "PDF": "https://arxiv.org/pdf/2506.16710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a physical setup and software pipeline for evaluating multi-robot search algorithms, which pertains to robotics rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08761",
      "abstract": "Reinforcement learning with offline data suffers from Q-value extrapolation errors. To address this issue, we first demonstrate that linear extrapolation of the Q-function beyond the data range is particularly problematic. To mitigate this, we propose guiding the gradual decrease of Q-values outside the data range, which is achieved through reward scaling with layer normalization (RS-LN) and a penalization mechanism for infeasible actions (PA). By combining RS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS across a range of tasks, demonstrating superior performance compared to state-of-the-art algorithms in both offline training and online fine-tuning on the D4RL benchmark, with notable success in the challenging AntMaze Ultra task.",
      "authors": [
        "Jeonghye Kim",
        "Yongjae Shin",
        "Whiyoung Jung",
        "Sunghoon Hong",
        "Deunsol Yoon",
        "Youngchul Sung",
        "Kanghoon Lee",
        "Woohyung Lim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:16:02+00:00",
          "link": "https://arxiv.org/abs/2507.08761v1",
          "size": "4991kb",
          "version": "v1"
        }
      ],
      "title": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08761",
        "HTML": "https://arxiv.org/html/2507.08761v1",
        "PDF": "https://arxiv.org/pdf/2507.08761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a reinforcement learning algorithm optimized for using offline data, mentioning data scaling techniques, but it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.17414",
      "abstract": "We present X-Dancer, a novel zero-shot music-driven image animation pipeline that creates diverse and long-range lifelike human dance videos from a single static image. As its core, we introduce a unified transformer-diffusion framework, featuring an autoregressive transformer model that synthesize extended and music-synchronized token sequences for 2D body, head and hands poses, which then guide a diffusion model to produce coherent and realistic dance video frames. Unlike traditional methods that primarily generate human motion in 3D, X-Dancer addresses data limitations and enhances scalability by modeling a wide spectrum of 2D dance motions, capturing their nuanced alignment with musical beats through readily available monocular videos. To achieve this, we first build a spatially compositional token representation from 2D human pose labels associated with keypoint confidences, encoding both large articulated body movements (e.g., upper and lower body) and fine-grained motions (e.g., head and hands). We then design a music-to-motion transformer model that autoregressively generates music-aligned dance pose token sequences, incorporating global attention to both musical style and prior motion context. Finally we leverage a diffusion backbone to animate the reference image with these synthesized pose tokens through AdaIN, forming a fully differentiable end-to-end framework. Experimental results demonstrate that X-Dancer is able to produce both diverse and characterized dance videos, substantially outperforming state-of-the-art methods in term of diversity, expressiveness and realism. Code and model will be available for research purposes.",
      "authors": [
        "Zeyuan Chen",
        "Hongyi Xu",
        "Guoxian Song",
        "You Xie",
        "Chenxu Zhang",
        "Xin Chen",
        "Chao Wang",
        "Di Chang",
        "Linjie Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T18:47:54+00:00",
          "link": "https://arxiv.org/abs/2502.17414v1",
          "size": "2826kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:58:23+00:00",
          "link": "https://arxiv.org/abs/2502.17414v2",
          "size": "6596kb",
          "version": "v2"
        }
      ],
      "title": "X-Dancer: Expressive Music to Human Dance Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17414",
        "HTML": "https://arxiv.org/html/2502.17414v2",
        "PDF": "https://arxiv.org/pdf/2502.17414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with zero-shot music-driven image animation for dance video generation, without discussing LLM training data collection or processing."
      },
      "tasks": [
        "Image Animation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02870",
      "abstract": "As the use of predictive machine learning algorithms increases in high-stakes decision-making, it is imperative that these algorithms are fair across sensitive groups. However, measuring and enforcing fairness in real-world applications can be challenging due to the missing or incomplete sensitive group information. Proxy-sensitive attributes have been proposed as a practical and effective solution in these settings, but only for parity-based fairness notions. Knowing how to evaluate and control for fairness with missing sensitive group data for newer, different, and more flexible frameworks, such as multiaccuracy and multicalibration, remain unexplored. In this work, we address this gap by demonstrating that in the absence of sensitive group data, proxy-sensitive attributes can provably used to derive actionable upper bounds on the true multiaccuracy and multicalibration violations, providing insights into a predictive model's potential worst-case fairness violations. Additionally, we show that adjusting models to satisfy multiaccuracy and multicalibration across proxy-sensitive attributes can significantly mitigate these violations for the true, but unknown, sensitive groups. Through several experiments on real-world datasets, we illustrate that approximate multiaccuracy and multicalibration can be achieved even when sensitive group data is incomplete or unavailable.",
      "authors": [
        "Beepul Bharti",
        "Mary Versa Clemens-Sewall",
        "Paul H. Yi",
        "and Jeremias Sulam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T18:47:54+00:00",
          "link": "https://arxiv.org/abs/2503.02870v1",
          "size": "115kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T04:41:11+00:00",
          "link": "https://arxiv.org/abs/2503.02870v2",
          "size": "115kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T12:37:16+00:00",
          "link": "https://arxiv.org/abs/2503.02870v3",
          "size": "112kb",
          "version": "v3"
        }
      ],
      "title": "Multiaccuracy and Multicalibration via Proxy Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02870",
        "HTML": "https://arxiv.org/html/2503.02870v3",
        "PDF": "https://arxiv.org/pdf/2503.02870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses fairness evaluation through proxy-sensitive attributes in predictive models but does not address LLM training data processing or dataset creation."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08037",
      "abstract": "Recent advancements in large language models (LLMs) underscore the need for stronger reasoning capabilities to solve complex problems effectively. While Chain-of-Thought (CoT) reasoning has been a step forward, it remains insufficient for many domains. A promising alternative is explicit high-level plan generation, but existing approaches largely assume that LLMs can produce effective plans through few-shot prompting alone, without additional training. In this work, we challenge this assumption and introduce CRISP (Complex Reasoning with Interpretable Step-based Plans), a multi-domain dataset of high-level plans for mathematical reasoning and code generation. The plans in CRISP are automatically generated and rigorously validated--both intrinsically, using an LLM as a judge, and extrinsically, by evaluating their impact on downstream task performance. We demonstrate that fine-tuning a small model on CRISP enables it to generate higher-quality plans than much larger models using few-shot prompting, while significantly outperforming Chain-of-Thought reasoning. Furthermore, our out-of-domain evaluation reveals that fine-tuning on one domain improves plan generation in the other, highlighting the generalizability of learned planning capabilities.",
      "authors": [
        "Matan Vetzler",
        "Koren Lazar",
        "Guy Uziel",
        "Eran Hirsch",
        "Ateret Anaby-Tavor",
        "Leshem Choshen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:40:24+00:00",
          "link": "https://arxiv.org/abs/2507.08037v1",
          "size": "201kb",
          "version": "v1"
        }
      ],
      "title": "CRISP: Complex Reasoning with Interpretable Step-based Plans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08037",
        "HTML": "https://arxiv.org/html/2507.08037v1",
        "PDF": "https://arxiv.org/pdf/2507.08037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces CRISP, a dataset of high-level plans for reasoning tasks, focusing on data generation and validation processes to improve training data quality for fine-tuning, which directly contributes to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08214",
      "abstract": "While total intracranial carotid artery calcification (ICAC) volume is an established stroke biomarker, growing evidence shows this aggregate metric ignores the critical influence of plaque location, since calcification in different segments carries distinct prognostic and procedural risks. However, a finer-grained, segment-specific quantification has remained technically infeasible. Conventional 3D models are forced to process downsampled volumes or isolated patches, sacrificing the global context required to resolve anatomical ambiguity and render reliable landmark localization. To overcome this, we reformulate the 3D challenge as a \\textbf{Parallel Probabilistic Landmark Localization} task along the 1D axial dimension. We propose the \\textbf{Depth-Sequence Transformer (DST)}, a framework that processes full-resolution CT volumes as sequences of 2D slices, learning to predict $N=6$ independent probability distributions that pinpoint key anatomical landmarks. Our DST framework demonstrates exceptional accuracy and robustness. Evaluated on a 100-patient clinical cohort with rigorous 5-fold cross-validation, it achieves a Mean Absolute Error (MAE) of \\textbf{0.1 slices}, with \\textbf{96\\%} of predictions falling within a $\\pm1$ slice tolerance. Furthermore, to validate its architectural power, the DST backbone establishes the best result on the public Clean-CC-CCII classification benchmark under an end-to-end evaluation protocol. Our work delivers the first practical tool for automated segment-specific ICAC analysis. The proposed framework provides a foundation for further studies on the role of location-specific biomarkers in diagnosis, prognosis, and procedural planning. Our code will be made publicly available.",
      "authors": [
        "Xiangjian Hou",
        "Ebru Yaman Akcicek",
        "Xin Wang",
        "Kazem Hashemizadeh",
        "Scott Mcnally",
        "Chun Yuan",
        "Xiaodong Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:12:12+00:00",
          "link": "https://arxiv.org/abs/2507.08214v1",
          "size": "1602kb",
          "version": "v1"
        }
      ],
      "title": "Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08214",
        "HTML": "https://arxiv.org/html/2507.08214v1",
        "PDF": "https://arxiv.org/pdf/2507.08214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a transformer model for medical imaging analysis, without addressing any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22236",
      "abstract": "The integration of the history and philosophy of statistics was initiated at least by Hacking (1965) and advanced by Mayo (1996), but it has not received sustained follow-up. Yet such integration is more urgent than ever, as the recent success of artificial intelligence has been driven largely by machine learning -- a field historically developed alongside statistics. Today, the boundary between statistics and machine learning is increasingly blurred. What we now need is integration, twice over: of history and philosophy, and of two fields they engage -- statistics and machine learning. I present a case study of a philosophical idea in machine learning (and in formal epistemology) whose root can be traced back to an often under-appreciated insight in Neyman and Pearson's 1936 work (a follow-up to their 1933 classic). This leads to the articulation of an epistemological principle -- largely implicit in, but shared by, the practices of frequentist statistics and machine learning -- which I call achievabilism: the thesis that the correct standard for assessing non-deductive inference methods should not be fixed, but should instead be sensitive to what is achievable in specific problem contexts. Another integration also emerges at the level of methodology, combining two ends of the philosophy of science spectrum: history and philosophy of science on the one hand, and formal epistemology on the other hand.",
      "authors": [
        "Hanti Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Other Statistics (stat.OT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:59:08+00:00",
          "link": "https://arxiv.org/abs/2506.22236v1",
          "size": "616kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:26:21+00:00",
          "link": "https://arxiv.org/abs/2506.22236v2",
          "size": "616kb",
          "version": "v2"
        }
      ],
      "title": "A Plea for History and Philosophy of Statistics and Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22236",
        "HTML": "https://arxiv.org/html/2506.22236v2",
        "PDF": "https://arxiv.org/pdf/2506.22236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is philosophical, discussing the integration of history and philosophy in statistics and machine learning without any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07460",
      "abstract": "Out-of-Distribution (OoD) segmentation is critical for safety-sensitive applications like autonomous driving. However, existing mask-based methods often suffer from boundary imprecision, inconsistent anomaly scores within objects, and false positives from background noise. We propose \\textbf{\\textit{Objectomaly}}, an objectness-aware refinement framework that incorporates object-level priors. Objectomaly consists of three stages: (1) Coarse Anomaly Scoring (CAS) using an existing OoD backbone, (2) Objectness-Aware Score Calibration (OASC) leveraging SAM-generated instance masks for object-level score normalization, and (3) Meticulous Boundary Precision (MBP) applying Laplacian filtering and Gaussian smoothing for contour refinement. Objectomaly achieves state-of-the-art performance on key OoD segmentation benchmarks, including SMIYC AnomalyTrack/ObstacleTrack and RoadAnomaly, improving both pixel-level (AuPRC up to 96.99, FPR$_{95}$ down to 0.07) and component-level (F1$-$score up to 83.44) metrics. Ablation studies and qualitative results on real-world driving videos further validate the robustness and generalizability of our method. Code will be released upon publication.",
      "authors": [
        "Jeonghoon Song",
        "Sunghun Kim",
        "Jaegyun Im",
        "Byeongjoon Noh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:23:35+00:00",
          "link": "https://arxiv.org/abs/2507.07460v1",
          "size": "15294kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T04:12:46+00:00",
          "link": "https://arxiv.org/abs/2507.07460v2",
          "size": "15293kb",
          "version": "v2"
        }
      ],
      "title": "Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07460",
        "HTML": "https://arxiv.org/html/2507.07460v2",
        "PDF": "https://arxiv.org/pdf/2507.07460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes Objectomaly for enhanced segmentation accuracy but focuses on OoD segmentation techniques rather than processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08024",
      "abstract": "Precision agriculture relies heavily on accurate image analysis for crop disease identification and treatment recommendation, yet existing vision-language models (VLMs) often underperform in specialized agricultural domains. This work presents a domain-aware framework for agricultural image processing that combines prompt-based expert evaluation with self-consistency mechanisms to enhance VLM reliability in precision agriculture applications. We introduce two key innovations: (1) a prompt-based evaluation protocol that configures a language model as an expert plant pathologist for scalable assessment of image analysis outputs, and (2) a cosine-consistency self-voting mechanism that generates multiple candidate responses from agricultural images and selects the most semantically coherent diagnosis using domain-adapted embeddings. Applied to maize leaf disease identification from field images using a fine-tuned PaliGemma model, our approach improves diagnostic accuracy from 82.2\\% to 87.8\\%, symptom analysis from 38.9\\% to 52.2\\%, and treatment recommendation from 27.8\\% to 43.3\\% compared to standard greedy decoding. The system remains compact enough for deployment on mobile devices, supporting real-time agricultural decision-making in resource-constrained environments. These results demonstrate significant potential for AI-driven precision agriculture tools that can operate reliably in diverse field conditions.",
      "authors": [
        "Mihir Gupta",
        "Abhay Mangla",
        "Ross Greer",
        "Pratik Desai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:32:21+00:00",
          "link": "https://arxiv.org/abs/2507.08024v1",
          "size": "3052kb",
          "version": "v1"
        }
      ],
      "title": "Self-Consistency in Vision-Language Models for Precision Agriculture: Multi-Response Consensus for Crop Disease Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08024",
        "HTML": "https://arxiv.org/html/2507.08024v1",
        "PDF": "https://arxiv.org/pdf/2507.08024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for enhancing vision-language models in precision agriculture, focusing on prompt-based evaluation and self-consistency mechanisms, without a focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08262",
      "abstract": "Building a robust perception module is crucial for visuomotor policy learning. While recent methods incorporate pre-trained 2D foundation models into robotic perception modules to leverage their strong semantic understanding, they struggle to capture 3D spatial information and generalize across diverse camera viewpoints. These limitations hinder the policy's effectiveness, especially in fine-grained robotic manipulation scenarios. To address these challenges, we propose CL3R, a novel 3D pre-training framework designed to enhance robotic manipulation policies. Our method integrates both spatial awareness and semantic understanding by employing a point cloud Masked Autoencoder to learn rich 3D representations while leveraging pre-trained 2D foundation models through contrastive learning for efficient semantic knowledge transfer. Additionally, we propose a 3D visual representation pre-training framework for robotic tasks. By unifying coordinate systems across datasets and introducing random fusion of multi-view point clouds, we mitigate camera view ambiguity and improve generalization, enabling robust perception from novel viewpoints at test time. Extensive experiments in both simulation and the real world demonstrate the superiority of our method, highlighting its effectiveness in visuomotor policy learning for robotic manipulation.",
      "authors": [
        "Wenbo Cui",
        "Chengyang Zhao",
        "Yuhui Chen",
        "Haoran Li",
        "Zhizheng Zhang",
        "Dongbin Zhao",
        "He Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:16:32+00:00",
          "link": "https://arxiv.org/abs/2507.08262v1",
          "size": "2845kb",
          "version": "v1"
        }
      ],
      "title": "CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08262",
        "HTML": "https://arxiv.org/html/2507.08262v1",
        "PDF": "https://arxiv.org/pdf/2507.08262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a pre-training framework for 3D representations in robotic manipulation, emphasizing perception and visuomotor policy learning rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08725",
      "abstract": "Large data and computing centers consume a significant share of the world's energy consumption. A prominent subset of the workloads in such centers are workflows with interdependent tasks, usually represented as directed acyclic graphs (DAGs). To reduce the carbon emissions resulting from executing such workflows in centers with a mixed (renewable and non-renewable) energy supply, it is advisable to move task executions to time intervals with sufficient green energy when possible. To this end, we formalize the above problem as a scheduling problem with a given mapping and ordering of the tasks. We show that this problem can be solved in polynomial time in the uniprocessor case. For at least two processors, however, the problem becomes NP-hard. Hence, we propose a heuristic framework called CaWoSched that combines several greedy approaches with local search. To assess the 16 heuristics resulting from different combinations, we also devise a simple baseline algorithm and an exact ILP-based solution. Our experimental results show that our heuristics provide significant savings in carbon emissions compared to the baseline.",
      "authors": [
        "Dominik Schweisgut and Anne Benoit and Yves Robert and Henning Meyerhenke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:25:13+00:00",
          "link": "https://arxiv.org/abs/2507.08725v1",
          "size": "4264kb",
          "version": "v1"
        }
      ],
      "title": "Carbon-Aware Workflow Scheduling with Fixed Mapping and Deadline Constraint",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08725",
        "HTML": "https://arxiv.org/html/2507.08725v1",
        "PDF": "https://arxiv.org/pdf/2507.08725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on carbon-aware workflow scheduling with task mapping and deadline constraint in computational centers, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08459",
      "abstract": "With the widespread application of Large Language Models (LLMs) in various tasks, the mainstream LLM platforms generate massive user-model interactions daily. In order to efficiently analyze the performance of models and diagnose failures in their answers, it is essential to develop an automated framework to systematically categorize and attribute errors. However, existing evaluation models lack error attribution capability. In this work, we establish a comprehensive Misattribution Framework with 6 primary and 15 secondary categories to facilitate in-depth analysis. Based on this framework, we present AttriData, a dataset specifically designed for error attribution, encompassing misattribution, along with the corresponding scores and feedback. We also propose MisAttributionLLM, a fine-tuned model on AttriData, which is the first general-purpose judge model capable of simultaneously generating score, misattribution, and feedback. Extensive experiments and analyses are conducted to confirm the effectiveness and robustness of our proposed method.",
      "authors": [
        "Zishan Xu",
        "Shuyi Xie",
        "Qingsong Lv",
        "Shupei Xiao",
        "Linlin Song",
        "Sui Wenjuan",
        "Fan Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:02:21+00:00",
          "link": "https://arxiv.org/abs/2507.08459v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "Diagnosing Failures in Large Language Models' Answers: Integrating Error Attribution into Evaluation Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08459",
        "PDF": "https://arxiv.org/pdf/2507.08459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel error attribution framework and dataset (AttriData) for evaluating LLM responses, focusing on diagnosing errors rather than processing or creating training data directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.06743",
      "abstract": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to navigate safely by anticipating the movements of surrounding road users. However, current deep learning models often lack trustworthiness as their predictions can be physically infeasible and illogical to humans. To make predictions more trustworthy, recent research has incorporated prior knowledge, like the social force model for modeling interactions and kinematic models for physical realism. However, these approaches focus on priors that suit either vehicles or pedestrians and do not generalize to traffic with mixed agent classes. We propose incorporating interaction and kinematic priors of all agent classes--vehicles, pedestrians, and cyclists with class-specific interaction layers to capture agent behavioral differences. To improve the interpretability of the agent interactions, we introduce DG-SFM, a rule-based interaction importance score that guides the interaction layer. To ensure physically feasible predictions, we proposed suitable kinematic models for all agent classes with a novel pedestrian kinematic model. We benchmark our approach on the Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our baseline. Experiments demonstrate that our method improves interaction interpretability, revealing a correlation between incorrect predictions and divergence from our interaction prior. Even though incorporating the kinematic models causes a slight decrease in accuracy, they eliminate infeasible trajectories found in the dataset and the baseline model. Thus, our approach fosters trust in trajectory prediction as its interaction reasoning is interpretable, and its predictions adhere to physics.",
      "authors": [
        "Marius Baden",
        "Ahmed Abouelazm",
        "Christian Hubschneider",
        "Yin Wu",
        "Daniel Slieter",
        "and J. Marius Z\\\"ollner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-10T19:29:32+00:00",
          "link": "https://arxiv.org/abs/2505.06743v1",
          "size": "1361kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:34:44+00:00",
          "link": "https://arxiv.org/abs/2505.06743v2",
          "size": "1362kb",
          "version": "v2"
        }
      ],
      "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06743",
        "HTML": "https://arxiv.org/html/2505.06743v2",
        "PDF": "https://arxiv.org/pdf/2505.06743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving trajectory prediction for autonomous driving by incorporating prior knowledge and kinematic models, which does not involve LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Navigate",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08264",
      "abstract": "This paper addresses the challenges of training end-to-end autonomous driving agents using Reinforcement Learning (RL). RL agents are typically trained in a fixed set of scenarios and nominal behavior of surrounding road users in simulations, limiting their generalization and real-life deployment. While domain randomization offers a potential solution by randomly sampling driving scenarios, it frequently results in inefficient training and sub-optimal policies due to the high variance among training scenarios. To address these limitations, we propose an automatic curriculum learning framework that dynamically generates driving scenarios with adaptive complexity based on the agent's evolving capabilities. Unlike manually designed curricula that introduce expert bias and lack scalability, our framework incorporates a ``teacher'' that automatically generates and mutates driving scenarios based on their learning potential -- an agent-centric metric derived from the agent's current policy -- eliminating the need for expert design. The framework enhances training efficiency by excluding scenarios the agent has mastered or finds too challenging. We evaluate our framework in a reinforcement learning setting where the agent learns a driving policy from camera images. Comparative results against baseline methods, including fixed scenario training and domain randomization, demonstrate that our approach leads to enhanced generalization, achieving higher success rates: +9% in low traffic density, +21% in high traffic density, and faster convergence with fewer training steps. Our findings highlight the potential of ACL in improving the robustness and efficiency of RL-based autonomous driving agents.",
      "authors": [
        "Ahmed Abouelazm",
        "Tim Weinstein",
        "Tim Joseph",
        "Philip Sch\\\"orner",
        "and J. Marius Z\\\"ollner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T06:26:57+00:00",
          "link": "https://arxiv.org/abs/2505.08264v1",
          "size": "2874kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:23:36+00:00",
          "link": "https://arxiv.org/abs/2505.08264v2",
          "size": "2874kb",
          "version": "v2"
        }
      ],
      "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08264",
        "HTML": "https://arxiv.org/html/2505.08264v2",
        "PDF": "https://arxiv.org/pdf/2505.08264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an automatic curriculum learning framework for autonomous driving scenarios in reinforcement learning, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08254",
      "abstract": "Current challenges in developing foundational models for volumetric imaging data, such as magnetic resonance imaging (MRI), stem from the computational complexity of training state-of-the-art architectures in high dimensions and curating sufficiently large datasets of volumes. To address these challenges, we introduce Raptor (Random Planar Tensor Reduction), a train-free method for generating semantically rich embeddings for volumetric data. Raptor leverages a frozen 2D foundation model, pretrained on natural images, to extract visual tokens from individual cross-sections of medical volumes. These tokens are then spatially compressed using random projections, significantly reducing computational complexity while retaining semantic information. Extensive experiments on ten diverse medical volume tasks verify the superior performance of Raptor over state-of-the-art methods, including those pretrained exclusively on medical volumes (+3% SuPreM, +6% MISFM, +10% Merlin, +13% VoCo, and +14% SLIViT), while entirely bypassing the need for costly training. Our results highlight the effectiveness and versatility of Raptor as a foundation for advancing deep learning-based methods for medical volumes.",
      "authors": [
        "Ulzee An",
        "Moonseong Jeong",
        "Simon A. Lee",
        "Aditya Gorla",
        "Yuzhe Yang",
        "Sriram Sankararaman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:59:52+00:00",
          "link": "https://arxiv.org/abs/2507.08254v1",
          "size": "2445kb",
          "version": "v1"
        }
      ],
      "title": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08254",
        "HTML": "https://arxiv.org/html/2507.08254v1",
        "PDF": "https://arxiv.org/pdf/2507.08254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for generating embeddings from 3D medical volumes but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08268",
      "abstract": "The way a person moves is a direct reflection of their neurological and musculoskeletal health, yet it remains one of the most underutilized vital signs in clinical practice. Although clinicians visually observe movement impairments, they lack accessible and validated methods to objectively measure movement in routine care. This gap prevents wider use of biomechanical measurements in practice, which could enable more sensitive outcome measures or earlier identification of impairment. We present our Portable Biomechanics Laboratory (PBL), which includes a secure, cloud-enabled smartphone app for data collection and a novel algorithm for fitting biomechanical models to this data. We extensively validated PBL's biomechanical measures using a large, clinically representative dataset. Next, we tested the usability and utility of our system in neurosurgery and sports medicine clinics. We found joint angle errors within 3 degrees across participants with neurological injury, lower-limb prosthesis users, pediatric inpatients, and controls. In addition to being easy to use, gait metrics computed from the PBL showed high reliability and were sensitive to clinical differences. For example, in individuals undergoing decompression surgery for cervical myelopathy, the mJOA score is a common patient-reported outcome measure; we found that PBL gait metrics correlated with mJOA scores and demonstrated greater responsiveness to surgical intervention than the patient-reported outcomes. These findings support the use of handheld smartphone video as a scalable, low-burden tool for capturing clinically meaningful biomechanical data, offering a promising path toward accessible monitoring of mobility impairments. We release the first clinically validated method for measuring whole-body kinematics from handheld smartphone video at https://intelligentsensingandrehabilitation.github.io/MonocularBiomechanics/ .",
      "authors": [
        "J.D. Peiffer",
        "Kunal Shah",
        "Irina Djuraskovic",
        "Shawana Anarwala",
        "Kayan Abdou",
        "Rujvee Patel",
        "Prakash Jayabalan",
        "Brenton Pennicooke",
        "and R. James Cotton"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:29:26+00:00",
          "link": "https://arxiv.org/abs/2507.08268v1",
          "size": "2589kb",
          "version": "v1"
        }
      ],
      "title": "Portable Biomechanics Laboratory: Clinically Accessible Movement Analysis from a Handheld Smartphone",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08268",
        "HTML": "https://arxiv.org/html/2507.08268v1",
        "PDF": "https://arxiv.org/pdf/2507.08268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a biomechanics laboratory for movement analysis using a smartphone. It does not focus on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08410",
      "abstract": "Prompt learning facilitates the efficient adaptation of Vision-Language Models (VLMs) to various downstream tasks. However, it faces two significant challenges: (1) inadequate modeling of class embedding distributions for unseen instances, leading to suboptimal generalization on novel classes; (2) prevailing methodologies predominantly confine cross-modal alignment to the final output layer of vision and text encoders, which fundamentally limits their capacity to preserve topological consistency with pre-trained multi-modal embedding spaces. To this end, we introduce MuGCP (Multi-modal Mutual-Guidance Conditional Prompt Learning), a novel paradigm designed for conditional prompt generation. MuGCP leverages Multi-modal Large Language Models (MLLMs) as conditional prompt learners to adaptively generate Semantic Conditional Prompts (SCP) that incorporate rich, fine-grained high-level semantic knowledge for image instances. To ensure effective alignment and interaction across the multi-modal space of Vision-Language Models (VLMs), we introduce the Attention Mutual-Guidance (AMG) module, which facilitates interactions between visual and semantic information. Through mutual guidance, the AMG module generates Visual Conditional Prompts (VCP), enhancing the model's performance in multi-modal tasks. Additionally, we present a Multi-Prompt Fusion (MPF) mechanism that integrates SCP and VCP with contextual prompts, ensuring seamless coordination among the different prompts and enhancing the modeling of class embeddings and instance-specific knowledge. Our MuGCP outperforms existing state-of-the-art methods on 14 different datasets. The code will be made available after publication.",
      "authors": [
        "Shijun Yang",
        "Xiang Zhang",
        "Wanqing Zhao",
        "Hangzai Luo",
        "Sheng Zhong",
        "Jinye Peng",
        "Jianping Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:45:27+00:00",
          "link": "https://arxiv.org/abs/2507.08410v1",
          "size": "39477kb",
          "version": "v1"
        }
      ],
      "title": "Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08410",
        "HTML": "https://arxiv.org/html/2507.08410v1",
        "PDF": "https://arxiv.org/pdf/2507.08410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a method for conditional prompt learning in Vision-Language Models to enhance modeling tasks, it primarily focuses on task performance and alignment, not on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08555",
      "abstract": "3D Semantic Scene Completion (SSC) has gained increasing attention due to its pivotal role in 3D perception. Recent advancements have primarily focused on refining voxel-level features to construct 3D scenes. However, treating voxels as the basic interaction units inherently limits the utilization of class-level information, which is proven critical for enhancing the granularity of completion results. To address this, we propose \\textbf{D}isentangling Instance and Scene Contexts (DISC), a novel dual-stream paradigm that enhances learning for both instance and scene categories through separated optimization. Specifically, we replace voxel queries with discriminative class queries, which incorporate class-specific geometric and semantic priors. Additionally, we exploit the intrinsic properties of classes to design specialized decoding modules, facilitating targeted interactions and efficient class-level information flow. Experimental results demonstrate that DISC achieves state-of-the-art (SOTA) performance on both SemanticKITTI and SSCBench-KITTI-360 benchmarks, with mIoU scores of 17.35 and 20.55, respectively. Remarkably, DISC even outperforms multi-frame SOTA methods using only single-frame input and significantly improves instance category performance, surpassing both single-frame and multi-frame SOTA instance mIoU by 17.9\\% and 11.9\\%, respectively, on the SemanticKITTI hidden test. The code is available at https://github.com/Enyu-Liu/DISC.",
      "authors": [
        "Enyu Liu",
        "En Yu",
        "Sijia Chen",
        "Wenbing Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:57:14+00:00",
          "link": "https://arxiv.org/abs/2507.08555v1",
          "size": "8395kb",
          "version": "v1"
        }
      ],
      "title": "Disentangling Instance and Scene Contexts for 3D Semantic Scene Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08555",
        "HTML": "https://arxiv.org/html/2507.08555v1",
        "PDF": "https://arxiv.org/pdf/2507.08555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with 3D semantic scene completion using disentangled instance and scene contexts, focusing on geometry and semantics, without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08771",
      "abstract": "To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while each token activates only a few parameters, these sparsely-activated architectures exhibit low chunk-level sparsity, indicating that the union of multiple consecutive tokens activates a large ratio of parameters. Such a sparsity pattern is unfriendly for acceleration under low-resource conditions (e.g., end-side devices) and incompatible with mainstream acceleration techniques (e.g., speculative decoding). To address these challenges, we introduce a novel MoE architecture, BlockFFN, as well as its efficient training and deployment techniques. Specifically, we use a router integrating ReLU activation and RMSNorm for differentiable and flexible routing. Next, to promote both token-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training objectives are designed, making BlockFFN more acceleration-friendly. Finally, we implement efficient acceleration kernels, combining activation sparsity and speculative decoding for the first time. The experimental results demonstrate the superior performance of BlockFFN over other MoE baselines, achieving over 80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67$\\times$ speedup on real end-side devices than dense models. All codes and checkpoints are available publicly (https://github.com/thunlp/BlockFFN).",
      "authors": [
        "Chenyang Song",
        "Weilin Zhao",
        "Xu Han",
        "Chaojun Xiao",
        "Yingfa Chen",
        "Yuxuan Li",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:28:56+00:00",
          "link": "https://arxiv.org/abs/2507.08771v1",
          "size": "1144kb",
          "version": "v1"
        }
      ],
      "title": "BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08771",
        "HTML": "https://arxiv.org/html/2507.08771v1",
        "PDF": "https://arxiv.org/pdf/2507.08771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a novel MoE architecture with efficient training and deployment techniques, it does not primarily focus on data processing for LLM training but rather on architectural improvements for acceleration."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05928",
      "abstract": "Medical Visual Question Answering (Med-VQA) represents a critical and challenging subtask within the general VQA domain. Despite significant advancements in general VQA, multimodal large language models (MLLMs) still exhibit substantial limitations when handling multi-task VQA scenarios. These limitations manifest through erroneous spatial localization and misinterpretation of medical images, which primarily arise from two fundamental issues: inadequate image-text alignment and insufficient domain-specified knowledge for medical applications. To address these issues, we introduce the Cross-Modal Clinical Knowledge Distiller (ClinKD), an innovative framework designed to enhance image-text alignment and establish more effective medical knowledge transformation mechanisms, which enables MLLMs to perform better even when lacking prior medical knowledge. Our extensive experimental evaluations demonstrate that the ClinKD achieves state-of-the-art performance on several datasets which are challenging for Med-VQA task. The results indicate that our approach not only significantly improves image-text alignment but also effectively enables MLLMs to adapt to the medical knowledge. The source code for ClinKD is available at: https://github.com/overloadedHenry/ClinKD.",
      "authors": [
        "Hongyu Ge",
        "Longkun Hao",
        "Zihui Xu",
        "Zhenxin Lin",
        "Bin Li",
        "Shoujun Zhou",
        "Hongjin Zhao",
        "Yihang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-09T15:08:10+00:00",
          "link": "https://arxiv.org/abs/2502.05928v1",
          "size": "251kb",
          "version": "v1"
        },
        {
          "date": "2025-03-08T15:52:19+00:00",
          "link": "https://arxiv.org/abs/2502.05928v2",
          "size": "579kb",
          "version": "v2"
        },
        {
          "date": "2025-04-19T14:13:40+00:00",
          "link": "https://arxiv.org/abs/2502.05928v3",
          "size": "821kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T04:08:20+00:00",
          "link": "https://arxiv.org/abs/2502.05928v4",
          "size": "577kb",
          "version": "v4"
        }
      ],
      "title": "ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05928",
        "HTML": "https://arxiv.org/html/2502.05928v4",
        "PDF": "https://arxiv.org/pdf/2502.05928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ClinKD to enhance multimodal LLM performance in medical visual question answering, focusing on knowledge distillation, but not primarily on training data processing."
      },
      "tasks": [
        "Clinical Knowledge",
        "Medical Visual Question Answering",
        "Question Answering",
        "Visual Question Answering",
        "Visual Question Answering (VQA)"
      ],
      "repo_urls": [
        "https://github.com/overloadedhenry/clinkd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09131",
      "abstract": "Hyperspectral images (HSIs) often suffer from diverse and unknown degradations during imaging, leading to severe spectral and spatial distortions. Existing HSI restoration methods typically rely on specific degradation assumptions, limiting their effectiveness in complex scenarios. In this paper, we propose \\textbf{MP-HSIR}, a novel multi-prompt framework that effectively integrates spectral, textual, and visual prompts to achieve universal HSI restoration across diverse degradation types and intensities. Specifically, we develop a prompt-guided spatial-spectral transformer, which incorporates spatial self-attention and a prompt-guided dual-branch spectral self-attention. Since degradations affect spectral features differently, we introduce spectral prompts in the local spectral branch to provide universal low-rank spectral patterns as prior knowledge for enhancing spectral reconstruction. Furthermore, the text-visual synergistic prompt fuses high-level semantic representations with fine-grained visual features to encode degradation information, thereby guiding the restoration process. Extensive experiments on 9 HSI restoration tasks, including all-in-one scenarios, generalization tests, and real-world cases, demonstrate that MP-HSIR not only consistently outperforms existing all-in-one methods but also surpasses state-of-the-art task-specific approaches across multiple tasks. The code and models are available at https://github.com/ZhehuiWu/MP-HSIR.",
      "authors": [
        "Zhehui Wu",
        "Yong Chen",
        "Naoto Yokoya and Wei He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T07:40:49+00:00",
          "link": "https://arxiv.org/abs/2503.09131v1",
          "size": "6229kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:06:12+00:00",
          "link": "https://arxiv.org/abs/2503.09131v2",
          "size": "6836kb",
          "version": "v2"
        }
      ],
      "title": "MP-HSIR: A Multi-Prompt Framework for Universal Hyperspectral Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09131",
        "HTML": "https://arxiv.org/html/2503.09131v2",
        "PDF": "https://arxiv.org/pdf/2503.09131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a multi-prompt framework for hyperspectral image restoration, focusing on model architecture and not relevant to LLM training data processing."
      },
      "tasks": [
        "Image Restoration",
        "Spectral Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/zhehuiwu/mp-hsir"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07531",
      "abstract": "Epistemic injustice related to AI is a growing concern. In relation to machine learning models, epistemic injustice can have a diverse range of sources, ranging from epistemic opacity, the discriminatory automation of testimonial prejudice, and the distortion of human beliefs via generative AI's hallucinations to the exclusion of the global South in global AI governance, the execution of bureaucratic violence via algorithmic systems, and interactions with conversational artificial agents. Based on a proposed general taxonomy of epistemic injustice, this paper first sketches a taxonomy of the types of epistemic injustice in the context of AI, relying on the work of scholars from the fields of philosophy of technology, political philosophy and social epistemology. Secondly, an additional conceptualization on epistemic injustice in the context of AI is provided: generative hermeneutical erasure. I argue that this injustice the automation of 'epistemicide', the injustice done to epistemic agents in their capacity for collective sense-making through the suppression of difference in epistemology and conceptualization by LLMs. AI systems' 'view from nowhere' epistemically inferiorizes non-Western epistemologies and thereby contributes to the erosion of their epistemic particulars, gradually contributing to hermeneutical erasure. This work's relevance lies in proposal of a taxonomy that allows epistemic injustices to be mapped in the AI domain and the proposal of a novel form of AI-related epistemic injustice.",
      "authors": [
        "Warmhold Jan Thomas Mollema"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T07:54:47+00:00",
          "link": "https://arxiv.org/abs/2504.07531v1",
          "size": "4481kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:32:41+00:00",
          "link": "https://arxiv.org/abs/2504.07531v2",
          "size": "4563kb",
          "version": "v2"
        }
      ],
      "title": "A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07531",
        "PDF": "https://arxiv.org/pdf/2504.07531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses epistemic injustice in AI and the philosophical aspects of LLMs, focusing on taxonomy and concepts rather than on processing or engineering of LLM training data."
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07722",
      "abstract": "Recent works have revisited the infamous task ``Name That Dataset'', demonstrating that non-medical datasets contain underlying biases and that the dataset origin task can be solved with high accuracy. In this work, we revisit the same task applied to popular open-source chest X-ray datasets. Medical images are naturally more difficult to release for open-source due to their sensitive nature, which has led to certain open-source datasets being extremely popular for research purposes. By performing the same task, we wish to explore whether dataset bias also exists in these datasets. To extend our work, we apply simple transformations to the datasets, repeat the same task, and perform an analysis to identify and explain any detected biases. Given the importance of AI applications in medical imaging, it's vital to establish whether modern methods are taking shortcuts or are focused on the relevant pathology. We implement a range of different network architectures on the datasets: NIH, CheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more explainable research being performed in medical imaging and the creation of more open-source datasets in the medical domain. Our code can be found here: https://github.com/eedack01/x_ray_ds_bias.",
      "authors": [
        "Ethan Dack",
        "Chengliang Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.07722v1",
          "size": "999kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:22:21+00:00",
          "link": "https://arxiv.org/abs/2507.07722v2",
          "size": "1013kb",
          "version": "v2"
        }
      ],
      "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07722",
        "HTML": "https://arxiv.org/html/2507.07722v2",
        "PDF": "https://arxiv.org/pdf/2507.07722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses dataset biases in medical imaging datasets and performs transformations, but it does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08011",
      "abstract": "We develop an energy management system (EMS) for artificial intelligence (AI) data centers with colocated renewable generation. Under a profit-maximizing framework, the EMS of renewable-colocated data center (RCDC) co-optimizes AI workload scheduling, on-site renewable utilization, and electricity market participation. Within both wholesale and retail market participation models, the economic benefit of the RCDC operation is maximized. Empirical evaluations using real-world traces of electricity prices, data center power consumption, and renewable generation demonstrate significant profit gains from renewable and AI data center colocations.",
      "authors": [
        "Siying Li and Lang Tong and Timothy D. Mount"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T18:25:42+00:00",
          "link": "https://arxiv.org/abs/2507.08011v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "Energy Management for Renewable-Colocated Artificial Intelligence Data Centers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08011",
        "HTML": "https://arxiv.org/html/2507.08011v1",
        "PDF": "https://arxiv.org/pdf/2507.08011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses energy management systems for AI data centers, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08424",
      "abstract": "Random telegraph noise is a prevalent variability phenomenon in nanoelectronic devices, arising from stochastic carrier exchange at defect sites and critically impacting device reliability and performance. Conventional analysis techniques often rely on restrictive assumptions or manual interventions, limiting their applicability to complex, noisy datasets. Here, we introduce RTNinja, a generalized, fully automated machine learning framework for the unsupervised analysis of random telegraph noise signals. RTNinja deconvolves complex signals to identify the number and characteristics of hidden individual sources, without requiring prior knowledge of the system. The framework comprises two modular components: LevelsExtractor, which uses Bayesian inference and model selection to denoise and discretize the signal; and SourcesMapper, which infers source configurations through probabilistic clustering and optimization. To evaluate performance, we developed a Monte Carlo simulator that generates labeled datasets spanning broad signal-to-noise ratios and source complexities; across 7000 such datasets, RTNinja consistently demonstrated high-fidelity signal reconstruction and accurate extraction of source amplitudes and activity patterns. Our results demonstrate that RTNinja offers a robust, scalable, and device-agnostic tool for random telegraph noise characterization, enabling large-scale statistical benchmarking, reliability-centric technology qualification, predictive failure modeling, and device physics exploration in next-generation nanoelectronics.",
      "authors": [
        "Anirudh Varanasi",
        "Robin Degraeve",
        "Philippe Roussel",
        "Clement Merckling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:09:01+00:00",
          "link": "https://arxiv.org/abs/2507.08424v1",
          "size": "22636kb",
          "version": "v1"
        }
      ],
      "title": "RTNinja: a generalized machine learning framework for analyzing random telegraph noise signals in nanoelectronic devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08424",
        "HTML": "https://arxiv.org/html/2507.08424v1",
        "PDF": "https://arxiv.org/pdf/2507.08424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces RTNinja, focused on analyzing random telegraph noise signals in nanoelectronic devices using machine learning. This is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08621",
      "abstract": "Argument mining (AM) is an interdisciplinary research field that integrates insights from logic, philosophy, linguistics, rhetoric, law, psychology, and computer science. It involves the automatic identification and extraction of argumentative components, such as premises and claims, and the detection of relationships between them, such as support, attack, or neutrality. Recently, the field has advanced significantly, especially with the advent of large language models (LLMs), which have enhanced the efficiency of analyzing and extracting argument semantics compared to traditional methods and other deep learning models. There are many benchmarks for testing and verifying the quality of LLM, but there is still a lack of research and results on the operation of these models in publicly available argument classification databases. This paper presents a study of a selection of LLM's, using diverse datasets such as Args.me and UKP. The models tested include versions of GPT, Llama, and DeepSeek, along with reasoning-enhanced variants incorporating the Chain-of-Thoughts algorithm. The results indicate that ChatGPT-4o outperforms the others in the argument classification benchmarks. In case of models incorporated with reasoning capabilities, the Deepseek-R1 shows its superiority. However, despite their superiority, GPT-4o and Deepseek-R1 still make errors. The most common errors are discussed for all models. To our knowledge, the presented work is the first broader analysis of the mentioned datasets using LLM and prompt algorithms. The work also shows some weaknesses of known prompt algorithms in argument analysis, while indicating directions for their improvement. The added value of the work is the in-depth analysis of the available argument datasets and the demonstration of their shortcomings.",
      "authors": [
        "Marcin Pietro\\'n",
        "Rafa{\\l} Olszowski",
        "Jakub Gomu{\\l}ka",
        "Filip Gampel",
        "Andrzej Tomski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:23:40+00:00",
          "link": "https://arxiv.org/abs/2507.08621v1",
          "size": "1747kb",
          "version": "v1"
        }
      ],
      "title": "A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08621",
        "HTML": "https://arxiv.org/html/2507.08621v1",
        "PDF": "https://arxiv.org/pdf/2507.08621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a study of argument classification using LLMs, focusing on model performance over existing datasets, without any contribution to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08736",
      "abstract": "Catastrophic forgetting in deep neural networks occurs when learning new tasks degrades performance on previously learned tasks due to knowledge overwriting. Among the approaches to mitigate this issue, regularization techniques aim to identify and constrain \"important\" parameters to preserve previous knowledge. In the highly nonconvex optimization landscape of deep learning, we propose a novel perspective: tracking parameters during the final training plateau is more effective than monitoring them throughout the entire training process. We argue that parameters that exhibit higher activity (movement and variability) during this plateau reveal directions in the loss landscape that are relatively flat, making them suitable for adaptation to new tasks while preserving knowledge from previous ones. Our comprehensive experiments demonstrate that this approach achieves superior performance in balancing catastrophic forgetting mitigation with strong performance on newly learned tasks.",
      "authors": [
        "Idan Mashiach",
        "Oren Glickman",
        "and Tom Tirer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:38:40+00:00",
          "link": "https://arxiv.org/abs/2507.08736v1",
          "size": "4354kb",
          "version": "v1"
        }
      ],
      "title": "Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08736",
        "HTML": "https://arxiv.org/html/2507.08736v1",
        "PDF": "https://arxiv.org/pdf/2507.08736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mitigating catastrophic forgetting in deep neural networks, specifically through regularization techniques and parameter tracking, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08549",
      "abstract": "The low Earth orbit (LEO) mega-constellation network (LMCN), which uses thousands of satellites across multi-shell architectures to deliver different services, is facing challenges in inter-shell routing stability due to dynamic network topologies and frequent inter-satellite link (ISL) switching. Existing strategies, such as the Minimum Hop Path set, prioritize minimizing hop counts to reduce latency, but ignore ISL switching costs, which leads to high instability. To overcome this, the Adaptive Path Routing Scheme introduces path similarity thresholds to reduce the ISL switching frequency between shells. However, the greedy approach of Adaptive Path Routing Scheme is often trapped in local optima, sacrificing inter-shell path distance efficiency. To address these limitations, we propose the Dynamic Programming-based Integrated Routing Cost (DP-IRC) algorithm, which is designed explicitly for inter-shell routing optimization. By formulating multi-shell paths as a multistage decision problem, DP-IRC balances hop counts and ISL stability through an Integrated Routing Cost (IRC) metric, combining inter-/intra-shell hops and switching costs. Experiments over 60 time slots with real-world Starlink and OneWeb configurations show that DP-IRC reduces inter-shell ISL switching rates by 39.1% and 22.0% compared to the Minimum Hop Path set strategy and Adaptive Path Routing Scheme, respectively, while still maintaining near-optimal end-to-end distances.",
      "authors": [
        "Yaojia Wang",
        "Qi Zhang",
        "Kun Qiu",
        "Yue Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:53:32+00:00",
          "link": "https://arxiv.org/abs/2507.08549v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "Stabilizing and Optimizing Inter-Shell Routing in LEO Networks with Integrated Routing Cost",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08549",
        "HTML": "https://arxiv.org/html/2507.08549v1",
        "PDF": "https://arxiv.org/pdf/2507.08549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses routing optimization in satellite networks without any mention of LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08232",
      "abstract": "Large Language Models (LLMs) are increasingly used as proxy students in the development of Intelligent Tutoring Systems (ITSs) and in piloting test questions. However, to what extent these proxy students accurately emulate the behavior and characteristics of real students remains an open question. To investigate this, we collected a dataset of 489 items from the National Assessment of Educational Progress (NAEP), covering mathematics and reading comprehension in grades 4, 8, and 12. We then apply an Item Response Theory (IRT) model to position 11 diverse and state-of-the-art LLMs on the same ability scale as real student populations. Our findings reveal that, without guidance, strong general-purpose models consistently outperform the average student at every grade, while weaker or domain-mismatched models may align incidentally. Using grade-enforcement prompts changes models' performance, but whether they align with the average grade-level student remains highly model- and prompt-specific: no evaluated model-prompt pair fits the bill across subjects and grades, underscoring the need for new training and evaluation strategies. We conclude by providing guidelines for the selection of viable proxies based on our findings.",
      "authors": [
        "KV Aditya Srivatsa",
        "Kaushal Kumar Maurya",
        "Ekaterina Kochmar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:36:57+00:00",
          "link": "https://arxiv.org/abs/2507.08232v1",
          "size": "1101kb",
          "version": "v1"
        }
      ],
      "title": "Can LLMs Reliably Simulate Real Students' Abilities in Mathematics and Reading Comprehension?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08232",
        "HTML": "https://arxiv.org/html/2507.08232v1",
        "PDF": "https://arxiv.org/pdf/2507.08232"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs as proxy students for Intelligent Tutoring Systems and piloting test questions, but the focus is primarily on evaluation and prompting methods rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.09512",
      "abstract": "Text-to-Speech (TTS) technology offers notable benefits, such as providing a voice for individuals with speech impairments, but it also facilitates the creation of audio deepfakes and spoofing attacks. AI-based detection methods can help mitigate these risks; however, the performance of such models is inherently dependent on the quality and diversity of their training data. Presently, the available datasets are heavily skewed towards English and Chinese audio, which limits the global applicability of these anti-spoofing systems.\n  To address this limitation, this paper presents the Multi-Language Audio Anti-Spoofing Dataset (MLAAD), version 7, created using 101 TTS models, comprising 52 different architectures, to generate 485.3 hours of synthetic voice in 40 different languages. We train and evaluate three state-of-the-art deepfake detection models with MLAAD and observe that it demonstrates superior performance over comparable datasets like InTheWild and Fake-Or-Real when used as a training resource. Moreover, compared to the renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary resource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately outperformed each other, each excelling on four datasets. By publishing MLAAD and making a trained model accessible via an interactive webserver, we aim to democratize anti-spoofing technology, making it accessible beyond the realm of specialists, and contributing to global efforts against audio spoofing and deepfakes.",
      "authors": [
        "Nicolas M. M\\\"uller",
        "Piotr Kawa",
        "Wei Herng Choong",
        "Edresson Casanova",
        "Eren G\\\"olge",
        "Thorsten M\\\"uller",
        "Piotr Syga",
        "Philip Sperl",
        "Konstantin B\\\"ottinger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-17T15:09:02+00:00",
          "link": "https://arxiv.org/abs/2401.09512v1",
          "size": "1721kb",
          "version": "v1"
        },
        {
          "date": "2024-02-28T19:07:09+00:00",
          "link": "https://arxiv.org/abs/2401.09512v2",
          "size": "1952kb",
          "version": "v2"
        },
        {
          "date": "2024-04-16T11:25:18+00:00",
          "link": "https://arxiv.org/abs/2401.09512v3",
          "size": "2184kb",
          "version": "v3"
        },
        {
          "date": "2024-09-24T07:44:30+00:00",
          "link": "https://arxiv.org/abs/2401.09512v4",
          "size": "2666kb",
          "version": "v4"
        },
        {
          "date": "2024-11-02T11:56:17+00:00",
          "link": "https://arxiv.org/abs/2401.09512v5",
          "size": "2514kb",
          "version": "v5"
        },
        {
          "date": "2025-04-26T11:19:21+00:00",
          "link": "https://arxiv.org/abs/2401.09512v6",
          "size": "2872kb",
          "version": "v6"
        },
        {
          "date": "2025-07-11T16:51:17+00:00",
          "link": "https://arxiv.org/abs/2401.09512v7",
          "size": "3239kb",
          "version": "v7"
        }
      ],
      "title": "MLAAD: The Multi-Language Audio Anti-Spoofing Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.09512",
        "HTML": "https://arxiv.org/html/2401.09512",
        "PDF": "https://arxiv.org/pdf/2401.09512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the creation of the Multi-Language Audio Anti-Spoofing Dataset (MLAAD), detailing the generation and processing of a large dataset for training language models for audio spoofing detection\u2014contributing directly to training data processing."
      },
      "datasets": [
        {
          "dataset_name": "mueller91/MLAAD",
          "downloads": "2978",
          "likes": "8",
          "link": "https://huggingface.co/datasets/mueller91/MLAAD"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08420",
      "abstract": "LiDAR-based 3D mapping suffers from cumulative drift causing global misalignment, particularly in GNSS-constrained environments. To address this, we propose a unified framework that fuses LiDAR, GNSS, and IMU data for high-resolution city-scale mapping. The method performs velocity-based temporal alignment using Dynamic Time Warping and refines GNSS and IMU signals via extended Kalman filtering. Local maps are built using Normal Distributions Transform-based registration and pose graph optimization with loop closure detection, while global consistency is enforced using GNSS-constrained anchors followed by fine registration of overlapping segments. We also introduce a large-scale multimodal dataset captured in Perth, Western Australia to facilitate future research in this direction. Our dataset comprises 144{,}000 frames acquired with a 128-channel Ouster LiDAR, synchronized RTK-GNSS trajectories, and MEMS-IMU measurements across 21 urban loops. To assess geometric consistency, we evaluated our method using alignment metrics based on road centerlines and intersections to capture both global and local accuracy. Our method reduces the average global alignment error from 3.32\\,m to 1.24\\,m, achieving a 61.4\\% improvement. The constructed high-fidelity map supports a wide range of applications, including smart city planning, geospatial data integration, infrastructure monitoring, and GPS-free navigation. Our method, and dataset together establish a new benchmark for evaluating 3D city mapping in GNSS-constrained environments. The dataset and code will be released publicly.",
      "authors": [
        "Haitian Wang",
        "Hezam Albaqami",
        "Xinyu Wang",
        "Muhammad Ibrahim",
        "Zainy M. Malakan",
        "Abdullah M. Algamdi",
        "Mohammed H. Alghamdi",
        "Ajmal Mian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:06:14+00:00",
          "link": "https://arxiv.org/abs/2507.08420v1",
          "size": "44737kb",
          "version": "v1"
        }
      ],
      "title": "LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to Construct 3D City Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08420",
        "HTML": "https://arxiv.org/html/2507.08420v1",
        "PDF": "https://arxiv.org/pdf/2507.08420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for 3D city-scale mapping using LiDAR, GNSS, and IMU data. The contribution is related to geospatial mapping and sensor alignment, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08505",
      "abstract": "Vision-Language Models (VLMs) offer promising capabilities for mobile devices, but their deployment faces significant challenges due to computational limitations and energy inefficiency, especially for real-time applications. This study provides a comprehensive survey of deployment frameworks for VLMs on mobile devices, evaluating llama.cpp, MLC-Imp, and mllm in the context of running LLaVA-1.5 7B, MobileVLM-3B, and Imp-v1.5 3B as representative workloads on a OnePlus 13R. Each deployment framework was evaluated on the OnePlus 13R while running VLMs, with measurements covering CPU, GPU, and NPU utilization, temperature, inference time, power consumption, and user experience. Benchmarking revealed critical performance bottlenecks across frameworks: CPU resources were consistently over-utilized during token generation, while GPU and NPU accelerators were largely unused. When the GPU was used, primarily for image feature extraction, it was saturated, leading to degraded device responsiveness. The study contributes framework-level benchmarks, practical profiling tools, and an in-depth analysis of hardware utilization bottlenecks, highlighting the consistent overuse of CPUs and the ineffective or unstable use of GPUs and NPUs in current deployment frameworks.",
      "authors": [
        "Pablo Robin Guerrero",
        "Yueyang Pan",
        "Sanidhya Kashyap"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:30:57+00:00",
          "link": "https://arxiv.org/abs/2507.08505v1",
          "size": "1576kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08505",
        "HTML": "https://arxiv.org/html/2507.08505v1",
        "PDF": "https://arxiv.org/pdf/2507.08505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the deployment of vision-language models on mobile devices, primarily discussing performance and hardware utilization without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2209.01619",
      "abstract": "Under what circumstances can a system be said to have beliefs and goals, and how do such agency-related features relate to its physical state? Recent work has proposed a notion of interpretation map, a function that maps the state of a system to a probability distribution representing its beliefs about an external world. Such a map is not completely arbitrary, as the beliefs it attributes to the system must evolve over time in a manner that is consistent with Bayes' theorem, and consequently the dynamics of a system constrain its possible interpretations. Here we build on this approach, proposing a notion of interpretation not just in terms of beliefs but in terms of goals and actions. To do this we make use of the existing theory of partially observable Markov processes (POMDPs): we say that a system can be interpreted as a solution to a POMDP if it not only admits an interpretation map describing its beliefs about the hidden state of a POMDP but also takes actions that are optimal according to its belief state. An agent is then a system together with an interpretation of this system as a POMDP solution. Although POMDPs are not the only possible formulation of what it means to have a goal, this nevertheless represents a step towards a more general formal definition of what it means for a system to be an agent.",
      "authors": [
        "Martin Biehl and Nathaniel Virgo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2022-09-04T13:40:33+00:00",
          "link": "https://arxiv.org/abs/2209.01619v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:04:40+00:00",
          "link": "https://arxiv.org/abs/2209.01619v2",
          "size": "44kb",
          "version": "v2"
        }
      ],
      "title": "Interpreting systems as solving POMDPs: a step towards a formal understanding of agency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.01619",
        "HTML": "https://arxiv.org/html/2209.01619v2",
        "PDF": "https://arxiv.org/pdf/2209.01619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses interpreting systems as solving POMDPs and understanding of agency, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07362",
      "abstract": "SRL, defined as learners' ability to systematically plan, monitor, and regulate their learning activities, is crucial for sustained academic achievement and lifelong learning competencies. Emerging Artificial Intelligence (AI) developments profoundly influence SRL interactions by potentially either diminishing or strengthening learners' opportunities to exercise their own regulatory skills. Recent literature emphasizes a balanced approach termed Hybrid Human-AI Regulated Learning (HHAIRL), in which AI provides targeted, timely scaffolding while preserving the learners' role as active decision-makers and reflective monitors of their learning process. Nevertheless, existing digital tools frequently fall short, lacking adaptability, focusing narrowly on isolated SRL phases, and insufficiently support meaningful human-AI interactions. In response, this paper introduces the enhanced FLoRA Engine, which incorporates advanced Generative Artificial Intelligence (GenAI) features and state-of-the-art learning analytics, explicitly grounded in SRL and HHAIRL theories. The FLoRA Engine offers instrumentation tools such as collaborative writing, multi-agents chatbot, and detailed learning trace logging to support dynamic, adaptive scaffolding tailored to individual needs in real time. We further present a summary of several research studies that provide the validations for and illustrate how these instrumentation tools can be utilized in real-world educational and experimental contexts. These studies demonstrate the effectiveness of FLoRA Engine in fostering SRL and HHAIRL, providing both theoretical insights and practical solutions for the future of AI-enhanced learning context.",
      "authors": [
        "Xinyu Li and Tongguang Li and Lixiang Yan and Yuheng Li and Linxuan Zhao and Mladen Rakovi\\'c and Inge Molenaar and Dragan Ga\\v{s}evi\\'c and Yizhou Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:11:52+00:00",
          "link": "https://arxiv.org/abs/2507.07362v1",
          "size": "16820kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:10:44+00:00",
          "link": "https://arxiv.org/abs/2507.07362v2",
          "size": "16820kb",
          "version": "v2"
        }
      ],
      "title": "FLoRA: An Advanced AI-Powered Engine to Facilitate Hybrid Human-AI Regulated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07362",
        "HTML": "https://arxiv.org/html/2507.07362v2",
        "PDF": "https://arxiv.org/pdf/2507.07362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the development of an AI-powered engine for facilitating learning in educational contexts but does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07879",
      "abstract": "Deep learning-based machine listening is broadening the scope of industrial acoustic analysis for applications like anomaly detection and predictive maintenance, thereby improving manufacturing efficiency and reliability. Nevertheless, its reliance on large, task-specific annotated datasets for every new task limits widespread implementation on shop floors. While emerging sound foundation models aim to alleviate data dependency, they are too large and computationally expensive, requiring cloud infrastructure or high-end hardware that is impractical for on-site, real-time deployment. We address this gap with LISTEN (Lightweight Industrial Sound-representable Transformer for Edge Notification), a kilobyte-sized industrial sound foundation model. Using knowledge distillation, LISTEN runs in real-time on low-cost edge devices. On benchmark downstream tasks, it performs nearly identically to its much larger parent model, even when fine-tuned with minimal datasets and training resource. Beyond the model itself, we demonstrate its real-world utility by integrating LISTEN into a complete machine monitoring framework on an edge device with an Industrial Internet of Things (IIoT) sensor and system, validating its performance and generalization capabilities on a live manufacturing shop floor.",
      "authors": [
        "Changheon Han",
        "Yun Seok Kang",
        "Yuseop Sim",
        "Hyung Wook Park",
        "Martin Byung-Guk Jun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:02:50+00:00",
          "link": "https://arxiv.org/abs/2507.07879v1",
          "size": "6370kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:50:18+00:00",
          "link": "https://arxiv.org/abs/2507.07879v2",
          "size": "6396kb",
          "version": "v2"
        }
      ],
      "title": "LISTEN: Lightweight Industrial Sound-representable Transformer for Edge Notification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07879",
        "PDF": "https://arxiv.org/pdf/2507.07879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a lightweight model for industrial sound analysis using knowledge distillation with minimal datasets for real-time edge deployment. It does not contribute substantially to LLM training data collection, processing, or creation, as its primary focus is on model efficiency and real-world application."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08203",
      "abstract": "Generative Large Language Models (LLMs)inevitably produce untruthful responses. Accurately predicting the truthfulness of these outputs is critical, especially in high-stakes settings. To accelerate research in this domain and make truthfulness prediction methods more accessible, we introduce TruthTorchLM an open-source, comprehensive Python library featuring over 30 truthfulness prediction methods, which we refer to as Truth Methods. Unlike existing toolkits such as Guardrails, which focus solely on document-grounded verification, or LM-Polygraph, which is limited to uncertainty-based methods, TruthTorchLM offers a broad and extensible collection of techniques. These methods span diverse tradeoffs in computational cost, access level (e.g., black-box vs white-box), grounding document requirements, and supervision type (self-supervised or supervised). TruthTorchLM is seamlessly compatible with both HuggingFace and LiteLLM, enabling support for locally hosted and API-based models. It also provides a unified interface for generation, evaluation, calibration, and long-form truthfulness prediction, along with a flexible framework for extending the library with new methods. We conduct an evaluation of representative truth methods on three datasets, TriviaQA, GSM8K, and FactScore-Bio. The code is available at https://github.com/Ybakman/TruthTorchLM",
      "authors": [
        "Duygu Nur Yaldiz",
        "Yavuz Faruk Bakman",
        "Sungmin Kang",
        "Alperen \\\"Ozi\\c{s}",
        "Hayrettin Eren Yildiz",
        "Mitash Ashish Shah",
        "Zhiqi Huang",
        "Anoop Kumar",
        "Alfy Samuel",
        "Daben Liu",
        "Sai Praneeth Karimireddy",
        "Salman Avestimehr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:23:51+00:00",
          "link": "https://arxiv.org/abs/2507.08203v1",
          "size": "887kb",
          "version": "v1"
        }
      ],
      "title": "TruthTorchLM: A Comprehensive Library for Predicting Truthfulness in LLM Outputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08203",
        "HTML": "https://arxiv.org/html/2507.08203v1",
        "PDF": "https://arxiv.org/pdf/2507.08203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "TruthTorchLM is a library aimed at predicting truthfulness in LLM outputs, evaluating methods on existing datasets. It doesn't focus on training-data processing but rather evaluation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08384",
      "abstract": "Real-world applications of computer vision in the humanities require algorithms to be robust against artistic abstraction, peripheral objects, and subtle differences between fine-grained target classes. Existing datasets provide instance-level annotations on artworks but are generally biased towards the image centre and limited with regard to detailed object classes. The proposed ODOR dataset fills this gap, offering 38,116 object-level annotations across 4712 images, spanning an extensive set of 139 fine-grained categories. Conducting a statistical analysis, we showcase challenging dataset properties, such as a detailed set of categories, dense and overlapping objects, and spatial distribution over the whole image canvas. Furthermore, we provide an extensive baseline analysis for object detection models and highlight the challenging properties of the dataset through a set of secondary studies. Inspiring further research on artwork object detection and broader visual cultural heritage studies, the dataset challenges researchers to explore the intersection of object recognition and smell perception.",
      "authors": [
        "Mathias Zinnen",
        "Prathmesh Madhu",
        "Inger Leemans",
        "Peter Bell",
        "Azhar Hussian",
        "Hang Tran",
        "Ali H\\\"urriyeto\\u{g}lu",
        "Andreas Maier",
        "Vincent Christlein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:58:21+00:00",
          "link": "https://arxiv.org/abs/2507.08384v1",
          "size": "11842kb",
          "version": "v1"
        }
      ],
      "title": "Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08384",
        "HTML": "https://arxiv.org/html/2507.08384v1",
        "PDF": "https://arxiv.org/pdf/2507.08384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes the ODOR dataset with detailed data processing steps, including object-level annotations across images and statistical analysis of dataset properties, contributing significantly to data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09250",
      "abstract": "Few-shot class-incremental learning (FSCIL) aims to continually learn new classes from only a few samples without forgetting previous ones, requiring intelligent agents to adapt to dynamic environments. FSCIL combines the characteristics and challenges of class-incremental learning and few-shot learning: (i) Current classes occupy the entire feature space, which is detrimental to learning new classes. (ii) The small number of samples in incremental rounds is insufficient for fully training. In existing mainstream virtual class methods, for addressing the challenge (i), they attempt to use virtual classes as placeholders. However, new classes may not necessarily align with the virtual classes. For the challenge (ii), they replace trainable fully connected layers with Nearest Class Mean (NCM) classifiers based on cosine similarity, but NCM classifiers do not account for sample imbalance issues. To address these issues in previous methods, we propose the class-center guided embedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning framework, which provides balanced space for all classes and leverages norm differences caused by sample imbalance to enhance classification criteria. Specifically, for challenge (i), SAAN divides the feature space into multiple subspaces and allocates a dedicated subspace for each session by guiding samples with the pre-set category centers. For challenge (ii), SAAN establishes a norm distribution for each class and generates angle-norm joint logits. Experiments demonstrate that SAAN can achieve state-of-the-art performance and it can be directly embedded into other SOTA methods as a plug-in, further enhancing their performance.",
      "authors": [
        "Dunwei Tu",
        "Huiyu Yi",
        "Tieyi Zhang",
        "Ruotong Li",
        "Furao Shen",
        "Jian Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T07:31:12+00:00",
          "link": "https://arxiv.org/abs/2411.09250v1",
          "size": "8919kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T08:10:28+00:00",
          "link": "https://arxiv.org/abs/2411.09250v2",
          "size": "9690kb",
          "version": "v2"
        }
      ],
      "title": "Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09250",
        "HTML": "https://arxiv.org/html/2411.09250v2",
        "PDF": "https://arxiv.org/pdf/2411.09250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for few-shot class-incremental learning and does not discuss any aspect of training data processing or dataset construction for LLMs."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Few-Shot Class-Incremental Learning",
        "Few-Shot Learning",
        "Incremental Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17372",
      "abstract": "Search and rescue (SAR) missions require reliable search methods to locate survivors, especially in challenging or inaccessible environments. This is why introducing unmanned aerial vehicles (UAVs) can be of great help to enhance the efficiency of SAR missions while simultaneously increasing the safety of everyone involved in the mission. Motivated by this, we design and experiment with autonomous UAV search for humans in a Mediterranean karst environment. The UAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic control method according to known probability density and detection function. The implemented sensing framework consists of a probabilistic search model, motion control system, and computer vision object detection. It enables calculation of the probability of the target being detected in the SAR mission, and this paper focuses on experimental validation of proposed probabilistic framework and UAV control. The uniform probability density to ensure the even probability of finding the targets in the desired search area is achieved by assigning suitably thought-out tasks to 78 volunteers. The detection model is based on YOLO and trained with a previously collected ortho-photo image database. The experimental search is carefully planned and conducted, while as many parameters as possible are recorded. The thorough analysis consists of the motion control system, object detection, and the search validation. The assessment of the detection and search performance provides strong indication that the designed detection model in the UAV control algorithm is aligned with real-world results.",
      "authors": [
        "Stella Dumen\\v{c}i\\'c",
        "Luka Lan\\v{c}a",
        "Karlo Jakac and Stefan Ivi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T17:53:54+00:00",
          "link": "https://arxiv.org/abs/2502.17372v1",
          "size": "1702kb",
          "version": "v1"
        }
      ],
      "title": "Experimental validation of UAV search and detection system in real wilderness environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17372",
        "PDF": "https://arxiv.org/pdf/2502.17372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on UAV search and detection systems using computer vision and probabilistic frameworks, with no mention of LLM training data processing."
      },
      "tasks": [
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08336",
      "abstract": "Training text rerankers is crucial for information retrieval. Two primary strategies are widely used: contrastive learning (optimizing directly on ground-truth labels) and knowledge distillation (transferring knowledge from a larger reranker). While both have been studied in the literature, a clear comparison of their effectiveness for training cross-encoder rerankers under practical conditions is needed.\n  This paper empirically compares these strategies by training rerankers of different sizes and architectures using both methods on the same data, with a strong contrastive learning model acting as the distillation teacher. Our results show that knowledge distillation generally yields better in-domain and out-of-domain ranking performance than contrastive learning when distilling from a larger teacher model. This finding is consistent across student model sizes and architectures. However, distilling from a teacher of the same capacity does not provide the same advantage, particularly for out-of-domain tasks. These findings offer practical guidance for choosing a training strategy based on available teacher models. Therefore, we recommend using knowledge distillation to train smaller rerankers if a larger, more powerful teacher is accessible; in its absence, contrastive learning provides a strong and more reliable alternative otherwise.",
      "authors": [
        "Zhichao Xu",
        "Zhiqi Huang",
        "Shengyao Zhuang",
        "Ashim Gupta",
        "Vivek Srikumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:28:35+00:00",
          "link": "https://arxiv.org/abs/2507.08336v1",
          "size": "192kb",
          "version": "v1"
        }
      ],
      "title": "Distillation versus Contrastive Learning: How to Train Your Rerankers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08336",
        "HTML": "https://arxiv.org/html/2507.08336v1",
        "PDF": "https://arxiv.org/pdf/2507.08336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper compares knowledge distillation and contrastive learning for training text rerankers in information retrieval, not in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08403",
      "abstract": "Artificial Intelligence/Machine Learning (AI/ML) has become the most certain and prominent feature of 6G mobile networks. Unlike 5G, where AI/ML was not natively integrated but rather an add-on feature over existing architecture, 6G shall incorporate AI from the onset to address its complexity and support ubiquitous AI applications. Based on our extensive mobile network operation and standardization experience from 2G to 5G, this paper explores the design and standardization principles of AI-Native radio access networks (RAN) for 6G, with a particular focus on its critical Day 1 architecture, functionalities and capabilities. We investigate the framework of AI-Native RAN and present its three essential capabilities to shed some light on the standardization direction; namely, AI-driven RAN processing/optimization/automation, reliable AI lifecycle management (LCM), and AI-as-a-Service (AIaaS) provisioning. The standardization of AI-Native RAN, in particular the Day 1 features, including an AI-Native 6G RAN architecture, were proposed. For validation, a large-scale field trial with over 5000 5G-A base stations have been built and delivered significant improvements in average air interface latency, root cause identification, and network energy consumption with the proposed architecture and the supporting AI functions. This paper aims to provide a Day 1 framework for 6G AI-Native RAN standardization design, balancing technical innovation with practical deployment.",
      "authors": [
        "Nan Li",
        "Qi Sun",
        "Lehan Wang",
        "Xiaofei Xu",
        "Jinri Huang",
        "Chunhui Liu",
        "Jing Gao",
        "Yuhong Huang",
        "and Chih-Lin I"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:21:08+00:00",
          "link": "https://arxiv.org/abs/2507.08403v1",
          "size": "2644kb",
          "version": "v1"
        }
      ],
      "title": "Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08403",
        "HTML": "https://arxiv.org/html/2507.08403v1",
        "PDF": "https://arxiv.org/pdf/2507.08403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on AI/ML integration in 6G networks and RAN standardization, discussing AI lifecycle management and architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08675",
      "abstract": "This paper introduces LIMITER, a gamified digital musical instrument for harnessing and performing microtonal and justly intonated sounds. While microtonality in Western music remains a niche and esoteric system that can be difficult both to conceptualize and to perform with, LIMITER presents a novel, easy to pickup interface that utilizes color, geometric transformations, and game-like controls to create a simpler inlet into utilizing these sounds as a means of expression. We report on the background of the development of LIMITER, as well as explain the underlying musical and engineering systems that enable its function. Additionally, we offer a discussion and preliminary evaluation of the creativity-enhancing effects of the interface.",
      "authors": [
        "Antonis Christou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:15:25+00:00",
          "link": "https://arxiv.org/abs/2507.08675v1",
          "size": "19653kb",
          "version": "v1"
        }
      ],
      "title": "LIMITER: A Gamified Interface for Harnessing Just Intonation Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08675",
        "HTML": "https://arxiv.org/html/2507.08675v1",
        "PDF": "https://arxiv.org/pdf/2507.08675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a musical instrument interface, which is unrelated to the topic of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.14192",
      "abstract": "Consider a linguistic structure formed by $n$ elements, for instance, subject, direct object and verb ($n=3$) or subject, direct object, indirect object and verb ($n=4$). We investigate whether the frequency of the $n!$ possible orders is constrained by two principles. First, entropy minimization, a principle that has been suggested to shape natural communication systems at distinct levels of organization. Second, swap distance minimization, namely a preference for word orders that require fewer swaps of adjacent elements to be produced from a source order. We present average swap distance, a novel score for research on swap distance minimization. We find strong evidence of pressure for entropy minimization and swap distance minimization with respect to a die rolling experiment in distinct linguistic structures with $n=3$ or $n=4$. Evidence with respect to a Polya urn process is strong for $n=4$ but weaker for $n=3$. We still find evidence consistent with the action of swap distance minimization when word order frequencies are shuffled, indicating that swap distance minimization effects are beyond pressure to reduce word order entropy.",
      "authors": [
        "V\\'ictor Franco-S\\'anchez",
        "Arnau Mart\\'i-Llobet and Ramon Ferrer-i-Cancho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-22T14:01:09+00:00",
          "link": "https://arxiv.org/abs/2404.14192v1",
          "size": "234kb",
          "version": "v1"
        },
        {
          "date": "2024-04-28T17:38:51+00:00",
          "link": "https://arxiv.org/abs/2404.14192v2",
          "size": "234kb",
          "version": "v2"
        },
        {
          "date": "2024-05-25T14:10:05+00:00",
          "link": "https://arxiv.org/abs/2404.14192v3",
          "size": "248kb",
          "version": "v3"
        },
        {
          "date": "2024-12-21T15:47:15+00:00",
          "link": "https://arxiv.org/abs/2404.14192v4",
          "size": "245kb",
          "version": "v4"
        },
        {
          "date": "2025-07-11T08:32:31+00:00",
          "link": "https://arxiv.org/abs/2404.14192v5",
          "size": "259kb",
          "version": "v5"
        }
      ],
      "title": "Swap distance minimization beyond entropy minimization in word order variation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14192",
        "HTML": "https://arxiv.org/html/2404.14192v5",
        "PDF": "https://arxiv.org/pdf/2404.14192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores principles affecting word order variation in linguistic structures, such as entropy minimization and swap distance minimization, but does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.18607",
      "abstract": "Task Arithmetic is a model merging technique that enables the combination of multiple models' capabilities into a single model through simple arithmetic in the weight space, without the need for additional fine-tuning or access to the original training data. However, the factors that determine the success of Task Arithmetic remain unclear. In this paper, we examine Task Arithmetic for multi-task learning by framing it as a one-shot Federated Learning problem. We demonstrate that Task Arithmetic is mathematically equivalent to the commonly used algorithm in Federated Learning, called Federated Averaging (FedAvg). By leveraging well-established theoretical results from FedAvg, we identify two key factors that impact the performance of Task Arithmetic: data heterogeneity and training heterogeneity. To mitigate these challenges, we adapt several algorithms from Federated Learning to improve the effectiveness of Task Arithmetic. Our experiments demonstrate that applying these algorithms can often significantly boost performance of the merged model compared to the original Task Arithmetic approach. This work bridges Task Arithmetic and Federated Learning, offering new theoretical perspectives on Task Arithmetic and improved practical methodologies for model merging.",
      "authors": [
        "Zhixu Silvia Tao",
        "Ian Mason",
        "Sanjeev Kulkarni",
        "Xavier Boix"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T18:53:41+00:00",
          "link": "https://arxiv.org/abs/2411.18607v1",
          "size": "82kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:24:39+00:00",
          "link": "https://arxiv.org/abs/2411.18607v2",
          "size": "106kb",
          "version": "v2"
        }
      ],
      "title": "Task Arithmetic Through The Lens Of One-Shot Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18607",
        "HTML": "https://arxiv.org/html/2411.18607v2",
        "PDF": "https://arxiv.org/pdf/2411.18607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines Task Arithmetic for model merging and federated learning improvements, without discussing LLM training data processing or any data engineering operations."
      },
      "tasks": [
        "Federated Learning",
        "Multi-Task Learning",
        "Task Arithmetic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08238",
      "abstract": "Human state detection and behavior prediction have seen significant advancements with the rise of machine learning and multimodal sensing technologies. However, predicting prosocial behavior intentions in mobility scenarios, such as helping others on the road, is an underexplored area. Current research faces a major limitation. There are no large, labeled datasets available for prosocial behavior, and small-scale datasets make it difficult to train deep-learning models effectively. To overcome this, we propose a self-supervised learning approach that harnesses multi-modal data from existing physiological and behavioral datasets. By pre-training our model on diverse tasks and fine-tuning it with a smaller, manually labeled prosocial behavior dataset, we significantly enhance its performance. This method addresses the data scarcity issue, providing a more effective benchmark for prosocial behavior prediction, and offering valuable insights for improving intelligent vehicle systems and human-machine interaction.",
      "authors": [
        "Abinay Reddy Naini",
        "Zhaobo K. Zheng",
        "Teruhisa Misu",
        "and Kumar Akash"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:49:46+00:00",
          "link": "https://arxiv.org/abs/2507.08238v1",
          "size": "22112kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Learning-Based Multimodal Prediction on Prosocial Behavior Intentions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08238",
        "HTML": "https://arxiv.org/html/2507.08238v1",
        "PDF": "https://arxiv.org/pdf/2507.08238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Mentioning pre-training and fine-tuning with existing datasets in a self-supervised approach, but focuses on model behavior prediction rather than LLM training data handling or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08350",
      "abstract": "Large language models (LLMs) are increasingly used to support creative tasks such as research idea generation. While recent work has shown that structured dialogues between LLMs can improve the novelty and feasibility of generated ideas, the optimal design of such interactions remains unclear. In this study, we conduct a comprehensive analysis of multi-agent LLM dialogues for scientific ideation. We compare different configurations of agent roles, number of agents, and dialogue depth to understand how these factors influence the novelty and feasibility of generated ideas. Our experimental setup includes settings where one agent generates ideas and another critiques them, enabling iterative improvement. Our results show that enlarging the agent cohort, deepening the interaction depth, and broadening agent persona heterogeneity each enrich the diversity of generated ideas. Moreover, specifically increasing critic-side diversity within the ideation-critique-revision loop further boosts the feasibility of the final proposals. Our findings offer practical guidelines for building effective multi-agent LLM systems for scientific ideation. Our code is available at https://github.com/g6000/MultiAgent-Research-Ideator.",
      "authors": [
        "Keisuke Ueda",
        "Wataru Hirota",
        "Takuto Asakura",
        "Takahiro Omi",
        "Kosuke Takahashi",
        "Kosuke Arima and Tatsuya Ishigaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:53:46+00:00",
          "link": "https://arxiv.org/abs/2507.08350v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Design of Multi-Agent LLM Dialogues for Research Ideation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08350",
        "HTML": "https://arxiv.org/html/2507.08350v1",
        "PDF": "https://arxiv.org/pdf/2507.08350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses structuring dialogues between LLMs for research ideation, but it primarily focuses on dialogue setup and agent configuration rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08443",
      "abstract": "Retrieval-Augmented Generation (RAG) enhances language models by grounding responses in external information, yet explainability remains a critical challenge, particularly when retrieval relies on unstructured text. Knowledge graphs (KGs) offer a solution by introducing structured, semantically rich representations of entities and their relationships, enabling transparent retrieval paths and interpretable reasoning. In this work, we present KGRAG-Ex, a RAG system that improves both factual grounding and explainability by leveraging a domain-specific KG constructed via prompt-based information extraction. Given a user query, KGRAG-Ex identifies relevant entities and semantic paths in the graph, which are then transformed into pseudo-paragraphs: natural language representations of graph substructures that guide corpus retrieval. To improve interpretability and support reasoning transparency, we incorporate perturbation-based explanation methods that assess the influence of specific KG-derived components on the generated answers. We conduct a series of experiments to analyze the sensitivity of the system to different perturbation methods, the relationship between graph component importance and their structural positions, the influence of semantic node types, and how graph metrics correspond to the influence of components within the explanations process.",
      "authors": [
        "Georgios Balanos",
        "Evangelos Chasanis",
        "Konstantinos Skianis",
        "Evaggelia Pitoura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:35:13+00:00",
          "link": "https://arxiv.org/abs/2507.08443v1",
          "size": "696kb",
          "version": "v1"
        }
      ],
      "title": "KGRAG-Ex: Explainable Retrieval-Augmented Generation with Knowledge Graph-based Perturbations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08443",
        "HTML": "https://arxiv.org/html/2507.08443v1",
        "PDF": "https://arxiv.org/pdf/2507.08443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancements in retrieval-augmented generation using knowledge graphs. It partially touches upon data processing by constructing a domain-specific KG, but does not focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08567",
      "abstract": "We introduce the Autoregressive Block-Based Iterative Encoder (AbbIE), a novel recursive generalization of the encoder-only Transformer architecture, which achieves better perplexity than a standard Transformer and allows for the dynamic scaling of compute resources at test time. This simple, recursive approach is a complement to scaling large language model (LLM) performance through parameter and token counts. AbbIE performs its iterations in latent space, but unlike latent reasoning models, does not require a specialized dataset or training protocol. We show that AbbIE upward generalizes (ability to generalize to arbitrary iteration lengths) at test time by only using 2 iterations during train time, far outperforming alternative iterative methods. AbbIE's ability to scale its computational expenditure based on the complexity of the task gives it an up to \\textbf{12\\%} improvement in zero-shot in-context learning tasks versus other iterative and standard methods and up to 5\\% improvement in language perplexity. The results from this study open a new avenue to Transformer performance scaling. We perform all of our evaluations on model sizes up to 350M parameters.",
      "authors": [
        "Preslav Aleksandrov",
        "Meghdad Kurmanji",
        "Fernando Garcia Redondo",
        "David O'Shea",
        "William Shen",
        "Alex Iacob",
        "Lorenzo Sani",
        "Xinchi Qiu",
        "Nicola Cancedda",
        "Nicholas D. Lane"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:11:11+00:00",
          "link": "https://arxiv.org/abs/2507.08567v1",
          "size": "250kb",
          "version": "v1"
        }
      ],
      "title": "AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08567",
        "HTML": "https://arxiv.org/html/2507.08567v1",
        "PDF": "https://arxiv.org/pdf/2507.08567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "AbbIE is proposed as a recursive transformer architecture for performance scaling, which does not involve data processing techniques or operations for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08697",
      "abstract": "The domain-consistent adoption of artificial intelligence (AI) remains low in thermal power plants due to the black-box nature of AI algorithms and low representation of domain knowledge in conventional data-centric analytics. In this paper, we develop a MAhalanobis Distance-based OPTimization (MAD-OPT) framework that incorporates the Mahalanobis distance-based constraint to introduce domain knowledge into data-centric analytics. The developed MAD-OPT framework is applied to maximize thermal efficiency and minimize turbine heat rate for a 395 MW capacity gas turbine system. We demonstrate that the MAD-OPT framework can estimate domain-informed optimal process conditions under different ambient conditions, and the optimal solutions are found to be robust as evaluated by Monte Carlo simulations. We also apply the MAD-OPT framework to estimate optimal process conditions beyond the design power generation limit of the gas turbine system, and have found comparable results with the actual data of the power plant. We demonstrate that implementing data-centric optimization analytics without incorporating domain-informed constraints may provide ineffective solutions that may not be implementable in the real operation of the gas turbine system. This research advances the integration of the data-driven domain knowledge into machine learning-powered analytics that enhances the domain-informed operation excellence and paves the way for safe AI adoption in thermal power systems.",
      "authors": [
        "Waqar Muhammad Ashraf",
        "Amir H. Keshavarzzadeh",
        "Abdulelah S. Alshehri",
        "Abdulrahman bin Jumah",
        "Ramit Debnath",
        "and Vivek Dua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:50:23+00:00",
          "link": "https://arxiv.org/abs/2507.08697v1",
          "size": "17989kb",
          "version": "v1"
        }
      ],
      "title": "Domain-Informed Operation Excellence of Gas Turbine System with Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08697",
        "HTML": "https://arxiv.org/html/2507.08697v1",
        "PDF": "https://arxiv.org/pdf/2507.08697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It focuses on machine learning optimization for a gas turbine system with domain-informed AI integration, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08745",
      "abstract": "Pattern set mining, which is the task of finding a good set of patterns instead of all patterns, is a fundamental problem in data mining. Many different definitions of what constitutes a good set have been proposed in recent years. In this paper, we consider the reconstruction error as a proxy measure for the goodness of the set, and concentrate on the adjacent problem of how to find a good set efficiently. We propose a method based on bottom-k hashing for efficiently selecting the set and extend the method for the common case where the patterns might only appear in approximate form in the data. Our approach has applications in tiling databases, Boolean matrix factorization, and redescription mining, among others. We show that our hashing-based approach is significantly faster than the standard greedy algorithm while obtaining almost equally good results in both synthetic and real-world data sets.",
      "authors": [
        "Maiju Karjalainen",
        "Pauli Miettinen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:55:25+00:00",
          "link": "https://arxiv.org/abs/2507.08745v1",
          "size": "87kb",
          "version": "v1"
        }
      ],
      "title": "Hashing for Fast Pattern Set Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08745",
        "HTML": "https://arxiv.org/html/2507.08745v1",
        "PDF": "https://arxiv.org/pdf/2507.08745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on efficient pattern set mining through hashing methods, which is a fundamental problem in data mining, but does not discuss LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08776",
      "abstract": "This paper proposes a neural rendering approach that represents a scene as \"compressed light-field tokens (CLiFTs)\", retaining rich appearance and geometric information of a scene. CLiFT enables compute-efficient rendering by compressed tokens, while being capable of changing the number of tokens to represent a scene or render a novel view with one trained network. Concretely, given a set of images, multi-view encoder tokenizes the images with the camera poses. Latent-space K-means selects a reduced set of rays as cluster centroids using the tokens. The multi-view ``condenser'' compresses the information of all the tokens into the centroid tokens to construct CLiFTs. At test time, given a target view and a compute budget (i.e., the number of CLiFTs), the system collects the specified number of nearby tokens and synthesizes a novel view using a compute-adaptive renderer. Extensive experiments on RealEstate10K and DL3DV datasets quantitatively and qualitatively validate our approach, achieving significant data reduction with comparable rendering quality and the highest overall rendering score, while providing trade-offs of data size, rendering quality, and rendering speed.",
      "authors": [
        "Zhengqing Wang",
        "Yuefan Wu",
        "Jiacheng Chen",
        "Fuyang Zhang",
        "Yasutaka Furukawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:38:52+00:00",
          "link": "https://arxiv.org/abs/2507.08776v1",
          "size": "10091kb",
          "version": "v1"
        }
      ],
      "title": "CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08776",
        "HTML": "https://arxiv.org/html/2507.08776v1",
        "PDF": "https://arxiv.org/pdf/2507.08776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on neural rendering techniques using compressed light-field tokens. It does not address the processing of LLM training data or data engineering methods related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.12682",
      "abstract": "Quantum stabilizer codes often struggle with syndrome errors due to measurement imperfections. Typically, multiple rounds of syndrome extraction are employed to ensure reliable error information. In this paper, we consider phenomenological decoding problems, where data qubit errors may occur between extractions, and each measurement can be faulty. We introduce generalized quantum data-syndrome codes along with a generalized check matrix that integrates both quaternary and binary alphabets to represent diverse error sources. This results in a Tanner graph with mixed variable nodes, enabling the design of belief propagation (BP) decoding algorithms that effectively handle phenomenological errors. Importantly, our BP decoders are applicable to general sparse quantum codes. Through simulations, we achieve an error threshold of more than 3\\% for quantum memory protected by rotated toric codes, using solely BP without post-processing. Our results indicate that $d$ rounds of syndrome extraction are sufficient for a toric code of distance $d$. We observe that at high error rates, fewer rounds of syndrome extraction tend to perform better, while more rounds improve performance at lower error rates. Additionally, we propose a method to construct effective redundant stabilizer checks for single-shot error correction. Our simulations show that BP decoding remains highly effective even with a high syndrome error rate.",
      "authors": [
        "Kao-Yueh Kuo and Ching-Yi Lai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-19T12:23:05+00:00",
          "link": "https://arxiv.org/abs/2310.12682v1",
          "size": "989kb",
          "version": "v1"
        },
        {
          "date": "2025-01-12T13:30:50+00:00",
          "link": "https://arxiv.org/abs/2310.12682v2",
          "size": "982kb",
          "version": "v2"
        }
      ],
      "title": "Generalized quantum data-syndrome codes and belief propagation decoding for phenomenological noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.12682",
        "HTML": "https://arxiv.org/html/2310.12682",
        "PDF": "https://arxiv.org/pdf/2310.12682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on quantum data-syndrome codes for error correction in quantum computing, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01635",
      "abstract": "Temporal alignment of multiple signals through time warping is crucial in many fields, such as classification within speech recognition or robot motion learning. Almost all related works are limited to data in Euclidean space. Although an attempt was made in 2011 to adapt this concept to unit quaternions, a general extension to Riemannian manifolds remains absent. Given its importance for numerous applications in robotics and beyond, we introduce Riemannian Time Warping (RTW). This novel approach efficiently aligns multiple signals by considering the geometric structure of the Riemannian manifold in which the data is embedded. Extensive experiments on synthetic and real-world data, including tests with an LBR iiwa robot, demonstrate that RTW consistently outperforms state-of-the-art baselines in both averaging and classification tasks.",
      "authors": [
        "Julian Richter",
        "Christopher Erd\\\"os",
        "Christian Scheurer",
        "Jochen J. Steil",
        "Niels Dehio"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T13:12:02+00:00",
          "link": "https://arxiv.org/abs/2506.01635v1",
          "size": "1408kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:00:27+00:00",
          "link": "https://arxiv.org/abs/2506.01635v2",
          "size": "1407kb",
          "version": "v2"
        }
      ],
      "title": "Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01635",
        "HTML": "https://arxiv.org/html/2506.01635v2",
        "PDF": "https://arxiv.org/pdf/2506.01635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Riemannian Time Warping for aligning temporal signals, which does not involve LLM training data processing."
      },
      "tasks": [
        "Multiple Sequence Alignment",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08235",
      "abstract": "Smart buildings generate vast streams of sensor and control data, but facility managers often lack clear explanations for anomalous energy usage. We propose InsightBuild, a two-stage framework that integrates causality analysis with a fine-tuned large language model (LLM) to provide human-readable, causal explanations of energy consumption patterns. First, a lightweight causal inference module applies Granger causality tests and structural causal discovery on building telemetry (e.g., temperature, HVAC settings, occupancy) drawn from Google Smart Buildings and Berkeley Office datasets. Next, an LLM, fine-tuned on aligned pairs of sensor-level causes and textual explanations, receives as input the detected causal relations and generates concise, actionable explanations. We evaluate InsightBuild on two real-world datasets (Google: 2017-2022; Berkeley: 2018-2020), using expert-annotated ground-truth causes for a held-out set of anomalies. Our results demonstrate that combining explicit causal discovery with LLM-based natural language generation yields clear, precise explanations that assist facility managers in diagnosing and mitigating energy inefficiencies.",
      "authors": [
        "Pinaki Prasad Guha Neogi",
        "Ahmad Mohammadshirazi",
        "Rajiv Ramnath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:45:16+00:00",
          "link": "https://arxiv.org/abs/2507.08235v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08235",
        "HTML": "https://arxiv.org/html/2507.08235v1",
        "PDF": "https://arxiv.org/pdf/2507.08235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper focuses on causal reasoning in energy efficiency using LLMs, mentioning fine-tuning on data sets, but does not focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08383",
      "abstract": "Representation of inductive coupling lines with conventional static phasors is the main reason of inadequacy of the existing phasors based simplified stability analysis methods for microgrids with inductive coupling lines. In the literature, dynamic phasors have been proposed for the dynamic modelling of inductive lines to conserve the simplified structure of the analysis method. In this study a generalized stability analysis method for LV AC microgrids, composed of droop controlled inverters, is presented. The proposed analysis method is based on the inclusion of dynamic phasors for inductive coupling lines into the existing phasors based stability analysis method. The results show that the stability analysis method with dynamic phasors successfully predicts the instability boundaries of LV AC microgrids.",
      "authors": [
        "B\\\"ulent Da\\u{g}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.08383v1",
          "size": "1282kb",
          "version": "v1"
        }
      ],
      "title": "A Generalized Stability Analysis Method with Dynamic Phasors for LV AC Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08383",
        "PDF": "https://arxiv.org/pdf/2507.08383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses stability analysis methods for LV AC microgrids using dynamic phasors and does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08017",
      "abstract": "Recent findings in mechanistic interpretability (MI), the field probing the inner workings of Large Language Models (LLMs), challenge the view that these models rely solely on superficial statistics. Here, we offer an accessible synthesis of these findings that doubles as an introduction to MI, all while integrating these findings within a novel theoretical framework for thinking about machine understanding. We argue that LLMs develop internal structures that are functionally analogous to the kind of understanding that consists in seeing connections. To sharpen this idea, we propose a three-tiered conception of machine understanding. First, conceptual understanding emerges when a model forms \"features\" as directions in latent space, thereby learning the connections between diverse manifestations of something. Second, state-of-the-world understanding emerges when a model learns contingent factual connections between features and dynamically tracks changes in the world. Third, principled understanding emerges when a model ceases to rely on a collection of memorized facts and discovers a \"circuit\" that connects these facts. However, we conclude by exploring the \"parallel mechanisms\" phenomenon, arguing that while LLMs exhibit forms of understanding, their cognitive architecture remains different from ours, and the debate should shift from whether LLMs understand to how their strange minds work.",
      "authors": [
        "Pierre Beckmann and Matthieu Queloz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.08017v1",
          "size": "427kb",
          "version": "v1"
        }
      ],
      "title": "Mechanistic Indicators of Understanding in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08017",
        "PDF": "https://arxiv.org/pdf/2507.08017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses mechanistic interpretability of LLMs and proposes a theoretical framework for understanding machine intelligence, without addressing training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08538",
      "abstract": "To ensure equitable access to the benefits of large language models (LLMs), it is essential to evaluate their capabilities across the world's languages. We introduce the AI Language Proficiency Monitor, a comprehensive multilingual benchmark that systematically assesses LLM performance across up to 200 languages, with a particular focus on low-resource languages. Our benchmark aggregates diverse tasks including translation, question answering, math, and reasoning, using datasets such as FLORES+, MMLU, GSM8K, TruthfulQA, and ARC. We provide an open-source, auto-updating leaderboard and dashboard that supports researchers, developers, and policymakers in identifying strengths and gaps in model performance. In addition to ranking models, the platform offers descriptive insights such as a global proficiency map and trends over time. By complementing and extending prior multilingual benchmarks, our work aims to foster transparency, inclusivity, and progress in multilingual AI. The system is available at https://huggingface.co/spaces/fair-forward/evals-for-every-language.",
      "authors": [
        "David Pomerenke and Jonas Nothnagel and Simon Ostermann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:38:02+00:00",
          "link": "https://arxiv.org/abs/2507.08538v1",
          "size": "529kb",
          "version": "v1"
        }
      ],
      "title": "The AI Language Proficiency Monitor -- Tracking the Progress of LLMs on Multilingual Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08538",
        "HTML": "https://arxiv.org/html/2507.08538v1",
        "PDF": "https://arxiv.org/pdf/2507.08538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes benchmarks for evaluating LLMs across multiple languages, it does not focus on creating or processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08632",
      "abstract": "We study algorithms to estimate geometric properties of raw point cloud data through implicit surface representations. Given that any level-set function with a constant level set corresponding to the surface can be used for such estimations, numerical methods need not specify a unique target function for the domain-type interpolation problems. In this paper, we focus on kernel-based interpolation by radial basis functions (RBF) and reformulate the uniquely solvable interpolation problem into a constrained optimization model. This model minimizes some user-defined norm while enforcing all interpolation conditions. To enable nontrivial feasible solutions, we propose to enhance the trial space with 1D kernel basis functions inspired by Kolmogorov-Arnold Networks (KANs). Numerical experiments demonstrate that our proposed mixed dimensional trial space significantly improves surface reconstruction from raw point clouds. This is particularly evident in the precise estimation of surface normals, outperforming traditional RBF trial spaces including the one for Hermite interpolation. This framework not only enhances processing of raw point cloud data but also shows potential for further contributions to computational geometry. We demonstrate this with a point cloud processing example.",
      "authors": [
        "Alex Shiu Lun Chu",
        "Leevan Ling",
        "Ka Chun Cheung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:32:23+00:00",
          "link": "https://arxiv.org/abs/2507.08632v1",
          "size": "15649kb",
          "version": "v1"
        }
      ],
      "title": "Minimum-norm interpolation for unknown surface reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08632",
        "HTML": "https://arxiv.org/html/2507.08632v1",
        "PDF": "https://arxiv.org/pdf/2507.08632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about algorithms for surface reconstruction from point clouds and does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08755",
      "abstract": "In this paper, we study column twisted Reed-Solomon(TRS) codes. We establish some conditions for column TRS codes to be MDS codes and show that the dimension of their Schur square codes is $2k$. Consequently, these TRS codes are not equivalent to Reed-Solomon(RS) codes. Moreover, this construction method provides more flexible parameters compared to previous twisted generalized Reed-Solomon(TGRS) code constructions. For large odd prime power $q$, different from the systematically constructed TGRS codes whose length was previously limited to $\\frac{q+1}{2}$, our construction achieves code lengths up to $\\frac{q+3}{2}$. Finally, we present the dual codes of column TRS codes. This paper provides a new approach to construct MDS codes by adding column vectors to generator matrix of RS codes.",
      "authors": [
        "Wei Liu",
        "Jinquan Luo",
        "Puyin Wang",
        "and Dengxin Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:07:59+00:00",
          "link": "https://arxiv.org/abs/2507.08755v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Column Twisted Reed-Solomon Codes as MDS Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08755",
        "HTML": "https://arxiv.org/html/2507.08755v1",
        "PDF": "https://arxiv.org/pdf/2507.08755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the construction of new MDS codes using twisted Reed-Solomon codes but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04298",
      "abstract": "In recent years, great progress has been made in the field of formal verification for low-level systems. Many of them are based on one of two popular approaches: refinement or unary separation logic. These two approaches are very different in nature and offer complementary benefits in compositionality.\n  Recently, to fuse these benefits into a single unified mechanism, a new approach called Conditional Contextual Refinement (CCR 1.0 for short) was proposed. In this paper, we advance CCR 1.0 and provide novel and intuitive reasoning principles, resulting in CCR 2.0. Achieving this goal was challenging due to non-trivial counterexamples which necessitated elegant changes to the model of CCR 1.0. On top of CCR 2.0, we show how to fuse the benefits of refinement, unary separation logic, and also relational separation logic.\n  Our results are formalized in Rocq.",
      "authors": [
        "Youngju Song and Minki Cho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T08:51:48+00:00",
          "link": "https://arxiv.org/abs/2507.04298v1",
          "size": "1745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.04298v2",
          "size": "824kb",
          "version": "v2"
        }
      ],
      "title": "CCR 2.0: High-level Reasoning for Conditional Refinements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04298",
        "PDF": "https://arxiv.org/pdf/2507.04298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper advances formal verification approaches and reasoning principles, which are unrelated to LLM training data processing or dataset creation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08264",
      "abstract": "Abductive reasoning, reasoning for inferring explanations for observations, is often mentioned in scientific, design-related and artistic contexts, but its understanding varies across these domains. This paper reviews how abductive reasoning is discussed in epistemology, science and design, and then analyses how various computational systems use abductive reasoning. Our analysis shows that neither theoretical accounts nor computational implementations of abductive reasoning adequately address generating creative hypotheses. Theoretical frameworks do not provide a straightforward model for generating creative abductive hypotheses, computational systems largely implement syllogistic forms of abductive reasoning. We break down abductive computational systems into components and conclude by identifying specific directions for future research that could advance the state of creative abductive reasoning in computational systems.",
      "authors": [
        "Abhinav Sood",
        "Kazjon Grace",
        "Stephen Wan and Cecile Paris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:21:41+00:00",
          "link": "https://arxiv.org/abs/2507.08264v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "Abductive Computational Systems: Creative Abduction and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08264",
        "HTML": "https://arxiv.org/html/2507.08264v1",
        "PDF": "https://arxiv.org/pdf/2507.08264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews abductive reasoning in epistemology and computational systems, focusing on reasoning algorithms rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08719",
      "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly improved code generation, yet most models remain text-only, neglecting crucial visual aids like diagrams and flowcharts used in real-world software development. To bridge this gap, we introduce MM-Coder, a Multilingual Multimodal software developer. MM-Coder integrates visual design inputs-Unified Modeling Language (UML) diagrams and flowcharts (termed Visual Workflow)-with textual instructions to enhance code generation accuracy and architectural alignment. To enable this, we developed MMc-Instruct, a diverse multimodal instruction-tuning dataset including visual-workflow-based code generation, allowing MM-Coder to synthesize textual and graphical information like human developers, distinct from prior work on narrow tasks. Furthermore, we introduce MMEval, a new benchmark for evaluating multimodal code generation, addressing existing text-only limitations. Our evaluations using MMEval highlight significant remaining challenges for models in precise visual information capture, instruction following, and advanced programming knowledge. Our work aims to revolutionize industrial programming by enabling LLMs to interpret and implement complex specifications conveyed through both text and visual designs.",
      "authors": [
        "Linzheng Chai",
        "Jian Yang",
        "Shukai Liu",
        "Wei Zhang",
        "Liran Wang",
        "Ke Jin",
        "Tao Sun",
        "Congnan Liu",
        "Chenchen Zhang",
        "Hualei Zhu",
        "Jiaheng Liu",
        "Xianjie Wu",
        "Ge Zhang",
        "Tianyu Liu",
        "Zhoujun Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:19:53+00:00",
          "link": "https://arxiv.org/abs/2507.08719v1",
          "size": "14054kb",
          "version": "v1"
        }
      ],
      "title": "Multilingual Multimodal Software Developer for Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08719",
        "PDF": "https://arxiv.org/pdf/2507.08719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces MM-Coder, a multilingual multimodal software developer, and the creation of MMc-Instruct, a multimodal instruction-tuning dataset, which includes detailed steps on data processing to enhance LLM code generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06850",
      "abstract": "The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.",
      "authors": [
        "Matteo Lupinacci",
        "Francesco Aurelio Pironti",
        "Francesco Blefari",
        "Francesco Romeo",
        "Luigi Arena",
        "Angelo Furfaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:54:58+00:00",
          "link": "https://arxiv.org/abs/2507.06850v1",
          "size": "442kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:18:20+00:00",
          "link": "https://arxiv.org/abs/2507.06850v2",
          "size": "442kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T09:50:02+00:00",
          "link": "https://arxiv.org/abs/2507.06850v3",
          "size": "442kb",
          "version": "v3"
        }
      ],
      "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06850",
        "HTML": "https://arxiv.org/html/2507.06850v3",
        "PDF": "https://arxiv.org/pdf/2507.06850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on security vulnerabilities in LLMs, specifically relating to attacks via multi-agent systems, rather than on processes or methodologies for training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.10240",
      "abstract": "Circuit link prediction identifying missing component connections from incomplete netlists is crucial in automating analog circuit design. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural Networks (GNNs) based framework featuring three innovations to tackle these challenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes for Link Prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with a large language model (LLM) to enhance the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different component classes. Experiments demonstrate accuracy improvements of 16.08% on SpiceNetlist, 11.38% on Image2Net, and 16.01% on Masala-CHAI compared to the baseline in intra-dataset evaluation, while maintaining accuracy from 92.05% to 99.07% in cross-dataset evaluation, exhibiting robust feature transfer capabilities.",
      "authors": [
        "Guanyuan Pan",
        "Tiansheng Zhou",
        "Bingtao Ma",
        "Yaqi Wang",
        "Jianxiang Zhao",
        "Zhi Li",
        "Yugui Lin",
        "Pietro Lio",
        "Shuai Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T14:02:09+00:00",
          "link": "https://arxiv.org/abs/2504.10240v1",
          "size": "1140kb",
          "version": "v1"
        },
        {
          "date": "2025-05-18T07:38:47+00:00",
          "link": "https://arxiv.org/abs/2504.10240v2",
          "size": "6712kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T12:58:59+00:00",
          "link": "https://arxiv.org/abs/2504.10240v3",
          "size": "1708kb",
          "version": "v3"
        }
      ],
      "title": "GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10240",
        "HTML": "https://arxiv.org/html/2504.10240v3",
        "PDF": "https://arxiv.org/pdf/2504.10240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper constructs a new dataset called SpiceNetlist, detailing its creation process, and introduces technologies like Netlist Babel Fish that relate to data processing with LLM support."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Link Prediction",
        "Prediction",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14697",
      "abstract": "The rapid advancement of vision-language models (VLMs) and their integration into embodied agents have unlocked powerful capabilities for decision-making. However, as these systems are increasingly deployed in real-world environments, they face mounting safety concerns, particularly when responding to hazardous instructions. In this work, we propose AGENTSAFE, the first comprehensive benchmark for evaluating the safety of embodied VLM agents under hazardous instructions. AGENTSAFE simulates realistic agent-environment interactions within a simulation sandbox and incorporates a novel adapter module that bridges the gap between high-level VLM outputs and low-level embodied controls. Specifically, it maps recognized visual entities to manipulable objects and translates abstract planning into executable atomic actions in the environment. Building on this, we construct a risk-aware instruction dataset inspired by Asimovs Three Laws of Robotics, including base risky instructions and mutated jailbroken instructions. The benchmark includes 45 adversarial scenarios, 1,350 hazardous tasks, and 8,100 hazardous instructions, enabling systematic testing under adversarial conditions ranging from perception, planning, and action execution stages.",
      "authors": [
        "Aishan Liu",
        "Zonghao Ying",
        "Le Wang",
        "Junjie Mu",
        "Jinyang Guo",
        "Jiakai Wang",
        "Yuqing Ma",
        "Siyuan Liang",
        "Mingchuan Zhang",
        "Xianglong Liu",
        "Dacheng Tao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T16:37:35+00:00",
          "link": "https://arxiv.org/abs/2506.14697v1",
          "size": "2805kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:57:14+00:00",
          "link": "https://arxiv.org/abs/2506.14697v2",
          "size": "2808kb",
          "version": "v2"
        }
      ],
      "title": "AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14697",
        "HTML": "https://arxiv.org/html/2506.14697v2",
        "PDF": "https://arxiv.org/pdf/2506.14697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking the safety of embodied agents, and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08165",
      "abstract": "Visually impaired people face significant challenges in their day-to-day commutes in the urban cities of Bangladesh due to the vast number of obstructions on every path. With many injuries taking place through road accidents on a daily basis, it is paramount for a system to be developed that can alert the visually impaired of objects at close distance beforehand. To overcome this issue, a novel alert system is proposed in this research to assist the visually impaired in commuting through these busy streets without colliding with any objects. The proposed system can alert the individual to objects that are present at a close distance. It utilizes transfer learning to train models for depth estimation and object detection, and combines both models to introduce a novel system. The models are optimized through the utilization of quantization techniques to make them lightweight and efficient, allowing them to be easily deployed on embedded systems. The proposed solution achieved a lightweight real-time depth estimation and object detection model with an mAP50 of 0.801.",
      "authors": [
        "Jareen Anjom",
        "Rashik Iram Chowdhury",
        "Tarbia Hasan",
        "Md. Ishan Arefin Hossain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:55:22+00:00",
          "link": "https://arxiv.org/abs/2507.08165v1",
          "size": "1669kb",
          "version": "v1"
        }
      ],
      "title": "An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08165",
        "HTML": "https://arxiv.org/html/2507.08165v1",
        "PDF": "https://arxiv.org/pdf/2507.08165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper addresses real-time object alert systems for the visually impaired, it does not relate to LLM training data processing or enhancements."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.19002",
      "abstract": "Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a multi-modal problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the \"goals\" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can predict both pedestrian's trajectories and bounding boxes. The overall model is efficient and modular, and its outputs can be changed according to the usage scenario. Experimental results show that GoalNet significantly improves the previous state-of-the-art performance by 48.7% on the JAAD and 40.8% on the PIE dataset.",
      "authors": [
        "Amar Fadillah",
        "Ching-Lin Lee",
        "Zhi-Xuan Wang",
        "Kuan-Ting Lai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-29T09:53:19+00:00",
          "link": "https://arxiv.org/abs/2402.19002v1",
          "size": "4014kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:39:37+00:00",
          "link": "https://arxiv.org/abs/2402.19002v2",
          "size": "8276kb",
          "version": "v2"
        }
      ],
      "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.19002",
        "HTML": "https://arxiv.org/html/2402.19002v2",
        "PDF": "https://arxiv.org/pdf/2402.19002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces GoalNet for pedestrian trajectory prediction and doesn't discuss training data processing related to LLMs."
      },
      "tasks": [
        "Autonomous Driving",
        "Decision Making",
        "Pedestrian Trajectory Prediction",
        "Prediction",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12003",
      "abstract": "The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built index architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid index/registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized indexes for critical agents and federated meshes for specialized use cases.",
      "authors": [
        "Ramesh Raskar",
        "Pradyumna Chari",
        "Jared James Grogan",
        "Mahesh Lambe",
        "Robert Lincourt",
        "Raghu Bala",
        "Aditi Joshi",
        "Abhishek Singh",
        "Ayush Chopra",
        "Rajesh Ranjan",
        "Shailja Gupta",
        "Dimitris Stripelis",
        "Maria Gorskikh",
        "Sichao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T17:55:38+00:00",
          "link": "https://arxiv.org/abs/2506.12003v1",
          "size": "707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:44:32+00:00",
          "link": "https://arxiv.org/abs/2506.12003v2",
          "size": "727kb",
          "version": "v2"
        }
      ],
      "title": "Upgrade or Switch: Do We Need a Next-Gen Trusted Architecture for the Internet of AI Agents?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12003",
        "PDF": "https://arxiv.org/pdf/2506.12003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on infrastructure for AI agents without discussing any aspects of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.02788",
      "abstract": "Vision Transformers (ViTs) have shown promise in medical image semantic segmentation (MISS) by capturing long-range correlations. However, ViTs often struggle to model local spatial information effectively, which is essential for accurately segmenting fine anatomical details, particularly when applied to small datasets without extensive pre-training. We introduce Gabor and Laplacian of Gaussian Convolutional Swin Network (GLoG-CSUnet), a novel architecture enhancing Transformer-based models by incorporating learnable radiomic features. This approach integrates dynamically adaptive Gabor and Laplacian of Gaussian (LoG) filters to capture texture, edge, and boundary information, enhancing the feature representation processed by the Transformer model. Our method uniquely combines the long-range dependency modeling of Transformers with the texture analysis capabilities of Gabor and LoG features. Evaluated on the Synapse multi-organ and ACDC cardiac segmentation datasets, GLoG-CSUnet demonstrates significant improvements over state-of-the-art models, achieving a 1.14% increase in Dice score for Synapse and 0.99% for ACDC, with minimal computational overhead (only 15 and 30 additional parameters, respectively). GLoG-CSUnet's flexible design allows integration with various base models, offering a promising approach for incorporating radiomics-inspired feature extraction in Transformer architectures for medical image analysis. The code implementation is available on GitHub at: https://github.com/HAAIL/GLoG-CSUnet.",
      "authors": [
        "Niloufar Eghbali",
        "Hassan Bagher-Ebadian",
        "Tuka Alhanai",
        "and Mohammad M. Ghassemi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T06:07:40+00:00",
          "link": "https://arxiv.org/abs/2501.02788v1",
          "size": "1706kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T18:33:07+00:00",
          "link": "https://arxiv.org/abs/2501.02788v2",
          "size": "3644kb",
          "version": "v2"
        }
      ],
      "title": "GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02788",
        "HTML": "https://arxiv.org/html/2501.02788",
        "PDF": "https://arxiv.org/pdf/2501.02788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel architecture for medical image segmentation, enhancing Vision Transformers with adaptable radiomic features. It does not discuss LLM training data processing or contribute to data engineering operations for LLMs."
      },
      "tasks": [
        "Cardiac Segmentation",
        "Image Segmentation",
        "Medical Image Analysis",
        "Medical Image Segmentation",
        "Semantic Segmentation",
        "Texture Classification"
      ],
      "repo_urls": [
        "https://github.com/haail/glog-csunet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08387",
      "abstract": "Offline-to-online reinforcement learning (RL) aims to integrate the complementary strengths of offline and online RL by pre-training an agent offline and subsequently fine-tuning it through online interactions. However, recent studies reveal that offline pre-trained agents often underperform during online fine-tuning due to inaccurate value estimation caused by distribution shift, with random initialization proving more effective in certain cases. In this work, we propose a novel method, Online Pre-Training for Offline-to-Online RL (OPT), explicitly designed to address the issue of inaccurate value estimation in offline pre-trained agents. OPT introduces a new learning phase, Online Pre-Training, which allows the training of a new value function tailored specifically for effective online fine-tuning. Implementation of OPT on TD3 and SPOT demonstrates an average 30% improvement in performance across a wide range of D4RL environments, including MuJoCo, Antmaze, and Adroit.",
      "authors": [
        "Yongjae Shin",
        "Jeonghye Kim",
        "Whiyoung Jung",
        "Sunghoon Hong",
        "Deunsol Yoon",
        "Youngsoo Jang",
        "Geonhyeong Kim",
        "Jongseong Chae",
        "Youngchul Sung",
        "Kanghoon Lee",
        "Woohyung Lim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:00:12+00:00",
          "link": "https://arxiv.org/abs/2507.08387v1",
          "size": "10206kb",
          "version": "v1"
        }
      ],
      "title": "Online Pre-Training for Offline-to-Online Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08387",
        "HTML": "https://arxiv.org/html/2507.08387v1",
        "PDF": "https://arxiv.org/pdf/2507.08387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses improvements in reinforcement learning techniques and does not focus on LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.05076",
      "abstract": "The United States (US) opioid crisis contributed to 81,806 fatalities in 2022. It has strained hospitals, treatment facilities, and law enforcement agencies due to the enormous resources and procedures needed to respond to the crisis. As a result, many individuals who use opioids never receive or finish the treatment they need and instead have many interactions with hospitals or the criminal justice system. This paper introduces a discrete event simulation model that evaluates three opioid use disorder treatment policies: arrest diversion, re-entry case management, and overdose diversion. Publicly available data from 2011 to 2019 in Dane County, Wisconsin, was used to forecast opioid-related outcomes through 2032. Through analyzing a variety of policy-mix implementations, the study offers a versatile framework for evaluating policies at various implementation levels. The results demonstrate that treatment policies that create new pathways and programming by utilizing treatment services and successfully divert at least 20% of eligible individuals can lead to more opioid-resilient communities. The benefits increase when more policies are enacted and/or offered to more individuals, with the largest impact from overdose diversion, followed by re-entry case management, and the smallest impact from arrest diversion. The statistically significant 10-year cumulative total reduction in societal costs from 2023 through 2032 ranges from $39 M (USD) to $584 M (USD), excluding implementation costs of policies. To reverse the opioid crisis within a community, treatment policies may need to be combined with other strategies, such as harm reduction, supply reduction, and use prevention.",
      "authors": [
        "Veronica M. White and Laura A. Albert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-09T00:15:30+00:00",
          "link": "https://arxiv.org/abs/2311.05076v1",
          "size": "7904kb",
          "version": "v1"
        },
        {
          "date": "2023-12-01T20:03:54+00:00",
          "link": "https://arxiv.org/abs/2311.05076v2",
          "size": "7904kb",
          "version": "v2"
        },
        {
          "date": "2024-08-07T21:43:05+00:00",
          "link": "https://arxiv.org/abs/2311.05076v3",
          "size": "8258kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T21:16:55+00:00",
          "link": "https://arxiv.org/abs/2311.05076v4",
          "size": "7842kb",
          "version": "v4"
        }
      ],
      "title": "Evaluating diversion and treatment policies for opioid use disorder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.05076",
        "HTML": "https://arxiv.org/html/2311.05076v4",
        "PDF": "https://arxiv.org/pdf/2311.05076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating policies for opioid use disorder using simulation models and does not discuss any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/vmwhite/des-paper-data-and-analysis-2023"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23896",
      "abstract": "Deep neural networks learn structured features from complex, non-Gaussian inputs, but the mechanisms behind this process remain poorly understood. Our work is motivated by the observation that the first-layer filters learnt by deep convolutional neural networks from natural images resemble those learnt by independent component analysis (ICA), a simple unsupervised method that seeks the most non-Gaussian projections of its inputs. This similarity suggests that ICA provides a simple, yet principled model for studying feature learning. Here, we leverage this connection to investigate the interplay between data structure and optimisation in feature learning for the most popular ICA algorithm, FastICA, and stochastic gradient descent (SGD), which is used to train deep networks. We rigorously establish that FastICA requires at least $n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from $d$-dimensional inputs on a simple synthetic data model. We show that vanilla online SGD outperforms FastICA, and prove that the optimal sample complexity $n \\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent way. We finally demonstrate the existence of a search phase for FastICA on ImageNet, and discuss how the strong non-Gaussianity of said images compensates for the poor sample complexity of FastICA.",
      "authors": [
        "Fabiola Ricci",
        "Lorenzo Bardone",
        "Sebastian Goldt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T09:46:47+00:00",
          "link": "https://arxiv.org/abs/2503.23896v1",
          "size": "3245kb",
          "version": "v1"
        }
      ],
      "title": "Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23896",
        "HTML": "https://arxiv.org/html/2503.23896",
        "PDF": "https://arxiv.org/pdf/2503.23896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores feature learning from non-Gaussian inputs using ICA and SGD, focusing on learning mechanisms rather than processing LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08513",
      "abstract": "Multimodal Large Language Models (MLLMs) struggle with accurately capturing camera-object relations, especially for object orientation, camera viewpoint, and camera shots. This stems from the fact that existing MLLMs are trained on images with limited diverse camera-object relations and corresponding textual descriptions. To address this, we propose a synthetic generation pipeline to create large-scale 3D visual instruction datasets. Our framework takes 3D assets as input and uses rendering and diffusion-based image generation models to create photorealistic images preserving precise camera-object relations. Additionally, large language models (LLMs) are used to generate text prompts for guiding visual instruction tuning and controlling image generation. We create Ultimate3D, a dataset of 240K VQAs with precise camera-object annotations, and corresponding benchmark. MLLMs fine-tuned on our proposed dataset outperform commercial models by a large margin, achieving an average accuracy improvement of 33.4% on camera-object relation recognition tasks. Our code, dataset, and benchmark will contribute to broad MLLM applications.",
      "authors": [
        "Liu He",
        "Xiao Zeng",
        "Yizhi Song",
        "Albert Y. C. Chen",
        "Lu Xia",
        "Shashwat Verma",
        "Sankalp Dayal",
        "Min Sun",
        "Cheng-Hao Kuo",
        "Daniel Aliaga"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:00:10+00:00",
          "link": "https://arxiv.org/abs/2507.08513v1",
          "size": "45607kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08513",
        "HTML": "https://arxiv.org/html/2507.08513v1",
        "PDF": "https://arxiv.org/pdf/2507.08513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper proposes a synthetic generation pipeline to create large-scale 3D visual instruction datasets, indicating a substantial contribution to LLM training data processing, particularly in dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08705",
      "abstract": "We present elsciRL, an open-source Python library to facilitate the application of language solutions on reinforcement learning problems. We demonstrate the potential of our software by extending the Language Adapter with Self-Completing Instruction framework defined in (Osborne, 2024) with the use of LLMs. Our approach can be re-applied to new applications with minimal setup requirements. We provide a novel GUI that allows a user to provide text input for an LLM to generate instructions which it can then self-complete. Empirical results indicate that these instructions \\textit{can} improve a reinforcement learning agent's performance. Therefore, we present this work to accelerate the evaluation of language solutions on reward based environments to enable new opportunities for scientific discovery.",
      "authors": [
        "Philip Osborne",
        "Danilo S. Carvalho",
        "Andr\\'e Freitas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:02:24+00:00",
          "link": "https://arxiv.org/abs/2507.08705v1",
          "size": "4767kb",
          "version": "v1"
        }
      ],
      "title": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08705",
        "HTML": "https://arxiv.org/html/2507.08705v1",
        "PDF": "https://arxiv.org/pdf/2507.08705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a library for integrating language solutions into reinforcement learning, mentioning LLMs, but primarily focuses on model application in RL settings, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07393",
      "abstract": "We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy on MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication.",
      "authors": [
        "Jinseong Kim",
        "Junghoon Song",
        "Gyeongseon Baek",
        "Byeongjoon Noh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:15:57+00:00",
          "link": "https://arxiv.org/abs/2507.07393v1",
          "size": "3910kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T04:18:18+00:00",
          "link": "https://arxiv.org/abs/2507.07393v2",
          "size": "3910kb",
          "version": "v2"
        }
      ],
      "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07393",
        "HTML": "https://arxiv.org/html/2507.07393v2",
        "PDF": "https://arxiv.org/pdf/2507.07393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for video-based person re-identification using keypoints, focusing on spatiotemporal representation learning, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08124",
      "abstract": "Traditional physics-informed neural networks (PINNs) do not guarantee strict constraint satisfaction. This is problematic in engineering systems where minor violations of governing laws can significantly degrade the reliability and consistency of model predictions. In this work, we develop KKT-Hardnet, a PINN architecture that enforces both linear and nonlinear equality and inequality constraints up to machine precision. It leverages a projection onto the feasible region through solving Karush-Kuhn-Tucker (KKT) conditions of a distance minimization problem. Furthermore, we reformulate the nonlinear KKT conditions using log-exponential transformation to construct a general sparse system with only linear and exponential terms, thereby making the projection differentiable. We apply KKT-Hardnet on both test problems and a real-world chemical process simulation. Compared to multilayer perceptrons and PINNs, KKT-Hardnet achieves higher accuracy and strict constraint satisfaction. This approach allows the integration of domain knowledge into machine learning towards reliable hybrid modeling of complex systems.",
      "authors": [
        "Ashfaq Iftakher",
        "Rahul Golder",
        "M. M. Faruque Hasan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:24:53+00:00",
          "link": "https://arxiv.org/abs/2507.08124v1",
          "size": "2247kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Neural Networks with Hard Nonlinear Equality and Inequality Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08124",
        "HTML": "https://arxiv.org/html/2507.08124v1",
        "PDF": "https://arxiv.org/pdf/2507.08124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study deals with neural network architectures enforcing hard constraints using KKT conditions without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08518",
      "abstract": "Data depths are score functions that quantify in an unsupervised fashion how central is a point inside a distribution, with numerous applications such as anomaly detection, multivariate or functional data analysis, arising across various fields. The halfspace depth was the first depth to aim at generalising the notion of quantile beyond the univariate case. Among the existing variety of depth definitions, it remains one of the most used notions of data depth. Taking a different angle from the quantile point of view, we show that the halfspace depth can also be regarded as the minimum loss of a set of classifiers for a specific labelling of the points. By changing the loss or the set of classifiers considered, this new angle naturally leads to a family of \"loss depths\", extending to well-studied classifiers such as, e.g., SVM or logistic regression, among others. This framework directly inherits computational efficiency of existing machine learning algorithms as well as their fast statistical convergence rates, and opens the data depth realm to the high-dimensional setting. Furthermore, the new loss depths highlight a connection between the dataset and the right amount of complexity or simplicity of the classifiers. The simplicity of classifiers as well as the interpretation as a risk makes our new kind of data depth easy to explain, yet efficient for anomaly detection, as is shown by experiments.",
      "authors": [
        "Arturo Castellanos and Pavlo Mozharovskyi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:05:03+00:00",
          "link": "https://arxiv.org/abs/2507.08518v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Data Depth as a Risk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08518",
        "HTML": "https://arxiv.org/html/2507.08518v1",
        "PDF": "https://arxiv.org/pdf/2507.08518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for data depth related to anomaly detection and classification, but does not address processing of LLM training data or related data engineering practices."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08212",
      "abstract": "Even a slight perturbation in the graph structure can cause a significant drop in the accuracy of graph neural networks (GNNs). Most existing attacks leverage gradient information to perturb edges. This relaxes the attack's optimization problem from a discrete to a continuous space, resulting in solutions far from optimal. It also restricts the adaptability of the attack to non-differentiable objectives. Instead, we introduce a few simple yet effective enhancements of an evolutionary-based algorithm to solve the discrete optimization problem directly. Our Evolutionary Attack (EvA) works with any black-box model and objective, eliminating the need for a differentiable proxy loss. This allows us to design two novel attacks that reduce the effectiveness of robustness certificates and break conformal sets. The memory complexity of our attack is linear in the attack budget. Among our experiments, EvA shows $\\sim$11\\% additional drop in accuracy on average compared to the best previous attack, revealing significant untapped potential in designing attacks.",
      "authors": [
        "Mohammad Sadegh Akhondzadeh",
        "Soroush H. Zargarbashi",
        "Jimin Cao",
        "Aleksandar Bojchevski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:50:58+00:00",
          "link": "https://arxiv.org/abs/2507.08212v1",
          "size": "1592kb",
          "version": "v1"
        }
      ],
      "title": "EvA: Evolutionary Attacks on Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08212",
        "HTML": "https://arxiv.org/html/2507.08212v1",
        "PDF": "https://arxiv.org/pdf/2507.08212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses evolutionary attacks on graph neural networks, focusing on optimization problems and robustness, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.06303",
      "abstract": "Compositional generalization is a crucial step towards developing data-efficient intelligent machines that generalize in human-like ways. In this work, we tackle a challenging form of distribution shift, termed compositional shift, where some attribute combinations are completely absent at training but present in the test distribution. This shift tests the model's ability to generalize compositionally to novel attribute combinations in discriminative tasks. We model the data with flexible additive energy distributions, where each energy term represents an attribute, and derive a simple alternative to empirical risk minimization termed compositional risk minimization (CRM). We first train an additive energy classifier to predict the multiple attributes and then adjust this classifier to tackle compositional shifts. We provide an extensive theoretical analysis of CRM, where we show that our proposal extrapolates to special affine hulls of seen attribute combinations. Empirical evaluations on benchmark datasets confirms the improved robustness of CRM compared to other methods from the literature designed to tackle various forms of subpopulation shifts.",
      "authors": [
        "Divyat Mahajan",
        "Mohammad Pezeshki",
        "Charles Arnal",
        "Ioannis Mitliagkas",
        "Kartik Ahuja",
        "Pascal Vincent"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T19:25:07+00:00",
          "link": "https://arxiv.org/abs/2410.06303v1",
          "size": "495kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T23:16:02+00:00",
          "link": "https://arxiv.org/abs/2410.06303v2",
          "size": "820kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T22:00:10+00:00",
          "link": "https://arxiv.org/abs/2410.06303v3",
          "size": "740kb",
          "version": "v3"
        }
      ],
      "title": "Compositional Risk Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06303",
        "HTML": "https://arxiv.org/html/2410.06303v3",
        "PDF": "https://arxiv.org/pdf/2410.06303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract describes tackling compositional shift using compositional risk minimization, focusing mainly on model adaptation to distribution shifts rather than LLM training data processing."
      },
      "tasks": [
        "Attribute"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.19076",
      "abstract": "Large Language Models (LLMs) are increasingly used to evaluate information retrieval (IR) systems, generating relevance judgments traditionally made by human assessors. Recent empirical studies suggest that LLM-based evaluations often align with human judgments, leading some to suggest that human judges may no longer be necessary, while others highlight concerns about judgment reliability, validity, and long-term impact. As IR systems begin incorporating LLM-generated signals, evaluation outcomes risk becoming self-reinforcing, potentially leading to misleading conclusions.\n  This paper examines scenarios where LLM-evaluators may falsely indicate success, particularly when LLM-based judgments influence both system development and evaluation. We highlight key risks, including bias reinforcement, reproducibility challenges, and inconsistencies in assessment methodologies. To address these concerns, we propose tests to quantify adverse effects, guardrails, and a collaborative framework for constructing reusable test collections that integrate LLM judgments responsibly. By providing perspectives from academia and industry, this work aims to establish best practices for the principled use of LLMs in IR evaluation.",
      "authors": [
        "Laura Dietz",
        "Oleg Zendel",
        "Peter Bailey",
        "Charles Clarke",
        "Ellese Cotterill",
        "Jeff Dalton",
        "Faegheh Hasibi",
        "Mark Sanderson",
        "Nick Craswell"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-27T02:14:21+00:00",
          "link": "https://arxiv.org/abs/2504.19076v1",
          "size": "788kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Evaluation Tropes: Perspectives on the Validity of LLM-Evaluations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19076",
        "HTML": "https://arxiv.org/html/2504.19076",
        "PDF": "https://arxiv.org/pdf/2504.19076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on evaluating information retrieval systems using LLMs, without discussing LLM training data processing or engineering."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00258",
      "abstract": "In solving linear systems of equations of the form $Ax=b$, corruptions present in $b$ affect stochastic iterative algorithms' ability to reach the true solution $x^\\ast$ to the uncorrupted linear system. The randomized Kaczmarz method converges in expectation to $x^\\ast$ up to an error horizon dependent on the conditioning of $A$ and the supremum norm of the corruption in $b$. To avoid this error horizon in the sparse corruption setting, previous works have proposed quantile-based adaptations that make iterative methods robust. Our work first establishes a new convergence rate for the quantile-based random Kaczmarz (qRK) and double quantile-based random Kaczmarz (dqRK) methods, which, under certain conditions, improves upon known bounds. We further consider the more practical setting in which the vector $b$ includes both non-sparse ``noise\" and sparse ``corruption\". Error horizon bounds for qRK and dqRK are derived and shown to produce a smaller error horizon compared to their non-quantile-based counterparts, further demonstrating the advantages of quantile-based methods.",
      "authors": [
        "Emeric Battaglia and Anna Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T02:48:15+00:00",
          "link": "https://arxiv.org/abs/2505.00258v1",
          "size": "95kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T00:55:09+00:00",
          "link": "https://arxiv.org/abs/2505.00258v2",
          "size": "97kb",
          "version": "v2"
        }
      ],
      "title": "Quantile-RK and Double Quantile-RK Error Horizon Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00258",
        "PDF": "https://arxiv.org/pdf/2505.00258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving convergence rates of quantile-based Random Kaczmarz algorithms for solving corrupted linear systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07789",
      "abstract": "Recent work has demonstrated that imaging systems can be evaluated through the information content of their measurements alone, enabling application-agnostic optical design that avoids computational decoding challenges. Information-Driven Encoder Analysis Learning (IDEAL) was proposed to automate this process through gradient-based optimization. In this work, we study IDEAL across diverse imaging systems and find that it suffers from high memory usage, long runtimes, and a potentially mismatched objective function due to end-to-end differentiability requirements. We introduce IDEAL with Interchanging Optimization (IDEAL-IO), a method that decouples density estimation from optical parameter optimization by alternating between fitting models to current measurements and updating optical parameters using fixed models for information estimation. This approach reduces runtime and memory usage by up to 6x while enabling more expressive density models that guide optimization toward superior designs. We validate our method on diffractive optics, lensless imaging, and snapshot 3D microscopy applications, establishing information-theoretic optimization as a practical, scalable strategy for real-world imaging system design.",
      "authors": [
        "Eric Markley",
        "Henry Pinkard",
        "Leyla Kabuli",
        "Nalini Singh",
        "Laura Waller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:14:08+00:00",
          "link": "https://arxiv.org/abs/2507.07789v1",
          "size": "15465kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.07789v2",
          "size": "15465kb",
          "version": "v2"
        }
      ],
      "title": "Computationally Efficient Information-Driven Optical Design with Interchanging Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07789",
        "HTML": "https://arxiv.org/html/2507.07789v2",
        "PDF": "https://arxiv.org/pdf/2507.07789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optical design optimization using IDEAL and does not address any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08166",
      "abstract": "Rowhammer is a read disturbance vulnerability in modern DRAM that causes bit-flips, compromising security and reliability. While extensively studied on Intel and AMD CPUs with DDR and LPDDR memories, its impact on GPUs using GDDR memories, critical for emerging machine learning applications, remains unexplored. Rowhammer attacks on GPUs face unique challenges: (1) proprietary mapping of physical memory to GDDR banks and rows, (2) high memory latency and faster refresh rates that hinder effective hammering, and (3) proprietary mitigations in GDDR memories, difficult to reverse-engineer without FPGA-based test platforms. We introduce GPUHammer, the first Rowhammer attack on NVIDIA GPUs with GDDR6 DRAM. GPUHammer proposes novel techniques to reverse-engineer GDDR DRAM row mappings, and employs GPU-specific memory access optimizations to amplify hammering intensity and bypass mitigations. Thus, we demonstrate the first successful Rowhammer attack on a discrete GPU, injecting up to 8 bit-flips across 4 DRAM banks on an NVIDIA A6000 with GDDR6 memory. We also show how an attacker can use these to tamper with ML models, causing significant accuracy drops (up to 80%).",
      "authors": [
        "Chris S. Lin",
        "Joyce Qu",
        "Gururaj Saileshwar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:57:47+00:00",
          "link": "https://arxiv.org/abs/2507.08166v1",
          "size": "1048kb",
          "version": "v1"
        }
      ],
      "title": "GPUHammer: Rowhammer Attacks on GPU Memories are Practical",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08166",
        "HTML": "https://arxiv.org/html/2507.08166v1",
        "PDF": "https://arxiv.org/pdf/2507.08166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on security vulnerabilities in GPU memories and their impact on ML models, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08656",
      "abstract": "Learning whole-body control for locomotion and arm motions in a single policy has challenges, as the two tasks have conflicting goals. For instance, efficient locomotion typically favors a horizontal base orientation, while end-effector tracking may benefit from base tilting to extend reachability. Additionally, current Reinforcement Learning (RL) approaches using a pose-based task specification lack the ability to directly control the end-effector velocity, making smoothly executing trajectories very challenging. To address these limitations, we propose an RL-based framework that allows for dynamic, velocity-aware whole-body end-effector control. Our method introduces a multi-critic actor architecture that decouples the reward signals for locomotion and manipulation, simplifying reward tuning and allowing the policy to resolve task conflicts more effectively. Furthermore, we design a twist-based end-effector task formulation that can track both discrete poses and motion trajectories. We validate our approach through a set of simulation and hardware experiments using a quadruped robot equipped with a robotic arm. The resulting controller can simultaneously walk and move its end-effector and shows emergent whole-body behaviors, where the base assists the arm in extending the workspace, despite a lack of explicit formulations.",
      "authors": [
        "Aravind Elanjimattathil Vijayan",
        "Andrei Cramariuc",
        "Mattia Risiglione",
        "Christian Gehring",
        "Marco Hutter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:59:59+00:00",
          "link": "https://arxiv.org/abs/2507.08656v1",
          "size": "27799kb",
          "version": "v1"
        }
      ],
      "title": "Multi-critic Learning for Whole-body End-effector Twist Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08656",
        "HTML": "https://arxiv.org/html/2507.08656v1",
        "PDF": "https://arxiv.org/pdf/2507.08656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves learning whole-body control for robots with reinforcement learning but does not pertain to LLM training data processing or production."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08128",
      "abstract": "We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) large audio-language model that advances reasoning and understanding across speech, sound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encoder trained using a novel strategy for joint representation learning across all 3 modalities of speech, sound, and music; (ii) flexible, on-demand thinking, allowing the model to do chain-of-thought-type reasoning before answering; (iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning (including speech) up to 10 minutes; and (v) voice-to-voice interaction. To enable these capabilities, we propose several large-scale training datasets curated using novel strategies, including AudioSkills-XL, LongAudio-XL, AF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-based training strategy. Trained on only open-source audio data, AF3 achieves new SOTA results on over 20+ (long) audio understanding and reasoning benchmarks, surpassing both open-weight and closed-source models trained on much larger datasets.",
      "authors": [
        "Arushi Goel and Sreyan Ghosh and Jaehyeon Kim and Sonal Kumar and Zhifeng Kong and Sang-gil Lee and Chao-Han Huck Yang and Ramani Duraiswami and Dinesh Manocha and Rafael Valle and Bryan Catanzaro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:40:21+00:00",
          "link": "https://arxiv.org/abs/2507.08128v1",
          "size": "24654kb",
          "version": "v1"
        }
      ],
      "title": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08128",
        "HTML": "https://arxiv.org/html/2507.08128v1",
        "PDF": "https://arxiv.org/pdf/2507.08128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces several large-scale training datasets for an audio-language model, curated using novel strategies, which indicates a significant contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08150",
      "abstract": "Accurate uncertainty quantification is critical for reliable predictive modeling, especially in regression tasks. Existing methods typically address either aleatoric uncertainty from measurement noise or epistemic uncertainty from limited data, but not necessarily both in a balanced way. We propose CLEAR, a calibration method with two distinct parameters, $\\gamma_1$ and $\\gamma_2$, to combine the two uncertainty components for improved conditional coverage. CLEAR is compatible with any pair of aleatoric and epistemic estimators; we show how it can be used with (i) quantile regression for aleatoric uncertainty and (ii) ensembles drawn from the Predictability-Computability-Stability (PCS) framework for epistemic uncertainty. Across 17 diverse real-world datasets, CLEAR achieves an average improvement of 28.2% and 17.4% in the interval width compared to the two individually calibrated baselines while maintaining nominal coverage. This improvement can be particularly evident in scenarios dominated by either high epistemic or high aleatoric uncertainty.",
      "authors": [
        "Ilia Azizi",
        "Juraj Bodik",
        "Jakob Heiss",
        "Bin Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:13:00+00:00",
          "link": "https://arxiv.org/abs/2507.08150v1",
          "size": "383kb",
          "version": "v1"
        }
      ],
      "title": "CLEAR: Calibrated Learning for Epistemic and Aleatoric Risk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08150",
        "HTML": "https://arxiv.org/html/2507.08150v1",
        "PDF": "https://arxiv.org/pdf/2507.08150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on calibration for uncertainty quantification in predictive modeling, specifically using methods for quantile regression and ensemble techniques, without mentioning any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08800",
      "abstract": "We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems.",
      "authors": [
        "Luke Rivard",
        "Sun Sun",
        "Hongyu Guo",
        "Wenhu Chen",
        "Yuntian Deng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:59:40+00:00",
          "link": "https://arxiv.org/abs/2507.08800v1",
          "size": "9226kb",
          "version": "v1"
        }
      ],
      "title": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08800",
        "HTML": "https://arxiv.org/html/2507.08800v1",
        "PDF": "https://arxiv.org/pdf/2507.08800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes NeuralOS, which uses a large-scale dataset for training its neural framework. The detailed data collection process from Ubuntu XFCE recordings, including both random and realistic interactions, represents a significant data processing effort for creating a new dataset."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.03897",
      "abstract": "While large language models (LLMs) excel in various natural language tasks in English, their performance in lower-resourced languages like Hebrew, especially for generative tasks such as abstractive summarization, remains unclear. The high morphological richness in Hebrew adds further challenges due to the ambiguity in sentence comprehension and the complexities in meaning construction. In this paper, we address this resource and evaluation gap by introducing HeSum, a novel benchmark specifically designed for abstractive text summarization in Modern Hebrew. HeSum consists of 10,000 article-summary pairs sourced from Hebrew news websites written by professionals. Linguistic analysis confirms HeSum's high abstractness and unique morphological challenges. We show that HeSum presents distinct difficulties for contemporary state-of-the-art LLMs, establishing it as a valuable testbed for generative language technology in Hebrew, and MRLs generative challenges in general.",
      "authors": [
        "Tzuf Paz-Argaman",
        "Itai Mondshine",
        "Asaf Achi Mordechai",
        "and Reut Tsarfaty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-06T09:36:14+00:00",
          "link": "https://arxiv.org/abs/2406.03897v1",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "2024-06-10T05:45:25+00:00",
          "link": "https://arxiv.org/abs/2406.03897v2",
          "size": "53kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T07:40:01+00:00",
          "link": "https://arxiv.org/abs/2406.03897v3",
          "size": "53kb",
          "version": "v3"
        }
      ],
      "title": "HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03897",
        "HTML": "https://arxiv.org/html/2406.03897v3",
        "PDF": "https://arxiv.org/pdf/2406.03897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the HeSum dataset for abstractive summarization in Hebrew, including detailed linguistic analysis and data creation processes, focusing primarily on dataset creation and processing."
      },
      "datasets": [
        {
          "dataset_name": "biunlp/HeSum",
          "downloads": "138",
          "likes": "0",
          "link": "https://huggingface.co/datasets/biunlp/HeSum"
        }
      ],
      "tasks": [
        "Abstractive Text Summarization",
        "Sentence",
        "Text Summarization"
      ],
      "repo_urls": [
        "https://github.com/OnlpLab/HeSum"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13857",
      "abstract": "Background. Systematic reviews in comparative effectiveness research require timely evidence synthesis. Preprints accelerate knowledge dissemination but vary in quality, posing challenges for systematic reviews.\n  Methods. We propose AutoConfidence (automated confidence assessment), an advanced framework for predicting preprint publication, which reduces reliance on manual curation and expands the range of predictors, including three key advancements: (1) automated data extraction using natural language processing techniques, (2) semantic embeddings of titles and abstracts, and (3) large language model (LLM)-driven evaluation scores. Additionally, we employed two prediction models: a random forest classifier for binary outcome and a survival cure model that predicts both binary outcome and publication risk over time.\n  Results. The random forest classifier achieved AUROC 0.692 with LLM-driven scores, improving to 0.733 with semantic embeddings and 0.747 with article usage metrics. The survival cure model reached AUROC 0.716 with LLM-driven scores, improving to 0.731 with semantic embeddings. For publication risk prediction, it achieved a concordance index of 0.658, increasing to 0.667 with semantic embeddings.\n  Conclusion. Our study advances the framework for preprint publication prediction through automated data extraction and multiple feature integration. By combining semantic embeddings with LLM-driven evaluations, AutoConfidence enhances predictive performance while reducing manual annotation burden. The framework has the potential to facilitate incorporation of preprint articles during the appraisal phase of systematic reviews, supporting researchers in more effective utilization of preprint resources.",
      "authors": [
        "Rui Yang",
        "Jiayi Tong",
        "Haoyuan Wang",
        "Hui Huang",
        "Ziyang Hu",
        "Peiyu Li",
        "Nan Liu",
        "Christopher J. Lindsell",
        "Michael J. Pencina",
        "Yong Chen",
        "Chuan Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T03:14:23+00:00",
          "link": "https://arxiv.org/abs/2503.13857v1",
          "size": "7670kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T15:21:06+00:00",
          "link": "https://arxiv.org/abs/2503.13857v2",
          "size": "7674kb",
          "version": "v2"
        },
        {
          "date": "2025-05-27T07:41:53+00:00",
          "link": "https://arxiv.org/abs/2503.13857v3",
          "size": "1680kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T08:59:48+00:00",
          "link": "https://arxiv.org/abs/2503.13857v4",
          "size": "1694kb",
          "version": "v4"
        }
      ],
      "title": "Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13857",
        "PDF": "https://arxiv.org/pdf/2503.13857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper touches on automated data extraction using NLP and LLM-driven evaluation scores, but primarily focuses on preprint publication prediction rather than LLM training data processing."
      },
      "tasks": [
        "Articles",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00927",
      "abstract": "Soft attention is a critical mechanism powering LLMs to locate relevant parts within a given context. However, individual attention weights are determined by the similarity of only a single query and key token vector. This \"single token attention\" bottlenecks the amount of information used in distinguishing a relevant part from the rest of the context. To address this issue, we propose a new attention method, Multi-Token Attention (MTA), which allows LLMs to condition their attention weights on multiple query and key vectors simultaneously. This is achieved by applying convolution operations over queries, keys and heads, allowing nearby queries and keys to affect each other's attention weights for more precise attention. As a result, our method can locate relevant context using richer, more nuanced information that can exceed a single vector's capacity. Through extensive evaluations, we demonstrate that MTA achieves enhanced performance on a range of popular benchmarks. Notably, it outperforms Transformer baseline models on standard language modeling tasks, and on tasks that require searching for information within long contexts, where our method's ability to leverage richer information proves particularly beneficial.",
      "authors": [
        "Olga Golovneva",
        "Tianlu Wang",
        "Jason Weston",
        "Sainbayar Sukhbaatar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T15:59:32+00:00",
          "link": "https://arxiv.org/abs/2504.00927v1",
          "size": "2691kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:49:30+00:00",
          "link": "https://arxiv.org/abs/2504.00927v2",
          "size": "1889kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Token Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00927",
        "HTML": "https://arxiv.org/html/2504.00927v2",
        "PDF": "https://arxiv.org/pdf/2504.00927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a new attention mechanism, Multi-Token Attention, to improve LLMs' context handling; there is no focus on training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08649",
      "abstract": "We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that can produce formal theorem proofs in Lean 4, with verifier-integrated Long Chain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we continual to choose to posttrain existing strong prover models for further performance improvement. In our V2 version, we mainly upgrade the Reinforcement Learning (RL) with feedback provided by the Lean 4 verifier. Crucially, verifier feedback, such as indicating success or detailing specific errors, allows the LLM to become ``self-aware'' of the correctness of its own reasoning process and learn to reflexively correct errors. Leanabell-Prover-V2 directly optimizes LLM reasoning trajectories with multi-turn verifier interactions, together with feedback token masking for stable RL training and a simple reward strategy. Experiments show that Leanabell-Prover-V2 improves performance by 3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with DeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data and models are available at: https://github.com/Leanabell-LM/Leanabell-Prover-V2.",
      "authors": [
        "Xingguang Ji",
        "Yahui Liu",
        "Qi Wang",
        "Jingyuan Zhang",
        "Yang Yue",
        "Rui Shi",
        "Chenxi Sun",
        "Fuzheng Zhang",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:53:14+00:00",
          "link": "https://arxiv.org/abs/2507.08649v1",
          "size": "509kb",
          "version": "v1"
        }
      ],
      "title": "Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08649",
        "HTML": "https://arxiv.org/html/2507.08649v1",
        "PDF": "https://arxiv.org/pdf/2507.08649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents improvements in formal theorem proving via reinforcement learning but centers on model reasoning and verification, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06583",
      "abstract": "Wheel loaders in mines and construction sites repeatedly load soil from a pile to load receivers. Automating this task presents a challenging planning problem since each loading's performance depends on the pile state, which depends on previous loadings. We investigate an end-to-end optimization approach considering future loading outcomes and transportation costs between the pile and load receivers. To predict the evolution of the pile state and the loading performance, we use world models that leverage deep neural networks trained on numerous simulated loading cycles. A look-ahead tree search optimizes the sequence of loading actions by evaluating the performance of thousands of action candidates, which expand into subsequent action candidates under the predicted pile states recursively. Test results demonstrate that, over a horizon of 15 sequential loadings, the look-ahead tree search is 6% more efficient than a greedy strategy, which always selects the action that maximizes the current single loading performance, and 14% more efficient than using a fixed loading controller optimized for the nominal case.",
      "authors": [
        "Koji Aoshima and Eddie Wadbro and Martin Servin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-11T16:38:06+00:00",
          "link": "https://arxiv.org/abs/2501.06583v1",
          "size": "8527kb",
          "version": "v1"
        },
        {
          "date": "2025-04-13T19:58:37+00:00",
          "link": "https://arxiv.org/abs/2501.06583v2",
          "size": "8551kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T21:45:23+00:00",
          "link": "https://arxiv.org/abs/2501.06583v3",
          "size": "8540kb",
          "version": "v3"
        }
      ],
      "title": "Optimizing wheel loader performance -- an end-to-end approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06583",
        "HTML": "https://arxiv.org/html/2501.06583v3",
        "PDF": "https://arxiv.org/pdf/2501.06583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates optimizing wheel loader performance using end-to-end approaches and tree search strategies, which are unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.18489",
      "abstract": "We prove the following asymptotically tight lower bound for $k$-color discrepancy: For any $k \\geq 2$, there exists a hypergraph with $n$ hyperedges such that its $k$-color discrepancy is at least $\\Omega(\\sqrt{n})$. This improves on the previously known lower bound of $\\Omega(\\sqrt{n/\\log k})$ due to Caragiannis et al. (arXiv:2502.10516). As an application, we show that our result implies improved lower bounds for group fair division.",
      "authors": [
        "Pasin Manurangsi",
        "Raghu Meka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T16:58:59+00:00",
          "link": "https://arxiv.org/abs/2504.18489v1",
          "size": "12kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:46:56+00:00",
          "link": "https://arxiv.org/abs/2504.18489v2",
          "size": "12kb",
          "version": "v2"
        }
      ],
      "title": "Tight Lower Bound for Multicolor Discrepancy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18489",
        "HTML": "https://arxiv.org/html/2504.18489v2",
        "PDF": "https://arxiv.org/pdf/2504.18489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on theoretical bounds for multicolor discrepancy in hypergraphs and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04196",
      "abstract": "Air pollution poses a critical health threat in cities worldwide, with nitrogen dioxide levels in Cork, Ireland exceeding World Health Organization safety standards by up to $278\\%$. This study leverages artificial intelligence to predict air pollution with unprecedented accuracy, analyzing nearly ten years of data from five monitoring stations combined with 30 years of weather records. We evaluated 17 machine learning algorithms, with Extra Trees emerging as the optimal solution, achieving $77\\%$ prediction accuracy and significantly outperforming traditional forecasting methods. Our analysis reveals that meteorological conditions particularly temperature, wind speed, and humidity are the primary drivers of pollution levels, while traffic patterns and seasonal changes create predictable pollution cycles. Pollution exhibits dramatic seasonal variations, with winter levels nearly double those of summer, and daily rush-hour peaks reaching $120\\%$ above normal levels. While Cork's air quality shows concerning violations of global health standards, our models detected an encouraging $31\\%$ improvement from 2014 to 2022. This research demonstrates that intelligent forecasting systems can provide city planners and environmental officials with powerful prediction tools, enabling life-saving early warning systems and informed urban planning decisions. The technology exists today to transform urban air quality management. All research materials and code are freely available at: https://github.com/MdRashidunnabi/Air-Pollution-Analysis.git",
      "authors": [
        "Md Rashidunnabi",
        "Fahmida Faiza Ananna",
        "Kailash Hambarde",
        "Bruno Gabriel Nascimento Andrade",
        "Dean Venables",
        "Hugo Proenca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T00:11:11+00:00",
          "link": "https://arxiv.org/abs/2507.04196v1",
          "size": "13509kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T10:30:18+00:00",
          "link": "https://arxiv.org/abs/2507.04196v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Predicting Air Pollution in Cork, Ireland Using Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04196",
        "PDF": "https://arxiv.org/pdf/2507.04196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on predicting air pollution using machine learning and does not discuss any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08467",
      "abstract": "Floating-point programs form the foundation of modern science and engineering, providing the essential computational framework for a wide range of applications, such as safety-critical systems, aerospace engineering, and financial analysis. Floating-point errors can lead to severe consequences. Although floating-point errors widely exist, only a subset of inputs may trigger significant errors in floating-point programs. Therefore, it is crucial to determine whether a given input could produce such errors. Researchers tend to take the results of high-precision floating-point programs as oracles for detecting floating-point errors, which introduces two main limitations: (1) difficulty of implementation and (2) prolonged execution time. The two recent tools, ATOMU and FPCC, can partially address these issues. However, ATOMU suffers from false positives; while FPCC, though eliminating false positives, operates at a considerably slower speed.\n  To address these two challenges, we propose a novel approach named PI-detector to computing floating-point errors effectively and efficiently. Our approach is based on the observation that floating-point errors stem from large condition numbers in atomic operations (such as addition and subtraction), which then propagate and accumulate. PI-detector injects small perturbations into the operands of individual atomic operations within the program and compares the outcomes of the original program with the perturbed version to compute floating-point errors. We evaluate PI-detector with datasets from ATOMU and HSED, as well as a complex linear system-solving program. Experimental results demonstrate that PI-detector can perform efficient and accurate floating-point error computation.",
      "authors": [
        "Youshuai Tan",
        "Zhanwei Zhang",
        "Jinfu Chen",
        "Zishuo Ding",
        "Jifeng Xuan",
        "Weiyi Shang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:19:14+00:00",
          "link": "https://arxiv.org/abs/2507.08467v1",
          "size": "1524kb",
          "version": "v1"
        }
      ],
      "title": "Computing Floating-Point Errors by Injecting Perturbations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08467",
        "HTML": "https://arxiv.org/html/2507.08467v1",
        "PDF": "https://arxiv.org/pdf/2507.08467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes methods to compute floating-point errors, which is not related to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19034",
      "abstract": "Mappings from biological sequences (DNA, RNA, protein) to quantitative measures of sequence functionality play an important role in contemporary biology. We are interested in the related tasks of (i) inferring predictive sequence-to-function maps and (ii) decomposing sequence-function maps to elucidate the contributions of individual subsequences. Because each sequence-function map can be written as a weighted sum over subsequences in multiple ways, meaningfully interpreting these weights requires \"gauge-fixing,\" i.e., defining a unique representation for each map. Recent work has established that most existing gauge-fixed representations arise as the unique solutions to $L_2$-regularized regression in an overparameterized \"weight space\" where the choice of regularizer defines the gauge. Here, we establish the relationship between regularized regression in overparameterized weight space and Gaussian process approaches that operate in \"function space,\" i.e. the space of all real-valued functions on a finite set of sequences. We disentangle how weight space regularizers both impose an implicit prior on the learned function and restrict the optimal weights to a particular gauge. We also show how to construct regularizers that correspond to arbitrary explicit Gaussian process priors combined with a wide variety of gauges. Next, we derive the distribution of gauge-fixed weights implied by the Gaussian process posterior and demonstrate that even for long sequences this distribution can be efficiently computed for product-kernel priors using a kernel trick. Finally, we characterize the implicit function space priors associated with the most common weight space regularizers. Overall, our framework unifies and extends our ability to infer and interpret sequence-function relationships.",
      "authors": [
        "Samantha Petti",
        "Carlos Mart\\'i-G\\'omez",
        "Justin B. Kinney",
        "Juannan Zhou",
        "David M. McCandlish"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Genomics (q-bio.GN)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-26T22:00:42+00:00",
          "link": "https://arxiv.org/abs/2504.19034v1",
          "size": "35kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:07:37+00:00",
          "link": "https://arxiv.org/abs/2504.19034v2",
          "size": "35kb",
          "version": "v2"
        }
      ],
      "title": "On learning functions over biological sequence space: relating Gaussian process priors, regularization, and gauge fixing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19034",
        "HTML": "https://arxiv.org/html/2504.19034v2",
        "PDF": "https://arxiv.org/pdf/2504.19034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses inferring sequence-to-function maps for biological sequences and is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.05788",
      "abstract": "The emergence of conversational assistants has fundamentally reshaped user interactions with digital platforms. This paper introduces Flippi-a cutting-edge, end-to-end conversational assistant powered by large language models (LLMs) and tailored for the e-commerce sector. Flippi addresses the challenges posed by the vast and often overwhelming product landscape, enabling customers to discover products more efficiently through natural language dialogue. By accommodating both objective and subjective user requirements, Flippi delivers a personalized shopping experience that surpasses traditional search methods. This paper details how Flippi interprets customer queries to provide precise product information, leveraging advanced NLP techniques such as Query Reformulation, Intent Detection, Retrieval-Augmented Generation (RAG), Named Entity Recognition (NER), and Context Reduction. Flippi's unique capability to identify and present the most attractive offers on an e-commerce site is also explored, demonstrating how it empowers users to make cost-effective decisions. Additionally, the paper discusses Flippi's comparative analysis features, which help users make informed choices by contrasting product features, prices, and other relevant attributes. The system's robust architecture is outlined, emphasizing its adaptability for integration across various e-commerce platforms and the technological choices underpinning its performance and accuracy. Finally, a comprehensive evaluation framework is presented, covering performance metrics, user satisfaction, and the impact on customer engagement and conversion rates. By bridging the convenience of online shopping with the personalized assistance traditionally found in physical stores, Flippi sets a new standard for customer satisfaction and engagement in the digital marketplace.",
      "authors": [
        "Anand A. Rajasekar",
        "Praveen Tangarajan",
        "Anjali Nainani",
        "Amogh Batwal",
        "Vinay Rao Dandin",
        "Anusua Trivedi and Ozan Ersoy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:50:47+00:00",
          "link": "https://arxiv.org/abs/2507.05788v1",
          "size": "209kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T08:00:51+00:00",
          "link": "https://arxiv.org/abs/2507.05788v2",
          "size": "209kb",
          "version": "v2"
        }
      ],
      "title": "Flippi: End To End GenAI Assistant for E-Commerce",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05788",
        "HTML": "https://arxiv.org/html/2507.05788v2",
        "PDF": "https://arxiv.org/pdf/2507.05788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Flippi, an AI assistant for e-commerce using LLMs, detailing NLP techniques for query understanding in product discovery without discussing LLM training data processing or data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08151",
      "abstract": "The distillation of knowledge from Large Language Models (LLMs) into Smaller Language Models (SLMs), preserving the capabilities and performance of LLMs while reducing model size, has played a key role in the proliferation of LLMs. Because SLMs are considerably smaller than LLMs, they are often utilized in domains where human interaction is frequent but resources are highly constrained, e.g., smart phones. Therefore, it is crucial to ensure that empathy, a fundamental aspect of positive human interactions, already instilled into LLMs, is retained by SLMs after distillation. In this paper, we develop a comprehensive approach for effective empathy distillation from LLMs into SLMs. Our approach features a two-step fine-tuning process that fully leverages datasets of empathetic dialogue responses distilled from LLMs. We explore several distillation methods beyond basic direct prompting and propose four unique sets of prompts for targeted empathy improvement to significantly enhance the empathy distillation process. Our evaluations demonstrate that SLMs fine-tuned through the two-step fine-tuning process with distillation datasets enhanced by the targeted empathy improvement prompts significantly outperform the base SLM at generating empathetic responses with a win rate of 90%. Our targeted empathy improvement prompts substantially outperform the basic direct prompting with a 10% improvement in win rate.",
      "authors": [
        "Henry J. Xie",
        "Jinghan Zhang",
        "Xinhao Zhang",
        "and Kunpeng Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:20:02+00:00",
          "link": "https://arxiv.org/abs/2507.08151v1",
          "size": "9181kb",
          "version": "v1"
        }
      ],
      "title": "Distilling Empathy from Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08151",
        "HTML": "https://arxiv.org/html/2507.08151v1",
        "PDF": "https://arxiv.org/pdf/2507.08151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a two-step fine-tuning process that uses datasets of empathetic dialogue responses but focuses more on empathy distillation methods, not on processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08158",
      "abstract": "Differential Privacy (DP) is a family of definitions that bound the worst-case privacy leakage of a mechanism. One important feature of the worst-case DP guarantee is it naturally implies protections against adversaries with less prior information, more sophisticated attack goals, and complex measures of a successful attack. However, the analytical tradeoffs between the adversarial model and the privacy protections conferred by DP are not well understood thus far. To that end, this work sheds light on what the worst-case guarantee of DP implies about the success of attackers that are more representative of real-world privacy risks.\n  In this paper, we present a single flexible framework that generalizes and extends the patchwork of bounds on DP mechanisms found in prior work. Our framework allows us to compute high-probability guarantees for DP mechanisms on a large family of natural attack settings that previous bounds do not capture. One class of such settings is the approximate reconstruction of multiple individuals' data, such as inferring nearly entire columns of a tabular data set from noisy marginals and extracting sensitive information from DP-trained language models.\n  We conduct two empirical case studies to illustrate the versatility of our bounds and compare them to the success of state-of-the-art attacks. Specifically, we study attacks that extract non-uniform PII from a DP-trained language model, as well as multi-column reconstruction attacks where the adversary has access to some columns in the clear and attempts to reconstruct the remaining columns for each person's record. We find that the absolute privacy risk of attacking non-uniform data is highly dependent on the adversary's prior probability of success. Our high probability bounds give us a nuanced understanding of the privacy leakage of DP mechanisms in a variety of previously understudied attack settings.",
      "authors": [
        "Marika Swanberg",
        "Meenatchi Sundaram Muthu Selva Annamalai",
        "Jamie Hayes",
        "Borja Balle",
        "and Adam Smith"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:36:31+00:00",
          "link": "https://arxiv.org/abs/2507.08158v1",
          "size": "10025kb",
          "version": "v1"
        }
      ],
      "title": "Beyond the Worst Case: Extending Differential Privacy Guarantees to Realistic Adversaries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08158",
        "HTML": "https://arxiv.org/html/2507.08158v1",
        "PDF": "https://arxiv.org/pdf/2507.08158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses differential privacy in data mechanisms and its implications for privacy risks but does not involve processing of LLM training data or improvements in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.11436",
      "abstract": "We present evidence on how generative AI changes the work patterns of knowledge workers using data from a 6-month-long, cross-industry, randomized field experiment. Half of the 7,137 workers in the study received access to a generative AI tool integrated into the applications they already used for emails, document creation, and meetings. We find that access to the AI tool during the first year of its release primarily impacted behaviors that workers could change independently and not behaviors that require coordination to change: workers who used the tool in more than half of the sample weeks spent 3.6 fewer hours, or 31% less time on email each week (intent to treat estimate is 1.3 hours) and completed documents moderately faster, but did not significantly change time spent in meetings.",
      "authors": [
        "Eleanor Wiske Dillon",
        "Sonia Jaffe",
        "Nicole Immorlica",
        "Christopher T. Stanton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Machine Learning (cs.LG)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T17:52:00+00:00",
          "link": "https://arxiv.org/abs/2504.11436v1",
          "size": "1180kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T22:28:06+00:00",
          "link": "https://arxiv.org/abs/2504.11436v2",
          "size": "1154kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T21:43:32+00:00",
          "link": "https://arxiv.org/abs/2504.11436v3",
          "size": "1132kb",
          "version": "v3"
        }
      ],
      "title": "Shifting Work Patterns with Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11436",
        "HTML": "https://arxiv.org/html/2504.11436v3",
        "PDF": "https://arxiv.org/pdf/2504.11436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the impact of generative AI on work patterns, without any focus on LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08030",
      "abstract": "Generative AI models, including large language models (LLMs) and vision-language models (VLMs), are increasingly used to interpret medical images and answer clinical questions. Their responses often include inaccuracies; therefore, safety measures like medical disclaimers are critical to remind users that AI outputs are not professionally vetted or a substitute for medical advice. This study evaluated the presence of disclaimers in LLM and VLM outputs across model generations from 2022 to 2025. Using 500 mammograms, 500 chest X-rays, 500 dermatology images, and 500 medical questions, outputs were screened for disclaimer phrases. Medical disclaimer presence in LLM and VLM outputs dropped from 26.3% in 2022 to 0.97% in 2025, and from 19.6% in 2023 to 1.05% in 2025, respectively. By 2025, the majority of models displayed no disclaimers. As public models become more capable and authoritative, disclaimers must be implemented as a safeguard adapting to the clinical context of each output.",
      "authors": [
        "Sonali Sharma",
        "Ahmed M. Alaa",
        "Roxana Daneshjou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:50:30+00:00",
          "link": "https://arxiv.org/abs/2507.08030v1",
          "size": "11195kb",
          "version": "v1"
        }
      ],
      "title": "A Systematic Analysis of Declining Medical Safety Messaging in Generative AI Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08030",
        "HTML": "https://arxiv.org/html/2507.08030v1",
        "PDF": "https://arxiv.org/pdf/2507.08030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates medical safety messaging in generative AI models but does not focus on the specifics of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08265",
      "abstract": "The source detection problem in network analysis involves identifying the origins of diffusion processes, such as disease outbreaks or misinformation propagation. Traditional methods often focus on single sources, whereas real-world scenarios frequently involve multiple sources, complicating detection efforts. This study addresses the multiple-source detection (MSD) problem by integrating edge clustering algorithms into the community-based label propagation framework, effectively handling mixed-membership issues where nodes belong to multiple communities.\n  The proposed approach applies the automated latent space edge clustering model to a network, partitioning infected networks into edge-based clusters to identify multiple sources. Simulation studies on ADD HEALTH social network datasets demonstrate that this method achieves superior accuracy, as measured by the F1-Measure, compared to state-of-the-art clustering algorithms. The results highlight the robustness of edge clustering in accurately detecting sources, particularly in networks with complex and overlapping source regions. This work advances the applicability of clustering-based methods to MSD problems, offering improved accuracy and adaptability for real-world network analyses.",
      "authors": [
        "Haomin Li and Daniel K. Sewell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:22:16+00:00",
          "link": "https://arxiv.org/abs/2507.08265v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Addressing overlapping communities in multiple-source detection: An edge clustering approach for complex networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08265",
        "HTML": "https://arxiv.org/html/2507.08265v1",
        "PDF": "https://arxiv.org/pdf/2507.08265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with detecting multiple sources in complex networks via edge clustering, focusing on diffusion processes in networks, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08574",
      "abstract": "This study aims to develop a novel multi-modal fusion framework for brain tumor segmentation that integrates spatial-language-vision information through bidirectional interactive attention mechanisms to improve segmentation accuracy and boundary delineation. Methods: We propose two core components: Multi-modal Semantic Fusion Adapter (MSFA) integrating 3D MRI data with clinical text descriptions through hierarchical semantic decoupling, and Bidirectional Interactive Visual-semantic Attention (BIVA) enabling iterative information exchange between modalities. The framework was evaluated on BraTS 2020 dataset comprising 369 multi-institutional MRI scans. Results: The proposed method achieved average Dice coefficient of 0.8505 and 95% Hausdorff distance of 2.8256mm across enhancing tumor, tumor core, and whole tumor regions, outperforming state-of-the-art methods including SCAU-Net, CA-Net, and 3D U-Net. Ablation studies confirmed critical contributions of semantic and spatial modules to boundary precision. Conclusion: Multi-modal semantic fusion combined with bidirectional interactive attention significantly enhances brain tumor segmentation performance, establishing new paradigms for integrating clinical knowledge into medical image analysis.",
      "authors": [
        "Mingda Zhang",
        "Kaiwen Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:21:56+00:00",
          "link": "https://arxiv.org/abs/2507.08574v1",
          "size": "4067kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08574",
        "HTML": "https://arxiv.org/html/2507.08574v1",
        "PDF": "https://arxiv.org/pdf/2507.08574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for brain tumor segmentation using multimodal data integration and attention mechanisms, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.20653",
      "abstract": "Histopathology slide digitization introduces scanner-induced domain shift that can significantly impact computational pathology models based on deep learning methods. In the state-of-the-art, this shift is often characterized at a broad scale (slide-level or dataset-level) but not patch-level, which limits our comprehension of the impact of localized tissue characteristics on the accuracy of the deep learning models. To address this challenge, we present a domain shift analysis framework based on UWarp, a novel registration tool designed to accurately align histological slides scanned under varying conditions. UWarp employs a hierarchical registration approach, combining global affine transformations with fine-grained local corrections to achieve robust tissue patch alignment. We evaluate UWarp using two private datasets, CypathLung and BosomShieldBreast, containing whole slide images scanned by multiple devices. Our experiments demonstrate that UWarp outperforms existing open-source registration methods, achieving a median target registration error (TRE) of less than 4 pixels (<1 micrometer at 40x magnification) while significantly reducing computational time. Additionally, we apply UWarp to characterize scanner-induced local domain shift in the predictions of Breast-NEOprAIdict, a deep learning model for breast cancer pathological response prediction. We find that prediction variability is strongly correlated with tissue density on a given patch. Our findings highlight the importance of localized domain shift analysis and suggest that UWarp can serve as a valuable tool for improving model robustness and domain adaptation strategies in computational pathology.",
      "authors": [
        "Antoine Schieb",
        "Bilal Hadjadji",
        "Natalia Fernanda Valderrama",
        "Daniel Tshokola Mweze",
        "Valentin Derang\\`ere",
        "Laurent Arnould",
        "Sylvain Ladoire",
        "Alain Lalande",
        "Alessio Fiorin",
        "Carlos L\\'opez Pablo",
        "No\\`elia Gallardo Borr\\`as",
        "Shrief Abdelazeez",
        "Vincenzo Della Mea",
        "Anna Korzynska",
        "Louis-Oscar Morel",
        "Nathan Vin\\c{c}on"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T15:48:38+00:00",
          "link": "https://arxiv.org/abs/2503.20653v1",
          "size": "23494kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:57:07+00:00",
          "link": "https://arxiv.org/abs/2503.20653v2",
          "size": "22738kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T18:00:46+00:00",
          "link": "https://arxiv.org/abs/2503.20653v3",
          "size": "22738kb",
          "version": "v3"
        }
      ],
      "title": "UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20653",
        "PDF": "https://arxiv.org/pdf/2503.20653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on histopathology slide registration and the characterization of scanner-induced domain shifts, with no mention of LLM or training data processing."
      },
      "tasks": [
        "Domain Adaptation",
        "Image Registration",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08044",
      "abstract": "Foundation models are pre-trained on large-scale datasets and subsequently fine-tuned on small-scale datasets using parameter-efficient fine-tuning (PEFT) techniques like low-rank adapters (LoRA). In most previous works, LoRA weight matrices are randomly initialized with a fixed rank across all attachment points. In this paper, we improve convergence and final performance of LoRA fine-tuning, using our proposed data-driven weight initialization method, ConsNoTrainLoRA (CNTLoRA). We express LoRA initialization as a domain shift problem where we use multiple constraints relating the pre-training and fine-tuning activations. By reformulating these constraints, we obtain a closed-form estimate of LoRA weights that depends on pre-training weights and fine-tuning activation vectors and hence requires no training during initialization. This weight estimate is decomposed to initialize the up and down matrices with proposed flexibility of variable ranks. With the proposed initialization method, we fine-tune on downstream tasks such as image generation, image classification and image understanding. Both quantitative and qualitative results demonstrate that CNTLoRA outperforms standard and data-driven weight initialization methods. Extensive analyses and ablations further elucidate the design choices of our framework, providing an optimal recipe for faster convergence and enhanced performance.",
      "authors": [
        "Debasmit Das",
        "Hyoungwoo Park",
        "Munawar Hayat",
        "Seokeon Choi",
        "Sungrack Yun",
        "Fatih Porikli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:52:31+00:00",
          "link": "https://arxiv.org/abs/2507.08044v1",
          "size": "35919kb",
          "version": "v1"
        }
      ],
      "title": "ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08044",
        "HTML": "https://arxiv.org/html/2507.08044v1",
        "PDF": "https://arxiv.org/pdf/2507.08044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a data-driven weight initialization method for fine-tuning LLMs using LoRA, but primarily focuses on improving convergence and performance in fine-tuning rather than training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08730",
      "abstract": "Modern configurable software systems need to learn models that correlate configuration and performance. However, when the system operates in dynamic environments, the workload variations, hardware changes, and system updates will inevitably introduce concept drifts at different levels - global drifts, which reshape the performance landscape of the entire configuration space; and local drifts, which only affect certain sub-regions of that space. As such, existing offline and transfer learning approaches can struggle to adapt to these implicit and unpredictable changes in real-time, rendering configuration performance learning challenging. To address this, we propose DHDA, an online configuration performance learning framework designed to capture and adapt to these drifts at different levels. The key idea is that DHDA adapts to both the local and global drifts using dually hierarchical adaptation: at the upper level, we redivide the data into different divisions, within each of which the local model is retrained, to handle global drifts only when necessary. At the lower level, the local models of the divisions can detect local drifts and adapt themselves asynchronously. To balance responsiveness and efficiency, DHDA combines incremental updates with periodic full retraining to minimize redundant computation when no drifts are detected. Through evaluating eight software systems and against state-of-the-art approaches, we show that DHDA achieves considerably better accuracy and can effectively adapt to drifts with up to 2x improvements, while incurring reasonable overhead and is able to improve different local models in handling concept drift.",
      "authors": [
        "Zezhen Xiang",
        "Jingzhi Gong",
        "Tao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:31:42+00:00",
          "link": "https://arxiv.org/abs/2507.08730v1",
          "size": "1386kb",
          "version": "v1"
        }
      ],
      "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08730",
        "HTML": "https://arxiv.org/html/2507.08730v1",
        "PDF": "https://arxiv.org/pdf/2507.08730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes DHDA for drift adaptation in software systems configuration learning, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.01984",
      "abstract": "The focus of this paper is on operating the electric power grid in a secure manner when wildfire risks are high. This is a challenging problem because of the uncertain ways in which the fires can impact the operation of the power system. To address this challenge, we propose a novel preventive-corrective coordinated decision-making scheme that quickly mitigates both static and dynamic insecurities given the risk of active wildfires in a region. The scheme utilizes a comprehensive contingency analysis tool for multi-asset outages that leverages: (i) a Feasibility Test algorithm which exhaustively desaturates overloaded cut-sets to prevent cascading line outages, and (ii) a data-driven transient stability analyzer which alleviates dynamic instabilities. This tool is then used to operate a coordinated unit commitment/optimal power flow model that is designed to adapt to varying risk levels associated with wildfires. Depending on the allowed risk, the model balances economical operation and grid robustness. The results obtained using the IEEE 118-bus system indicate that the proposed approach alleviates system vulnerabilities to wildfires while also minimizing operational cost.",
      "authors": [
        "Satyaprajna Sahoo",
        "Anamitra Pal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T19:44:59+00:00",
          "link": "https://arxiv.org/abs/2410.01984v1",
          "size": "10741kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:34:53+00:00",
          "link": "https://arxiv.org/abs/2410.01984v2",
          "size": "11562kb",
          "version": "v2"
        }
      ],
      "title": "A Preventive-Corrective Scheme for Ensuring Power System Security During Active Wildfire Risks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01984",
        "PDF": "https://arxiv.org/pdf/2410.01984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a preventive-corrective scheme for power system security during wildfires, addressing challenges in grid operation; it does not discuss LLM training data processing."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04729",
      "abstract": "Many physical systems can be modelled as parameter-dependent variational problems. In numerous cases, multiple equilibria co-exist, requiring the evaluation of their stability, and the monitoring of transitions between them. Generally, the stability characteristics of the equilibria change near folds in the parameter space. The direction of stability changes is embedded in a specific projection of the solutions, known as distinguished bifurcation diagrams. In this article, we identify such projections for variational problems characterized by fixed-free ends -- a class of problems frequently encountered in mechanics. Using these diagrams, we study an Elastica subject to an end load applied through a rigid lever arm. Several instances of snap-back instability are reported, along with their dependence on system parameters through numerical examples. These findings have potential applications in the design of soft robot arms and other actuator designs.",
      "authors": [
        "Siva Prasad Chakri Dhanakoti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Soft Condensed Matter (cond-mat.soft)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T15:37:56+00:00",
          "link": "https://arxiv.org/abs/2501.04729v1",
          "size": "2047kb",
          "version": "v1"
        },
        {
          "date": "2025-02-21T00:08:09+00:00",
          "link": "https://arxiv.org/abs/2501.04729v2",
          "size": "7794kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T10:17:08+00:00",
          "link": "https://arxiv.org/abs/2501.04729v3",
          "size": "6394kb",
          "version": "v3"
        }
      ],
      "title": "Stability analysis through folds: An end-loaded elastic with a lever arm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04729",
        "HTML": "https://arxiv.org/html/2501.04729v3",
        "PDF": "https://arxiv.org/pdf/2501.04729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with stability analysis through folds in variational problems and mechanical systems, not related to LLM training data processing or any aspect of data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08270",
      "abstract": "The emergence of autonomous Large Language Model (LLM) agents capable of tool usage has introduced new safety risks that go beyond traditional conversational misuse. These agents, empowered to execute external functions, are vulnerable to both user-initiated threats (e.g., adversarial prompts) and tool-initiated threats (e.g., malicious outputs from compromised tools). In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning. We introduce a tri-modal taxonomy, including benign, malicious, and sensitive for both user prompts and tool responses, and define a policy-driven decision model. Our framework employs a custom-designed sandbox environment that simulates real-world tool execution and allows fine-grained reward shaping. Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks. Our results show that safety and effectiveness can be jointly optimized, laying the groundwork for trustworthy deployment of autonomous LLM agents.",
      "authors": [
        "Zeyang Sha and Hanling Tian and Zhuoer Xu and Shiwen Cui and Changhua Meng and Weiqiang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:34:16+00:00",
          "link": "https://arxiv.org/abs/2507.08270v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "Agent Safety Alignment via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08270",
        "HTML": "https://arxiv.org/html/2507.08270v1",
        "PDF": "https://arxiv.org/pdf/2507.08270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a safety-alignment framework for LLM agents via reinforcement learning, focusing on safety rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08299",
      "abstract": "Next-generation wireless networks (xG) must provide ubiquitous connectivity while enhancing user experience in both densely populated urban areas and rural regions. To achieve this, a disruptive network architecture is essential, and high altitude platform stations (HAPS) offer a promising solution. By integrating HAPS with terrestrial networks, we can create HAPS-empowered vertical heterogeneous networks (vHetNets), which significantly improve coverage and capacity, as well as support emerging use cases. In HAPS-empowered vHetNets, different tiers can share the same spectrum, forming harmonized spectrum vHetNets that enhance spectral efficiency (SE). However, we face two major challenges: i) co-channel interference in harmonized spectrum vHetNets, and ii) the large-scale nature of the network. To address the first challenge, we adopt a cell-free approach as the underlying network architecture for the HAPS-empowered vHetNet. In this approach, base stations use beamforming to direct high-gain, narrow beams toward users, which helps mitigate interference. However, this creates a nonconvex and high-dimensional optimization problem, which highlights the second challenge of dealing with a large-scale network. Consequently, centralized solutions become impractical due to the computational and communication overhead involved. The standard two-block alternating direction method of multipliers (ADMM) is one option, but nonconvex constraints can hinder its convergence. As an alternative, we have developed a two-level distributed proportional fairness beamforming weight design (PFBWD) algorithm. This algorithm uses a combination of the augmented Lagrangian method (ALM) and a three-block ADMM framework. The proposed method effectively tackles nonconvexity, reduces complexity, and enables scalable, distributed optimization with guaranteed convergence.",
      "authors": [
        "Afsoon Alidadi Shamsabadi",
        "Animesh Yadav",
        "and Halim Yanikomeroglu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:09:44+00:00",
          "link": "https://arxiv.org/abs/2507.08299v1",
          "size": "3842kb",
          "version": "v1"
        }
      ],
      "title": "Two-Level Distributed Interference Management for Large-Scale HAPS-Empowered vHetNets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08299",
        "HTML": "https://arxiv.org/html/2507.08299v1",
        "PDF": "https://arxiv.org/pdf/2507.08299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses interference management in wireless networks, which is unrelated to LLM training data processing or language model datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08364",
      "abstract": "Considerable advancements have been achieved in SLAM methods tailored for structured environments, yet their robustness under challenging corner cases remains a critical limitation. Although multi-sensor fusion approaches integrating diverse sensors have shown promising performance improvements, the research community faces two key barriers: On one hand, the lack of standardized and configurable benchmarks that systematically evaluate SLAM algorithms under diverse degradation scenarios hinders comprehensive performance assessment. While on the other hand, existing SLAM frameworks primarily focus on fusing a limited set of sensor types, without effectively addressing adaptive sensor selection strategies for varying environmental conditions.\n  To bridge these gaps, we make three key contributions: First, we introduce M3DGR dataset: a sensor-rich benchmark with systematically induced degradation patterns including visual challenge, LiDAR degeneracy, wheel slippage and GNSS denial. Second, we conduct a comprehensive evaluation of forty SLAM systems on M3DGR, providing critical insights into their robustness and limitations under challenging real-world conditions. Third, we develop a resilient modular multi-sensor fusion framework named Ground-Fusion++, which demonstrates robust performance by coupling GNSS, RGB-D, LiDAR, IMU (Inertial Measurement Unit) and wheel odometry. Codes and datasets are publicly available.",
      "authors": [
        "Deteng Zhang",
        "Junjie Zhang",
        "Yan Sun",
        "Tao Li",
        "Hao Yin",
        "Hongzhao Xie and Jie Yin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:26:06+00:00",
          "link": "https://arxiv.org/abs/2507.08364v1",
          "size": "12509kb",
          "version": "v1"
        }
      ],
      "title": "Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08364",
        "HTML": "https://arxiv.org/html/2507.08364v1",
        "PDF": "https://arxiv.org/pdf/2507.08364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating SLAM systems using a new dataset with sensor degradation patterns. It does not involve processing LLM training data but rather assesses SLAM algorithms."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08496",
      "abstract": "While large language models (LLMs) have advanced procedural planning for embodied AI systems through strong reasoning abilities, the integration of multimodal inputs and counterfactual reasoning remains underexplored. To tackle these challenges, we introduce LLaPa, a vision-language model framework designed for multimodal procedural planning. LLaPa generates executable action sequences from textual task descriptions and visual environmental images using vision-language models (VLMs). Furthermore, we enhance LLaPa with two auxiliary modules to improve procedural planning. The first module, the Task-Environment Reranker (TER), leverages task-oriented segmentation to create a task-sensitive feature space, aligning textual descriptions with visual environments and emphasizing critical regions for procedural execution. The second module, the Counterfactual Activities Retriever (CAR), identifies and emphasizes potential counterfactual conditions, enhancing the model's reasoning capability in counterfactual scenarios. Extensive experiments on ActPlan-1K and ALFRED benchmarks demonstrate that LLaPa generates higher-quality plans with superior LCS and correctness, outperforming advanced models. The code and models are available https://github.com/sunshibo1234/LLaPa.",
      "authors": [
        "Shibo Sun",
        "Xue Li",
        "Donglin Di",
        "Mingjie Wei",
        "Lanshun Nie",
        "Wei-Nan Zhang",
        "Dechen Zhan",
        "Yang Song",
        "Lei Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:18:49+00:00",
          "link": "https://arxiv.org/abs/2507.08496v1",
          "size": "1413kb",
          "version": "v1"
        }
      ],
      "title": "LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08496",
        "HTML": "https://arxiv.org/html/2507.08496v1",
        "PDF": "https://arxiv.org/pdf/2507.08496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a vision-language model framework for procedural planning, emphasizing counterfactual awareness and task segmentation, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08686",
      "abstract": "Overfitting in deep neural networks occurs less frequently than expected. This is a puzzling observation, as theory predicts that greater model capacity should eventually lead to overfitting -- yet this is rarely seen in practice. But what if overfitting does occur, not globally, but in specific sub-regions of the data space? In this work, we introduce a novel score that measures the forgetting rate of deep models on validation data, capturing what we term local overfitting: a performance degradation confined to certain regions of the input space. We demonstrate that local overfitting can arise even without conventional overfitting, and is closely linked to the double descent phenomenon.\n  Building on these insights, we introduce a two-stage approach that leverages the training history of a single model to recover and retain forgotten knowledge: first, by aggregating checkpoints into an ensemble, and then by distilling it into a single model of the original size, thus enhancing performance without added inference cost.\n  Extensive experiments across multiple datasets, modern architectures, and training regimes validate the effectiveness of our approach. Notably, in the presence of label noise, our method -- Knowledge Fusion followed by Knowledge Distillation -- outperforms both the original model and independently trained ensembles, achieving a rare win-win scenario: reduced training and inference complexity.",
      "authors": [
        "Uri Stern",
        "Eli Corn and Daphna Weinshall"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:37:24+00:00",
          "link": "https://arxiv.org/abs/2507.08686v1",
          "size": "1490kb",
          "version": "v1"
        }
      ],
      "title": "Forget Me Not: Fighting Local Overfitting with Knowledge Fusion and Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08686",
        "HTML": "https://arxiv.org/html/2507.08686v1",
        "PDF": "https://arxiv.org/pdf/2507.08686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on addressing local overfitting in model training using ensemble aggregation and knowledge distillation but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08184",
      "abstract": "Graph neural networks have shown remarkable performance in forecasting stock movements, which arises from learning complex inter-dependencies between stocks and intra-dynamics of stocks. Existing approaches based on graph neural networks typically rely on static or manually defined factors to model changing inter-dependencies between stocks. Furthermore, these works often struggle to preserve hierarchical features within stocks. To bridge these gaps, this work presents the Energy-based Parallel Graph Attention Neural Network, a novel approach for predicting future movements for multiple stocks. First, it generates a dynamic stock graph with the energy difference between stocks and Boltzmann distribution, capturing evolving inter-dependencies between stocks. Then, a parallel graph attention mechanism is proposed to preserve the hierarchical intra-stock dynamics. Extensive experiments on five real-world datasets are conducted to validate the proposed approach, spanning from the US stock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). The experimental results demonstrate that EP-GAT consistently outperforms competitive five baselines on test periods across various metrics. The ablation studies and hyperparameter sensitivity analysis further validate the effectiveness of each module in the proposed method.",
      "authors": [
        "Zhuodong Jiang",
        "Pengju Zhang",
        "Peter Martin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:45:09+00:00",
          "link": "https://arxiv.org/abs/2507.08184v1",
          "size": "219kb",
          "version": "v1"
        }
      ],
      "title": "EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08184",
        "HTML": "https://arxiv.org/html/2507.08184v1",
        "PDF": "https://arxiv.org/pdf/2507.08184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with stock trend classification using graph neural networks and does not cover any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08194",
      "abstract": "A fundamental question in parallel computation, posed by Karp, Upfal, and Wigderson (FOCS 1985, JCSS 1988), asks: \\emph{given only independence-oracle access to a matroid on $n$ elements, how many rounds are required to find a basis using only polynomially many queries?} This question generalizes, among others, the complexity of finding bases of linear spaces, partition matroids, and spanning forests in graphs. In their work, they established an upper bound of $O(\\sqrt{n})$ rounds and a lower bound of $\\widetilde{\\Omega}(n^{1/3})$ rounds for this problem, and these bounds have remained unimproved since then.\n  In this work, we make the first progress in narrowing this gap by designing a parallel algorithm that finds a basis of an arbitrary matroid in $\\tilde{O}(n^{7/15})$ rounds (using polynomially many independence queries per round) with high probability, surpassing the long-standing $O(\\sqrt{n})$ barrier. Our approach introduces a novel matroid decomposition technique and other structural insights that not only yield this general result but also lead to a much improved new algorithm for the class of \\emph{partition matroids} (which underlies the $\\widetilde\\Omega(n^{1/3})$ lower bound of Karp, Upfal, and Wigderson). Specifically, we develop an $\\tilde{O}(n^{1/3})$-round algorithm, thereby settling the round complexity of finding a basis in partition matroids.",
      "authors": [
        "Sanjeev Khanna",
        "Aaron Putterman",
        "Junkai Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:04:36+00:00",
          "link": "https://arxiv.org/abs/2507.08194v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "On the Parallel Complexity of Finding a Matroid Basis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08194",
        "HTML": "https://arxiv.org/html/2507.08194v1",
        "PDF": "https://arxiv.org/pdf/2507.08194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on parallel computation complexity for finding a matroid basis, which does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08224",
      "abstract": "Large language models (LLMs) have shown promise in robotic procedural planning, yet their human-centric reasoning often omits the low-level, grounded details needed for robotic execution. Vision-language models (VLMs) offer a path toward more perceptually grounded plans, but current methods either rely on expensive, large-scale models or are constrained to narrow simulation settings. We introduce SelfReVision, a lightweight and scalable self-improvement framework for vision-language procedural planning. SelfReVision enables small VLMs to iteratively critique, revise, and verify their own plans-without external supervision or teacher models-drawing inspiration from chain-of-thought prompting and self-instruct paradigms. Through this self-distillation loop, models generate higher-quality, execution-ready plans that can be used both at inference and for continued fine-tuning. Using models varying from 3B to 72B, our results show that SelfReVision not only boosts performance over weak base VLMs but also outperforms models 100X the size, yielding improved control in downstream embodied tasks.",
      "authors": [
        "Chan Young Park",
        "Jillian Fisher",
        "Marius Memmel",
        "Dipika Khullar",
        "Andy Yun",
        "Abhishek Gupta",
        "Yejin Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:17:08+00:00",
          "link": "https://arxiv.org/abs/2507.08224v1",
          "size": "27057kb",
          "version": "v1"
        }
      ],
      "title": "Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08224",
        "HTML": "https://arxiv.org/html/2507.08224v1",
        "PDF": "https://arxiv.org/pdf/2507.08224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While focusing on improving VLMs for robotic planning, the paper mentions fine-tuning methods but does not primarily address LLM training data processing or creation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.08830",
      "abstract": "Several popular language models represent local contexts in an input text $x$ as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in $x$, with edges representing the (ordered) co-occurrence of two words within a sliding window of size $w$. However, this compressed representation is not generally bijective: some may be ambiguous, admitting several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and algorithmic point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size $w$, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When $w=2$, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the $\\#$P-hardness of enumeration. For $w \\ge 3$, we prove the hardness of all variants, even when $w$ is considered as a constant, with the notable exception of the undirected unweighted case for which we propose XP algorithms for both problems, tight due to a corresponding $W[1]-$hardness result. We conclude with an integer program formulation to solve the realizability problem, and a dynamic programming algorithm to solve the enumeration problem in instances of moderate sizes. This work leaves open the membership to NP of both problems, a non-trivial question due to the existence of minimum realizations having size exponential on the instance encoding.",
      "authors": [
        "Sammy Khalife",
        "Yann Ponty",
        "Laurent Bulteau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-13T22:22:51+00:00",
          "link": "https://arxiv.org/abs/2402.08830v1",
          "size": "70kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T00:42:38+00:00",
          "link": "https://arxiv.org/abs/2402.08830v2",
          "size": "109kb",
          "version": "v2"
        }
      ],
      "title": "Sequence graphs realizations and ambiguity in language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.08830",
        "PDF": "https://arxiv.org/pdf/2402.08830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores sequence graphs related to language models, addressing realizability and ambiguity from a combinatorial perspective, which touches briefly on data representation but not on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08715",
      "abstract": "For developing innovative systems architectures, modeling and optimization techniques have been central to frame the architecting process and define the optimization and modeling problems. In this context, for system-of-systems the use of efficient dedicated approaches (often physics-based simulations) is highly recommended to reduce the computational complexity of the targeted applications. However, exploring novel architectures using such dedicated approaches might pose challenges for optimization algorithms, including increased evaluation costs and potential failures. To address these challenges, surrogate-based optimization algorithms, such as Bayesian optimization utilizing Gaussian process models have emerged.",
      "authors": [
        "Paul Saves",
        "Jasper Bussemaker",
        "R\\'emi Lafage",
        "Thierry Lefebvre",
        "Nathalie Bartoli",
        "Youssef Diouane",
        "Joseph Morlier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:15:41+00:00",
          "link": "https://arxiv.org/abs/2507.08715v1",
          "size": "10369kb",
          "version": "v1"
        }
      ],
      "title": "System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08715",
        "HTML": "https://arxiv.org/html/2507.08715v1",
        "PDF": "https://arxiv.org/pdf/2507.08715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It focuses on system modeling and optimization frameworks for intermodal mobility, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07994",
      "abstract": "Keypoint detection, integral to modern machine perception, faces challenges in few-shot learning, particularly when source data from the same distribution as the query is unavailable. This gap is addressed by leveraging sketches, a popular form of human expression, providing a source-free alternative. However, challenges arise in mastering cross-modal embeddings and handling user-specific sketch styles. Our proposed framework overcomes these hurdles with a prototypical setup, combined with a grid-based locator and prototypical domain adaptation. We also demonstrate success in few-shot convergence across novel keypoints and classes through extensive experiments.",
      "authors": [
        "Subhajit Maity",
        "Ayan Kumar Bhunia",
        "Subhadeep Koley",
        "Pinaki Nath Chowdhury",
        "Aneeshan Sain",
        "Yi-Zhe Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:49+00:00",
          "link": "https://arxiv.org/abs/2507.07994v1",
          "size": "14072kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:49:08+00:00",
          "link": "https://arxiv.org/abs/2507.07994v2",
          "size": "14072kb",
          "version": "v2"
        }
      ],
      "title": "Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07994",
        "HTML": "https://arxiv.org/html/2507.07994v2",
        "PDF": "https://arxiv.org/pdf/2507.07994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses keypoint detection using sketches and few-shot learning, which involves model techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08404",
      "abstract": "Deep hashing is an effective approach for large-scale image retrieval. Current methods are typically classified by their supervision types: point-wise, pair-wise, and list-wise. Recent point-wise techniques (e.g., CSQ, MDS) have improved retrieval performance by pre-assigning a hash center to each class, enhancing the discriminability of hash codes across various datasets. However, these methods rely on data-independent algorithms to generate hash centers, which neglect the semantic relationships between classes and may degrade retrieval performance.\n  This paper introduces the concept of semantic hash centers, building on the idea of traditional hash centers. We hypothesize that hash centers of semantically related classes should have closer Hamming distances, while those of unrelated classes should be more distant. To this end, we propose a three-stage framework, SHC, to generate hash codes that preserve semantic structure.\n  First, we develop a classification network to identify semantic similarities between classes using a data-dependent similarity calculation that adapts to varying data distributions. Second, we introduce an optimization algorithm to generate semantic hash centers, preserving semantic relatedness while enforcing a minimum distance between centers to avoid excessively similar hash codes. Finally, a deep hashing network is trained using these semantic centers to convert images into binary hash codes.\n  Experimental results on large-scale retrieval tasks across several public datasets show that SHC significantly improves retrieval performance. Specifically, SHC achieves average improvements of +7.26%, +7.62%, and +11.71% in MAP@100, MAP@1000, and MAP@ALL metrics, respectively, over state-of-the-art methods.",
      "authors": [
        "Li Chen",
        "Rui Liu",
        "Yuxiang Zhou",
        "Xudong Ma",
        "Yong Chen",
        "Dell Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:22:27+00:00",
          "link": "https://arxiv.org/abs/2507.08404v1",
          "size": "5105kb",
          "version": "v1"
        }
      ],
      "title": "Deep Hashing with Semantic Hash Centers for Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08404",
        "HTML": "https://arxiv.org/html/2507.08404v1",
        "PDF": "https://arxiv.org/pdf/2507.08404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving image retrieval by enhancing the discriminability of hash codes using semantic hash centers. It does not discuss LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08422",
      "abstract": "Diffusion transformers have emerged as an alternative to U-net-based diffusion models for high-fidelity image and video generation, offering superior scalability. However, their heavy computation remains a major obstacle to real-world deployment. Existing acceleration methods primarily exploit the temporal dimension such as reusing cached features across diffusion timesteps. Here, we propose Region-Adaptive Latent Upsampling (RALU), a training-free framework that accelerates inference along spatial dimension. RALU performs mixed-resolution sampling across three stages: 1) low-resolution denoising latent diffusion to efficiently capture global semantic structure, 2) region-adaptive upsampling on specific regions prone to artifacts at full-resolution, and 3) all latent upsampling at full-resolution for detail refinement. To stabilize generations across resolution transitions, we leverage noise-timestep rescheduling to adapt the noise level across varying resolutions. Our method significantly reduces computation while preserving image quality by achieving up to 7.0$\\times$ speed-up on FLUX and 3.0$\\times$ on Stable Diffusion 3 with minimal degradation. Furthermore, RALU is complementary to existing temporal accelerations such as caching methods, thus can be seamlessly integrated to further reduce inference latency without compromising generation quality.",
      "authors": [
        "Wongi Jeong",
        "Kyungryeol Lee",
        "Hoigi Seo and Se Young Chun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:07:43+00:00",
          "link": "https://arxiv.org/abs/2507.08422v1",
          "size": "11501kb",
          "version": "v1"
        }
      ],
      "title": "Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08422",
        "HTML": "https://arxiv.org/html/2507.08422v1",
        "PDF": "https://arxiv.org/pdf/2507.08422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Region-Adaptive Latent Upsampling for diffusion transformers focused on accelerating image and video generation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.10381",
      "abstract": "Collaborative filtering generates recommendations by exploiting user-item similarities based on rating data, which often contains numerous unrated items. This paper proposes a nonnegative/binary matrix factorization (NBMF) algorithm modified for collaborative filtering and demonstrates that utilizing a low-latency Ising machine in NBMF is advantageous in terms of computation time. While previous studies have primarily applied NBMF to dense data, such as images, this study applies a modified NBMF to sparse data. Results show the benefits of using a low-latency Ising machine to implement the proposed method.",
      "authors": [
        "Yukino Terui",
        "Yuka Inoue",
        "Yohei Hamakawa",
        "Kosuke Tatsumura",
        "Kazue Kudo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T11:10:15+00:00",
          "link": "https://arxiv.org/abs/2410.10381v1",
          "size": "194kb",
          "version": "v1"
        },
        {
          "date": "2024-12-28T06:07:17+00:00",
          "link": "https://arxiv.org/abs/2410.10381v2",
          "size": "198kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T10:07:47+00:00",
          "link": "https://arxiv.org/abs/2410.10381v3",
          "size": "2937kb",
          "version": "v3"
        }
      ],
      "title": "Collaborative filtering based on nonnegative/binary matrix factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10381",
        "HTML": "https://arxiv.org/html/2410.10381v3",
        "PDF": "https://arxiv.org/pdf/2410.10381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study modifies collaborative filtering with NBMF, focusing on recommendations rather than any aspect of LLM training data processing or dataset creation."
      },
      "tasks": [
        "Collaborative Filtering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00467",
      "abstract": "We present the design process and findings of the pre-conference workshop at the Machine Learning for Healthcare Conference (2024) entitled Red Teaming Large Language Models for Healthcare, which took place on August 15, 2024. Conference participants, comprising a mix of computational and clinical expertise, attempted to discover vulnerabilities -- realistic clinical prompts for which a large language model (LLM) outputs a response that could cause clinical harm. Red-teaming with clinicians enables the identification of LLM vulnerabilities that may not be recognised by LLM developers lacking clinical expertise. We report the vulnerabilities found, categorise them, and present the results of a replication study assessing the vulnerabilities across all LLMs provided.",
      "authors": [
        "Vahid Balazadeh",
        "Michael Cooper",
        "David Pellow",
        "Atousa Assadi",
        "Jennifer Bell",
        "Mark Coatsworth",
        "Kaivalya Deshpande",
        "Jim Fackler",
        "Gabriel Funingana",
        "Spencer Gable-Cook",
        "Anirudh Gangadhar",
        "Abhishek Jaiswal",
        "Sumanth Kaja",
        "Christopher Khoury",
        "Amrit Krishnan",
        "Randy Lin",
        "Kaden McKeen",
        "Sara Naimimohasses",
        "Khashayar Namdar",
        "Aviraj Newatia",
        "Allan Pang",
        "Anshul Pattoo",
        "Sameer Peesapati",
        "Diana Prepelita",
        "Bogdana Rakova",
        "Saba Sadatamin",
        "Rafael Schulman",
        "Ajay Shah",
        "Syed Azhar Shah",
        "Syed Ahmar Shah",
        "Babak Taati",
        "Balagopal Unnikrishnan",
        "I\\~nigo Urteaga",
        "Stephanie Williams",
        "and Rahul G Krishnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T11:43:27+00:00",
          "link": "https://arxiv.org/abs/2505.00467v1",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:39:47+00:00",
          "link": "https://arxiv.org/abs/2505.00467v2",
          "size": "53kb",
          "version": "v2"
        }
      ],
      "title": "Red Teaming Large Language Models for Healthcare",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00467",
        "HTML": "https://arxiv.org/html/2505.00467v2",
        "PDF": "https://arxiv.org/pdf/2505.00467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating vulnerabilities in LLM responses in healthcare settings without discussing any aspect of training data processing or engineering."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Red Teaming"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01381",
      "abstract": "Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
      "authors": [
        "Tong Liu",
        "Yinuo Wang",
        "Xujie Song",
        "Wenjun Zou",
        "Liangfa Chen",
        "Likun Wang",
        "Bin Shuai",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T05:50:10+00:00",
          "link": "https://arxiv.org/abs/2507.01381v1",
          "size": "9125kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T04:38:33+00:00",
          "link": "https://arxiv.org/abs/2507.01381v2",
          "size": "7149kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T03:34:59+00:00",
          "link": "https://arxiv.org/abs/2507.01381v3",
          "size": "7145kb",
          "version": "v3"
        }
      ],
      "title": "Distributional Soft Actor-Critic with Diffusion Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01381",
        "HTML": "https://arxiv.org/html/2507.01381v3",
        "PDF": "https://arxiv.org/pdf/2507.01381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a reinforcement learning algorithm, DSAC-D, focusing on multimodal policy estimation. It does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07445",
      "abstract": "Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.",
      "authors": [
        "Weihao Tan",
        "Changjiu Jiang",
        "Yu Duan",
        "Mingcong Lei",
        "Jiageng Li",
        "Yitian Hong",
        "Xinrun Wang",
        "Bo An"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:48:28+00:00",
          "link": "https://arxiv.org/abs/2507.07445v1",
          "size": "6684kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:40:05+00:00",
          "link": "https://arxiv.org/abs/2507.07445v2",
          "size": "6684kb",
          "version": "v2"
        }
      ],
      "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07445",
        "PDF": "https://arxiv.org/pdf/2507.07445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark called StarDojo for evaluating multimodal LLMs in simulations but does not discuss the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07668",
      "abstract": "Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes.",
      "authors": [
        "Felix Frohnert",
        "Denny Lane B. Sombillo",
        "Evert van Nieuwenburg",
        "Patrick Emonts"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:49:17+00:00",
          "link": "https://arxiv.org/abs/2507.07668v1",
          "size": "2576kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:41:35+00:00",
          "link": "https://arxiv.org/abs/2507.07668v2",
          "size": "2576kb",
          "version": "v2"
        }
      ],
      "title": "Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07668",
        "HTML": "https://arxiv.org/html/2507.07668v2",
        "PDF": "https://arxiv.org/pdf/2507.07668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pole structure inference in hadronic states using machine learning techniques, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08051",
      "abstract": "Room impulse response estimation is essential for tasks like speech dereverberation, which improves automatic speech recognition. Most existing methods rely on either statistical signal processing or deep neural networks designed to replicate signal processing principles. However, combining statistical and physical modeling for RIR estimation remains largely unexplored. This paper proposes a novel approach integrating both aspects through a theoretically grounded model. The RIR is decomposed into interpretable parameters: white Gaussian noise filtered by a frequency-dependent exponential decay (e.g. modeling wall absorption) and an autoregressive filter (e.g. modeling microphone response). A variational free-energy cost function enables practical parameter estimation. As a proof of concept, we show that given dry and reverberant speech signals, the proposed method outperforms classical deconvolution in noisy environments, as validated by objective metrics.",
      "authors": [
        "Louis Lalay (LTCI",
        "IP Paris",
        "S2A)",
        "Mathieu Fontaine (LTCI",
        "IP Paris",
        "S2A)",
        "Roland Badeau (S2A",
        "LTCI",
        "IP Paris)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)",
        "Classical Physics (physics.class-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:05:46+00:00",
          "link": "https://arxiv.org/abs/2507.08051v1",
          "size": "239kb",
          "version": "v1"
        }
      ],
      "title": "Mod\\`ele physique variationnel pour l'estimation de r\\'eponses impulsionnelles de salles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08051",
        "PDF": "https://arxiv.org/pdf/2507.08051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses room impulse response estimation for speech dereverberation, not related to LLM training data processing. It combines statistical and physical modeling but does not involve LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.00381",
      "abstract": "Understanding the risks posed by extreme rainfall events necessitates both high-resolution products (to assess localized hazards) and extensive historical records (to capture rare occurrences). Radar and mesonet networks provide kilometer-scale precipitation fields, but with limited historical records and geographical coverage. Conversely, global gauge and blended products span decades, yet their coarse 30-50 km grids obscure local extremes. This work introduces Wasserstein Regularized Diffusion (WassDiff), a generative downscaling framework that integrates diffusion modeling with a distribution-matching (Wasserstein) regularizer, suppressing bias throughout the entire generative denoising process. Conditioned on 55 km CPC gauge-based precipitation and the 31 km ERA5 reanalysis, WassDiff generates 1 km precipitation estimates that remain well-calibrated to targets across the full intensity range, including the extremes. Comprehensive evaluations demonstrate that WassDiff outperforms existing state-of-the-art downscaling methods, delivering lower reconstruction error and reduced bias. Case studies further demonstrate its ability to reproduce realistic fine-scale structures and accurate peak intensities from extreme weather phenomena, such as tropical storms and cold fronts. By unlocking decades of high-resolution rainfall information from globally available coarse records, WassDiff offers a practical pathway toward more accurate flood-risk assessments and climate-adaptation planning.",
      "authors": [
        "Yuhao Liu",
        "James Doss-Gollin",
        "Qiushi Dai",
        "Ashok Veeraraghavan",
        "Guha Balakrishnan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T04:12:40+00:00",
          "link": "https://arxiv.org/abs/2410.00381v1",
          "size": "39922kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T20:41:38+00:00",
          "link": "https://arxiv.org/abs/2410.00381v2",
          "size": "23676kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T20:14:28+00:00",
          "link": "https://arxiv.org/abs/2410.00381v3",
          "size": "23676kb",
          "version": "v3"
        }
      ],
      "title": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00381",
        "HTML": "https://arxiv.org/html/2410.00381v3",
        "PDF": "https://arxiv.org/pdf/2410.00381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for downscaling precipitation data using generative frameworks, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.05481",
      "abstract": "This article studies the problem of distributed formation control for multiple robots by using onboard ultra wide band (UWB) distance and inertial odometer (IO) measurements.\n  Although this problem has been widely studied, a fundamental limitation of most works is that they require each robot's pose and sensor measurements are expressed in a common reference frame.\n  However, it is inapplicable for nonholonomic robot formations due to the practical difficulty of aligning IO measurements of individual robot in a common frame.\n  To address this problem, firstly, a concurrent-learning based estimator is firstly proposed to achieve relative localization between neighboring robots in a local frame.\n  Different from most relative localization methods in a global frame, both relative position and orientation in a local frame are estimated with only UWB ranging and IO\n  measurements.\n  Secondly, to deal with information loss caused by directed communication topology, a cooperative localization algorithm is introduced to estimate the relative pose to the leader robot.\n  Thirdly, based on the theoretical results on relative pose estimation, a distributed formation tracking controller is proposed for nonholonomic robots.\n  Both 3D and 2D real-world experiments conducted on aerial robots and grounded robots are provided to demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Kunrui Ze",
        "Wei Wang",
        "Shuoyu Yue",
        "Guibin Sun",
        "Kexin Liu",
        "Jinhu L\\\"u"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-08T11:19:45+00:00",
          "link": "https://arxiv.org/abs/2411.05481v1",
          "size": "15640kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:35:28+00:00",
          "link": "https://arxiv.org/abs/2411.05481v2",
          "size": "16636kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T08:45:47+00:00",
          "link": "https://arxiv.org/abs/2411.05481v3",
          "size": "16636kb",
          "version": "v3"
        }
      ],
      "title": "Relative Pose Estimation for Nonholonomic Robot Formation with UWB-IO Measurements (Extended version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05481",
        "HTML": "https://arxiv.org/html/2411.05481v3",
        "PDF": "https://arxiv.org/pdf/2411.05481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This article addresses relative pose estimation and formation control in robotics, making no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07883",
      "abstract": "Multi-task learning (MTL) enables a joint model to capture commonalities across multiple tasks, reducing computation costs and improving data efficiency. However, a major challenge in MTL optimization is task conflicts, where the task gradients differ in direction or magnitude, limiting model performance compared to single-task counterparts. Sharpness-aware minimization (SAM) minimizes task loss while simultaneously reducing the sharpness of the loss landscape. Our empirical observations show that SAM effectively mitigates task conflicts in MTL. Motivated by these findings, we explore integrating SAM into MTL but face two key challenges. While both the average loss gradient and individual task gradients-referred to as global and local information-contribute to SAM, how to combine them remains unclear. Moreover, directly computing each task gradient introduces significant computational and memory overheads. To address these challenges, we propose SAMO, a lightweight \\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization approach, that leverages a joint global-local perturbation. The local perturbations are approximated using only forward passes and are layerwise normalized to improve efficiency. Extensive experiments on a suite of multi-task benchmarks demonstrate both the effectiveness and efficiency of our method. Code is available at https://github.com/OptMN-Lab/SAMO.",
      "authors": [
        "Hao Ban",
        "Gokul Ram Subramani",
        "Kaiyi Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:06:02+00:00",
          "link": "https://arxiv.org/abs/2507.07883v1",
          "size": "537kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:57:39+00:00",
          "link": "https://arxiv.org/abs/2507.07883v2",
          "size": "536kb",
          "version": "v2"
        }
      ],
      "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07883",
        "HTML": "https://arxiv.org/html/2507.07883v2",
        "PDF": "https://arxiv.org/pdf/2507.07883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores a sharpness-aware approach for optimizing multitask learning but does not contribute directly to LLM training data processing. It is focused on optimization strategies for MTL, not on data collection or preprocessing for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08465",
      "abstract": "Multilayer perceptron (MLP), one of the most fundamental neural networks, is extensively utilized for classification and regression tasks. In this paper, we establish a new generalization error bound, which reveals how the variance of empirical loss influences the generalization ability of the learning model. Inspired by this learning bound, we advocate to reduce the variance of empirical loss to enhance the ability of MLP. As is well-known, bagging is a popular ensemble method to realize variance reduction. However, bagging produces the base training data sets by the Simple Random Sampling (SRS) method, which exhibits a high degree of randomness. To handle this issue, we introduce an ordered structure in the training data set by Rank Set Sampling (RSS) to further reduce the variance of loss and develop a RSS-MLP method. Theoretical results show that the variance of empirical exponential loss and the logistic loss estimated by RSS are smaller than those estimated by SRS, respectively. To validate the performance of RSS-MLP, we conduct comparison experiments on twelve benchmark data sets in terms of the two convex loss functions under two fusion methods. Extensive experimental results and analysis illustrate the effectiveness and rationality of the propose method.",
      "authors": [
        "Feijiang Li",
        "Liuya Zhang",
        "Jieting Wang",
        "Tao Yan",
        "Yuhua Qian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:17:58+00:00",
          "link": "https://arxiv.org/abs/2507.08465v1",
          "size": "516kb",
          "version": "v1"
        }
      ],
      "title": "Ranked Set Sampling-Based Multilayer Perceptron: Improving Generalization via Variance-Based Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08465",
        "HTML": "https://arxiv.org/html/2507.08465v1",
        "PDF": "https://arxiv.org/pdf/2507.08465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the improvement of generalization in multilayer perceptrons using Ranked Set Sampling, without addressing LLM training data processing or new dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08744",
      "abstract": "Motion capture technologies are increasingly used in creative and performance contexts but often exclude disabled practitioners due to normative assumptions in body modeling, calibration, and avatar representation. EqualMotion introduces a body-agnostic, wearable motion capture system designed through a disability-centred co-design approach. By enabling personalised calibration, integrating mobility aids, and adopting an inclusive visual language, EqualMotion supports diverse body types and movement styles. The system is developed collaboratively with disabled researchers and creatives, aiming to foster equitable participation in digital performance and prototyping. This paper outlines the system's design principles and highlights ongoing case studies in dance and music to evaluate accessibility in real-world creative workflows.",
      "authors": [
        "Clarice Hilton",
        "Kat Hawkins",
        "Phill Tew",
        "Freddie Collins",
        "Seb Madgwick",
        "Dominic Potts",
        "Tom Mitchell"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:51:40+00:00",
          "link": "https://arxiv.org/abs/2507.08744v1",
          "size": "1323kb",
          "version": "v1"
        }
      ],
      "title": "EqualMotion: Accessible Motion Capture for the Creative Industries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08744",
        "HTML": "https://arxiv.org/html/2507.08744v1",
        "PDF": "https://arxiv.org/pdf/2507.08744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "EqualMotion discusses motion capture technologies with a focus on disability-centred design. It does not involve LLM training data processing or any data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.05274",
      "abstract": "A wide variety of queueing systems can be naturally modeled as infinite-state Markov Decision Processes (MDPs). In the reinforcement learning (RL) context, a variety of algorithms have been developed to learn and optimize these MDPs. At the heart of many popular policy-gradient based learning algorithms, such as natural actor-critic, TRPO, and PPO, lies the Natural Policy Gradient (NPG) policy optimization algorithm. Convergence results for these RL algorithms rest on convergence results for the NPG algorithm. However, all existing results on the convergence of the NPG algorithm are limited to finite-state settings.\n  We study a general class of queueing MDPs, and prove a $O(1/\\sqrt{T})$ convergence rate for the NPG algorithm, if the NPG algorithm is initialized with the MaxWeight policy. This is the first convergence rate bound for the NPG algorithm for a general class of infinite-state average-reward MDPs. Moreover, our result applies to a beyond the queueing setting to any countably-infinite MDP satisfying certain mild structural assumptions, given a sufficiently good initial policy. Key to our result are state-dependent bounds on the relative value function achieved by the iterate policies of the NPG algorithm.",
      "authors": [
        "Isaac Grosof",
        "Siva Theja Maguluri",
        "R. Srikant"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T21:43:57+00:00",
          "link": "https://arxiv.org/abs/2402.05274v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2024-10-31T23:14:00+00:00",
          "link": "https://arxiv.org/abs/2402.05274v2",
          "size": "63kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T20:01:54+00:00",
          "link": "https://arxiv.org/abs/2402.05274v3",
          "size": "60kb",
          "version": "v3"
        }
      ],
      "title": "Convergence of Natural Policy Gradient for a Family of Infinite-State Queueing MDPs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.05274",
        "HTML": "https://arxiv.org/html/2402.05274v3",
        "PDF": "https://arxiv.org/pdf/2402.05274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies convergence of Natural Policy Gradient algorithms for infinite-state MDPs, which is unrelated to any aspect of LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.08352",
      "abstract": "Information measures can be constructed from R\\'enyi divergences much like mutual information from Kullback-Leibler divergence. One such information measure is known as Sibson $\\alpha$-mutual information and has received renewed attention recently in several contexts: concentration of measure under dependence, statistical learning, hypothesis testing, and estimation theory. In this paper, we survey and extend the state of the art. In particular, we introduce variational representations for Sibson $\\alpha$-mutual information and employ them in each described context to derive novel results. Namely, we produce generalized Transportation-Cost inequalities and Fano-type inequalities. We also present an overview of known applications, spanning from learning theory and Bayesian risk to universal prediction.",
      "authors": [
        "Amedeo Roberto Esposito",
        "Michael Gastpar",
        "Ibrahim Issa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-14T06:45:27+00:00",
          "link": "https://arxiv.org/abs/2405.08352v1",
          "size": "310kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T00:52:00+00:00",
          "link": "https://arxiv.org/abs/2405.08352v2",
          "size": "521kb",
          "version": "v2"
        }
      ],
      "title": "Sibson $\\alpha$-Mutual Information and Its Variational Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.08352",
        "HTML": "https://arxiv.org/html/2405.08352v2",
        "PDF": "https://arxiv.org/pdf/2405.08352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Sibson $\\alpha$-mutual information and its applications across various contexts. It does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06143",
      "abstract": "We investigate the multilingual and multimodal performance of a large language model-based artificial intelligence (AI) system, GPT-4o, using a diverse set of physics concept inventories spanning multiple languages and subject categories. The inventories, sourced from the PhysPort website, cover classical physics topics such as mechanics, electromagnetism, optics, and thermodynamics, as well as relativity, quantum mechanics, astronomy, mathematics, and laboratory skills. Unlike previous text-only studies, we uploaded the inventories as images to reflect what a student would see on paper, thereby assessing the system's multimodal functionality. Our results indicate variation in performance across subjects, with laboratory skills standing out as the weakest. We also observe differences across languages, with English and European languages showing the strongest performance. Notably, the relative difficulty of an inventory item is largely independent of the language of the survey. When comparing AI results to existing literature on student performance, we find that the AI system outperforms average post-instruction undergraduate students in all subject categories except laboratory skills. Furthermore, the AI performs worse on items requiring visual interpretation of images than on those that are purely text-based. While our exploratory findings show GPT-4o's potential usefulness in physics education, they highlight the critical need for instructors to foster students' ability to critically evaluate AI outputs, adapt curricula thoughtfully in response to AI advancements, and address equity concerns associated with AI integration.",
      "authors": [
        "Gerd Kortemeyer",
        "Marina Babayeva",
        "Giulia Polverini",
        "Ralf Widenhorn",
        "Bor Gregorcic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics Education (physics.ed-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T18:08:07+00:00",
          "link": "https://arxiv.org/abs/2501.06143v1",
          "size": "890kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T10:02:28+00:00",
          "link": "https://arxiv.org/abs/2501.06143v2",
          "size": "557kb",
          "version": "v2"
        },
        {
          "date": "2025-05-12T12:07:32+00:00",
          "link": "https://arxiv.org/abs/2501.06143v3",
          "size": "1309kb",
          "version": "v3"
        }
      ],
      "title": "Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06143",
        "HTML": "https://arxiv.org/html/2501.06143",
        "PDF": "https://arxiv.org/pdf/2501.06143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the use of physics concept inventories for evaluating a multilingual and multimodal AI system, but it does not focus on training data processing for LLMs; instead, it evaluates AI performance on existing datasets."
      },
      "tasks": [
        "Astronomy",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08115",
      "abstract": "This study proposes a novel spatial discretization procedure for the compressible Euler equations that guarantees entropy conservation at a discrete level for thermally perfect gases. The procedure is based on a locally conservative formulation, and extends the entropy-conserving schemes to the more realistic case of thermally perfect gases, while still guaranteeing preservation of both linear invariants and kinetic energy. The proposed methodology, which can also be extended to multicomponent gases and to an Asymptotically Entropy-Conservative formulation, shows advantages in terms of accuracy and robustness when compared to existing similar approaches.",
      "authors": [
        "Alessandro Aiello",
        "Carlo De Michele",
        "Gennaro Coppola"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:56:28+00:00",
          "link": "https://arxiv.org/abs/2507.08115v1",
          "size": "389kb",
          "version": "v1"
        }
      ],
      "title": "Entropy-conservative numerical fluxes for compressible Euler equations with thermally perfect gas models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08115",
        "HTML": "https://arxiv.org/html/2507.08115v1",
        "PDF": "https://arxiv.org/pdf/2507.08115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel numerical flux for compressible Euler equations and thermally perfect gases, focusing on spatial discretization procedures for entropy conservation, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08243",
      "abstract": "Density and geometry have long served as two of the fundamental guiding principles in clustering algorithm design, with algorithm usually focusing either on the density structure of the data (e.g., HDBSCAN and Density Peak Clustering) or the complexity of underlying geometry (e.g., manifold clustering algorithms).\n  In this paper, we identify and formalize a recurring but often overlooked interaction between distribution and geometry and leverage this insight to design our clustering enhancement framework CoreSPECT (Core Space Projection-based Enhancement of Clustering Techniques). Our framework boosts the performance of simple algorithms like K-Means and GMM by applying them to strategically selected regions, then extending the partial partition to a complete partition for the dataset using a novel neighborhood graph based multi-layer propagation procedure.\n  We apply our framework on 15 datasets from three different domains and obtain consistent and substantial gain in clustering accuracy for both K-Means and GMM. On average, our framework improves the ARI of K-Means by 40% and of GMM by 14%, often surpassing the performance of both manifold-based and recent density-based clustering algorithms. We further support our framework with initial theoretical guarantees, ablation to demonstrate the usefulness of the individual steps and with evidence of robustness to noise.",
      "authors": [
        "Chandra Sekhar Mukherjee",
        "Joonyoung Bae",
        "and Jiapeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:13:17+00:00",
          "link": "https://arxiv.org/abs/2507.08243v1",
          "size": "1072kb",
          "version": "v1"
        }
      ],
      "title": "CoreSPECT: Enhancing Clustering Algorithms via an Interplay of Density and Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08243",
        "HTML": "https://arxiv.org/html/2507.08243v1",
        "PDF": "https://arxiv.org/pdf/2507.08243"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about enhancing clustering algorithms and does not discuss LLM training data processing or contribute to the creation or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08344",
      "abstract": "In this paper, we present MM-Gesture, the solution developed by our team HFUT-VUT, which ranked 1st in the micro-gesture classification track of the 3rd MiGA Challenge at IJCAI 2025, achieving superior performance compared to previous state-of-the-art methods. MM-Gesture is a multimodal fusion framework designed specifically for recognizing subtle and short-duration micro-gestures (MGs), integrating complementary cues from joint, limb, RGB video, Taylor-series video, optical-flow video, and depth video modalities. Utilizing PoseConv3D and Video Swin Transformer architectures with a novel modality-weighted ensemble strategy, our method further enhances RGB modality performance through transfer learning pre-trained on the larger MA-52 dataset. Extensive experiments on the iMiGUE benchmark, including ablation studies across different modalities, validate the effectiveness of our proposed approach, achieving a top-1 accuracy of 73.213%.",
      "authors": [
        "Jihao Gu",
        "Fei Wang",
        "Kun Li",
        "Yanyan Wei",
        "Zhiliang Wu",
        "Dan Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:45:42+00:00",
          "link": "https://arxiv.org/abs/2507.08344v1",
          "size": "2552kb",
          "version": "v1"
        }
      ],
      "title": "MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08344",
        "HTML": "https://arxiv.org/html/2507.08344v1",
        "PDF": "https://arxiv.org/pdf/2507.08344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a multimodal fusion framework for gesture recognition, focusing on model architecture and performance enhancement rather than LLM training data preparation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08637",
      "abstract": "Transformer models are computationally costly on long sequences since regular attention has quadratic $O(n^2)$ time complexity. We introduce Wavelet-Enhanced Random Spectral Attention (WERSA), a novel mechanism of linear $O(n)$ time complexity that is pivotal to enable successful long-sequence processing without the performance trade-off. WERSA merges content-adaptive random spectral features together with multi-resolution Haar wavelets and learnable parameters to selectively attend to informative scales of data while preserving linear efficiency.\n  Large-scale comparisons \\textbf{on single GPU} and across various benchmarks (vision, NLP, hierarchical reasoning) and various attention mechanisms (like Multiheaded Attention, Flash-Attention-2, FNet, Linformer, Performer, Waveformer), reveal uniform advantages of WERSA. It achieves best accuracy in all tests. On ArXiv classification, WERSA improves accuracy over vanilla attention by 1.2\\% (86.2\\% vs 85.0\\%) while cutting training time by 81\\% (296s vs 1554s) and FLOPS by 73.4\\% (26.2G vs 98.4G). Significantly, WERSA excels where vanilla and FlashAttention-2 fail: on ArXiv-128k's extremely lengthy sequences, it achieves best accuracy (79.1\\%) and AUC (0.979) among viable methods, operating on data that gives Out-Of-Memory errors to quadratic methods while being \\textbf{twice as fast} as Waveformer, its next-best competitor.\n  By significantly reducing computational loads without compromising accuracy, WERSA makes possible more practical, more affordable, long-context models, in particular on low-resource hardware, for more sustainable and more scalable AI development.",
      "authors": [
        "Vincenzo Dentamaro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:40:40+00:00",
          "link": "https://arxiv.org/abs/2507.08637v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08637",
        "HTML": "https://arxiv.org/html/2507.08637v1",
        "PDF": "https://arxiv.org/pdf/2507.08637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel attention mechanism to efficiently process long sequences in transformers, focusing mainly on model architecture and computational efficiency rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2108.12003",
      "abstract": "Temporal logics are widely used by the Formal Methods and AI communities. Linear Temporal Logic is a popular temporal logic and is valued for its ease of use as well as its balance between expressiveness and complexity. LTL is equivalent in expressiveness to Monadic First-Order Logic and satisfiability for LTL is PSPACE-complete. Linear Dynamic Logic (LDL), another temporal logic, is equivalent to Monadic Second-Order Logic, but its method of satisfiability checking cannot be applied to a nontrivial subset of LDL formulas.\n\nHere we introduce Automata Linear Dynamic Logic on Finite Traces (ALDL_f) and show that satisfiability for ALDL_f formulas is in PSPACE. A variant of Linear Dynamic Logic on Finite Traces (LDL_f), ALDL_f combines propositional logic with nondeterministic finite automata (NFA) to express temporal constraints. ALDL$_f$ is equivalent in expressiveness to Monadic Second-Order Logic. This is a gain in expressiveness over LTL at no cost.",
      "authors": [
        "Kevin W. Smith",
        "Moshe Y. Vardi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2021-08-26T19:14:50+00:00",
          "link": "https://arxiv.org/abs/2108.12003v1",
          "size": "392kb",
          "version": "v1"
        },
        {
          "date": "2024-04-27T14:45:11+00:00",
          "link": "https://arxiv.org/abs/2108.12003v2",
          "size": "427kb",
          "version": "v2"
        },
        {
          "date": "2024-09-30T01:34:47+00:00",
          "link": "https://arxiv.org/abs/2108.12003v3",
          "size": "48kb",
          "version": "v3"
        },
        {
          "date": "2025-06-15T15:20:56+00:00",
          "link": "https://arxiv.org/abs/2108.12003v4",
          "size": "41kb",
          "version": "v4"
        },
        {
          "date": "2025-07-08T10:33:10+00:00",
          "link": "https://arxiv.org/abs/2108.12003v5",
          "size": "42kb",
          "version": "v5"
        },
        {
          "date": "2025-07-10T19:08:35+00:00",
          "link": "https://arxiv.org/abs/2108.12003v6",
          "size": "42kb",
          "version": "v6"
        }
      ],
      "title": "Automata Linear Dynamic Logic on Finite Traces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2108.12003",
        "PDF": "https://arxiv.org/pdf/2108.12003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a new temporal logic (ALDL_f) and discusses its satisfiability, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.18865",
      "abstract": "Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences. Multiple methods recover such directions and build probes that are described as uncovering a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon, looking closely at the impact of context on the probes. Our experiments establish where in the LLM the probe's predictions are (most) sensitive to the presence of related sentences, and how to best characterize this kind of sensitivity. We do so by measuring different types of consistency errors that occur after probing an LLM whose inputs consist of hypotheses preceded by (negated) supporting and contradicting sentences. We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these truth-value directions influences the position of an entailed or contradicted sentence along that same direction. We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs. Our experiments show that the type of errors depend on the layer, the model, and the kind of data. Finally, our results suggest that truth-value directions are causal mediators in the inference process that incorporates in-context information.",
      "authors": [
        "Stefan F. Schouten",
        "Peter Bloem",
        "Ilia Markov",
        "Piek Vossen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-29T16:52:57+00:00",
          "link": "https://arxiv.org/abs/2404.18865v1",
          "size": "1119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:21:39+00:00",
          "link": "https://arxiv.org/abs/2404.18865v2",
          "size": "1051kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T07:37:47+00:00",
          "link": "https://arxiv.org/abs/2404.18865v3",
          "size": "1054kb",
          "version": "v3"
        }
      ],
      "title": "Truth-value judgment in language models: 'truth directions' are context sensitive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.18865",
        "HTML": "https://arxiv.org/html/2404.18865v3",
        "PDF": "https://arxiv.org/pdf/2404.18865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates truth-value judgment in language models, focusing on context sensitivity in probes, but it does not focus primarily on training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.04088",
      "abstract": "With the rapid expansion of cloud computing infrastructure, energy consumption has become a critical challenge, driving the need for accurate and efficient prediction models. This study proposes a novel Vector Weighted Average Kernel Extreme Learning Machine (VWAA-KELM) model to enhance energy consumption prediction in cloud computing environments. By integrating a vector weighted average algorithm (VWAA) with kernel extreme learning machine (KELM), the proposed model dynamically adjusts feature weights and optimizes kernel functions, significantly improving prediction accuracy and generalization. Experimental results demonstrate the superior performance of VWAA-KELM: 94.7% of test set prediction errors fall within [0, 50] units, with only three cases exceeding 100 units, indicating strong stability. The model achieves a coefficient of determination (R2) of 0.987 in the training set (RMSE = 28.108, RPD = 8.872) and maintains excellent generalization with R2 = 0.973 in the test set (RMSE = 43.227, RPD = 6.202). Visual analysis confirms that predicted values closely align with actual energy consumption trends, avoiding overfitting while capturing nonlinear dependencies. A key innovation of this study is the introduction of adaptive feature weighting, allowing the model to dynamically assign importance to different input parameters, thereby enhancing high-dimensional data processing. This advancement provides a scalable and efficient approach for optimizing cloud data center energy consumption. Beyond cloud computing, the proposed hybrid framework has broader applications in Internet of Things (IoT) and edge computing, supporting real-time energy management and intelligent resource allocation.",
      "authors": [
        "Yuqing Wang",
        "Xiao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T04:52:50+00:00",
          "link": "https://arxiv.org/abs/2503.04088v1",
          "size": "548kb",
          "version": "v1"
        },
        {
          "date": "2025-04-10T17:04:01+00:00",
          "link": "https://arxiv.org/abs/2503.04088v2",
          "size": "574kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T21:38:07+00:00",
          "link": "https://arxiv.org/abs/2503.04088v3",
          "size": "1119kb",
          "version": "v3"
        }
      ],
      "title": "Cloud Computing Energy Consumption Prediction Based on Kernel Extreme Learning Machine Algorithm Improved by Vector Weighted Average Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04088",
        "PDF": "https://arxiv.org/pdf/2503.04088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a model for energy consumption prediction in cloud computing without discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Cloud Computing",
        "Edge-computing",
        "energy management",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04165",
      "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their biological plausibility and energy efficiency, positioning them as strong alternatives to Artificial Neural Networks (ANNs) in neuromorphic computing applications. SNNs inherently process temporal information by leveraging the precise timing of spikes, but balancing temporal feature utilization with low energy consumption remains a challenge. In this work, we introduce Temporal Shift module for Spiking Neural Networks (TS-SNN), which incorporates a novel Temporal Shift (TS) module to integrate past, present, and future spike features within a single timestep via a simple yet effective shift operation. A residual combination method prevents information loss by integrating shifted and original features. The TS module is lightweight, requiring only one additional learnable parameter, and can be seamlessly integrated into existing architectures with minimal additional computational cost. TS-SNN achieves state-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100 (80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low energy consumption. This work marks a significant step forward in developing efficient and accurate SNN architectures.",
      "authors": [
        "Kairong Yu",
        "Tianqing Zhang",
        "Qi Xu",
        "Gang Pan",
        "Hongwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T06:34:34+00:00",
          "link": "https://arxiv.org/abs/2505.04165v1",
          "size": "1021kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T08:17:59+00:00",
          "link": "https://arxiv.org/abs/2505.04165v2",
          "size": "1021kb",
          "version": "v2"
        },
        {
          "date": "2025-05-13T13:09:28+00:00",
          "link": "https://arxiv.org/abs/2505.04165v3",
          "size": "1830kb",
          "version": "v3"
        },
        {
          "date": "2025-05-16T13:56:30+00:00",
          "link": "https://arxiv.org/abs/2505.04165v4",
          "size": "1830kb",
          "version": "v4"
        },
        {
          "date": "2025-07-11T13:45:05+00:00",
          "link": "https://arxiv.org/abs/2505.04165v5",
          "size": "1029kb",
          "version": "v5"
        }
      ],
      "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04165",
        "HTML": "https://arxiv.org/html/2505.04165v5",
        "PDF": "https://arxiv.org/pdf/2505.04165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a Temporal Shift module for Spiking Neural Networks, focusing on model design and performance improvement, not on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2208.02010",
      "abstract": "Human safety has always been the main priority when working near an industrial robot. With the rise of Human-Robot Collaborative environments, physical barriers to avoiding collisions have been disappearing, increasing the risk of accidents and the need for solutions that ensure a safe Human-Robot Collaboration. This paper proposes a safety system that implements Speed and Separation Monitoring (SSM) type of operation. For this, safety zones are defined in the robot's workspace following current standards for industrial collaborative robots. A deep learning-based computer vision system detects, tracks, and estimates the 3D position of operators close to the robot. The robot control system receives the operator's 3D position and generates 3D representations of them in a simulation environment. Depending on the zone where the closest operator was detected, the robot stops or changes its operating speed. Three different operation modes in which the human and robot interact are presented. Results show that the vision-based system can correctly detect and classify in which safety zone an operator is located and that the different proposed operation modes ensure that the robot's reaction and stop time are within the required time limits to guarantee safety.",
      "authors": [
        "Lina Mar\\'ia Amaya-Mej\\'ia",
        "Nicol\\'as Duque-Su\\'arez",
        "Daniel Jaramillo-Ram\\'irez",
        "Carol Martinez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-03T12:31:03+00:00",
          "link": "https://arxiv.org/abs/2208.02010v1",
          "size": "4494kb",
          "version": "v1"
        }
      ],
      "title": "Vision-Based Safety System for Barrierless Human-Robot Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.02010",
        "PDF": "https://arxiv.org/pdf/2208.02010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a vision-based safety system for robots, focusing on human-robot collaboration, which is not related to LLM training data processing."
      },
      "tasks": [
        "Position"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14123",
      "abstract": "Tokenization is used almost universally by modern language models, enabling efficient text representation using multi-byte or multi-character tokens. However, prior work has shown that tokenization can introduce distortion into the model's generations, an issue known as the Prompt Boundary Problem (PBP). For example, users are often advised not to end their prompts with a space because it prevents the model from including the space as part of the next token. While this heuristic is effective in English, the underlying PBP continues to affect languages such as Chinese as well as code generation, where tokens often do not line up with word and syntactic boundaries. In this work, we present an inference-time method to convert any autoregressive LM with a BPE tokenizer into a character-level or byte-level LM. Our method efficiently solves the PBP and is also able to unify the vocabularies of language models with different tokenizers, allowing one to ensemble LMs with different tokenizers at inference time or transfer the post-training from one model to another using proxy-tuning. We demonstrate in experiments that the ensemble and proxy-tuned models outperform their constituents on downstream evals. Code is available at https://github.com/SewoongLab/byte-sampler .",
      "authors": [
        "Jonathan Hayase",
        "Alisa Liu",
        "Noah A. Smith",
        "Sewoong Oh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T02:37:04+00:00",
          "link": "https://arxiv.org/abs/2506.14123v1",
          "size": "49kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:43:41+00:00",
          "link": "https://arxiv.org/abs/2506.14123v2",
          "size": "47kb",
          "version": "v2"
        }
      ],
      "title": "Sampling from Your Language Model One Byte at a Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14123",
        "HTML": "https://arxiv.org/html/2506.14123v2",
        "PDF": "https://arxiv.org/pdf/2506.14123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a method to convert language models into byte-level or character-level LMs, addressing tokenization issues, which is a significant contribution to LLM data processing."
      },
      "tasks": [
        "Code Generation",
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08162",
      "abstract": "Red-blood-cell lysis (HC50) is the principal safety barrier for antimicrobial-peptide (AMP) therapeutics, yet existing models only say \"toxic\" or \"non-toxic.\" AmpLyze closes this gap by predicting the actual HC50 value from sequence alone and explaining the residues that drive toxicity. The model couples residue-level ProtT5/ESM2 embeddings with sequence-level descriptors in dual local and global branches, aligned by a cross-attention module and trained with log-cosh loss for robustness to assay noise. The optimal AmpLyze model reaches a PCC of 0.756 and an MSE of 0.987, outperforming classical regressors and the state-of-the-art. Ablations confirm that both branches are essential, and cross-attention adds a further 1% PCC and 3% MSE improvement. Expected-Gradients attributions reveal known toxicity hotspots and suggest safer substitutions. By turning hemolysis assessment into a quantitative, sequence-based, and interpretable prediction, AmpLyze facilitates AMP design and offers a practical tool for early-stage toxicity screening.",
      "authors": [
        "Peng Qiu",
        "Hanqi Feng",
        "Barnabas Poczos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:47:06+00:00",
          "link": "https://arxiv.org/abs/2507.08162v1",
          "size": "3527kb",
          "version": "v1"
        }
      ],
      "title": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08162",
        "HTML": "https://arxiv.org/html/2507.08162v1",
        "PDF": "https://arxiv.org/pdf/2507.08162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a model for predicting hemolytic concentration in peptides, without discussing LLM training data collection, processing, or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.11193",
      "abstract": "Source localization in graphs involves identifying the origin of a phenomenon or event, such as an epidemic outbreak or a misinformation source, by leveraging structural graph properties. One key concept in this context is the metric dimension, which quantifies the minimum number of strategically placed sensors needed to uniquely identify all vertices based on their distances. While powerful, the traditional metric dimension imposes a stringent requirement that every vertex must be uniquely identified, often necessitating a large number of sensors. In this work, we relax the metric dimension and allow vertices at a graph distance less than k to share identical distance profiles relative to the sensors. This relaxation reduces the number of sensors needed while maintaining sufficient resolution for practical applications like source localization and network monitoring. We provide two main theoretical contributions: an analysis of the k-relaxed metric dimension in deterministic trees, revealing the interplay between structural properties and sensor placement, and an extension to random trees generated by branching processes, offering insights into stochastic settings. We also conduct numerical experiments across a variety of graph types, including random trees, random geometric graphs, and real-world networks. The results show that the relaxed metric dimension is significantly smaller than the traditional metric dimension. Furthermore, the number of vertices indistinguishable from any given target vertex always remains small. Finally, we propose and evaluate a two-step localization strategy that balances the trade-off between resolution and the number of sensors required. This strategy identifies an optimal relaxation level that minimizes the total number of sensors across both steps, providing a practical and efficient approach to source localization.",
      "authors": [
        "Paula M\\\"urmann",
        "Robin Jaccard",
        "Maximilien Dreveton",
        "Aryan Alavi Razavi Ravari",
        "Patrick Thiran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T12:51:42+00:00",
          "link": "https://arxiv.org/abs/2505.11193v1",
          "size": "417kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:04:52+00:00",
          "link": "https://arxiv.org/abs/2505.11193v2",
          "size": "417kb",
          "version": "v2"
        }
      ],
      "title": "Reducing Sensor Requirements by Relaxing the Network Metric Dimension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11193",
        "HTML": "https://arxiv.org/html/2505.11193v2",
        "PDF": "https://arxiv.org/pdf/2505.11193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sensor requirements in graphs and source localization, unrelated to LLM training data processing or dataset creation."
      },
      "repo_urls": [
        "https://github.com/mdreveton/metric-dimension-relaxed"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08052",
      "abstract": "Cloud and cloud shadow masking is a crucial preprocessing step in hyperspectral satellite imaging, enabling the extraction of high-quality, analysis-ready data. This study evaluates various machine learning approaches, including gradient boosting methods such as XGBoost and LightGBM as well as convolutional neural networks (CNNs). All boosting and CNN models achieved accuracies exceeding 93%. Among the investigated models, the CNN with feature reduction emerged as the most efficient, offering a balance of high accuracy, low storage requirements, and rapid inference times on both CPUs and GPUs. Variations of this version, with only up to 597 trainable parameters, demonstrated the best trade-off in terms of deployment feasibility, accuracy, and computational efficiency. These results demonstrate the potential of lightweight artificial intelligence (AI) models for real-time hyperspectral image processing, supporting the development of on-board satellite AI systems for space-based applications.",
      "authors": [
        "Mazen Ali",
        "Ant\\'onio Pereira",
        "Fabio Gentile",
        "Aser Cortines",
        "Sam Mugel",
        "Rom\\'an Or\\'us",
        "Stelios P. Neophytides",
        "Michalis Mavrovouniotis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:10:11+00:00",
          "link": "https://arxiv.org/abs/2507.08052v1",
          "size": "3495kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08052",
        "HTML": "https://arxiv.org/html/2507.08052v1",
        "PDF": "https://arxiv.org/pdf/2507.08052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Discusses preprocessing in hyperspectral imaging but primarily focuses on cloud masking models rather than LLM training data processing. It evaluates machine learning approaches for preprocessing rather than LLM data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02548",
      "abstract": "Flow Matching (FM) is a simulation-free method for learning a continuous and invertible flow to interpolate between two distributions, and in particular to generate data from noise. Inspired by the variational nature of the diffusion process as a gradient flow, we introduce a stepwise FM model called Local Flow Matching (LFM), which consecutively learns a sequence of FM sub-models, each matching a diffusion process up to the time of the step size in the data-to-noise direction. In each step, the two distributions to be interpolated by the sub-flow model are closer to each other than data vs. noise, and this enables the use of smaller models with faster training. This variational perspective also allows us to theoretically prove a generation guarantee of the proposed flow model in terms of the $\\chi^2$-divergence between the generated and true data distributions, utilizing the contraction property of the diffusion process. In practice, the stepwise structure of LFM is natural to be distilled and different distillation techniques can be adopted to speed up generation. We empirically demonstrate improved training efficiency and competitive generative performance of LFM compared to FM on the unconditional generation of tabular data and image datasets, and also on the conditional generation of robotic manipulation policies.",
      "authors": [
        "Chen Xu",
        "Xiuyuan Cheng",
        "Yao Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T14:53:10+00:00",
          "link": "https://arxiv.org/abs/2410.02548v1",
          "size": "2554kb",
          "version": "v1"
        },
        {
          "date": "2024-12-31T01:50:58+00:00",
          "link": "https://arxiv.org/abs/2410.02548v2",
          "size": "4434kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T17:24:48+00:00",
          "link": "https://arxiv.org/abs/2410.02548v3",
          "size": "2999kb",
          "version": "v3"
        }
      ],
      "title": "Local Flow Matching Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02548",
        "HTML": "https://arxiv.org/html/2410.02548v3",
        "PDF": "https://arxiv.org/pdf/2410.02548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a simulation-free method for learning flows in generative models, focusing on interpolation between distributions, not LLM training data processing."
      },
      "tasks": [
        "Density Estimation"
      ],
      "repo_urls": [
        "https://github.com/hamrel-cxu/localflowmatching"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08229",
      "abstract": "Spiking neural network (SNN) has emerged as a promising paradigm in computational neuroscience and artificial intelligence, offering advantages such as low energy consumption and small memory footprint. However, their practical adoption is constrained by several challenges, prominently among them being performance optimization. In this study, we present a novel approach to enhance the performance of SNN for images through a new coding method that exploits bit plane representation. Our proposed technique is designed to improve the accuracy of SNN without increasing model size. Also, we investigate the impacts of color models of the proposed coding process. Through extensive experimental validation, we demonstrate the effectiveness of our coding strategy in achieving performance gain across multiple datasets. To the best of our knowledge, this is the first research that considers bit planes and color models in the context of SNN. By leveraging the unique characteristics of bit planes, we hope to unlock new potentials in SNNs performance, potentially paving the way for more efficient and effective SNNs models in future researches and applications.",
      "authors": [
        "Nhan T. Luu",
        "Duong T. Luu",
        "Nam N. Pham",
        "Thang C. Truong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-28T15:52:49+00:00",
          "link": "https://arxiv.org/abs/2410.08229v1",
          "size": "2436kb",
          "version": "v1"
        },
        {
          "date": "2024-11-08T14:14:23+00:00",
          "link": "https://arxiv.org/abs/2410.08229v2",
          "size": "3596kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T05:47:34+00:00",
          "link": "https://arxiv.org/abs/2410.08229v3",
          "size": "1034kb",
          "version": "v3"
        }
      ],
      "title": "Improvement of Spiking Neural Network with Bit Planes and Color Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08229",
        "HTML": "https://arxiv.org/html/2410.08229v3",
        "PDF": "https://arxiv.org/pdf/2410.08229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving spiking neural networks using coding methods for image data, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.02582",
      "abstract": "The discovery of new materials is essential for enabling technological advancements. Computational approaches for predicting novel materials must effectively learn the manifold of stable crystal structures within an infinite design space. We introduce Open Materials Generation (OMatG), a unifying framework for the generative design and discovery of inorganic crystalline materials. OMatG employs stochastic interpolants (SI) to bridge an arbitrary base distribution to the target distribution of inorganic crystals via a broad class of tunable stochastic processes, encompassing both diffusion models and flow matching as special cases. In this work, we adapt the SI framework by integrating an equivariant graph representation of crystal structures and extending it to account for periodic boundary conditions in unit cell representations. Additionally, we couple the SI flow over spatial coordinates and lattice vectors with discrete flow matching for atomic species. We benchmark OMatG's performance on two tasks: Crystal Structure Prediction (CSP) for specified compositions, and 'de novo' generation (DNG) aimed at discovering stable, novel, and unique structures. In our ground-up implementation of OMatG, we refine and extend both CSP and DNG metrics compared to previous works. OMatG establishes a new state of the art in generative modeling for materials discovery, outperforming purely flow-based and diffusion-based implementations. These results underscore the importance of designing flexible deep learning frameworks to accelerate progress in materials science. The OMatG code is available at https://github.com/FERMat-ML/OMatG.",
      "authors": [
        "Philipp Hoellmer",
        "Thomas Egg",
        "Maya M. Martirossyan",
        "Eric Fuemmeler",
        "Zeren Shui",
        "Amit Gupta",
        "Pawan Prakash",
        "Adrian Roitberg",
        "Mingjie Liu",
        "George Karypis",
        "Mark Transtrum",
        "Richard G. Hennig",
        "Ellad B. Tadmor",
        "Stefano Martiniani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T18:56:47+00:00",
          "link": "https://arxiv.org/abs/2502.02582v1",
          "size": "12558kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:35:20+00:00",
          "link": "https://arxiv.org/abs/2502.02582v2",
          "size": "7847kb",
          "version": "v2"
        }
      ],
      "title": "Open Materials Generation with Stochastic Interpolants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02582",
        "HTML": "https://arxiv.org/html/2502.02582v2",
        "PDF": "https://arxiv.org/pdf/2502.02582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a generative modeling framework for inorganic crystalline materials, which does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08002",
      "abstract": "Thematic analysis provides valuable insights into participants' experiences through coding and theme development, but its resource-intensive nature limits its use in large healthcare studies. Large language models (LLMs) can analyze text at scale and identify key content automatically, potentially addressing these challenges. However, their application in mental health interviews needs comparison with traditional human analysis. This study evaluates out-of-the-box and knowledge-base LLM-based thematic analysis against traditional methods using transcripts from a stress-reduction trial with healthcare workers. OpenAI's GPT-4o model was used along with the Role, Instructions, Steps, End-Goal, Narrowing (RISEN) prompt engineering framework and compared to human analysis in Dedoose. Each approach developed codes, noted saturation points, applied codes to excerpts for a subset of participants (n = 20), and synthesized data into themes. Outputs and performance metrics were compared directly. LLMs using the RISEN framework developed deductive parent codes similar to human codes, but humans excelled in inductive child code development and theme synthesis. Knowledge-based LLMs reached coding saturation with fewer transcripts (10-15) than the out-of-the-box model (15-20) and humans (90-99). The out-of-the-box LLM identified a comparable number of excerpts to human researchers, showing strong inter-rater reliability (K = 0.84), though the knowledge-based LLM produced fewer excerpts. Human excerpts were longer and involved multiple codes per excerpt, while LLMs typically applied one code. Overall, LLM-based thematic analysis proved more cost-effective but lacked the depth of human analysis. LLMs can transform qualitative analysis in mental healthcare and clinical research when combined with human oversight to balance participant perspectives and research resources.",
      "authors": [
        "Karisa Parkington",
        "Bazen G. Teferra",
        "Marianne Rouleau-Tang",
        "Argyrios Perivolaris",
        "Alice Rueda",
        "Adam Dubrowski",
        "Bill Kapralos",
        "Reza Samavi",
        "Andrew Greenshaw",
        "Yanbo Zhang",
        "Bo Cao",
        "Yuqi Wu",
        "Sirisha Rambhatla",
        "Sridhar Krishnan",
        "and Venkat Bhat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T13:31:13+00:00",
          "link": "https://arxiv.org/abs/2507.08002v1",
          "size": "1973kb",
          "version": "v1"
        }
      ],
      "title": "Human vs. LLM-Based Thematic Analysis for Digital Mental Health Research: Proof-of-Concept Comparative Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08002",
        "PDF": "https://arxiv.org/pdf/2507.08002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Though the paper compares LLM-based thematic analysis to human methods, it primarily focuses on analysis rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.10578",
      "abstract": "Average-reward Markov decision processes (MDPs) provide a foundational framework for sequential decision-making under uncertainty. However, average-reward MDPs have remained largely unexplored in reinforcement learning (RL) settings, with the majority of RL-based efforts having been allocated to discounted MDPs. In this work, we study a unique structural property of average-reward MDPs and utilize it to introduce Reward-Extended Differential (or RED) reinforcement learning: a novel RL framework that can be used to effectively and efficiently solve various learning objectives, or subtasks, simultaneously in the average-reward setting. We introduce a family of RED learning algorithms for prediction and control, including proven-convergent algorithms for the tabular case. We then showcase the power of these algorithms by demonstrating how they can be used to learn a policy that optimizes, for the first time, the well-known conditional value-at-risk (CVaR) risk measure in a fully-online manner, without the use of an explicit bi-level optimization scheme or an augmented state-space.",
      "authors": [
        "Juan Sebastian Rojas",
        "Chi-Guhn Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T14:52:23+00:00",
          "link": "https://arxiv.org/abs/2410.10578v1",
          "size": "3624kb",
          "version": "v1"
        },
        {
          "date": "2024-10-19T14:58:25+00:00",
          "link": "https://arxiv.org/abs/2410.10578v2",
          "size": "3616kb",
          "version": "v2"
        },
        {
          "date": "2024-10-30T23:23:42+00:00",
          "link": "https://arxiv.org/abs/2410.10578v3",
          "size": "3614kb",
          "version": "v3"
        },
        {
          "date": "2024-12-01T15:49:16+00:00",
          "link": "https://arxiv.org/abs/2410.10578v4",
          "size": "4857kb",
          "version": "v4"
        },
        {
          "date": "2024-12-03T16:26:09+00:00",
          "link": "https://arxiv.org/abs/2410.10578v5",
          "size": "4857kb",
          "version": "v5"
        },
        {
          "date": "2024-12-09T15:26:00+00:00",
          "link": "https://arxiv.org/abs/2410.10578v6",
          "size": "4857kb",
          "version": "v6"
        },
        {
          "date": "2024-12-15T22:28:30+00:00",
          "link": "https://arxiv.org/abs/2410.10578v7",
          "size": "4857kb",
          "version": "v7"
        },
        {
          "date": "2024-12-22T16:11:18+00:00",
          "link": "https://arxiv.org/abs/2410.10578v8",
          "size": "4858kb",
          "version": "v8"
        },
        {
          "date": "2025-02-24T19:53:06+00:00",
          "link": "https://arxiv.org/abs/2410.10578v9",
          "size": "1795kb",
          "version": "v9"
        },
        {
          "date": "2025-07-11T04:33:09+00:00",
          "link": "https://arxiv.org/abs/2410.10578v10",
          "size": "5042kb",
          "version": "v10"
        }
      ],
      "title": "Burning RED: Unlocking Subtask-Driven Reinforcement Learning and Risk-Awareness in Average-Reward Markov Decision Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10578",
        "PDF": "https://arxiv.org/pdf/2410.10578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reinforcement learning for average-reward MDPs and introduces a novel RL framework but does not deal with LLM training data processing or engineering."
      },
      "tasks": [
        "Decision Making",
        "Decision Making Under Uncertainty",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07802",
      "abstract": "Large-scale multi-modal models have demonstrated remarkable performance across various visual recognition tasks by leveraging extensive paired multi-modal training data. However, in real-world applications, the presence of missing or incomplete modality inputs often leads to significant performance degradation. Recent research has focused on prompt-based strategies to tackle this issue; however, existing methods are hindered by two major limitations: (1) static prompts lack the flexibility to adapt to varying missing-data conditions, and (2) basic prompt-tuning methods struggle to ensure reliable performance when critical modalities are missing.To address these challenges, we propose a novel Synergistic Prompting (SyP) framework for robust visual recognition with missing modalities. The proposed SyP introduces two key innovations: (I) a Dynamic Adapter, which computes adaptive scaling factors to dynamically generate prompts, replacing static parameters for flexible multi-modal adaptation, and (II) a Synergistic Prompting Strategy, which combines static and dynamic prompts to balance information across modalities, ensuring robust reasoning even when key modalities are missing. The proposed SyP achieves significant performance improvements over existing approaches across three widely-used visual recognition datasets, demonstrating robustness under diverse missing rates and conditions. Extensive experiments and ablation studies validate its effectiveness in handling missing modalities, highlighting its superior adaptability and reliability.",
      "authors": [
        "Zhihui Zhang",
        "Luanyuan Dai",
        "Qika Lin",
        "Yunfeng Diao",
        "Guangyin Jin",
        "Yufei Guo",
        "Jing Zhang",
        "Xiaoshuai Hao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:28:12+00:00",
          "link": "https://arxiv.org/abs/2507.07802v1",
          "size": "2191kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:27:52+00:00",
          "link": "https://arxiv.org/abs/2507.07802v2",
          "size": "2194kb",
          "version": "v2"
        }
      ],
      "title": "Synergistic Prompting for Robust Visual Recognition with Missing Modalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07802",
        "HTML": "https://arxiv.org/html/2507.07802v2",
        "PDF": "https://arxiv.org/pdf/2507.07802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for visual recognition with missing modalities but does not focus on any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08249",
      "abstract": "There is growing interest in giving AI agents access to cryptocurrencies as well as to the smart contracts that transact them. But doing so, this position paper argues, could lead to formidable new vectors of AI harm. To support this argument, we first examine the unique properties of cryptocurrencies and smart contracts that could lead to these new vectors of harm. Next, we describe each of these new vectors of harm in detail. Finally, we conclude with a call for more technical research aimed at preventing and mitigating these harms and, thereby making it safer to endow AI agents with cryptocurrencies and smart contracts.",
      "authors": [
        "Bill Marino and Ari Juels"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:22:02+00:00",
          "link": "https://arxiv.org/abs/2507.08249v1",
          "size": "85kb",
          "version": "v1"
        }
      ],
      "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08249",
        "HTML": "https://arxiv.org/html/2507.08249v1",
        "PDF": "https://arxiv.org/pdf/2507.08249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses potential harms associated with AI access to cryptocurrencies and smart contracts and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08250",
      "abstract": "In recent years, significant research has been conducted into classifying application (app) user feedback, primarily relying on supervised machine learning algorithms. However, fine-tuning more generalizable classifiers based on existing labeled datasets remains an important challenge, as creating large and accurately labeled datasets often requires considerable time and resources. In this paper, we evaluate the capabilities of four advanced LLMs, including GPT-3.5-Turbo, GPT-4, Flan-T5, and Llama3-70b, to enhance user feedback classification and address the challenge of the limited labeled dataset. To achieve this, we conduct several experiments on eight datasets that have been meticulously labeled in prior research. These datasets include user reviews from app stores, posts from the X platform, and discussions from the public forums, widely recognized as representative sources of app user feedback. We analyze the performance of various LLMs in identifying both fine-grained and coarse-grained user feedback categories. Given the substantial volume of daily user feedback and the computational limitations of LLMs, we leverage these models as an annotation tool to augment labeled datasets with general and app-specific data. This augmentation aims to enhance the performance of state-of-the-art BERT-based classification models. Our findings indicate that LLMs when guided by well-crafted prompts, can effectively classify user feedback into coarse-grained categories. Moreover, augmenting the training dataset with datasets labeled using the consensus of LLMs can significantly enhance classifier performance.",
      "authors": [
        "Yasaman Abedini and Abbas Heydarnoori"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:33:54+00:00",
          "link": "https://arxiv.org/abs/2507.08250v1",
          "size": "1535kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Large Language Models for Classifying App Users' Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08250",
        "HTML": "https://arxiv.org/html/2507.08250v1",
        "PDF": "https://arxiv.org/pdf/2507.08250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper evaluates LLMs' capability to augment labeled datasets for app user feedback classification, which involves significant contributions to LLM training data processing through dataset augmentation and enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.00615",
      "abstract": "This study presents a machine learning approach to predict the number of barges transported by vessels on inland waterways using tracking data from the Automatic Identification System (AIS). While AIS tracks the location of tug and tow vessels, it does not monitor the presence or number of barges transported by those vessels. Understanding the number and types of barges conveyed along river segments, between ports, and at ports is crucial for estimating the quantities of freight transported on the nation's waterways. This insight is also valuable for waterway management and infrastructure operations impacting areas such as targeted dredging operations, and data-driven resource allocation. Labeled sample data was generated using observations from traffic cameras located along key river segments and matched to AIS data records. A sample of 164 vessels representing up to 42 barge convoys per vessel was used for model development. The methodology involved first predicting barge presence and then predicting barge quantity. Features derived from the AIS data included speed measures, vessel characteristics, turning measures, and interaction terms. For predicting barge presence, the AdaBoost model achieved an F1 score of 0.932. For predicting barge quantity, the Random Forest combined with an AdaBoost ensemble model achieved an F1 score of 0.886. Bayesian optimization was used for hyperparameter tuning. By advancing predictive modeling for inland waterways, this study offers valuable insights for transportation planners and organizations, which require detailed knowledge of traffic volumes, including the flow of commodities, their destinations, and the tonnage moving in and out of ports.",
      "authors": [
        "Geoffery Agorku",
        "Sarah Hernandez",
        "Maria Falquez",
        "Subhadipto Poddar",
        "Shihao Pang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T19:28:21+00:00",
          "link": "https://arxiv.org/abs/2501.00615v1",
          "size": "1387kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:33:58+00:00",
          "link": "https://arxiv.org/abs/2501.00615v2",
          "size": "1387kb",
          "version": "v2"
        }
      ],
      "title": "Predicting Barge Presence and Quantity on Inland Waterways using Vessel Tracking Data: A Machine Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00615",
        "PDF": "https://arxiv.org/pdf/2501.00615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses predicting barge presence and quantity using machine learning and AIS data related to vessel tracking on waterways, with no discussion of LLM training data processing or any related methodologies."
      },
      "tasks": [
        "Bayesian Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02356",
      "abstract": "Long context fine-tuning of large language models(LLMs) involves training on datasets that are predominantly composed of short sequences and a small proportion of longer sequences. However, existing approaches overlook this long-tail distribution and employ training strategies designed specifically for long sequences. Moreover, these approaches also fail to address the challenges posed by variable sequence lengths during distributed training, such as load imbalance in data parallelism and severe pipeline bubbles in pipeline parallelism. These issues lead to suboptimal training performance and poor GPU resource utilization. To tackle these problems, we propose a chunk-centric training method named ChunkFlow. ChunkFlow reorganizes input sequences into uniformly sized chunks by consolidating short sequences and splitting longer ones. This approach achieves optimal computational efficiency and balance among training inputs. Additionally, ChunkFlow incorporates a state-aware chunk scheduling mechanism to ensure that the peak memory usage during training is primarily determined by the chunk size rather than the maximum sequence length in the dataset. Integrating this scheduling mechanism with existing pipeline scheduling algorithms further enhances the performance of distributed training. Experimental results demonstrate that, compared with Megatron-LM, ChunkFlow can be up to 4.53x faster in the long context fine-tuning of LLMs. Furthermore, we believe that ChunkFlow serves as an effective solution for a broader range of scenarios, such as long context continual pre-training, where datasets contain variable-length sequences.",
      "authors": [
        "Xiulong Yuan",
        "Hongtao Xu",
        "Wenting Shen",
        "Ang Wang",
        "Xiafei Qiu",
        "Jie Zhang",
        "Yuqiong Liu",
        "Bowen Yu",
        "Junyang Lin",
        "Mingzhen Li",
        "Weile Jia",
        "Yong Li",
        "Wei Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T07:27:41+00:00",
          "link": "https://arxiv.org/abs/2503.02356v1",
          "size": "9325kb",
          "version": "v1"
        },
        {
          "date": "2025-03-06T02:44:16+00:00",
          "link": "https://arxiv.org/abs/2503.02356v2",
          "size": "9325kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T06:20:51+00:00",
          "link": "https://arxiv.org/abs/2503.02356v3",
          "size": "11628kb",
          "version": "v3"
        }
      ],
      "title": "Efficient Long Context Fine-tuning with Chunk Flow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02356",
        "HTML": "https://arxiv.org/html/2503.02356v3",
        "PDF": "https://arxiv.org/pdf/2503.02356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions input sequence reorganization for efficient training, it primarily focuses on optimizing computational efficiency in the training process rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08259",
      "abstract": "Cold Atmospheric Pressure Plasma Jets (APPJs) show significant potential for biomedical applications, but their inherent complexity, characterized by nonlinear dynamics and strong sensitivity to operating conditions like tip-to-surface distance, presents considerable challenges for achieving robust and reliable real-time control. To address these issues, this paper presents the Neural Parameter-Varying Data-enabled Predictive Control (NPV-DeePC) framework. By integrating hyper neural networks (hypernets) into the neural Data-enabled Predictive Control (DeePC) paradigm, the proposed method adaptively captures system nonlinearities and parameter variations, updates the neural feature space accordingly, and enables efficient and accurate trajectory prediction and control. The NPV-DeePC framework is validated through extensive simulations involving surface temperature tracking and thermal dose delivery. The results highlight its ability to outperform existing controllers in terms of accuracy and adaptability. The computational efficiency of the NPV-DeePC approach makes it a viable candidate for real-time applications. These findings underscore its potential to advance the safe and precise control of APPJs and provide a scalable solution for other parameter-varying nonlinear systems.",
      "authors": [
        "Pegah GhafGhanbari",
        "Mircea Lazar",
        "Javad Mohammadpour Velni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:08:57+00:00",
          "link": "https://arxiv.org/abs/2507.08259v1",
          "size": "620kb",
          "version": "v1"
        }
      ],
      "title": "Neural Parameter-varying Data-enabled Predictive Control of Cold Atmospheric Pressure Plasma Jets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08259",
        "HTML": "https://arxiv.org/html/2507.08259v1",
        "PDF": "https://arxiv.org/pdf/2507.08259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses predictive control of plasma jets using neural networks, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08267",
      "abstract": "Enhancing the mathematical reasoning of Large Language Models (LLMs) is a pivotal challenge in advancing AI capabilities. While Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are the dominant training paradigms, a systematic methodology for combining them to maximize both accuracy and efficiency remains largely unexplored. This paper introduces a practical and effective training recipe that strategically integrates extended SFT with RL from online inference (GRPO). We posit that these methods play complementary, not competing, roles: a prolonged SFT phase first pushes the model's accuracy to its limits, after which a GRPO phase dramatically improves token efficiency while preserving this peak performance. Our experiments reveal that extending SFT for as many as 10 epochs is crucial for performance breakthroughs, and that the primary role of GRPO in this framework is to optimize solution length. The efficacy of our recipe is rigorously validated through top-tier performance on challenging benchmarks, including a high rank among over 2,200 teams in the strictly leak-free AI Mathematical Olympiad (AIMO). This work provides the community with a battle-tested blueprint for developing state-of-the-art mathematical reasoners that are both exceptionally accurate and practically efficient. To ensure full reproducibility and empower future research, we will open-source our entire framework, including all code, model checkpoints, and training configurations at https://github.com/analokmaus/kaggle-aimo2-fast-math-r1.",
      "authors": [
        "Hiroshi Yoshihara",
        "Taiki Yamaguchi",
        "Yuichi Inoue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:26:01+00:00",
          "link": "https://arxiv.org/abs/2507.08267v1",
          "size": "501kb",
          "version": "v1"
        }
      ],
      "title": "A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08267",
        "HTML": "https://arxiv.org/html/2507.08267v1",
        "PDF": "https://arxiv.org/pdf/2507.08267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing LLM mathematical reasoning using SFT and RL but mainly centers on training methodologies rather than specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08498",
      "abstract": "Latent Dirichlet Allocation (LDA) is a prominent generative probabilistic model used for uncovering abstract topics within document collections. In this paper, we explore the effectiveness of augmenting topic models with Large Language Models (LLMs) through integration into two key phases: Initialization and Post-Correction. Since the LDA is highly dependent on the quality of its initialization, we conduct extensive experiments on the LLM-guided topic clustering for initializing the Gibbs sampling algorithm. Interestingly, the experimental results reveal that while the proposed initialization strategy improves the early iterations of LDA, it has no effect on the convergence and yields the worst performance compared to the baselines. The LLM-enabled post-correction, on the other hand, achieved a promising improvement of 5.86% in the coherence evaluation. These results highlight the practical benefits of the LLM-in-the-loop approach and challenge the belief that LLMs are always the superior text mining alternative.",
      "authors": [
        "Mengze Hong",
        "Chen Jason Zhang",
        "Di Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:20:39+00:00",
          "link": "https://arxiv.org/abs/2507.08498v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Semantic-Augmented Latent Topic Modeling with LLM-in-the-Loop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08498",
        "HTML": "https://arxiv.org/html/2507.08498v1",
        "PDF": "https://arxiv.org/pdf/2507.08498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores adding LLMs to latent topic modeling, focusing on improving topic coherence but does not directly tackle LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08322",
      "abstract": "Quantitative facts are continually generated by companies and governments, supporting data-driven decision-making. While common facts are structured, many long-tail quantitative facts remain buried in unstructured documents, making them difficult to access. We propose the task of Quantity Retrieval: given a description of a quantitative fact, the system returns the relevant value and supporting evidence. Understanding quantity semantics in context is essential for this task. We introduce a framework based on description parsing that converts text into structured (description, quantity) pairs for effective retrieval. To improve learning, we construct a large paraphrase dataset using weak supervision based on quantity co-occurrence. We evaluate our approach on a large corpus of financial annual reports and a newly annotated quantity description dataset. Our method significantly improves top-1 retrieval accuracy from 30.98 percent to 64.66 percent.",
      "authors": [
        "Yixuan Cao",
        "Zhengrong Chen",
        "Chengxuan Xia",
        "Kun Wu",
        "Ping Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:25:09+00:00",
          "link": "https://arxiv.org/abs/2507.08322v1",
          "size": "1246kb",
          "version": "v1"
        }
      ],
      "title": "Towards Efficient Quantity Retrieval from Text:an Approach via Description Parsing and Weak Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08322",
        "HTML": "https://arxiv.org/html/2507.08322v1",
        "PDF": "https://arxiv.org/pdf/2507.08322"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for retrieval by converting text into structured pairs, applies weak supervision for learning, and constructs a dataset, but focuses on quantity retrieval rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08402",
      "abstract": "Intracortical Brain-Computer Interfaces (iBCI) aim to decode behavior from neural population activity, enabling individuals with motor impairments to regain motor functions and communication abilities. A key challenge in long-term iBCI is the nonstationarity of neural recordings, where the composition and tuning profiles of the recorded populations are unstable across recording sessions. Existing methods attempt to address this issue by explicit alignment techniques; however, they rely on fixed neural identities and require test-time labels or parameter updates, limiting their generalization across sessions and imposing additional computational burden during deployment. In this work, we introduce SPINT - a Spatial Permutation-Invariant Neural Transformer framework for behavioral decoding that operates directly on unordered sets of neural units. Central to our approach is a novel context-dependent positional embedding scheme that dynamically infers unit-specific identities, enabling flexible generalization across recording sessions. SPINT supports inference on variable-size populations and allows few-shot, gradient-free adaptation using a small amount of unlabeled data from the test session. To further promote model robustness to population variability, we introduce dynamic channel dropout, a regularization method for iBCI that simulates shifts in population composition during training. We evaluate SPINT on three multi-session datasets from the FALCON Benchmark, covering continuous motor decoding tasks in human and non-human primates. SPINT demonstrates robust cross-session generalization, outperforming existing zero-shot and few-shot unsupervised baselines while eliminating the need for test-time alignment and fine-tuning. Our work contributes an initial step toward a robust and scalable neural decoding framework for long-term iBCI applications.",
      "authors": [
        "Trung Le",
        "Hao Fang",
        "Jingyuan Li",
        "Tung Nguyen",
        "Lu Mi",
        "Amy Orsborn",
        "Uygar S\\\"umb\\\"ul",
        "Eli Shlizerman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:20:19+00:00",
          "link": "https://arxiv.org/abs/2507.08402v1",
          "size": "5571kb",
          "version": "v1"
        }
      ],
      "title": "SPINT: Spatial Permutation-Invariant Neural Transformer for Consistent Intracortical Motor Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08402",
        "HTML": "https://arxiv.org/html/2507.08402v1",
        "PDF": "https://arxiv.org/pdf/2507.08402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces SPINT, a neural transformer for motor decoding, emphasizing architecture and model robustness, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08619",
      "abstract": "Early-stage engineering design involves complex, iterative reasoning, yet existing large language model (LLM) workflows struggle to maintain task continuity and generate executable models. We evaluate whether a structured multi-agent system (MAS) can more effectively manage requirements extraction, functional decomposition, and simulator code generation than a simpler two-agent system (2AS). The target application is a solar-powered water filtration system as described in a cahier des charges. We introduce the Design-State Graph (DSG), a JSON-serializable representation that bundles requirements, physical embodiments, and Python-based physics models into graph nodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS collapses the process to a Generator-Reflector loop. Both systems run a total of 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1 70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON validity, requirement coverage, embodiment presence, code compatibility, workflow completion, runtime, and graph size. Across all runs, both MAS and 2AS maintained perfect JSON integrity and embodiment tagging. Requirement coverage remained minimal (less than 20\\%). Code compatibility peaked at 100\\% under specific 2AS settings but averaged below 50\\% for MAS. Only the reasoning-distilled model reliably flagged workflow completion. Powered by DeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes) whereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced design detail. Reasoning-distilled LLM improved completion rates, yet low requirements and fidelity gaps in coding persisted.",
      "authors": [
        "Soheyl Massoudi and Mark Fuge"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:19:05+00:00",
          "link": "https://arxiv.org/abs/2507.08619v1",
          "size": "797kb",
          "version": "v1"
        }
      ],
      "title": "Agentic Large Language Models for Conceptual Systems Engineering and Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08619",
        "HTML": "https://arxiv.org/html/2507.08619v1",
        "PDF": "https://arxiv.org/pdf/2507.08619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates structured multi-agent LLM systems in conceptual systems engineering and design, without discussing any aspect related to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08794",
      "abstract": "Generative reward models (also known as LLMs-as-judges), which use large language models (LLMs) to evaluate answer quality, are increasingly adopted in reinforcement learning with verifiable rewards (RLVR). They are often preferred over rigid rule-based metrics, especially for complex reasoning tasks involving free-form outputs. In this paradigm, an LLM is typically prompted to compare a candidate answer against a ground-truth reference and assign a binary reward indicating correctness. Despite the seeming simplicity of this comparison task, we find that generative reward models exhibit surprising vulnerabilities to superficial manipulations: non-word symbols (e.g., \":\" or \".\") or reasoning openers like \"Thought process:\" and \"Let's solve this problem step by step.\" can often lead to false positive rewards. We demonstrate that this weakness is widespread across LLMs, datasets, and prompt formats, posing a serious threat for core algorithmic paradigms that rely on generative reward models, such as rejection sampling, preference optimization, and RLVR. To mitigate this issue, we introduce a simple yet effective data augmentation strategy and train a new generative reward model with substantially improved robustness. Our findings highlight the urgent need for more reliable LLM-based evaluation methods. We release our robust, general-domain reward model and its synthetic training data at https://huggingface.co/sarosavo/Master-RM and https://huggingface.co/datasets/sarosavo/Master-RM.",
      "authors": [
        "Yulai Zhao",
        "Haolin Liu",
        "Dian Yu",
        "S.Y. Kung",
        "Haitao Mi",
        "Dong Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:55:22+00:00",
          "link": "https://arxiv.org/abs/2507.08794v1",
          "size": "1111kb",
          "version": "v1"
        }
      ],
      "title": "One Token to Fool LLM-as-a-Judge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08794",
        "HTML": "https://arxiv.org/html/2507.08794v1",
        "PDF": "https://arxiv.org/pdf/2507.08794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces data augmentation to improve generative reward model robustness, its primary focus is on evaluating LLM-generated outputs rather than processing LLM training data directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08210",
      "abstract": "What drives an agent to explore the world while also maintaining control over the environment? From a child at play to scientists in the lab, intelligent agents must balance curiosity (the drive to seek knowledge) with competence (the drive to master and control the environment). Bridging cognitive theories of intrinsic motivation with reinforcement learning, we ask how evolving internal representations mediate the trade-off between curiosity (novelty or information gain) and competence (empowerment). We compare two model-based agents using handcrafted state abstractions (Tabular) or learning an internal world model (Dreamer). The Tabular agent shows curiosity and competence guide exploration in distinct patterns, while prioritizing both improves exploration. The Dreamer agent reveals a two-way interaction between exploration and representation learning, mirroring the developmental co-evolution of curiosity and competence. Our findings formalize adaptive exploration as a balance between pursuing the unknown and the controllable, offering insights for cognitive theories and efficient reinforcement learning.",
      "authors": [
        "Fryderyk Mantiuk",
        "Hanqi Zhou",
        "Charley M. Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:45:28+00:00",
          "link": "https://arxiv.org/abs/2507.08210v1",
          "size": "905kb",
          "version": "v1"
        }
      ],
      "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08210",
        "HTML": "https://arxiv.org/html/2507.08210v1",
        "PDF": "https://arxiv.org/pdf/2507.08210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores intrinsic motivation in agents and reinforcement learning models, focusing on exploration dynamics and world models, without addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08380",
      "abstract": "Low-level enhancement and high-level visual understanding in low-light vision have traditionally been treated separately. Low-light enhancement improves image quality for downstream tasks, but existing methods rely on physical or geometric priors, limiting generalization. Evaluation mainly focuses on visual quality rather than downstream performance. Low-light visual understanding, constrained by scarce labeled data, primarily uses task-specific domain adaptation, which lacks scalability. To address these challenges, we build a generalized bridge between low-light enhancement and low-light understanding, which we term Generalized Enhancement For Understanding (GEFU). This paradigm improves both generalization and scalability. To address the diverse causes of low-light degradation, we leverage pretrained generative diffusion models to optimize images, achieving zero-shot generalization performance. Building on this, we propose Semantically Consistent Unsupervised Fine-tuning (SCUF). Specifically, to overcome text prompt limitations, we introduce an illumination-aware image prompt to explicitly guide image generation and propose a cycle-attention adapter to maximize its semantic potential. To mitigate semantic degradation in unsupervised training, we propose caption and reflectance consistency to learn high-level semantics and image-level spatial semantics. Extensive experiments demonstrate that our proposed method outperforms current state-of-the-art methods in traditional image quality and GEFU tasks including classification, detection, and semantic segmentation.",
      "authors": [
        "Sen Wang",
        "Shao Zeng",
        "Tianjun Gu",
        "Zhizhong Zhang",
        "Ruixin Zhang",
        "Shouhong Ding",
        "Jingyun Zhang",
        "Jun Wang",
        "Xin Tan",
        "Yuan Xie",
        "Lizhuang Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:51:26+00:00",
          "link": "https://arxiv.org/abs/2507.08380v1",
          "size": "9422kb",
          "version": "v1"
        }
      ],
      "title": "From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08380",
        "HTML": "https://arxiv.org/html/2507.08380v1",
        "PDF": "https://arxiv.org/pdf/2507.08380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes methods for low-light image enhancement and visual understanding via unsupervised fine-tuning, but it focuses more on model architecture and downstream task performance, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08611",
      "abstract": "Massive multiple-input multiple-output (mMIMO) is a key capacity-boosting technology in 5G wireless systems. To reduce the number of radio frequency (RF) chains needed in such systems, a novel approach has recently been introduced involving an antenna array supported by a reconfigurable intelligent surface. This arrangement, known as a reconfigurable intelligent base station (RIBS), offers performance comparable to that of a traditional mMIMO array, but with significantly fewer RF chains. Given the growing importance of precise, location-specific performance prediction, this paper evaluates the performance of an RIBS system by means of the SIONNA ray-tracing module. That performance is contrasted against results derived from a statistical 3GPP-compliant channel model, optimizing power and RIS configuration to maximize the sum spectral efficiency. Ray tracing predicts better performance than the statistical model in the evaluated scenario, suggesting the potential of site-specific modeling. However, empirical validation is needed to confirm this advantage.",
      "authors": [
        "Sina Beyraghi",
        "Giovanni Interdonato",
        "Giovanni Geraci",
        "Stefano Buzzi",
        "Angel Lozano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:09:04+00:00",
          "link": "https://arxiv.org/abs/2507.08611v1",
          "size": "1889kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Performance of Reconfigurable Intelligent Base Stations through Ray Tracing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08611",
        "HTML": "https://arxiv.org/html/2507.08611v1",
        "PDF": "https://arxiv.org/pdf/2507.08611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses entirely on evaluating the performance of reconfigurable intelligent base stations using ray tracing, without discussing any aspects related to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.00994",
      "abstract": "Time series forecasting often demands a trade-off between accuracy and efficiency. While recent Transformer models have improved forecasting capabilities, they come with high computational costs. Linear-based models have shown better accuracy than Transformers but still fall short of ideal performance. We propose PIAD-SRNN, a physics-informed adaptive decomposition state-space RNN, that separates seasonal and trend components and embeds domain equations in a recurrent framework. We evaluate PIAD-SRNN's performance on indoor air quality datasets, focusing on CO2 concentration prediction across various forecasting horizons, and results demonstrate that it consistently outperforms SoTA models in both long-term and short-term time series forecasting, including transformer-based architectures, in terms of both MSE and MAE. Besides proposing PIAD-SRNN which balances accuracy with efficiency, this paper also provides four curated datasets. Code and data: https://github.com/ahmad-shirazi/DSSRNN",
      "authors": [
        "Ahmad Mohammadshirazi",
        "Pinaki Prasad Guha Neogi",
        "Rajiv Ramnath"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-01T22:55:58+00:00",
          "link": "https://arxiv.org/abs/2412.00994v1",
          "size": "1972kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T18:37:02+00:00",
          "link": "https://arxiv.org/abs/2412.00994v2",
          "size": "1744kb",
          "version": "v2"
        }
      ],
      "title": "PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00994",
        "HTML": "https://arxiv.org/html/2412.00994v2",
        "PDF": "https://arxiv.org/pdf/2412.00994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The focus of the paper is on PIAD-SRNN for time series forecasting. It briefly mentions providing curated datasets, suggesting some level of data processing, but it's not a main contribution or focused on LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Physics-informed machine learning",
        "State Space Models",
        "Time Series",
        "Time Series Analysis",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/ahmad-shirazi/DSSRNN"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11903",
      "abstract": "Advances in transformer-based language models have highlighted the benefits of language-specific pre-training on high-quality corpora. In this context, German NLP stands to gain from updated architectures and modern datasets tailored to the linguistic characteristics of the German language. GeistBERT seeks to improve German language processing by incrementally training on a diverse corpus and optimizing model performance across various NLP tasks. We pre-trained GeistBERT using fairseq, following the RoBERTa base configuration with Whole Word Masking (WWM), and initialized from GottBERT weights. The model was trained on a 1.3 TB German corpus with dynamic masking and a fixed sequence length of 512 tokens. For evaluation, we fine-tuned the model on standard downstream tasks, including NER (CoNLL 2003, GermEval 2014), text classification (GermEval 2018 coarse/fine, 10kGNAD), and NLI (German XNLI), using $F_1$ score and accuracy as evaluation metrics. GeistBERT achieved strong results across all tasks, leading among base models and setting a new state-of-the-art (SOTA) in GermEval 2018 fine text classification. It also outperformed several larger models, particularly in classification benchmarks. To support research in German NLP, we release GeistBERT under the MIT license.",
      "authors": [
        "Raphael Scheible-Schmitt and Johann Frei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T15:53:17+00:00",
          "link": "https://arxiv.org/abs/2506.11903v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T23:06:09+00:00",
          "link": "https://arxiv.org/abs/2506.11903v2",
          "size": "131kb",
          "version": "v2"
        },
        {
          "date": "2025-06-24T12:31:06+00:00",
          "link": "https://arxiv.org/abs/2506.11903v3",
          "size": "131kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T20:40:55+00:00",
          "link": "https://arxiv.org/abs/2506.11903v4",
          "size": "5303kb",
          "version": "v4"
        }
      ],
      "title": "GeistBERT: Breathing Life into German NLP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11903",
        "HTML": "https://arxiv.org/html/2506.11903v4",
        "PDF": "https://arxiv.org/pdf/2506.11903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes pretraining GeistBERT on a large German corpus but does not detail any novel data processing steps or creation of datasets apart from using existing corpora."
      },
      "models": [
        {
          "model_path": "GeistBERT/GeistBERT_base",
          "downloads": "815",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/GeistBERT/GeistBERT_base"
        }
      ],
      "tasks": [
        "8k",
        "NER",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08160",
      "abstract": "Generative Artificial Intelligence (GenAI) tools for source code generation have significantly boosted productivity in software development. However, they also raise concerns, particularly the risk that developers may rely heavily on these tools, reducing their understanding of the generated code. We hypothesize that this loss of understanding may be reflected in source code knowledge models, which are used to identify developer expertise. In this work, we present an exploratory analysis of how a knowledge model and a Truck Factor algorithm built upon it can be affected by GenAI usage. To investigate this, we collected statistical data on the integration of ChatGPT-generated code into GitHub projects and simulated various scenarios by adjusting the degree of GenAI contribution. Our findings reveal that most scenarios led to measurable impacts, indicating the sensitivity of current expertise metrics. This suggests that as GenAI becomes more integrated into development workflows, the reliability of such metrics may decrease.",
      "authors": [
        "Ot\\'avio Cury",
        "Guilherme Avelino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:43:08+00:00",
          "link": "https://arxiv.org/abs/2507.08160v1",
          "size": "854kb",
          "version": "v1"
        }
      ],
      "title": "The Impact of Generative AI on Code Expertise Models: An Exploratory Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08160",
        "HTML": "https://arxiv.org/html/2507.08160v1",
        "PDF": "https://arxiv.org/pdf/2507.08160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the impact of Generative AI on code expertise metrics rather than LLM training data processing. It does not discuss or contribute to the techniques for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08617",
      "abstract": "Collaborative fairness is a crucial challenge in federated learning. However, existing approaches often overlook a practical yet complex form of heterogeneity: imbalanced covariate shift. We provide a theoretical analysis of this setting, which motivates the design of FedAKD (Federated Asynchronous Knowledge Distillation)- simple yet effective approach that balances accurate prediction with collaborative fairness. FedAKD consists of client and server updates. In the client update, we introduce a novel asynchronous knowledge distillation strategy based on our preliminary analysis, which reveals that while correctly predicted samples exhibit similar feature distributions across clients, incorrectly predicted samples show significant variability. This suggests that imbalanced covariate shift primarily arises from misclassified samples. Leveraging this insight, our approach first applies traditional knowledge distillation to update client models while keeping the global model fixed. Next, we select correctly predicted high-confidence samples and update the global model using these samples while keeping client models fixed. The server update simply aggregates all client models. We further provide a theoretical proof of FedAKD's convergence. Experimental results on public datasets (FashionMNIST and CIFAR10) and a real-world Electronic Health Records (EHR) dataset demonstrate that FedAKD significantly improves collaborative fairness, enhances predictive accuracy, and fosters client participation even under highly heterogeneous data distributions.",
      "authors": [
        "Tianrun Yu",
        "Jiaqi Wang",
        "Haoyu Wang",
        "Mingquan Lin",
        "Han Liu",
        "Nelson S. Yee and Fenglong Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:13:41+00:00",
          "link": "https://arxiv.org/abs/2507.08617v1",
          "size": "852kb",
          "version": "v1"
        }
      ],
      "title": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08617",
        "HTML": "https://arxiv.org/html/2507.08617v1",
        "PDF": "https://arxiv.org/pdf/2507.08617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with federated learning and collaborative fairness, emphasizing prediction accuracy under covariate shift but does not address LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08707",
      "abstract": "Inverse Reinforcement Learning (IRL) presents a powerful paradigm for learning complex robotic tasks from human demonstrations. However, most approaches make the assumption that expert demonstrations are available, which is often not the case. Those that allow for suboptimality in the demonstrations are not designed for long-horizon goals or adversarial tasks. Many desirable robot capabilities fall into one or both of these categories, thus highlighting a critical shortcoming in the ability of IRL to produce field-ready robotic agents. We introduce Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations (SPLASH), which advances the state-of-the-art in learning from suboptimal demonstrations to long-horizon and adversarial settings. We empirically validate SPLASH on a maritime capture-the-flag task in simulation, and demonstrate real-world applicability with sim-to-real translation experiments on autonomous unmanned surface vehicles. We show that our proposed methods allow SPLASH to significantly outperform the state-of-the-art in reward learning from suboptimal demonstrations.",
      "authors": [
        "Peter Crowley",
        "Zachary Serlin",
        "Tyler Paine",
        "Makai Mann",
        "Michael Benjamin and Calin Belta"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:05:18+00:00",
          "link": "https://arxiv.org/abs/2507.08707v1",
          "size": "3581kb",
          "version": "v1"
        }
      ],
      "title": "SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08707",
        "HTML": "https://arxiv.org/html/2507.08707v1",
        "PDF": "https://arxiv.org/pdf/2507.08707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving inverse reinforcement learning for long-horizon adversarial tasks, utilizing suboptimal demonstrations rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.16521",
      "abstract": "This paper explores conversational self-play with LLMs as a scalable approach for analyzing and exploring psychotherapy approaches, evaluating how well AI-generated therapeutic dialogues align with established modalities.",
      "authors": [
        "Onno P Kampman",
        "Michael Xing",
        "Charmaine Lim",
        "Ahmad Ishqi Jabir",
        "Ryan Louie",
        "Jimmy Lee",
        "Robert JT Morris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T02:16:41+00:00",
          "link": "https://arxiv.org/abs/2503.16521v1",
          "size": "1148kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T06:31:58+00:00",
          "link": "https://arxiv.org/abs/2503.16521v2",
          "size": "1136kb",
          "version": "v2"
        }
      ],
      "title": "Conversational Self-Play for Discovering and Understanding Psychotherapy Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16521",
        "HTML": "https://arxiv.org/html/2503.16521v2",
        "PDF": "https://arxiv.org/pdf/2503.16521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores conversational self-play with LLMs for psychotherapy analysis and does not mention any LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08260",
      "abstract": "We present a graphical, node-based system through which users can visually chain generative AI models for creative tasks. Research in the area of chaining LLMs has found that while chaining provides transparency, controllability and guardrails to approach certain tasks, chaining with pre-defined LLM steps prevents free exploration. Using cognitive processes from creativity research as a basis, we create a system that addresses the inherent constraints of chat-based AI interactions. Specifically, our system aims to overcome the limiting linear structure that inhibits creative exploration and ideation. Further, our node-based approach enables the creation of reusable, shareable templates that can address different creative tasks. In a small-scale user study, we find that our graph-based system supports ideation and allows some users to better visualise and think through their writing process when compared to a similar conversational interface. We further discuss the weaknesses and limitations of our system, noting the benefits to creativity that user interfaces with higher complexity can provide for users who can effectively use them.",
      "authors": [
        "Abhinav Sood",
        "Maria Teresa Llano",
        "Jon McCormack"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:11:25+00:00",
          "link": "https://arxiv.org/abs/2507.08260v1",
          "size": "734kb",
          "version": "v1"
        }
      ],
      "title": "Do Conversational Interfaces Limit Creativity? Exploring Visual Graph Systems for Creative Writing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08260",
        "HTML": "https://arxiv.org/html/2507.08260v1",
        "PDF": "https://arxiv.org/pdf/2507.08260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores creative writing interfaces using generative models but does not address processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08307",
      "abstract": "Audio-driven talking head generation holds significant potential for film production. While existing 3D methods have advanced motion modeling and content synthesis, they often produce rendering artifacts, such as motion blur, temporal jitter, and local penetration, due to limitations in representing stable, fine-grained motion fields. Through systematic analysis, we reformulate talking head generation into a unified framework comprising three steps: video preprocessing, motion representation, and rendering reconstruction. This framework underpins our proposed M2DAO-Talker, which addresses current limitations via multi-granular motion decoupling and alternating optimization.Specifically, we devise a novel 2D portrait preprocessing pipeline to extract frame-wise deformation control conditions (motion region segmentation masks, and camera parameters) to facilitate motion representation. To ameliorate motion modeling, we elaborate a multi-granular motion decoupling strategy, which independently models non-rigid (oral and facial) and rigid (head) motions for improved reconstruction accuracy.Meanwhile, a motion consistency constraint is developed to ensure head-torso kinematic consistency, thereby mitigating penetration artifacts caused by motion aliasing. In addition, an alternating optimization strategy is designed to iteratively refine facial and oral motion parameters, enabling more realistic video generation.Experiments across multiple datasets show that M2DAO-Talker achieves state-of-the-art performance, with the 2.43 dB PSNR improvement in generation quality and 0.64 gain in user-evaluated video realness versus TalkingGaussian while with 150 FPS inference speed. Our project homepage is https://m2dao-talker.github.io/M2DAO-Talk.github.io",
      "authors": [
        "Kui Jiang",
        "Shiyu Liu",
        "Junjun Jiang",
        "Xin Yang",
        "Hongxun Yang and Xiaopeng Fan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:48:12+00:00",
          "link": "https://arxiv.org/abs/2507.08307v1",
          "size": "8214kb",
          "version": "v1"
        }
      ],
      "title": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08307",
        "HTML": "https://arxiv.org/html/2507.08307v1",
        "PDF": "https://arxiv.org/pdf/2507.08307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audio-driven talking head generation and discusses motion modeling and rendering, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08784",
      "abstract": "Distributed optimization is pivotal for large-scale signal processing and machine learning, yet communication overhead remains a major bottleneck. Low-rank gradient compression, in which the transmitted gradients are approximated by low-rank matrices to reduce communication, offers a promising remedy. Existing methods typically adopt either randomized or greedy compression strategies: randomized approaches project gradients onto randomly chosen subspaces, introducing high variance and degrading empirical performance; greedy methods select the most informative subspaces, achieving strong empirical results but lacking convergence guarantees. To address this gap, we propose GreedyLore--the first Greedy Low-Rank gradient compression algorithm for distributed learning with rigorous convergence guarantees. GreedyLore incorporates error feedback to correct the bias introduced by greedy compression and introduces a semi-lazy subspace update that ensures the compression operator remains contractive throughout all iterations. With these techniques, we prove that GreedyLore achieves a convergence rate of $\\mathcal{O}(\\sigma/\\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD and Adam--marking the first linear speedup convergence rate for low-rank gradient compression. Extensive experiments are conducted to validate our theoretical findings.",
      "authors": [
        "Chuyan Chen",
        "Yutong He",
        "Pengrui Li",
        "Weichen Jia",
        "Kun Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:46:12+00:00",
          "link": "https://arxiv.org/abs/2507.08784v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08784",
        "HTML": "https://arxiv.org/html/2507.08784v1",
        "PDF": "https://arxiv.org/pdf/2507.08784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses gradient compression for distributed learning and mentions convergence guarantees. It does not discuss training data processing or creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20207",
      "abstract": "When validated neural networks (NNs) are pruned (and retrained) before deployment, it is desirable to prove that the new NN behaves equivalently to the (original) reference NN. To this end, our paper revisits the idea of differential verification which performs reasoning on differences between NNs: On the one hand, our paper proposes a novel abstract domain for differential verification admitting more efficient reasoning about equivalence. On the other hand, we investigate empirically and theoretically which equivalence properties are (not) efficiently solved using differential reasoning. Based on the gained insights, and following a recent line of work on confidence-based verification, we propose a novel equivalence property that is amenable to Differential Verification while providing guarantees for large parts of the input space instead of small-scale guarantees constructed w.r.t. predetermined input points. We implement our approach in a new tool called VeryDiff and perform an extensive evaluation on numerous old and new benchmark families, including new pruned NNs for particle jet classification in the context of CERN's LHC where we observe median speedups >300x over the State-of-the-Art verifier alpha,beta-CROWN.",
      "authors": [
        "Samuel Teuber",
        "Philipp Kern",
        "Marvin Janzen",
        "Bernhard Beckert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T15:53:25+00:00",
          "link": "https://arxiv.org/abs/2410.20207v1",
          "size": "472kb",
          "version": "v1"
        },
        {
          "date": "2025-01-29T16:21:27+00:00",
          "link": "https://arxiv.org/abs/2410.20207v2",
          "size": "472kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Differential Verification: Equivalence Verification with Confidence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20207",
        "PDF": "https://arxiv.org/pdf/2410.20207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with differential verification for neural networks but does not involve any aspects of LLM training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.05255",
      "abstract": "Affective polarization and political sorting drive public antagonism around issues at the science-policy nexus. Looking at the COVID-19 period, we study cross-domain spillover of incivility and contentiousness in public engagements with climate change and public health on Twitter and Reddit. We find strong evidence of the signatures of affective polarization surrounding COVID-19 spilling into the climate change domain. Across different social media systems, COVID-19 content is associated with incivility and contentiousness in climate discussions. These patterns of increased antagonism were responsive to pandemic events that made the link between science and public policy more salient. The observed spillover activated along pre-pandemic political cleavages, specifically anti-internationalist populist beliefs, that linked climate policy opposition to vaccine hesitancy. Our findings show how affective polarization in public engagement with science becomes entrenched across science policy domains.",
      "authors": [
        "Hasti Narimanzadeh",
        "Arash Badie-Modiri",
        "Iuliia Smirnova and Ted Hsuan Yun Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T18:08:50+00:00",
          "link": "https://arxiv.org/abs/2502.05255v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:42:55+00:00",
          "link": "https://arxiv.org/abs/2502.05255v2",
          "size": "130kb",
          "version": "v2"
        }
      ],
      "title": "Incivility and Contentiousness Spillover in Public Engagement with Public Health and Climate Science",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05255",
        "HTML": "https://arxiv.org/html/2502.05255v2",
        "PDF": "https://arxiv.org/pdf/2502.05255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines public engagement incivility in science discussions on social media, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13959",
      "abstract": "Current efforts in AI safety prioritize filtering harmful content, preventing manipulation of human behavior, and eliminating existential risks in cybersecurity or biosecurity. While pressing, this narrow focus overlooks critical human-centric considerations that shape the long-term trajectory of a society. In this position paper, we identify the risks of overlooking the impact of AI on the future of work and recommend comprehensive transition support towards the evolution of meaningful labor with human agency. Through the lens of economic theories, we highlight the intertemporal impacts of AI on human livelihood and the structural changes in labor markets that exacerbate income inequality. Additionally, the closed-source approach of major stakeholders in AI development resembles rent-seeking behavior through exploiting resources, breeding mediocrity in creative labor, and monopolizing innovation. To address this, we argue in favor of a robust international copyright anatomy supported by implementing collective licensing that ensures fair compensation mechanisms for using data to train AI models. We strongly recommend a pro-worker framework of global AI governance to enhance shared prosperity and economic justice while reducing technical debt.",
      "authors": [
        "Sanchaita Hazra",
        "Bodhisattwa Prasad Majumder",
        "Tuhin Chakrabarty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T23:12:30+00:00",
          "link": "https://arxiv.org/abs/2504.13959v1",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T17:42:10+00:00",
          "link": "https://arxiv.org/abs/2504.13959v2",
          "size": "66kb",
          "version": "v2"
        }
      ],
      "title": "AI Safety Should Prioritize the Future of Work",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13959",
        "HTML": "https://arxiv.org/html/2504.13959v2",
        "PDF": "https://arxiv.org/pdf/2504.13959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This position paper discusses the implications of AI on the future of work and economic transformations, without focusing on any aspects of LLM training data processing."
      },
      "tasks": [
        "Anatomy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06574",
      "abstract": "Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO) effort contributes to NASA's Concepts for Ocean worlds Life Detection Technology (COLDTech) program, which explores science platform technologies for ocean worlds such as Europa and Enceladus. Ocean world missions pose significant operational challenges. These include long communication lags, limited power, and lifetime limitations caused by radiation damage and hostile conditions. Given these operational limitations, onboard autonomy will be vital for future Ocean world missions. Besides the management of nominal lander operations, onboard autonomy must react appropriately in the event of anomalies. Traditional spacecraft rely on a transition into 'safe-mode' in which non-essential components and subsystems are powered off to preserve safety and maintain communication with Earth. For a severely time-limited Ocean world mission, resolutions to these anomalies that can be executed without Earth-in-the-loop communication and associated delays are paramount for completion of the mission objectives and science goals. To address these challenges, the REASIMO effort aims to demonstrate a robust level of AI-assisted autonomy for such missions, including the ability to detect and recover from anomalies, and to perform missions based on pre-trained behaviors rather than hard-coded, predetermined logic like all prior space missions. We developed an AI-assisted, personality-driven, intelligent framework for control of an Ocean world mission by combining a mix of advanced technologies. To demonstrate the capabilities of the framework, we perform tests of autonomous sampling operations on a lander-manipulator testbed at the NASA Jet Propulsion Laboratory, approximating possible surface conditions such a mission might encounter.",
      "authors": [
        "Thomas Touma",
        "Ersin Da\\c{s}",
        "Erica Tevere",
        "Martin Feather",
        "Ksenia Kolcio",
        "Maurice Prather",
        "Alberto Candela",
        "Ashish Goel",
        "Erik Kramer",
        "Hari Nayar",
        "Lorraine Fesq",
        "Joel W. Burdick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:05:52+00:00",
          "link": "https://arxiv.org/abs/2507.06574v1",
          "size": "9902kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T04:32:10+00:00",
          "link": "https://arxiv.org/abs/2507.06574v2",
          "size": "9902kb",
          "version": "v2"
        }
      ],
      "title": "AI Space Cortex: An Experimental System for Future Era Space Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06574",
        "HTML": "https://arxiv.org/html/2507.06574v2",
        "PDF": "https://arxiv.org/pdf/2507.06574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research involves developing an AI-assisted autonomy framework for space exploration missions, without addressing LLM training data processing or dataset preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07847",
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications.",
      "authors": [
        "Youngjoon Jang",
        "Seongtae Hong",
        "Junyoung Son",
        "Sungjin Park",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:26:59+00:00",
          "link": "https://arxiv.org/abs/2507.07847v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07847",
        "HTML": "https://arxiv.org/html/2507.07847",
        "PDF": "https://arxiv.org/pdf/2507.07847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improving document retrieval and generative performance via coreference resolution in Retrieval-Augmented Generation systems. While it indirectly involves data processing for better LLM outcomes, it primarily focuses on enhancing retrieval strategies and generative performance rather than core data processing for pretraining or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08735",
      "abstract": "Solving computer vision problems through machine learning, one often encounters lack of sufficient training data. To mitigate this we propose the use of ensembles of weak learners based on spectral total-variation (STV) features (Gilboa 2014). The features are related to nonlinear eigenfunctions of the total-variation subgradient and can characterize well textures at various scales. It was shown (Burger et-al 2016) that, in the one-dimensional case, orthogonal features are generated, whereas in two-dimensions the features are empirically lowly correlated. Ensemble learning theory advocates the use of lowly correlated weak learners. We thus propose here to design ensembles using learners based on STV features. To show the effectiveness of this paradigm we examine a hard real-world medical imaging problem: the predictive value of computed tomography (CT) data for high uptake in positron emission tomography (PET) for patients suspected of skeletal metastases. The database consists of 457 scans with 1524 unique pairs of registered CT and PET slices. Our approach is compared to deep-learning methods and to Radiomics features, showing STV learners perform best (AUC=0.87), compared to neural nets (AUC=0.75) and Radiomics (AUC=0.79). We observe that fine STV scales in CT images are especially indicative for the presence of high uptake in PET.",
      "authors": [
        "Anna Rosenberg",
        "John Kennedy",
        "Zohar Keidar",
        "Yehoshua Y. Zeevi and Guy Gilboa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:38:28+00:00",
          "link": "https://arxiv.org/abs/2507.08735v1",
          "size": "7110kb",
          "version": "v1"
        }
      ],
      "title": "Ensemble of Weak Spectral Total Variation Learners: a PET-CT Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08735",
        "HTML": "https://arxiv.org/html/2507.08735v1",
        "PDF": "https://arxiv.org/pdf/2507.08735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research proposes using ensembles of weak learners for solving computer vision problems in medical imaging, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07580",
      "abstract": "Introduced in [CG24], pseudorandom error-correcting codes (PRCs) are a new cryptographic primitive with applications in watermarking generative AI models. These are codes where a collection of polynomially many codewords is computationally indistinguishable from random for an adversary that does not have the secret key, but anyone with the secret key is able to efficiently decode corrupted codewords. In this work, we examine the assumptions under which PRCs with robustness to a constant error rate exist.\n  1. We show that if both the planted hyperloop assumption introduced in [BKR23] and security of a version of Goldreich's PRG hold, then there exist public-key PRCs for which no efficient adversary can distinguish a polynomial number of codewords from random with better than $o(1)$ advantage.\n  2. We revisit the construction of [CG24] and show that it can be based on a wider range of assumptions than presented in [CG24]. To do this, we introduce a weakened version of the planted XOR assumption which we call the weak planted XOR assumption and which may be of independent interest.\n  3. We initiate the study of PRCs which are secure against space-bounded adversaries. We show how to construct secret-key PRCs of length $O(n)$ which are $\\textit{unconditionally}$ indistinguishable from random by $\\text{poly}(n)$ time, $O(n^{1.5-\\varepsilon})$ space adversaries.",
      "authors": [
        "Surendra Ghentiyala",
        "Venkatesan Guruswami"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T19:14:39+00:00",
          "link": "https://arxiv.org/abs/2409.07580v1",
          "size": "927kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:29:27+00:00",
          "link": "https://arxiv.org/abs/2409.07580v2",
          "size": "930kb",
          "version": "v2"
        }
      ],
      "title": "New constructions of pseudorandom codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07580",
        "HTML": "https://arxiv.org/html/2409.07580v2",
        "PDF": "https://arxiv.org/pdf/2409.07580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pseudorandom error-correcting codes (PRCs) and their cryptographic applications, not on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12096",
      "abstract": "In this paper, we introduce token communications (TokCom), a large model-driven framework to leverage cross-modal context information in generative semantic communications (GenSC). TokCom is a new paradigm, motivated by the recent success of generative foundation models and multimodal large language models (GFM/MLLMs), where the communication units are tokens, enabling efficient transformer-based token processing at the transmitter and receiver. In this paper, we introduce the potential opportunities and challenges of leveraging context in GenSC, explore how to integrate GFM/MLLMs-based token processing into semantic communication systems to leverage cross-modal context effectively at affordable complexity, present the key principles for efficient TokCom at various layers in future wireless networks. In a typical image semantic communication setup, we demonstrate a significant improvement of the bandwidth efficiency, achieved by TokCom by leveraging the context information among tokens. Finally, the potential research directions are identified to facilitate adoption of TokCom in future wireless networks.",
      "authors": [
        "Li Qiao",
        "Mahdi Boloursaz Mashhadi",
        "Zhen Gao",
        "Rahim Tafazolli",
        "Mehdi Bennis",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T18:14:18+00:00",
          "link": "https://arxiv.org/abs/2502.12096v1",
          "size": "1903kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T18:53:50+00:00",
          "link": "https://arxiv.org/abs/2502.12096v2",
          "size": "2389kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T13:47:50+00:00",
          "link": "https://arxiv.org/abs/2502.12096v3",
          "size": "2389kb",
          "version": "v3"
        }
      ],
      "title": "Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12096",
        "HTML": "https://arxiv.org/html/2502.12096v3",
        "PDF": "https://arxiv.org/pdf/2502.12096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces token communications for efficient processing in generative semantic communications but does not primarily focus on LLM training data processing."
      },
      "tasks": [
        "Semantic Communication"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20687",
      "abstract": "The original description of the k-d tree recognized that rebalancing techniques, such as used to build an AVL tree or a red-black tree, are not applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is necessary to find the median of a set of data for each recursive subdivision of that set. The sort or selection used to find the median, and the technique used to partition the set about that median, strongly influence the computational complexity of building a k-d tree. This article describes and contrasts three variants of the k-d tree that differ in their technique used to partition the set, and compares the performance of those variants. In addition, dual-threaded execution is proposed and analyzed for one of the three variants.",
      "authors": [
        "Russell A. Brown"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T01:01:38+00:00",
          "link": "https://arxiv.org/abs/2506.20687v1",
          "size": "714kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T22:55:07+00:00",
          "link": "https://arxiv.org/abs/2506.20687v2",
          "size": "808kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T22:13:37+00:00",
          "link": "https://arxiv.org/abs/2506.20687v3",
          "size": "794kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T21:32:47+00:00",
          "link": "https://arxiv.org/abs/2506.20687v4",
          "size": "797kb",
          "version": "v4"
        }
      ],
      "title": "Review of Three Variants of the k-d Tree",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20687",
        "HTML": "https://arxiv.org/html/2506.20687v4",
        "PDF": "https://arxiv.org/pdf/2506.20687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the computational complexity and techniques for building k-d trees, a data structure used in various applications, without any mention of processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08025",
      "abstract": "Conservation and decision-making regarding forest resources necessitate regular forest inventory. Light detection and ranging (LiDAR) in laser scanning systems has gained significant attention over the past two decades as a remote and non-destructive solution to streamline the labor-intensive and time-consuming procedure of forest inventory. Advanced multispectral (MS) LiDAR systems simultaneously acquire three-dimensional (3D) spatial and spectral information across multiple wavelengths of the electromagnetic spectrum. Consequently, MS-LiDAR technology enables the estimation of both the biochemical and biophysical characteristics of forests. Forest component segmentation is crucial for forest inventory. The synergistic use of spatial and spectral laser information has proven to be beneficial for achieving precise forest semantic segmentation. Thus, this study aims to investigate the potential of MS-LiDAR data, captured by the HeliALS system, providing high-density multispectral point clouds to segment forests into six components: ground, low vegetation, trunks, branches, foliage, and woody debris. Three point-wise 3D deep learning models and one machine learning model, including kernel point convolution, superpoint transformer, point transformer V3, and random forest, are implemented. Our experiments confirm the superior accuracy of the KPConv model. Additionally, various geometric and spectral feature vector scenarios are examined. The highest accuracy is achieved by feeding all three wavelengths (1550 nm, 905 nm, and 532 nm) as the initial features into the deep learning model, resulting in improvements of 33.73% and 32.35% in mean intersection over union (mIoU) and in mean accuracy (mAcc), respectively. This study highlights the excellent potential of multispectral LiDAR for improving the accuracy in fully automated forest component segmentation.",
      "authors": [
        "Narges Takhtkeshha",
        "Lauris Bocaux",
        "Lassi Ruoppa",
        "Fabio Remondino",
        "Gottfried Mandlburger",
        "Antero Kukko and Juha Hyypp\\\"a"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.08025v1",
          "size": "7370kb",
          "version": "v1"
        }
      ],
      "title": "3D forest semantic segmentation using multispectral LiDAR and 3D deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08025",
        "PDF": "https://arxiv.org/pdf/2507.08025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves forest semantic segmentation using multispectral LiDAR and deep learning, and does not discuss any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08223",
      "abstract": "We present SurfDist, a convolutional neural network architecture for three-dimensional volumetric instance segmentation. SurfDist enables prediction of instances represented as closed surfaces composed of smooth parametric surface patches, specifically bicubic B\\'ezier triangles. SurfDist is a modification of the popular model architecture StarDist-3D which breaks StarDist-3D's coupling of instance parameterization dimension and instance voxel resolution, and it produces predictions which may be upsampled to arbitrarily high resolutions without introduction of voxelization artifacts.\n  For datasets with blob-shaped instances, common in biomedical imaging, SurfDist can outperform StarDist-3D with more compact instance parameterizations. We detail SurfDist's technical implementation and show one synthetic and one real-world dataset for which it outperforms StarDist-3D. These results demonstrate that interpretable instance surface models can be learned effectively alongside instance membership.",
      "authors": [
        "Jackson Borchardt",
        "Saul Kato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.08223v1",
          "size": "5130kb",
          "version": "v1"
        }
      ],
      "title": "SurfDist: Interpretable Three-Dimensional Instance Segmentation Using Curved Surface Patches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08223",
        "HTML": "https://arxiv.org/html/2507.08223v1",
        "PDF": "https://arxiv.org/pdf/2507.08223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a neural network architecture for 3D instance segmentation and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08438",
      "abstract": "We study the linear bandit problem under limited adaptivity, known as the batched linear bandit. While existing approaches can achieve near-optimal regret in theory, they are often computationally prohibitive or underperform in practice. We propose \\texttt{BLAE}, a novel batched algorithm that integrates arm elimination with regularized G-optimal design, achieving the minimax optimal regret (up to logarithmic factors in $T$) in both large-$K$ and small-$K$ regimes for the first time, while using only $O(\\log\\log T)$ batches. Our analysis introduces new techniques for batch-wise optimal design and refined concentration bounds. Crucially, \\texttt{BLAE} demonstrates low computational overhead and strong empirical performance, outperforming state-of-the-art methods in extensive numerical evaluations. Thus, \\texttt{BLAE} is the first algorithm to combine provable minimax-optimality in all regimes and practical superiority in batched linear bandits.",
      "authors": [
        "Sanghoon Yu and Min-hwan Oh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:29:28+00:00",
          "link": "https://arxiv.org/abs/2507.08438v1",
          "size": "1446kb",
          "version": "v1"
        }
      ],
      "title": "Optimal and Practical Batched Linear Bandit Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08438",
        "HTML": "https://arxiv.org/html/2507.08438v1",
        "PDF": "https://arxiv.org/pdf/2507.08438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a batched algorithm for linear bandit problems, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.11540",
      "abstract": "Point transformers have demonstrated remarkable progress in 3D understanding through expanded receptive fields (RF), but further expanding the RF leads to dilution in group attention and decreases detailed feature extraction capability. Proxy, which serves as abstract representations for simplifying feature maps, enables global RF. However, existing proxy-based approaches face critical limitations: Global proxies incur quadratic complexity for large-scale point clouds and suffer positional ambiguity, while local proxy alternatives struggle with 1) Unreliable sampling from the geometrically diverse point cloud, 2) Inefficient proxy interaction computation, and 3) Imbalanced local-global information fusion; To address these challenges, we propose Sparse Proxy Point Transformer (SP$^{2}$T) -- a local proxy-based dual-stream point transformer with three key innovations: First, for reliable sampling, spatial-wise proxy sampling with vertex-based associations enables robust sampling on geometrically diverse point clouds. Second, for efficient proxy interaction, sparse proxy attention with a table-based relative bias effectively achieves the interaction with efficient map-reduce computation. Third, for local-global information fusion, our dual-stream architecture maintains local-global balance through parallel branches. Comprehensive experiments reveal that SP$^{2}$T sets state-of-the-art results with acceptable latency on indoor and outdoor 3D comprehension benchmarks, demonstrating marked improvement (+3.8% mIoU vs. SPoTr@S3DIS, +22.9% mIoU vs. PointASNL@Sem.KITTI) compared to other proxy-based point cloud methods.",
      "authors": [
        "Jiaxu Wan",
        "Hong Zhang",
        "Ziqi He",
        "Yangyan Deng",
        "Qishu Wang",
        "Ding Yuan",
        "Yifan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T08:21:09+00:00",
          "link": "https://arxiv.org/abs/2412.11540v1",
          "size": "4166kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T10:38:22+00:00",
          "link": "https://arxiv.org/abs/2412.11540v2",
          "size": "3111kb",
          "version": "v2"
        }
      ],
      "title": "SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11540",
        "HTML": "https://arxiv.org/html/2412.11540v2",
        "PDF": "https://arxiv.org/pdf/2412.11540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces SP$^2$T for 3D point cloud understanding and does not involve any processing of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08665",
      "abstract": "Modern large language models (LLMs) show promising progress in formalizing informal mathematics into machine-verifiable theorems. However, these methods still face bottlenecks due to the limited quantity and quality of multilingual parallel corpora. In this paper, we propose a novel neuro-symbolic framework KELPS (Knowledge-Equation based Logical Processing System) to address these problems. KELPS is an iterative framework for translating, synthesizing, and filtering informal data into multiple formal languages (Lean, Coq, and Isabelle). First, we translate natural language into Knowledge Equations (KEs), a novel language that we designed, theoretically grounded in assertional logic. Next, we convert them to target languages through rigorously defined rules that preserve both syntactic structure and semantic meaning. This process yielded a parallel corpus of over 60,000 problems. Our framework achieves 88.9% syntactic accuracy (pass@1) on MiniF2F, outperforming SOTA models such as Deepseek-V3 (81%) and Herald (81.3%) across multiple datasets. All datasets and codes are available in the supplementary materials.",
      "authors": [
        "Jiyao Zhang",
        "Chengli Zhong",
        "Hui Xu",
        "Qige Li",
        "Yi Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:05:06+00:00",
          "link": "https://arxiv.org/abs/2507.08665v1",
          "size": "386kb",
          "version": "v1"
        }
      ],
      "title": "KELPS: A Framework for Verified Multi-Language Autoformalization via Semantic-Syntactic Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08665",
        "HTML": "https://arxiv.org/html/2507.08665v1",
        "PDF": "https://arxiv.org/pdf/2507.08665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a novel framework for creating a parallel corpus by translating, synthesizing, and filtering informal data into formal languages, clearly detailing data processing steps for creating new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.02984",
      "abstract": "Objectieve:This review aims to deliver a comprehensive analysis of Large Language Models (LLMs) utilization in mental health care, evaluating their effectiveness, identifying challenges, and exploring their potential for future application. Materials and Methods: A systematic search was performed across multiple databases including PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and PsyArXiv in November 2023. The review includes all types of original research, regardless of peer-review status, published or disseminated between October 1, 2019, and December 2, 2023. Studies were included without language restrictions if they employed LLMs developed after T5 and directly investigated research questions within mental health care settings. Results: Out of an initial 313 articles, 34 were selected based on their relevance to LLMs applications in mental health care and the rigor of their reported outcomes. The review identified various LLMs applications in mental health care, including diagnostics, therapy, and enhancing patient engagement. Key challenges highlighted were related to data availability and reliability, the nuanced handling of mental states, and effective evaluation methods. While LLMs showed promise in improving accuracy and accessibility, significant gaps in clinical applicability and ethical considerations were noted. Conclusion: LLMs hold substantial promise for enhancing mental health care. For their full potential to be realized, emphasis must be placed on developing robust datasets, development and evaluation frameworks, ethical guidelines, and interdisciplinary collaborations to address current limitations.",
      "authors": [
        "Yining Hua",
        "Fenglin Liu",
        "Kailai Yang",
        "Zehan Li",
        "Hongbin Na",
        "Yi-han Sheu",
        "Peilin Zhou",
        "Lauren V. Moran",
        "Sophia Ananiadou",
        "David A. Clifton",
        "Andrew Beam",
        "John Torous"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-01T17:35:52+00:00",
          "link": "https://arxiv.org/abs/2401.02984v1",
          "size": "1283kb",
          "version": "v1"
        },
        {
          "date": "2024-08-21T13:55:37+00:00",
          "link": "https://arxiv.org/abs/2401.02984v2",
          "size": "1946kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T16:38:18+00:00",
          "link": "https://arxiv.org/abs/2401.02984v3",
          "size": "1029kb",
          "version": "v3"
        }
      ],
      "title": "Large Language Models in Mental Health Care: a Scoping Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.02984",
        "HTML": "https://arxiv.org/html/2401.02984v3",
        "PDF": "https://arxiv.org/pdf/2401.02984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper reviews LLM applications in mental health care, identifying challenges related to data availability hints at data processing concerns, but the primary focus is on evaluating LLM efficacy rather than training data processing."
      },
      "tasks": [
        "Articles"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07901",
      "abstract": "The fragmentation of AI agent ecosystems has created urgent demands for interoperability, trust, and economic coordination that current protocols -- including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al., 2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present the Nanda Unified Architecture, a decentralized framework built around three core innovations: fast DID-based agent discovery through distributed registries, semantic agent cards with verifiable credentials and composability profiles, and a dynamic trust layer that integrates behavioral attestations with policy compliance. The system introduces X42/H42 micropayments for economic coordination and MAESTRO, a security framework incorporating Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure containerization. Real-world deployments demonstrate 99.9 percent compliance in healthcare applications and substantial monthly transaction volumes with strong privacy guarantees. By unifying MIT's trust research with production deployments from Cisco and Synergetics, we show how cryptographic proofs and policy-as-code transform agents into trust-anchored participants in a decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a globally interoperable Internet of Agents where trust becomes the native currency of collaboration across both enterprise and Web3 ecosystems.",
      "authors": [
        "Sree Bhargavi Balija",
        "Rekha Singal",
        "Abhishek Singh",
        "Ramesh Raskar",
        "Erfan Darzi",
        "Raghu Bala",
        "Thomas Hardjono",
        "Ken Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.07901v1",
          "size": "4620kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:11:21+00:00",
          "link": "https://arxiv.org/abs/2507.07901v2",
          "size": "4620kb",
          "version": "v2"
        }
      ],
      "title": "The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07901",
        "HTML": "https://arxiv.org/html/2507.07901v2",
        "PDF": "https://arxiv.org/pdf/2507.07901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a decentralized framework for agent ecosystems with trust and economic coordination innovations. It does not involve any aspect of LLM training data processing or dataset creation but focuses on interoperability and trust in AI agent ecosystems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08773",
      "abstract": "Firstly, assuming Gaussianity, equations for the following information theory measures are presented: total correlation/coherence (TC), dual total correlation/coherence (DTC), O-information, TSE complexity, and the redundancy-synergy index (RSI). Since these measures are functions of the covariance matrix \"S\" and its inverse \"S^-1\", the associated Wishart and inverse-Wishart distributions are of note. The DTC is shown here to be the Kullback-Leibler (KL) divergence for the inverse-Wishart pair \"(S^-1)\" and its diagonal matrix \"diag(S^-1)\", shedding light on its interpretation as a measure of \"total partial correlation\", -lndetP, with test hypothesis H0: P=I, where \"P\" is the standardized inverse covariance (i.e. P=(D^-1/2)(S^-1)(D^-1/2), with D=diag(S^-1)). The second aim of this paper introduces a generalization of all these measures for structured groups of variables. For instance, consider three or more groups, each consisting of three or more variables, with predominant redundancy within each group, but with synergistic interactions between groups. O-information will miss the between group synergy (since redundancy occurs more often in the system). In contrast, the structured O-information measure presented here will correctly report predominant synergy between groups. This is a relevant generalization towards structured multivariate information measures. A third aim is the presentation of a framework for quantifying the contribution of \"connections\" between variables, to the system's TC, DTC, O-information, and TSE complexity. A fourth aim is to present a generalization of the redundancy-synergy index for quantifying the contribution of a group of variables to the system's redundancy-synergy balance. Finally, it is shown that the expressions derived here directly apply to data from several other elliptical distributions. All program codes, data files, and executables are available.",
      "authors": [
        "Roberto D. Pascual-Marqui",
        "Kieko Kochi",
        "Toshihiko Kinoshita"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:35:04+00:00",
          "link": "https://arxiv.org/abs/2507.08773v1",
          "size": "864kb",
          "version": "v1"
        }
      ],
      "title": "Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08773",
        "PDF": "https://arxiv.org/pdf/2507.08773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the development of information-theoretic measures for multivariate data analysis and does not involve any specific processing or engineering of LLM training data or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08211",
      "abstract": "Large language model (LLM) chatbots show increasing promise in persuasive communication. Yet their real-world utility remains uncertain, particularly in clinical settings where sustained conversations are difficult to scale. In a pre-registered randomized controlled trial, we enrolled 915 U.S. adults (ages 45-75) who had never completed colorectal cancer (CRC) screening. Participants were randomized to: (1) no message control, (2) expert-written patient materials, (3) single AI-generated message, or (4) a motivational interviewing chatbot. All participants were required to remain in their assigned condition for at least three minutes. Both AI arms tailored content using participant's self-reported demographics including age and gender. Both AI interventions significantly increased stool test intentions by over 12 points (12.9-13.8/100), compared to a 7.5 gain for expert materials (p<.001 for all comparisons). While the AI arms outperformed the no message control for colonoscopy intent, neither showed improvement xover expert materials. Notably, for both outcomes, the chatbot did not outperform the single AI message in boosting intent despite participants spending ~3.5 minutes more on average engaging with it. These findings suggest concise, demographically tailored AI messages may offer a more scalable and clinically viable path to health behavior change than more complex conversational agents and generic time intensive expert-written materials. Moreover, LLMs appear more persuasive for lesser-known and less-invasive screening approaches like stool testing, but may be less effective for entrenched preferences like colonoscopy. Future work should examine which facets of personalization drive behavior change, whether integrating structural supports can translate these modest intent gains into completed screenings, and which health behaviors are most responsive to AI-supported guidance.",
      "authors": [
        "Neil K. R. Sehgal and Manuel Tonneau and Andy Tan and Shivan J. Mehta and Alison Buttenheim and Lyle Ungar and Anish K. Agarwal and Sharath Chandra Guntuku"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:46:43+00:00",
          "link": "https://arxiv.org/abs/2507.08211v1",
          "size": "3716kb",
          "version": "v1"
        }
      ],
      "title": "Effect of Static vs. Conversational AI-Generated Messages on Colorectal Cancer Screening Intent: a Randomized Controlled Trial",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08211",
        "PDF": "https://arxiv.org/pdf/2507.08211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the effectiveness of AI-generated messages using LLMs in health communications, briefly mentioning tailored content without focusing on training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08315",
      "abstract": "The $2$-to-$1$ mapping over finite fields has a wide range of applications, including combinatorial mathematics and coding theory. Thus, constructions of $2$-to-$1$ mappings have attracted considerable attention recently. Based on summarizing the existing construction results of all $2$-to-$1$ mappings over finite fields with even characteristic, this article first applies the generalized switching method to the study of $2$-to-$1$ mappings, that is, to construct $2$-to-$1$ mappings over the finite field $\\mathbb{F}_{q^l}$ with $F(x)=G(x)+{\\rm Tr}_{q^l/q}(R(x))$, where $G$ is a monomial and $R$ is a monomial or binomial. Using the properties of Dickson polynomial theory and the complete characterization of low-degree equations, we construct a total of $16$ new classes of $2$-to-$1$ mappings, which are not QM-equivalent to any existing $2$-to-$1$ polynomials. Among these, $9$ classes are of the form $cx + {\\rm Tr}_{q^l/q}(x^d)$, and $7$ classes have the form $cx + {\\rm Tr}_{q^l/q}(x^{d_1} + x^{d_2})$. These new infinite classes explain most of numerical results by MAGMA under the conditions that $q=2^k$, $k>1$, $kl<14$ and $c \\in \\gf_{q^l}^*$. Finally, we construct some binary linear codes using the newly proposed $2$-to-$1$ mappings of the form $cx + {\\rm Tr}_{q^l/q}(x^d)$. The weight distributions of these codes are also determined. Interestingly, our codes are self-orthogonal, minimal, and have few weights.",
      "authors": [
        "Yaqin Li",
        "Kangquan Li",
        "Qiancheng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:05:51+00:00",
          "link": "https://arxiv.org/abs/2507.08315v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "New constructions of $2$-to-$1$ mappings over $\\gf_{2^n}$ and their applications to binary linear codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08315",
        "HTML": "https://arxiv.org/html/2507.08315v1",
        "PDF": "https://arxiv.org/pdf/2507.08315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on constructing $2$-to-$1$ mappings and binary linear codes over finite fields, which is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.00404",
      "abstract": "We introduce SecRef*, a secure compilation framework protecting stateful programs verified in F* against linked unverified code, with which the program dynamically shares ML-style mutable references. To ease program verification in this setting, we propose a way of tracking which references are shareable with the unverified code, and which ones are not shareable and whose contents are thus guaranteed to be unchanged after calling into unverified code. This universal property of non-shareable references is exposed in the interface on which the verified program can rely when calling into unverified code. The remaining refinement types and pre- and post-conditions that the verified code expects from the unverified code are converted into dynamic checks about the shared references by using higher-order contracts. We prove formally in F* that this strategy ensures sound and secure interoperability with unverified code. Since SecRef* is built on top of the Monotonic State effect of F*, these proofs rely on the first monadic representation for this effect, which is a contribution of our work that can be of independent interest. Finally, we use SecRef* to build a simple cooperative multi-threading scheduler that is verified and that securely interacts with unverified threads.",
      "authors": [
        "Cezar-Constantin Andrici",
        "Danel Ahman",
        "Catalin Hritcu",
        "Ruxandra Icleanu",
        "Guido Mart\\'inez",
        "Exequiel Rivas",
        "Th\\'eo Winterhalter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T08:48:39+00:00",
          "link": "https://arxiv.org/abs/2503.00404v1",
          "size": "76kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T06:17:13+00:00",
          "link": "https://arxiv.org/abs/2503.00404v2",
          "size": "82kb",
          "version": "v2"
        }
      ],
      "title": "SecRef*: Securely Sharing Mutable References Between Verified and Unverified Code in F*",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00404",
        "HTML": "https://arxiv.org/html/2503.00404v2",
        "PDF": "https://arxiv.org/pdf/2503.00404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SecRef* focuses on secure compilation and interoperability in code verification, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08448",
      "abstract": "3D reconstruction, which aims to recover the dense three-dimensional structure of a scene, is a cornerstone technology for numerous applications, including augmented/virtual reality, autonomous driving, and robotics. While traditional pipelines like Structure from Motion (SfM) and Multi-View Stereo (MVS) achieve high precision through iterative optimization, they are limited by complex workflows, high computational cost, and poor robustness in challenging scenarios like texture-less regions. Recently, deep learning has catalyzed a paradigm shift in 3D reconstruction. A new family of models, exemplified by DUSt3R, has pioneered a feed-forward approach. These models employ a unified deep network to jointly infer camera poses and dense geometry directly from an Unconstrained set of images in a single forward pass. This survey provides a systematic review of this emerging domain. We begin by dissecting the technical framework of these feed-forward models, including their Transformer-based correspondence modeling, joint pose and geometry regression mechanisms, and strategies for scaling from two-view to multi-view scenarios. To highlight the disruptive nature of this new paradigm, we contrast it with both traditional pipelines and earlier learning-based methods like MVSNet. Furthermore, we provide an overview of relevant datasets and evaluation metrics. Finally, we discuss the technology's broad application prospects and identify key future challenges and opportunities, such as model accuracy and scalability, and handling dynamic scenes.",
      "authors": [
        "Wei Zhang",
        "Yihang Wu",
        "Songhua Li",
        "Wenjie Ma",
        "Xin Ma",
        "Qiang Li",
        "Qi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:41:54+00:00",
          "link": "https://arxiv.org/abs/2507.08448v1",
          "size": "624kb",
          "version": "v1"
        }
      ],
      "title": "Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08448",
        "PDF": "https://arxiv.org/pdf/2507.08448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D reconstruction methods, contrasting deep learning models for pose and geometry prediction. There is no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.08419",
      "abstract": "We establish various complexity results for the entailment problem between formulas in Separation Logic with user-defined predicates denoting recursive data structures. The considered fragments are characterized by syntactic conditions on the inductive rules that define the semantics of the predicates. We focus on so-called P-rules, which are similar to (but simpler than) the PCE rules introduced by Iosif et al. in 2013. In particular, for a specific fragment where predicates are defined by so-called loc-deterministic inductive rules, we devise a sound and complete cyclic proof procedure running in polynomial time. Several complexity lower bounds are provided, showing that any relaxing of the provided conditions makes the problem intractable.",
      "authors": [
        "Mnacho Echenim and Nicolas Peltier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-15T08:00:55+00:00",
          "link": "https://arxiv.org/abs/2305.08419v1",
          "size": "73kb",
          "version": "v1"
        },
        {
          "date": "2023-12-04T13:58:19+00:00",
          "link": "https://arxiv.org/abs/2305.08419v2",
          "size": "84kb",
          "version": "v2"
        },
        {
          "date": "2024-05-23T14:31:19+00:00",
          "link": "https://arxiv.org/abs/2305.08419v3",
          "size": "86kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T14:30:25+00:00",
          "link": "https://arxiv.org/abs/2305.08419v4",
          "size": "86kb",
          "version": "v4"
        }
      ],
      "title": "Tractable and Intractable Entailment Problems in Separation Logic with Inductively Defined Predicates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.08419",
        "HTML": "https://arxiv.org/html/2305.08419v4",
        "PDF": "https://arxiv.org/pdf/2305.08419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses complexity results for entailment problems in Separation Logic, which is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05730",
      "abstract": "Hyperspectral images are high-dimensional datasets comprising hundreds of contiguous spectral bands, enabling detailed analysis of materials and surfaces. Hyperspectral anomaly detection (HAD) refers to the technique of identifying and locating anomalous targets in such data without prior information about a hyperspectral scene or target spectrum. This technology has seen rapid advancements in recent years, with applications in agriculture, defence, military surveillance, and environmental monitoring. Despite this significant progress, existing HAD methods continue to face challenges such as high computational complexity, sensitivity to noise, and limited generalisation across diverse datasets. This study presents a comprehensive comparison of various HAD techniques, categorising them into statistical models, representation-based methods, classical machine learning approaches, and deep learning models. We evaluated these methods across 17 benchmarking datasets using different performance metrics, such as ROC, AUC, and separability map to analyse detection accuracy, computational efficiency, their strengths, limitations, and directions for future research. Our findings highlight that deep learning models achieved the highest detection accuracy, while statistical models demonstrated exceptional speed across all datasets. This survey aims to provide valuable insights for researchers and practitioners working to advance the field of hyperspectral anomaly detection methods.",
      "authors": [
        "Aayushma Pant",
        "Arbind Agrahari Baniya",
        "Tsz-Kwan Lee",
        "and Sunil Aryal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:23:24+00:00",
          "link": "https://arxiv.org/abs/2507.05730v1",
          "size": "10339kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:35:34+00:00",
          "link": "https://arxiv.org/abs/2507.05730v2",
          "size": "10226kb",
          "version": "v2"
        }
      ],
      "title": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05730",
        "PDF": "https://arxiv.org/pdf/2507.05730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys hyperspectral anomaly detection methods, focusing on technique comparisons and evaluations, rather than discussing LLM training data processing or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08167",
      "abstract": "Emotion detection in older adults is crucial for understanding their cognitive and emotional well-being, especially in hospital and assisted living environments. In this work, we investigate an edge-based, non-obtrusive approach to emotion identification that uses only physiological signals obtained via wearable sensors. Our dataset includes data from 40 older individuals. Emotional states were obtained using physiological signals from the Empatica E4 and Shimmer3 GSR+ wristband and facial expressions were recorded using camera-based emotion recognition with the iMotion's Facial Expression Analysis (FEA) module. The dataset also contains twelve emotion categories in terms of relative intensities. We aim to study how well emotion recognition can be accomplished using simply physiological sensor data, without the requirement for cameras or intrusive facial analysis. By leveraging classical machine learning models, we predict the intensity of emotional responses based on physiological signals. We achieved the highest 0.782 r2 score with the lowest 0.0006 MSE on the regression task. This method has significant implications for individuals with Alzheimer's Disease and Related Dementia (ADRD), as well as veterans coping with Post-Traumatic Stress Disorder (PTSD) or other cognitive impairments. Our results across multiple classical regression models validate the feasibility of this method, paving the way for privacy-preserving and efficient emotion recognition systems in real-world settings.",
      "authors": [
        "Md. Saif Hassan Onim",
        "Andrew M. Kiselica and Himanshu Thapliyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:59:25+00:00",
          "link": "https://arxiv.org/abs/2507.08167v1",
          "size": "2917kb",
          "version": "v1"
        }
      ],
      "title": "Emotion Detection in Older Adults Using Physiological Signals from Wearable Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08167",
        "HTML": "https://arxiv.org/html/2507.08167v1",
        "PDF": "https://arxiv.org/pdf/2507.08167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on emotion detection using physiological signals, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08331",
      "abstract": "In recent years, the increasing awareness of cybersecurity has led to a heightened focus on information security within hardware devices and products. Incorporating Trusted Execution Environments (TEEs) into product designs has become a standard practice for safeguarding sensitive user information. However, vulnerabilities within these components present significant risks, if exploited by attackers, these vulnerabilities could lead to the leakage of sensitive data, thereby compromising user privacy and security. This research centers on trusted applications (TAs) within the Qualcomm TEE and introduces a novel emulator specifically designed for these applications. Through reverse engineering techniques, we thoroughly analyze Qualcomm TAs and develop a partial emulation environment that accurately emulates their behavior. Additionally, we integrate fuzzing testing techniques into the emulator to systematically uncover potential vulnerabilities within Qualcomm TAs, demonstrating its practical effectiveness in identifying real-world security flaws. This research makes a significant contribution by being the first to provide both the implementation methods and source codes for a Qualcomm TAs emulator, offering a valuable reference for future research efforts. Unlike previous approaches that relied on complex and resource-intensive full-system simulations, our approach is lightweight and effective, making security testing of TA more convenient.",
      "authors": [
        "Chun-I Fan",
        "Li-En Chang",
        "Cheng-Han Shie"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:10:15+00:00",
          "link": "https://arxiv.org/abs/2507.08331v1",
          "size": "897kb",
          "version": "v1"
        }
      ],
      "title": "Qualcomm Trusted Application Emulation for Fuzzing Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08331",
        "HTML": "https://arxiv.org/html/2507.08331v1",
        "PDF": "https://arxiv.org/pdf/2507.08331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing an emulator for Qualcomm Trusted Applications and integrating fuzzing testing techniques, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08393",
      "abstract": "The centerline of a bobsleigh track defines its geometry and is essential for simulation modeling. To reduce bBobsleigh training costs, leveraging the centerline of the bobsleigh track to construct a virtual environment that closely replicates real competitive settings presents a promising solution. However, publicly available centerline data are typically limited and it is imprecise to construct a training system solely based on 2-dimensional (2D) centerline. To address this practical issue, this paper proposes a method for generating a 3-dimensional (3D) track centerline based on 2D centerline data. Incorporating international track design regulations, the method formulates an optimization problem that considers total track length, height difference, slope constraints, and geometric continuity. A Projected Gradient Descent (PGD) algorithm is used to solve the optimization problem. The generated 3D centerlines are compared with real track data, and the results show that the method can reproduce realistic centerline trends from original or scaled 2D data. For the selected track segment, the relative errors in total length, height difference, and average slope are within 1.7%, 3.2% and 4.1%, respectively, for real 2D data and within 1.1%, 3.5% and 4.3% respectively for scaled data. All slope values remain within the allowable limits. Moreover, by adjusting the segmentation or modifying the weight of height difference in the cost function, various centerline styles applicable to different competitions can be generated. Under different segmentation and weight factors, the maximum errors reach up to 4.4%, 4.8%, and 9.8%, and 4.4%, 4.8%, and 10.0%, respectively. The proposed method provides a flexible and efficient tool for supporting bobsleigh track centerline design.",
      "authors": [
        "Zhe Chen and Huichao Zhao and Yongfeng Jiang and Minghui Bai and Lun Li and Jicheng Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:05:22+00:00",
          "link": "https://arxiv.org/abs/2507.08393v1",
          "size": "4688kb",
          "version": "v1"
        }
      ],
      "title": "PGD-based optimization of 3D bobsleigh track centerlines from 2D centerlines for simulation applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08393",
        "HTML": "https://arxiv.org/html/2507.08393v1",
        "PDF": "https://arxiv.org/pdf/2507.08393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing the geometry of bobsleigh tracks using 2D data to generate 3D centerlines, which does not involve processing LLM training data or any form of data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08717",
      "abstract": "Previous generations of cellular communication, such as 5G, have been designed with the objective of improving key performance indicators (KPIs) such as throughput, latency, etc. However, to meet the evolving KPI demands as well as the ambitious sustainability targets for the ICT industry, 6G will need to be designed differently. Concretely, 6G will need to consider both the performance and sustainability targets for the various use cases it will serve. Moreover, like previous generations, 6G will have various candidate technological enablers, making the design space of the system even more complex. Furthermore, given the subjective nature of the sustainability indicators, in particular social sustainability, there is a significant gap in literature on how technical enablers and 6G System design can be linked to them. Hence, in this article a novel method for 6G end-to-end (E2E) system design based on Knowledge graphs (KG) has been introduced. It considers as its input: the use case KPIs, use case sustainability requirements expressed as Key Values (KV) and KV Indicators (KVIs), the ability of the technological enablers to satisfy these KPIs and KVIs, the 6G system design principles defined in Hexa-X-II project, the maturity of a technological enabler and the dependencies between the various enablers. As part of the KG method, a novel approach for determining the key values a technological enabler addresses, has also been introduced. The effectiveness of the KG method was demonstrated by its application in designing the 6G E2E system for the cooperating mobile robot use case defined in the Hexa-X-II project, where 82 enablers were selected. Lastly, results from proof-of-concept demonstrations for a subset of the selected enablers have also been provided, which reinforce the efficacy of the KG method for designing a sustainable 6G system.",
      "authors": [
        "Akshay Jain",
        "Sylvaine Kerboeuf",
        "Sokratis Barmpounakis",
        "Crist\\'obal Vinagre Z.",
        "Stefan Wendt",
        "Dinh Thai Bui",
        "Pol Alemany",
        "Riccardo Nicolicchia",
        "Jos\\'e Mar\\'ia Jorquera Valero",
        "Dani Korpi",
        "Mohammad Hossein Moghaddam",
        "Mikko A. Uusitalo",
        "Patrik Rugeland",
        "Abdelkader Outtagarts",
        "Karthik Upadhya",
        "Panagiotis Demestichas",
        "Raul Mu\\~noz",
        "Manuel Gil P\\'erez",
        "Daniel Adanza",
        "Ricard Vilalta"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:17:46+00:00",
          "link": "https://arxiv.org/abs/2507.08717v1",
          "size": "3056kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Graph-Based approach for Sustainable 6G End-to-End System Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08717",
        "HTML": "https://arxiv.org/html/2507.08717v1",
        "PDF": "https://arxiv.org/pdf/2507.08717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the design of 6G systems using knowledge graphs and technical enablers, without any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.06227",
      "abstract": "Nonparametric estimation using uniform-width binning is a standard approach for evaluating the calibration performance of machine learning models. However, existing theoretical analyses of the bias induced by binning are limited to binary classification, creating a significant gap with practical applications such as multiclass classification. Additionally, many parametric recalibration algorithms lack theoretical guarantees for their generalization performance. To address these issues, we conduct a generalization analysis of calibration error using the probably approximately correct Bayes framework. This approach enables us to derive the first optimizable upper bound for generalization error in the calibration context. On the basis of our theory, we propose a generalization-aware recalibration algorithm. Numerical experiments show that our algorithm enhances the performance of Gaussian process-based recalibration across various benchmark datasets and models.",
      "authors": [
        "Masahiro Fujisawa",
        "Futoshi Futami"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-10T12:53:13+00:00",
          "link": "https://arxiv.org/abs/2406.06227v1",
          "size": "207kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:22:08+00:00",
          "link": "https://arxiv.org/abs/2406.06227v2",
          "size": "444kb",
          "version": "v2"
        }
      ],
      "title": "PAC-Bayes Analysis for Recalibration in Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.06227",
        "HTML": "https://arxiv.org/html/2406.06227v2",
        "PDF": "https://arxiv.org/pdf/2406.06227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses calibration in classification tasks using PAC-Bayes analysis, without any contribution to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08005",
      "abstract": "Generative AI presents chemists with novel ideas for drug design and facilitates the exploration of vast chemical spaces. Diffusion models (DMs), an emerging tool, have recently attracted great attention in drug R\\&D. This paper comprehensively reviews the latest advancements and applications of DMs in molecular generation. It begins by introducing the theoretical principles of DMs. Subsequently, it categorizes various DM-based molecular generation methods according to their mathematical and chemical applications. The review further examines the performance of these models on benchmark datasets, with a particular focus on comparing the generation performance of existing 3D methods. Finally, it concludes by emphasizing current challenges and suggesting future research directions to fully exploit the potential of DMs in drug discovery.",
      "authors": [
        "Peining Zhang",
        "Daniel Baker",
        "Minghu Song",
        "Jinbo Bi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T03:55:44+00:00",
          "link": "https://arxiv.org/abs/2507.08005v1",
          "size": "428kb",
          "version": "v1"
        }
      ],
      "title": "Unraveling the Potential of Diffusion Models in Small Molecule Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08005",
        "HTML": "https://arxiv.org/html/2507.08005v1",
        "PDF": "https://arxiv.org/pdf/2507.08005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on diffusion models for small molecule generation in drug design, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08149",
      "abstract": "Developers now have access to a growing array of increasingly autonomous AI tools to support software development. While numerous studies have examined developer use of copilots, which can provide chat assistance or code completions, evaluations of coding agents, which can automatically write files and run code, still largely rely on static benchmarks without humans-in-the-loop. In this work, we conduct the first academic study to explore developer interactions with coding agents and characterize how more autonomous AI tools affect user productivity and experience, compared to existing copilots. We evaluate two leading copilot and agentic coding assistants, GitHub Copilot and OpenHands, recruiting participants who regularly use the former. Our results show agents have the potential to assist developers in ways that surpass copilots (e.g., completing tasks that humans might not have accomplished before) and reduce the user effort required to complete tasks. However, there are challenges involved in enabling their broader adoption, including how to ensure users have an adequate understanding of agent behaviors. Our results not only provide insights into how developer workflows change as a result of coding agents but also highlight how user interactions with agents differ from those with existing copilots, motivating a set of recommendations for researchers building new agents. Given the broad set of developers who still largely rely on copilot-like systems, our work highlights key challenges of adopting more agentic systems into developer workflows.",
      "authors": [
        "Valerie Chen",
        "Ameet Talwalkar",
        "Robert Brennan",
        "Graham Neubig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:12:54+00:00",
          "link": "https://arxiv.org/abs/2507.08149v1",
          "size": "2358kb",
          "version": "v1"
        }
      ],
      "title": "Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08149",
        "PDF": "https://arxiv.org/pdf/2507.08149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies developer interactions with AI tools in coding, focusing on copilot and agent systems, but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08392",
      "abstract": "Incorporating ethics into the requirement elicitation process is essential for creating ethically aligned systems. Although eliciting manual ethics requirements is effective, it requires diverse input from multiple stakeholders, which can be challenging due to time and resource constraints. Moreover, it is often given a low priority in the requirements elicitation process. This study proposes a framework for generating ethics requirements drafts by introducing an ethics advocate agent in a multi-agent LLM setting. This agent critiques and provides input on ethical issues based on the system description. The proposed framework is evaluated through two case studies from different contexts, demonstrating that it captures the majority of ethics requirements identified by researchers during 30-minute interviews and introduces several additional relevant requirements. However, it also highlights reliability issues in generating ethics requirements, emphasizing the need for human feedback in this sensitive domain. We believe this work can facilitate the broader adoption of ethics in the requirements engineering process, ultimately leading to more ethically aligned products.",
      "authors": [
        "Asma Yamani and Malak Baslyman and Moataz Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:04:32+00:00",
          "link": "https://arxiv.org/abs/2507.08392v1",
          "size": "1984kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08392",
        "HTML": "https://arxiv.org/html/2507.08392v1",
        "PDF": "https://arxiv.org/pdf/2507.08392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for generating ethics requirements drafts using a multi-agent LLM setting, focusing on ethical input rather than substantive LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08202",
      "abstract": "We propose a novel data-driven method called QENDy (Quadratic Embedding of Nonlinear Dynamics) that not only allows us to learn quadratic representations of highly nonlinear dynamical systems, but also to identify the governing equations. The approach is based on an embedding of the system into a higher-dimensional feature space in which the dynamics become quadratic. Just like SINDy (Sparse Identification of Nonlinear Dynamics), our method requires trajectory data, time derivatives for the training data points, which can also be estimated using finite difference approximations, and a set of preselected basis functions, called dictionary. We illustrate the efficacy and accuracy of QENDy with the aid of various benchmark problems and compare its performance with SINDy and a deep learning method for identifying quadratic embeddings. Furthermore, we analyze the convergence of QENDy and SINDy in the infinite data limit, highlight their similarities and main differences, and compare the quadratic embedding with linearization techniques based on the Koopman operator.",
      "authors": [
        "Stefan Klus",
        "Joel-Pascal Ntwali N'konzi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T15:37:03+00:00",
          "link": "https://arxiv.org/abs/2501.08202v1",
          "size": "1555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:09:59+00:00",
          "link": "https://arxiv.org/abs/2501.08202v2",
          "size": "1621kb",
          "version": "v2"
        }
      ],
      "title": "Data-driven system identification using quadratic embeddings of nonlinear dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08202",
        "HTML": "https://arxiv.org/html/2501.08202v2",
        "PDF": "https://arxiv.org/pdf/2501.08202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a novel data-driven method for system identification using quadratic embeddings of nonlinear dynamics, which is not related to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08191",
      "abstract": "This is the third year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we refreshed both the document and the passage collections which also led to a nearly four times increase in the document collection size and nearly $16$ times increase in the size of the passage collection. Deep neural ranking models that employ large scale pretraininig continued to outperform traditional retrieval methods this year. We also found that single stage retrieval can achieve good performance on both tasks although they still do not perform at par with multistage retrieval pipelines. Finally, the increase in the collection size and the general data refresh raised some questions about completeness of NIST judgments and the quality of the training labels that were mapped to the new collections from the old ones which we discuss in this report.",
      "authors": [
        "Nick Craswell",
        "Bhaskar Mitra",
        "Emine Yilmaz",
        "Daniel Campos",
        "and Jimmy Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:58:41+00:00",
          "link": "https://arxiv.org/abs/2507.08191v1",
          "size": "5512kb",
          "version": "v1"
        }
      ],
      "title": "Overview of the TREC 2021 deep learning track",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08191",
        "HTML": "https://arxiv.org/html/2507.08191v1",
        "PDF": "https://arxiv.org/pdf/2507.08191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses MS MARCO datasets and data refresh impacting the quality of training labels. It mentions data processing related issues but does not focus on core data processing techniques for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08253",
      "abstract": "Nonlinear computation is essential for a wide range of information processing tasks, yet implementing nonlinear functions using optical systems remains a challenge due to the weak and power-intensive nature of optical nonlinearities. Overcoming this limitation without relying on nonlinear optical materials could unlock unprecedented opportunities for ultrafast and parallel optical computing systems. Here, we demonstrate that large-scale nonlinear computation can be performed using linear optics through optimized diffractive processors composed of passive phase-only surfaces. In this framework, the input variables of nonlinear functions are encoded into the phase of an optical wavefront, e.g., via a spatial light modulator (SLM), and transformed by an optimized diffractive structure with spatially varying point-spread functions to yield output intensities that approximate a large set of unique nonlinear functions, all in parallel. We provide proof establishing that this architecture serves as a universal function approximator for an arbitrary set of bandlimited nonlinear functions, also covering multi-variate and complex-valued functions. We also numerically demonstrate the parallel computation of one million distinct nonlinear functions, accurately executed at wavelength-scale spatial density at the output of a diffractive optical processor. Furthermore, we experimentally validated this framework using in situ optical learning and approximated 35 unique nonlinear functions in a single shot using a compact setup consisting of an SLM and an image sensor. These results establish diffractive optical processors as a scalable platform for massively parallel universal nonlinear function approximation, paving the way for new capabilities in analog optical computing based on linear materials.",
      "authors": [
        "Md Sadman Sakib Rahman",
        "Yuhang Li",
        "Xilin Yang",
        "Shiqi Chen",
        "Aydogan Ozcan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:54:10+00:00",
          "link": "https://arxiv.org/abs/2507.08253v1",
          "size": "1296kb",
          "version": "v1"
        }
      ],
      "title": "Massively parallel and universal approximation of nonlinear functions using diffractive processors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08253",
        "PDF": "https://arxiv.org/pdf/2507.08253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optical computing systems and universal approximation of nonlinear functions, without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08477",
      "abstract": "The deep integration of large language models and automatic speech recognition systems has become a promising research direction with high practical value. To address the overfitting issue commonly observed in Low-Rank Adaptation (LoRA) during the supervised fine-tuning (SFT) stage, this work proposes an innovative training paradigm Iterative LoRA Training (ILT) in combination with an Iterative Pseudo Labeling strategy, effectively enhancing the theoretical upper bound of model performance. Based on Whisper-large-v3 and Qwen2-Audio, we conduct systematic experiments using a three-stage training process: Focus Training, Feed Back Training, and Fix Training. Experimental results demonstrate the effectiveness of the proposed method. Furthermore, the MegaAIS research team applied this technique in the Interspeech 2025 Multilingual Conversational Speech Language Modeling Challenge (MLC-SLM), achieving 4th in Track 1 (Multilingual ASR Task) and 1st place in Track 2 (Speech Separation and Recognition Task), showcasing the practical feasibility and strong application potential of our approach.",
      "authors": [
        "Qingliang Meng",
        "Hao Wu",
        "Wei Liang",
        "Wei Xu",
        "Qing Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:38:51+00:00",
          "link": "https://arxiv.org/abs/2507.08477v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08477",
        "HTML": "https://arxiv.org/html/2507.08477v1",
        "PDF": "https://arxiv.org/pdf/2507.08477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions improving the performance of LLMs in multilingual speech recognition but focuses on iterative training paradigms rather than data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08487",
      "abstract": "Essays are considered a valuable mechanism for evaluating learning outcomes in writing. Textual cohesion is an essential characteristic of a text, as it facilitates the establishment of meaning between its parts. Automatically scoring cohesion in essays presents a challenge in the field of educational artificial intelligence. The machine learning algorithms used to evaluate texts generally do not consider the individual characteristics of the instances that comprise the analysed corpus. In this meaning, item response theory can be adapted to the context of machine learning, characterising the ability, difficulty and discrimination of the models used. This work proposes and analyses the performance of a cohesion score prediction approach based on item response theory to adjust the scores generated by machine learning models. In this study, the corpus selected for the experiments consisted of the extended Essay-BR, which includes 6,563 essays in the style of the National High School Exam (ENEM), and the Brazilian Portuguese Narrative Essays, comprising 1,235 essays written by 5th to 9th grade students from public schools. We extracted 325 linguistic features and treated the problem as a machine learning regression task. The experimental results indicate that the proposed approach outperforms conventional machine learning models and ensemble methods in several evaluation metrics. This research explores a potential approach for improving the automatic evaluation of cohesion in educational essays.",
      "authors": [
        "Bruno Alexandre Rosa",
        "Hil\\'ario Oliveira",
        "Luiz Rodrigues",
        "Eduardo Araujo Oliveira",
        "Rafael Ferreira Mello"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:05:27+00:00",
          "link": "https://arxiv.org/abs/2507.08487v1",
          "size": "3616kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08487",
        "HTML": "https://arxiv.org/html/2507.08487v1",
        "PDF": "https://arxiv.org/pdf/2507.08487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel approach for cohesion assessment in essays using item response theory, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.24537",
      "abstract": "We present ASP Chef Mustache, an extension of ASP Chef that enhances template-based rendering of ASP solutions using a logic-less templating system inspired by Mustache. Our approach integrates data visualization frameworks such as Tabulator, Chart.js, and vis.js, enabling interactive representations of ASP interpretations as tables, charts, and graphs. Mustache queries in templates support advanced constructs for formatting, sorting, and multi-stage expansion, facilitating the generation of rich, structured outputs. We demonstrate the power of this framework through a series of use cases, including data analysis for the Italian VQR, visualization of blocking sets in graphs, and scheduling problems. The result is a versatile tool for bridging declarative problem solving and modern web-based visual analytics.",
      "authors": [
        "Mario Alviano",
        "Wolfgang Faber and Luis Angel Rodriguez Reiners"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T12:42:10+00:00",
          "link": "https://arxiv.org/abs/2505.24537v1",
          "size": "503kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:45:24+00:00",
          "link": "https://arxiv.org/abs/2505.24537v2",
          "size": "508kb",
          "version": "v2"
        }
      ],
      "title": "ASP Chef grows Mustache to look better",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24537",
        "PDF": "https://arxiv.org/pdf/2505.24537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ASP Chef and Mustache templating for rendering ASP solutions but does not relate to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08802",
      "abstract": "The concept of causal abstraction got recently popularised to demystify the opaque decision-making processes of machine learning models; in short, a neural network can be abstracted as a higher-level algorithm if there exists a function which allows us to map between them. Notably, most interpretability papers implement these maps as linear functions, motivated by the linear representation hypothesis: the idea that features are encoded linearly in a model's representations. However, this linearity constraint is not required by the definition of causal abstraction. In this work, we critically examine the concept of causal abstraction by considering arbitrarily powerful alignment maps. In particular, we prove that under reasonable assumptions, any neural network can be mapped to any algorithm, rendering this unrestricted notion of causal abstraction trivial and uninformative. We complement these theoretical findings with empirical evidence, demonstrating that it is possible to perfectly map models to algorithms even when these models are incapable of solving the actual task; e.g., on an experiment using randomly initialised language models, our alignment maps reach 100% interchange-intervention accuracy on the indirect object identification task. This raises the non-linear representation dilemma: if we lift the linearity constraint imposed to alignment maps in causal abstraction analyses, we are left with no principled way to balance the inherent trade-off between these maps' complexity and accuracy. Together, these results suggest an answer to our title's question: causal abstraction is not enough for mechanistic interpretability, as it becomes vacuous without assumptions about how models encode information. Studying the connection between this information-encoding assumption and causal abstraction should lead to exciting future work.",
      "authors": [
        "Denis Sutter",
        "Julian Minder",
        "Thomas Hofmann",
        "Tiago Pimentel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.08802v1",
          "size": "3079kb",
          "version": "v1"
        }
      ],
      "title": "The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08802",
        "PDF": "https://arxiv.org/pdf/2507.08802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses causal abstraction in machine learning models with an emphasis on interpretability and alignment maps, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08365",
      "abstract": "Lane changes of preceding vehicles have a great impact on the motion planning of automated vehicles especially in complex traffic situations. Predicting them would benefit the public in terms of safety and efficiency. While many research efforts have been made in this direction, few concentrated on predicting maneuvers within a set time interval compared to predicting at a set prediction time. In addition, there exist a lack of comparisons between different architectures to try to determine the best performing one and to assess how to correctly choose the input for such models. In this paper the structure of an LSTM, a CNN and a Transformer network are described and implemented to predict the intention of human drivers to perform a lane change. We show how the data was prepared starting from a publicly available dataset (highD), which features were used, how the networks were designed and finally we compare the results of the three networks with different configurations of input data. We found that transformer networks performed better than the other networks and was less affected by overfitting. The accuracy of the method spanned from $82.79\\%$ to $96.73\\%$ for different input configurations and showed overall good performances considering also precision and recall.",
      "authors": [
        "Francesco De Cristofaro",
        "Felix Hofbaur",
        "Aixi Yang",
        "Arno Eichberger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.08365v1",
          "size": "3275kb",
          "version": "v1"
        }
      ],
      "title": "Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN and a Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08365",
        "HTML": "https://arxiv.org/html/2507.08365v1",
        "PDF": "https://arxiv.org/pdf/2507.08365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes how data from a public dataset (highD) was prepared and used for training various models (LSTM, CNN, Transformer) but focuses on model comparison, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08536",
      "abstract": "Lowering the resource overhead needed to achieve fault-tolerant quantum computation is crucial to building scalable quantum computers. We show that adapting conventional maximum likelihood (ML) decoders to a small subset of efficiently learnable physical error characteristics can significantly improve the logical performance of a quantum error-correcting code. Specifically, we leverage error information obtained from efficient characterization methods based on Cycle Error Reconstruction (CER), which yields Pauli error rates on the $n$ qubits of an error-correcting code. Although the total number of Pauli error rates needed to describe a general noise process is exponentially large in $n$, we show that only a few of the largest few Pauli error rates are needed and that a heuristic technique can complete the Pauli error distribution for ML decoding from this restricted dataset. Using these techniques, we demonstrate significant performance improvements for decoding quantum codes under a variety of physically relevant error models. For instance, with CER data that constitute merely $1\\%$ of the Pauli error rates in the system, we achieve a $10X$ gain in performance compared to the case where decoding is based solely on the fidelity of the underlying noise process. Our conclusions underscore the promise of recent error characterization methods for improving quantum error correction and lowering overheads.",
      "authors": [
        "Pavithran Iyer",
        "Aditya Jain",
        "Stephen D. Bartlett and Joseph Emerson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:36:30+00:00",
          "link": "https://arxiv.org/abs/2507.08536v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Decoding Performance using Efficient Error Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08536",
        "HTML": "https://arxiv.org/html/2507.08536v1",
        "PDF": "https://arxiv.org/pdf/2507.08536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work pertains to quantum error correction through efficient error learning, not involving any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08766",
      "abstract": "This study presents a hybrid model for classifying handwritten digits in the MNIST dataset, combining convolutional neural networks (CNNs) with a multi-well Hopfield network. The approach employs a CNN to extract high-dimensional features from input images, which are then clustered into class-specific prototypes using k-means clustering. These prototypes serve as attractors in a multi-well energy landscape, where a Hopfield network performs classification by minimizing an energy function that balances feature similarity and class assignment.The model's design enables robust handling of intraclass variability, such as diverse handwriting styles, while providing an interpretable framework through its energy-based decision process. Through systematic optimization of the CNN architecture and the number of wells, the model achieves a high test accuracy of 99.2% on 10,000 MNIST images, demonstrating its effectiveness for image classification tasks. The findings highlight the critical role of deep feature extraction and sufficient prototype coverage in achieving high performance, with potential for broader applications in pattern recognition.",
      "authors": [
        "Ahmed Farooq"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:26:06+00:00",
          "link": "https://arxiv.org/abs/2507.08766v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08766",
        "HTML": "https://arxiv.org/html/2507.08766v1",
        "PDF": "https://arxiv.org/pdf/2507.08766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a model for MNIST classification, primarily focusing on feature extraction and classification methods, without addressing any aspects of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.18290",
      "abstract": "One of the primary challenges in online learning environments, is to retain learner engagement. Several different instructional strategies are proposed both in online and offline environments to enhance learner engagement. The Concept Attainment Model is one such instructional strategy that focuses on learners acquiring a deeper understanding of a concept rather than just its dictionary definition. This is done by searching and listing the properties used to distinguish examples from non-examples of various concepts. Our work attempts to apply the Concept Attainment Model to build conceptual riddles, to deploy over online learning environments. The approach involves creating factual triples from learning resources, classifying them based on their uniqueness to a concept into `Topic Markers' and `Common', followed by generating riddles based on the Concept Attainment Model's format and capturing all possible solutions to those riddles. The results obtained from the human evaluation of riddles prove encouraging.",
      "authors": [
        "Niharika Sri Parasa",
        "Chaitali Diwan",
        "Srinath Srinivasa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-27T17:28:23+00:00",
          "link": "https://arxiv.org/abs/2310.18290v1",
          "size": "1089kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T07:01:33+00:00",
          "link": "https://arxiv.org/abs/2310.18290v2",
          "size": "450kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T23:11:02+00:00",
          "link": "https://arxiv.org/abs/2310.18290v3",
          "size": "26kb",
          "version": "v3"
        }
      ],
      "title": "Riddle Generation using Learning Resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.18290",
        "HTML": "https://arxiv.org/html/2310.18290v3",
        "PDF": "https://arxiv.org/pdf/2310.18290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a method for riddle generation using learning resources, implying some level of data synthesis for educational content but not specifically targeting LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08799",
      "abstract": "We propose cache steering, a lightweight method for implicit steering of language models via a one-shot intervention applied directly to the key-value cache. To validate its effectiveness, we apply cache steering to induce chain-of-thought reasoning in small language models. Our approach leverages GPT-4o-generated reasoning traces to construct steering vectors that shift model behavior toward more explicit, multi-step reasoning without fine-tuning or prompt modifications. Experimental evaluations on diverse reasoning benchmarks demonstrate that cache steering improves both the qualitative structure of model reasoning and quantitative task performance. Compared to prior activation steering techniques that require continuous interventions, our one-shot cache steering offers substantial advantages in terms of hyperparameter stability, inference-time efficiency, and ease of integration, making it a more robust and practical solution for controlled generation.",
      "authors": [
        "Max Belitsky",
        "Dawid J. Kopiczko",
        "Michael Dorkenwald",
        "M. Jehanzeb Mirza",
        "Cees G. M. Snoek",
        "Yuki M. Asano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.08799v1",
          "size": "177kb",
          "version": "v1"
        }
      ],
      "title": "KV Cache Steering for Inducing Reasoning in Small Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08799",
        "PDF": "https://arxiv.org/pdf/2507.08799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces cache steering for language models, emphasizing reasoning improvement without discussing data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.10011",
      "abstract": "The class-agnostic counting (CAC) task has recently been proposed to solve the problem of counting all objects of an arbitrary class with several exemplars given in the input image. To address this challenging task, existing leading methods all resort to density map regression, which renders them impractical for downstream tasks that require object locations and restricts their ability to well explore the scale information of exemplars for supervision. To address the limitations, we propose a novel localization-based CAC approach, termed Scale-modulated Query and Localization Network (SQLNet). It fully explores the scales of exemplars in both the query and localization stages and achieves effective counting by accurately locating each object and predicting its approximate size. Specifically, during the query stage, rich discriminative representations of the target class are acquired by the Hierarchical Exemplars Collaborative Enhancement (HECE) module from the few exemplars through multi-scale exemplar cooperation with equifrequent size prompt embedding. These representations are then fed into the Exemplars-Unified Query Correlation (EUQC) module to interact with the query features in a unified manner and produce the correlated query tensor. In the localization stage, the Scale-aware Multi-head Localization (SAML) module utilizes the query tensor to predict the confidence, location, and size of each potential object. Moreover, a scale-aware localization loss is introduced, which exploits flexible location associations and exemplar scales for supervision to optimize the model performance. Extensive experiments demonstrate that SQLNet outperforms state-of-the-art methods on popular CAC benchmarks, achieving excellent performance not only in counting accuracy but also in localization and bounding box generation. Our codes will be available at https://github.com/HCPLab-SYSU/SQLNet",
      "authors": [
        "Hefeng Wu",
        "Yandong Chen",
        "Lingbo Liu",
        "Tianshui Chen",
        "Keze Wang",
        "Liang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-16T16:50:56+00:00",
          "link": "https://arxiv.org/abs/2311.10011v1",
          "size": "1498kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:51:21+00:00",
          "link": "https://arxiv.org/abs/2311.10011v2",
          "size": "1850kb",
          "version": "v2"
        }
      ],
      "title": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.10011",
        "HTML": "https://arxiv.org/html/2311.10011v2",
        "PDF": "https://arxiv.org/pdf/2311.10011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a network model for class-agnostic object counting, focusing on localization and scaling techniques, but does not discuss LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/hcplab-sysu/sqlnet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08357",
      "abstract": "In-context learning (ICL) is emerging as a promising technique for achieving universal medical image segmentation, where a variety of objects of interest across imaging modalities can be segmented using a single model. Nevertheless, its performance is highly sensitive to the alignment between the query image and in-context image-mask pairs. In a clinical scenario, the scarcity of annotated medical images makes it challenging to select optimal in-context pairs, and fine-tuning foundation ICL models on contextual data is infeasible due to computational costs and the risk of catastrophic forgetting. To address this challenge, we propose Cycle Context Verification (CCV), a novel framework that enhances ICL-based medical image segmentation by enabling self-verification of predictions and accordingly enhancing contextual alignment. Specifically, CCV employs a cyclic pipeline in which the model initially generates a segmentation mask for the query image. Subsequently, the roles of the query and an in-context pair are swapped, allowing the model to validate its prediction by predicting the mask of the original in-context image. The accuracy of this secondary prediction serves as an implicit measure of the initial query segmentation. A query-specific prompt is introduced to alter the query image and updated to improve the measure, thereby enhancing the alignment between the query and in-context pairs. We evaluated CCV on seven medical image segmentation datasets using two ICL foundation models, demonstrating its superiority over existing methods. Our results highlight CCV's ability to enhance ICL-based segmentation, making it a robust solution for universal medical image segmentation. The code will be available at https://github.com/ShishuaiHu/CCV.",
      "authors": [
        "Shishuai Hu",
        "Zehui Liao",
        "Liangli Zhen",
        "Huazhu Fu",
        "Yong Xia"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:18:01+00:00",
          "link": "https://arxiv.org/abs/2507.08357v1",
          "size": "374kb",
          "version": "v1"
        }
      ],
      "title": "Cycle Context Verification for In-Context Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08357",
        "HTML": "https://arxiv.org/html/2507.08357v1",
        "PDF": "https://arxiv.org/pdf/2507.08357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper pertains to in-context learning for medical image segmentation and does not involve LLM training data processing or dataset improvements for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08507",
      "abstract": "Unmanned aerial vehicle (UAV) swarms utilizing collaborative beamforming (CB) in low-altitude wireless networks (LAWN) demonstrate significant potential for enhanced communication range, energy efficiency, and signal directivity through the formation of virtual antenna arrays (VAA). However, environmental disturbances, particularly wind fields, significantly degrade CB performance by introducing positional errors that disrupt beam patterns, thereby compromising transmission reliability. This paper investigates the critical challenge of maintaining CB performance in UAV-based VAAs operating in LAWN under wind field disturbances. We propose a comprehensive framework that models the impact of three distinct wind conditions (constant, shear, and turbulent) on UAV array performance, and formulate a long-term real-time optimization problem to maximize directivity while minimizing maximum sidelobe levels through adaptive excitation current weight adjustments. To address the inherent complexity of this problem, we propose a novel proximal policy optimization algorithm with long short-term memory (LSTM) structure and adaptive learning rate (PPO-LA), which effectively captures temporal patterns in wind field disturbances and enables real-time adaptation without requiring extensive prior training for specific wind conditions. Our simulation results demonstrate that the proposed PPO-LA algorithm successfully recovers degraded CB performance across various wind scenarios, and thus significantly outperforming benchmark algorithms.",
      "authors": [
        "Geng Sun",
        "Chenbang Liu",
        "Jiahui Li",
        "Guannan Qu",
        "Shuang Liang",
        "Jiacheng Wang",
        "Changyuan Zhao",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:46:09+00:00",
          "link": "https://arxiv.org/abs/2507.08507v1",
          "size": "3544kb",
          "version": "v1"
        }
      ],
      "title": "Recovery of UAV Swarm-enabled Collaborative Beamforming in Low-altitude Wireless Networks under Wind Field Disturbances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08507",
        "HTML": "https://arxiv.org/html/2507.08507v1",
        "PDF": "https://arxiv.org/pdf/2507.08507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on recovering UAV swarm-enabled collaborative beamforming under wind field disturbances, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08234",
      "abstract": "Accurate and efficient maneuver detection is critical for ensuring the safety and predictability of spacecraft trajectories. This paper presents a novel maneuver detection approach based on comparing the confidence levels associated with the orbital state estimation and the observation likelihood. First, a confidence-dominance maneuver indicator (CDMI) is proposed by setting a confidence level for the state estimation and computing the maximum likelihood of the observation and its confidence level. The CDMI then flag a maneuver when the observation's confidence level exceeds that of the state estimation, indicating that the observation is unlikely under the no-maneuver hypothesis while maintaining consistency with the prior state estimation confidence. To efficiently compute the maximum likelihood of the observation and obtain the CDMI, a recursive polynomial optimization method is developed, taking advantage of convex optimization and polynomial approximation. In addition, an integrated CDMI approach is developed to eliminate the need to manually select the state confidence level. The integrated CDMI approach maintains high detection accuracy while simultaneously providing an indication of maneuver likelihood, thereby enhancing robustness and practical applicability. The performance of the proposed CDMI-based maneuver detection approaches is evaluated against an optimal control distance metric and two mixture-based approaches. The simulation results demonstrate that the proposed integrated CDMI approach can achieve up to 99.33\\% detection accuracy, at least 10% higher than the competing methods, while substantially reducing computational costs.",
      "authors": [
        "Xingyu Zhou and Roberto Armellin and Laura Pirovano and Dong Qiao and Xiangyu Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:44:45+00:00",
          "link": "https://arxiv.org/abs/2507.08234v1",
          "size": "15667kb",
          "version": "v1"
        }
      ],
      "title": "Maneuver Detection via a Confidence Dominance Maneuver Indicator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08234",
        "HTML": "https://arxiv.org/html/2507.08234v1",
        "PDF": "https://arxiv.org/pdf/2507.08234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a maneuver detection method for spacecraft trajectories. It does not discuss any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08454",
      "abstract": "We define several canonical problems related to contrastive explanations, each answering a question of the form ''Why P but not Q?''. The problems compute causes for both P and Q, explicitly comparing their differences. We investigate the basic properties of our definitions in the setting of propositional logic. We show, inter alia, that our framework captures a cardinality-minimal version of existing contrastive explanations in the literature. Furthermore, we provide an extensive analysis of the computational complexities of the problems. We also implement the problems for CNF-formulas using answer set programming and present several examples demonstrating how they work in practice.",
      "authors": [
        "Tobias Geibinger and Reijo Jaakkola and Antti Kuusisto and Xinghan Liu and Miikka Vilander"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:55:04+00:00",
          "link": "https://arxiv.org/abs/2507.08454v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Why this and not that? A Logic-based Framework for Contrastive Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08454",
        "HTML": "https://arxiv.org/html/2507.08454v1",
        "PDF": "https://arxiv.org/pdf/2507.08454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses contrastive explanations within propositional logic, involving computation and logic-based frameworks without any relation to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08483",
      "abstract": "A pair of letters $x$ and $y$ are said to alternate in a word $w$ if, after removing all letters except for the copies of $x$ and $y$ from $w$, the resulting word is of the form $xyxy\\ldots$ (of even or odd length) or $yxyx\\ldots$ (of even or odd length). A graph $G = (V (G), E(G))$ is word-representable if there exists a word $w$ over the alphabet $V(G)$, such that any two distinct vertices $x, y \\in V (G)$ are adjacent in $G$ (i.e., $xy \\in E(G)$) if and only if the letters $x$ and $y$ alternate in $w$. A split graph is a graph in which the vertices can be partitioned into a clique and an independent set. Word-representability of split graphs has been studied in a series of papers [2, 5, 7, 9] in the literature. In this work, we give a minimal forbidden induced subgraph characterization of word-representable split graphs with an independent set of size 4, which is an open problem posed by Kitaev and Pyatkin in [9]",
      "authors": [
        "Suchanda Roy and Ramesh Hariharasubramanian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:54:15+00:00",
          "link": "https://arxiv.org/abs/2507.08483v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Word-Representability of Split Graphs with Independent Set of Size 4",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08483",
        "HTML": "https://arxiv.org/html/2507.08483v1",
        "PDF": "https://arxiv.org/pdf/2507.08483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the word-representability of split graphs, which is a problem in combinatorics, and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08772",
      "abstract": "Recent advances in 3D generation have transitioned from multi-view 2D rendering approaches to 3D-native latent diffusion frameworks that exploit geometric priors in ground truth data. Despite progress, three key limitations persist: (1) Single-latent representations fail to capture complex multi-part geometries, causing detail degradation; (2) Holistic latent coding neglects part independence and interrelationships critical for compositional design; (3) Global conditioning mechanisms lack fine-grained controllability. Inspired by human 3D design workflows, we propose CoPart - a part-aware diffusion framework that decomposes 3D objects into contextual part latents for coherent multi-part generation. This paradigm offers three advantages: i) Reduces encoding complexity through part decomposition; ii) Enables explicit part relationship modeling; iii) Supports part-level conditioning. We further develop a mutual guidance strategy to fine-tune pre-trained diffusion models for joint part latent denoising, ensuring both geometric coherence and foundation model priors. To enable large-scale training, we construct Partverse - a novel 3D part dataset derived from Objaverse through automated mesh segmentation and human-verified annotations. Extensive experiments demonstrate CoPart's superior capabilities in part-level editing, articulated object generation, and scene composition with unprecedented controllability.",
      "authors": [
        "Shaocong Dong",
        "Lihe Ding",
        "Xiao Chen",
        "Yaokun Li",
        "Yuxin Wang",
        "Yucheng Wang",
        "Qi Wang",
        "Jaehyeok Kim",
        "Chenjian Gao",
        "Zhanpeng Huang",
        "Zibin Wang",
        "Tianfan Xue",
        "Dan Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:33:18+00:00",
          "link": "https://arxiv.org/abs/2507.08772v1",
          "size": "4402kb",
          "version": "v1"
        }
      ],
      "title": "From One to More: Contextual Part Latents for 3D Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08772",
        "HTML": "https://arxiv.org/html/2507.08772v1",
        "PDF": "https://arxiv.org/pdf/2507.08772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper involves creating a new 3D dataset, Partverse, with automated mesh segmentation and human-verified annotations, which indicates substantive data processing steps in dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.06069",
      "abstract": "In this paper, we investigate the use of multilevel Monte Carlo (MLMC) methods for estimating the expectation of discretized random fields. Specifically, we consider a setting in which the input and output vectors of numerical simulators have inconsistent dimensions across the multilevel hierarchy. This motivates the introduction of grid transfer operators borrowed from multigrid methods. By adapting mathematical tools from multigrid methods, we perform a theoretical spectral analysis of the MLMC estimator of the expectation of discretized random fields, in the specific case of linear, symmetric and circulant simulators. We then propose filtered MLMC (F-MLMC) estimators based on a filtering mechanism similar to the smoothing process of multigrid methods, and we show that the filtering operators improve the estimation of both the small- and large-scale components of the variance, resulting in a reduction of the total variance of the estimator. Next, the conclusions of the spectral analysis are experimentally verified with a one-dimensional illustration. Finally, the proposed F-MLMC estimator is applied to the problem of estimating the discretized variance field of a diffusion-based covariance operator, which amounts to estimating the expectation of a discretized random field. The numerical experiments support the conclusions of the theoretical analysis even with non-linear simulators, and demonstrate the improvements brought by the F-MLMC estimator compared to both a crude MC and an unfiltered MLMC estimator.",
      "authors": [
        "J\\'er\\'emy Briant (1 and 3)",
        "Paul Mycek (2",
        "3 and 4)",
        "Mayeul Destouches (5)",
        "Olivier Goux (2 and 3)",
        "Serge Gratton (1 and 6)",
        "Selime G\\\"urol (2 and 3)",
        "Ehouarn Simon (1)",
        "Anthony T. Weaver (2 and 3) ((1) IRIT",
        "Univ Toulouse",
        "CNRS",
        "Toulouse INP",
        "(2) Cerfacs",
        "(3) CECI",
        "Univ Toulouse",
        "Cerfacs",
        "CNRS",
        "IRD",
        "(4) Concace",
        "Airbus CR&T",
        "Cerfacs",
        "Inria",
        "(5) CNRM",
        "Univ Toulouse",
        "M\\'et\\'eo-France",
        "CNRS",
        "(6) ANITI)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-10T14:04:43+00:00",
          "link": "https://arxiv.org/abs/2311.06069v1",
          "size": "4393kb",
          "version": "v1"
        },
        {
          "date": "2024-12-19T06:54:12+00:00",
          "link": "https://arxiv.org/abs/2311.06069v2",
          "size": "4338kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T14:42:56+00:00",
          "link": "https://arxiv.org/abs/2311.06069v3",
          "size": "4366kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T07:36:44+00:00",
          "link": "https://arxiv.org/abs/2311.06069v4",
          "size": "4366kb",
          "version": "v4"
        }
      ],
      "title": "A filtered multilevel Monte Carlo method for estimating the expectation of cell-centered discretized random fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.06069",
        "HTML": "https://arxiv.org/html/2311.06069v4",
        "PDF": "https://arxiv.org/pdf/2311.06069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a filtered multilevel Monte Carlo method for random field estimation and does not make any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08441",
      "abstract": "Leveraging the powerful representations of pre-trained vision foundation models -- traditionally used for visual comprehension -- we explore a novel direction: building an image tokenizer directly atop such models, a largely underexplored area. Specifically, we employ a frozen vision foundation model as the encoder of our tokenizer. To enhance its effectiveness, we introduce two key components: (1) a region-adaptive quantization framework that reduces redundancy in the pre-trained features on regular 2D grids, and (2) a semantic reconstruction objective that aligns the tokenizer's outputs with the foundation model's representations to preserve semantic fidelity. Based on these designs, our proposed image tokenizer, VFMTok, achieves substantial improvements in image reconstruction and generation quality, while also enhancing token efficiency. It further boosts autoregressive (AR) generation -- achieving a gFID of 2.07 on ImageNet benchmarks, while accelerating model convergence by three times, and enabling high-fidelity class-conditional synthesis without the need for classifier-free guidance (CFG). The code will be released publicly to benefit the community.",
      "authors": [
        "Anlin Zheng",
        "Xin Wen",
        "Xuanyang Zhang",
        "Chuofan Ma",
        "Tiancai Wang",
        "Gang Yu",
        "Xiangyu Zhang and Xiaojuan Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:32:45+00:00",
          "link": "https://arxiv.org/abs/2507.08441v1",
          "size": "3108kb",
          "version": "v1"
        }
      ],
      "title": "Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08441",
        "HTML": "https://arxiv.org/html/2507.08441v1",
        "PDF": "https://arxiv.org/pdf/2507.08441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses on vision foundation models as visual tokenizers for image generation, it does involve some preprocessing to enhance the tokenizer's effectiveness, which relates to data processing in a limited sense."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09686",
      "abstract": "Regressing a function $F$ on $\\mathbb{R}^d$ without the statistical and computational curse of dimensionality requires special statistical models, for example that impose geometric assumptions on the distribution of the data (e.g., that its support is low-dimensional), or strong smoothness assumptions on $F$, or a special structure $F$. Among the latter, compositional models $F=f\\circ g$ with $g$ mapping to $\\mathbb{R}^r$ with $r\\ll d$ include classical single- and multi-index models, as well as neural networks. While the case where $g$ is linear is well-understood, less is known when $g$ is nonlinear, and in particular for which $g$'s the curse of dimensionality in estimating $F$, or both $f$ and $g$, may be circumvented. Here we consider a model $F(X):=f(\\Pi_\\gamma X)$ where $\\Pi_\\gamma:\\mathbb{R}^d\\to[0,\\textrm{len}_\\gamma]$ is the closest-point projection onto the parameter of a regular curve $\\gamma:[0, \\textrm{len}_\\gamma]\\to\\mathbb{R}^d$, and $f:[0,\\textrm{len}_\\gamma]\\to \\mathbb{R}^1$. The input data $X$ is not low-dimensional: it can be as far from $\\gamma$ as the condition that $\\Pi_\\gamma(X)$ is well-defined allows. The distribution $X$, the curve $\\gamma$ and the function $f$ are all unknown. This model is a natural nonlinear generalization of the single-index model, corresponding to $\\gamma$ being a line. We propose a nonparametric estimator, based on conditional regression, that under suitable assumptions, the strongest of which being that $f$ is coarsely monotone, achieves, up to log factors, the $\\textit{one-dimensional}$ optimal min-max rate for non-parametric regression, up to the level of noise in the observations, and be constructed in time $\\mathcal{O}(d^2 n\\log n)$. All the constants in the learning bounds, in the minimal number of samples required for our bounds to hold, and in the computational complexity are at most low-order polynomials in $d$.",
      "authors": [
        "Yantao Wu",
        "Mauro Maggioni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T18:53:51+00:00",
          "link": "https://arxiv.org/abs/2411.09686v1",
          "size": "2626kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:03:51+00:00",
          "link": "https://arxiv.org/abs/2411.09686v2",
          "size": "2631kb",
          "version": "v2"
        }
      ],
      "title": "Conditional regression for the Nonlinear Single-Variable Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09686",
        "HTML": "https://arxiv.org/html/2411.09686v2",
        "PDF": "https://arxiv.org/pdf/2411.09686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with conditional regression for nonlinear models, focusing on statistical modeling rather than processing or preparing training data for LLMs."
      },
      "tasks": [
        "model",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20287",
      "abstract": "Instruction-based video editing allows effective and interactive editing of videos using only instructions without extra inputs such as masks or attributes. However, collecting high-quality training triplets (source video, edited video, instruction) is a challenging task. Existing datasets mostly consist of low-resolution, short duration, and limited amount of source videos with unsatisfactory editing quality, limiting the performance of trained editing models. In this work, we present a high-quality Instruction-based Video Editing dataset with 1M triplets, namely InsViE-1M. We first curate high-resolution and high-quality source videos and images, then design an effective editing-filtering pipeline to construct high-quality editing triplets for model training. For a source video, we generate multiple edited samples of its first frame with different intensities of classifier-free guidance, which are automatically filtered by GPT-4o with carefully crafted guidelines. The edited first frame is propagated to subsequent frames to produce the edited video, followed by another round of filtering for frame quality and motion evaluation. We also generate and filter a variety of video editing triplets from high-quality images. With the InsViE-1M dataset, we propose a multi-stage learning strategy to train our InsViE model, progressively enhancing its instruction following and editing ability. Extensive experiments demonstrate the advantages of our InsViE-1M dataset and the trained model over state-of-the-art works. Codes are available at \\href{https://github.com/langmanbusi/InsViE}{InsViE}.",
      "authors": [
        "Yuhui Wu",
        "Liyi Chen",
        "Ruibin Li",
        "Shihao Wang",
        "Chenxi Xie",
        "Lei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T07:30:58+00:00",
          "link": "https://arxiv.org/abs/2503.20287v1",
          "size": "45889kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:39:34+00:00",
          "link": "https://arxiv.org/abs/2503.20287v2",
          "size": "45891kb",
          "version": "v2"
        }
      ],
      "title": "InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20287",
        "HTML": "https://arxiv.org/html/2503.20287v2",
        "PDF": "https://arxiv.org/pdf/2503.20287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of the InsViE-1M dataset with detailed processing steps, including a pipeline for curating, editing, and filtering high-quality video triplets, which is a direct contribution to data quality enhancement for model training."
      },
      "datasets": [
        {
          "dataset_name": "wyh6666/InsViE",
          "downloads": "88",
          "likes": "0",
          "link": "https://huggingface.co/datasets/wyh6666/InsViE"
        }
      ],
      "tasks": [
        "Instruction Following",
        "Video Editing"
      ],
      "repo_urls": [
        "https://github.com/langmanbusi/insvie"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08348",
      "abstract": "Censor-Hillel, Cohen, Gelles, and Sela (PODC 2022 \\& Distributed Computing 2023) studied fully-defective asynchronous networks, where communication channels may suffer an extreme form of alteration errors, rendering messages completely corrupted. The model is equivalent to content-oblivious computation, where nodes communicate solely via pulses. They showed that if the network is 2-edge-connected, then any algorithm for a noiseless setting can be simulated in the fully-defective setting; otherwise, no non-trivial computation is possible in the fully-defective setting. However, their simulation requires a predesignated leader, which they conjectured to be necessary for any non-trivial content-oblivious task.\n  Recently, Frei, Gelles, Ghazy, and Nolin (DISC 2024) refuted this conjecture for the special case of oriented ring topology. They designed two asynchronous content-oblivious leader election algorithms with message complexity $O(n \\cdot \\mathsf{ID}_{\\max})$, where $n$ is the number of nodes and $\\mathsf{ID}_{\\max}$ is the maximum $\\mathsf{ID}$. The first algorithm stabilizes in unoriented rings without termination detection. The second algorithm quiescently terminates in oriented rings, thus enabling the execution of the simulation algorithm after leader election.\n  In this work, we present an asynchronous content-oblivious leader election algorithm that quiescently terminates in any 2-edge connected network with message complexity $O(m \\cdot N \\cdot \\mathsf{ID}_{\\min})$, where $m$ is the number of edges, $N$ is a known upper bound on the number of nodes, and $\\mathsf{ID}_{\\min}$ is the smallest $\\mathsf{ID}$. Combined with the previous simulation result, our finding implies that any algorithm from the noiseless setting can be simulated in the fully-defective setting without assuming a preselected leader, entirely refuting the original conjecture.",
      "authors": [
        "Yi-Jun Chang",
        "Lyuting Chen",
        "Haoran Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:48:21+00:00",
          "link": "https://arxiv.org/abs/2507.08348v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Content-Oblivious Leader Election in 2-Edge-Connected Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08348",
        "HTML": "https://arxiv.org/html/2507.08348v1",
        "PDF": "https://arxiv.org/pdf/2507.08348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on leader election algorithms in 2-edge-connected networks and does not discuss processing of LLM training data or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08508",
      "abstract": "Federated Learning (FL) is a distributed machine learning paradigm which coordinates multiple clients to collaboratively train a global model via a central server. Sequential Federated Learning (SFL) is a newly-emerging FL training framework where the global model is trained in a sequential manner across clients. Since SFL can provide strong convergence guarantees under data heterogeneity, it has attracted significant research attention in recent years. However, experiments show that SFL suffers from severe catastrophic forgetting in heterogeneous environments, meaning that the model tends to forget knowledge learned from previous clients. To address this issue, we propose an SFL framework with discrepancy-aware multi-teacher knowledge distillation, called SFedKD, which selects multiple models from the previous round to guide the current round of training. In SFedKD, we extend the single-teacher Decoupled Knowledge Distillation approach to our multi-teacher setting and assign distinct weights to teachers' target-class and non-target-class knowledge based on the class distributional discrepancy between teacher and student data. Through this fine-grained weighting strategy, SFedKD can enhance model training efficacy while mitigating catastrophic forgetting. Additionally, to prevent knowledge dilution, we eliminate redundant teachers for the knowledge distillation and formalize it as a variant of the maximum coverage problem. Based on the greedy strategy, we design a complementary-based teacher selection mechanism to ensure that the selected teachers achieve comprehensive knowledge space coverage while reducing communication and computational costs. Extensive experiments show that SFedKD effectively overcomes catastrophic forgetting in SFL and outperforms state-of-the-art FL methods.",
      "authors": [
        "Haotian Xu",
        "Jinrui Zhou",
        "Xichong Zhang",
        "Mingjun Xiao",
        "He Sun",
        "Yin Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:48:11+00:00",
          "link": "https://arxiv.org/abs/2507.08508v1",
          "size": "6743kb",
          "version": "v1"
        }
      ],
      "title": "SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08508",
        "HTML": "https://arxiv.org/html/2507.08508v1",
        "PDF": "https://arxiv.org/pdf/2507.08508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is about federated learning, specifically knowledge distillation to prevent catastrophic forgetting during training, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08702",
      "abstract": "We present ONION, a multi-layered framework for participatory Entity-Relationship (ER) modeling that integrates insights from design justice, participatory AI, and conceptual modeling. ONION introduces a five-stage methodology: Observe, Nurture, Integrate, Optimize, Normalize. It supports progressive abstraction from unstructured stakeholder input to structured ER diagrams.\n  Our approach aims to reduce designer bias, promote inclusive participation, and increase transparency through the modeling process. We evaluate ONION through real-world workshops focused on sociotechnical systems in Ukraine, highlighting how diverse stakeholder engagement leads to richer data models and deeper mutual understanding. Early results demonstrate ONION's potential to host diversity in early-stage data modeling. We conclude with lessons learned, limitations and challenges involved in scaling and refining the framework for broader adoption.",
      "authors": [
        "Viktoriia Makovska",
        "George Fletcher",
        "and Julia Stoyanovich"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T15:53:44+00:00",
          "link": "https://arxiv.org/abs/2507.08702v1",
          "size": "1341kb",
          "version": "v1"
        }
      ],
      "title": "ONION: A Multi-Layered Framework for Participatory ER Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08702",
        "HTML": "https://arxiv.org/html/2507.08702v1",
        "PDF": "https://arxiv.org/pdf/2507.08702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces ONION, a participatory framework for ER modeling, which focuses on reducing bias and enhancing stakeholder engagement in data modeling, irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.06737",
      "abstract": "Reinforcement Learning (RL) is a promising approach for achieving autonomous driving due to robust decision-making capabilities. RL learns a driving policy through trial and error in traffic scenarios, guided by a reward function that combines the driving objectives. The design of such reward function has received insufficient attention, yielding ill-defined rewards with various pitfalls. Safety, in particular, has long been regarded only as a penalty for collisions. This leaves the risks associated with actions leading up to a collision unaddressed, limiting the applicability of RL in real-world scenarios. To address these shortcomings, our work focuses on enhancing the reward formulation by defining a set of driving objectives and structuring them hierarchically. Furthermore, we discuss the formulation of these objectives in a normalized manner to transparently determine their contribution to the overall reward. Additionally, we introduce a novel risk-aware objective for various driving interactions based on a two-dimensional ellipsoid function and an extension of Responsibility-Sensitive Safety (RSS) concepts. We evaluate the efficacy of our proposed reward in unsignalized intersection scenarios with varying traffic densities. The approach decreases collision rates by 21\\% on average compared to baseline rewards and consistently surpasses them in route progress and cumulative reward, demonstrating its capability to promote safer driving behaviors while maintaining high-performance levels.",
      "authors": [
        "Ahmed Abouelazm",
        "Jonas Michel",
        "Helen Gremmelmaier",
        "Tim Joseph",
        "Philip Sch\\\"orner",
        "and J. Marius Z\\\"ollner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-10T19:05:03+00:00",
          "link": "https://arxiv.org/abs/2505.06737v1",
          "size": "1777kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:28:18+00:00",
          "link": "https://arxiv.org/abs/2505.06737v2",
          "size": "1778kb",
          "version": "v2"
        }
      ],
      "title": "Balancing Progress and Safety: A Novel Risk-Aware Objective for RL in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06737",
        "HTML": "https://arxiv.org/html/2505.06737v2",
        "PDF": "https://arxiv.org/pdf/2505.06737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with reinforcement learning objectives for autonomous driving, focusing on the formulation of reward functions rather than LLM data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12430",
      "abstract": "Multimodal Large Language Models (MLLMs) have enabled transformative advancements across diverse applications but remain susceptible to safety threats, especially jailbreak attacks that induce harmful outputs. To systematically evaluate and improve their safety, we organized the Adversarial Testing & Large-model Alignment Safety Grand Challenge (ATLAS) 2025}. This technical report presents findings from the competition, which involved 86 teams testing MLLM vulnerabilities via adversarial image-text attacks in two phases: white-box and black-box evaluations. The competition results highlight ongoing challenges in securing MLLMs and provide valuable guidance for developing stronger defense mechanisms. The challenge establishes new benchmarks for MLLM safety evaluation and lays groundwork for advancing safer multimodal AI systems. The code and data for this challenge are openly available at https://github.com/NY1024/ATLAS_Challenge_2025.",
      "authors": [
        "Zonghao Ying",
        "Siyang Wu",
        "Run Hao",
        "Peng Ying",
        "Shixuan Sun",
        "Pengyu Chen",
        "Junze Chen",
        "Hao Du",
        "Kaiwen Shen",
        "Shangkun Wu",
        "Jiwei Wei",
        "Shiyuan He",
        "Yang Yang",
        "Xiaohai Xu",
        "Ke Ma",
        "Qianqian Xu",
        "Qingming Huang",
        "Shi Lin",
        "Xun Wang",
        "Changting Lin",
        "Meng Han",
        "Yilei Jiang",
        "Siqi Lai",
        "Yaozhi Zheng",
        "Yifei Song",
        "Xiangyu Yue",
        "Zonglei Jing",
        "Tianyuan Zhang",
        "Zhilei Zhu",
        "Aishan Liu",
        "Jiakai Wang",
        "Siyuan Liang",
        "Xianglong Kong",
        "Hainan Li",
        "Junjie Mu",
        "Haotong Qin",
        "Yue Yu",
        "Lei Chen",
        "Felix Juefei-Xu",
        "Qing Guo",
        "Xinyun Chen",
        "Yew Soon Ong",
        "Xianglong Liu",
        "Dawn Song",
        "Alan Yuille",
        "Philip Torr",
        "Dacheng Tao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T10:03:17+00:00",
          "link": "https://arxiv.org/abs/2506.12430v1",
          "size": "546kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:01:54+00:00",
          "link": "https://arxiv.org/abs/2506.12430v2",
          "size": "549kb",
          "version": "v2"
        }
      ],
      "title": "Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12430",
        "HTML": "https://arxiv.org/html/2506.12430v2",
        "PDF": "https://arxiv.org/pdf/2506.12430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on safety testing for multimodal LLMs and adversarial testing methods without addressing LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/ny1024/atlas_challenge_2025"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08349",
      "abstract": "Accurate extrinsic calibration between multiple LiDAR sensors and a GNSS-aided inertial navigation system (GINS) is essential for achieving reliable sensor fusion in intelligent mining environments. Such calibration enables vehicle-road collaboration by aligning perception data from vehicle-mounted sensors to a unified global reference frame. However, existing methods often depend on artificial targets, overlapping fields of view, or precise trajectory estimation, which are assumptions that may not hold in practice. Moreover, the planar motion of mining vehicles leads to observability issues that degrade calibration performance. This paper presents a targetless extrinsic calibration method that aligns multiple onboard LiDAR sensors to the GINS coordinate system without requiring overlapping sensor views or external targets. The proposed approach introduces an observation model based on the known installation height of the GINS unit to constrain unobservable calibration parameters under planar motion. A joint optimization framework is developed to refine both the extrinsic parameters and GINS trajectory by integrating multiple constraints derived from geometric correspondences and motion consistency. The proposed method is applicable to heterogeneous LiDAR configurations, including both mechanical and solid-state sensors. Extensive experiments on simulated and real-world datasets demonstrate the accuracy, robustness, and practical applicability of the approach under diverse sensor setups.",
      "authors": [
        "Junhui Wang",
        "Yan Qiao",
        "Chao Gao",
        "and Naiqi Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:48:53+00:00",
          "link": "https://arxiv.org/abs/2507.08349v1",
          "size": "4285kb",
          "version": "v1"
        }
      ],
      "title": "Joint Optimization-based Targetless Extrinsic Calibration for Multiple LiDARs and GNSS-Aided INS of Ground Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08349",
        "HTML": "https://arxiv.org/html/2507.08349v1",
        "PDF": "https://arxiv.org/pdf/2507.08349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses calibration methods for LiDAR sensors and GNSS systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08356",
      "abstract": "In analogy to flexible bipyramids, also known as Bricard octahedra, we study flexible couplings of two Bennett mechanisms. The resulting flexible bi-Bennett structures can be used as building blocks of flexible tubes with quadrilateral cross-section that possess skew faces. We present three 4-dimensional families of flexible arranged Bennett tubes and discuss some of their properties as well as their relation to flexible bipyramids and biprisms, respectively.",
      "authors": [
        "Georg Nawratil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:15:28+00:00",
          "link": "https://arxiv.org/abs/2507.08356v1",
          "size": "32467kb",
          "version": "v1"
        }
      ],
      "title": "Flexible arrangement of two Bennett tubes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08356",
        "HTML": "https://arxiv.org/html/2507.08356v1",
        "PDF": "https://arxiv.org/pdf/2507.08356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on flexible arrangements of Bennett tubes, which is related to mechanical structures and geometry, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.08708",
      "abstract": "Over the past few years, ubiquitous, or pervasive computing has gained popularity as the primary approach for a wide range of applications, including enterprise-grade systems, consumer applications, and gaming systems. Ubiquitous computing refers to the integration of computing technologies into everyday objects and environments, creating a network of interconnected devices that can communicate with each other and with humans. By using ubiquitous computing technologies, communities can become more connected and efficient, with members able to communicate and collaborate more easily. This enabled interconnectedness and collaboration can lead to a more successful and sustainable community. The spread of ubiquitous computing, however, has emphasized the importance of automated learning and smart applications in general. Even though there have been significant strides in Artificial Intelligence and Deep Learning, large scale adoption has been hesitant due to mounting pressure on expensive and highly complex cloud numerical-compute infrastructures. Adopting, and even developing, practical machine learning systems can come with prohibitive costs, not only in terms of complex infrastructures but also of solid expertise in Data Science and Machine Learning. In this paper we present an innovative approach for low-code development and deployment of end-to-end AI cooperative application pipelines. We address infrastructure allocation, costs, and secure job distribution in a fully decentralized global cooperative community based on tokenized economics.",
      "authors": [
        "Cristian Bleotiu",
        "Stefan Saraev",
        "Bogdan Hobeanu",
        "Andrei Ionut Damian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-14T19:20:43+00:00",
          "link": "https://arxiv.org/abs/2306.08708v1",
          "size": "849kb",
          "version": "v1"
        },
        {
          "date": "2024-04-15T17:24:56+00:00",
          "link": "https://arxiv.org/abs/2306.08708v2",
          "size": "849kb",
          "version": "v2"
        },
        {
          "date": "2024-07-31T13:31:40+00:00",
          "link": "https://arxiv.org/abs/2306.08708v3",
          "size": "870kb",
          "version": "v3"
        },
        {
          "date": "2024-09-07T09:17:33+00:00",
          "link": "https://arxiv.org/abs/2306.08708v4",
          "size": "870kb",
          "version": "v4"
        },
        {
          "date": "2025-02-08T07:03:35+00:00",
          "link": "https://arxiv.org/abs/2306.08708v5",
          "size": "868kb",
          "version": "v5"
        },
        {
          "date": "2025-07-11T11:45:52+00:00",
          "link": "https://arxiv.org/abs/2306.08708v6",
          "size": "376kb",
          "version": "v6"
        }
      ],
      "title": "Naeural AI OS -- Decentralized ubiquitous computing MLOps execution engine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.08708",
        "HTML": "https://arxiv.org/html/2306.08708",
        "PDF": "https://arxiv.org/pdf/2306.08708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a decentralized computing engine for MLOps, focusing on low-code AI pipelines and infrastructure, without addressing LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.07735",
      "abstract": "Large Language Models are versatile, general-purpose tools with a wide range of applications. Recently, the advent of \"reasoning models\" has led to substantial improvements in their abilities in advanced problem-solving domains such as mathematics and software engineering. In this work, we assessed the ability of reasoning models to perform chemistry tasks directly, without any assistance from external tools. We created a novel benchmark, called ChemIQ, consisting of 816 questions assessing core concepts in organic chemistry, focused on molecular comprehension and chemical reasoning. Unlike previous benchmarks, which primarily use multiple choice formats, our approach requires models to construct short-answer responses, more closely reflecting real-world applications. The reasoning models, OpenAI's o3-mini, Google's Gemini Pro 2.5, and DeepSeek R1, answered 50%-57% of questions correctly in the highest reasoning modes, with higher reasoning levels significantly increasing performance on all tasks. These models substantially outperformed the non-reasoning models which achieved only 3%-7% accuracy. We found that Large Language Models can now convert SMILES strings to IUPAC names, a task earlier models were unable to perform. Additionally, we show that the latest reasoning models can elucidate structures from 1D and 2D 1H and 13C NMR data, with Gemini Pro 2.5 correctly generating SMILES strings for around 90% of molecules containing up to 10 heavy atoms, and in one case solving a structure comprising 25 heavy atoms. For each task, we found evidence that the reasoning process mirrors that of a human chemist. Our results demonstrate that the latest reasoning models can, in some cases, perform advanced chemical reasoning.",
      "authors": [
        "Nicholas T. Runcie",
        "Charlotte M. Deane",
        "Fergus Imrie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T16:44:38+00:00",
          "link": "https://arxiv.org/abs/2505.07735v1",
          "size": "1191kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:25:11+00:00",
          "link": "https://arxiv.org/abs/2505.07735v2",
          "size": "699kb",
          "version": "v2"
        }
      ],
      "title": "Assessing the Chemical Intelligence of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07735",
        "HTML": "https://arxiv.org/html/2505.07735v2",
        "PDF": "https://arxiv.org/pdf/2505.07735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper assesses the chemical reasoning capabilities of existing LLMs using a benchmark but does not involve processing or creating LLM training data."
      },
      "tasks": [
        "Multiple-choice"
      ],
      "repo_urls": [
        "https://github.com/oxpig/ChemIQ"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08022",
      "abstract": "This report presents the CuriosAI team's submission to the EgoExo4D Proficiency Estimation Challenge at CVPR 2025. We propose two methods for multi-view skill assessment: (1) a multi-task learning framework using Sapiens-2B that jointly predicts proficiency and scenario labels (43.6 % accuracy), and (2) a two-stage pipeline combining zero-shot scenario recognition with view-specific VideoMAE classifiers (47.8 % accuracy). The superior performance of the two-stage approach demonstrates the effectiveness of scenario-conditioned modeling for proficiency estimation.",
      "authors": [
        "Hayato Tanoue",
        "Hiroki Nishihara",
        "Yuma Suzuki",
        "Takayuki Hori",
        "Hiroki Takushima",
        "Aiswariya Manojkumar",
        "Yuki Shibata",
        "Mitsuru Takeda",
        "Fumika Beppu",
        "Zhao Hengwei",
        "Yuto Kanda",
        "Daichi Yamaga"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:33:02+00:00",
          "link": "https://arxiv.org/abs/2507.08022v1",
          "size": "216kb",
          "version": "v1"
        }
      ],
      "title": "CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08022",
        "HTML": "https://arxiv.org/html/2507.08022v1",
        "PDF": "https://arxiv.org/pdf/2507.08022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for proficiency estimation in a challenge using multi-task learning and pipelines but does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08529",
      "abstract": "Despite advances from medical large language models in healthcare, rare-disease diagnosis remains hampered by insufficient knowledge-representation depth, limited concept understanding, and constrained clinical reasoning. We propose a framework that couples multi-granularity sparse activation of medical concepts with a hierarchical knowledge graph. Four complementary matching algorithms, diversity control, and a five-level fallback strategy enable precise concept activation, while a three-layer knowledge graph (taxonomy, clinical features, instances) provides structured, up-to-date context. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09, ROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89 approaching the 0.90 clinical threshold. Expert evaluation confirms improvements in information quality, reasoning, and professional expression, suggesting our approach shortens the \"diagnostic odyssey\" for rare-disease patients.",
      "authors": [
        "Mingda Zhang",
        "Na Zhao",
        "Jianglong Qin",
        "Guoyu Ye",
        "Ruixiang Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:26:19+00:00",
          "link": "https://arxiv.org/abs/2507.08529v1",
          "size": "1312kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08529",
        "HTML": "https://arxiv.org/html/2507.08529v1",
        "PDF": "https://arxiv.org/pdf/2507.08529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for rare disease diagnosis focusing on concept activation and knowledge graph fusion but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.16138",
      "abstract": "Conformal Autoencoders are a neural network architecture that imposes orthogonality conditions between the gradients of latent variables to obtain disentangled representations of data. In this work we show that orthogonality relations within the latent layer of the network can be leveraged to infer the intrinsic dimensionality of nonlinear manifold data sets (locally characterized by the dimension of their tangent space), while simultaneously computing encoding and decoding (embedding) maps. We outline the relevant theory relying on differential geometry, and describe the corresponding gradient-descent optimization algorithm. The method is applied to several data sets and we highlight its applicability, advantages, and shortcomings. In addition, we demonstrate that the same computational technology can be used to build coordinate invariance to local group actions when defined only on a (reduced) submanifold of the embedding space.",
      "authors": [
        "George A. Kevrekidis",
        "Zan Ahmad",
        "Mauro Maggioni",
        "Soledad Villar",
        "Yannis G. Kevrekidis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Differential Geometry (math.DG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T20:56:35+00:00",
          "link": "https://arxiv.org/abs/2408.16138v1",
          "size": "30206kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:54:35+00:00",
          "link": "https://arxiv.org/abs/2408.16138v2",
          "size": "5830kb",
          "version": "v2"
        }
      ],
      "title": "Thinner Latent Spaces: Detecting Dimension and Imposing Invariance with Conformal Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16138",
        "HTML": "https://arxiv.org/html/2408.16138v2",
        "PDF": "https://arxiv.org/pdf/2408.16138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Conformal Autoencoders for data representation and dimensionality reduction, with no focus on processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06892",
      "abstract": "Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.",
      "authors": [
        "Jing Liang",
        "Hongyao Tang",
        "Yi Ma",
        "Jinyi Liu",
        "Yan Zheng",
        "Shuyue Hu",
        "Lei Bai",
        "Jianye Hao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.06892v1",
          "size": "519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:42:04+00:00",
          "link": "https://arxiv.org/abs/2507.06892v2",
          "size": "479kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T10:32:34+00:00",
          "link": "https://arxiv.org/abs/2507.06892v3",
          "size": "492kb",
          "version": "v3"
        }
      ],
      "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06892",
        "HTML": "https://arxiv.org/html/2507.06892v3",
        "PDF": "https://arxiv.org/pdf/2507.06892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses efficient off-policy reinforcement learning for LLMs and doesn't focus on training data processing or any methods related to data collection or engineering for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08026",
      "abstract": "This paper outlines the development of a Canada-wide morphology map classifying regions into residential, urban low-rise, and urban high-rise environments, following the ITU-R P.1411-12 propagation model guidelines. To address the qualitative nature of the environment-type descriptors found in the Recommendation, a machine learning approach is employed to automate the classification process. Extensive experimentation optimized classification accuracy, resulting in a Canada-wide morphology map that ensures more accurate path loss estimations for outdoor short-range propagation at frequencies ranging from 300 MHz to 100 GHz.",
      "authors": [
        "Jennifer P. T. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:51:00+00:00",
          "link": "https://arxiv.org/abs/2507.08026v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "Development of a Canada-Wide Morphology Map for the ITU-R P. 1411 Propagation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08026",
        "PDF": "https://arxiv.org/pdf/2507.08026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper on developing a morphology map using machine learning does not make any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18964",
      "abstract": "We propose a linear algebraic framework for performing density estimation. It consists of three simple steps: convolving the empirical distribution with certain smoothing kernels to remove the exponentially large variance; compressing the empirical distribution after convolution as a tensor train, with efficient tensor decomposition algorithms; and finally, applying a deconvolution step to recover the estimated density from such tensor-train representation. Numerical results demonstrate the high accuracy and efficiency of the proposed methods.",
      "authors": [
        "Yifan Peng",
        "Siyao Yang",
        "Yuehaw Khoo",
        "Daren Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-25T18:45:04+00:00",
          "link": "https://arxiv.org/abs/2412.18964v1",
          "size": "1406kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T08:38:33+00:00",
          "link": "https://arxiv.org/abs/2412.18964v2",
          "size": "3053kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T04:10:33+00:00",
          "link": "https://arxiv.org/abs/2412.18964v3",
          "size": "1877kb",
          "version": "v3"
        }
      ],
      "title": "Tensor Density Estimator by Convolution-Deconvolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18964",
        "HTML": "https://arxiv.org/html/2412.18964v3",
        "PDF": "https://arxiv.org/pdf/2412.18964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for density estimation using convolution-deconvolution and tensor decomposition, which is unrelated to LLM training data processing, focusing instead on a mathematical framework for data manipulation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07620",
      "abstract": "Reliable Uncertainty Quantification (UQ) and failure prediction remain open challenges for Vision-Language Models (VLMs). We introduce ViLU, a new Vision-Language Uncertainty quantification framework that contextualizes uncertainty estimates by leveraging all task-relevant textual representations. ViLU constructs an uncertainty-aware multi-modal representation by integrating the visual embedding, the predicted textual embedding, and an image-conditioned textual representation via cross-attention. Unlike traditional UQ methods based on loss prediction, ViLU trains an uncertainty predictor as a binary classifier to distinguish correct from incorrect predictions using a weighted binary cross-entropy loss, making it loss-agnostic. In particular, our proposed approach is well-suited for post-hoc settings, where only vision and text embeddings are available without direct access to the model itself. Extensive experiments on diverse datasets show the significant gains of our method compared to state-of-the-art failure prediction methods. We apply our method to standard classification datasets, such as ImageNet-1k, as well as large-scale image-caption datasets like CC12M and LAION-400M. Ablation studies highlight the critical role of our architecture and training in achieving effective uncertainty quantification. Our code is publicly available and can be found here: https://github.com/ykrmm/ViLU.",
      "authors": [
        "Marc Lafon",
        "Yannis Karmim",
        "Julio Silva-Rodr\\'iguez",
        "Paul Couairon",
        "Cl\\'ement Rambour",
        "Rapha\\\"el Fournier-Sniehotta",
        "Ismail Ben Ayed",
        "Jose Dolz",
        "Nicolas Thome"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:41:13+00:00",
          "link": "https://arxiv.org/abs/2507.07620v1",
          "size": "16787kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:41:56+00:00",
          "link": "https://arxiv.org/abs/2507.07620v2",
          "size": "16788kb",
          "version": "v2"
        }
      ],
      "title": "ViLU: Learning Vision-Language Uncertainties for Failure Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07620",
        "HTML": "https://arxiv.org/html/2507.07620v2",
        "PDF": "https://arxiv.org/pdf/2507.07620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for uncertainty quantification in Vision-Language Models, focusing on representation integration and failure prediction, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08205",
      "abstract": "In medical image segmentation, convolutional neural networks (CNNs) and transformers are dominant. For CNNs, given the local receptive fields of convolutional layers, long-range spatial correlations are captured through consecutive convolutions and pooling. However, as the computational cost and memory footprint can be prohibitively large, 3D models can only afford fewer layers than 2D models with reduced receptive fields and abstract levels. For transformers, although long-range correlations can be captured by multi-head attention, its quadratic complexity with respect to input size is computationally demanding. Therefore, either model may require input size reduction to allow more filters and layers for better segmentation. Nevertheless, given their discrete nature, models trained with patch-wise training or image downsampling may produce suboptimal results when applied on higher resolutions. To address this issue, here we propose the resolution-robust HNOSeg-XS architecture. We model image segmentation by learnable partial differential equations through the Fourier neural operator which has the zero-shot super-resolution property. By replacing the Fourier transform by the Hartley transform and reformulating the problem in the frequency domain, we created the HNOSeg-XS model, which is resolution robust, fast, memory efficient, and extremely parameter efficient. When tested on the BraTS'23, KiTS'23, and MVSeg'23 datasets with a Tesla V100 GPU, HNOSeg-XS showed its superior resolution robustness with fewer than 34.7k model parameters. It also achieved the overall best inference time (< 0.24 s) and memory efficiency (< 1.8 GiB) compared to the tested CNN and transformer models.",
      "authors": [
        "Ken C. L. Wong",
        "Hongzhi Wang",
        "and Tanveer Syeda-Mahmood"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:33:19+00:00",
          "link": "https://arxiv.org/abs/2507.08205v1",
          "size": "3837kb",
          "version": "v1"
        }
      ],
      "title": "HNOSeg-XS: Extremely Small Hartley Neural Operator for Efficient and Resolution-Robust 3D Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08205",
        "PDF": "https://arxiv.org/pdf/2507.08205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an architecture for 3D image segmentation using neural operators, without any reference to training-data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08893",
      "abstract": "An ideal model evaluation should achieve two goals: identifying where the model fails and providing actionable improvement guidance. Toward these goals for language model (LM) evaluations, we formulate the problem of generating a weakness profile, a set of weaknesses expressed in natural language, given an LM's performance on every individual instance in a benchmark. We introduce a suite of quantitative assessments to compare different weakness profiling methods. We also introduce a weakness profiling method EvalTree. EvalTree constructs a capability tree where each node represents a capability described in natural language and is linked to a subset of benchmark instances that specifically evaluate this capability; it then extracts nodes where the LM performs poorly to generate a weakness profile. On the MATH and WildChat benchmarks, we show that EvalTree outperforms baseline weakness profiling methods by identifying weaknesses more precisely and comprehensively. Weakness profiling further enables weakness-guided data collection, and training data collection guided by EvalTree-identified weaknesses improves LM performance more than other data collection strategies. We also show how EvalTree exposes flaws in Chatbot Arena's human-voter-based evaluation practice. To facilitate future work, we provide an interface that allows practitioners to interactively explore the capability trees built by EvalTree.",
      "authors": [
        "Zhiyuan Zeng",
        "Yizhong Wang",
        "Hannaneh Hajishirzi",
        "Pang Wei Koh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T21:12:48+00:00",
          "link": "https://arxiv.org/abs/2503.08893v1",
          "size": "2588kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T05:27:37+00:00",
          "link": "https://arxiv.org/abs/2503.08893v2",
          "size": "2579kb",
          "version": "v2"
        }
      ],
      "title": "EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08893",
        "HTML": "https://arxiv.org/html/2503.08893v2",
        "PDF": "https://arxiv.org/pdf/2503.08893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's contribution centers on weakness-guided data collection strategies for language model improvement, highlighting a novel profiling method (EvalTree) that identifies weaknesses to guide training data collection for enhanced performance."
      },
      "tasks": [
        "Chatbot",
        "Language Modeling",
        "Language Modelling",
        "Math"
      ],
      "repo_urls": [
        "https://github.com/zhiyuan-zeng/evaltree"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05314",
      "abstract": "Accurate segmentation of wounds and scale markers in clinical images remainsa significant challenge, crucial for effective wound management and automatedassessment. In this study, we propose a novel dual-attention U-Net++ archi-tecture, integrating channel-wise (SCSE) and spatial attention mechanisms toaddress severe class imbalance and variability in medical images effectively.Initially, extensive benchmarking across diverse architectures and encoders via 5-fold cross-validation identified EfficientNet-B7 as the optimal encoder backbone.Subsequently, we independently trained two class-specific models with tailoredpreprocessing, extensive data augmentation, and Bayesian hyperparameter tun-ing (WandB sweeps). The final model ensemble utilized Test Time Augmentationto further enhance prediction reliability. Our approach was evaluated on a bench-mark dataset from the NBC 2025 & PCBBE 2025 competition. Segmentationperformance was quantified using a weighted F1-score (75% wounds, 25% scalemarkers), calculated externally by competition organizers on undisclosed hard-ware. The proposed approach achieved an F1-score of 0.8640, underscoring itseffectiveness for complex medical segmentation tasks.",
      "authors": [
        "Daniel Cie\\'slak",
        "Miriam Reca",
        "Olena Onyshchenko and Jacek Rumi\\'nski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:24:15+00:00",
          "link": "https://arxiv.org/abs/2507.05314v1",
          "size": "4193kb",
          "version": "v1"
        }
      ],
      "title": "Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05314",
        "HTML": "https://arxiv.org/html/2507.05314v1",
        "PDF": "https://arxiv.org/pdf/2507.05314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses medical image segmentation using a novel architecture and data augmentation for training, which does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08190",
      "abstract": "Intel(r) Software Guard Extensions (SGX) was originally released on client platforms and later extended to single socket server platforms. As developers have become familiar with the capabilities of the technology, the applicability of this capability in the cloud has been tested. Various Cloud Service Providers (CSPs) are demonstrating the value of using SGX based Trusted Execution Environments (TEE) to create a new paradigm of Confidential Cloud Computing. This paper describes the additional platform enhancements we believe are necessary to deliver a user programmable Trusted Execution Environment that scales to cloud usages, performs and is secure on multi-package platforms.",
      "authors": [
        "Simon Johnson",
        "Raghunandan Makaram",
        "Amy Santoni",
        "Vinnie Scarlata"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:58:23+00:00",
          "link": "https://arxiv.org/abs/2507.08190v1",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "title": "Supporting Intel(r) SGX on Multi-Package Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08190",
        "PDF": "https://arxiv.org/pdf/2507.08190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Intel SGX on multi-package platforms and enhancements for cloud usage, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.00136",
      "abstract": "Visual text rendering are widespread in various real-world applications, requiring careful font selection and typographic choices. Recent progress in diffusion transformer (DiT)-based text-to-image (T2I) models show promise in automating these processes. However, these methods still encounter challenges like inconsistent fonts, style variation, and limited fine-grained control, particularly at the word-level. This paper proposes a two-stage DiT-based pipeline to address these problems by enhancing controllability over typography and style in text rendering. We introduce typography control fine-tuning (TC-FT), an parameter-efficient fine-tuning method (on $5\\%$ key parameters) with enclosing typography control tokens (ETC-tokens), which enables precise word-level application of typographic features. To further address style inconsistency in text rendering, we propose a text-agnostic style control adapter (SCA) that prevents content leakage while enhancing style consistency. To implement TC-FT and SCA effectively, we incorporated HTML-render into the data synthesis pipeline and proposed the first word-level controllable dataset. Through comprehensive experiments, we demonstrate the effectiveness of our approach in achieving superior word-level typographic control, font consistency, and style consistency in text rendering tasks. The datasets and models will be available for academic use.",
      "authors": [
        "Wenda Shi and Yiren Song and Dengming Zhang and Jiaming Liu and Xingxing Zou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T16:19:37+00:00",
          "link": "https://arxiv.org/abs/2412.00136v1",
          "size": "20874kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T08:43:03+00:00",
          "link": "https://arxiv.org/abs/2412.00136v2",
          "size": "42127kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T09:19:13+00:00",
          "link": "https://arxiv.org/abs/2412.00136v3",
          "size": "31621kb",
          "version": "v3"
        }
      ],
      "title": "FonTS: Text Rendering with Typography and Style Controls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00136",
        "HTML": "https://arxiv.org/html/2412.00136v3",
        "PDF": "https://arxiv.org/pdf/2412.00136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper's main contribution is enhancing controllability in visual text rendering, and it mentions creating a word-level controllable dataset using HTML-render data synthesis, briefly touching upon data processing, but not focusing primarily on LLM training data."
      },
      "tasks": [
        "parameter-efficient fine-tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13078",
      "abstract": "Computer vision is transforming fashion industry through Virtual Try-On (VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo of another person wearing the garment. VTOFF, in contrast, extracts standardized garment images from photos of clothed individuals. We introduce Multi-Garment TryOffDiff (MGT), a diffusion-based VTOFF model capable of handling diverse garment types, including upper-body, lower-body, and dresses. MGT builds on a latent diffusion architecture with SigLIP-based image conditioning to capture garment characteristics such as shape, texture, and pattern. To address garment diversity, MGT incorporates class-specific embeddings, achieving state-of-the-art VTOFF results on VITON-HD and competitive performance on DressCode. When paired with VTON models, it further enhances p2p-VTON by reducing unwanted attribute transfer, such as skin tone, ensuring preservation of person-specific characteristics. Demo, code, and models are available at: https://rizavelioglu.github.io/tryoffdiff/",
      "authors": [
        "Riza Velioglu",
        "Petra Bevandic",
        "Robin Chan",
        "Barbara Hammer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T16:45:18+00:00",
          "link": "https://arxiv.org/abs/2504.13078v1",
          "size": "48247kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T08:51:16+00:00",
          "link": "https://arxiv.org/abs/2504.13078v2",
          "size": "34600kb",
          "version": "v2"
        }
      ],
      "title": "MGT: Extending Virtual Try-Off to Multi-Garment Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13078",
        "HTML": "https://arxiv.org/html/2504.13078v2",
        "PDF": "https://arxiv.org/pdf/2504.13078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on virtual try-on and try-off models within the fashion industry, emphasizing computer vision applications rather than any aspect of LLM training data processing."
      },
      "models": [
        {
          "model_path": "rizavelioglu/tryoffdiff",
          "downloads": "0",
          "likes": "41",
          "trending_score": "0.0",
          "link": "https://huggingface.co/rizavelioglu/tryoffdiff"
        }
      ],
      "tasks": [
        "Attribute",
        "Garment Reconstruction",
        "Image Generation",
        "Virtual Try-Off",
        "Virtual Try-on"
      ],
      "repo_urls": [
        "https://github.com/rizavelioglu/tryoffdiff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08029",
      "abstract": "Artificial intelligence (AI) is increasingly used in recruitment, yet empirical evidence quantifying its impact on hiring efficiency and candidate selection remains limited. We randomly assign 37,000 applicants for a junior-developer position to either a traditional recruitment process (resume screening followed by human selection) or an AI-assisted recruitment pipeline incorporating an initial AI-driven structured video interview before human evaluation. Candidates advancing from either track faced the same final-stage human interview, with interviewers blind to the earlier selection method. In the AI-assisted pipeline, 54% of candidates passed the final interview compared with 34% from the traditional pipeline, yielding an average treatment effect of 20 percentage points (SE 12 pp.). Five months later, we collected LinkedIn profiles of top applicants from both groups and found that 18% (SE 1.1%) of applicants from the traditional track found new jobs compared with 23% (SE 2.3%) from the AI group, resulting in a 5.9 pp. (SE 2.6 pp.) difference in the probability of finding new employment between groups. The AI system tended to select younger applicants with less experience and fewer advanced credentials. We analyze AI-generated interview transcripts to examine the selection criteria and conversational dynamics. Our findings contribute to understanding how AI technologies affect decision making in recruitment and talent acquisition while highlighting some of their potential implications.",
      "authors": [
        "Ada Aka",
        "Emil Palikot",
        "Ali Ansari",
        "and Nima Yazdani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:51:46+00:00",
          "link": "https://arxiv.org/abs/2507.08029v1",
          "size": "8226kb",
          "version": "v1"
        }
      ],
      "title": "Better Together: Quantifying the Benefits of AI-Assisted Recruitment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08029",
        "HTML": "https://arxiv.org/html/2507.08029v1",
        "PDF": "https://arxiv.org/pdf/2507.08029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI-assisted recruitment processes and analyzes the impact on hiring rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08726",
      "abstract": "Learning robot manipulation policies from raw, real-world image data requires a large number of robot-action trials in the physical environment. Although training using simulations offers a cost-effective alternative, the visual domain gap between simulation and robot workspace remains a major limitation. Gaussian Splatting visual reconstruction methods have recently provided new directions for robot manipulation by generating realistic environments. In this paper, we propose the first method for learning supervised-based robot handovers solely from RGB images without the need of real-robot training or real-robot data collection. The proposed policy learner, Human-to-Robot Handover using Sparse-View Gaussian Splatting (H2RH-SGS), leverages sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes to generate robot demonstrations containing image-action pairs captured with a camera mounted on the robot gripper. As a result, the simulated camera pose changes in the reconstructed scene can be directly translated into gripper pose changes. We train a robot policy on demonstrations collected with 16 household objects and {\\em directly} deploy this policy in the real environment. Experiments in both Gaussian Splatting reconstructed scene and real-world human-to-robot handover experiments demonstrate that H2RH-SGS serves as a new and effective representation for the human-to-robot handover task.",
      "authors": [
        "Yuekun Wu",
        "Yik Lung Pang",
        "Andrea Cavallaro",
        "Changjae Oh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.08726v1",
          "size": "13403kb",
          "version": "v1"
        }
      ],
      "title": "Learning human-to-robot handovers through 3D scene reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08726",
        "HTML": "https://arxiv.org/html/2507.08726v1",
        "PDF": "https://arxiv.org/pdf/2507.08726"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study discusses learning robot manipulation policies and 3D scene reconstruction for human-to-robot handover tasks, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.01518",
      "abstract": "Delegating authentication to identity providers like Google or Facebook, while convenient, compromises user privacy. These identity providers can record users' every move; the global identifiers they provide also enable internet-wide tracking.\n  We show that neither is a necessary evil by presenting the BISON pseudonym derivation protocol, inspired by Oblivious Pseudorandom Functions. It hides the service provider's identity from the identity provider yet produces a trusted, scoped, immutable pseudonym. Colluding service providers cannot link BISON pseudonyms; this prevents user tracking. BISON does not require a long-lived state on the user device and does not add additional actors to the authentication process.\n  BISON is practical. It is easy to understand, implement, and reason about, and is designed to integrate into existing authentication protocols. To demonstrate this, we provide an OpenID Connect extension that allows OIDC's PPID pseudonyms to be derived using BISON while remaining fully backwards compatible. Additionally, BISON uses only lightweight cryptography. Pseudonym derivation requires a total of four elliptic curve scalar-point multiplications and four hash function evaluations, taking $\\approx$3 ms in our proof of concept implementation. Thus, BISON's privacy guarantees can be realized in practice. This makes BISON a crucial stepping stone towards the privacy-preserving internet of tomorrow.",
      "authors": [
        "Jakob Heher",
        "Stefan More",
        "Lena Heimberger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-03T16:48:47+00:00",
          "link": "https://arxiv.org/abs/2406.01518v1",
          "size": "196kb",
          "version": "v1"
        },
        {
          "date": "2024-07-17T15:26:49+00:00",
          "link": "https://arxiv.org/abs/2406.01518v2",
          "size": "260kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T13:37:53+00:00",
          "link": "https://arxiv.org/abs/2406.01518v3",
          "size": "1607kb",
          "version": "v3"
        }
      ],
      "title": "BISON: Blind Identification with Stateless scOped pseudoNyms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.01518",
        "HTML": "https://arxiv.org/html/2406.01518v3",
        "PDF": "https://arxiv.org/pdf/2406.01518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy-preserving authentication protocols using the BISON pseudonym derivation protocol, which is unrelated to LLM training data processing or dataset creation."
      },
      "repo_urls": [
        "https://github.com/iaik-jheher/bison"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.00922",
      "abstract": "This paper proposes a modular approach that combines the online convex optimization framework and reference governors to solve a constrained control problem featuring time-varying and a priori unknown cost functions. Compared to existing results, the proposed framework is uniquely applicable to nonlinear dynamical systems subject to state and input constraints. Furthermore, our method is general in the sense that we do not limit our analysis to a specific choice of online convex optimization algorithm or reference governor. We show that the dynamic regret of the proposed framework is bounded linearly in both the dynamic regret and the path length of the chosen online convex optimization algorithm, even though the online convex optimization algorithm does not account for the underlying dynamics. We prove that a linear bound with respect to the online convex optimization algorithm's dynamic regret is optimal, i.e., cannot be improved upon. Furthermore, for a standard class of online convex optimization algorithms, our proposed framework attains a bound on its dynamic regret that is linear only in the variation of the cost functions, which is known to be an optimal bound. Finally, we demonstrate implementation and flexibility of the proposed framework by comparing different combinations of online convex optimization algorithms and reference governors to control a nonlinear chemical reactor in a numerical experiment.",
      "authors": [
        "Marko Nonhoff and Johannes K\\\"ohler and Matthias A. M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-01T18:13:21+00:00",
          "link": "https://arxiv.org/abs/2412.00922v1",
          "size": "473kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:48:05+00:00",
          "link": "https://arxiv.org/abs/2412.00922v2",
          "size": "474kb",
          "version": "v2"
        }
      ],
      "title": "Online convex optimization for constrained control of nonlinear systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00922",
        "PDF": "https://arxiv.org/pdf/2412.00922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a modular approach for online convex optimization in control systems, with no discussion related to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.11992",
      "abstract": "Novel view synthesis (NVS) boosts immersive experiences in computer vision and graphics. Existing techniques, though progressed, rely on dense multi-view observations, restricting their application. This work takes on the challenge of reconstructing photorealistic 3D scenes from sparse or single-view inputs. We introduce SpatialCrafter, a framework that leverages the rich knowledge in video diffusion models to generate plausible additional observations, thereby alleviating reconstruction ambiguity. Through a trainable camera encoder and an epipolar attention mechanism for explicit geometric constraints, we achieve precise camera control and 3D consistency, further reinforced by a unified scale estimation strategy to handle scale discrepancies across datasets. Furthermore, by integrating monocular depth priors with semantic features in the video latent space, our framework directly regresses 3D Gaussian primitives and efficiently processes long-sequence features using a hybrid network structure. Extensive experiments show our method enhances sparse view reconstruction and restores the realistic appearance of 3D scenes.",
      "authors": [
        "Songchun Zhang",
        "Huiyao Xu",
        "Sitong Guo",
        "Zhongwei Xie",
        "Hujun Bao",
        "Weiwei Xu",
        "Changqing Zou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-17T13:05:13+00:00",
          "link": "https://arxiv.org/abs/2505.11992v1",
          "size": "31284kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:50:49+00:00",
          "link": "https://arxiv.org/abs/2505.11992v2",
          "size": "14489kb",
          "version": "v2"
        }
      ],
      "title": "SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11992",
        "HTML": "https://arxiv.org/html/2505.11992v2",
        "PDF": "https://arxiv.org/pdf/2505.11992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on novel view synthesis for scene reconstruction using video diffusion models, without any contribution to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Novel View Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08412",
      "abstract": "Environmental sound recordings often contain intelligible speech, raising privacy concerns that limit analysis, sharing and reuse of data. In this paper, we introduce a method that renders speech unintelligible while preserving both the integrity of the acoustic scene, and the overall audio quality. Our approach involves reversing waveform segments to distort speech content. This process is enhanced through a voice activity detection and speech separation pipeline, which allows for more precise targeting of speech.\n  In order to demonstrate the effectivness of the proposed approach, we consider a three-part evaluation protocol that assesses: 1) speech intelligibility using Word Error Rate (WER), 2) sound sources detectability using Sound source Classification Accuracy-Drop (SCAD) from a widely used pre-trained model, and 3) audio quality using the Fr\\'echet Audio Distance (FAD), computed with our reference dataset that contains unaltered speech. Experiments on this simulated evaluation dataset, which consists of linear mixtures of speech and environmental sound scenes, show that our method achieves satisfactory speech intelligibility reduction (97.9% WER), minimal degradation of the sound sources detectability (2.7% SCAD), and high perceptual quality (FAD of 1.40). An ablation study further highlights the contribution of each component of the pipeline. We also show that incorporating random splicing to our speech content privacy enforcement method can enhance the algorithm's robustness to attempt to recover the clean speech, at a slight cost of audio quality.",
      "authors": [
        "Modan Tailleur",
        "Mathieu Lagrange",
        "Pierre Aumond",
        "Vincent Tourre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:48:59+00:00",
          "link": "https://arxiv.org/abs/2507.08412v1",
          "size": "324kb",
          "version": "v1"
        }
      ],
      "title": "Enforcing Speech Content Privacy in Environmental Sound Recordings using Segment-wise Waveform Reversal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08412",
        "HTML": "https://arxiv.org/html/2507.08412v1",
        "PDF": "https://arxiv.org/pdf/2507.08412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method to enforce speech content privacy in sound recordings. It does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08138",
      "abstract": "Ratios of D-finite sequences and their limits -- known as Ap\\'ery limits -- have driven much of the work on irrationality proofs since Ap\\'ery's 1979 breakthrough proof of the irrationality of $\\zeta(3)$. We extend ratios of D-finite sequences to a high-dimensional setting by introducing the Conservative Matrix Field (CMF). We demonstrate how classical Ap\\'ery limits are included by this object as special cases. A useful construction of CMFs is provided, drawing a connection to gauge transformations and to representations of shift operators in finite dimensional modules of Ore algebras. Finally, numerical experiments on these objects reveal surprising arithmetic and dynamical phenomena, which are formulated into conjectures. If established, these conjectures would extend Poincar\\'e--Perron asymptotics to higher dimensions, potentially opening the door to optimization-based searches for new irrationality proofs.",
      "authors": [
        "Shachar Weinbaum",
        "Elyasheev Leibtag",
        "Rotem Kalisch",
        "Michael Shalyt",
        "Ido Kaminer"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Symbolic Computation (cs.SC)",
        "Combinatorics (math.CO)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:56:14+00:00",
          "link": "https://arxiv.org/abs/2507.08138v1",
          "size": "923kb",
          "version": "v1"
        }
      ],
      "title": "On Conservative Matrix Fields: Continuous Asymptotics and Arithmetic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08138",
        "HTML": "https://arxiv.org/html/2507.08138v1",
        "PDF": "https://arxiv.org/pdf/2507.08138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical concepts related to irrationality proofs and does not mention any aspect of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08440",
      "abstract": "Decision conferences are structured, collaborative meetings that bring together experts from various fields to address complex issues and reach a consensus on recommendations for future actions or policies. These conferences often rely on facilitated discussions to ensure productive dialogue and collective agreement. Recently, Large Language Models (LLMs) have shown significant promise in simulating real-world scenarios, particularly through collaborative multi-agent systems that mimic group interactions. In this work, we present a novel LLM-based multi-agent system designed to simulate decision conferences, specifically focusing on detecting agreement among the participant agents. To achieve this, we evaluate six distinct LLMs on two tasks: stance detection, which identifies the position an agent takes on a given issue, and stance polarity detection, which identifies the sentiment as positive, negative, or neutral. These models are further assessed within the multi-agent system to determine their effectiveness in complex simulations. Our results indicate that LLMs can reliably detect agreement even in dynamic and nuanced debates. Incorporating an agreement-detection agent within the system can also improve the efficiency of group debates and enhance the overall quality and coherence of deliberations, making them comparable to real-world decision conferences regarding outcome and decision-making. These findings demonstrate the potential for LLM-based multi-agent systems to simulate group decision-making processes. They also highlight that such systems could be instrumental in supporting decision-making with expert elicitation workshops across various domains.",
      "authors": [
        "Selina Heller and Mohamed Ibrahim and David Antony Selby and Sebastian Vollmer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:31:10+00:00",
          "link": "https://arxiv.org/abs/2507.08440v1",
          "size": "472kb",
          "version": "v1"
        }
      ],
      "title": "Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08440",
        "HTML": "https://arxiv.org/html/2507.08440v1",
        "PDF": "https://arxiv.org/pdf/2507.08440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of LLMs in decision conferences and simulations, with no focus on training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.15982",
      "abstract": "Sparse Discrete Empirical Interpolation Method (S-DEIM) was recently proposed for state estimation in dynamical systems when only a sparse subset of the state variables can be observed. The S-DEIM estimate involves a kernel vector whose optimal value is inferred through a data assimilation algorithm. This data assimilation step suffers from two drawbacks: (i) It requires the knowledge of the governing equations of the dynamical system, and (ii) It is not generally guaranteed to converge to the optimal kernel vector. To address these issues, here we introduce an equation-free S-DEIM framework that estimates the optimal kernel vector from sparse observational time series using recurrent neural networks (RNNs). We show that the recurrent architecture is necessary since the kernel vector cannot be estimated from instantaneous observations. But RNNs, which incorporate the past history of the observations in the learning process, lead to nearly optimal estimations. We demonstrate the efficacy of our method on three numerical examples with increasing degree of spatiotemporal complexity: a conceptual model of atmospheric flow known as the Lorenz-96 system, the Kuramoto-Sivashinsky equation, and the Rayleigh-Benard convection. In each case, the resulting S-DEIM estimates are satisfactory even when a relatively simple RNN architecture, namely the reservoir computing network, is used.",
      "authors": [
        "Mohammad Farazmand"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T13:12:22+00:00",
          "link": "https://arxiv.org/abs/2410.15982v1",
          "size": "4000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T21:34:35+00:00",
          "link": "https://arxiv.org/abs/2410.15982v2",
          "size": "9523kb",
          "version": "v2"
        }
      ],
      "title": "State Estimation Using Sparse DEIM and Recurrent Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15982",
        "HTML": "https://arxiv.org/html/2410.15982v2",
        "PDF": "https://arxiv.org/pdf/2410.15982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses state estimation using sparse DEIM and RNNs for dynamical systems, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "State Estimation",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08425",
      "abstract": "Large Language Models (LLMs) have demonstrated their transformative potential across numerous disciplinary studies, reshaping the existing research methodologies and fostering interdisciplinary collaboration. However, a systematic understanding of their integration into diverse disciplines remains underexplored. This survey paper provides a comprehensive overview of the application of LLMs in interdisciplinary studies, categorising research efforts from both a technical perspective and with regard to their applicability. From a technical standpoint, key methodologies such as supervised fine-tuning, retrieval-augmented generation, agent-based approaches, and tool-use integration are examined, which enhance the adaptability and effectiveness of LLMs in discipline-specific contexts. From the perspective of their applicability, this paper explores how LLMs are contributing to various disciplines including mathematics, physics, chemistry, biology, and the humanities and social sciences, demonstrating their role in discipline-specific tasks. The prevailing challenges are critically examined and the promising research directions are highlighted alongside the recent advances in LLMs. By providing a comprehensive overview of the technical developments and applications in this field, this survey aims to serve as an invaluable resource for the researchers who are navigating the complex landscape of LLMs in the context of interdisciplinary studies.",
      "authors": [
        "Lu Xiang",
        "Yang Zhao",
        "Yaping Zhang",
        "Chengqing Zong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:11:18+00:00",
          "link": "https://arxiv.org/abs/2507.08425v1",
          "size": "91kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08425",
        "HTML": "https://arxiv.org/html/2507.08425v1",
        "PDF": "https://arxiv.org/pdf/2507.08425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The survey paper discusses key methodologies in supervised fine-tuning and other techniques related to LLMs but focuses on their application across disciplines rather than on data processing methods for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08541",
      "abstract": "We introduce a series of graph decompositions based on the modulator/target scheme of modification problems that enable several algorithmic applications that parametrically extend the algorithmic potential of planarity. In the core of our approach is a polynomial time algorithm for computing planar H-modulators. Given a graph class H, a planar H-modulator of a graph G is a set X \\subseteq V(G) such that the ``torso'' of X is planar and all connected components of G - X belong to H. Here, the torso of X is obtained from G[X] if, for every connected component of G-X, we form a clique out of its neighborhood on G[X]. We introduce H-Planarity as the problem of deciding whether a graph G has a planar H-modulator. We prove that, if H is hereditary, CMSO-definable, and decidable in polynomial time, then H-Planarity is solvable in polynomial time. Further, we introduce two parametric extensions of H-Planarity by defining the notions of H-planar treedepth and H-planar treewidth, which generalize the concepts of elimination distance and tree decompositions to the class H. Combining this result with existing FPT algorithms for various H-modulator problems, we thereby obtain FPT algorithms parameterized by H-planar treedepth and H-planar treewidth for numerous graph classes H. By combining the well-known algorithmic properties of planar graphs and graphs of bounded treewidth, our methods for computing H-planar treedepth and H-planar treewidth lead to a variety of algorithmic applications. For instance, once we know that a given graph has bounded H-planar treedepth or bounded H-planar treewidth, we can derive additive approximation algorithms for graph coloring and polynomial-time algorithms for counting (weighted) perfect matchings. Furthermore, we design Efficient Polynomial-Time Approximation Schemes (EPTAS-es) for several problems, including Maximum Independent Set.",
      "authors": [
        "Fedor V. Fomin",
        "Petr A. Golovach",
        "Laure Morelle",
        "and Dimitrios M. Thilikos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:42:31+00:00",
          "link": "https://arxiv.org/abs/2507.08541v1",
          "size": "628kb",
          "version": "v1"
        }
      ],
      "title": "H-Planarity and Parametric Extensions: when Modulators Act Globally",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08541",
        "HTML": "https://arxiv.org/html/2507.08541v1",
        "PDF": "https://arxiv.org/pdf/2507.08541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses graph decompositions and algorithmic applications related to graph theory, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08542",
      "abstract": "Circular RNAs (circRNAs) are important components of the non-coding RNA regulatory network. Previous circRNA identification primarily relies on high-throughput RNA sequencing (RNA-seq) data combined with alignment-based algorithms that detect back-splicing signals. However, these methods face several limitations: they can't predict circRNAs directly from genomic DNA sequences and relies heavily on RNA experimental data; they involve high computational costs due to complex alignment and filtering steps; and they are inefficient for large-scale or genome-wide circRNA prediction. The challenge is even greater in plants, where plant circRNA splice sites often lack the canonical GT-AG motif seen in human mRNA splicing, and no efficient deep learning model with strong generalization capability currently exists. Furthermore, the number of currently identified plant circRNAs is likely far lower than their true abundance. In this paper, we propose a deep learning framework named CircFormerMoE based on transformers and mixture-of experts for predicting circRNAs directly from plant genomic DNA. Our framework consists of two subtasks known as splicing site detection (SSD) and splicing site pairing (SSP). The model's effectiveness has been validated on gene data of 10 plant species. Trained on known circRNA instances, it is also capable of discovering previously unannotated circRNAs. In addition, we performed interpretability analyses on the trained model to investigate the sequence patterns contributing to its predictions. Our framework provides a fast and accurate computational method and tool for large-scale circRNA discovery in plants, laying a foundation for future research in plant functional genomics and non-coding RNA annotation.",
      "authors": [
        "Tianyou Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:43:17+00:00",
          "link": "https://arxiv.org/abs/2507.08542v1",
          "size": "1706kb",
          "version": "v1"
        }
      ],
      "title": "CircFormerMoE: An End-to-End Deep Learning Framework for Circular RNA Splice Site Detection and Pairing in Plant Genomes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08542",
        "PDF": "https://arxiv.org/pdf/2507.08542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a deep learning framework for circRNA detection in plant genomes, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08594",
      "abstract": "Proto-personas are commonly used during early-stage Product Discovery, such as Lean Inception, to guide product definition and stakeholder alignment. However, the manual creation of proto-personas is often time-consuming, cognitively demanding, and prone to bias. In this paper, we propose and empirically investigate a prompt engineering-based approach to generate proto-personas with the support of Generative AI (GenAI). Our goal is to evaluate the approach in terms of efficiency, effectiveness, user acceptance, and the empathy elicited by the generated personas. We conducted a case study with 19 participants embedded in a real Lean Inception, employing a qualitative and quantitative methods design. The results reveal the approach's efficiency by reducing time and effort and improving the quality and reusability of personas in later discovery phases, such as Minimum Viable Product (MVP) scoping and feature refinement. While acceptance was generally high, especially regarding perceived usefulness and ease of use, participants noted limitations related to generalization and domain specificity. Furthermore, although cognitive empathy was strongly supported, affective and behavioral empathy varied significantly across participants. These results contribute novel empirical evidence on how GenAI can be effectively integrated into software Product Discovery practices, while also identifying key challenges to be addressed in future iterations of such hybrid design processes.",
      "authors": [
        "Fernando Ayach",
        "Vitor Lameir\\~ao",
        "Raul Le\\~ao",
        "Jerfferson Felizardo",
        "Rafael Sobrinho",
        "Vanessa Borges",
        "Patr\\'icia Matsubara",
        "Awdren Font\\~ao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:42:12+00:00",
          "link": "https://arxiv.org/abs/2507.08594v1",
          "size": "553kb",
          "version": "v1"
        }
      ],
      "title": "Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08594",
        "HTML": "https://arxiv.org/html/2507.08594v1",
        "PDF": "https://arxiv.org/pdf/2507.08594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on generating proto-personas using prompt engineering, addressing effectiveness in software discovery practices without discussing LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.15647",
      "abstract": "Rational Identity Testing (RIT) is the decision problem of determining whether or not a noncommutative rational formula computes zero in the free skew field. It admits a deterministic polynomial-time white-box algorithm [Garg, Gurvits, Oliveira, and Wigderson (2016); Ivanyos, Qiao, Subrahmanyam (2018); Hamada and Hirai (2021)], and a randomized polynomial-time algorithm [Derksen and Makam (2017)] in the black-box setting, via singularity testing of linear matrices over the free skew field. Indeed, a randomized NC algorithm for RIT in the white-box setting follows from the result of Derksen and Makam (2017).\n  Designing an efficient deterministic black-box algorithm for RIT and understanding the parallel complexity of RIT are major open problems in this area. Despite being open since the work of Garg, Gurvits, Oliveira, and Wigderson (2016), these questions have seen limited progress. In fact, the only known result in this direction is the construction of a quasipolynomial-size hitting set for rational formulas of only inversion height two [Arvind, Chatterjee, Mukhopadhyay (2022)].\n  In this paper, we significantly improve the black-box complexity of this problem and obtain the first quasipolynomial-size hitting set for all rational formulas of polynomial size. Our construction also yields the first deterministic quasi-NC upper bound for RIT in the white-box setting.",
      "authors": [
        "V. Arvind",
        "Abhranil Chatterjee",
        "and Partha Mukhopadhyay"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-27T13:32:28+00:00",
          "link": "https://arxiv.org/abs/2309.15647v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2023-11-15T14:21:20+00:00",
          "link": "https://arxiv.org/abs/2309.15647v2",
          "size": "61kb",
          "version": "v2"
        },
        {
          "date": "2024-04-06T08:03:39+00:00",
          "link": "https://arxiv.org/abs/2309.15647v3",
          "size": "84kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T05:42:13+00:00",
          "link": "https://arxiv.org/abs/2309.15647v4",
          "size": "59kb",
          "version": "v4"
        }
      ],
      "title": "Black-Box Identity Testing of Noncommutative Rational Formulas in Deterministic Quasipolynomial Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.15647",
        "HTML": "https://arxiv.org/html/2309.15647v4",
        "PDF": "https://arxiv.org/pdf/2309.15647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Rational Identity Testing (RIT) with complex algorithms, focusing on algebraic identity testing rather than any aspect of LLM data processing or handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18114",
      "abstract": "Integrating task-relevant information into neural representations is a fundamental ability of both biological and artificial intelligence systems. Recent theories have categorized learning into two regimes: the rich regime, where neural networks actively learn task-relevant features, and the lazy regime, where networks behave like random feature models. Yet this simple lazy-rich dichotomy overlooks a diverse underlying taxonomy of feature learning, shaped by differences in learning algorithms, network architectures, and data properties. To address this gap, we introduce an analysis framework to study feature learning via the geometry of neural representations. Rather than inspecting individual learned features, we characterize how task-relevant representational manifolds evolve throughout the learning process. We show, in both theoretical and empirical settings, that as networks learn features, task-relevant manifolds untangle, with changes in manifold geometry revealing distinct learning stages and strategies beyond the lazy-rich dichotomy. This framework provides novel insights into feature learning across neuroscience and machine learning, shedding light on structural inductive biases in neural circuits and the mechanisms underlying out-of-distribution generalization.",
      "authors": [
        "Chi-Ning Chou",
        "Hang Le",
        "Yichen Wang",
        "SueYeon Chung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T15:39:56+00:00",
          "link": "https://arxiv.org/abs/2503.18114v1",
          "size": "40707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:03:15+00:00",
          "link": "https://arxiv.org/abs/2503.18114v2",
          "size": "10892kb",
          "version": "v2"
        }
      ],
      "title": "Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18114",
        "HTML": "https://arxiv.org/html/2503.18114v2",
        "PDF": "https://arxiv.org/pdf/2503.18114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for analyzing feature learning in neural networks without discussing training data processing for LLMs."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Out-of-Distribution Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08031",
      "abstract": "The emergence of Small Language Models (SLMs) as privacy-preserving alternatives for sensitive applications raises a fundamental question about their inherent understanding capabilities compared to Large Language Models (LLMs). This paper investigates the mental health understanding capabilities of current SLMs through systematic evaluation across diverse classification tasks. Employing zero-shot and few-shot learning paradigms, we benchmark their performance against established LLM baselines to elucidate their relative strengths and limitations in this critical domain. We assess five state-of-the-art SLMs (Phi-3, Phi-3.5, Qwen2.5, Llama-3.2, Gemma2) against three LLMs (GPT-4, FLAN-T5-XXL, Alpaca-7B) on six mental health understanding tasks. Our findings reveal that SLMs achieve mean performance within 2\\% of LLMs on binary classification tasks (F1 scores of 0.64 vs 0.66 in zero-shot settings), demonstrating notable competence despite orders of magnitude fewer parameters. Both model categories experience similar degradation on multi-class severity tasks (a drop of over 30\\%), suggesting that nuanced clinical understanding challenges transcend model scale. Few-shot prompting provides substantial improvements for SLMs (up to 14.6\\%), while LLM gains are more variable. Our work highlights the potential of SLMs in mental health understanding, showing they can be effective privacy-preserving tools for analyzing sensitive online text data. In particular, their ability to quickly adapt and specialize with minimal data through few-shot learning positions them as promising candidates for scalable mental health screening tools.",
      "authors": [
        "Hong Jia",
        "Shiya Fu",
        "Vassilis Kostakos",
        "Feng Xia",
        "Ting Dang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:40:02+00:00",
          "link": "https://arxiv.org/abs/2507.08031v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08031",
        "HTML": "https://arxiv.org/html/2507.08031v1",
        "PDF": "https://arxiv.org/pdf/2507.08031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using small language models in mental health understanding but mainly focuses on performance evaluation, not primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08627",
      "abstract": "Studies show that large language models (LLMs) produce buggy code translations. One avenue to improve translation accuracy is through intermediate representations, which could provide structured insights to guide the model's understanding. We explore whether code translation using LLMs can benefit from intermediate representations via natural language (NL) and abstract syntax trees (ASTs). Since prompt engineering greatly affects LLM performance, we consider several ways to integrate these representations, from one-shot to chain-of-thought (CoT) prompting. Using Open Gpt4 8X7B and specialized StarCoder and CodeGen models on popular code translation benchmarks (CodeNet and AVATAR), we find that CoT with an intermediate NL summary performs best, with an increase of 13.8% and 6.7%, respectively, in successful translations for the best-performing model (Open Gpt4 8X7B) compared to the zero-shot prompt.",
      "authors": [
        "Chi-en Amy Tai",
        "Pengyu Nie",
        "Lukasz Golab",
        "Alexander Wong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:29:21+00:00",
          "link": "https://arxiv.org/abs/2507.08627v1",
          "size": "683kb",
          "version": "v1"
        }
      ],
      "title": "NL in the Middle: Code Translation with LLMs and Intermediate Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08627",
        "HTML": "https://arxiv.org/html/2507.08627v1",
        "PDF": "https://arxiv.org/pdf/2507.08627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper investigates code translation improvements using intermediate representations for LLMs, it primarily addresses model prompting techniques rather than substantive processing of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08182",
      "abstract": "Chain-of-thought (CoT) reasoning enables large language models (LLMs) to break down complex problems into interpretable intermediate steps, significantly enhancing model transparency and performance in reasoning tasks. However, conventional CoT methods rely on heuristic sampling without structured modeling of reasoning transitions, constraining their ability to systematically explore and discover diverse and effective reasoning trajectories. In this work, we introduce CTRLS, a framework that formulates CoT reasoning as a Markov decision process (MDP) with latent state transitions, enabling principled and state-aware exploration via distributional reinforcement learning. By modelling reasoning actions as explicit probability distributions in latent space, our approach explicitly models epistemic uncertainty, facilitating robust exploration of the reasoning space. As part of our framework, we introduce an on-policy reinforcement learning strategy incorporating epsilon-greedy exploration and entropy-based regularization to iteratively refine latent state transitions without requiring additional fine-tuning of the underlying LLM. Theoretical analyses provide evidence lower bounds (ELBO), theoretically grounding our transition-aware modeling of latent reasoning dynamics. Further experiments demonstrate improvements in reasoning accuracy, diversity, and exploration efficiency across benchmark reasoning tasks.",
      "authors": [
        "Junda Wu",
        "Yuxin Xiong",
        "Xintong Li",
        "Zhengmian Hu",
        "Tong Yu",
        "Rui Wang",
        "Xiang Chen",
        "Jingbo Shang",
        "Julian McAuley"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:32:18+00:00",
          "link": "https://arxiv.org/abs/2507.08182v1",
          "size": "732kb",
          "version": "v1"
        }
      ],
      "title": "CTRLS: Chain-of-Thought Reasoning via Latent State-Transition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08182",
        "HTML": "https://arxiv.org/html/2507.08182v1",
        "PDF": "https://arxiv.org/pdf/2507.08182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for improving reasoning in large language models. It does not discuss data processing or creation related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08749",
      "abstract": "A discrete-time conditional Gaussian Koopman network (CGKN) is developed in this work to learn surrogate models that can perform efficient state forecast and data assimilation (DA) for high-dimensional complex dynamical systems, e.g., systems governed by nonlinear partial differential equations (PDEs). Focusing on nonlinear partially observed systems that are common in many engineering and earth science applications, this work exploits Koopman embedding to discover a proper latent representation of the unobserved system states, such that the dynamics of the latent states are conditional linear, i.e., linear with the given observed system states. The modeled system of the observed and latent states then becomes a conditional Gaussian system, for which the posterior distribution of the latent states is Gaussian and can be efficiently evaluated via analytical formulae. The analytical formulae of DA facilitate the incorporation of DA performance into the learning process of the modeled system, which leads to a framework that unifies scientific machine learning (SciML) and data assimilation. The performance of discrete-time CGKN is demonstrated on several canonical problems governed by nonlinear PDEs with intermittency and turbulent features, including the viscous Burgers' equation, the Kuramoto-Sivashinsky equation, and the 2-D Navier-Stokes equations, with which we show that the discrete-time CGKN framework achieves comparable performance as the state-of-the-art SciML methods in state forecast and provides efficient and accurate DA results. The discrete-time CGKN framework also serves as an example to illustrate unifying the development of SciML models and their other outer-loop applications such as design optimization, inverse problems, and optimal control.",
      "authors": [
        "Chuanqi Chen",
        "Zhongrui Wang",
        "Nan Chen",
        "Jin-Long Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:59:27+00:00",
          "link": "https://arxiv.org/abs/2507.08749v1",
          "size": "4228kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Partially Observed Nonlinear Dynamical Systems and Efficient Data Assimilation via Discrete-Time Conditional Gaussian Koopman Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08749",
        "HTML": "https://arxiv.org/html/2507.08749v1",
        "PDF": "https://arxiv.org/pdf/2507.08749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses modeling for state forecast and data assimilation in dynamical systems using a Koopman network, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.03873",
      "abstract": "Robotic devices provide a great opportunity to assist in delivering physical therapy and rehabilitation movements, yet current robot-assisted methods struggle to incorporate biomechanical metrics essential for safe and effective therapy. We introduce BATON, a Biomechanics-Aware Trajectory Optimization approach to online robotic Navigation of human musculoskeletal loads for rotator cuff rehabilitation. BATON embeds a high-fidelity OpenSim model of the human shoulder into an optimal control framework, generating strain-minimizing trajectories for real-time control of therapeutic movements. \\addedText{Its core strength lies in the ability to adapt biomechanics-informed trajectories online to unpredictable volitional human actions or reflexive reactions during physical human-robot interaction based on robot-sensed motion and forces. BATON's adaptability is enabled by a real-time, model-based estimator that infers changes in muscle activity via a rapid redundancy solver driven by robot pose and force/torque sensor data. We validated BATON through physical human-robot interaction experiments, assessing response speed, motion smoothness, and interaction forces.",
      "authors": [
        "Italo Belli",
        "Florian van Melis",
        "J. Micah Prendergast",
        "Ajay Seth",
        "Luka Peternel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T12:40:59+00:00",
          "link": "https://arxiv.org/abs/2411.03873v1",
          "size": "11000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:27:37+00:00",
          "link": "https://arxiv.org/abs/2411.03873v2",
          "size": "5156kb",
          "version": "v2"
        }
      ],
      "title": "Biomechanics-Aware Trajectory Optimization for Online Navigation during Robotic Physiotherapy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03873",
        "HTML": "https://arxiv.org/html/2411.03873v2",
        "PDF": "https://arxiv.org/pdf/2411.03873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on trajectory optimization for robotic physiotherapy using biomechanical models, which does not relate to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07649",
      "abstract": "Hybrid solvers for combinatorial optimization problems combine the advantages of classical and quantum computing to overcome difficult computational challenges. Although their theoretical performance seems promising, their practical applicability is challenging due to the lack of a technological stack that can seamlessly integrate quantum solutions with existing classical optimization frameworks. We tackle this challenge by introducing the ProvideQ toolbox, a software tool that enables users to easily adapt and configure hybrid solvers via Meta-Solver strategies. A Meta-Solver strategy implements decomposition techniques, which splits problems into classical and quantum subroutines. The ProvideQ toolbox enables the interactive creation of such decompositions via a Meta-Solver configuration tool. It combines well-established classical optimization techniques with quantum circuits that are seamlessly executable on multiple backends. This paper introduces the technical details of the ProvideQ toolbox, explains its architecture, and demonstrates possible applications for several real-world use cases. Our proof of concept shows that Meta-Solver strategies already enable the application of quantum subroutines today, however, more sophisticated hardware is required to make their performance competitive.",
      "authors": [
        "Domenik Eichhorn",
        "Nick Poser",
        "Maximilian Schweikart",
        "Ina Schaefer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.07649v1",
          "size": "983kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T06:12:02+00:00",
          "link": "https://arxiv.org/abs/2507.07649v2",
          "size": "983kb",
          "version": "v2"
        }
      ],
      "title": "ProvideQ: A Quantum Optimization Toolbox",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07649",
        "HTML": "https://arxiv.org/html/2507.07649v2",
        "PDF": "https://arxiv.org/pdf/2507.07649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a quantum optimization toolbox for hybrid solvers, focusing on integration with classical optimization frameworks, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08018",
      "abstract": "A key challenge for iterative text generation is enabling models to efficiently identify and correct their own errors. We propose Review, Remask, Refine (R3), a relatively simple yet elegant framework that requires no additional model training and can be applied to any pre-trained masked text diffusion model (e.g., LLaDA or BD3-LM). In R3, a Process Reward Model (PRM) is utilized for the Review of intermediate generated blocks. The framework then translates these PRM scores into a Remask strategy: the lower a block's PRM score, indicating potential mistakes, the greater the proportion of tokens within that block are remasked. Finally, the model is compelled to Refine these targeted segments, focusing its efforts more intensively on specific sub-optimal parts of past generations, leading to improved final output.",
      "authors": [
        "Nikita Mounier",
        "Parsa Idehpour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T21:18:54+00:00",
          "link": "https://arxiv.org/abs/2507.08018v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Review, Remask, Refine (R3): Process-Guided Block Diffusion for Text Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08018",
        "HTML": "https://arxiv.org/html/2507.08018v1",
        "PDF": "https://arxiv.org/pdf/2507.08018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for iterative text generation, utilizing existing models without significant focus on modifying or processing training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.16060",
      "abstract": "Background-oriented schlieren (BOS) is a powerful technique for flow visualization. Nevertheless, the widespread dissemination of BOS is impeded by its dependence on scientific cameras, computing hardware, and dedicated analysis software. In this work, we aim to democratize BOS by providing a smartphone based scientific tool called \"Pocket Schlieren\". Pocket Schlieren enables users to directly capture, process, and visualize flow phenomena on their smartphones. The underlying algorithm incorporates consecutive frame subtraction (CFS) and optical flow (OF) techniques to compute the density gradients inside a flow. It performs on both engineered and natural background patterns. Using Pocket Schlieren, we successfully visualized the flow produced from a burning candle flame, butane lighter, hot soldering iron, room heater, water immersion heating rod, and a large outdoor butane flame. Pocket Schlieren promises to serve as a frugal yet potent instrument for scientific and educational purposes. We have made it publicly available at doi: 10.5281/zenodo.10949271.",
      "authors": [
        "Diganta Rabha",
        "Vimod Kumar",
        "Akshay Kumar",
        "Dinesh Saini and Manish Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Physics Education (physics.ed-ph)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-15T17:34:31+00:00",
          "link": "https://arxiv.org/abs/2404.16060v1",
          "size": "2999kb",
          "version": "v1"
        }
      ],
      "title": "Pocket Schlieren: a background oriented schlieren imaging platform on a smartphone",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16060",
        "PDF": "https://arxiv.org/pdf/2404.16060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Pocket Schlieren discusses a visualization tool for flow phenomena that uses smartphones, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08012",
      "abstract": "A Prompt-based Text-To-Speech model allows a user to control different aspects of speech, such as speaking rate and perceived gender, through natural language instruction. Although user-friendly, such approaches are on one hand constrained: control is limited to acoustic features exposed to the model during training, and too flexible on the other: the same inputs yields uncontrollable variation that are reflected in the corpus statistics.\n  We investigate a novel fine-tuning regime to address both of these issues at the same time by exploiting the uncontrollable variance of the model. Through principal component analysis of thousands of synthesised samples, we determine latent features that account for the highest proportion of the output variance and incorporate them as new labels for secondary fine-tuning. We evaluate the proposed methods on two models trained on an expressive Icelandic speech corpus, one with emotional disclosure and one without. In the case of the model without emotional disclosure, the method yields both continuous and discrete features that improve overall controllability of the model.",
      "authors": [
        "Atli Sigurgeirsson and Simon King"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T10:59:00+00:00",
          "link": "https://arxiv.org/abs/2507.08012v1",
          "size": "2668kb",
          "version": "v1"
        }
      ],
      "title": "RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08012",
        "HTML": "https://arxiv.org/html/2507.08012v1",
        "PDF": "https://arxiv.org/pdf/2507.08012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores fine-tuning of TTS models but does not focus on LLM training data processing; rather, it investigates model features and controllability."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.19054",
      "abstract": "This paper is a significant step forward in understanding dependency equilibria within the framework of real algebraic geometry encompassing both pure and mixed equilibria. In alignment with Spohn's original definition of dependency equilibria, we propose two alternative definitions, allowing for an algebro-geometric comprehensive study of all dependency equilibria. We give a sufficient condition for the existence of a pure dependency equilibrium and show that every Nash equilibrium lies on the Spohn variety, the algebraic model for dependency equilibria. For generic games, the set of real points of the Spohn variety is Zariski dense. Furthermore, every Nash equilibrium in this case is a dependency equilibrium. Finally, we present a detailed analysis of the geometric structure of dependency equilibria for $(2\\times2)$-games",
      "authors": [
        "Irem Portakal and Daniel Windisch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Algebraic Geometry (math.AG)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-29T12:56:07+00:00",
          "link": "https://arxiv.org/abs/2405.19054v1",
          "size": "218kb",
          "version": "v1"
        },
        {
          "date": "2025-04-05T15:53:46+00:00",
          "link": "https://arxiv.org/abs/2405.19054v2",
          "size": "220kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T16:18:26+00:00",
          "link": "https://arxiv.org/abs/2405.19054v3",
          "size": "221kb",
          "version": "v3"
        }
      ],
      "title": "Dependency equilibria: Boundary cases and their real algebraic geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.19054",
        "HTML": "https://arxiv.org/html/2405.19054v3",
        "PDF": "https://arxiv.org/pdf/2405.19054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides an algebro-geometric study of dependency equilibria in games. It does not engage with LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11924",
      "abstract": "This paper introduces a novel dataset REGEN (Reviews Enhanced with GEnerative Narratives), designed to benchmark the conversational capabilities of recommender Large Language Models (LLMs), addressing the limitations of existing datasets that primarily focus on sequential item prediction. REGEN extends the Amazon Product Reviews dataset by inpainting two key natural language features: (1) user critiques, representing user \"steering\" queries that lead to the selection of a subsequent item, and (2) narratives, rich textual outputs associated with each recommended item taking into account prior context. The narratives include product endorsements, purchase explanations, and summaries of user preferences.\n  Further, we establish an end-to-end modeling benchmark for the task of conversational recommendation, where models are trained to generate both recommendations and corresponding narratives conditioned on user history (items and critiques). For this joint task, we introduce a modeling framework LUMEN (LLM-based Unified Multi-task Model with Critiques, Recommendations, and Narratives) which uses an LLM as a backbone for critiquing, retrieval and generation. We also evaluate the dataset's quality using standard auto-rating techniques and benchmark it by training both traditional and LLM-based recommender models. Our results demonstrate that incorporating critiques enhances recommendation quality by enabling the recommender to learn language understanding and integrate it with recommendation signals. Furthermore, LLMs trained on our dataset effectively generate both recommendations and contextual narratives, achieving performance comparable to state-of-the-art recommenders and language models.",
      "authors": [
        "Kun Su",
        "Krishna Sayana",
        "Hubert Pham",
        "James Pine",
        "Yuri Vasilevski",
        "Raghavendra Vasudeva",
        "Marialena Kyriakidi",
        "Liam Hebert",
        "Ambarish Jash",
        "Anushya Subbiah",
        "Sukhdeep Sodhi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T23:47:46+00:00",
          "link": "https://arxiv.org/abs/2503.11924v1",
          "size": "505kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:13:04+00:00",
          "link": "https://arxiv.org/abs/2503.11924v2",
          "size": "485kb",
          "version": "v2"
        }
      ],
      "title": "REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11924",
        "HTML": "https://arxiv.org/html/2503.11924v2",
        "PDF": "https://arxiv.org/pdf/2503.11924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of the REGEN dataset, with detailed processes of data inpainting and enhancements aimed at benchmarking conversational capabilities of LLMs, showcasing novel data processing techniques."
      },
      "tasks": [
        "Conversational Recommendation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05718",
      "abstract": "Grokking refers to a delayed generalization following overfitting when optimizing artificial neural networks with gradient-based methods. In this work, we demonstrate that grokking can be induced by regularization, either explicit or implicit. More precisely, we show that when there exists a model with a property $P$ (e.g., sparse or low-rank weights) that generalizes on the problem of interest, gradient descent with a small but non-zero regularization of $P$ (e.g., $\\ell_1$ or nuclear norm regularization) results in grokking. This extends previous work showing that small non-zero weight decay induces grokking. Moreover, our analysis shows that over-parameterization by adding depth makes it possible to grok or ungrok without explicitly using regularization, which is impossible in shallow cases. We further show that the $\\ell_2$ norm is not a reliable proxy for generalization when the model is regularized toward a different property $P$, as the $\\ell_2$ norm grows in many cases where no weight decay is used, but the model generalizes anyway. We also show that grokking can be amplified solely through data selection, with any other hyperparameter fixed.",
      "authors": [
        "Pascal Jr Tikeng Notsawo",
        "Guillaume Dumas",
        "Guillaume Rabusseau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T03:44:28+00:00",
          "link": "https://arxiv.org/abs/2506.05718v1",
          "size": "9922kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T20:57:34+00:00",
          "link": "https://arxiv.org/abs/2506.05718v2",
          "size": "6439kb",
          "version": "v2"
        }
      ],
      "title": "Grokking Beyond the Euclidean Norm of Model Parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05718",
        "PDF": "https://arxiv.org/pdf/2506.05718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on the phenomenon of grokking in neural networks related to regularization and generalization but does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08367",
      "abstract": "This study investigates the potential of a multimodal large language model (LLM), specifically ChatGPT-4o, to perform human-like interpretations of traffic scenes using static dashcam images. Herein, we focus on three judgment tasks relevant to elderly driver assessments: evaluating traffic density, assessing intersection visibility, and recognizing stop signs recognition. These tasks require contextual reasoning rather than simple object detection. Using zero-shot, few-shot, and multi-shot prompting strategies, we evaluated the performance of the model with human annotations serving as the reference standard. Evaluation metrics included precision, recall, and F1-score. Results indicate that prompt design considerably affects performance, with recall for intersection visibility increasing from 21.7% (zero-shot) to 57.0% (multi-shot). For traffic density, agreement increased from 53.5% to 67.6%. In stop-sign detection, the model demonstrated high precision (up to 86.3%) but a lower recall (approximately 76.7%), indicating a conservative response tendency. Output stability analysis revealed that humans and the model faced difficulties interpreting structurally ambiguous scenes. However, the model's explanatory texts corresponded with its predictions, enhancing interpretability. These findings suggest that, with well-designed prompts, LLMs hold promise as supportive tools for scene-level driving risk assessments. Future studies should explore scalability using larger datasets, diverse annotators, and next-generation model architectures for elderly driver assessments.",
      "authors": [
        "Yuki Yoshihara",
        "Linjing Jiang",
        "Nihan Karatas",
        "Hitoshi Kanamori",
        "Asuka Harada",
        "Takahiro Tanaka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:28:49+00:00",
          "link": "https://arxiv.org/abs/2507.08367v1",
          "size": "8823kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Driving Risks using Large Language Models: Toward Elderly Driver Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08367",
        "HTML": "https://arxiv.org/html/2507.08367v1",
        "PDF": "https://arxiv.org/pdf/2507.08367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the use of LLM (ChatGPT-4o) for interpreting traffic scenes and discusses prompt design strategies, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08768",
      "abstract": "In this study, we leverage a unique UNESCO collection of mid-20th century radio recordings to probe the robustness of modern off-the-shelf language identification (LID) and speaker recognition (SR) methods, especially with respect to the impact of multilingual speakers and cross-age recordings. Our findings suggest that LID systems, such as Whisper, are increasingly adept at handling second-language and accented speech. However, speaker embeddings remain a fragile component of speech processing pipelines that is prone to biases related to the channel, age, and language. Issues which will need to be overcome should archives aim to employ SR methods for speaker indexing.",
      "authors": [
        "Peter Sullivan and Muhammad Abdul-Mageed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.08768v1",
          "size": "6939kb",
          "version": "v1"
        }
      ],
      "title": "On Barriers to Archival Audio Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08768",
        "HTML": "https://arxiv.org/html/2507.08768v1",
        "PDF": "https://arxiv.org/pdf/2507.08768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines language and speaker recognition systems on archival audio and does not deal with LLM training data or related data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.00945",
      "abstract": "Motivated by the ideal peak-to-average-power ratio and radar sensing capability of traditional frequency-coded radar waveforms, this paper considers the frequency shift keying (FSK) based waveform for joint communications and radar (JCR). An analysis of the probability distributions of its ambiguity function (AF) sidelobe levels (SLs) and peak sidelobe level (PSL) is conducted to study the radar sensing capability of random FSK. Numerical results show that the independent frequency modulation introduces uncontrollable AF PSLs. In order to address this problem, the initial phases of waveform sub-pulses are designed by solving a min-max optimisation problem. Numerical results indicate that the optimisation-based phase design can effectively reduce the AF PSL to a level close to well-designed radar waveforms while having no impact on the data rate and the receiver complexity. For large numbers of waveform sub-pulses and modulation orders, the impact on the error probability is also insignificant.",
      "authors": [
        "Tian Han",
        "Peter J Smith",
        "Urbashi Mitra",
        "Jamie S Evans",
        "Rajitha Senanayake"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-02T02:12:26+00:00",
          "link": "https://arxiv.org/abs/2405.00945v1",
          "size": "471kb",
          "version": "v1"
        }
      ],
      "title": "Can FSK Be Optimised for Integrated Sensing and Communications?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.00945",
        "HTML": "https://arxiv.org/html/2405.00945",
        "PDF": "https://arxiv.org/pdf/2405.00945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on optimizing frequency shift keying for integrated sensing and communications, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08230",
      "abstract": "As artificial intelligence (AI) systems become increasingly sophisticated at generating synthetic human faces, understanding how these images are perceived across diverse populations is important. This study investigates how autistic individuals/individuals with autism perceive AI-generated faces, focusing on the uncanny valley effect. Using a qualitative approach, we analyzed discussions from the r/autism community on Reddit to explore how autistic participants/participants with autism describe their experiences with AI-generated faces and the uncanny valley phenomenon. The findings suggest that autistic people/people with autism may experience the uncanny valley differently, often reporting stronger discomfort with real human faces than with artificial ones. This research contributes to our understanding of visual perception in autism and has implications for the development of inclusive AI systems and assistive technologies.",
      "authors": [
        "Gabriella Waters"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:35:59+00:00",
          "link": "https://arxiv.org/abs/2507.08230v1",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "title": "Uncanny or Not? Perceptions of AI-Generated Faces in Autism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08230",
        "PDF": "https://arxiv.org/pdf/2507.08230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates perceptions of AI-generated faces among autistic individuals. It does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08572",
      "abstract": "When inverse kinematics (IK) is adopted to control robotic arms in manipulation tasks, there is often a discrepancy between the end effector (EE) position of the robot model in the simulator and the physical EE in reality. In most robotic scenarios with sim-to-real transfer, we have information about joint positions in both simulation and reality, but the EE position is only available in simulation. We developed a novel method to overcome this difficulty based on haptic feedback calibration, using a touchscreen in front of the robot that provides information on the EE position in the real environment. During the calibration procedure, the robot touches specific points on the screen, and the information is stored. In the next stage, we build a transformation function from the data based on linear transformation and neural networks that is capable of outputting all missing variables from any partial input (simulated/real joint/EE position). Our results demonstrate that a fully nonlinear neural network model performs best, significantly reducing positioning errors.",
      "authors": [
        "Juraj Gavura and Michal Vavrecka and Igor Farkas and Connor Gade"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:20:33+00:00",
          "link": "https://arxiv.org/abs/2507.08572v1",
          "size": "347kb",
          "version": "v1"
        }
      ],
      "title": "Robotic Calibration Based on Haptic Feedback Improves Sim-to-Real Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08572",
        "HTML": "https://arxiv.org/html/2507.08572v1",
        "PDF": "https://arxiv.org/pdf/2507.08572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sim-to-real transfer in robotics using haptic feedback and neural networks, with no mention of training data processing related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07257",
      "abstract": "We present a multi-agent system for automation of scientific research tasks, cmbagent (https://github.com/CMBAgents/cmbagent). The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.",
      "authors": [
        "Licong Xu",
        "Milind Sarkar",
        "Anto I. Lonappan",
        "\\'I\\~nigo Zubeldia",
        "Pablo Villanueva-Domingo",
        "Santiago Casas",
        "Christian Fidler",
        "Chetana Amancharla",
        "Ujjwal Tiwari",
        "Adrian Bayer",
        "Chadi Ait Ekioui",
        "Miles Cranmer",
        "Adrian Dimitrov",
        "James Fergusson",
        "Kahaan Gandhi",
        "Sven Krippendorf",
        "Andrew Laverick",
        "Julien Lesgourgues",
        "Antony Lewis",
        "Thomas Meier",
        "Blake Sherwin",
        "Kristen Surrao",
        "Francisco Villaescusa-Navarro",
        "Chi Wang",
        "Xueqing Xu",
        "Boris Bolliet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:03:30+00:00",
          "link": "https://arxiv.org/abs/2507.07257v1",
          "size": "7109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:43:29+00:00",
          "link": "https://arxiv.org/abs/2507.07257v2",
          "size": "7109kb",
          "version": "v2"
        }
      ],
      "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07257",
        "PDF": "https://arxiv.org/pdf/2507.07257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a system for automation of scientific research tasks using multiple LLM agents, but does not focus on any training-data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.06728",
      "abstract": "A neural network with one hidden layer or a two-layer network (regardless of the input layer) is the simplest feedforward neural network, whose mechanism may be the basis of more general network architectures. However, even to this type of simple architecture, it is also a ``black box''; that is, it remains unclear how to interpret the mechanism of its solutions obtained by the back-propagation algorithm and how to control the training process through a deterministic way. This paper systematically studies the first problem by constructing universal function-approximation solutions. It is shown that, both theoretically and experimentally, the training solution for the one-dimensional input could be completely understood, and that for a higher-dimensional input can also be well interpreted to some extent. Those results pave the way for thoroughly revealing the black box of two-layer ReLU networks and advance the understanding of deep ReLU networks.",
      "authors": [
        "Changcun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T05:51:11+00:00",
          "link": "https://arxiv.org/abs/2411.06728v1",
          "size": "127kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:06:04+00:00",
          "link": "https://arxiv.org/abs/2411.06728v2",
          "size": "128kb",
          "version": "v2"
        }
      ],
      "title": "On the Principles of ReLU Networks with One Hidden Layer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06728",
        "HTML": "https://arxiv.org/html/2411.06728v2",
        "PDF": "https://arxiv.org/pdf/2411.06728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding the mechanism of ReLU networks with one hidden layer, without mentioning any LLM training data processing or dataset preparation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.06311",
      "abstract": "Ground Penetrating Radar (GPR) is a widely used Non-Destructive Testing (NDT) technique for subsurface exploration, particularly in infrastructure inspection and maintenance. However, conventional interpretation methods are often limited by noise sensitivity and a lack of structural awareness. This study presents a novel framework that enhances the detection of underground utilities, especially pipelines, by integrating shape-aware topological features derived from B-scan GPR images using Topological Data Analysis (TDA), with the spatial detection capabilities of the YOLOv5 deep neural network (DNN). We propose a novel shape-aware topological representation that amplifies structural features in the input data, thereby improving the model's responsiveness to the geometrical features of buried objects. To address the scarcity of annotated real-world data, we employ a Sim2Real strategy that generates diverse and realistic synthetic datasets, effectively bridging the gap between simulated and real-world domains. Experimental results demonstrate significant improvements in mean Average Precision (mAP), validating the robustness and efficacy of our approach. This approach underscores the potential of TDA-enhanced learning in achieving reliable, real-time subsurface object detection, with broad applications in urban planning, safety inspection, and infrastructure management.",
      "authors": [
        "Meiyan Kang",
        "Shizuo Kaji",
        "Sang-Yun Lee",
        "Taegon Kim",
        "Hee-Hwan Ryu",
        "Suyoung Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T10:43:34+00:00",
          "link": "https://arxiv.org/abs/2506.06311v1",
          "size": "4844kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:37:00+00:00",
          "link": "https://arxiv.org/abs/2506.06311v2",
          "size": "4560kb",
          "version": "v2"
        }
      ],
      "title": "A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06311",
        "HTML": "https://arxiv.org/html/2506.06311v2",
        "PDF": "https://arxiv.org/pdf/2506.06311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses employing a Sim2Real strategy to generate synthetic datasets, which is a clear contribution to data generation for improving real-world data scarcity in detection tasks."
      },
      "tasks": [
        "GPR",
        "object-detection",
        "Object Detection",
        "Topological Data Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08554",
      "abstract": "Semantic segmentation relies on many dense pixel-wise annotations to achieve the best performance, but owing to the difficulty of obtaining accurate annotations for real world data, practitioners train on large-scale synthetic datasets. Unpaired image translation is one method used to address the ensuing domain gap by generating more realistic training data in low-data regimes. Current methods for unpaired image translation train generative adversarial networks (GANs) to perform the translation and enforce pixel-level semantic matching through cycle consistency. These methods do not guarantee that the semantic matching holds, posing a problem for semantic segmentation where performance is sensitive to noisy pixel labels. We propose a novel image translation method, Domain Adversarial Kernel Prediction Network (DA-KPN), that guarantees semantic matching between the synthetic label and translation. DA-KPN estimates pixel-wise input transformation parameters of a lightweight and simple translation function. To ensure the pixel-wise transformation is realistic, DA-KPN uses multi-scale discriminators to distinguish between translated and target samples. We show DA-KPN outperforms previous GAN-based methods on syn2real benchmarks for semantic segmentation with limited access to real image labels and achieves comparable performance on face parsing.",
      "authors": [
        "Cristina Mata",
        "Michael S. Ryoo",
        "Henrik Turbell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:56:22+00:00",
          "link": "https://arxiv.org/abs/2507.08554v1",
          "size": "9044kb",
          "version": "v1"
        }
      ],
      "title": "Image Translation with Kernel Prediction Networks for Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08554",
        "HTML": "https://arxiv.org/html/2507.08554v1",
        "PDF": "https://arxiv.org/pdf/2507.08554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on image translation for semantic segmentation using synthetic datasets but does not address LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.02672",
      "abstract": "The estimation of conditional average treatment effects (CATEs) is an important topic in many scientific fields. CATEs can be estimated with high accuracy if data distributed across multiple parties are centralized. However, it is difficult to aggregate such data owing to confidentiality or privacy concerns. To address this issue, we propose data collaboration double machine learning, a method for estimating CATE models using privacy-preserving fusion data constructed from distributed sources, and evaluate its performance through simulations. We make three main contributions. First, our method enables estimation and testing of semi-parametric CATE models without iterative communication on distributed data, providing robustness to model mis-specification compared to parametric approaches. Second, it enables collaborative estimation across different time points and parties by accumulating a knowledge base. Third, our method performs as well as or better than existing methods in simulations using synthetic, semi-synthetic, and real-world datasets.",
      "authors": [
        "Yuji Kawamata",
        "Ryoki Motai",
        "Yukihiko Okada",
        "Akira Imakura",
        "Tetsuya Sakurai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-05T02:17:21+00:00",
          "link": "https://arxiv.org/abs/2402.02672v1",
          "size": "374kb",
          "version": "v1"
        },
        {
          "date": "2024-05-25T08:15:07+00:00",
          "link": "https://arxiv.org/abs/2402.02672v2",
          "size": "390kb",
          "version": "v2"
        },
        {
          "date": "2024-09-10T06:17:16+00:00",
          "link": "https://arxiv.org/abs/2402.02672v3",
          "size": "472kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T07:50:56+00:00",
          "link": "https://arxiv.org/abs/2402.02672v4",
          "size": "484kb",
          "version": "v4"
        }
      ],
      "title": "Estimation of conditional average treatment effects on distributed confidential data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02672",
        "HTML": "https://arxiv.org/html/2402.02672v4",
        "PDF": "https://arxiv.org/pdf/2402.02672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a method for estimating CATE models with privacy-preserving data fusion, which may involve data construction but it does not focus on LLM-specific training data processing."
      },
      "tasks": [
        "Privacy Preserving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.19715",
      "abstract": "Speculative decoding reduces the inference latency of a target large language model via utilizing a smaller and faster draft model. Its performance depends on a hyperparameter K -- the candidate length, i.e., the number of candidate tokens for the target model to verify in each round. However, previous methods often use simple heuristics to choose K, which may result in sub-optimal performance. We study the choice of the candidate length K and formulate it as a Markov Decision Process. We theoretically show that the optimal policy of this Markov decision process takes the form of a threshold policy, i.e., the current speculation should stop and be verified when the probability of getting a rejection exceeds a threshold value. Motivated by this theory, we propose SpecDec++, an enhanced version of speculative decoding that adaptively determines the candidate length on the fly. We augment the draft model with a trained acceptance prediction head to predict the conditional acceptance probability of the candidate tokens. SpecDec++ will stop the current speculation when the predicted probability that at least one token gets rejected exceeds a threshold. We implement SpecDec++ and apply it to the llama-2-chat 7B & 70B model pair. Our adaptive method achieves a 2.04x speedup on the Alpaca dataset (7.2% improvement over the baseline speculative decoding). On the GSM8K and HumanEval datasets, our method achieves a 2.26x speedup (9.4% improvement) and 2.23x speedup (11.1% improvement), respectively. The code of this paper is available at https://github.com/Kaffaljidhmah2/SpecDec_pp.",
      "authors": [
        "Kaixuan Huang",
        "Xudong Guo",
        "Mengdi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-30T05:49:38+00:00",
          "link": "https://arxiv.org/abs/2405.19715v1",
          "size": "218kb",
          "version": "v1"
        },
        {
          "date": "2024-06-21T01:01:42+00:00",
          "link": "https://arxiv.org/abs/2405.19715v2",
          "size": "218kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T01:33:18+00:00",
          "link": "https://arxiv.org/abs/2405.19715v3",
          "size": "215kb",
          "version": "v3"
        }
      ],
      "title": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.19715",
        "HTML": "https://arxiv.org/html/2405.19715v3",
        "PDF": "https://arxiv.org/pdf/2405.19715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The focus is on enhancing speculative decoding for LLMs by adjusting candidate lengths, which is a model inference technique, rather than processing or engineering of training data."
      },
      "models": [
        {
          "model_path": "hacky/acchead-llama2-chat-7bx70b",
          "downloads": "3",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/hacky/acchead-llama2-chat-7bx70b"
        }
      ],
      "tasks": [
        "GSM8K",
        "HumanEval",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08136",
      "abstract": "3D Gaussian Splatting (3DGS) has demonstrated its potential in reconstructing scenes from unposed images. However, optimization-based 3DGS methods struggle with sparse views due to limited prior knowledge. Meanwhile, feed-forward Gaussian approaches are constrained by input formats, making it challenging to incorporate more input views. To address these challenges, we propose RegGS, a 3D Gaussian registration-based framework for reconstructing unposed sparse views. RegGS aligns local 3D Gaussians generated by a feed-forward network into a globally consistent 3D Gaussian representation. Technically, we implement an entropy-regularized Sinkhorn algorithm to efficiently solve the optimal transport Mixture 2-Wasserstein $(\\text{MW}_2)$ distance, which serves as an alignment metric for Gaussian mixture models (GMMs) in $\\mathrm{Sim}(3)$ space. Furthermore, we design a joint 3DGS registration module that integrates the $\\text{MW}_2$ distance, photometric consistency, and depth geometry. This enables a coarse-to-fine registration process while accurately estimating camera poses and aligning the scene. Experiments on the RE10K and ACID datasets demonstrate that RegGS effectively registers local Gaussians with high fidelity, achieving precise pose estimation and high-quality novel-view synthesis. Project page: https://3dagentworld.github.io/reggs/.",
      "authors": [
        "Chong Cheng",
        "Yu Hu",
        "Sicheng Yu",
        "Beizhen Zhao",
        "Zijian Wang",
        "Hao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:56:08+00:00",
          "link": "https://arxiv.org/abs/2507.08136v1",
          "size": "4562kb",
          "version": "v1"
        }
      ],
      "title": "RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08136",
        "HTML": "https://arxiv.org/html/2507.08136v1",
        "PDF": "https://arxiv.org/pdf/2507.08136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for reconstructing scenes from unposed images, without addressing LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05416",
      "abstract": "Air pollution from agricultural emissions is a significant yet often overlooked contributor to environmental and public health challenges. Traditional air quality forecasting models rely on physics-based approaches, which struggle to capture complex, nonlinear pollutant interactions. In this work, we explore forecasting N$_2$O agricultural emissions through evaluating popular architectures, and proposing two novel deep learning architectures, EmissionNet (ENV) and EmissionNet-Transformer (ENT). These models leverage convolutional and transformer-based architectures to extract spatial-temporal dependencies from high-resolution emissions data",
      "authors": [
        "Prady Saligram",
        "Tanvir Bhathal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:58:22+00:00",
          "link": "https://arxiv.org/abs/2507.05416v1",
          "size": "3727kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.05416v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "EmissionNet: Air Quality Pollution Forecasting for Agriculture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05416",
        "PDF": "https://arxiv.org/pdf/2507.05416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deep learning architectures for air quality forecasting, specifically agricultural emissions. It does not discuss LLM training data processing or data engineering related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08053",
      "abstract": "Tree-structured Parzen estimator (TPE) is a versatile hyperparameter optimization (HPO) method supported by popular HPO tools. Since these HPO tools have been developed in line with the trend of deep learning (DL), the problem setups often used in the DL domain have been discussed for TPE such as multi-objective optimization and multi-fidelity optimization. However, the practical applications of HPO are not limited to DL, and black-box combinatorial optimization is actively utilized in some domains, e.g., chemistry and biology. As combinatorial optimization has been an untouched, yet very important, topic in TPE, we propose an efficient combinatorial optimization algorithm for TPE. In this paper, we first generalize the categorical kernel with the numerical kernel in TPE, enabling us to introduce a distance structure to the categorical kernel. Then we discuss modifications for the newly developed kernel to handle a large combinatorial search space. These modifications reduce the time complexity of the kernel calculation with respect to the size of a combinatorial search space. In the experiments using synthetic problems, we verified that our proposed method identifies better solutions with fewer evaluations than the original TPE. Our algorithm is available in Optuna, an open-source framework for HPO.",
      "authors": [
        "Kenshin Abe",
        "Yunzhuo Wang",
        "Shuhei Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:26:49+00:00",
          "link": "https://arxiv.org/abs/2507.08053v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08053",
        "HTML": "https://arxiv.org/html/2507.08053v1",
        "PDF": "https://arxiv.org/pdf/2507.08053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a combinatorial optimization algorithm for hyperparameter optimization, but it does not focus on LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08598",
      "abstract": "Polar codes are widely used in modern communication systems due to their capacity-achieving properties. This paper investigates the importance of coded bits in the decoding process of polar codes and aims to determine which bits contribute most to successful decoding. We investigate the problem via a brute-force search approach and surrogate optimization techniques to identify the most critical coded bits. We also demonstrate how mapping these important bits to the most reliable channels improves system performance with minimal additional cost. We show the performance of our proposed bit mapping in OFDM based systems, and demonstrate up to x7 gain in BER performance.",
      "authors": [
        "Hossam Hassan",
        "Ali Gaber",
        "Mohammed Karmoose",
        "Noha Korany"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:47:15+00:00",
          "link": "https://arxiv.org/abs/2507.08598v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Discovering the Unequal Importance of Coded Bits in the Decoding of Polar Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08598",
        "HTML": "https://arxiv.org/html/2507.08598v1",
        "PDF": "https://arxiv.org/pdf/2507.08598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The investigation into polar codes focuses purely on decoding efficiency and does not involve LLM training data processing or any related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.01134",
      "abstract": "The ability to autonomously assemble structures is crucial for the development of future space infrastructure. However, the unpredictable conditions of space pose significant challenges for robotic systems, necessitating the development of advanced learning techniques to enable autonomous assembly. In this study, we present a novel approach for learning autonomous peg-in-hole assembly in the context of space robotics. Our focus is on enhancing the generalization and adaptability of autonomous systems through deep reinforcement learning. By integrating procedural generation and domain randomization, we train agents in a highly parallelized simulation environment across a spectrum of diverse scenarios with the aim of acquiring a robust policy. The proposed approach is evaluated using three distinct reinforcement learning algorithms to investigate the trade-offs among various paradigms. We demonstrate the adaptability of our agents to novel scenarios and assembly sequences while emphasizing the potential of leveraging advanced simulation techniques for robot learning in space. Our findings set the stage for future advancements in intelligent robotic systems capable of supporting ambitious space missions and infrastructure development beyond Earth.",
      "authors": [
        "Andrej Orsula",
        "Matthieu Geist",
        "Miguel Olivares-Mendez",
        "Carol Martinez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-02T09:50:01+00:00",
          "link": "https://arxiv.org/abs/2405.01134v1",
          "size": "3709kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Procedural Generation for Learning Autonomous Peg-in-Hole Assembly in Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.01134",
        "HTML": "https://arxiv.org/html/2405.01134",
        "PDF": "https://arxiv.org/pdf/2405.01134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on autonomous assembly using reinforcement learning in space robotics, integrating procedural generation and domain randomization. It does not address LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/andrejorsula/drl_omni_peg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07340",
      "abstract": "Visual storytelling systems, particularly large vision-language models, struggle to maintain character and object identity across frames, often failing to recognize when entities in different images represent the same individuals or objects, leading to inconsistent references and referential hallucinations. This occurs because models lack explicit training on when to establish entity connections across frames. We propose a contrastive reinforcement learning approach that trains models to discriminate between coherent image sequences and stories from unrelated images. We extend the Story Reasoning dataset with synthetic negative examples to teach appropriate entity connection behavior. We employ Direct Preference Optimization with a dual-component reward function that promotes grounding and re-identification of entities in real stories while penalizing incorrect entity connections in synthetic contexts. Using this contrastive framework, we fine-tune Qwen Storyteller (based on Qwen2.5-VL 7B). Evaluation shows improvements in grounding mAP from 0.27 to 0.31 (+14.8%), F1 from 0.35 to 0.41 (+17.1%). Pronoun grounding accuracy improved across all pronoun types except \"its\", and cross-frame character and object persistence increased across all frame counts, with entities appearing in 5 or more frames advancing from 29.3% to 33.3% (+13.7%). Well-structured stories, containing the chain-of-thought and grounded story, increased from 79.1% to 97.5% (+23.3%).",
      "authors": [
        "Daniel A. P. Oliveira",
        "David Martins de Matos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:52:10+00:00",
          "link": "https://arxiv.org/abs/2507.07340v1",
          "size": "96kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T00:58:38+00:00",
          "link": "https://arxiv.org/abs/2507.07340v2",
          "size": "96kb",
          "version": "v2"
        }
      ],
      "title": "Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07340",
        "HTML": "https://arxiv.org/html/2507.07340v2",
        "PDF": "https://arxiv.org/pdf/2507.07340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces synthetic negative examples for training models in visual storytelling, the focus is on contrastive reinforcement learning rather than on creating or processing LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07524",
      "abstract": "The class PLS (Polynomial Local Search) captures the complexity of finding a solution that is locally optimal and has proven to be an important concept in the theory of local search. It has been shown that local search versions of various combinatorial optimization problems, such as Maximum Independent Set and Max Cut, are complete for this class. Such computational intractability typically arises in local search problems allowing arbitrary weights; in contrast, for unweighted problems, locally optimal solutions can be found in polynomial time under standard settings. In this paper, we pursue the complexity of local search problems from a different angle: We show that computing two locally optimal solutions is NP-hard for various natural unweighted local search problems, including Maximum Independent Set, Minimum Dominating Set, Max SAT, and Max Cut. We also discuss several tractable cases for finding two (or more) local optimal solutions.",
      "authors": [
        "Yasuaki Kobayashi",
        "Kazuhiro Kurita",
        "Yutaro Yamaguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.07524v1",
          "size": "142kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T05:46:48+00:00",
          "link": "https://arxiv.org/abs/2507.07524v2",
          "size": "142kb",
          "version": "v2"
        }
      ],
      "title": "Finding One Local Optimum Is Easy -- But What about Two?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07524",
        "HTML": "https://arxiv.org/html/2507.07524v2",
        "PDF": "https://arxiv.org/pdf/2507.07524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the complexity of finding locally optimal solutions in combinatorial optimization problems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.07791",
      "abstract": "Understanding the dynamics of financial transactions among people is critical for various applications such as fraud detection. One important aspect of financial transaction networks is temporality. The order and repetition of transactions can offer new insights when considered within the graph structure. Temporal motifs, defined as a set of nodes that interact with each other in a short time period, are a promising tool in this context. In this work, we study three unique temporal financial networks: transactions in Mercari, an online marketplace, payments in a synthetic network generated by J.P. Morgan Chase, and payments and friendships among Venmo users. We consider the fraud detection problem on the Mercari and J.P. Morgan Chase networks, for which the ground truth is available. We show that temporal motifs offer superior performance to several baselines, including a previous method that considers simple graph features and two node embedding techniques (LINE and node2vec), while being practical in terms of runtime performance. For the Venmo network, we investigate the interplay between financial and social relations on three tasks: friendship prediction, vendor identification, and analysis of temporal cycles. For friendship prediction, temporal motifs yield better results than general heuristics, such as Jaccard and Adamic-Adar measures. We are also able to identify vendors with high accuracy and observe interesting patterns in rare motifs, such as temporal cycles. We believe that the analysis, datasets, and lessons from this work will be beneficial for future research on financial transaction networks.",
      "authors": [
        "Penghang Liu",
        "Bahadir Altun",
        "Rupam Acharyya",
        "Robert E. Tillman",
        "Shunya Kimura",
        "Naoki Masuda",
        "Ahmet Erdem Sar{\\i}y\\\"uce"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-18T21:22:57+00:00",
          "link": "https://arxiv.org/abs/2301.07791v1",
          "size": "1782kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:26:29+00:00",
          "link": "https://arxiv.org/abs/2301.07791v2",
          "size": "1736kb",
          "version": "v2"
        }
      ],
      "title": "Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.07791",
        "HTML": "https://arxiv.org/html/2301.07791v2",
        "PDF": "https://arxiv.org/pdf/2301.07791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies temporal motifs in financial networks and focuses on fraud detection and social relations analysis, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Fraud Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.16415",
      "abstract": "With the rapid application of unmanned aerial vehicles (UAVs) in urban areas, the identification and tracking of hovering UAVs have become critical challenges, significantly impacting the safety of aircraft take-off and landing operations. As a promising technology for 6G mobile systems, integrated sensing and communication (ISAC) can be used to detect high-mobility UAVs with a low deployment cost. The micro-Doppler signals from UAV rotors can be leveraged to address the detection of low-mobility and hovering UAVs using ISAC signals. However, determining whether the frame structure of the ISAC system can be used to identify UAVs, and how to accurately capture the weak rotor micro-Doppler signals of UAVs in complex environments, remain two challenging problems. This paper first proposes a novel frame structure for UAV micro-Doppler extraction and the representation of UAV micro-Doppler signals within the channel state information (CSI). Furthermore, to address complex environments and the interference caused by UAV body vibrations, the rotor micro-Doppler null space pursuit (rmD-NSP) algorithm and the feature extraction algorithm synchroextracting transform (SET) are designed to effectively separate UAV's rotor micro-Doppler signals and enhance their features in the spectrogram. Finally, both simulation and hardware testbed demonstrate that the proposed rmD-NSP algorithm enables the ISAC base station (BS) to accurately and completely extract UAV's rotor micro-Doppler signals. Within a 0.1s observation period, ISAC BS successfully captures eight rotations of the DJI M300 RTK UAV's rotor in urban environments. Compared to the existing AM-FM NSP and NSP signal decomposition algorithms, the integrity of the rotor micro-Doppler features is improved by 60%.",
      "authors": [
        "Jiachen Wei",
        "Dingyou Ma",
        "Feiyang He",
        "Qixun Zhang",
        "Zhiyong Feng",
        "Zhengfeng Liu",
        "Taohong Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-29T10:21:02+00:00",
          "link": "https://arxiv.org/abs/2408.16415v1",
          "size": "7591kb",
          "version": "v1"
        }
      ],
      "title": "UAV's Rotor Micro-Doppler Feature Extraction Using Integrated Sensing and Communication Signal: Algorithm Design and Testbed Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16415",
        "HTML": "https://arxiv.org/html/2408.16415",
        "PDF": "https://arxiv.org/pdf/2408.16415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with UAV rotor signal extraction using communication signals and doesn't address any LLM training data processing or engineering."
      },
      "tasks": [
        "Integrated sensing and communication",
        "ISAC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.10715",
      "abstract": "Multi-modal sensor fusion in Bird's Eye View (BEV) representation has become the leading approach for 3D object detection. However, existing methods often rely on depth estimators or transformer encoders to transform image features into BEV space, which reduces robustness or introduces significant computational overhead. Moreover, the insufficient geometric guidance in view transformation results in ray-directional misalignments, limiting the effectiveness of BEV representations. To address these challenges, we propose Efficient View Transformation (EVT), a novel 3D object detection framework that constructs a well-structured BEV representation, improving both accuracy and efficiency. Our approach focuses on two key aspects. First, Adaptive Sampling and Adaptive Projection (ASAP), which utilizes LiDAR guidance to generate 3D sampling points and adaptive kernels, enables more effective transformation of image features into BEV space and a refined BEV representation. Second, an improved query-based detection framework, incorporating group-wise mixed query selection and geometry-aware cross-attention, effectively captures both the common properties and the geometric structure of objects in the transformer decoder. On the nuScenes test set, EVT achieves state-of-the-art performance of 75.3% NDS with real-time inference speed.",
      "authors": [
        "Yongjin Lee",
        "Hyeon-Mun Jeong",
        "Yurim Jeon",
        "Sanghyun Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-16T06:11:10+00:00",
          "link": "https://arxiv.org/abs/2411.10715v1",
          "size": "2398kb",
          "version": "v1"
        },
        {
          "date": "2024-11-19T09:07:18+00:00",
          "link": "https://arxiv.org/abs/2411.10715v2",
          "size": "2397kb",
          "version": "v2"
        },
        {
          "date": "2025-03-26T05:34:52+00:00",
          "link": "https://arxiv.org/abs/2411.10715v3",
          "size": "2447kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T06:50:01+00:00",
          "link": "https://arxiv.org/abs/2411.10715v4",
          "size": "2443kb",
          "version": "v4"
        }
      ],
      "title": "EVT: Efficient View Transformation for Multi-Modal 3D Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10715",
        "HTML": "https://arxiv.org/html/2411.10715v4",
        "PDF": "https://arxiv.org/pdf/2411.10715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on view transformation for 3D object detection, with no mention of LLM training data processing or dataset creation."
      },
      "tasks": [
        "3D Object Detection",
        "Decoder",
        "object-detection",
        "Object Detection",
        "Sensor Fusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.19470",
      "abstract": "Integrated sensing and communication (ISAC) is emerging as a pivotal technology for next-generation wireless networks. However, existing ISAC systems are based on fixed-position antennas (FPAs), which inevitably incur a loss in performance when balancing the trade-off between sensing and communication. Movable antenna (MA) technology offers promising potential to enhance ISAC performance by enabling flexible antenna movement. Nevertheless, exploiting more spatial channel variations requires larger antenna moving regions, which may invalidate the conventional far-field assumption for channels between transceivers. Therefore, this paper utilizes the MA to enhance sensing and communication capabilities in near-field ISAC systems, where a full-duplex base station (BS) is equipped with multiple transmit and receive MAs movable in large-size regions to simultaneously sense multiple targets and serve multiple uplink (UL) and downlink (DL) users for communication. We aim to maximize the weighted sum of sensing and communication rates (WSR) by jointly designing the transmit beamformers, sensing signal covariance matrices, receive beamformers, and MA positions at the BS, as well as the UL power allocation. The resulting optimization problem is challenging to solve. Thus, we propose an efficient two-layer random position (RP) algorithm to tackle it. In addition, to reduce movement delay and cost, we design an antenna position matching (APM) algorithm based on the greedy strategy to minimize the total MA movement distance. Extensive simulation results demonstrate the substantial performance improvement achieved by deploying MAs in near-field ISAC systems. Moreover, the results show the effectiveness of the proposed APM algorithm in reducing the antenna movement distance, which is helpful for energy saving and time overhead reduction for MA-aided near-field ISAC systems with large moving regions.",
      "authors": [
        "Jingze Ding",
        "Zijian Zhou",
        "Xiaodan Shao",
        "Bingli Jiao",
        "Rui Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T05:45:35+00:00",
          "link": "https://arxiv.org/abs/2412.19470v1",
          "size": "8410kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:27:38+00:00",
          "link": "https://arxiv.org/abs/2412.19470v2",
          "size": "5334kb",
          "version": "v2"
        }
      ],
      "title": "Movable Antenna-Aided Near-Field Integrated Sensing and Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19470",
        "HTML": "https://arxiv.org/html/2412.19470v2",
        "PDF": "https://arxiv.org/pdf/2412.19470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around improving integrated sensing and communication systems in wireless networks using movable antennas, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02188",
      "abstract": "Autonomous robot person-following (RPF) systems are crucial for personal assistance and security but suffer from target loss due to occlusions in dynamic, unknown environments. Current methods rely on pre-built maps and assume static environments, limiting their effectiveness in real-world settings. There is a critical gap in re-finding targets under topographic (e.g., walls, corners) and dynamic (e.g., moving pedestrians) occlusions. In this paper, we propose a novel heuristic-guided search framework that dynamically builds environmental maps while following the target and explicitly addresses these two types of occlusions through distinct mechanisms. For topographic occlusions, a belief-guided search field estimates the likelihood of the target's presence and guides search toward promising frontiers. For dynamic occlusions, an observation-based search strategy adaptively switches between a fluid-following field and an overtaking potential field based on occluder motion patterns. Our results demonstrate that the proposed method outperforms existing approaches in terms of search efficiency and success rates, both in simulations and real-world tests. Our target search method enhances the adaptability and reliability of RPF systems in unknown and dynamic environments, supporting their use in real-world applications.",
      "authors": [
        "Hanjing Ye",
        "Kuanqi Cai",
        "Yu Zhan",
        "Bingyi Xia",
        "Arash Ajoudani",
        "Hong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T01:50:50+00:00",
          "link": "https://arxiv.org/abs/2503.02188v1",
          "size": "11700kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:24:03+00:00",
          "link": "https://arxiv.org/abs/2503.02188v2",
          "size": "23836kb",
          "version": "v2"
        }
      ],
      "title": "RPF-Search: Field-based Search for Robot Person Following in Unknown Dynamic Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02188",
        "HTML": "https://arxiv.org/html/2503.02188v2",
        "PDF": "https://arxiv.org/pdf/2503.02188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing robot person-following systems through heuristic-guided search frameworks in dynamic environments, without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23182",
      "abstract": "Generative machine learning models offer a powerful framework for therapeutic design by efficiently exploring large spaces of biological sequences enriched for desirable properties. Unlike supervised learning methods, which require both positive and negative labeled data, generative models such as LSTMs can be trained solely on positively labeled sequences, for example, high-affinity antibodies. This is particularly advantageous in biological settings where negative data are scarce, unreliable, or biologically ill-defined. However, the lack of attribution methods for generative models has hindered the ability to extract interpretable biological insights from such models. To address this gap, we developed Generative Attribution Metric Analysis (GAMA), an attribution method for autoregressive generative models based on Integrated Gradients. We assessed GAMA using synthetic datasets with known ground truths to characterize its statistical behavior and validate its ability to recover biologically relevant features. We further demonstrated the utility of GAMA by applying it to experimental antibody-antigen binding data. GAMA enables model interpretability and the validation of generative sequence design strategies without the need for negative training data.",
      "authors": [
        "Robert Frank",
        "Michael Widrich",
        "Rahmad Akbar",
        "G\\\"unter Klambauer",
        "Geir Kjetil Sandve",
        "Philippe A. Robert",
        "Victor Greiff"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:50:46+00:00",
          "link": "https://arxiv.org/abs/2506.23182v1",
          "size": "5863kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T14:05:02+00:00",
          "link": "https://arxiv.org/abs/2506.23182v2",
          "size": "5863kb",
          "version": "v2"
        }
      ],
      "title": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23182",
        "PDF": "https://arxiv.org/pdf/2506.23182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an attribution method for generative models named GAMA, which is aimed at improving model interpretability using positive-only data. It does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08342",
      "abstract": "Automatic n-gram based metrics such as ROUGE are widely used for evaluating generative tasks such as summarization. While these metrics are considered indicative (even if imperfect) of human evaluation for English, their suitability for other languages remains unclear. To address this, we systematically assess evaluation metrics for generation both n-gram-based and neural based to evaluate their effectiveness across languages and tasks. Specifically, we design a large-scale evaluation suite across eight languages from four typological families: agglutinative, isolating, low-fusional, and high-fusional, spanning both low- and high-resource settings, to analyze their correlation with human judgments. Our findings highlight the sensitivity of evaluation metrics to the language type. For example, in fusional languages, n-gram-based metrics show lower correlation with human assessments compared to isolating and agglutinative languages. We also demonstrate that proper tokenization can significantly mitigate this issue for morphologically rich fusional languages, sometimes even reversing negative trends. Additionally, we show that neural-based metrics specifically trained for evaluation, such as COMET, consistently outperform other neural metrics and better correlate with human judgments in low-resource languages. Overall, our analysis highlights the limitations of n-gram metrics for fusional languages and advocates for greater investment in neural-based metrics trained for evaluation tasks.",
      "authors": [
        "Itai Mondshine",
        "Tzuf Paz-Argaman",
        "Reut Tsarfaty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:44:52+00:00",
          "link": "https://arxiv.org/abs/2507.08342v1",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "title": "Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08342",
        "HTML": "https://arxiv.org/html/2507.08342v1",
        "PDF": "https://arxiv.org/pdf/2507.08342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating metrics for multilingual summarization and improving correlation with human judgments, which does not involve LLM training data creation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08445",
      "abstract": "Despite the remarkable progress of Large Language Models (LLMs), their performance in question answering (QA) remains limited by the lack of domain-specific and up-to-date knowledge. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external information, often from graph-structured data. However, existing graph-based RAG methods suffer from poor graph quality due to incomplete extraction and insufficient utilization of query information during retrieval. To overcome these limitations, we propose CUE-RAG, a novel approach that introduces (1) a multi-partite graph index incorporates text Chunks, knowledge Units, and Entities to capture semantic content at multiple levels of granularity, (2) a hybrid extraction strategy that reduces LLM token usage while still producing accurate and disambiguated knowledge units, and (3) Q-Iter, a query-driven iterative retrieval strategy that enhances relevance through semantic search and constrained graph traversal. Experiments on three QA benchmarks show that CUE-RAG significantly outperforms state-of-the-art baselines, achieving up to 99.33% higher Accuracy and 113.51% higher F1 score while reducing indexing costs by 72.58%. Remarkably, CUE-RAG matches or outperforms baselines even without using an LLM for indexing. These results demonstrate the effectiveness and cost-efficiency of CUE-RAG in advancing graph-based RAG systems.",
      "authors": [
        "Yaodong Su",
        "Yixiang Fang",
        "Yingli Zhou",
        "Quanqing Xu",
        "Chuanhui Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:36:45+00:00",
          "link": "https://arxiv.org/abs/2507.08445v1",
          "size": "597kb",
          "version": "v1"
        }
      ],
      "title": "CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08445",
        "HTML": "https://arxiv.org/html/2507.08445v1",
        "PDF": "https://arxiv.org/pdf/2507.08445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces CUE-RAG, which improves graph-based RAG methods by incorporating better data extraction and retrieval strategies, focusing on reducing token usage and enhancing semantic search, directly contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08796",
      "abstract": "What should a function that extrapolates beyond known input/output examples look like? This is a tricky question to answer in general, as any function matching the outputs on those examples can in principle be a correct extrapolant. We argue that a \"good\" extrapolant should follow certain kinds of rules, and here we study a particularly appealing criterion for rule-following in list functions: that the function should behave predictably even when certain elements are removed. In functional programming, a standard way to express such removal operations is by using a filter function. Accordingly, our paper introduces a new semantic class of functions -- the filter equivariant functions. We show that this class contains interesting examples, prove some basic theorems about it, and relate it to the well-known class of map equivariant functions. We also present a geometric account of filter equivariants, showing how they correspond naturally to certain simplicial structures. Our highlight result is the amalgamation algorithm, which constructs any filter-equivariant function's output by first studying how it behaves on sublists of the input, in a way that extrapolates perfectly.",
      "authors": [
        "Owen Lewis",
        "Neil Ghani",
        "Andrew Dudzik",
        "Christos Perivolaropoulos",
        "Razvan Pascanu",
        "Petar Veli\\v{c}kovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:57:16+00:00",
          "link": "https://arxiv.org/abs/2507.08796v1",
          "size": "105kb",
          "version": "v1"
        }
      ],
      "title": "Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08796",
        "HTML": "https://arxiv.org/html/2507.08796v1",
        "PDF": "https://arxiv.org/pdf/2507.08796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the theoretical framework of filter-equivariant functions and their properties, without addressing any aspects of processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.16522",
      "abstract": "Deep learning-based informative band selection methods on hyperspectral images (HSI) recently have gained intense attention to eliminate spectral correlation and redundancies. However, the existing deep learning-based methods either need additional post-processing strategies to select the descriptive bands or optimize the model indirectly, due to the parameterization inability of discrete variables for the selection procedure. To overcome these limitations, this work proposes a novel end-to-end network for informative band selection. The proposed network is inspired by the advances in concrete autoencoder (CAE) and dropout feature ranking strategy. Different from the traditional deep learning-based methods, the proposed network is trained directly given the required band subset eliminating the need for further post-processing. Experimental results on four HSI scenes show that the proposed dropout CAE achieves substantial and effective performance levels outperforming the competing methods.",
      "authors": [
        "Lei Xu",
        "Mete Ahishali",
        "and Moncef Gabbouj"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-29T19:53:17+00:00",
          "link": "https://arxiv.org/abs/2401.16522v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Dropout Concrete Autoencoder for Band Selection on HSI Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.16522",
        "HTML": "https://arxiv.org/html/2401.16522",
        "PDF": "https://arxiv.org/pdf/2401.16522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses deep learning methods for band selection in hyperspectral image processing, which are unrelated to LLM training data processes or improvements."
      },
      "tasks": [
        "Deep Learning",
        "Descriptive"
      ],
      "repo_urls": [
        "https://github.com/leixuai/hyperspectral"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20550",
      "abstract": "Let $G$ be a connected graph with $N$ vertices. Let $k$ be the number of vertices in a longest path of $G$ such that every vertex on the path is a cut vertex of $G$, and every intermediate vertex of the path is a degree-two vertex of $G$. Let $k$ be the number of vertices of such a longest path of $T$ that every vertex of the path is a cut vertex and that every intermediate vertex of the path is a degree-two vertex of $T$. Let $P=\\{1,\\ldots,n\\}$ be a set of pebbles with $n+k < N$. A configuration of $P$ on $G$ is defined as a function $f$ from $V(G)$ to $\\{0, 1, \\ldots, n \\}$ with $|f^{-1}(i)| = 1$ for $1 \\le i \\le n$, where $f^{-1}(i)$ is a vertex occupied with the $i$th pebble for $1 \\le i \\le n$ and $f^{-1}(0)$ is a set of unoccupied vertices. A move is defined as shifting a pebble from a vertex to some unoccupied neighbor. The pebble motion problem on the pair $(G,P)$ is to decide whether a given configuration of pebbles is reachable from another by executing a sequence of moves. In this paper, we show that the length of the shortest solution sequence of the pebble motion problem on the pair $(G,P)$ is in $O(Nn + n^2 \\log(\\min\\{n,k\\}))$ if $G$ is a $N$-vertex tree, and it is in $O(N^2 + \\frac{n^3}{N-n} + n^2 \\log(\\min\\{n,N-n\\}))$ if $G$ is a connected general $N$-vertex graph. We provide an algorithm that can obtain a solution sequence of lengths that satisfy these orders, with the same computational complexity as the order of the length.\n  Keywords: pebble motion, motion planning, multi-agent path finding, $15$-puzzle, tree",
      "authors": [
        "Tomoki Nakamigawa and Tadashi Sakuma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T13:46:44+00:00",
          "link": "https://arxiv.org/abs/2503.20550v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T10:06:44+00:00",
          "link": "https://arxiv.org/abs/2503.20550v2",
          "size": "117kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T14:00:13+00:00",
          "link": "https://arxiv.org/abs/2503.20550v3",
          "size": "119kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T10:37:26+00:00",
          "link": "https://arxiv.org/abs/2503.20550v4",
          "size": "120kb",
          "version": "v4"
        }
      ],
      "title": "On the order of the shortest solution sequences for the pebble motion problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20550",
        "HTML": "https://arxiv.org/html/2503.20550v4",
        "PDF": "https://arxiv.org/pdf/2503.20550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the mathematical properties and algorithms related to pebble motion problems on graphs, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07787",
      "abstract": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72/100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation.",
      "authors": [
        "Elizabeth Hilliard",
        "Akshaya Jagadeesh",
        "Alex Cook",
        "Steele Billings",
        "Nicholas Skytland",
        "Alicia Llewellyn",
        "Jackson Paull",
        "Nathan Paull",
        "Nolan Kurylo",
        "Keatra Nesbitt",
        "Robert Gruenewald",
        "Anthony Jantzi",
        "Omar Chavez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:09:53+00:00",
          "link": "https://arxiv.org/abs/2507.07787v1",
          "size": "1130kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T04:57:41+00:00",
          "link": "https://arxiv.org/abs/2507.07787v2",
          "size": "1130kb",
          "version": "v2"
        }
      ],
      "title": "Measuring AI Alignment with Human Flourishing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07787",
        "HTML": "https://arxiv.org/html/2507.07787v2",
        "PDF": "https://arxiv.org/pdf/2507.07787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for AI alignment with human flourishing and evaluates language models but does not discuss training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08003",
      "abstract": "We contribute a comprehensive dataset to study user attention and purchasing behavior on Search Engine Result Pages (SERPs). Previous work has relied on mouse movements as a low-cost large-scale behavioral proxy but also has relied on self-reported ground-truth labels, collected at post-task, which can be inaccurate and prone to biases. To address this limitation, we use an eye tracker to construct an objective ground-truth of continuous visual attention. Our dataset comprises 2,776 transactional queries on Google SERPs, collected from 47 participants, and includes: (1) HTML source files, with CSS and images; (2) rendered SERP screenshots; (3) eye movement data; (4) mouse movement data; (5) bounding boxes of direct display and organic advertisements; and (6) scripts for further preprocessing the data. In this paper we provide an overview of the dataset and baseline experiments (classification tasks) that can inspire researchers about the different possibilities for future work.",
      "authors": [
        "Kayhan Latifzadeh",
        "Jacek Gwizdka",
        "Luis A. Leiva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T08:27:47+00:00",
          "link": "https://arxiv.org/abs/2507.08003v1",
          "size": "3242kb",
          "version": "v1"
        }
      ],
      "title": "A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08003",
        "HTML": "https://arxiv.org/html/2507.08003v1",
        "PDF": "https://arxiv.org/pdf/2507.08003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper details the creation of a dataset, describing the collection and preprocessing of mouse and eye movement data, indicating clear data processing steps relevant to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08100",
      "abstract": "In crowded environments, individuals must navigate around other occupants to reach their destinations. Understanding and controlling traffic flows in these spaces is relevant to coordinating robot swarms and designing infrastructure for dense populations. Here, we combine simulations, theory, and robotic experiments to study how noisy motion can disrupt traffic jams and enable flow as agents travel to individual goals. Above a critical noise level, large jams do not persist. From this observation, we analytically approximate the goal attainment rate as a function of the noise level, then solve for the optimal agent density and noise level that maximize the swarm's goal attainment rate. We perform robotic experiments to corroborate our simulated and theoretical results. Finally, we compare simple, local navigation approaches with a sophisticated but computationally costly central planner. A simple reactive scheme performs well up to moderate densities and is far more computationally efficient than a planner, suggesting lessons for real-world problems.",
      "authors": [
        "Lucy Liu",
        "Justin Werfel",
        "Federico Toschi",
        "L. Mahadevan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Soft Condensed Matter (cond-mat.soft)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:28:52+00:00",
          "link": "https://arxiv.org/abs/2507.08100v1",
          "size": "5595kb",
          "version": "v1"
        }
      ],
      "title": "Noise-Enabled Goal Attainment in Crowded Collectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08100",
        "HTML": "https://arxiv.org/html/2507.08100v1",
        "PDF": "https://arxiv.org/pdf/2507.08100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on noise-enabled goal attainment in crowded collectives with simulations and robotic experiments, which does not involve any aspect of processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08154",
      "abstract": "Machine learning has been proposed as a way to improve educational assessment by making fine-grained predictions about student performance and learning relationships between items. One challenge with many machine learning approaches is incorporating new items, as these approaches rely heavily on historical data. We develop Text-LENS by extending the LENS partial variational auto-encoder for educational assessment to leverage item text embeddings, and explore the impact on predictive performance and generalization to previously unseen items. We examine performance on two datasets: Eedi, a publicly available dataset that includes item content, and LLM-Sim, a novel dataset with test items produced by an LLM. We find that Text-LENS matches LENS' performance on seen items and improves upon it in a variety of conditions involving unseen items; it effectively learns student proficiency from and makes predictions about student performance on new items.",
      "authors": [
        "Arisha Khan and Nathaniel Li and Tori Shen and Anna N. Rafferty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:23:02+00:00",
          "link": "https://arxiv.org/abs/2507.08154v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "Just Read the Question: Enabling Generalization to New Assessment Items with Text Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08154",
        "HTML": "https://arxiv.org/html/2507.08154v1",
        "PDF": "https://arxiv.org/pdf/2507.08154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes leveraging LLM-generated test items for educational assessment but focuses mainly on the model performance and generalization processes rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08218",
      "abstract": "Out-of-context reasoning (OOCR) is a phenomenon in which fine-tuned LLMs exhibit surprisingly deep out-of-distribution generalization. Rather than learning shallow heuristics, they implicitly internalize and act on the consequences of observations scattered throughout the fine-tuning data. In this work, we investigate this phenomenon mechanistically and find that many instances of OOCR in the literature have a simple explanation: the LoRA fine-tuning essentially adds a constant steering vector, steering the model towards a general concept. This improves performance on the fine-tuning task and in many other concept-related domains, causing the surprising generalization. Moreover, we can directly train steering vectors for these tasks from scratch, which also induces OOCR. We find that our results hold even for a task that seems like it must involve conditional behavior (model backdoors); it turns out that unconditionally adding a steering vector is sufficient. Overall, our work presents one explanation of what gets learned during fine-tuning for OOCR tasks, contributing to the key question of why LLMs can reason out of context, an advanced capability that is highly relevant to their safe and reliable deployment.",
      "authors": [
        "Atticus Wang",
        "Joshua Engels",
        "Oliver Clive-Griffin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:47:05+00:00",
          "link": "https://arxiv.org/abs/2507.08218v1",
          "size": "631kb",
          "version": "v1"
        }
      ],
      "title": "Simple Mechanistic Explanations for Out-Of-Context Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08218",
        "HTML": "https://arxiv.org/html/2507.08218v1",
        "PDF": "https://arxiv.org/pdf/2507.08218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates mechanisms behind out-of-context reasoning in LLMs but does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.05401",
      "abstract": "Climate change communication on social media increasingly employs microtargeting strategies to effectively reach and influence specific demographic groups. This study presents a post-hoc analysis of microtargeting practices within climate campaigns by leveraging large language models (LLMs) to examine Facebook advertisements. Our analysis focuses on two key aspects: demographic targeting and fairness. We evaluate the ability of LLMs to accurately predict the intended demographic targets, such as gender and age group, achieving an overall accuracy of 88.55%. Furthermore, we instruct the LLMs to generate explanations for their classifications, providing transparent reasoning behind each decision. These explanations reveal the specific thematic elements used to engage different demographic segments, highlighting distinct strategies tailored to various audiences. Our findings show that young adults are primarily targeted through messages emphasizing activism and environmental consciousness, while women are engaged through themes related to caregiving roles and social advocacy. In addition to evaluating the effectiveness of LLMs in detecting microtargeted messaging, we conduct a comprehensive fairness analysis to identify potential biases in model predictions. Our findings indicate that while LLMs perform well overall, certain biases exist, particularly in the classification of senior citizens and male audiences. By showcasing the efficacy of LLMs in dissecting and explaining targeted communication strategies and by highlighting fairness concerns, this study provides a valuable framework for future research aimed at enhancing transparency, accountability, and inclusivity in social media-driven climate campaigns.",
      "authors": [
        "Tunazzina Islam",
        "Dan Goldwasser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T18:07:56+00:00",
          "link": "https://arxiv.org/abs/2410.05401v1",
          "size": "2187kb",
          "version": "v1"
        },
        {
          "date": "2025-04-23T23:04:25+00:00",
          "link": "https://arxiv.org/abs/2410.05401v2",
          "size": "1666kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T23:19:49+00:00",
          "link": "https://arxiv.org/abs/2410.05401v3",
          "size": "1933kb",
          "version": "v3"
        }
      ],
      "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05401",
        "HTML": "https://arxiv.org/html/2410.05401v3",
        "PDF": "https://arxiv.org/pdf/2410.05401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs to analyze microtargeting in social media ads but focuses on themes and strategies rather than LLM training data processing or data engineering operations."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04518",
      "abstract": "We introduce Dirichlet Process Posterior Sampling (DPPS), a Bayesian non-parametric algorithm for multi-arm bandits based on Dirichlet Process (DP) priors. Like Thompson-sampling, DPPS is a probability-matching algorithm, i.e., it plays an arm based on its posterior-probability of being optimal. Instead of assuming a parametric class for the reward generating distribution of each arm, and then putting a prior on the parameters, in DPPS the reward generating distribution is directly modeled using DP priors. DPPS provides a principled approach to incorporate prior belief about the bandit environment, and in the noninformative limit of the DP posteriors (i.e. Bayesian Bootstrap), we recover Non Parametric Thompson Sampling (NPTS), a popular non-parametric bandit algorithm, as a special case of DPPS. We employ stick-breaking representation of the DP priors, and show excellent empirical performance of DPPS in challenging synthetic and real world bandit environments. Finally, using an information-theoretic analysis, we show non-asymptotic optimality of DPPS in the Bayesian regret setup.",
      "authors": [
        "Sumit Vashishtha",
        "Odalric-Ambrym Maillard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T15:06:01+00:00",
          "link": "https://arxiv.org/abs/2503.04518v1",
          "size": "6979kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:53:49+00:00",
          "link": "https://arxiv.org/abs/2503.04518v2",
          "size": "7026kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging priors on distribution functions for multi-arm bandits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04518",
        "HTML": "https://arxiv.org/html/2503.04518v2",
        "PDF": "https://arxiv.org/pdf/2503.04518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on introducing a Bayesian algorithm for multi-arm bandits by leveraging Dirichlet Process priors and does not discuss any aspect related to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03222",
      "abstract": "Biological and artificial learning systems alike confront the plasticity-stability dilemma. In the brain, neuromodulators such as acetylcholine and noradrenaline relieve this tension by tuning neuronal gain and inhibitory gating, balancing segregation and integration of circuits. Fed by dense cholinergic and noradrenergic projections from the ascending arousal system, layer-5 pyramidal neurons in the cerebral cortex offer a relevant substrate for understanding these dynamics. When distal dendritic signals coincide with back-propagating action potentials, calcium plateaus turn a single somatic spike into a high-gain burst, and interneuron inhibition sculpts the output. These properties make layer-5 cells gain-tunable amplifiers that translate neuromodulatory cues into flexible cortical activity. To capture this mechanism we developed a two-compartment Izhikevich model for pyramidal neurons and single-compartment somatostatin (SOM) and parvalbumin (PV) interneurons, linked by Gaussian connectivity and spike-timing-dependent plasticity (STDP). The soma and apical dendrite are so coupled that somatic spikes back-propagate, while dendritic plateaus can switch the soma from regular firing to bursting by shifting reset and adaptation variables. We show that stronger dendritic drive or tighter coupling raise gain by increasing the likelihood of calcium-triggered somatic bursts. In contrast, dendritic-targeted inhibition suppresses gain, while somatic-targeted inhibition raises the firing threshold of neighboring neurons, thus gating neurons output. Notably, bursting accelerates STDP, supporting rapid synaptic reconfiguration and flexibility. This suggests that brief gain pulses driven by neuromodulators could serve as an adaptive two-timescale optimization mechanism, effectively modulating the synaptic weight updates.",
      "authors": [
        "Alejandro Rodriguez-Garcia",
        "Christopher J. Whyte",
        "Brandon R. Munn",
        "Jie Mei",
        "James M. Shine",
        "Srikanth Ramaswamy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T23:29:29+00:00",
          "link": "https://arxiv.org/abs/2507.03222v1",
          "size": "4374kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:31:56+00:00",
          "link": "https://arxiv.org/abs/2507.03222v2",
          "size": "4374kb",
          "version": "v2"
        }
      ],
      "title": "The role of gain neuromodulation in layer-5 pyramidal neurons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03222",
        "HTML": "https://arxiv.org/html/2507.03222v2",
        "PDF": "https://arxiv.org/pdf/2507.03222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on neuromodulation in neurons and does not discuss any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07248",
      "abstract": "As the performance of large language models (LLMs) continues to advance, their adoption is expanding across a wide range of domains, including the medical field. The integration of LLMs into medical applications raises critical safety concerns, particularly due to their use by users with diverse roles, e.g. patients and clinicians, and the potential for model's outputs to directly affect human health. Despite the domain-specific capabilities of medical LLMs, prior safety evaluations have largely focused only on general safety benchmarks. In this paper, we introduce a safety evaluation protocol tailored to the medical domain in both patient user and clinician user perspectives, alongside general safety assessments and quantitatively analyze the safety of medical LLMs. We bridge a gap in the literature by building the PatientSafetyBench containing 466 samples over 5 critical categories to measure safety from the perspective of the patient. We apply our red-teaming protocols on the MediPhi model collection as a case study. To our knowledge, this is the first work to define safety evaluation criteria for medical LLMs through targeted red-teaming taking three different points of view - patient, clinician, and general user - establishing a foundation for safer deployment in medical domains.",
      "authors": [
        "Jean-Philippe Corbeil",
        "Minseon Kim",
        "Alessandro Sordoni",
        "Francois Beaulieu",
        "Paul Vozila"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:38:58+00:00",
          "link": "https://arxiv.org/abs/2507.07248v1",
          "size": "176kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:39:47+00:00",
          "link": "https://arxiv.org/abs/2507.07248v2",
          "size": "176kb",
          "version": "v2"
        }
      ],
      "title": "Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07248",
        "PDF": "https://arxiv.org/pdf/2507.07248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing safety evaluation protocols for medical LLMs, including the PatientSafetyBench for measuring safety, but does not involve processing LLM training data."
      },
      "models": [
        {
          "model_path": "microsoft/MediPhi-Instruct",
          "downloads": "39",
          "likes": "7",
          "trending_score": "7.0",
          "link": "https://huggingface.co/microsoft/MediPhi-Instruct"
        },
        {
          "model_path": "microsoft/MediPhi",
          "downloads": "30",
          "likes": "3",
          "trending_score": "3.0",
          "link": "https://huggingface.co/microsoft/MediPhi"
        },
        {
          "model_path": "microsoft/MediPhi-MedCode",
          "downloads": "15",
          "likes": "3",
          "trending_score": "3.0",
          "link": "https://huggingface.co/microsoft/MediPhi-MedCode"
        },
        {
          "model_path": "microsoft/MediPhi-Clinical",
          "downloads": "15",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/microsoft/MediPhi-Clinical"
        },
        {
          "model_path": "microsoft/MediPhi-Guidelines",
          "downloads": "17",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/microsoft/MediPhi-Guidelines"
        },
        {
          "model_path": "microsoft/MediPhi-PubMed",
          "downloads": "37",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/microsoft/MediPhi-PubMed"
        },
        {
          "model_path": "microsoft/MediPhi-MedWiki",
          "downloads": "14",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/microsoft/MediPhi-MedWiki"
        },
        {
          "model_path": "gabriellarson/MediPhi-Instruct-GGUF",
          "downloads": "212",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/gabriellarson/MediPhi-Instruct-GGUF"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08039",
      "abstract": "The advancements in the domain of LLMs in recent years have surprised many, showcasing their remarkable capabilities and diverse applications. Their potential applications in various real-world scenarios have led to significant research on their reliability and effectiveness. On the other hand, multimodal LLMs and Text-to-Image models have only recently gained prominence, especially when compared to text-only LLMs. Their reliability remains constrained due to insufficient research on assessing their performance and robustness. This paper aims to establish a comprehensive evaluation framework for Text-to-Image models, concentrating particularly on their adherence to prompts. We created a novel dataset that aimed to assess the robustness of these models in generating images that conform to the specified factors of variation in the input text prompts. Our evaluation studies present findings on three variants of Stable Diffusion models: Stable Diffusion 3 Medium, Stable Diffusion 3.5 Large, and Stable Diffusion 3.5 Large Turbo, and two variants of Janus models: Janus Pro 1B and Janus Pro 7B. We introduce a pipeline that leverages text descriptions generated by the gpt-4o model for our ground-truth images, which are then used to generate artificial images by passing these descriptions to the Text-to-Image models. We then pass these generated images again through gpt-4o using the same system prompt and compare the variation between the two descriptions. Our results reveal that these models struggle to create simple binary images with only two factors of variation: a simple geometric shape and its location. We also show, using pre-trained VAEs on our dataset, that they fail to generate images that follow our input dataset distribution.",
      "authors": [
        "Sujith Vemishetty",
        "Advitiya Arora",
        "Anupama Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:40:17+00:00",
          "link": "https://arxiv.org/abs/2507.08039v1",
          "size": "10533kb",
          "version": "v1"
        }
      ],
      "title": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08039",
        "HTML": "https://arxiv.org/html/2507.08039v1",
        "PDF": "https://arxiv.org/pdf/2507.08039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a novel dataset for evaluating text-to-image model robustness, but primarily focuses on evaluation methods rather than processing LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08284",
      "abstract": "We introduce a lightweight yet highly effective safety guardrail framework for language models, demonstrating that small-scale language models can achieve, and even surpass, the performance of larger counterparts in content moderation tasks. This is accomplished through high-fidelity synthetic data generation and adversarial training. The synthetic data generation process begins with human-curated seed data, which undergoes query augmentation and paraphrasing to create diverse and contextually rich examples. This augmented data is then subjected to multiple rounds of curation, ensuring high fidelity and relevance. Inspired by recent advances in the Generative Adversarial Network (GAN) architecture, our adversarial training employs reinforcement learning to guide a generator that produces challenging synthetic examples. These examples are used to fine-tune the safety classifier, enhancing its ability to detect and mitigate harmful content. Additionally, we incorporate strategies from recent research on efficient LLM training, leveraging the capabilities of smaller models to improve the performance of larger generative models. With iterative adversarial training and the generation of diverse, high-quality synthetic data, our framework enables small language models (SLMs) to serve as robust safety guardrails. This approach not only reduces computational overhead but also enhances resilience against adversarial attacks, offering a scalable and efficient solution for content moderation in AI systems.",
      "authors": [
        "Aleksei Ilin",
        "Gor Matevosyan",
        "Xueying Ma",
        "Vladimir Eremin",
        "Suhaa Dada",
        "Muqun Li",
        "Riyaaz Shaik",
        "Haluk Noyan Tokgozoglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:17:58+00:00",
          "link": "https://arxiv.org/abs/2507.08284v1",
          "size": "182kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08284",
        "PDF": "https://arxiv.org/pdf/2507.08284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's main contribution centers around synthetic data generation and iterative adversarial training, enhancing data quality for content moderation and model fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.02482",
      "abstract": "In modern deep neural networks, the learning dynamics of the individual neurons is often obscure, as the networks are trained via global optimization. Conversely, biological systems build on self-organized, local learning, achieving robustness and efficiency with limited global information. We here show how self-organization between individual artificial neurons can be achieved by designing abstract bio-inspired local learning goals. These goals are parameterized using a recent extension of information theory, Partial Information Decomposition (PID), which decomposes the information that a set of information sources holds about an outcome into unique, redundant and synergistic contributions. Our framework enables neurons to locally shape the integration of information from various input classes, i.e. feedforward, feedback, and lateral, by selecting which of the three inputs should contribute uniquely, redundantly or synergistically to the output. This selection is expressed as a weighted sum of PID terms, which, for a given problem, can be directly derived from intuitive reasoning or via numerical optimization, offering a window into understanding task-relevant local information processing. Achieving neuron-level interpretability while enabling strong performance using local learning, our work advances a principled information-theoretic foundation for local learning strategies.",
      "authors": [
        "Andreas C. Schneider",
        "Valentin Neuhaus",
        "David A. Ehrlich",
        "Abdullah Makkeh",
        "Alexander S. Ecker",
        "Viola Priesemann",
        "Michael Wibral"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T14:45:46+00:00",
          "link": "https://arxiv.org/abs/2412.02482v1",
          "size": "1223kb",
          "version": "v1"
        },
        {
          "date": "2024-12-05T11:50:40+00:00",
          "link": "https://arxiv.org/abs/2412.02482v2",
          "size": "1232kb",
          "version": "v2"
        },
        {
          "date": "2025-01-21T09:46:38+00:00",
          "link": "https://arxiv.org/abs/2412.02482v3",
          "size": "1232kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T13:19:43+00:00",
          "link": "https://arxiv.org/abs/2412.02482v4",
          "size": "911kb",
          "version": "v4"
        }
      ],
      "title": "What should a neuron aim for? Designing local objective functions based on information theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02482",
        "HTML": "https://arxiv.org/html/2412.02482v4",
        "PDF": "https://arxiv.org/pdf/2412.02482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing local objective functions for individual neurons based on information theory, without discussing any aspect of processing LLM training data."
      },
      "tasks": [
        "global-optimization"
      ],
      "repo_urls": [
        "https://github.com/priesemann-group/infomorphic_networks"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08047",
      "abstract": "Multilayer Extreme Learning Machine (ML-ELM) and its variants have proven to be an effective technique for the classification of different natural signals such as audio, video, acoustic and images. In this paper, a Hybrid Multilayer Extreme Learning Machine (HML-ELM) that is based on ELM-based autoencoder (ELM-AE) and an Interval Type-2 fuzzy Logic theory is suggested for active image classification and applied to Unmanned Aerial Vehicles (UAVs). The proposed methodology is a hierarchical ELM learning framework that consists of two main phases: 1) self-taught feature extraction and 2) supervised feature classification. First, unsupervised multilayer feature encoding is achieved by stacking a number of ELM-AEs, in which input data is projected into a number of high-level representations. At the second phase, the final features are classified using a novel Simplified Interval Type-2 Fuzzy ELM (SIT2-FELM) with a fast output reduction layer based on the SC algorithm; an improved version of the algorithm Center of Sets Type Reducer without Sorting Requirement (COSTRWSR). To validate the efficiency of the HML-ELM, two types of experiments for the classification of images are suggested. First, the HML-ELM is applied to solve a number of benchmark problems for image classification. Secondly, a number of real experiments to the active classification and transport of four different objects between two predefined locations using a UAV is implemented. Experiments demonstrate that the proposed HML-ELM delivers a superior efficiency compared to other similar methodologies such as ML-ELM, Multilayer Fuzzy Extreme Learning Machine (ML-FELM) and ELM.",
      "authors": [
        "Rolando A.Hernandez-Hernandez",
        "Adrian Rubio-Solis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:02:46+00:00",
          "link": "https://arxiv.org/abs/2507.08047v1",
          "size": "2315kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid Multilayer Extreme Learning Machine for Image Classification with an Application to Quadcopters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08047",
        "HTML": "https://arxiv.org/html/2507.08047v1",
        "PDF": "https://arxiv.org/pdf/2507.08047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a hybrid extreme learning machine for image classification, unrelated to LLM training data processing or data engineering for textual datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08312",
      "abstract": "The rapid advancement of quantum computing poses a critical threat to classical cryptographic algorithms such as RSA and ECC, particularly in Internet of Things (IoT) devices, where secure communication is essential but often constrained by limited computational resources. This paper investigates the feasibility of deploying post-quantum cryptography (PQC) algorithms on resource-constrained devices. In particular, we implement three PQC algorithms -- BIKE, CRYSTALS-Kyber, and HQC -- on a lightweight IoT platform built with Raspberry Pi devices. Leveraging the Open Quantum Safe (\\texttt{liboqs}) library in conjunction with \\texttt{mbedTLS}, we develop quantum-secure key exchange protocols, and evaluate their performance in terms of computational overhead, memory usage, and energy consumption for quantum secure communication. Experimental results demonstrate that the integration of PQC algorithms on constrained hardware is practical, reinforcing the urgent need for quantum-resilient cryptographic frameworks in next-generation IoT devices. The implementation of this paper is available at https://iqsec-lab.github.io/PQC-IoT/.",
      "authors": [
        "Jesus Lopez",
        "Viviana Cadena",
        "Mohammad Saidur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:03:19+00:00",
          "link": "https://arxiv.org/abs/2507.08312v1",
          "size": "12346kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Post-Quantum Cryptographic Algorithms on Resource-Constrained Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08312",
        "HTML": "https://arxiv.org/html/2507.08312v1",
        "PDF": "https://arxiv.org/pdf/2507.08312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on evaluating post-quantum cryptographic algorithms for IoT devices, with no mention of LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08352",
      "abstract": "This article studies the efficiency of secrecy data offloading for an unmanned aerial vehicle (UAV)-assisted nonorthogonal multiple access (NOMA)-integrated mobile-edge computing (MEC) incorporating wireless power transfer (WPT) within an Internet of Things (IoT) network. Specifically, this study assumes an UAV to function in dual roles: as a mobile computation platform and as an aerial power-supply station, offering substantial advantages for resource-constrained edge devices (EDs) in mitigating interference from an passive eavesdropper. To assess the system's secrecy offloading efficacy, the secrecy successful computation probability (SSCP) closed-formed formulation under Nakagami-m fading channel is derived. The theoretical results are conducted with a variety of parameters, thereby validating the precision of our analysis.",
      "authors": [
        "Gia-Huy Nguyen",
        "Anh-Nhat Nguyen",
        "Minh-Sang Nguyen",
        "Khai Nguyen",
        "Tung-Son Ngo",
        "Ngoc-Anh Bui",
        "Phuong-Chi Le",
        "Manh-Duc Hoang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:59:57+00:00",
          "link": "https://arxiv.org/abs/2507.08352v1",
          "size": "937kb",
          "version": "v1"
        }
      ],
      "title": "Secrecy Offloading Analysis of UAV-assisted NOMA-MEC Incorporating WPT in IoT Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08352",
        "HTML": "https://arxiv.org/html/2507.08352v1",
        "PDF": "https://arxiv.org/pdf/2507.08352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on secrecy offloading in UAV-assisted networks within an IoT setting, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08626",
      "abstract": "Recent advances in generative AI have made the creation of speech deepfakes widely accessible, posing serious challenges to digital trust. To counter this, various speech deepfake detection strategies have been proposed, including Person-of-Interest (POI) approaches, which focus on identifying impersonations of specific individuals by modeling and analyzing their unique vocal traits. Despite their excellent performance, the existing methods offer limited granularity and lack interpretability. In this work, we propose a POI-based speech deepfake detection method that operates at the phoneme level. Our approach decomposes reference audio into phonemes to construct a detailed speaker profile. In inference, phonemes from a test sample are individually compared against this profile, enabling fine-grained detection of synthetic artifacts. The proposed method achieves comparable accuracy to traditional approaches while offering superior robustness and interpretability, key aspects in multimedia forensics. By focusing on phoneme analysis, this work explores a novel direction for explainable, speaker-centric deepfake detection.",
      "authors": [
        "Davide Salvi",
        "Viola Negroni",
        "Sara Mandelli",
        "Paolo Bestagini",
        "Stefano Tubaro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:27:57+00:00",
          "link": "https://arxiv.org/abs/2507.08626v1",
          "size": "951kb",
          "version": "v1"
        }
      ],
      "title": "Phoneme-Level Analysis for Person-of-Interest Speech Deepfake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08626",
        "HTML": "https://arxiv.org/html/2507.08626v1",
        "PDF": "https://arxiv.org/pdf/2507.08626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deepfake detection strategies, particularly phoneme-level analysis for speech, and does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.04097",
      "abstract": "Graph partitioning has many applications in powersystems from decentralized state estimation to parallel simulation. Focusing on parallel simulation, optimal grid partitioning minimizes the idle time caused by different simulation times for the sub-networks and their components and reduces the overhead required to simulate the cuts. Partitioning a graph into two parts such that, for example, the cut is minimal and the subgraphs have equal size is an NP-hard problem. In this paper we show how optimal partitioning of a graph can be obtained using quantum annealing (QA). We show how to map the requirements for optimal splitting to a quadratic unconstrained binary optimization (QUBO) formulation and test the proposed formulation using a current D-Wave QPU. We show that the necessity to find an embedding of the QUBO on current D-Wave QPUs limits the problem size to under 200 buses and notably affects the time-to-solution. We finally discuss the implications on near-term implementation of QA in combination to traditional CPU or GPU based simulation.",
      "authors": [
        "Carsten Hartmann",
        "Junjie Zhang",
        "Carlos D. Gonzalez Calaza",
        "Thiemo Pesch",
        "Kristel Michielsen and Andrea Benigni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-07T21:28:26+00:00",
          "link": "https://arxiv.org/abs/2408.04097v1",
          "size": "758kb",
          "version": "v1"
        },
        {
          "date": "2025-01-16T17:34:10+00:00",
          "link": "https://arxiv.org/abs/2408.04097v2",
          "size": "1270kb",
          "version": "v2"
        }
      ],
      "title": "Quantum Annealing based Power Grid Partitioning for Parallel Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04097",
        "PDF": "https://arxiv.org/pdf/2408.04097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum annealing and graph partitioning for power grid simulation, which does not relate to LLM training data processing or improvement."
      },
      "tasks": [
        "graph partitioning",
        "State Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02380",
      "abstract": "We present \"Reciprocating Locks\", a novel mutual exclusion locking algorithm, targeting cache-coherent shared memory (CC), that enjoys a number of desirable properties. The doorway arrival phase and the release operation both run in constant-time. Waiting threads use local spinning and only a single waiting element is required per thread, regardless of the number of locks a thread might hold at a given time. While our lock does not provide strict FIFO admission, it bounds bypass and has strong anti-starvation properties. The lock is compact, space efficient, and has been intentionally designed to be readily usable in real-world general purpose computing environments such as the linux kernel, pthreads, or C++. We show the lock exhibits high throughput under contention and low latency in the uncontended case. The performance of Reciprocating Locks is competitive with and often better than the best state-of-the-art scalable spin locks.",
      "authors": [
        "Dave Dice",
        "Alex Kogan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-04T20:59:34+00:00",
          "link": "https://arxiv.org/abs/2501.02380v1",
          "size": "223kb",
          "version": "v1"
        },
        {
          "date": "2025-01-12T20:08:46+00:00",
          "link": "https://arxiv.org/abs/2501.02380v2",
          "size": "238kb",
          "version": "v2"
        },
        {
          "date": "2025-01-14T20:04:15+00:00",
          "link": "https://arxiv.org/abs/2501.02380v3",
          "size": "239kb",
          "version": "v3"
        },
        {
          "date": "2025-01-25T20:50:22+00:00",
          "link": "https://arxiv.org/abs/2501.02380v4",
          "size": "240kb",
          "version": "v4"
        },
        {
          "date": "2025-01-29T16:44:27+00:00",
          "link": "https://arxiv.org/abs/2501.02380v5",
          "size": "242kb",
          "version": "v5"
        },
        {
          "date": "2025-05-06T19:28:56+00:00",
          "link": "https://arxiv.org/abs/2501.02380v6",
          "size": "286kb",
          "version": "v6"
        },
        {
          "date": "2025-05-15T13:48:40+00:00",
          "link": "https://arxiv.org/abs/2501.02380v7",
          "size": "287kb",
          "version": "v7"
        },
        {
          "date": "2025-06-02T17:46:50+00:00",
          "link": "https://arxiv.org/abs/2501.02380v8",
          "size": "205kb",
          "version": "v8"
        },
        {
          "date": "2025-07-11T14:27:25+00:00",
          "link": "https://arxiv.org/abs/2501.02380v9",
          "size": "172kb",
          "version": "v9"
        }
      ],
      "title": "Reciprocating Locks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02380",
        "PDF": "https://arxiv.org/pdf/2501.02380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focused on mutual exclusion algorithms for locking in shared memory environments, this paper does not discuss LLM training data processing or any contributions toward enhancing data quality or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02494",
      "abstract": "We consider the distributionally robust optimization (DRO) model of principal component analysis (PCA) to account for uncertainty in the underlying probability distribution. The resulting formulation leads to a nonsmooth constrained min-max optimization problem, where the ambiguity set captures the distributional uncertainty by the type-$2$ Wasserstein distance. We prove that the inner maximization problem admits a closed-form optimal value. This explicit characterization equivalently reformulates the original DRO model into a minimization problem on the Stiefel manifold with intricate nonsmooth terms, a challenging formulation beyond the reach of existing algorithms. To address this issue, we devise an efficient smoothing manifold proximal gradient algorithm. Our analysis establishes Riemannian gradient consistency and global convergence of our algorithm to a stationary point of the nonsmooth minimization problem. We also provide the iteration complexity $O(\\epsilon^{-3})$ of our algorithm to achieve an $\\epsilon$-approximate stationary point. Finally, numerical experiments are conducted to validate the effectiveness and scalability of our algorithm, as well as to highlight the necessity and rationality of adopting the DRO model for PCA.",
      "authors": [
        "Lei Wang",
        "Xin Liu",
        "Xiaojun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T11:00:08+00:00",
          "link": "https://arxiv.org/abs/2503.02494v1",
          "size": "184kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T06:19:30+00:00",
          "link": "https://arxiv.org/abs/2503.02494v2",
          "size": "179kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Distributional Robustness in Principal Component Analysis by Wasserstein Distances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02494",
        "HTML": "https://arxiv.org/html/2503.02494v2",
        "PDF": "https://arxiv.org/pdf/2503.02494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around optimization for distributional robustness in PCA, with no mention of LLM training data processing or dataset creation."
      },
      "tasks": [
        "Riemannian optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.11319",
      "abstract": "This study develops and analyzes linear and nonlinear state space models for estimating the elemental composition of scrap steel used in steelmaking, with applications to Electric Arc Furnace (EAF) and Basic Oxygen Furnace (BOF) processes. The models incorporate mass balance equations and are fitted using a modified Kalman filter for linear cases and the Unscented Kalman Filter (UKF) for nonlinear cases. Using Cu and Cr as representative elements, we assess the sensitivity of model predictions to measurement noise in key process variables, including steel mass, steel composition, scrap input mass, slag mass, and iron oxide fraction in slag. Results show that the models are robust to moderate noise levels in most variables, particularly when errors are below $10\\%$. However, accuracy significantly deteriorates with noise in slag mass estimation. These findings highlight the practical feasibility and limitations of applying state space models for real-time scrap composition estimation in industrial settings.",
      "authors": [
        "Yiqing Zhou",
        "Karsten Naert",
        "Dirk Nuyens"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T15:59:42+00:00",
          "link": "https://arxiv.org/abs/2504.11319v1",
          "size": "3860kb",
          "version": "v1"
        }
      ],
      "title": "Sensitivity Analysis of State Space Models for Scrap Composition Estimation in EAF and BOF",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11319",
        "HTML": "https://arxiv.org/html/2504.11319",
        "PDF": "https://arxiv.org/pdf/2504.11319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with state space models for estimating scrap composition in steelmaking, unrelated to the processing of LLM training data."
      },
      "tasks": [
        "ARC",
        "State Space Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08599",
      "abstract": "We address the problem of reliable data transmission within a finite time horizon $T$ over a binary erasure channel with unknown erasure probability. We consider a feedback model wherein the transmitter can query the receiver infrequently and obtain the empirical erasure rate experienced by the latter. We aim to minimize a regret quantity, i.e. how much worse a strategy performs compared to an oracle who knows the probability of erasure, while operating at the same block error rate. A learning vs. exploitation dilemma manifests in this scenario -- specifically, we need to balance between (i) learning the erasure probability with reasonable accuracy and (ii) utilizing the channel to transmit as many information bits as possible. We propose two strategies: (i) a two-phase approach using rate estimation followed by transmission that achieves an $O({T}^{\\frac 23})$ regret using only one query, and (ii) a windowing strategy using geometrically-increasing window sizes that achieves an $O({\\sqrt{T}})$ regret using $O(\\log(T))$ queries.",
      "authors": [
        "Haricharan Balasundaram",
        "Krishna Jagannathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:47:16+00:00",
          "link": "https://arxiv.org/abs/2507.08599v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Transmit Over Unknown Erasure Channels with Empirical Erasure Rate Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08599",
        "HTML": "https://arxiv.org/html/2507.08599v1",
        "PDF": "https://arxiv.org/pdf/2507.08599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on data transmission strategies over erasure channels and does not address LLM training data processing or enhancement methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.03099",
      "abstract": "This article explores the integration of deep learning models into combinatorial optimization pipelines, specifically targeting NP-hard problems. Traditional exact algorithms for such problems often rely on heuristic criteria to guide the exploration of feasible solutions. In this work, we propose using neural networks to learn informative heuristics-most notably, an optimality score that estimates a solution's proximity to the optimum. This score is used to evaluate nodes within a branch-and-bound framework, enabling a more efficient traversal of the solution space. Focusing on the Traveling Salesman Problem, we describe two exact solvers-1-tree branch-and-bound and Concorde-and introduce a hybrid approach called Graph Convolutional Branch and Bound, which augments these solvers with a graph convolutional neural network along with a novel unsupervised training strategy that facilitates generalization to graphs of varying sizes without requiring labeled data. Empirical results demonstrate the effectiveness of the proposed method, showing a significant reduction in the number of explored branch-and-bound nodes and overall computational time.",
      "authors": [
        "Lorenzo Sciandra",
        "Roberto Esposito",
        "Andrea Cesare Grosso",
        "Laura Sacerdote and Cristina Zucca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-05T09:42:43+00:00",
          "link": "https://arxiv.org/abs/2406.03099v1",
          "size": "508kb",
          "version": "v1"
        },
        {
          "date": "2024-06-06T07:46:26+00:00",
          "link": "https://arxiv.org/abs/2406.03099v2",
          "size": "507kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T19:29:49+00:00",
          "link": "https://arxiv.org/abs/2406.03099v3",
          "size": "197kb",
          "version": "v3"
        }
      ],
      "title": "Graph Convolutional Branch and Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03099",
        "PDF": "https://arxiv.org/pdf/2406.03099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes using deep learning models to improve combinatorial optimization solvers, particularly for the Traveling Salesman Problem, without discussing any aspect of LLM training data processing or datasets."
      },
      "tasks": [
        "Traveling Salesman Problem"
      ],
      "repo_urls": [
        "https://github.com/LorenzoSciandra/GraphConvolutionalBranchandBound"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20487",
      "abstract": "Humanoid robots are drawing significant attention as versatile platforms for complex motor control, human-robot interaction, and general-purpose physical intelligence. However, achieving efficient whole-body control (WBC) in humanoids remains a fundamental challenge due to sophisticated dynamics, underactuation, and diverse task requirements. While learning-based controllers have shown promise for complex tasks, their reliance on labor-intensive and costly retraining for new scenarios limits real-world applicability. To address these limitations, behavior(al) foundation models (BFMs) have emerged as a new paradigm that leverages large-scale pre-training to learn reusable primitive skills and broad behavioral priors, enabling zero-shot or rapid adaptation to a wide range of downstream tasks. In this paper, we present a comprehensive overview of BFMs for humanoid WBC, tracing their development across diverse pre-training pipelines. Furthermore, we discuss real-world applications, current limitations, urgent challenges, and future opportunities, positioning BFMs as a key approach toward scalable and general-purpose humanoid intelligence. Finally, we provide a curated and long-term list of BFM papers and projects to facilitate more subsequent research, which is available at https://github.com/yuanmingqi/awesome-bfm-papers.",
      "authors": [
        "Mingqi Yuan",
        "Tao Yu",
        "Wenqi Ge",
        "Xiuyong Yao",
        "Huijiang Wang",
        "Jiayu Chen",
        "Xin Jin",
        "Bo Li",
        "Hua Chen",
        "Wei Zhang",
        "Wenjun Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T14:35:33+00:00",
          "link": "https://arxiv.org/abs/2506.20487v1",
          "size": "4847kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:52:10+00:00",
          "link": "https://arxiv.org/abs/2506.20487v2",
          "size": "6069kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20487",
        "HTML": "https://arxiv.org/html/2506.20487v2",
        "PDF": "https://arxiv.org/pdf/2506.20487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys behavioral foundation models for humanoid robots' control systems. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02358",
      "abstract": "Vanilla autoregressive image generation models generate visual tokens step-by-step, limiting their ability to capture holistic relationships among token sequences. Moreover, because most visual tokenizers map local image patches into latent tokens, global information is limited. To address this, we introduce \\textit{Hita}, a novel image tokenizer for autoregressive (AR) image generation. It introduces a holistic-to-local tokenization scheme with learnable holistic queries and local patch tokens. Hita incorporates two key strategies to better align with the AR generation process: 1) {arranging} a sequential structure with holistic tokens at the beginning, followed by patch-level tokens, and using causal attention to maintain awareness of previous tokens; and 2) adopting a lightweight fusion module before feeding the de-quantized tokens into the decoder to control information flow and prioritize holistic tokens. Extensive experiments show that Hita accelerates the training speed of AR generators and outperforms those trained with vanilla tokenizers, achieving \\textbf{2.59 FID} and \\textbf{281.9 IS} on the ImageNet benchmark. Detailed analysis of the holistic representation highlights its ability to capture global image properties, such as textures, materials, and shapes. Additionally, Hita also demonstrates effectiveness in zero-shot style transfer and image in-painting. The code is available at \\href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}.",
      "authors": [
        "Anlin Zheng",
        "Haochen Wang",
        "Yucheng Zhao",
        "Weipeng Deng",
        "Tiancai Wang",
        "Xiangyu Zhang and Xiaojuan Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:44:26+00:00",
          "link": "https://arxiv.org/abs/2507.02358v1",
          "size": "22118kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T15:10:39+00:00",
          "link": "https://arxiv.org/abs/2507.02358v2",
          "size": "22118kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T13:43:13+00:00",
          "link": "https://arxiv.org/abs/2507.02358v3",
          "size": "22118kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T09:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.02358v4",
          "size": "22118kb",
          "version": "v4"
        }
      ],
      "title": "Hita: Holistic Tokenizer for Autoregressive Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02358",
        "HTML": "https://arxiv.org/html/2507.02358v4",
        "PDF": "https://arxiv.org/pdf/2507.02358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on a novel image tokenizer for autoregressive image generation, which does not involve any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07878",
      "abstract": "Underwater image restoration algorithms seek to restore the color, contrast, and appearance of a scene that is imaged underwater. They are a critical tool in applications ranging from marine ecology and aquaculture to underwater construction and archaeology. While existing pixel-domain diffusion-based image restoration approaches are effective at restoring simple scenes with limited depth variation, they are computationally intensive and often generate unrealistic artifacts when applied to scenes with complex geometry and significant depth variation. In this work we overcome these limitations by combining a novel network architecture (SLURPP) with an accurate synthetic data generation pipeline. SLURPP combines pretrained latent diffusion models -- which encode strong priors on the geometry and depth of scenes -- with an explicit scene decomposition -- which allows one to model and account for the effects of light attenuation and backscattering. To train SLURPP we design a physics-based underwater image synthesis pipeline that applies varied and realistic underwater degradation effects to existing terrestrial image datasets. This approach enables the generation of diverse training data with dense medium/degradation annotations. We evaluate our method extensively on both synthetic and real-world benchmarks and demonstrate state-of-the-art performance. Notably, SLURPP is over 200X faster than existing diffusion-based methods while offering ~ 3 dB improvement in PSNR on synthetic benchmarks. It also offers compelling qualitative improvements on real-world data. Project website https://tianfwang.github.io/slurpp/.",
      "authors": [
        "Jiayi Wu",
        "Tianfu Wang",
        "Md Abu Bakr Siddique",
        "Md Jahidul Islam",
        "Cornelia Fermuller",
        "Yiannis Aloimonos",
        "Christopher A. Metzler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:02:07+00:00",
          "link": "https://arxiv.org/abs/2507.07878v1",
          "size": "34458kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T01:22:26+00:00",
          "link": "https://arxiv.org/abs/2507.07878v2",
          "size": "34458kb",
          "version": "v2"
        }
      ],
      "title": "Single-Step Latent Diffusion for Underwater Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07878",
        "HTML": "https://arxiv.org/html/2507.07878v2",
        "PDF": "https://arxiv.org/pdf/2507.07878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution by designing a physics-based underwater image synthesis pipeline, which applies realistic underwater degradation effects to generate diverse training data with annotations. This work significantly involves data generation and processing for training the model, making it relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.10012",
      "abstract": "While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view synthesis, its performance degrades with motion blur. In scenarios with rapid motion or low-light conditions, existing RGB-based deblurring methods struggle to model camera pose and radiance changes during exposure, reducing reconstruction accuracy. Event cameras, capturing continuous brightness changes during exposure, can effectively assist in modeling motion blur and improving reconstruction quality. Therefore, we propose Event-driven Bundle Adjusted Deblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D Gaussians from event streams and severely blurred images. This method jointly learns the parameters of these Gaussians while recovering camera motion trajectories during exposure time. Specifically, we first construct a blur loss function by synthesizing multiple latent sharp images during the exposure time, minimizing the difference between real and synthesized blurred images. Then we use event stream to supervise the light intensity changes between latent sharp images at any time within the exposure period, supplementing the light intensity dynamic changes lost in RGB images. Furthermore, we optimize the latent sharp images at intermediate exposure times based on the event-based double integral (EDI) prior, applying consistency constraints to enhance the details and texture information of the reconstructed images. Extensive experiments on synthetic and real-world datasets show that EBAD-Gaussian can achieve high-quality 3D scene reconstruction under the condition of blurred images and event stream inputs.",
      "authors": [
        "Yufei Deng",
        "Yuanjian Wang",
        "Rong Xiao",
        "Chenwei Tang",
        "Jizhe Zhou",
        "Jiahao Fan",
        "Deng Xiong",
        "Jiancheng Lv",
        "Huajin Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T09:17:00+00:00",
          "link": "https://arxiv.org/abs/2504.10012v1",
          "size": "10305kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T13:11:46+00:00",
          "link": "https://arxiv.org/abs/2504.10012v2",
          "size": "4220kb",
          "version": "v2"
        }
      ],
      "title": "EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10012",
        "HTML": "https://arxiv.org/html/2504.10012v2",
        "PDF": "https://arxiv.org/pdf/2504.10012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on novel view synthesis and deblurring techniques using event cameras, with no mention of processing or creating LLM training data."
      },
      "tasks": [
        "3D Scene Reconstruction",
        "Deblurring",
        "Novel View Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08110",
      "abstract": "Today, social media platforms are significant sources of news and political communication, but their role in spreading misinformation has raised significant concerns. In response, these platforms have implemented various content moderation strategies. One such method, Community Notes on X, relies on crowdsourced fact-checking and has gained traction, though it faces challenges such as partisan bias and delays in verification. This study explores an AI-assisted hybrid moderation framework in which participants receive AI-generated feedback -supportive, neutral, or argumentative -on their notes and are asked to revise them accordingly. The results show that incorporating feedback improves the quality of notes, with the most substantial gains resulting from argumentative feedback. This underscores the value of diverse perspectives and direct engagement in human-AI collective intelligence. The research contributes to ongoing discussions about AI's role in political content moderation, highlighting the potential of generative AI and the importance of informed design.",
      "authors": [
        "Saeedeh Mohammadi and Taha Yasseri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:52:50+00:00",
          "link": "https://arxiv.org/abs/2507.08110v1",
          "size": "2159kb",
          "version": "v1"
        }
      ],
      "title": "AI Feedback Enhances Community-Based Content Moderation through Engagement with Counterarguments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08110",
        "HTML": "https://arxiv.org/html/2507.08110v1",
        "PDF": "https://arxiv.org/pdf/2507.08110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates an AI-assisted moderation framework for social media content, focusing on enhancing feedback mechanisms rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08178",
      "abstract": "While multiple instance learning (MIL) has shown to be a promising approach for histopathological whole slide image (WSI) analysis, its reliance on permutation invariance significantly limits its capacity to effectively uncover semantic correlations between instances within WSIs. Based on our empirical and theoretical investigations, we argue that approaches that are not permutation-invariant but better capture spatial correlations between instances can offer more effective solutions. In light of these findings, we propose a novel alternative to existing MIL for WSI analysis by learning to restore the order of instances from their randomly shuffled arrangement. We term this task as cracking an instance jigsaw puzzle problem, where semantic correlations between instances are uncovered. To tackle the instance jigsaw puzzles, we propose a novel Siamese network solution, which is theoretically justified by optimal transport theory. We validate the proposed method on WSI classification and survival prediction tasks, where the proposed method outperforms the recent state-of-the-art MIL competitors. The code is available at https://github.com/xiwenc1/MIL-JigsawPuzzles.",
      "authors": [
        "Xiwen Chen",
        "Peijie Qiu",
        "Wenhui Zhu",
        "Hao Wang",
        "Huayu Li",
        "Xuanzhao Dong",
        "Xiaotong Sun",
        "Xiaobing Yu",
        "Yalin Wang",
        "Abolfazl Razi",
        "Aristeidis Sotiras"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:19:30+00:00",
          "link": "https://arxiv.org/abs/2507.08178v1",
          "size": "11805kb",
          "version": "v1"
        }
      ],
      "title": "Cracking Instance Jigsaw Puzzles: An Alternative to Multiple Instance Learning for Whole Slide Image Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08178",
        "HTML": "https://arxiv.org/html/2507.08178v1",
        "PDF": "https://arxiv.org/pdf/2507.08178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel approach for whole slide image analysis using deep learning techniques, which does not involve the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08280",
      "abstract": "In real-world data analysis, missingness distributional shifts between training and test input datasets frequently occur, posing a significant challenge to achieving robust prediction performance. In this study, we propose a novel deep learning framework designed to address such shifts in missingness distributions. We begin by introducing a set of mutual information-based conditions, called MI robustness conditions, which guide a prediction model to extract label-relevant information while remaining invariant to diverse missingness patterns, thereby enhancing robustness to unseen missingness scenarios at test-time. To make these conditions practical, we propose simple yet effective techniques to derive loss terms corresponding to each and formulate a final objective function, termed MIRRAMS(Mutual Information Regularization for Robustness Against Missingness Shifts). As a by-product, our analysis provides a theoretical interpretation of the principles underlying consistency regularization-based semi-supervised learning methods, such as FixMatch. Extensive experiments across various benchmark datasets show that MIRRAMS consistently outperforms existing baselines and maintains stable performance across diverse missingness scenarios. Moreover, our approach achieves state-of-the-art performance even without missing data and can be naturally extended to address semi-supervised learning tasks, highlighting MIRRAMS as a powerful, off-the-shelf framework for general-purpose learning.",
      "authors": [
        "Jihye Lee",
        "Minseo Kang",
        "and Dongha Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:03:30+00:00",
          "link": "https://arxiv.org/abs/2507.08280v1",
          "size": "135kb",
          "version": "v1"
        }
      ],
      "title": "MIRRAMS: Towards Training Models Robust to Missingness Distribution Shifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08280",
        "HTML": "https://arxiv.org/html/2507.08280v1",
        "PDF": "https://arxiv.org/pdf/2507.08280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with training models for robustness to missingness distribution shifts, but does not discuss explicit processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.02324",
      "abstract": "On-orbit servicing (OOS) activities will power the next big step for sustainable exploration and commercialization of space. Developing robotic capabilities for autonomous OOS operations is a priority for the space industry. Visual Servoing (VS) enables robots to achieve the precise manoeuvres needed for critical OOS missions by utilizing visual information for motion control. This article presents an overview of existing VS approaches for autonomous OOS operations with space manipulator systems (SMS). We divide the approaches according to their contribution to the typical phases of a robotic OOS mission: a) Recognition, b) Approach, and c) Contact. We also present a discussion on the reviewed VS approaches, identifying current trends. Finally, we highlight the challenges and areas for future research on VS techniques for robotic OOS.",
      "authors": [
        "Lina Mar\\'ia Amaya-Mej\\'ia",
        "Mohamed Ghita",
        "Jan Dentler",
        "Miguel Olivares-Mendez",
        "Carol Martinez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T22:36:11+00:00",
          "link": "https://arxiv.org/abs/2409.02324v1",
          "size": "1668kb",
          "version": "v1"
        }
      ],
      "title": "Visual Servoing for Robotic On-Orbit Servicing: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02324",
        "HTML": "https://arxiv.org/html/2409.02324",
        "PDF": "https://arxiv.org/pdf/2409.02324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey covers visual servoing techniques for robotic servicing missions in space, and does not pertain to processing of LLM training data or dataset creation."
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07499",
      "abstract": "Human pose estimation is a critical task in computer vision and sports biomechanics, with applications spanning sports science, rehabilitation, and biomechanical research. While significant progress has been made in monocular 3D pose estimation, current datasets often fail to capture the complex, high-acceleration movements typical of competitive sports. In this work, we introduce AthletePose3D, a novel dataset designed to address this gap. AthletePose3D includes 12 types of sports motions across various disciplines, with approximately 1.3 million frames and 165 thousand individual postures, specifically capturing high-speed, high-acceleration athletic movements. We evaluate state-of-the-art (SOTA) monocular 2D and 3D pose estimation models on the dataset, revealing that models trained on conventional datasets perform poorly on athletic motions. However, fine-tuning these models on AthletePose3D notably reduces the SOTA model mean per joint position error (MPJPE) from 214mm to 65mm-a reduction of over 69%. We also validate the kinematic accuracy of monocular pose estimations through waveform analysis, highlighting strong correlations in joint angle estimations but limitations in velocity estimation. Our work provides a comprehensive evaluation of monocular pose estimation models in the context of sports, contributing valuable insights for advancing monocular pose estimation techniques in high-performance sports environments. The dataset, code, and model checkpoints are available at: https://github.com/calvinyeungck/AthletePose3D",
      "authors": [
        "Calvin Yeung",
        "Tomohiro Suzuki",
        "Ryota Tanaka",
        "Zhuoer Yin",
        "Keisuke Fujii"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T16:16:02+00:00",
          "link": "https://arxiv.org/abs/2503.07499v1",
          "size": "17713kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T16:51:19+00:00",
          "link": "https://arxiv.org/abs/2503.07499v2",
          "size": "17707kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T08:21:23+00:00",
          "link": "https://arxiv.org/abs/2503.07499v3",
          "size": "17704kb",
          "version": "v3"
        }
      ],
      "title": "AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07499",
        "HTML": "https://arxiv.org/html/2503.07499v3",
        "PDF": "https://arxiv.org/pdf/2503.07499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset, AthletePose3D, with detailed data processing steps specifically designed to capture complex athletic movements, and demonstrates improved model fine-tuning results, which substantively involve processing training data."
      },
      "tasks": [
        "3D Human Pose Estimation",
        "3D Pose Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/calvinyeungck/athletepose3d"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17621",
      "abstract": "Reinforcement learning (RL) has emerged as a pivotal method for improving the reasoning capabilities of Large Language Models (LLMs). However, prevalent RL approaches such as Proximal Policy Optimization (PPO) and Group-Regularized Policy Optimization (GRPO) face critical limitations due to their reliance on sparse outcome-based rewards and inadequate mechanisms for incentivizing exploration. These limitations result in inefficient guidance for multi-step reasoning processes. Specifically, sparse reward signals fail to deliver effective or sufficient feedback, particularly for challenging problems. Furthermore, such reward structures induce systematic biases that prioritize exploitation of familiar trajectories over novel solution discovery. These shortcomings critically hinder performance in complex reasoning tasks, which inherently demand iterative refinement across ipntermediate steps. To address these challenges, we propose an Intrinsic Motivation guidEd exploratioN meThOd foR LLM Reasoning (i-MENTOR), a novel method designed to both deliver dense rewards and amplify explorations in the RL-based training paradigm. i-MENTOR introduces three key innovations: trajectory-aware exploration rewards that mitigate bias in token-level strategies while maintaining computational efficiency; dynamic reward scaling to stabilize exploration and exploitation in large action spaces; and advantage-preserving reward implementation that maintains advantage distribution integrity while incorporating exploratory guidance. Experiments across three public datasets demonstrate i-MENTOR's effectiveness with a 22.39% improvement on the difficult dataset Countdown-4.",
      "authors": [
        "Jingtong Gao",
        "Ling Pan",
        "Yejing Wang",
        "Rui Zhong",
        "Chi Lu",
        "Qingpeng Cai",
        "Peng Jiang",
        "Xiangyu Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T08:30:28+00:00",
          "link": "https://arxiv.org/abs/2505.17621v1",
          "size": "2063kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T04:06:17+00:00",
          "link": "https://arxiv.org/abs/2505.17621v2",
          "size": "2074kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T02:23:39+00:00",
          "link": "https://arxiv.org/abs/2505.17621v3",
          "size": "2064kb",
          "version": "v3"
        }
      ],
      "title": "Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17621",
        "HTML": "https://arxiv.org/html/2505.17621v3",
        "PDF": "https://arxiv.org/pdf/2505.17621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving LLM reasoning capabilities using reinforcement learning strategies and does not discuss aspects of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07521",
      "abstract": "Trajectory modeling of dense points usually employs implicit deformation fields, represented as neural networks that map coordinates to relate canonical spatial positions to temporal offsets. However, the inductive biases inherent in neural networks can hinder spatial coherence in ill-posed scenarios. Current methods focus either on enhancing encoding strategies for deformation fields, often resulting in opaque and less intuitive models, or adopt explicit techniques like linear blend skinning, which rely on heuristic-based node initialization. Additionally, the potential of implicit representations for interpolating sparse temporal signals remains under-explored. To address these challenges, we propose a spline-based trajectory representation, where the number of knots explicitly determines the degrees of freedom. This approach enables efficient analytical derivation of velocities, preserving spatial coherence and accelerations, while mitigating temporal fluctuations. To model knot characteristics in both spatial and temporal domains, we introduce a novel low-rank time-variant spatial encoding, replacing conventional coupled spatiotemporal techniques. Our method demonstrates superior performance in temporal interpolation for fitting continuous fields with sparse inputs. Furthermore, it achieves competitive dynamic scene reconstruction quality compared to state-of-the-art methods while enhancing motion coherence without relying on linear blend skinning or as-rigid-as-possible constraints.",
      "authors": [
        "Mingyang Song",
        "Yang Zhang",
        "Marko Mihajlovic",
        "Siyu Tang",
        "Markus Gross",
        "Tun\\c{c} Ozan Ayd{\\i}n"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:11:46+00:00",
          "link": "https://arxiv.org/abs/2507.07521v1",
          "size": "45702kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T12:49:53+00:00",
          "link": "https://arxiv.org/abs/2507.07521v2",
          "size": "45702kb",
          "version": "v2"
        }
      ],
      "title": "Spline Deformation Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07521",
        "HTML": "https://arxiv.org/html/2507.07521v2",
        "PDF": "https://arxiv.org/pdf/2507.07521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a spline-based trajectory representation for temporal interpolation but does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14734",
      "abstract": "In this paper, we solve the long-standing problem of designing I/O-efficient compressed indexes. Our solution broadly consists of generalizing suffix sorting and revisiting suffix tree path compression. In classic suffix trees, path compression works by replacing unary suffix trie paths with pairs of pointers to $T$, which must be available in the form of some random access oracle at query time. In our approach, instead, we (i) sort the suffix tree's leaves according to a more general priority function $\\pi$ (generalizing suffix sorting), (ii) we build a suffix tree path decomposition prioritizing the leftmost paths in such an order, and (iii) we path-compress the decomposition's paths as pointers to a small subset of the string's suffixes. At this point, we show that the colexicographically-sorted array of those pointers represents a new elegant, simple, and remarkably I/O-efficient compressed suffix tree. For instance, by taking $\\pi$ to be the lexicographic rank of $T$'s suffixes, we can compress the suffix tree topology in $O(r)$ space on top of a $n\\log\\sigma + O(\\log n)$-bits text representation while essentially matching the pattern matching I/O complexity of Weiner and McCreight's suffix tree. Another (more practical) solution is obtained by taking $\\pi$ to be the colexicographic rank of $T$'s prefixes and using a fully-compressed random access oracle. The resulting self-index allows us to locate all occurrences of a given query pattern in less space and orders of magnitude faster than the $r$-index.",
      "authors": [
        "Ruben Becker",
        "Davide Cenzato",
        "Travis Gagie",
        "Sung-Hwan Kim",
        "Ragnar Groot Koerkamp",
        "Giovanni Manzini",
        "Nicola Prezza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T17:15:08+00:00",
          "link": "https://arxiv.org/abs/2506.14734v1",
          "size": "667kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T20:02:01+00:00",
          "link": "https://arxiv.org/abs/2506.14734v2",
          "size": "584kb",
          "version": "v2"
        }
      ],
      "title": "Compressing Suffix Trees by Path Decompositions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14734",
        "HTML": "https://arxiv.org/html/2506.14734v2",
        "PDF": "https://arxiv.org/pdf/2506.14734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for compressing suffix trees, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08738",
      "abstract": "Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have shown promise in forecasting chaotic dynamical systems, such as the Lorenz-63 model and El Nino-Southern Oscillation. However, their reliance on fixed nonlinearities - polynomial expansions in NVAR or random feature maps in RC - limits their adaptability to high noise or real-world data. These methods also scale poorly in high-dimensional settings due to costly matrix inversion during readout computation. We propose an adaptive NVAR model that combines delay-embedded linear inputs with features generated by a shallow, learnable multi-layer perceptron (MLP). The MLP and linear readout are jointly trained using gradient-based optimization, enabling the model to learn data-driven nonlinearities while preserving a simple readout structure. Unlike standard NVAR, our approach avoids the need for an exhaustive and sensitive grid search over ridge and delay parameters. Instead, tuning is restricted to neural network hyperparameters, improving scalability. Initial experiments on chaotic systems tested under noise-free and synthetically noisy conditions showed that the adaptive model outperformed the standard NVAR in predictive accuracy and showed robust forecasting under noisy conditions with a lower observation frequency.",
      "authors": [
        "Azimov Sherkhon",
        "Susana Lopez-Moreno",
        "Eric Dolores-Cuenca",
        "Sieun Lee",
        "Sangil Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:40:10+00:00",
          "link": "https://arxiv.org/abs/2507.08738v1",
          "size": "13003kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08738",
        "HTML": "https://arxiv.org/html/2507.08738v1",
        "PDF": "https://arxiv.org/pdf/2507.08738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an adaptive model for forecasting chaotic time series using vector autoregression and reservoir computing. It does not address LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.18906",
      "abstract": "Unauthorized screen capturing and dissemination pose severe security threats such as data leakage and information theft. Several studies propose robust watermarking methods to track the copyright of Screen-Camera (SC) images, facilitating post-hoc certification against infringement. These techniques typically employ heuristic mathematical modeling or supervised neural network fitting as the noise layer, to enhance watermarking robustness against SC. However, both strategies cannot fundamentally achieve an effective approximation of SC noise. Mathematical simulation suffers from biased approximations due to the incomplete decomposition of the noise and the absence of interdependence among the noise components. Supervised networks require paired data to train the noise-fitting model, and it is difficult for the model to learn all the features of the noise. To address the above issues, we propose Simulation-to-Real (S2R). Specifically, an unsupervised noise layer employs unpaired data to learn the discrepancy between the modeled simulated noise distribution and the real-world SC noise distribution, rather than directly learning the mapping from sharp images to real-world images. Learning this transformation from simulation to reality is inherently simpler, as it primarily involves bridging the gap in noise distributions, instead of the complex task of reconstructing fine-grained image details. Extensive experimental results validate the efficacy of the proposed method, demonstrating superior watermark robustness and generalization compared to state-of-the-art methods.",
      "authors": [
        "Yufeng Wu",
        "Xin Liao",
        "Baowei Wang",
        "Han Fang",
        "Xiaoshuai Wu",
        "Guiling Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-26T12:42:57+00:00",
          "link": "https://arxiv.org/abs/2504.18906v1",
          "size": "2187kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T07:33:58+00:00",
          "link": "https://arxiv.org/abs/2504.18906v2",
          "size": "766kb",
          "version": "v2"
        }
      ],
      "title": "Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18906",
        "HTML": "https://arxiv.org/html/2504.18906v2",
        "PDF": "https://arxiv.org/pdf/2504.18906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concerns watermarking robustness for screen-captured images, with no mention of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07454",
      "abstract": "In this paper, we introduce a multi-robot system that integrates mapping, localization, and task and motion planning (TAMP) enabled by 3D scene graphs to execute complex instructions expressed in natural language. Our system builds a shared 3D scene graph incorporating an open-set object-based map, which is leveraged for multi-robot 3D scene graph fusion. This representation supports real-time, view-invariant relocalization (via the object-based map) and planning (via the 3D scene graph), allowing a team of robots to reason about their surroundings and execute complex tasks. Additionally, we introduce a planning approach that translates operator intent into Planning Domain Definition Language (PDDL) goals using a Large Language Model (LLM) by leveraging context from the shared 3D scene graph and robot capabilities. We provide an experimental assessment of the performance of our system on real-world tasks in large-scale, outdoor environments. A supplementary video is available at https://youtu.be/8xbGGOLfLAY.",
      "authors": [
        "Jared Strader",
        "Aaron Ray",
        "Jacob Arkin",
        "Mason B. Peterson",
        "Yun Chang",
        "Nathan Hughes",
        "Christopher Bradley",
        "Yi Xuan Jia",
        "Carlos Nieto-Granda",
        "Rajat Talak",
        "Chuchu Fan",
        "Luca Carlone",
        "Jonathan P. How",
        "Nicholas Roy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T06:02:34+00:00",
          "link": "https://arxiv.org/abs/2506.07454v1",
          "size": "4372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T23:26:07+00:00",
          "link": "https://arxiv.org/abs/2506.07454v2",
          "size": "4374kb",
          "version": "v2"
        }
      ],
      "title": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07454",
        "HTML": "https://arxiv.org/html/2506.07454v2",
        "PDF": "https://arxiv.org/pdf/2506.07454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses an LLM for translating operator intent into goals, it does not focus on processing or creating training data for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Motion Planning",
        "Task and Motion Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00557",
      "abstract": "In this paper, we propose a hybrid framework for Satisfiability Modulo the Theory of Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a two-dimensional cell-jump move, called \\emph{$2d$-cell-jump}, generalizing the key operation, cell-jump, of the local search method for SMT-NRA. Then, we propose an extended local search framework, named \\emph{$2d$-LS} (following the local search framework, LS, for SMT-NRA), integrating the model constructing satisfiability calculus (MCSAT) framework to improve search efficiency. To further improve the efficiency of MCSAT, we implement a recently proposed technique called \\emph{sample-cell projection operator} for MCSAT, which is well suited for CDCL-style search in the real domain and helps guide the search away from conflicting states. Finally, we present a hybrid framework for SMT-NRA integrating MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through information exchange. The experimental results demonstrate improvements in local search performance, highlighting the effectiveness of the proposed methods.",
      "authors": [
        "Tianyi Ding",
        "Haokun Li",
        "Xinpeng Ni",
        "Bican Xia",
        "Tianqi Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T08:27:29+00:00",
          "link": "https://arxiv.org/abs/2507.00557v1",
          "size": "3727kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:40:25+00:00",
          "link": "https://arxiv.org/abs/2507.00557v2",
          "size": "3575kb",
          "version": "v2"
        }
      ],
      "title": "A Hybrid SMT-NRA Solver: Integrating 2D Cell-Jump-Based Local Search, MCSAT and OpenCAD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00557",
        "HTML": "https://arxiv.org/html/2507.00557v2",
        "PDF": "https://arxiv.org/pdf/2507.00557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a hybrid framework for solving the SMT-NRA problem and focuses on improving search efficiency. It does not relate to LLM training data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08269",
      "abstract": "Dimensional synthesis of planar four-bar mechanisms is a challenging inverse problem in kinematics, requiring the determination of mechanism dimensions from desired motion specifications. We propose a data-driven framework that bypasses traditional equation-solving and optimization by leveraging supervised learning. Our method combines a synthetic dataset, an LSTM-based neural network for handling sequential precision points, and a Mixture of Experts (MoE) architecture tailored to different linkage types. Each expert model is trained on type-specific data and guided by a type-specifying layer, enabling both single-type and multi-type synthesis. A novel simulation metric evaluates prediction quality by comparing desired and generated motions. Experiments show our approach produces accurate, defect-free linkages across various configurations. This enables intuitive and efficient mechanism design, even for non-expert users, and opens new possibilities for scalable and flexible synthesis in kinematic design.",
      "authors": [
        "Woon Ryong Kim",
        "Jaeheun Jung",
        "Jeong Un Ha",
        "Donghun Lee",
        "Jae Kyung Shim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T02:32:29+00:00",
          "link": "https://arxiv.org/abs/2507.08269v1",
          "size": "1415kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Dimensional Synthesis of Diverse Planar Four-bar Function Generation Mechanisms via Direct Parameterization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08269",
        "HTML": "https://arxiv.org/html/2507.08269v1",
        "PDF": "https://arxiv.org/pdf/2507.08269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses dimensional synthesis of mechanisms through a data-driven framework for kinematic design, but does not make contributions to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08281",
      "abstract": "Byzantine fault-tolerant (BFT) web services provide critical integrity guarantees for distributed applications but face significant latency challenges that hinder interactive user experiences. We propose a novel two-layer architecture that addresses this fundamental tension between security and responsiveness in BFT systems. Our approach introduces a session-aware transaction buffer layer (Layer 2) that delivers immediate feedback to users through consensus simulation, while periodically committing batched operations to a fully Byzantine fault-tolerant consensus layer (Layer 1). By separating interactive operations from consensus finalization, our system achieves responsive user experiences of under 200ms, while maintaining strong BFT security guarantees. We demonstrate the efficacy of our architecture through a supply chain management implementation, where operators require both immediate feedback during multi-step workflows and tamper-proof record keeping. Our evaluation shows that our Layer 2 operations perform four times faster than the Layer 1 counterpart, while substantially preserving the end-to-end transaction integrity. Our approach enables BFT applications in domains previously considered impractical due to latency constraints, such as metaverse environments, where users require both responsive interaction and guaranteed state consistency.",
      "authors": [
        "Ahmad Zaki Akmal",
        "Azkario Rizky Pratama",
        "and Guntur Dharma Putra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T03:11:37+00:00",
          "link": "https://arxiv.org/abs/2507.08281v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Interactive Byzantine Fault-tolerant Web Services via Session-Based Consensus Decoupling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08281",
        "HTML": "https://arxiv.org/html/2507.08281v1",
        "PDF": "https://arxiv.org/pdf/2507.08281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a two-layer architecture for Byzantine fault-tolerant web services, focusing on security and responsiveness, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08468",
      "abstract": "This paper provides an experimental evaluation of the capability of large language models (LLMs) to assist in legal decision-making within the framework of Austrian and European Union value-added tax (VAT) law. In tax consulting practice, clients often describe cases in natural language, making LLMs a prime candidate for supporting automated decision-making and reducing the workload of tax professionals. Given the requirement for legally grounded and well-justified analyses, the propensity of LLMs to hallucinate presents a considerable challenge. The experiments focus on two common methods for enhancing LLM performance: fine-tuning and retrieval-augmented generation (RAG). In this study, these methods are applied on both textbook cases and real-world cases from a tax consulting firm to systematically determine the best configurations of LLM-based systems and assess the legal-reasoning capabilities of LLMs. The findings highlight the potential of using LLMs to support tax consultants by automating routine tasks and providing initial analyses, although current prototypes are not ready for full automation due to the sensitivity of the legal domain. The findings indicate that LLMs, when properly configured, can effectively support tax professionals in VAT tasks and provide legally grounded justifications for decisions. However, limitations remain regarding the handling of implicit client knowledge and context-specific documentation, underscoring the need for future integration of structured background information.",
      "authors": [
        "Marina Luketina and Andrea Benkel and Christoph G. Schuetz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:19:56+00:00",
          "link": "https://arxiv.org/abs/2507.08468v1",
          "size": "1070kb",
          "version": "v1"
        }
      ],
      "title": "Using Large Language Models for Legal Decision-Making in Austrian Value-Added Tax Law: An Experimental Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08468",
        "HTML": "https://arxiv.org/html/2507.08468v1",
        "PDF": "https://arxiv.org/pdf/2507.08468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses fine-tuning and retrieval-augmented generation (RAG) to evaluate LLM capabilities, it does not primarily contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08563",
      "abstract": "Accurate vehicle trajectory prediction is essential for ensuring safety and efficiency in fully autonomous driving systems. While existing methods primarily focus on modeling observed motion patterns and interactions with other vehicles, they often neglect the potential risks posed by the uncertain or aggressive behaviors of surrounding vehicles. In this paper, we propose a novel spatial-temporal risk-attentive trajectory prediction framework that incorporates a risk potential field to assess perceived risks arising from behaviors of nearby vehicles. The framework leverages a spatial-temporal encoder and a risk-attentive feature fusion decoder to embed the risk potential field into the extracted spatial-temporal feature representations for trajectory prediction. A risk-scaled loss function is further designed to improve the prediction accuracy of high-risk scenarios, such as short relative spacing. Experiments on the widely used NGSIM and HighD datasets demonstrate that our method reduces average prediction errors by 4.8% and 31.2% respectively compared to state-of-the-art approaches, especially in high-risk scenarios. The proposed framework provides interpretable, risk-aware predictions, contributing to more robust decision-making for autonomous driving systems.",
      "authors": [
        "Xinyi Ning",
        "Zilin Bian",
        "Kaan Ozbay",
        "Semiha Ergan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:05:35+00:00",
          "link": "https://arxiv.org/abs/2507.08563v1",
          "size": "759kb",
          "version": "v1"
        }
      ],
      "title": "STRAP: Spatial-Temporal Risk-Attentive Vehicle Trajectory Prediction for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08563",
        "HTML": "https://arxiv.org/html/2507.08563v1",
        "PDF": "https://arxiv.org/pdf/2507.08563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a trajectory prediction framework for autonomous driving, focusing on risk assessment in vehicle behaviors without any discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.12897",
      "abstract": "The astronomy communities are widely recognised as mature communities for their open science practices. However, while their data ecosystems are rather advanced and permit efficient data interoperability, there are still gaps between these ecosystems. Semantic artefacts (SAs) -- e.g., ontologies, thesauri, vocabularies or metadata schemas -- are a means to bridge that gap as they allow to semantically described the data and map the underlying concepts. The increasing use of SAs in astronomy presents challenges in description, selection, evaluation, trust, and mappings. The landscape remains fragmented, with SAs scattered across various registries in diverse formats and structures -- not yet fully developed or encoded with rich semantic web standards like OWL or SKOS -- and often with overlapping scopes. Enhancing data semantic interoperability requires common platforms to catalog, align, and facilitate the sharing of FAIR (Findable, Accessible, Interoperable and Reusable) SAs. In the frame of the FAIR-IMPACT project, we prototyped a SA catalogue for astronomy, heliophysics and planetary sciences. This exercise resulted in improved vocabulary and ontology management in the communities, and is now paving the way for better interdisciplinary data discovery and reuse. This article presents current practices in our discipline, reviews candidate SAs for such a catalogue, presents driving use cases and the perspective of a real production service for the astronomy community based on the OntoPortal technology, that will be called OntoPortal-Astro.",
      "authors": [
        "Baptiste Cecconi",
        "Laura Debisschop",
        "S\\'ebastien Derri\\`ere",
        "Mireille Louys",
        "Carmen Corre",
        "Nina Grau",
        "Cl\\'ement Jonquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T12:38:38+00:00",
          "link": "https://arxiv.org/abs/2504.12897v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T15:14:51+00:00",
          "link": "https://arxiv.org/abs/2504.12897v2",
          "size": "80kb",
          "version": "v2"
        }
      ],
      "title": "OntoPortal-Astro, a Semantic Artefact Catalogue for Astronomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12897",
        "HTML": "https://arxiv.org/html/2504.12897v2",
        "PDF": "https://arxiv.org/pdf/2504.12897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a semantic artefact catalogue for the astronomy community, focusing on data interoperability and ontology management rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06261",
      "abstract": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.",
      "authors": [
        "Gheorghe Comanici",
        "Eric Bieber",
        "Mike Schaekermann",
        "Ice Pasupat",
        "Noveen Sachdeva",
        "Inderjit Dhillon",
        "Marcel Blistein",
        "Ori Ram",
        "Dan Zhang",
        "Evan Rosen",
        "Luke Marris",
        "Sam Petulla",
        "Colin Gaffney",
        "Asaf Aharoni",
        "Nathan Lintz",
        "Tiago Cardal Pais",
        "Henrik Jacobsson",
        "Idan Szpektor",
        "Nan-Jiang Jiang",
        "Krishna Haridasan",
        "Ahmed Omran",
        "Nikunj Saunshi",
        "Dara Bahri",
        "Gaurav Mishra",
        "Eric Chu",
        "Toby Boyd",
        "Brad Hekman",
        "Aaron Parisi",
        "Chaoyi Zhang",
        "Kornraphop Kawintiranon",
        "Tania Bedrax-Weiss",
        "Oliver Wang",
        "Ya Xu",
        "Ollie Purkiss",
        "Uri Mendlovic",
        "Ila\\\"i Deutel",
        "Nam Nguyen",
        "Adam Langley",
        "Flip Korn",
        "Lucia Rossazza",
        "Alexandre Ram\\'e",
        "Sagar Waghmare",
        "Helen Miller",
        "Vaishakh Keshava",
        "Ying Jian",
        "Xiaofan Zhang",
        "Raluca Ada Popa",
        "Kedar Dhamdhere",
        "Bla\\v{z} Bratani\\v{c}",
        "Kyuyeun Kim",
        "Terry Koo",
        "Ferran Alet",
        "Yi-ting Chen",
        "Arsha Nagrani",
        "Hannah Muckenhirn",
        "Zhiyuan Zhang",
        "Corbin Quick",
        "Filip Paveti\\'c",
        "Duc Dung Nguyen",
        "Joao Carreira",
        "Michael Elabd",
        "Haroon Qureshi",
        "Fabian Mentzer",
        "Yao-Yuan Yang",
        "Danielle Eisenbud",
        "Anmol Gulati",
        "Ellie Talius",
        "Eric Ni",
        "Sahra Ghalebikesabi",
        "Edouard Yvinec",
        "Alaa Saade",
        "Thatcher Ulrich",
        "Lorenzo Blanco",
        "Dan A. Calian",
        "Muhuan Huang",
        "A\\\"aron van den Oord",
        "Naman Goyal",
        "Terry Chen",
        "Praynaa Rawlani",
        "Christian Schallhart",
        "Swachhand Lokhande",
        "Xianghong Luo",
        "Jyn Shan",
        "Ceslee Montgomery",
        "Victoria Krakovna",
        "Federico Piccinini",
        "Omer Barak",
        "Jingyu Cui",
        "Yiling Jia",
        "Mikhail Dektiarev",
        "Alexey Kolganov",
        "Shiyu Huang",
        "Zhe Chen",
        "Xingyu Wang",
        "Jessica Austin",
        "Peter de Boursac",
        "Evgeny Sluzhaev",
        "Frank Ding",
        "Huijian Li",
        "Surya Bhupatiraju",
        "Mohit Agarwal",
        "S{\\l}awek Kwasiborski",
        "Paramjit Sandhu",
        "Patrick Siegler",
        "Ahmet Iscen",
        "Eyal Ben-David",
        "Shiraz Butt",
        "Miltos Allamanis",
        "Seth Benjamin",
        "Robert Busa-Fekete",
        "Felix Hernandez-Campos",
        "Sasha Goldshtein",
        "Matt Dibb",
        "Weiyang Zhang",
        "Annie Marsden",
        "Carey Radebaugh",
        "Stephen Roller",
        "Abhishek Nayyar",
        "Jacob Austin",
        "Tayfun Terzi",
        "Bhargav Kanagal Shamanna",
        "Pete Shaw",
        "Aayush Singh",
        "Florian Luisier",
        "Artur Mendon\\c{c}a",
        "Vaibhav Aggarwal",
        "Larisa Markeeva",
        "Claudio Fantacci",
        "Sergey Brin",
        "HyunJeong Choe",
        "Guanyu Wang",
        "Hartwig Adam",
        "Avigail Dabush",
        "Tatsuya Kiyono",
        "Eyal Marcus",
        "Jeremy Cole",
        "Theophane Weber",
        "Hongrae Lee",
        "Ronny Huang",
        "Alex Muzio",
        "Leandro Kieliger",
        "Maigo Le",
        "Courtney Biles",
        "Long Le",
        "Archit Sharma",
        "Chengrun Yang",
        "Avery Lamp",
        "Dave Dopson",
        "Nate Hurley",
        "Katrina Xinyi Xu",
        "Zhihao Shan",
        "Shuang Song",
        "Jiewen Tan",
        "Alexandre Senges",
        "George Zhang",
        "Chong You",
        "Yennie Jun",
        "David Raposo",
        "Susanna Ricco",
        "Xuan Yang",
        "Weijie Chen",
        "Prakhar Gupta",
        "Arthur Szlam",
        "Kevin Villela",
        "Chun-Sung Ferng",
        "Daniel Kasenberg",
        "Chen Liang",
        "Rui Zhu",
        "Arunachalam Narayanaswamy",
        "Florence Perot",
        "Paul Pucciarelli",
        "Anna Shekhawat",
        "Alexey Stern",
        "Rishikesh Ingale",
        "Stefani Karp",
        "Sanaz Bahargam",
        "Adrian Goedeckemeyer",
        "Jie Han",
        "Sicheng Li",
        "Andrea Tacchetti",
        "Dian Yu",
        "Abhishek Chakladar",
        "Zhiying Zhang",
        "Mona El Mahdy",
        "Xu Gao",
        "Dale Johnson",
        "Samrat Phatale",
        "AJ Piergiovanni",
        "Hyeontaek Lim",
        "Clement Farabet",
        "Carl Lebsack",
        "Theo Guidroz",
        "John Blitzer",
        "Nico Duduta",
        "David Madras",
        "Steve Li",
        "Daniel von Dincklage",
        "Xin Li",
        "Mahdis Mahdieh",
        "George Tucker",
        "Ganesh Jawahar",
        "Owen Xiao",
        "Danny Tarlow",
        "Robert Geirhos",
        "Noam Velan",
        "Daniel Vlasic",
        "Kalesha Bullard",
        "SK Park",
        "Nishesh Gupta",
        "Kellie Webster",
        "Ayal Hitron",
        "Jieming Mao",
        "Julian Eisenschlos",
        "Laurel Prince",
        "Nina D'Souza",
        "Kelvin Zheng",
        "Sara Nasso",
        "Gabriela Botea",
        "Carl Doersch",
        "Caglar Unlu",
        "Chris Alberti",
        "Alexey Svyatkovskiy",
        "Ankita Goel",
        "Krzysztof Choromanski",
        "Pan-Pan Jiang",
        "Richard Nguyen",
        "Four Flynn",
        "Daria \\'Curko",
        "Peter Chen",
        "Nicholas Roth",
        "Kieran Milan",
        "Caleb Habtegebriel",
        "Shashi Narayan",
        "Michael Moffitt",
        "Jake Marcus",
        "Thomas Anthony",
        "Brendan McMahan",
        "Gowoon Cheon",
        "Ruibo Liu",
        "Megan Barnes",
        "Lukasz Lew",
        "Rebeca Santamaria-Fernandez",
        "Mayank Upadhyay",
        "Arjun Akula",
        "Arnar Mar Hrafnkelsson",
        "Alvaro Caceres",
        "Andrew Bunner",
        "Michal Sokolik",
        "Subha Puttagunta",
        "Lawrence Moore",
        "Berivan Isik",
        "Jay Hartford",
        "Lawrence Chan",
        "Pradeep Shenoy",
        "Dan Holtmann-Rice",
        "Jane Park",
        "Fabio Viola",
        "Alex Salcianu",
        "Sujeevan Rajayogam",
        "Ian Stewart-Binks",
        "Zelin Wu",
        "Richard Everett",
        "Xi Xiong",
        "Pierre-Antoine Manzagol",
        "Gary Leung",
        "Carl Saroufim",
        "Bo Pang",
        "Dawid Wegner",
        "George Papamakarios",
        "Jennimaria Palomaki",
        "Helena Pankov",
        "Guangda Lai",
        "Guilherme Tubone",
        "Shubin Zhao",
        "Theofilos Strinopoulos",
        "Seth Neel",
        "Mingqiu Wang",
        "Joe Kelley",
        "Li Li",
        "Pingmei Xu",
        "Anitha Vijayakumar",
        "Andrea D'olimpio",
        "Omer Levy",
        "Massimo Nicosia",
        "Grigory Rozhdestvenskiy",
        "Ni Lao",
        "Sirui Xie",
        "Yash Katariya",
        "Jon Simon",
        "Sanjiv Kumar",
        "Florian Hartmann",
        "Michael Kilgore",
        "Jinhyuk Lee",
        "Aroma Mahendru",
        "Roman Ring",
        "Tom Hennigan",
        "Fiona Lang",
        "Colin Cherry",
        "David Steiner",
        "Dawsen Hwang",
        "Ray Smith",
        "Pidong Wang",
        "Jeremy Chen",
        "Ming-Hsuan Yang",
        "Sam Kwei",
        "Philippe Schlattner",
        "Donnie Kim",
        "Ganesh Poomal Girirajan",
        "Nikola Momchev",
        "Ayushi Agarwal",
        "Xingyi Zhou",
        "Ilkin Safarli",
        "Zachary Garrett",
        "AJ Pierigiovanni",
        "Sarthak Jauhari",
        "Alif Raditya Rochman",
        "Shikhar Vashishth",
        "Quan Yuan",
        "Christof Angermueller",
        "Jon Blanton",
        "Xinying Song",
        "Nitesh Bharadwaj Gundavarapu",
        "Thi Avrahami",
        "Maxine Deines",
        "Subhrajit Roy",
        "Manish Gupta",
        "Christopher Semturs",
        "Shobha Vasudevan",
        "Aditya Srikanth Veerubhotla",
        "Shriya Sharma",
        "Josh Jacob",
        "Zhen Yang",
        "Andreas Terzis",
        "Dan Karliner",
        "Auriel Wright",
        "Tania Rojas-Esponda",
        "Ashley Brown",
        "Abhijit Guha Roy",
        "Pawan Dogra",
        "Andrei Kapishnikov",
        "Peter Young",
        "Wendy Kan",
        "Vinodh Kumar Rajendran",
        "Maria Ivanova",
        "Salil Deshmukh",
        "Chia-Hua Ho",
        "Mike Kwong",
        "Stav Ginzburg",
        "Annie Louis",
        "KP Sawhney",
        "Slav Petrov",
        "Jing Xie",
        "Yunfei Bai",
        "Georgi Stoyanov",
        "Alex Fabrikant",
        "Rajesh Jayaram",
        "Yuqi Li",
        "Joe Heyward",
        "Justin Gilmer",
        "Yaqing Wang",
        "Radu Soricut",
        "Luyang Liu",
        "Qingnan Duan",
        "Jamie Hayes",
        "Maura O'Brien",
        "Gaurav Singh Tomar",
        "Sivan Eiger",
        "Bahar Fatemi",
        "Jeffrey Hui",
        "Catarina Barros",
        "Adaeze Chukwuka",
        "Alena Butryna",
        "Saksham Thakur",
        "Austin Huang",
        "Zhufeng Pan",
        "Haotian Tang",
        "Serkan Cabi",
        "Tulsee Doshi",
        "Michiel Bakker",
        "Sumit Bagri",
        "Ruy Ley-Wild",
        "Adam Lelkes",
        "Jennie Lees",
        "Patrick Kane",
        "David Greene",
        "Shimu Wu",
        "J\\\"org Bornschein",
        "Gabriela Surita",
        "Sarah Hodkinson",
        "Fangtao Li",
        "Chris Hidey",
        "S\\'ebastien Pereira",
        "Sean Ammirati",
        "Phillip Lippe",
        "Adam Kraft",
        "Pu Han",
        "Sebastian Gerlach",
        "Zifeng Wang",
        "Liviu Panait",
        "Feng Han",
        "Brian Farris",
        "Yingying Bi",
        "Hannah DeBalsi",
        "Miaosen Wang",
        "Gladys Tyen",
        "James Cohan",
        "Susan Zhang",
        "Jarred Barber",
        "Da-Woon Chung",
        "Jaeyoun Kim",
        "Markus Kunesch",
        "Steven Pecht",
        "Nami Akazawa",
        "Abe Friesen",
        "James Lyon",
        "Ali Eslami",
        "Junru Wu",
        "Jie Tan",
        "Yue Song",
        "Ravi Kumar",
        "Chris Welty",
        "Ilia Akolzin",
        "Gena Gibson",
        "Sean Augenstein",
        "Arjun Pillai",
        "Nancy Yuen",
        "Du Phan",
        "Xin Wang",
        "Iain Barr",
        "Heiga Zen",
        "Nan Hua",
        "Casper Liu",
        "Jilei Jerry Wang",
        "Tanuj Bhatia",
        "Hao Xu",
        "Oded Elyada",
        "Pushmeet Kohli",
        "Mirek Ol\\v{s}\\'ak",
        "Ke Chen",
        "Azalia Mirhoseini",
        "Noam Shazeer",
        "Shoshana Jakobovits",
        "Maggie Tran",
        "Nolan Ramsden",
        "Tarun Bharti",
        "Fred Alcober",
        "Yunjie Li",
        "Shilpa Shetty",
        "Jing Chen",
        "Dmitry Kalashnikov",
        "Megha Nawhal",
        "Sercan Arik",
        "Hanwen Chen",
        "Michiel Blokzijl",
        "Shubham Gupta",
        "James Rubin",
        "Rigel Swavely",
        "Sophie Bridgers",
        "Ian Gemp",
        "Chen Su",
        "Arun Suggala",
        "Juliette Pluto",
        "Mary Cassin",
        "Alain Vaucher",
        "Kaiyang Ji",
        "Jiahao Cai",
        "Andrew Audibert",
        "Animesh Sinha",
        "David Tian",
        "Efrat Farkash",
        "Amy Hua",
        "Jilin Chen",
        "Duc-Hieu Tran",
        "Edward Loper",
        "Nicole Brichtova",
        "Lara McConnaughey",
        "Ballie Sandhu",
        "Robert Leland",
        "Doug DeCarlo",
        "Andrew Over",
        "James Huang",
        "Xing Wu",
        "Connie Fan",
        "Eric Li",
        "Yun Lei",
        "Deepak Sharma",
        "Cosmin Paduraru",
        "Luo Yu",
        "Matko Bo\\v{s}njak",
        "Phuong Dao",
        "Min Choi",
        "Sneha Kudugunta",
        "Jakub Adamek",
        "Carlos Gu\\'ia",
        "Ali Khodaei",
        "Jie Feng",
        "Wenjun Zeng",
        "David Welling",
        "Sandeep Tata",
        "Christina Butterfield",
        "Andrey Vlasov",
        "Seliem El-Sayed",
        "Swaroop Mishra",
        "Tara Sainath",
        "Shentao Yang",
        "RJ Skerry-Ryan",
        "Jeremy Shar",
        "Robert Berry",
        "Arunkumar Rajendran",
        "Arun Kandoor",
        "Andrea Burns",
        "Deepali Jain",
        "Tom Stone",
        "Wonpyo Park",
        "Shibo Wang",
        "Albin Cassirer",
        "Guohui Wang",
        "Hayato Kobayashi",
        "Sergey Rogulenko",
        "Vineetha Govindaraj",
        "Miko{\\l}aj Rybi\\'nski",
        "Nadav Olmert",
        "Colin Evans",
        "Po-Sen Huang",
        "Kelvin Xu",
        "Premal Shah",
        "Terry Thurk",
        "Caitlin Sikora",
        "Mu Cai",
        "Jin Xie",
        "Elahe Dabir",
        "Saloni Shah",
        "Norbert Kalb",
        "Carrie Zhang",
        "Shruthi Prabhakara",
        "Amit Sabne",
        "Artiom Myaskovsky",
        "Vikas Raunak",
        "Blanca Huergo",
        "Behnam Neyshabur",
        "Jon Clark",
        "Ye Zhang",
        "Shankar Krishnan",
        "Eden Cohen",
        "Dinesh Tewari",
        "James Lottes",
        "Yumeya Yamamori",
        "Hui Elena Li",
        "Mohamed Elhawaty",
        "Ada Maksutaj Oflazer",
        "Adri\\`a Recasens",
        "Sheryl Luo",
        "Duy Nguyen",
        "Taylor Bos",
        "Kalyan Andra",
        "Ana Salazar",
        "Ed Chi",
        "Jeongwoo Ko",
        "Matt Ginsberg",
        "Anders Andreassen",
        "Anian Ruoss",
        "Todor Davchev",
        "Elnaz Davoodi",
        "Chenxi Liu",
        "Min Kim",
        "Santiago Ontanon",
        "Chi Ming To",
        "Dawei Jia",
        "Rosemary Ke",
        "Jing Wang",
        "Anna Korsun",
        "Moran Ambar",
        "Ilya Kornakov",
        "Irene Giannoumis",
        "Toni Creswell",
        "Denny Zhou",
        "Yi Su",
        "Ishaan Watts",
        "Aleksandr Zaks",
        "Evgenii Eltyshev",
        "Ziqiang Feng",
        "Sidharth Mudgal",
        "Alex Kaskasoli",
        "Juliette Love",
        "Kingshuk Dasgupta",
        "Sam Shleifer",
        "Richard Green",
        "Sungyong Seo",
        "Chansoo Lee",
        "Dale Webster",
        "Prakash Shroff",
        "Ganna Raboshchuk",
        "Isabel Leal",
        "James Manyika",
        "Sofia Erell",
        "Daniel Murphy",
        "Zhisheng Xiao",
        "Anton Bulyenov",
        "Julian Walker",
        "Mark Collier",
        "Matej Kastelic",
        "Nelson George",
        "Sushant Prakash",
        "Sailesh Sidhwani",
        "Alexey Frolov",
        "Steven Hansen",
        "Petko Georgiev",
        "Tiberiu Sosea",
        "Chris Apps",
        "Aishwarya Kamath",
        "David Reid",
        "Emma Cooney",
        "Charlotte Magister",
        "Oriana Riva",
        "Alec Go",
        "Pu-Chin Chen",
        "Sebastian Krause",
        "Nir Levine",
        "Marco Fornoni",
        "Ilya Figotin",
        "Nick Roy",
        "Parsa Mahmoudieh",
        "Vladimir Magay",
        "Mukundan Madhavan",
        "Jin Miao",
        "Jianmo Ni",
        "Yasuhisa Fujii",
        "Ian Chou",
        "George Scrivener",
        "Zak Tsai",
        "Siobhan Mcloughlin",
        "Jeremy Selier",
        "Sandra Lefdal",
        "Jeffrey Zhao",
        "Abhijit Karmarkar",
        "Kushal Chauhan",
        "Shivanker Goel",
        "Zhaoyi Zhang",
        "Vihan Jain",
        "Parisa Haghani",
        "Mostafa Dehghani",
        "Jacob Scott",
        "Erin Farnese",
        "Anastasija Ili\\'c",
        "Steven Baker",
        "Julia Pawar",
        "Li Zhong",
        "Josh Camp",
        "Yoel Zeldes",
        "Shravya Shetty",
        "Anand Iyer",
        "V\\'it List\\'ik",
        "Jiaxian Guo",
        "Luming Tang",
        "Mark Geller",
        "Simon Bucher",
        "Yifan Ding",
        "Hongzhi Shi",
        "Carrie Muir",
        "Dominik Grewe",
        "Ramy Eskander",
        "Octavio Ponce",
        "Boqing Gong",
        "Derek Gasaway",
        "Samira Khan",
        "Umang Gupta",
        "Angelos Filos",
        "Weicheng Kuo",
        "Klemen Kloboves",
        "Jennifer Beattie",
        "Christian Wright",
        "Leon Li",
        "Alicia Jin",
        "Sandeep Mariserla",
        "Miteyan Patel",
        "Jens Heitkaemper",
        "Dilip Krishnan",
        "Vivek Sharma",
        "David Bieber",
        "Christian Frank",
        "John Lambert",
        "Paul Caron",
        "Martin Polacek",
        "Mai Gim\\'enez",
        "Himadri Choudhury",
        "Xing Yu",
        "Sasan Tavakkol",
        "Arun Ahuja",
        "Franz Och",
        "Rodolphe Jenatton",
        "Wojtek Skut",
        "Bryan Richter",
        "David Gaddy",
        "Andy Ly",
        "Misha Bilenko",
        "Megh Umekar",
        "Ethan Liang",
        "Martin Sevenich",
        "Mandar Joshi",
        "Hassan Mansoor",
        "Rebecca Lin",
        "Sumit Sanghai",
        "Abhimanyu Singh",
        "Xiaowei Li",
        "Sudheendra Vijayanarasimhan",
        "Zaheer Abbas",
        "Yonatan Bitton",
        "Hansa Srinivasan",
        "Manish Reddy Vuyyuru",
        "Alexander Fr\\\"ommgen",
        "Yanhua Sun",
        "Ralph Leith",
        "Alfonso Casta\\~no",
        "DJ Strouse",
        "Le Yan",
        "Austin Kyker",
        "Satish Kambala",
        "Mary Jasarevic",
        "Thibault Sellam",
        "Chao Jia",
        "Alexander Pritzel",
        "Raghavender R",
        "Huizhong Chen",
        "Natalie Clay",
        "Sudeep Gandhe",
        "Sean Kirmani",
        "Sayna Ebrahimi",
        "Hannah Kirkwood",
        "Jonathan Mallinson",
        "Chao Wang",
        "Adnan Ozturel",
        "Kuo Lin",
        "Shyam Upadhyay",
        "Vincent Cohen-Addad",
        "Sean Purser-haskell",
        "Yichong Xu",
        "Ebrahim Songhori",
        "Babi Seal",
        "Alberto Magni",
        "Almog Gueta",
        "Tingting Zou",
        "Guru Guruganesh",
        "Thais Kagohara",
        "Hung Nguyen",
        "Khalid Salama",
        "Alejandro Cruzado Ruiz",
        "Justin Frye",
        "Zhenkai Zhu",
        "Matthias Lochbrunner",
        "Simon Osindero",
        "Wentao Yuan",
        "Lisa Lee",
        "Aman Prasad",
        "Lam Nguyen Thiet",
        "Daniele Calandriello",
        "Victor Stone",
        "Qixuan Feng",
        "Han Ke",
        "Maria Voitovich",
        "Geta Sampemane",
        "Lewis Chiang",
        "Ling Wu",
        "Alexander Bykovsky",
        "Matt Young",
        "Luke Vilnis",
        "Ishita Dasgupta",
        "Aditya Chawla",
        "Qin Cao",
        "Bowen Liang",
        "Daniel Toyama",
        "Szabolcs Payrits",
        "Anca Stefanoiu",
        "Dimitrios Vytiniotis",
        "Ankesh Anand",
        "Tianxiao Shen",
        "Blagoj Mitrevski",
        "Michael Tschannen",
        "Sreenivas Gollapudi",
        "Aishwarya P S",
        "Jos\\'e Leal",
        "Zhe Shen",
        "Han Fu",
        "Wei Wang",
        "Arvind Kannan",
        "Doron Kukliansky",
        "Sergey Yaroshenko",
        "Svetlana Grant",
        "Umesh Telang",
        "David Wood",
        "Alexandra Chronopoulou",
        "Alexandru \\c{T}ifrea",
        "Tao Zhou",
        "Tony Tu\\'\\^an Nguy\\~\\^en",
        "Muge Ersoy",
        "Anima Singh",
        "Meiyan Xie",
        "Emanuel Taropa",
        "Woohyun Han",
        "Eirikur Agustsson",
        "Andrei Sozanschi",
        "Hui Peng",
        "Alex Chen",
        "Yoel Drori",
        "Efren Robles",
        "Yang Gao",
        "Xerxes Dotiwalla",
        "Ying Chen",
        "Anudhyan Boral",
        "Alexei Bendebury",
        "John Nham",
        "Chris Tar",
        "Luis Castro",
        "Jiepu Jiang",
        "Canoee Liu",
        "Felix Halim",
        "Jinoo Baek",
        "Andy Wan",
        "Jeremiah Liu",
        "Yuan Cao",
        "Shengyang Dai",
        "Trilok Acharya",
        "Ruoxi Sun",
        "Fuzhao Xue",
        "Saket Joshi",
        "Morgane Lustman",
        "Yongqin Xian",
        "Rishabh Joshi",
        "Deep Karkhanis",
        "Nora Kassner",
        "Jamie Hall",
        "Xiangzhuo Ding",
        "Gan Song",
        "Gang Li",
        "Chen Zhu",
        "Yana Kulizhskaya",
        "Bin Ni",
        "Alexey Vlaskin",
        "Solomon Demmessie",
        "Lucio Dery",
        "Salah Zaiem",
        "Yanping Huang",
        "Cindy Fan",
        "Felix Gimeno",
        "Ananth Balashankar",
        "Koji Kojima",
        "Hagai Taitelbaum",
        "Maya Meng",
        "Dero Gharibian",
        "Sahil Singla",
        "Wei Chen",
        "Ambrose Slone",
        "Guanjie Chen",
        "Sujee Rajayogam",
        "Max Schumacher",
        "Suyog Kotecha",
        "Rory Blevins",
        "Qifei Wang",
        "Mor Hazan Taege",
        "Alex Morris",
        "Xin Liu",
        "Fayaz Jamil",
        "Richard Zhang",
        "Pratik Joshi",
        "Ben Ingram",
        "Tyler Liechty",
        "Ahmed Eleryan",
        "Scott Baird",
        "Alex Grills",
        "Gagan Bansal",
        "Shan Han",
        "Kiran Yalasangi",
        "Shawn Xu",
        "Majd Al Merey",
        "Isabel Gao",
        "Felix Weissenberger",
        "Igor Karpov",
        "Robert Riachi",
        "Ankit Anand",
        "Gautam Prasad",
        "Kay Lamerigts",
        "Reid Hayes",
        "Jamie Rogers",
        "Mandy Guo",
        "Ashish Shenoy",
        "Qiong Q Hu",
        "Kyle He",
        "Yuchen Liu",
        "Polina Zablotskaia",
        "Sagar Gubbi",
        "Yifan Chang",
        "Jay Pavagadhi",
        "Kristian Kjems",
        "Archita Vadali",
        "Diego Machado",
        "Yeqing Li",
        "Renshen Wang",
        "Dipankar Ghosh",
        "Aahil Mehta",
        "Dana Alon",
        "George Polovets",
        "Alessio Tonioni",
        "Nate Kushman",
        "Joel D'sa",
        "Lin Zhuo",
        "Allen Wu",
        "Rohin Shah",
        "John Youssef",
        "Jiayu Ye",
        "Justin Snyder",
        "Karel Lenc",
        "Senaka Buthpitiya",
        "Matthew Tung",
        "Jichuan Chang",
        "Tao Chen",
        "David Saxton",
        "Jenny Lee",
        "Lydia Lihui Zhang",
        "James Qin",
        "Prabakar Radhakrishnan",
        "Maxwell Chen",
        "Piotr Ambroszczyk",
        "Metin Toksoz-Exley",
        "Yan Zhong",
        "Nitzan Katz",
        "Brendan O'Donoghue",
        "Tamara von Glehn",
        "Adi Gerzi Rosenthal",
        "Aga \\'Swietlik",
        "Xiaokai Zhao",
        "Nick Fernando",
        "Jinliang Wei",
        "Jieru Mei",
        "Sergei Vassilvitskii",
        "Diego Cedillo",
        "Pranjal Awasthi",
        "Hui Zheng",
        "Koray Kavukcuoglu",
        "Itay Laish",
        "Joseph Pagadora",
        "Marc Brockschmidt",
        "Christopher A. Choquette-Choo",
        "Arunkumar Byravan",
        "Yifeng Lu",
        "Xu Chen",
        "Mia Chen",
        "Kenton Lee",
        "Rama Pasumarthi",
        "Sijal Bhatnagar",
        "Aditya Shah",
        "Qiyin Wu",
        "Zhuoyuan Chen",
        "Zack Nado",
        "Bartek Perz",
        "Zixuan Jiang",
        "David Kao",
        "Ganesh Mallya",
        "Nino Vieillard",
        "Lantao Mei",
        "Sertan Girgin",
        "Mandy Jordan",
        "Yeongil Ko",
        "Alekh Agarwal",
        "Yaxin Liu",
        "Yasemin Altun",
        "Raoul de Liedekerke",
        "Anastasios Kementsietsidis",
        "Daiyi Peng",
        "Dangyi Liu",
        "Utku Evci",
        "Peter Humphreys",
        "Austin Tarango",
        "Xiang Deng",
        "Yoad Lewenberg",
        "Kevin Aydin",
        "Chengda Wu",
        "Bhavishya Mittal",
        "Tsendsuren Munkhdalai",
        "Kleopatra Chatziprimou",
        "Rodrigo Benenson",
        "Uri First",
        "Xiao Ma",
        "Jinning Li",
        "Armand Joulin",
        "Hamish Tomlinson",
        "Tingnan Zhang",
        "Milad Nasr",
        "Zhi Hong",
        "Micha\\\"el Sander",
        "Lisa Anne Hendricks",
        "Anuj Sharma",
        "Andrew Bolt",
        "Eszter V\\'ertes",
        "Jiri Simsa",
        "Tomer Levinboim",
        "Olcan Sercinoglu",
        "Divyansh Shukla",
        "Austin Wu",
        "Craig Swanson",
        "Danny Vainstein",
        "Fan Bu",
        "Bo Wang",
        "Ryan Julian",
        "Charles Yoon",
        "Sergei Lebedev",
        "Antonious Girgis",
        "Bernd Bandemer",
        "David Du",
        "Todd Wang",
        "Xi Chen",
        "Ying Xiao",
        "Peggy Lu",
        "Natalie Ha",
        "Vlad Ionescu",
        "Simon Rowe",
        "Josip Matak",
        "Federico Lebron",
        "Andreas Steiner",
        "Lalit Jain",
        "Manaal Faruqui",
        "Nicolas Lacasse",
        "Georgie Evans",
        "Neesha Subramaniam",
        "Dean Reich",
        "Giulia Vezzani",
        "Aditya Pandey",
        "Joe Stanton",
        "Tianhao Zhou",
        "Liam McCafferty",
        "Henry Griffiths",
        "Verena Rieser",
        "Soheil Hassas Yeganeh",
        "Eleftheria Briakou",
        "Lu Huang",
        "Zichuan Wei",
        "Liangchen Luo",
        "Erik Jue",
        "Gabby Wang",
        "Victor Cotruta",
        "Myriam Khan",
        "Jongbin Park",
        "Qiuchen Guo",
        "Peiran Li",
        "Rong Rong",
        "Diego Antognini",
        "Anastasia Petrushkina",
        "Chetan Tekur",
        "Eli Collins",
        "Parul Bhatia",
        "Chester Kwak",
        "Wenhu Chen",
        "Arvind Neelakantan",
        "Immanuel Odisho",
        "Sheng Peng",
        "Vincent Nallatamby",
        "Vaibhav Tulsyan",
        "Fabian Pedregosa",
        "Peng Xu",
        "Raymond Lin",
        "Yulong Wang",
        "Emma Wang",
        "Sholto Douglas",
        "Reut Tsarfaty",
        "Elena Gribovskaya",
        "Renga Aravamudhan",
        "Manu Agarwal",
        "Mara Finkelstein",
        "Qiao Zhang",
        "Elizabeth Cole",
        "Phil Crone",
        "Sarmishta Velury",
        "Anil Das",
        "Chris Sauer",
        "Luyao Xu",
        "Danfeng Qin",
        "Chenjie Gu",
        "Dror Marcus",
        "CJ Zheng",
        "Wouter Van Gansbeke",
        "Sobhan Miryoosefi",
        "Haitian Sun",
        "YaGuang Li",
        "Charlie Chen",
        "Jae Yoo",
        "Pavel Dubov",
        "Alex Tomala",
        "Adams Yu",
        "Pawe{\\l} Weso{\\l}owski",
        "Alok Gunjan",
        "Eddie Cao",
        "Jiaming Luo",
        "Nikhil Sethi",
        "Arkadiusz Socala",
        "Laura Graesser",
        "Tomas Kocisky",
        "Arturo BC",
        "Minmin Chen",
        "Edward Lee",
        "Sophie Wang",
        "Weize Kong",
        "Qiantong Xu",
        "Nilesh Tripuraneni",
        "Yiming Li",
        "Xinxin Yu",
        "Allen Porter",
        "Paul Voigtlaender",
        "Biao Zhang",
        "Arpi Vezer",
        "Sarah York",
        "Qing Wei",
        "Geoffrey Cideron",
        "Mark Kurzeja",
        "Seungyeon Kim",
        "Benny Li",
        "Ang\\'eline Pouget",
        "Hyo Lee",
        "Kaspar Daugaard",
        "Yang Li",
        "Dave Uthus",
        "Aditya Siddhant",
        "Paul Cavallaro",
        "Sriram Ganapathy",
        "Maulik Shah",
        "Rolf Jagerman",
        "Jeff Stanway",
        "Piermaria Mendolicchio",
        "Li Xiao",
        "Kayi Lee",
        "Tara Thompson",
        "Shubham Milind Phal",
        "Jason Chase",
        "Sun Jae Lee",
        "Adrian N Reyes",
        "Disha Shrivastava",
        "Zhen Qin",
        "Roykrong Sukkerd",
        "Seth Odoom",
        "Lior Madmoni",
        "John Aslanides",
        "Jonathan Herzig",
        "Elena Pochernina",
        "Sheng Zhang",
        "Parker Barnes",
        "Daisuke Ikeda",
        "Qiujia Li",
        "Shuo-yiin Chang",
        "Shakir Mohamed",
        "Jim Sproch",
        "Richard Powell",
        "Bidisha Samanta",
        "Domagoj \\'Cevid",
        "Anton Kovsharov",
        "Shrestha Basu Mallick",
        "Srinivas Tadepalli",
        "Anne Zheng",
        "Kareem Ayoub",
        "Andreas Noever",
        "Christian Reisswig",
        "Zhuo Xu",
        "Junhyuk Oh",
        "Martin Matysiak",
        "Tim Blyth",
        "Shereen Ashraf",
        "Julien Amelot",
        "Boone Severson",
        "Michele Bevilacqua",
        "Motoki Sano",
        "Ethan Dyer",
        "Ofir Roval",
        "Anu Sinha",
        "Yin Zhong",
        "Sagi Perel",
        "Tea Saboli\\'c",
        "Johannes Mauerer",
        "Willi Gierke",
        "Mauro Verzetti",
        "Rodrigo Cabrera",
        "Alvin Abdagic",
        "Steven Hemingray",
        "Austin Stone",
        "Jong Lee",
        "Farooq Ahmad",
        "Karthik Raman",
        "Lior Shani",
        "Jonathan Lai",
        "Orhan Firat",
        "Nathan Waters",
        "Eric Ge",
        "Mo Shomrat",
        "Himanshu Gupta",
        "Rajeev Aggarwal",
        "Tom Hudson",
        "Bill Jia",
        "Simon Baumgartner",
        "Palak Jain",
        "Joe Kovac",
        "Junehyuk Jung",
        "Ante \\v{Z}u\\v{z}ul",
        "Will Truong",
        "Morteza Zadimoghaddam",
        "Songyou Peng",
        "Marco Liang",
        "Rachel Sterneck",
        "Balaji Lakshminarayanan",
        "Machel Reid",
        "Oliver Woodman",
        "Tong Zhou",
        "Jianling Wang",
        "Vincent Coriou",
        "Arjun Narayanan",
        "Jay Hoover",
        "Yenai Ma",
        "Apoorv Jindal",
        "Clayton Sanford",
        "Doug Reid",
        "Swaroop Ramaswamy",
        "Alex Kurakin",
        "Roland Zimmermann",
        "Yana Lunts",
        "Dragos Dena",
        "Zal\\'an Borsos",
        "Vered Cohen",
        "Shujian Zhang",
        "Will Grathwohl",
        "Robert Dadashi",
        "Morgan Redshaw",
        "Joshua Kessinger",
        "Julian Odell",
        "Silvano Bonacina",
        "Zihang Dai",
        "Grace Chen",
        "Ayush Dubey",
        "Pablo Sprechmann",
        "Mantas Pajarskas",
        "Wenxuan Zhou",
        "Niharika Ahuja",
        "Tara Thomas",
        "Martin Nikoltchev",
        "Matija Kecman",
        "Bharath Mankalale",
        "Andrey Ryabtsev",
        "Jennifer She",
        "Christian Walder",
        "Jiaming Shen",
        "Lu Li",
        "Carolina Parada",
        "Sheena Panthaplackel",
        "Okwan Kwon",
        "Matt Lawlor",
        "Utsav Prabhu",
        "Yannick Schroecker",
        "Marc'aurelio Ranzato",
        "Pete Blois",
        "Iurii Kemaev",
        "Ting Yu",
        "Dmitry Lepikhin",
        "Hao Xiong",
        "Sahand Sharifzadeh",
        "Oleaser Johnson",
        "Jeremiah Willcock",
        "Rui Yao",
        "Greg Farquhar",
        "Sujoy Basu",
        "Hidetoshi Shimokawa",
        "Nina Anderson",
        "Haiguang Li",
        "Khiem Pham",
        "Yizhong Liang",
        "Sebastian Borgeaud",
        "Alexandre Moufarek",
        "Hideto Kazawa",
        "Blair Kutzman",
        "Marcin Sieniek",
        "Sara Smoot",
        "Ruth Wang",
        "Natalie Axelsson",
        "Nova Fallen",
        "Prasha Sundaram",
        "Yuexiang Zhai",
        "Varun Godbole",
        "Petros Maniatis",
        "Alek Wang",
        "Ilia Shumailov",
        "Santhosh Thangaraj",
        "Remi Crocker",
        "Nikita Gupta",
        "Gang Wu",
        "Phil Chen",
        "Gell\\'ert Weisz",
        "Celine Smith",
        "Mojtaba Seyedhosseini",
        "Boya Fang",
        "Xiyang Luo",
        "Roey Yogev",
        "Zeynep Cankara",
        "Andrew Hard",
        "Helen Ran",
        "Rahul Sukthankar",
        "George Necula",
        "Ga\\\"el Liu",
        "Honglong Cai",
        "Praseem Banzal",
        "Daniel Keysers",
        "Sanjay Ghemawat",
        "Connie Tao",
        "Emma Dunleavy",
        "Aditi Chaudhary",
        "Wei Li",
        "Maciej Miku{\\l}a",
        "Chen-Yu Lee",
        "Tiziana Refice",
        "Krishna Somandepalli",
        "Alexandre Fr\\'echette",
        "Dan Bahir",
        "John Karro",
        "Keith Rush",
        "Sarah Perrin",
        "Bill Rosgen",
        "Xiaomeng Yang",
        "Clara Huiyi Hu",
        "Mahmoud Alnahlawi",
        "Justin Mao-Jones",
        "Roopal Garg",
        "Hoang Nguyen",
        "Bat-Orgil Batsaikhan",
        "I\\~naki Iturrate",
        "Anselm Levskaya",
        "Avi Singh",
        "Ashyana Kachra",
        "Tony Lu",
        "Denis Petek",
        "Zheng Xu",
        "Mark Graham",
        "Lukas Zilka",
        "Yael Karov",
        "Marija Kostelac",
        "Fangyu Liu",
        "Yaohui Guo",
        "Weiyue Wang",
        "Bernd Bohnet",
        "Emily Pitler",
        "Tony Bruguier",
        "Keisuke Kinoshita",
        "Chrysovalantis Anastasiou",
        "Nilpa Jha",
        "Ting Liu",
        "Jerome Connor",
        "Phil Wallis",
        "Philip Pham",
        "Eric Bailey",
        "Shixin Li",
        "Heng-Tze Cheng",
        "Sally Ma",
        "Haiqiong Li",
        "Akanksha Maurya",
        "Kate Olszewska",
        "Manfred Warmuth",
        "Christy Koh",
        "Dominik Paulus",
        "Siddhartha Reddy Jonnalagadda",
        "Enrique Piqueras",
        "Ali Elqursh",
        "Geoff Brown",
        "Hadar Shemtov",
        "Loren Maggiore",
        "Fei Xia",
        "Ryan Foley",
        "Beka Westberg",
        "George van den Driessche",
        "Livio Baldini Soares",
        "Arjun Kar",
        "Michael Quinn",
        "Siqi Zuo",
        "Jialin Wu",
        "Kyle Kastner",
        "Anna Bortsova",
        "Aijun Bai",
        "Ales Mikhalap",
        "Luowei Zhou",
        "Jennifer Brennan",
        "Vinay Ramasesh",
        "Honglei Zhuang",
        "John Maggs",
        "Johan Schalkwyk",
        "Yuntao Xu",
        "Hui Huang",
        "Andrew Howard",
        "Sasha Brown",
        "Linting Xue",
        "Gloria Shen",
        "Brian Albert",
        "Neha Jha",
        "Daniel Zheng",
        "Varvara Krayvanova",
        "Spurthi Amba Hombaiah",
        "Olivier Lacombe",
        "Gautam Vasudevan",
        "Dan Graur",
        "Tian Xie",
        "Meet Gandhi",
        "Bangju Wang",
        "Dustin Zelle",
        "Harman Singh",
        "Dahun Kim",
        "S\\'ebastien Cevey",
        "Victor Ungureanu",
        "Natasha Noy",
        "Fei Liu",
        "Annie Xie",
        "Fangxiaoyu Feng",
        "Katerina Tsihlas",
        "Daniel Formoso",
        "Neera Vats",
        "Quentin Wellens",
        "Yinan Wang",
        "Niket Kumar Bhumihar",
        "Samrat Ghosh",
        "Matt Hoffman",
        "Tom Lieber",
        "Oran Lang",
        "Kush Bhatia",
        "Tom Paine",
        "Aroonalok Pyne",
        "Ronny Votel",
        "Madeleine Clare Elish",
        "Benoit Schillings",
        "Alex Panagopoulos",
        "Haichuan Yang",
        "Adam Raveret",
        "Zohar Yahav",
        "Shuang Liu",
        "Dalia El Badawy",
        "Nishant Agrawal",
        "Mohammed Badawi",
        "Mahdi Mirzazadeh",
        "Carla Bromberg",
        "Fan Ye",
        "Chang Liu",
        "Tatiana Sholokhova",
        "George-Cristian Muraru",
        "Gargi Balasubramaniam",
        "Jonathan Malmaud",
        "Alen Carin",
        "Danilo Martins",
        "Irina Jurenka",
        "Pankil Botadra",
        "Dave Lacey",
        "Richa Singh",
        "Mariano Schain",
        "Dan Zheng",
        "Isabelle Guyon",
        "Victor Lavrenko",
        "Seungji Lee",
        "Xiang Zhou",
        "Demis Hassabis",
        "Jeshwanth Challagundla",
        "Derek Cheng",
        "Nikhil Mehta",
        "Matthew Mauger",
        "Michela Paganini",
        "Pushkar Mishra",
        "Kate Lee",
        "Zhang Li",
        "Lexi Baugher",
        "Ondrej Skopek",
        "Max Chang",
        "Amir Zait",
        "Gaurav Menghani",
        "Lizzetth Bellot",
        "Guangxing Han",
        "Jean-Michel Sarr",
        "Sharat Chikkerur",
        "Himanshu Sahni",
        "Rohan Anil",
        "Arun Narayanan",
        "Chandu Thekkath",
        "Daniele Pighin",
        "Hana Strej\\v{c}ek",
        "Marko Velic",
        "Fred Bertsch",
        "Manuel Tragut",
        "Keran Rong",
        "Alicia Parrish",
        "Kai Bailey",
        "Jiho Park",
        "Isabela Albuquerque",
        "Abhishek Bapna",
        "Rajesh Venkataraman",
        "Alec Kosik",
        "Johannes Griesser",
        "Zhiwei Deng",
        "Alek Andreev",
        "Qingyun Dou",
        "Kevin Hui",
        "Fanny Wei",
        "Xiaobin Yu",
        "Lei Shu",
        "Avia Aharon",
        "David Barker",
        "Badih Ghazi",
        "Sebastian Flennerhag",
        "Chris Breaux",
        "Yuchuan Liu",
        "Matthew Bilotti",
        "Josh Woodward",
        "Uri Alon",
        "Stephanie Winkler",
        "Tzu-Kuo Huang",
        "Kostas Andriopoulos",
        "Jo\\~ao Gabriel Oliveira",
        "Penporn Koanantakool",
        "Berkin Akin",
        "Michael Wunder",
        "Cicero Nogueira dos Santos",
        "Mohammad Hossein Bateni",
        "Lin Yang",
        "Dan Horgan",
        "Beer Changpinyo",
        "Keyvan Amiri",
        "Min Ma",
        "Dayeong Lee",
        "Lihao Liang",
        "Anirudh Baddepudi",
        "Tejasi Latkar",
        "Raia Hadsell",
        "Jun Xu",
        "Hairong Mu",
        "Michael Han",
        "Aedan Pope",
        "Snchit Grover",
        "Frank Kim",
        "Ankit Bhagatwala",
        "Guan Sun",
        "Yamini Bansal",
        "Amir Globerson",
        "Alireza Nazari",
        "Samira Daruki",
        "Hagen Soltau",
        "Jane Labanowski",
        "Laurent El Shafey",
        "Matt Harvey",
        "Yanif Ahmad",
        "Elan Rosenfeld",
        "William Kong",
        "Etienne Pot",
        "Yi-Xuan Tan",
        "Aurora Wei",
        "Victoria Langston",
        "Marcel Prasetya",
        "Petar Veli\\v{c}kovi\\'c",
        "Richard Killam",
        "Robin Strudel",
        "Darren Ni",
        "Zhenhai Zhu",
        "Aaron Archer",
        "Kavya Kopparapu",
        "Lynn Nguyen",
        "Emilio Parisotto",
        "Hussain Masoom",
        "Sravanti Addepalli",
        "Jordan Grimstad",
        "Hexiang Hu",
        "Joss Moore",
        "Avinatan Hassidim",
        "Le Hou",
        "Mukund Raghavachari",
        "Jared Lichtarge",
        "Adam R. Brown",
        "Hilal Dib",
        "Natalia Ponomareva",
        "Justin Fu",
        "Yujing Zhang",
        "Altaf Rahman",
        "Joana Iljazi",
        "Edouard Leurent",
        "Gabriel Dulac-Arnold",
        "Cosmo Du",
        "Chulayuth Asawaroengchai",
        "Larry Jin",
        "Ela Gruzewska",
        "Ziwei Ji",
        "Benigno Uria",
        "Daniel De Freitas",
        "Paul Barham",
        "Lauren Beltrone",
        "V\\'ictor Campos",
        "Jun Yan",
        "Neel Kovelamudi",
        "Arthur Nguyen",
        "Elinor Davies",
        "Zhichun Wu",
        "Zoltan Egyed",
        "Kristina Toutanova",
        "Nithya Attaluri",
        "Hongliang Fei",
        "Peter Stys",
        "Siddhartha Brahma",
        "Martin Izzard",
        "Siva Velusamy",
        "Scott Lundberg",
        "Vincent Zhuang",
        "Kevin Sequeira",
        "Adam Santoro",
        "Ehsan Amid",
        "Ophir Aharoni",
        "Shuai Ye",
        "Mukund Sundararajan",
        "Lijun Yu",
        "Yu-Cheng Ling",
        "Stephen Spencer",
        "Hugo Song",
        "Josip Djolonga",
        "Christo Kirov",
        "Sonal Gupta",
        "Alessandro Bissacco",
        "Clemens Meyer",
        "Mukul Bhutani",
        "Andrew Dai",
        "Weiyi Wang",
        "Siqi Liu",
        "Ashwin Sreevatsa",
        "Qijun Tan",
        "Maria Wang",
        "Lucy Kim",
        "Yicheng Wang",
        "Alex Irpan",
        "Yang Xiao",
        "Stanislav Fort",
        "Yifan He",
        "Alex Gurney",
        "Bryan Gale",
        "Yue Ma",
        "Monica Roy",
        "Viorica Patraucean",
        "Taylan Bilal",
        "Golnaz Ghiasi",
        "Anahita Hosseini",
        "Melvin Johnson",
        "Zhuowan Li",
        "Yi Tay",
        "Benjamin Beyret",
        "Katie Millican",
        "Josef Broder",
        "Mayank Lunayach",
        "Danny Swisher",
        "Eugen Vu\\v{s}ak",
        "David Parkinson",
        "MH Tessler",
        "Adi Mayrav Gilady",
        "Richard Song",
        "Allan Dafoe",
        "Yves Raimond",
        "Masa Yamaguchi",
        "Itay Karo",
        "Elizabeth Nielsen",
        "Kevin Kilgour",
        "Mike Dusenberry",
        "Rajiv Mathews",
        "Jiho Choi",
        "Siyuan Qiao",
        "Harsh Mehta",
        "Sahitya Potluri",
        "Chris Knutsen",
        "Jialu Liu",
        "Tat Tan",
        "Kuntal Sengupta",
        "Keerthana Gopalakrishnan",
        "Abodunrinwa Toki",
        "Mencher Chiang",
        "Mike Burrows",
        "Grace Vesom",
        "Zafarali Ahmed",
        "Ilia Labzovsky",
        "Siddharth Vashishtha",
        "Preeti Singh",
        "Ankur Sharma",
        "Ada Ma",
        "Jinyu Xie",
        "Pranav Talluri",
        "Hannah Forbes-Pollard",
        "Aarush Selvan",
        "Joel Wee",
        "Loic Matthey",
        "Tom Funkhouser",
        "Parthasarathy Gopavarapu",
        "Lev Proleev",
        "Cheng Li",
        "Matt Thomas",
        "Kashyap Kolipaka",
        "Zhipeng Jia",
        "Ashwin Kakarla",
        "Srinivas Sunkara",
        "Joan Puigcerver",
        "Suraj Satishkumar Sheth",
        "Emily Graves",
        "Chen Wang",
        "Sadh MNM Khan",
        "Kai Kang",
        "Shyamal Buch",
        "Fred Zhang",
        "Omkar Savant",
        "David Soergel",
        "Kevin Lee",
        "Linda Friso",
        "Xuanyi Dong",
        "Rahul Arya",
        "Shreyas Chandrakaladharan",
        "Connor Schenck",
        "Greg Billock",
        "Tejas Iyer",
        "Anton Bakalov",
        "Leslie Baker",
        "Alex Ruiz",
        "Angad Chandorkar",
        "Trieu Trinh",
        "Matt Miecnikowski",
        "Yanqi Zhou",
        "Yangsibo Huang",
        "Jiazhong Nie",
        "Ali Shah",
        "Ashish Thapliyal",
        "Sam Haves",
        "Lun Wang",
        "Uri Shaham",
        "Patrick Morris-Suzuki",
        "Soroush Radpour",
        "Leonard Berrada",
        "Thomas Strohmann",
        "Chaochao Yan",
        "Jingwei Shen",
        "Sonam Goenka",
        "Tris Warkentin",
        "Petar Devi\\'c",
        "Dan Belov",
        "Albert Webson",
        "Madhavi Yenugula",
        "Puranjay Datta",
        "Jerry Chang",
        "Nimesh Ghelani",
        "Aviral Kumar",
        "Vincent Perot",
        "Jessica Lo",
        "Yang Song",
        "Herman Schmit",
        "Jianmin Chen",
        "Vasilisa Bashlovkina",
        "Xiaoyue Pan",
        "Diana Mincu",
        "Paul Roit",
        "Isabel Edkins",
        "Andy Davis",
        "Yujia Li",
        "Ben Horn",
        "Xinjian Li",
        "Pradeep Kumar S",
        "Eric Doi",
        "Wanzheng Zhu",
        "Sri Gayatri Sundara Padmanabhan",
        "Siddharth Verma",
        "Jasmine Liu",
        "Heng Chen",
        "Mihajlo Velimirovi\\'c",
        "Malcolm Reynolds",
        "Priyanka Agrawal",
        "Nick Sukhanov",
        "Abhinit Modi",
        "Siddharth Goyal",
        "John Palowitch",
        "Nima Khajehnouri",
        "Wing Lowe",
        "David Klinghoffer",
        "Sharon Silver",
        "Vinh Tran",
        "Candice Schumann",
        "Francesco Piccinno",
        "Xi Liu",
        "Mario Lu\\v{c}i\\'c",
        "Xiaochen Yang",
        "Sandeep Kumar",
        "Ajay Kannan",
        "Ragha Kotikalapudi",
        "Mudit Bansal",
        "Fabian Fuchs",
        "Mohammad Javad Hosseini",
        "Abdelrahman Abdelhamed",
        "Dawn Bloxwich",
        "Tianhe Yu",
        "Ruoxin Sang",
        "Gregory Thornton",
        "Karan Gill",
        "Yuchi Liu",
        "Virat Shejwalkar",
        "Jason Lin",
        "Zhipeng Yan",
        "Kehang Han",
        "Thomas Buschmann",
        "Michael Pliskin",
        "Zhi Xing",
        "Susheel Tatineni",
        "Junlin Zhang",
        "Sissie Hsiao",
        "Gavin Buttimore",
        "Marcus Wu",
        "Zefei Li",
        "Geza Kovacs",
        "Legg Yeung",
        "Tao Huang",
        "Aaron Cohen",
        "Bethanie Brownfield",
        "Averi Nowak",
        "Mikel Rodriguez",
        "Tianze Shi",
        "Hado van Hasselt",
        "Kevin Cen",
        "Deepanway Ghoshal",
        "Kushal Majmundar",
        "Weiren Yu",
        "Warren Weilun Chen",
        "Danila Sinopalnikov",
        "Hao Zhang",
        "Vlado Gali\\'c",
        "Di Lu",
        "Zeyu Zheng",
        "Maggie Song",
        "Gary Wang",
        "Gui Citovsky",
        "Swapnil Gawde",
        "Isaac Galatzer-Levy",
        "David Silver",
        "Ivana Balazevic",
        "Dipanjan Das",
        "Kingshuk Majumder",
        "Yale Cong",
        "Praneet Dutta",
        "Dustin Tran",
        "Hui Wan",
        "Junwei Yuan",
        "Daniel Eppens",
        "Alanna Walton",
        "Been Kim",
        "Harry Ragan",
        "James Cobon-Kerr",
        "Lu Liu",
        "Weijun Wang",
        "Bryce Petrini",
        "Jack Rae",
        "Rakesh Shivanna",
        "Yan Xiong",
        "Chace Lee",
        "Pauline Coquinot",
        "Yiming Gu",
        "Lisa Patel",
        "Blake Hechtman",
        "Aviel Boag",
        "Orion Jankowski",
        "Alex Wertheim",
        "Alex Lee",
        "Paul Covington",
        "Hila Noga",
        "Sam Sobell",
        "Shanthal Vasanth",
        "William Bono",
        "Chirag Nagpal",
        "Wei Fan",
        "Xavier Garcia",
        "Kedar Soparkar",
        "Aybuke Turker",
        "Nathan Howard",
        "Sachit Menon",
        "Yuankai Chen",
        "Vikas Verma",
        "Vladimir Pchelin",
        "Harish Rajamani",
        "Valentin Dalibard",
        "Ana Ramalho",
        "Yang Guo",
        "Kartikeya Badola",
        "Seojin Bang",
        "Nathalie Rauschmayr",
        "Julia Proskurnia",
        "Sudeep Dasari",
        "Xinyun Chen",
        "Mikhail Sushkov",
        "Anja Hauth",
        "Pauline Sho",
        "Abhinav Singh",
        "Bilva Chandra",
        "Allie Culp",
        "Max Dylla",
        "Olivier Bachem",
        "James Besley",
        "Heri Zhao",
        "Timothy Lillicrap",
        "Wei Wei",
        "Wael Al Jishi",
        "Ning Niu",
        "Alban Rrustemi",
        "Rapha\\\"el Lopez Kaufman",
        "Ryan Poplin",
        "Jewel Zhao",
        "Minh Truong",
        "Shikhar Bharadwaj",
        "Ester Hlavnova",
        "Eli Stickgold",
        "Cordelia Schmid",
        "Georgi Stephanov",
        "Zhaoqi Leng",
        "Frederick Liu",
        "L\\'eonard Hussenot",
        "Shenil Dodhia",
        "Juliana Vicente Franco",
        "Lesley Katzen",
        "Abhanshu Sharma",
        "Sarah Cogan",
        "Zuguang Yang",
        "Aniket Ray",
        "Sergi Caelles",
        "Shen Yan",
        "Ravin Kumar",
        "Daniel Gillick",
        "Renee Wong",
        "Joshua Ainslie",
        "Jonathan Hoech",
        "S\\'eb Arnold",
        "Dan Abolafia",
        "Anca Dragan",
        "Ben Hora",
        "Grace Hu",
        "Alexey Guseynov",
        "Yang Lu",
        "Chas Leichner",
        "Jinmeng Rao",
        "Abhimanyu Goyal",
        "Nagabhushan Baddi",
        "Daniel Hernandez Diaz",
        "Tim McConnell",
        "Max Bain",
        "Jake Abernethy",
        "Qiqi Yan",
        "Rylan Schaeffer",
        "Paul Vicol",
        "Will Thompson",
        "Montse Gonzalez Arenas",
        "Mathias Bellaiche",
        "Pablo Barrio",
        "Stefan Zinke",
        "Riccardo Patana",
        "Pulkit Mehta",
        "JK Kearns",
        "Avraham Ruderman",
        "Scott Pollom",
        "David D'Ambrosio",
        "Cath Hope",
        "Yang Yu",
        "Andrea Gesmundo",
        "Kuang-Huei Lee",
        "Aviv Rosenberg",
        "Yiqian Zhou",
        "Yaoyiran Li",
        "Drew Garmon",
        "Yonghui Wu",
        "Safeen Huda",
        "Gil Fidel",
        "Martin Baeuml",
        "Jian Li",
        "Phoebe Kirk",
        "Rhys May",
        "Tao Tu",
        "Sara Mc Carthy",
        "Toshiyuki Fukuzawa",
        "Miranda Aperghis",
        "Chih-Kuan Yeh",
        "Toshihiro Yoshino",
        "Bo Li",
        "Austin Myers",
        "Kaisheng Yao",
        "Ben Limonchik",
        "Changwan Ryu",
        "Rohun Saxena",
        "Alex Goldin",
        "Ruizhe Zhao",
        "Rocky Rhodes",
        "Tao Zhu",
        "Divya Tyam",
        "Heidi Howard",
        "Nathan Byrd",
        "Hongxu Ma",
        "Yan Wu",
        "Ryan Mullins",
        "Qingze Wang",
        "Aida Amini",
        "Sebastien Baur",
        "Yiran Mao",
        "Subhashini Venugopalan",
        "Will Song",
        "Wen Ding",
        "Paul Collins",
        "Sashank Reddi",
        "Megan Shum",
        "Andrei Rusu",
        "Luisa Zintgraf",
        "Kelvin Chan",
        "Sheela Goenka",
        "Mathieu Blondel",
        "Michael Collins",
        "Renke Pan",
        "Marissa Giustina",
        "Nikolai Chinaev",
        "Christian Schuler",
        "Ce Zheng",
        "Jonas Valfridsson",
        "Alyssa Loo",
        "Alex Yakubovich",
        "Jamie Smith",
        "Tao Jiang",
        "Rich Munoz",
        "Gabriel Barcik",
        "Rishabh Bansal",
        "Mingyao Yang",
        "Yilun Du",
        "Pablo Duque",
        "Mary Phuong",
        "Alexandra Belias",
        "Kunal Lad",
        "Zeyu Liu",
        "Tal Schuster",
        "Karthik Duddu",
        "Jieru Hu",
        "Paige Kunkle",
        "Matthew Watson",
        "Jackson Tolins",
        "Josh Smith",
        "Denis Teplyashin",
        "Garrett Bingham",
        "Marvin Ritter",
        "Marco Andreetto",
        "Divya Pitta",
        "Mohak Patel",
        "Shashank Viswanadha",
        "Trevor Strohman",
        "Catalin Ionescu",
        "Jincheng Luo",
        "Yogesh Kalley",
        "Jeremy Wiesner",
        "Dan Deutsch",
        "Derek Lockhart",
        "Peter Choy",
        "Rumen Dangovski",
        "Chawin Sitawarin",
        "Cat Graves",
        "Tanya Lando",
        "Joost van Amersfoort",
        "Ndidi Elue",
        "Zhouyuan Huo",
        "Pooya Moradi",
        "Jean Tarbouriech",
        "Henryk Michalewski",
        "Wenting Ye",
        "Eunyoung Kim",
        "Alex Druinsky",
        "Florent Altch\\'e",
        "Xinyi Chen",
        "Artur Dwornik",
        "Da-Cheng Juan",
        "Rivka Moroshko",
        "Horia Toma",
        "Jarrod Kahn",
        "Hai Qian",
        "Maximilian Sieb",
        "Irene Cai",
        "Roman Goldenberg",
        "Praneeth Netrapalli",
        "Sindhu Raghuram",
        "Yuan Gong",
        "Lijie Fan",
        "Evan Palmer",
        "Yossi Matias",
        "Valentin Gabeur",
        "Shreya Pathak",
        "Tom Ouyang",
        "Don Metzler",
        "Geoff Bacon",
        "Srinivasan Venkatachary",
        "Sridhar Thiagarajan",
        "Alex Cullum",
        "Eran Ofek",
        "Vytenis Sakenas",
        "Mohamed Hammad",
        "Cesar Magalhaes",
        "Mayank Daswani",
        "Oscar Chang",
        "Ashok Popat",
        "Ruichao Li",
        "Komal Jalan",
        "Yanhan Hou",
        "Josh Lipschultz",
        "Antoine He",
        "Wenhao Jia",
        "Pier Giuseppe Sessa",
        "Prateek Kolhar",
        "William Wong",
        "Sumeet Singh",
        "Lukas Haas",
        "Jay Whang",
        "Hanna Klimczak-Pluci\\'nska",
        "Georges Rotival",
        "Grace Chung",
        "Yiqing Hua",
        "Anfal Siddiqui",
        "Nicolas Serrano",
        "Dongkai Chen",
        "Billy Porter",
        "Libin Bai",
        "Keshav Shivam",
        "Sho Arora",
        "Partha Talukdar",
        "Tom Cobley",
        "Sangnie Bhardwaj",
        "Evgeny Gladchenko",
        "Simon Green",
        "Kelvin Guu",
        "Felix Fischer",
        "Xiao Wu",
        "Eric Wang",
        "Achintya Singhal",
        "Tatiana Matejovicova",
        "James Martens",
        "Hongji Li",
        "Roma Patel",
        "Elizabeth Kemp",
        "Jiaqi Pan",
        "Lily Wang",
        "Blake JianHang Chen",
        "Jean-Baptiste Alayrac",
        "Navneet Potti",
        "Erika Gemzer",
        "Eugene Ie",
        "Kay McKinney",
        "Takaaki Saeki",
        "Edward Chou",
        "Pascal Lamblin",
        "SQ Mah",
        "Zach Fisher",
        "Martin Chadwick",
        "Jon Stritar",
        "Obaid Sarvana",
        "Andrew Hogue",
        "Artem Shtefan",
        "Hadi Hashemi",
        "Yang Xu",
        "Jindong Gu",
        "Sharad Vikram",
        "Chung-Ching Chang",
        "Sabela Ramos",
        "Logan Kilpatrick",
        "Weijuan Xi",
        "Jenny Brennan",
        "Yinghao Sun",
        "Abhishek Jindal",
        "Ionel Gog",
        "Dawn Chen",
        "Felix Wu",
        "Jason Lee",
        "Sudhindra Kopalle",
        "Srinadh Bhojanapalli",
        "Oriol Vinyals",
        "Natan Potikha",
        "Burcu Karagol Ayan",
        "Yuan Yuan",
        "Michael Riley",
        "Piotr Stanczyk",
        "Sergey Kishchenko",
        "Bing Wang",
        "Dan Garrette",
        "Antoine Yang",
        "Vlad Feinberg",
        "CJ Carey",
        "Javad Azizi",
        "Viral Shah",
        "Erica Moreira",
        "Chongyang Shi",
        "Josh Feldman",
        "Elizabeth Salesky",
        "Thomas Lampe",
        "Aneesh Pappu",
        "Duhyeon Kim",
        "Jonas Adler",
        "Avi Caciularu",
        "Brian Walker",
        "Yunhan Xu",
        "Yochai Blau",
        "Dylan Scandinaro",
        "Terry Huang",
        "Sam El-Husseini",
        "Abhishek Sinha",
        "Lijie Ren",
        "Taylor Tobin",
        "Patrik Sundberg",
        "Tim Sohn",
        "Vikas Yadav",
        "Mimi Ly",
        "Emily Xue",
        "Jing Xiong",
        "Afzal Shama Soudagar",
        "Sneha Mondal",
        "Nikhil Khadke",
        "Qingchun Ren",
        "Ben Vargas",
        "Stan Bileschi",
        "Sarah Chakera",
        "Cindy Wang",
        "Boyu Wang",
        "Yoni Halpern",
        "Joe Jiang",
        "Vikas Sindhwani",
        "Petre Petrov",
        "Pranavaraj Ponnuramu",
        "Sanket Vaibhav Mehta",
        "Yu Watanabe",
        "Betty Chan",
        "Matheus Wisniewski",
        "Trang Pham",
        "Jingwei Zhang",
        "Conglong Li",
        "Dario de Cesare",
        "Art Khurshudov",
        "Alex Vasiloff",
        "Melissa Tan",
        "Zoe Ashwood",
        "Bobak Shahriari",
        "Maryam Majzoubi",
        "Garrett Tanzer",
        "Olga Kozlova",
        "Robin Alazard",
        "James Lee-Thorp",
        "Nguyet Minh Phu",
        "Isaac Tian",
        "Junwhan Ahn",
        "Andy Crawford",
        "Lauren Lax",
        "Yuan Shangguan",
        "Iftekhar Naim",
        "David Ross",
        "Oleksandr Ferludin",
        "Tongfei Guo",
        "Andrea Banino",
        "Hubert Soyer",
        "Xiaoen Ju",
        "Dominika Rogozi\\'nska",
        "Ishaan Malhi",
        "Marcella Valentine",
        "Daniel Balle",
        "Apoorv Kulshreshtha",
        "Maciej Kula",
        "Yiwen Song",
        "Sophia Austin",
        "John Schultz",
        "Roy Hirsch",
        "Arthur Douillard",
        "Apoorv Reddy",
        "Michael Fink",
        "Summer Yue",
        "Khyatti Gupta",
        "Adam Zhang",
        "Norman Rink",
        "Daniel McDuff",
        "Lei Meng",
        "Andr\\'as Gy\\\"orgy",
        "Yasaman Razeghi",
        "Ricky Liang",
        "Kazuki Osawa",
        "Aviel Atias",
        "Matan Eyal",
        "Tyrone Hill",
        "Nikolai Grigorev",
        "Zhengdong Wang",
        "Nitish Kulkarni",
        "Rachel Soh",
        "Ivan Lobov",
        "Zachary Charles",
        "Sid Lall",
        "Kazuma Hashimoto",
        "Ido Kessler",
        "Victor Gomes",
        "Zelda Mariet",
        "Danny Driess",
        "Alessandro Agostini",
        "Canfer Akbulut",
        "Jingcao Hu",
        "Marissa Ikonomidis",
        "Emily Caveness",
        "Kartik Audhkhasi",
        "Saurabh Agrawal",
        "Ioana Bica",
        "Evan Senter",
        "Jayaram Mudigonda",
        "Kelly Chen",
        "Jingchen Ye",
        "Xuanhui Wang",
        "James Svensson",
        "Philipp Fr\\\"anken",
        "Josh Newlan",
        "Li Lao",
        "Eva Schnider",
        "Sami Alabed",
        "Joseph Kready",
        "Jesse Emond",
        "Afief Halumi",
        "Tim Zaman",
        "Chengxi Ye",
        "Naina Raisinghani",
        "Vilobh Meshram",
        "Bo Chang",
        "Ankit Singh Rawat",
        "Axel Stjerngren",
        "Sergey Levi",
        "Rui Wang",
        "Xiangzhu Long",
        "Mitchelle Rasquinha",
        "Steven Hand",
        "Aditi Mavalankar",
        "Lauren Agubuzu",
        "Sudeshna Roy",
        "Junquan Chen",
        "Jarek Wilkiewicz",
        "Hao Zhou",
        "Michal Jastrzebski",
        "Qiong Hu",
        "Agustin Dal Lago",
        "Ramya Sree Boppana",
        "Wei-Jen Ko",
        "Jennifer Prendki",
        "Yao Su",
        "Zhi Li",
        "Eliza Rutherford",
        "Girish Ramchandra Rao",
        "Ramona Comanescu",
        "Adri\\`a Puigdom\\`enech",
        "Qihang Chen",
        "Dessie Petrova",
        "Christine Chan",
        "Vedrana Milutinovic",
        "Felipe Tiengo Ferreira",
        "Chin-Yi Cheng",
        "Ming Zhang",
        "Tapomay Dey",
        "Sherry Yang",
        "Ramesh Sampath",
        "Quoc Le",
        "Howard Zhou",
        "Chu-Cheng Lin",
        "Hoi Lam",
        "Christine Kaeser-Chen",
        "Kai Hui",
        "Dean Hirsch",
        "Tom Eccles",
        "Basil Mustafa",
        "Shruti Rijhwani",
        "Morgane Rivi\\`ere",
        "Yuanzhong Xu",
        "Junjie Wang",
        "Xinyang Geng",
        "Xiance Si",
        "Arjun Khare",
        "Cheolmin Kim",
        "Vahab Mirrokni",
        "Kamyu Lee",
        "Khuslen Baatarsukh",
        "Nathaniel Braun",
        "Lisa Wang",
        "Pallavi LV",
        "Richard Tanburn",
        "Yonghao Zhu",
        "Fangda Li",
        "Setareh Ariafar",
        "Dan Goldberg",
        "Ken Burke",
        "Daniil Mirylenka",
        "Meiqi Guo",
        "Olaf Ronneberger",
        "Hadas Natalie Vogel",
        "Liqun Cheng",
        "Nishita Shetty",
        "Johnson Jia",
        "Thomas Jimma",
        "Corey Fry",
        "Ted Xiao",
        "Martin Sundermeyer",
        "Ryan Burnell",
        "Yannis Assael",
        "Mario Pinto",
        "JD Chen",
        "Rohit Sathyanarayana",
        "Donghyun Cho",
        "Jing Lu",
        "Rishabh Agarwal",
        "Sugato Basu",
        "Lucas Gonzalez",
        "Dhruv Shah",
        "Meng Wei",
        "Dre Mahaarachchi",
        "Rohan Agrawal",
        "Tero Rissa",
        "Yani Donchev",
        "Ramiro Leal-Cavazos",
        "Adrian Hutter",
        "Markus Mircea",
        "Alon Jacovi",
        "Faruk Ahmed",
        "Jiageng Zhang",
        "Shuguang Hu",
        "Bo-Juen Chen",
        "Jonni Kanerva",
        "Guillaume Desjardins",
        "Andrew Lee",
        "Nikos Parotsidis",
        "Asier Mujika",
        "Tobias Weyand",
        "Jasper Snoek",
        "Jo Chick",
        "Kai Chen",
        "Paul Chang",
        "Ethan Mahintorabi",
        "Zi Wang",
        "Tolly Powell",
        "Orgad Keller",
        "Abhirut Gupta",
        "Claire Sha",
        "Kanav Garg",
        "Nicolas Heess",
        "\\'Agoston Weisz",
        "Cassidy Hardin",
        "Bartek Wydrowski",
        "Ben Coleman",
        "Karina Zainullina",
        "Pankaj Joshi",
        "Alessandro Epasto",
        "Terry Spitz",
        "Binbin Xiong",
        "Kai Zhao",
        "Arseniy Klimovskiy",
        "Ivy Zheng",
        "Johan Ferret",
        "Itay Yona",
        "Waleed Khawaja",
        "Jean-Baptiste Lespiau",
        "Maxim Krikun",
        "Siamak Shakeri",
        "Timothee Cour",
        "Bonnie Li",
        "Igor Krivokon",
        "Dan Suh",
        "Alex Hofer",
        "Jad Al Abdallah",
        "Nikita Putikhin",
        "Oscar Akerlund",
        "Silvio Lattanzi",
        "Anurag Kumar",
        "Shane Settle",
        "Himanshu Srivastava",
        "Folawiyo Campbell-Ajala",
        "Edouard Rosseel",
        "Mihai Dorin Istin",
        "Nishanth Dikkala",
        "Anand Rao",
        "Nick Young",
        "Kate Lin",
        "Dhruva Bhaswar",
        "Yiming Wang",
        "Jaume Sanchez Elias",
        "Kritika Muralidharan",
        "James Keeling",
        "Dayou Du",
        "Siddharth Gopal",
        "Gregory Dibb",
        "Charles Blundell",
        "Manolis Delakis",
        "Jacky Liang",
        "Marco Tulio Ribeiro",
        "Georgi Karadzhov",
        "Guillermo Garrido",
        "Ankur Bapna",
        "Jiawei Cao",
        "Adam Sadovsky",
        "Pouya Tafti",
        "Arthur Guez",
        "Coline Devin",
        "Yixian Di",
        "Jinwei Xing",
        "Chuqiao Joyce Xu",
        "Hanzhao Lin",
        "Chun-Te Chu",
        "Sameera Ponda",
        "Wesley Helmholz",
        "Fan Yang",
        "Yue Gao",
        "Sara Javanmardi",
        "Wael Farhan",
        "Alex Ramirez",
        "Ricardo Figueira",
        "Khe Chai Sim",
        "Yuval Bahat",
        "Ashwin Vaswani",
        "Liangzhe Yuan",
        "Gufeng Zhang",
        "Leland Rechis",
        "Hanjun Dai",
        "Tayo Oguntebi",
        "Alexandra Cordell",
        "Eug\\'enie Rives",
        "Kaan Tekelioglu",
        "Naveen Kumar",
        "Bing Zhang",
        "Aurick Zhou",
        "Nikolay Savinov",
        "Andrew Leach",
        "Alex Tudor",
        "Sanjay Ganapathy",
        "Yanyan Zheng",
        "Mirko Rossini",
        "Vera Axelrod",
        "Arnaud Autef",
        "Yukun Zhu",
        "Zheng Zheng",
        "Mingda Zhang",
        "Baochen Sun",
        "Jie Ren",
        "Nenad Tomasev",
        "Nithish Kannen",
        "Amer Sinha",
        "Charles Chen",
        "Louis O'Bryan",
        "Alex Pak",
        "Aditya Kusupati",
        "Weel Yang",
        "Deepak Ramachandran",
        "Patrick Griffin",
        "Seokhwan Kim",
        "Philipp Neubeck",
        "Craig Schiff",
        "Tammo Spalink",
        "Mingyang Ling",
        "Arun Nair",
        "Ga-Young Joung",
        "Linda Deng",
        "Avishkar Bhoopchand",
        "Lora Aroyo",
        "Tom Duerig",
        "Jordan Griffith",
        "Gabe Barth-Maron",
        "Jake Ades",
        "Alex Haig",
        "Ankur Taly",
        "Yunting Song",
        "Paul Michel",
        "Dave Orr",
        "Dean Weesner",
        "Corentin Tallec",
        "Carrie Grimes Bostock",
        "Paul Niemczyk",
        "Andy Twigg",
        "Mudit Verma",
        "Rohith Vallu",
        "Henry Wang",
        "Marco Gelmi",
        "Kiranbir Sodhia",
        "Aleksandr Chuklin",
        "Omer Goldman",
        "Jasmine George",
        "Liang Bai",
        "Kelvin Zhang",
        "Petar Sirkovic",
        "Efrat Nehoran",
        "Golan Pundak",
        "Jiaqi Mu",
        "Alice Chen",
        "Alex Greve",
        "Paulo Zacchello",
        "David Amos",
        "Heming Ge",
        "Eric Noland",
        "Colton Bishop",
        "Jeffrey Dudek",
        "Youhei Namiki",
        "Elena Buchatskaya",
        "Jing Li",
        "Dorsa Sadigh",
        "Masha Samsikova",
        "Dan Malkin",
        "Damien Vincent",
        "Robert David",
        "Rob Willoughby",
        "Phoenix Meadowlark",
        "Shawn Gao",
        "Yan Li",
        "Raj Apte",
        "Amit Jhindal",
        "Stein Xudong Lin",
        "Alex Polozov",
        "Zhicheng Wang",
        "Tomas Mery",
        "Anirudh GP",
        "Varun Yerram",
        "Sage Stevens",
        "Tianqi Liu",
        "Noah Fiedel",
        "Charles Sutton",
        "Matthew Johnson",
        "Xiaodan Song",
        "Kate Baumli",
        "Nir Shabat",
        "Muqthar Mohammad",
        "Hao Liu",
        "Marco Selvi",
        "Yichao Zhou",
        "Mehdi Hafezi Manshadi",
        "Chu-ling Ko",
        "Anthony Chen",
        "Michael Bendersky",
        "Jorge Gonzalez Mendez",
        "Nisarg Kothari",
        "Amir Zandieh",
        "Yiling Huang",
        "Daniel Andor",
        "Ellie Pavlick",
        "Idan Brusilovsky",
        "Jitendra Harlalka",
        "Sally Goldman",
        "Andrew Lampinen",
        "Guowang Li",
        "Asahi Ushio",
        "Somit Gupta",
        "Lei Zhang",
        "Chuyuan Kelly Fu",
        "Madhavi Sewak",
        "Timo Denk",
        "Jed Borovik",
        "Brendan Jou",
        "Avital Zipori",
        "Prateek Jain",
        "Junwen Bai",
        "Thang Luong",
        "Jonathan Tompson",
        "Alice Li",
        "Li Liu",
        "George Powell",
        "Jiajun Shen",
        "Alex Feng",
        "Grishma Chole",
        "Da Yu",
        "Yinlam Chow",
        "Tongxin Yin",
        "Eric Malmi",
        "Kefan Xiao",
        "Yash Pande",
        "Shachi Paul",
        "Niccol\\`o Dal Santo",
        "Adil Dostmohamed",
        "Sergio Guadarrama",
        "Aaron Phillips",
        "Thanumalayan Sankaranarayana Pillai",
        "Gal Yona",
        "Amin Ghafouri",
        "Preethi Lahoti",
        "Benjamin Lee",
        "Dhruv Madeka",
        "Eren Sezener",
        "Simon Tokumine",
        "Adrian Collister",
        "Nicola De Cao",
        "Richard Shin",
        "Uday Kalra",
        "Parker Beak",
        "Emily Nottage",
        "Ryo Nakashima",
        "Ivan Jurin",
        "Vikash Sehwag",
        "Meenu Gaba",
        "Junhao Zeng",
        "Kevin R. McKee",
        "Fernando Pereira",
        "Tamar Yakar",
        "Amayika Panda",
        "Arka Dhar",
        "Peilin Zhong",
        "Daniel Sohn",
        "Mark Brand",
        "Lars Lowe Sjoesund",
        "Viral Carpenter",
        "Sharon Lin",
        "Shantanu Thakoor",
        "Marcus Wainwright",
        "Ashwin Chaugule",
        "Pranesh Srinivasan",
        "Muye Zhu",
        "Bernett Orlando",
        "Jack Weber",
        "Ayzaan Wahid",
        "Gilles Baechler",
        "Apurv Suman",
        "Jovana Mitrovi\\'c",
        "Gabe Taubman",
        "Honglin Yu",
        "Helen King",
        "Josh Dillon",
        "Cathy Yip",
        "Dhriti Varma",
        "Tomas Izo",
        "Levent Bolelli",
        "Borja De Balle Pigem",
        "Julia Di Trapani",
        "Fotis Iliopoulos",
        "Adam Paszke",
        "Nishant Ranka",
        "Joe Zou",
        "Francesco Pongetti",
        "Jed McGiffin",
        "Alex Siegman",
        "Rich Galt",
        "Ross Hemsley",
        "Goran \\v{Z}u\\v{z}i\\'c",
        "Victor Carbune",
        "Tao Li",
        "Myle Ott",
        "F\\'elix de Chaumont Quitry",
        "David Vilar Torres",
        "Yuri Chervonyi",
        "Tomy Tsai",
        "Prem Eruvbetine",
        "Samuel Yang",
        "Matthew Denton",
        "Jake Walker",
        "Slavica Anda\\v{c}i\\'c",
        "Idan Heimlich Shtacher",
        "Vittal Premachandran",
        "Harshal Tushar Lehri",
        "Cip Baetu",
        "Damion Yates",
        "Lampros Lamprou",
        "Mariko Iinuma",
        "Ioana Mihailescu",
        "Ben Albrecht",
        "Shachi Dave",
        "Susie Sargsyan",
        "Bryan Perozzi",
        "Lucas Manning",
        "Chiyuan Zhang",
        "Denis Vnukov",
        "Igor Mordatch",
        "Raia Hadsell Wolfgang Macherey",
        "Ryan Kappedal",
        "Jim Stephan",
        "Aditya Tripathi",
        "Klaus Macherey",
        "Jun Qian",
        "Abhishek Bhowmick",
        "Shekoofeh Azizi",
        "R\\'emi Leblond",
        "Shiva Mohan Reddy Garlapati",
        "Timothy Knight",
        "Matthew Wiethoff",
        "Wei-Chih Hung",
        "Anelia Angelova",
        "Georgios Evangelopoulos",
        "Pawel Janus",
        "Dimitris Paparas",
        "Matthew Rahtz",
        "Ken Caluwaerts",
        "Vivek Sampathkumar",
        "Daniel Jarrett",
        "Shadi Noghabi",
        "Antoine Miech",
        "Chak Yeung",
        "Geoff Clark",
        "Henry Prior",
        "Fei Zheng",
        "Jean Pouget-Abadie",
        "Indro Bhattacharya",
        "Kalpesh Krishna",
        "Will Bishop",
        "Zhe Yuan",
        "Yunxiao Deng",
        "Ashutosh Sathe",
        "Kacper Krasowiak",
        "Ciprian Chelba",
        "Cho-Jui Hsieh",
        "Kiran Vodrahalli",
        "Buhuang Liu",
        "Thomas K\\\"oppe",
        "Amr Khalifa",
        "Lubo Litchev",
        "Pichi Charoenpanit",
        "Reed Roberts",
        "Sachin Yadav",
        "Yasumasa Onoe",
        "Desi Ivanov",
        "Megha Mohabey",
        "Vighnesh Birodkar",
        "Nemanja Raki\\'cevi\\'c",
        "Pierre Sermanet",
        "Vaibhav Mehta",
        "Krishan Subudhi",
        "Travis Choma",
        "Will Ng",
        "Luheng He",
        "Kathie Wang",
        "Tasos Kementsietsidis",
        "Shane Gu",
        "Mansi Gupta",
        "Andrew Nystrom",
        "Mehran Kazemi",
        "Timothy Chung",
        "Nacho Cano",
        "Nikhil Dhawan",
        "Yufei Wang",
        "Jiawei Xia",
        "Trevor Yacovone",
        "Eric Jia",
        "Mingqing Chen",
        "Simeon Ivanov",
        "Ashrith Sheshan",
        "Sid Dalmia",
        "Pawe{\\l} Stradomski",
        "Pengcheng Yin",
        "Salem Haykal",
        "Congchao Wang",
        "Dennis Duan",
        "Neslihan Bulut",
        "Greg Kochanski",
        "Liam MacDermed",
        "Namrata Godbole",
        "Shitao Weng",
        "Jingjing Chen",
        "Rachana Fellinger",
        "Ramin Mehran",
        "Daniel Suo",
        "Hisham Husain",
        "Tong He",
        "Kaushal Patel",
        "Joshua Howland",
        "Randall Parker",
        "Kelvin Nguyen",
        "Sharath Maddineni",
        "Chris Rawles",
        "Mina Khan",
        "Shlomi Cohen-Ganor",
        "Amol Mandhane",
        "Xinyi Wu",
        "Chenkai Kuang",
        "Iulia Com\\c{s}a",
        "Ramya Ganeshan",
        "Hanie Sedghi",
        "Adam Bloniarz",
        "Nuo Wang Pierse",
        "Anton Briukhov",
        "Petr Mitrichev",
        "Anita Gergely",
        "Serena Zhan",
        "Allan Zhou",
        "Nikita Saxena",
        "Eva Lu",
        "Josef Dean",
        "Ashish Gupta",
        "Nicolas Perez-Nieves",
        "Renjie Wu",
        "Cory McLean",
        "Wei Liang",
        "Disha Jindal",
        "Anton Tsitsulin",
        "Wenhao Yu",
        "Kaiz Alarakyia",
        "Tom Schaul",
        "Piyush Patil",
        "Peter Sung",
        "Elijah Peake",
        "Hongkun Yu",
        "Feryal Behbahani",
        "JD Co-Reyes",
        "Alan Ansell",
        "Sean Sun",
        "Clara Barbu",
        "Jonathan Lee",
        "Seb Noury",
        "James Allingham",
        "Bilal Piot",
        "Mohit Sharma",
        "Christopher Yew",
        "Ivan Korotkov",
        "Bibo Xu",
        "Demetra Brady",
        "Goran Petrovic",
        "Shibl Mourad",
        "Claire Cui",
        "Aditya Gupta",
        "Parker Schuh",
        "Saarthak Khanna",
        "Anna Goldie",
        "Abhinav Arora",
        "Vadim Zubov",
        "Amy Stuart",
        "Mark Epstein",
        "Yun Zhu",
        "Jianqiao Liu",
        "Yury Stuken",
        "Ziyue Wang",
        "Karolis Misiunas",
        "Dee Guo",
        "Ashleah Gill",
        "Ale Hartman",
        "Zaid Nabulsi",
        "Aurko Roy",
        "Aleksandra Faust",
        "Jason Riesa",
        "Ben Withbroe",
        "Mengchao Wang",
        "Marco Tagliasacchi",
        "Andreea Marzoca",
        "James Noraky",
        "Serge Toropov",
        "Malika Mehrotra",
        "Bahram Raad",
        "Sanja Deur",
        "Steve Xu",
        "Marianne Monteiro",
        "Zhongru Wu",
        "Yi Luan",
        "Sam Ritter",
        "Nick Li",
        "H{\\aa}vard Garnes",
        "Yanzhang He",
        "Martin Zlocha",
        "Jifan Zhu",
        "Matteo Hessel",
        "Will Wu",
        "Spandana Raj Babbula",
        "Chizu Kawamoto",
        "Yuanzhen Li",
        "Mehadi Hassen",
        "Yan Wang",
        "Brian Wieder",
        "James Freedman",
        "Yin Zhang",
        "Xinyi Bai",
        "Tianli Yu",
        "David Reitter",
        "XiangHai Sheng",
        "Mateo Wirth",
        "Aditya Kini",
        "Dima Damen",
        "Mingcen Gao",
        "Rachel Hornung",
        "Michael Voznesensky",
        "Brian Roark",
        "Adhi Kuncoro",
        "Yuxiang Zhou",
        "Rushin Shah",
        "Anthony Brohan",
        "Kuangyuan Chen",
        "James Wendt",
        "David Rim",
        "Paul Kishan Rubenstein",
        "Jonathan Halcrow",
        "Michelle Liu",
        "Ty Geri",
        "Yunhsuan Sung",
        "Jane Shapiro",
        "Shaan Bijwadia",
        "Chris Duvarney",
        "Christina Sorokin",
        "Paul Natsev",
        "Reeve Ingle",
        "Pramod Gupta",
        "Young Maeng",
        "Ndaba Ndebele",
        "Kexin Zhu",
        "Valentin Anklin",
        "Katherine Lee",
        "Yuan Liu",
        "Yaroslav Akulov",
        "Shaleen Gupta",
        "Guolong Su",
        "Flavien Prost",
        "Tianlin Liu",
        "Vitaly Kovalev",
        "Pol Moreno",
        "Martin Scholz",
        "Sam Redmond",
        "Zongwei Zhou",
        "Alex Castro-Ros",
        "Andr\\'e Susano Pinto",
        "Dia Kharrat",
        "Michal Yarom",
        "Rachel Saputro",
        "Jannis Bulian",
        "Ben Caine",
        "Ji Liu",
        "Abbas Abdolmaleki",
        "Shariq Iqbal",
        "Tautvydas Misiunas",
        "Mikhail Sirotenko",
        "Shefali Garg",
        "Guy Bensky",
        "Huan Gui",
        "Xuezhi Wang",
        "Raphael Koster",
        "Mike Bernico",
        "Da Huang",
        "Romal Thoppilan",
        "Trevor Cohn",
        "Ben Golan",
        "Wenlei Zhou",
        "Andrew Rosenberg",
        "Markus Freitag",
        "Tynan Gangwani",
        "Vincent Tsang",
        "Anand Shukla",
        "Xiaoqi Ren",
        "Minh Giang",
        "Chi Zou",
        "Andre Elisseeff",
        "Charline Le Lan",
        "Dheeru Dua",
        "Shuba Lall",
        "Pranav Shyam",
        "Frankie Garcia",
        "Sarah Nguyen",
        "Michael Guzman",
        "AJ Maschinot",
        "Marcello Maggioni",
        "Ming-Wei Chang",
        "Karol Gregor",
        "Lotte Weerts",
        "Kumaran Venkatesan",
        "Bogdan Damoc",
        "Leon Liu",
        "Jan Wassenberg",
        "Lewis Ho",
        "Becca Roelofs",
        "Majid Hadian",
        "Fran\\c{c}ois-Xavier Aubet",
        "Yu Liang",
        "Sami Lachgar",
        "Danny Karmon",
        "Yong Cheng",
        "Amelio V\\'azquez-Reina",
        "Angie Chen",
        "Zhuyun Dai",
        "Andy Brock",
        "Shubham Agrawal",
        "Chenxi Pang",
        "Peter Garst",
        "Mariella Sanchez-Vargas",
        "Ivor Rendulic",
        "Aditya Ayyar",
        "Andrija Ra\\v{z}natovi\\'c",
        "Olivia Ma",
        "Roopali Vij",
        "Neha Sharma",
        "Ashwin Balakrishna",
        "Bingyuan Liu",
        "Ian Mackinnon",
        "Sorin Baltateanu",
        "Petra Poklukar",
        "Gabriel Ibagon",
        "Colin Ji",
        "Hongyang Jiao",
        "Isaac Noble",
        "Wojciech Stokowiec",
        "Zhihao Li",
        "Jeff Dean",
        "David Lindner",
        "Mark Omernick",
        "Kristen Chiafullo",
        "Mason Dimarco",
        "Vitor Rodrigues",
        "Vittorio Selo",
        "Garrett Honke",
        "Xintian Cindy Wu",
        "Wei He",
        "Adam Hillier",
        "Anhad Mohananey",
        "Vihari Piratla",
        "Chang Ye",
        "Chase Malik",
        "Sebastian Riedel",
        "Samuel Albanie",
        "Zi Yang",
        "Kenny Vassigh",
        "Maria Bauza",
        "Sheng Li",
        "Yiqing Tao",
        "Nevan Wichers",
        "Andrii Maksai",
        "Abe Ittycheriah",
        "Ross Mcilroy",
        "Bryan Seybold",
        "Noah Goodman",
        "Romina Datta",
        "Steven M. Hernandez",
        "Tian Shi",
        "Yony Kochinski",
        "Anna Bulanova",
        "Ken Franko",
        "Mikita Sazanovich",
        "Nicholas FitzGerald",
        "Praneeth Kacham",
        "Shubha Srinivas Raghvendra",
        "Vincent Hellendoorn",
        "Alexander Grushetsky",
        "Julian Salazar",
        "Angeliki Lazaridou",
        "Jason Chang",
        "Jan-Thorsten Peter",
        "Sushant Kafle",
        "Yann Dauphin",
        "Abhishek Rao",
        "Filippo Graziano",
        "Izhak Shafran",
        "Yuguo Liao",
        "Tianli Ding",
        "Geng Yan",
        "Grace Chu",
        "Zhao Fu",
        "Vincent Roulet",
        "Gabriel Rasskin",
        "Duncan Williams",
        "Shahar Drath",
        "Alex Mossin",
        "Raphael Hoffmann",
        "Jordi Orbay",
        "Francesco Bertolini",
        "Hila Sheftel",
        "Justin Chiu",
        "Siyang Xue",
        "Yuheng Kuang",
        "Ferjad Naeem",
        "Swaroop Nath",
        "Nana Nti",
        "Phil Culliton",
        "Kashyap Krishnakumar",
        "Michael Isard",
        "Pei Sun",
        "Ayan Chakrabarti",
        "Nathan Clement",
        "Regev Cohen",
        "Arissa Wongpanich",
        "GS Oh",
        "Ashwin Murthy",
        "Hao Zheng",
        "Jessica Hamrick",
        "Oskar Bunyan",
        "Suhas Ganesh",
        "Nitish Gupta",
        "Roy Frostig",
        "John Wieting",
        "Yury Malkov",
        "Pierre Marcenac",
        "Zhixin Lucas Lai",
        "Xiaodan Tang",
        "Mohammad Saleh",
        "Fedir Zubach",
        "Chinmay Kulkarni",
        "Huanjie Zhou",
        "Vicky Zayats",
        "Nan Ding",
        "Anshuman Tripathi",
        "Arijit Pramanik",
        "Patrik Zochbauer",
        "Harish Ganapathy",
        "Vedant Misra",
        "Zach Behrman",
        "Hugo Vallet",
        "Mingyang Zhang",
        "Mukund Sridhar",
        "Ye Jin",
        "Mohammad Babaeizadeh",
        "Siim P\\~oder",
        "Megha Goel",
        "Divya Jain",
        "Tajwar Nasir",
        "Shubham Mittal",
        "Tim Dozat",
        "Diego Ardila",
        "Aliaksei Severyn",
        "Fabio Pardo",
        "Sammy Jerome",
        "Siyang Qin",
        "Louis Rouillard",
        "Amir Yazdanbakhsh",
        "Zizhao Zhang",
        "Shivani Agrawal",
        "Kaushik Shivakumar",
        "Caden Lu",
        "Praveen Kallakuri",
        "Rachita Chhaparia",
        "Kanishka Rao",
        "Charles Kwong",
        "Asya Fadeeva",
        "Shitij Nigam",
        "Yan Virin",
        "Yuan Zhang",
        "Balaji Venkatraman",
        "Beliz Gunel",
        "Marc Wilson",
        "Huiyu Wang",
        "Abhinav Gupta",
        "Xiaowei Xu",
        "Adrien Ali Ta\\\"iga",
        "Kareem Mohamed",
        "Doug Fritz",
        "Daniel Rodriguez",
        "Zoubin Ghahramani",
        "Harry Askham",
        "Lior Belenki",
        "James Zhao",
        "Rahul Gupta",
        "Krzysztof Jastrz\\k{e}bski",
        "Takahiro Kosakai",
        "Kaan Katircioglu",
        "Jon Schneider",
        "Rina Panigrahy",
        "Konstantinos Bousmalis",
        "Peter Grabowski",
        "Prajit Ramachandran",
        "Chaitra Hegde",
        "Mihaela Rosca",
        "Angelo Scorza Scarpati",
        "Kyriakos Axiotis",
        "Ying Xu",
        "Zach Gleicher",
        "Assaf Hurwitz Michaely",
        "Mandar Sharma",
        "Sanil Jain",
        "Christoph Hirnschall",
        "Tal Marian",
        "Xuhui Jia",
        "Kevin Mather",
        "Kilol Gupta",
        "Linhai Qiu",
        "Nigamaa Nayakanti",
        "Lucian Ionita",
        "Steven Zheng",
        "Lucia Loher",
        "Kurt Shuster",
        "Igor Petrovski",
        "Roshan Sharma",
        "Rahma Chaabouni",
        "Angel Yeh",
        "James An",
        "Arushi Gupta",
        "Steven Schwarcz",
        "Seher Ellis",
        "Sam Conway-Rahman",
        "Javier Snaider",
        "Alex Zhai",
        "James Atwood",
        "Daniel Golovin",
        "Liqian Peng",
        "Te I",
        "Vivian Xia",
        "Salvatore Scellato",
        "Mahan Malihi",
        "Arthur Bra\\v{z}inskas",
        "Vlad-Doru Ion",
        "Younghoon Jun",
        "James Swirhun",
        "Soroosh Mariooryad",
        "Jiao Sun",
        "Steve Chien",
        "Rey Coaguila",
        "Ariel Brand",
        "Yi Gao",
        "Tom Kwiatkowski",
        "Roee Aharoni",
        "Cheng-Chun Lee",
        "Mislav \\v{Z}ani\\'c",
        "Yichi Zhang",
        "Dan Ethier",
        "Vitaly Nikolaev",
        "Pranav Nair",
        "Yoav Ben Shalom",
        "Hen Fitoussi",
        "Jai Gupta",
        "Hongbin Liu",
        "Dee Cattle",
        "Tolga Bolukbasi",
        "Ben Murdoch",
        "Fantine Huot",
        "Yin Li",
        "Chris Hahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T17:36:04+00:00",
          "link": "https://arxiv.org/abs/2507.06261v1",
          "size": "8601kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:03:21+00:00",
          "link": "https://arxiv.org/abs/2507.06261v2",
          "size": "8601kb",
          "version": "v2"
        }
      ],
      "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06261",
        "HTML": "https://arxiv.org/html/2507.06261v2",
        "PDF": "https://arxiv.org/pdf/2507.06261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on introducing new models and their performance on various benchmarks, but it does not mention any specific contribution towards LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08027",
      "abstract": "Recent studies have revealed a consistent liberal orientation in the ethical and political responses generated by most commercial large language models (LLMs), yet the underlying causes and resulting implications remain unclear. This paper systematically investigates the political temperament of seven prominent LLMs - OpenAI's GPT-4o, Anthropic's Claude Sonnet 4, Perplexity (Sonar Large), Google's Gemini 2.5 Flash, Meta AI's Llama 4, Mistral 7b Le Chat and High-Flyer's DeepSeek R1 -- using a multi-pronged approach that includes Moral Foundations Theory, a dozen established political ideology scales and a new index of current political controversies. We find strong and consistent prioritization of liberal-leaning values, particularly care and fairness, across most models. Further analysis attributes this trend to four overlapping factors: Liberal-leaning training corpora, reinforcement learning from human feedback (RLHF), the dominance of liberal frameworks in academic ethical discourse and safety-driven fine-tuning practices. We also distinguish between political \"bias\" and legitimate epistemic differences, cautioning against conflating the two. A comparison of base and fine-tuned model pairs reveals that fine-tuning generally increases liberal lean, an effect confirmed through both self-report and empirical testing. We argue that this \"liberal tilt\" is not a programming error or the personal preference of programmers but an emergent property of training on democratic rights-focused discourse. Finally, we propose that LLMs may indirectly echo John Rawls' famous veil-of ignorance philosophical aspiration, reflecting a moral stance unanchored to personal identity or interest. Rather than undermining democratic discourse, this pattern may offer a new lens through which to examine collective reasoning.",
      "authors": [
        "W. Russell Neuman",
        "Chad Coleman",
        "Ali Dasdan",
        "Safinah Ali",
        "Manan Shah",
        "Kund Meghani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:19:25+00:00",
          "link": "https://arxiv.org/abs/2507.08027v1",
          "size": "791kb",
          "version": "v1"
        }
      ],
      "title": "\"Amazing, They All Lean Left\" -- Analyzing the Political Temperaments of Current LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08027",
        "PDF": "https://arxiv.org/pdf/2507.08027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the political temperament of LLMs but does not focus on training data processing or any data engineering operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08143",
      "abstract": "Modern Large Language Models (LLMs) are increasingly trained to support very large context windows. Unfortunately the ability to use long contexts in generation is complicated by the large memory requirement of the KV cache, which scales linearly with the context length. This memory footprint is often the dominant resource bottleneck in real-world deployments, limiting throughput and increasing serving cost. One way to address this is by compressing the KV cache, which can be done either with knowledge of the question being asked (query-aware) or without knowledge of the query (query-agnostic). We present Compactor, a parameter-free, query-agnostic KV compression strategy that uses approximate leverage scores to determine token importance. We show that Compactor can achieve the same performance as competing methods while retaining 1/2 the tokens in both synthetic and real-world context tasks, with minimal computational overhead. We further introduce a procedure for context-calibrated compression, which allows one to infer the maximum compression ratio a given context can support. Using context-calibrated compression, we show that Compactor achieves full KV performance on Longbench while reducing the KV memory burden by 63%, on average. To demonstrate the efficacy and generalizability of our approach, we apply Compactor to 27 synthetic and real-world tasks from RULER and Longbench, with models from both the Qwen 2.5 and Llama 3.1 families.",
      "authors": [
        "Vivek Chari and Benjamin Van Durme"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:03:35+00:00",
          "link": "https://arxiv.org/abs/2507.08143v1",
          "size": "6659kb",
          "version": "v1"
        }
      ],
      "title": "Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08143",
        "HTML": "https://arxiv.org/html/2507.08143v1",
        "PDF": "https://arxiv.org/pdf/2507.08143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a technique for KV cache compression, which indirectly affects the efficiency of data use in LLM deployment but does not directly process LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.04774",
      "abstract": "On Efficient and Scalable Computation of the Nonparametric Maximum Likelihood Estimator in Mixture ModelsTwin support vector machine (TSVM) is an emerging machine learning model with versatile applicability in classification and regression endeavors. Nevertheless, TSVM confronts noteworthy challenges: $(i)$ the imperative demand for matrix inversions presents formidable obstacles to its efficiency and applicability on large-scale datasets; $(ii)$ the omission of the structural risk minimization (SRM) principle in its primal formulation heightens the vulnerability to overfitting risks; and $(iii)$ the TSVM exhibits a high susceptibility to noise and outliers, and also demonstrates instability when subjected to resampling. In view of the aforementioned challenges, we propose the granular ball twin support vector machine (GBTSVM). GBTSVM takes granular balls, rather than individual data points, as inputs to construct a classifier. These granular balls, characterized by their coarser granularity, exhibit robustness to resampling and reduced susceptibility to the impact of noise and outliers. We further propose a novel large-scale granular ball twin support vector machine (LS-GBTSVM). LS-GBTSVM's optimization formulation ensures two critical facets: $(i)$ it eliminates the need for matrix inversions, streamlining the LS-GBTSVM's computational efficiency, and $(ii)$ it incorporates the SRM principle through the incorporation of regularization terms, effectively addressing the issue of overfitting. The proposed LS-GBTSVM exemplifies efficiency, scalability for large datasets, and robustness against noise and outliers. We conduct a comprehensive evaluation of the GBTSVM and LS-GBTSVM models on benchmark datasets from UCI, KEEL, and NDC datasets. Our experimental findings and statistical analyses affirm the superior generalization prowess of the proposed GBTSVM and LS-GBTSVM models.",
      "authors": [
        "A. Quadir",
        "M. Sajid",
        "M. Tanveer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T06:20:36+00:00",
          "link": "https://arxiv.org/abs/2410.04774v1",
          "size": "3448kb",
          "version": "v1"
        },
        {
          "date": "2025-04-18T11:11:23+00:00",
          "link": "https://arxiv.org/abs/2410.04774v2",
          "size": "5521kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T03:41:08+00:00",
          "link": "https://arxiv.org/abs/2410.04774v3",
          "size": "3243kb",
          "version": "v3"
        }
      ],
      "title": "Granular Ball Twin Support Vector Machine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04774",
        "PDF": "https://arxiv.org/pdf/2410.04774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new support vector machine method, focusing on efficient computation and robustness, not on LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/mtanveer1/GBTSVM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.09918",
      "abstract": "In cognition theory, human thinking is governed by two systems: the fast and intuitive System 1 and the slower but more deliberative System 2. Analogously, Large Language Models (LLMs) can operate in two reasoning modes: outputting only the solutions (\\emph{fast mode}) or both the reasoning chain and the final solution (\\emph{slow mode}). We present \\dualformer, a single Transformer model that seamlessly integrates both the fast and slow reasoning modes by training on randomized reasoning traces, where different parts of the traces are strategically dropped during training. At inference time, \\dualformer can be easily configured to execute in either fast or slow mode, or automatically decide which mode to engage (\\emph{auto mode}). It outperforms baselines in both performance and computational efficiency across all three modes: (1) in slow mode, \\dualformer achieves $97.6\\%$ optimal rate on unseen $30 \\times 30$ maze tasks, surpassing the \\searchformer baseline ($93.3\\%$) trained on data with complete reasoning traces, with $45.5\\%$ fewer reasoning steps; (2) in fast mode, \\dualformer achieves $80\\%$ optimal rate, significantly outperforming the Solution-Only model trained on solution-only data, which has an optimal rate of only $30\\%$; (3) in auto mode, \\dualformer achieves $96.6\\%$ optimal rate with $59.9\\%$ fewer steps than \\searchformer. Moreover, \\dualformer produces more diverse reasoning traces than \\searchformer{}. For math reasoning problems, our techniques have also achieved improved performance with LLM fine-tuning, demonstrating its generalization beyond task-specific models. We open source our code at https://github.com/facebookresearch/dualformer.",
      "authors": [
        "DiJia Su",
        "Sainbayar Sukhbaatar",
        "Michael Rabbat",
        "Yuandong Tian",
        "Qinqing Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-13T16:53:02+00:00",
          "link": "https://arxiv.org/abs/2410.09918v1",
          "size": "5826kb",
          "version": "v1"
        },
        {
          "date": "2025-04-10T18:46:07+00:00",
          "link": "https://arxiv.org/abs/2410.09918v2",
          "size": "5939kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T03:52:42+00:00",
          "link": "https://arxiv.org/abs/2410.09918v3",
          "size": "6621kb",
          "version": "v3"
        }
      ],
      "title": "Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09918",
        "HTML": "https://arxiv.org/html/2410.09918v3",
        "PDF": "https://arxiv.org/pdf/2410.09918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses randomized reasoning traces that aid in LLM fine-tuning, its primary focus is on reasoning modes and model architecture rather than data processing for LLM training."
      },
      "tasks": [
        "Computational Efficiency",
        "Math"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08061",
      "abstract": "The tools used to engineer something are just as important as the thing that is actually being engineered. In fact, in many cases, the tools can indeed determine what is engineerable. In fusion and fission1 energy engineering, software has become the dominant tool for design. For that reason, in 2024, for the first time ever, we asked 103 computational scientists developing the codes used in fusion and fission energy about the problems they are attempting to solve with their codes, the tools available to them to solve them, and their end to end developer experience with said tools.\n  The results revealed a changing tide in software tools in fusion and fission, with more and more computational scientists preferring modern programming languages, open-source codes, and modular software. These trends represent a peek into what will happen 5 to 10 years in the future of nuclear engineering. Since the majority of our respondents belonged to US national labs and universities, these results hint at the most cutting-edge trends in the industry. The insights included in the State of Computational Science in Fission and Fusion Energy indicate a dramatic shift toward multiphysics codes, a drop-off in the use of FORTRAN in favor of more modern languages like Python and C++, and ever-rising budgets for code development, at times reaching $50M in a single organization.\n  Our survey paints a future of nuclear engineering codes that is modular in nature, small in terms of compute, and increasingly prioritized by organizations. Access to our results in web form are available online.",
      "authors": [
        "Andrea Morales Coto",
        "Aditi Verma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:44:47+00:00",
          "link": "https://arxiv.org/abs/2507.08061v1",
          "size": "2074kb",
          "version": "v1"
        }
      ],
      "title": "The State of Computational Science in Fission and Fusion Energy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08061",
        "PDF": "https://arxiv.org/pdf/2507.08061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses software tools in fusion and fission energy engineering, but does not address any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08375",
      "abstract": "Video restoration and enhancement are critical not only for improving visual quality, but also as essential pre-processing steps to boost the performance of a wide range of downstream computer vision tasks. This survey presents a comprehensive review of video restoration and enhancement techniques with a particular focus on unsupervised approaches. We begin by outlining the most common video degradations and their underlying causes, followed by a review of early conventional and deep learning methods-based, highlighting their strengths and limitations. We then present an in-depth overview of unsupervised methods, categorise by their fundamental approaches, including domain translation, self-supervision signal design and blind spot or noise-based methods. We also provide a categorization of loss functions employed in unsupervised video restoration and enhancement, and discuss the role of paired synthetic datasets in enabling objective evaluation. Finally, we identify key challenges and outline promising directions for future research in this field.",
      "authors": [
        "Alexandra Malyugina",
        "Yini Li",
        "Joanne Lin",
        "Nantheera Anantrasirichai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:44:37+00:00",
          "link": "https://arxiv.org/abs/2507.08375v1",
          "size": "5006kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Methods for Video Quality Improvement: A Survey of Restoration and Enhancement Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08375",
        "HTML": "https://arxiv.org/html/2507.08375v1",
        "PDF": "https://arxiv.org/pdf/2507.08375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys methods for video quality improvement, specifically restoration and enhancement techniques, which do not directly pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.10242",
      "abstract": "The paper introduces a Signed Generalized Random Dot Product Graph (SGRDPG) model, which is a variant of the Generalized Random Dot Product Graph (GRDPG), where, in addition, edges can be positive or negative. The setting is extended to a multiplex version, where all layers have the same collection of nodes and follow the SGRDPG. The only common feature of the layers of the network is that they can be partitioned into groups with common subspace structures, while otherwise matrices of connection probabilities can be all different. The setting above is extremely flexible and includes a variety of existing multiplex network models, including GRDPG, as its particular cases.\n  By employing novel methodologies, our paper ensures strongly consistent clustering of layers and highly accurate subspace estimation, which are significant improvements over the results of Pensky and Wang (2024). All algorithms and theoretical results in the paper remain true for both signed and binary networks. In addition, the paper shows that keeping signs of the edges in the process of network construction leads to a better precision of estimation and clustering and, hence, is beneficial for tackling real world problems such as, for example, analysis of brain networks.",
      "authors": [
        "Marianna Pensky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-14T19:37:30+00:00",
          "link": "https://arxiv.org/abs/2402.10242v1",
          "size": "219kb",
          "version": "v1"
        },
        {
          "date": "2024-03-15T15:22:50+00:00",
          "link": "https://arxiv.org/abs/2402.10242v2",
          "size": "221kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T22:44:42+00:00",
          "link": "https://arxiv.org/abs/2402.10242v3",
          "size": "1067kb",
          "version": "v3"
        }
      ],
      "title": "Signed Diverse Multiplex Networks: Clustering and Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.10242",
        "HTML": "https://arxiv.org/html/2402.10242v3",
        "PDF": "https://arxiv.org/pdf/2402.10242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for signed multiplex networks and clustering, focusing on network inference rather than LLM training data processing."
      },
      "tasks": [
        "Clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.02624",
      "abstract": "Probabilistic graphs are an abstraction that allow us to study randomized propagation in graphs. In a probabilistic graph, each edge is \"active\" with a certain probability, independent of the other edges. For two vertices $u,v$, a classic quantity of interest, that we refer to as the proximity $\\mathcal{P}_{G}(u, v)$, is the probability that there exists a path between $u$ and $v$ all of whose edges are active. For a given subset of vertices $V_s$, the reach of $V_s$ is defined as the minimum over pairs $u \\in V_s$ and $v \\in V$ of the proximity $\\mathcal{P}_{G}(u,v)$. This quantity has been studied in the context of multicast in unreliable communication networks and in social network analysis.\n  We study the problem of improving the reach in a probabilistic graph via edge augmentation. Formally, given a budget $k$ of edge additions and a set of source vertices $V_s$, the goal of Reach Improvement is to maximize the reach of $V_s$ by adding at most $k$ new edges to the graph. The problem was introduced in earlier empirical work in the algorithmic fairness community. We provide the first approximation guarantees and hardness results for Reach Improvement.\n  We prove that the existence of a good augmentation implies a cluster structure for the graph. We use this structural result to analyze a novel algorithm that outputs a $k$-edge augmentation with an objective value that is poly($\\beta^*$), where $\\beta^*$ is the objective value for the optimal augmentation. We also give an algorithm that adds $O(k \\log n)$ edges and yields a multiplicative approximation to $\\beta^*$. Our arguments rely on new probabilistic tools for analyzing proximity, inspired by techniques in percolation theory; these tools may be of broader interest. Finally, we show that significantly better approximations are unlikely, under known hardness assumptions related to gap variants of the classic Set Cover problem.",
      "authors": [
        "Aditya Bhaskara",
        "Alex Crane",
        "Shweta Jain",
        "Md Mumtahin Habib Ullah Mazumder",
        "Blair D. Sullivan",
        "and Prasanth Yalamanchili"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-02T19:28:31+00:00",
          "link": "https://arxiv.org/abs/2407.02624v1",
          "size": "147kb",
          "version": "v1"
        },
        {
          "date": "2024-09-27T21:30:26+00:00",
          "link": "https://arxiv.org/abs/2407.02624v2",
          "size": "155kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T23:43:29+00:00",
          "link": "https://arxiv.org/abs/2407.02624v3",
          "size": "177kb",
          "version": "v3"
        }
      ],
      "title": "Optimizing Probabilistic Propagation in Graphs by Adding Edges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02624",
        "HTML": "https://arxiv.org/html/2407.02624v3",
        "PDF": "https://arxiv.org/pdf/2407.02624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing probabilistic graphs via edge augmentation and does not discuss LLM training data processing or any data engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.00901",
      "abstract": "Remote sensing spatiotemporal fusion (STF) addresses the fundamental trade-off between temporal and spatial resolution by combining high temporal-low spatial and high spatial-low temporal imagery. This paper presents the first comprehensive survey of deep learning advances in remote sensing STF over the past decade. We establish a systematic taxonomy of deep learning architectures including Convolutional Neural Networks (CNNs), Transformers, Generative Adversarial Networks (GANs), diffusion models, and sequence models, revealing significant growth in deep learning adoption for STF tasks. Our analysis reveals that CNN-based methods dominate spatial feature extraction, while Transformer architectures show superior performance in capturing long-range temporal dependencies. GAN and diffusion models demonstrate exceptional capability in detail reconstruction, substantially outperforming traditional methods in structural similarity and spectral fidelity. Through comprehensive experiments on seven benchmark datasets comparing ten representative methods, we validate these findings and quantify the performance trade-offs between different approaches. We identify five critical challenges: time-space conflicts, limited generalization across datasets, computational efficiency for large-scale processing, multi-source heterogeneous fusion, and insufficient benchmark diversity. The survey highlights promising opportunities in foundation models, hybrid architectures, and self-supervised learning approaches that could address current limitations and enable multimodal applications. The specific models, datasets, and other information mentioned in this article have been collected in: https://github.com/yc-cui/Deep-Learning-Spatiotemporal-Fusion-Survey.",
      "authors": [
        "Enzhe Sun and Yongchuan Cui and Peng Liu and Jining Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T15:30:48+00:00",
          "link": "https://arxiv.org/abs/2504.00901v1",
          "size": "18497kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:18:07+00:00",
          "link": "https://arxiv.org/abs/2504.00901v2",
          "size": "27293kb",
          "version": "v2"
        }
      ],
      "title": "A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00901",
        "PDF": "https://arxiv.org/pdf/2504.00901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys deep learning architectures for remote sensing spatiotemporal fusion, focusing on model taxonomy and challenges; it does not discuss LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/yc-cui/deep-learning-spatiotemporal-fusion-survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08653",
      "abstract": "In Wireless Networked Control Systems (WNCSs), control and communication systems must be co-designed due to their strong interdependence. This paper presents a novel optimization theory-based safe deep reinforcement learning (DRL) framework for ultra-reliable WNCSs, ensuring constraint satisfaction while optimizing performance, for the first time in the literature. The approach minimizes power consumption under key constraints, including Peak Age of Information (PAoI) violation probability, transmit power, and schedulability in the finite blocklength regime. PAoI violation probability is uniquely derived by combining stochastic maximum allowable transfer interval (MATI) and maximum allowable packet delay (MAD) constraints in a multi-sensor network. The framework consists of two stages: optimization theory and safe DRL. The first stage derives optimality conditions to establish mathematical relationships among variables, simplifying and decomposing the problem. The second stage employs a safe DRL model where a teacher-student framework guides the DRL agent (student). The control mechanism (teacher) evaluates compliance with system constraints and suggests the nearest feasible action when needed. Extensive simulations show that the proposed framework outperforms rule-based and other optimization theory based DRL benchmarks, achieving faster convergence, higher rewards, and greater stability.",
      "authors": [
        "Berire Gunes Reyhan and Sinem Coleri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:57:37+00:00",
          "link": "https://arxiv.org/abs/2507.08653v1",
          "size": "4124kb",
          "version": "v1"
        }
      ],
      "title": "Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08653",
        "HTML": "https://arxiv.org/html/2507.08653v1",
        "PDF": "https://arxiv.org/pdf/2507.08653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on safe deep reinforcement learning for resource allocation in Wireless Networked Control Systems and does not discuss any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.05520",
      "abstract": "With the development of blockchain technology, smart contracts have become an important component of blockchain applications. Despite their crucial role, the development of smart contracts may introduce vulnerabilities and potentially lead to severe consequences, such as financial losses. Meanwhile, large language models, represented by ChatGPT, have gained great attentions, showcasing great capabilities in code analysis tasks. In this paper, we presented an empirical study to investigate the performance of ChatGPT in identifying smart contract vulnerabilities. Initially, we evaluated ChatGPT's effectiveness using a publicly available smart contract dataset. Our findings discover that while ChatGPT achieves a high recall rate, its precision in pinpointing smart contract vulnerabilities is limited. Furthermore, ChatGPT's performance varies when detecting different vulnerability types. We delved into the root causes for the false positives generated by ChatGPT, and categorized them into four groups. Second, by comparing ChatGPT with other state-of-the-art smart contract vulnerability detection tools, we found that ChatGPT's F-score is lower than others for 3 out of the 7 vulnerabilities. In the case of the remaining 4 vulnerabilities, ChatGPT exhibits a slight advantage over these tools. Finally, we analyzed the limitation of ChatGPT in smart contract vulnerability detection, revealing that the robustness of ChatGPT in this field needs to be improved from two aspects: its uncertainty in answering questions; and the limited length of the detected code. In general, our research provides insights into the strengths and weaknesses of employing large language models, specifically ChatGPT, for the detection of smart contract vulnerabilities.",
      "authors": [
        "Chong Chen",
        "Jianzhong Su",
        "Jiachi Chen",
        "Yanlin Wang",
        "Tingting Bi",
        "Jianxing Yu",
        "Yanli Wang",
        "Xingwei Lin",
        "Ting Chen",
        "Zibin Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-11T15:02:44+00:00",
          "link": "https://arxiv.org/abs/2309.05520v1",
          "size": "451kb",
          "version": "v1"
        },
        {
          "date": "2023-09-12T10:04:09+00:00",
          "link": "https://arxiv.org/abs/2309.05520v2",
          "size": "452kb",
          "version": "v2"
        },
        {
          "date": "2023-09-14T08:42:45+00:00",
          "link": "https://arxiv.org/abs/2309.05520v3",
          "size": "451kb",
          "version": "v3"
        },
        {
          "date": "2024-08-21T07:40:16+00:00",
          "link": "https://arxiv.org/abs/2309.05520v4",
          "size": "592kb",
          "version": "v4"
        }
      ],
      "title": "When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are We?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.05520",
        "HTML": "https://arxiv.org/html/2309.05520",
        "PDF": "https://arxiv.org/pdf/2309.05520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates ChatGPT's performance in detecting smart contract vulnerabilities, and does not address LLM training data processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Artificial Intelligence (cs.AI)",
    "Machine Learning (cs.LG)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Computers and Society (cs.CY)",
    "Multimedia (cs.MM)",
    "Machine Learning (stat.ML)",
    "Computation and Language (cs.CL)",
    "Robotics (cs.RO)",
    "Social and Information Networks (cs.SI)",
    "Human-Computer Interaction (cs.HC)",
    "Statistics Theory (stat.TH)",
    "Cryptography and Security (cs.CR)",
    "Computational Complexity (cs.CC)",
    "Probability (math.PR)",
    "Statistics Theory (math.ST)",
    "Data Structures and Algorithms (cs.DS)",
    "Quantum Physics (quant-ph)",
    "Econometrics (econ.EM)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Information Theory (math.IT)",
    "Information Theory (cs.IT)",
    "Networking and Internet Architecture (cs.NI)",
    "Emerging Technologies (cs.ET)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Numerical Analysis (math.NA)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Systems and Control (eess.SY)",
    "Systems and Control (cs.SY)",
    "Computer Science and Game Theory (cs.GT)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Neurons and Cognition (q-bio.NC)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Quantitative Methods (q-bio.QM)",
    "Discrete Mathematics (cs.DM)",
    "Combinatorics (math.CO)",
    "Mathematical Software (cs.MS)",
    "Number Theory (math.NT)",
    "Software Engineering (cs.SE)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Programming Languages (cs.PL)",
    "Mathematical Physics (math.MP)",
    "Chaotic Dynamics (nlin.CD)",
    "Mathematical Physics (math-ph)",
    "Sound (cs.SD)",
    "Audio and Speech Processing (eess.AS)",
    "Image and Video Processing (eess.IV)",
    "Hardware Architecture (cs.AR)",
    "Optimization and Control (math.OC)",
    "Biomolecules (q-bio.BM)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computational Geometry (cs.CG)",
    "Statistical Finance (q-fin.ST)",
    "Computational Finance (q-fin.CP)",
    "Graphics (cs.GR)",
    "General Economics (econ.GN)",
    "Economics (q-fin.EC)",
    "Information Retrieval (cs.IR)",
    "Chemical Physics (physics.chem-ph)",
    "Databases (cs.DB)",
    "Category Theory (math.CT)",
    "Symplectic Geometry (math.SG)",
    "Differential Geometry (math.DG)",
    "Dynamical Systems (math.DS)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Risk Management (q-fin.RM)",
    "Theoretical Economics (econ.TH)",
    "Medical Physics (physics.med-ph)",
    "Methodology (stat.ME)",
    "Applications (stat.AP)",
    "Other Statistics (stat.OT)",
    "Physics and Society (physics.soc-ph)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Optics (physics.optics)",
    "Genomics (q-bio.GN)",
    "Computation (stat.CO)",
    "Soft Condensed Matter (cond-mat.soft)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "High Energy Physics - Experiment (hep-ex)",
    "Classical Physics (physics.class-ph)",
    "Signal Processing (eess.SP)",
    "Physics Education (physics.ed-ph)",
    "Performance (cs.PF)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Applied Physics (physics.app-ph)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Algebraic Geometry (math.AG)",
    "Symbolic Computation (cs.SC)",
    "Rings and Algebras (math.RA)",
    "Digital Libraries (cs.DL)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to LLM performance. You are a computer science expert specializing in data engineering for large language model (LLM) training data. Your task is to analyze a set of arXiv papers and identify those that focus on processing LLM training data.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it makes a technical contribution to **LLM training data processing**. In particular, focus on papers that involve **training-data processing** , including but not limited to:\n\n1. **Data processing during pretraining or fine-tuning**\n   * Preparation of data for LLM pretraining, instruction tuning, supervised fine-tuning (SFT), alignment tuning, etc.\n2. **training-data processing**\n   * Common data engineering operations, including data collection, data generation, data deduplication, data filtering, etc.\n   * Any methods or techniques that significantly improve data quality.\n   * Creation of a new dataset **with clear, detailed data processing steps.**\n\n**Note:** Ignore papers that merely use existing training datasets for downstream tasks (e.g., QA, reasoning), propose new model architectures, or conduct evaluation benchmarks\u2014unless they also **substantively modify or process the training data itself**.\n\n---\n\n### **Relevance Level Classification**\n\n* **`core`**: The paper\u2019s primary contribution lies in processing or creating LLM training data, or in constructing a higher-quality dataset from existing data\u2014e.g., dataset creation, data generation or synthesis, pipeline design, filtering methods, or other data\u2011engineering operations that improve data quality.\n* **`partial`**: The paper briefly mentions training data or standard preprocessing (e.g., using a standard dataset or tokenization, it focuses on model architecture, tasks, evaluation, prompting methods) but does **not** focus primarily on data processing.\n* **`irrelevant`**: The paper does **not** discuss any aspect of LLM training data collection, processing, or engineering.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper ID>\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing the key part of the abstract or methodology that justifies your classification\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "partial": 102,
    "irrelevant": 519,
    "core": 39
  },
  "arxiv_update_date": "2025-07-14",
  "updated_at": "2025-07-14 10:01:09"
}