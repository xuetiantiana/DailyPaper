{
  "data": [
    {
      "id": "2507.16818",
      "abstract": "The quality of a transtibial prosthetic socket depends on the prosthetist's skills and expertise, as the fitting is performed manually. This study investigates multiple artificial intelligence (AI) approaches to help standardize transtibial prosthetic socket design. Data from 118 patients were collected by prosthetists working in the Dutch healthcare system. This data consists of a three-dimensional (3D) scan of the residual limb and a corresponding 3D model of the prosthetist-designed socket. Multiple data pre-processing steps are performed for alignment, standardization and optionally compression using Morphable Models and Principal Component Analysis. Afterward, three different algorithms - a 3D neural network, Feedforward neural network, and random forest - are developed to either predict 1) the final socket shape or 2) the adaptations performed by a prosthetist to predict the socket shape based on the 3D scan of the residual limb. Each algorithm's performance was evaluated by comparing the prosthetist-designed socket with the AI-generated socket, using two metrics in combination with the error location. First, we measure the surface-to-surface distance to assess the overall surface error between the AI-generated socket and the prosthetist-designed socket. Second, distance maps between the AI-generated and prosthetist sockets are utilized to analyze the error's location. For all algorithms, estimating the required adaptations outperformed direct prediction of the final socket shape. The random forest model applied to adaptation prediction yields the lowest error with a median surface-to-surface distance of 1.24 millimeters, a first quartile of 1.03 millimeters, and a third quartile of 1.54 millimeters.",
      "authors": [
        "C.H.E. Jordaan",
        "M. van der Stelt",
        "T.J.J. Maal",
        "V.M.A. Stirler",
        "R. Leijendekkers",
        "T. Kachman",
        "G.A. de Jong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T09:57:58+00:00",
          "link": "https://arxiv.org/abs/2507.16818v1",
          "size": "5484kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Artificial Intelligence Algorithms for the Standardization of Transtibial Prosthetic Socket Shape Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16818",
        "HTML": "https://arxiv.org/html/2507.16818v1",
        "PDF": "https://arxiv.org/pdf/2507.16818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates AI algorithms for designing prosthetic sockets, focusing solely on medical application scenarios rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16819",
      "abstract": "We examined eye and head movements to gain insights into skill development in clinical settings. A total of 24 practitioners participated in simulated baby delivery training sessions. We calculated key metrics, including pupillary response rate, fixation duration, or angular velocity. Our findings indicate that eye and head tracking can effectively differentiate between trained and untrained practitioners, particularly during labor tasks. For example, head-related features achieved an F1 score of 0.85 and AUC of 0.86, whereas pupil-related features achieved F1 score of 0.77 and AUC of 0.85. The results lay the groundwork for computational models that support implicit skill assessment and training in clinical settings by using commodity eye-tracking glasses as a complementary device to more traditional evaluation methods such as subjective scores.",
      "authors": [
        "Kayhan Latifzadeh",
        "Luis A. Leiva",
        "Klen \\v{C}opi\\v{c} Pucihar",
        "Matja\\v{z} Kljun",
        "Iztok Devetak",
        "Lili Steblovnik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T08:27:05+00:00",
          "link": "https://arxiv.org/abs/2507.16819v1",
          "size": "8780kb",
          "version": "v1"
        }
      ],
      "title": "Assessing Medical Training Skills via Eye and Head Movements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16819",
        "HTML": "https://arxiv.org/html/2507.16819v1",
        "PDF": "https://arxiv.org/pdf/2507.16819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research assesses medical training skills using eye and head movements, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16820",
      "abstract": "This study presents a comprehensive bibliometric and topic analysis of the disaster informatics literature published between January 2020 to September 2022. Leveraging a large-scale corpus and advanced techniques such as pre-trained language models and generative AI, we identify the most active countries, institutions, authors, collaboration networks, emergent topics, patterns among the most significant topics, and shifts in research priorities spurred by the COVID-19 pandemic. Our findings highlight (1) countries that were most impacted by the COVID-19 pandemic were also among the most active, with each country having specific research interests, (2) countries and institutions within the same region or share a common language tend to collaborate, (3) top active authors tend to form close partnerships with one or two key partners, (4) authors typically specialized in one or two specific topics, while institutions had more diverse interests across several topics, and (5) the COVID-19 pandemic has influenced research priorities in disaster informatics, placing greater emphasis on public health. We further demonstrate that the field is converging on multidimensional resilience strategies and cross-sectoral data-sharing collaborations or projects, reflecting a heightened awareness of global vulnerability and interdependency. Collecting and quality assurance strategies, data analytic practices, LLM-based topic extraction and summarization approaches, and result visualization tools can be applied to comparable datasets or solve similar analytic problems. By mapping out the trends in disaster informatics, our analysis offers strategic insights for policymakers, practitioners, and scholars aiming to enhance disaster informatics capacities in an increasingly uncertain and complex risk landscape.",
      "authors": [
        "Ngan Tran",
        "Haihua Chen",
        "Ana Cleveland",
        "and Yuhan Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:30:36+00:00",
          "link": "https://arxiv.org/abs/2507.16820v1",
          "size": "4950kb",
          "version": "v1"
        }
      ],
      "title": "Disaster Informatics after the COVID-19 Pandemic: Bibliometric and Topic Analysis based on Large-scale Academic Literature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16820",
        "HTML": "https://arxiv.org/html/2507.16820v1",
        "PDF": "https://arxiv.org/pdf/2507.16820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on bibliometric and topic analysis of disaster informatics and does not discuss any aspect of LLM training data processing, such as data collection, filtering, or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16826",
      "abstract": "Retrieval Augmented Generation (RAG) has gradually emerged as a promising paradigm for enhancing the accuracy and factual consistency of content generated by large language models (LLMs). However, existing RAG studies primarily focus on retrieving isolated segments using similarity-based matching methods, while overlooking the intrinsic connections between them. This limitation hampers performance in RAG tasks. To address this, we propose QMKGF, a Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval Augmented Generation. First, we design prompt templates and employ general-purpose LLMs to extract entities and relations, thereby generating a knowledge graph (KG) efficiently. Based on the constructed KG, we introduce a multi-path subgraph construction strategy that incorporates one-hop relations, multi-hop relations, and importance-based relations, aiming to improve the semantic relevance between the retrieved documents and the user query. Subsequently, we designed a query-aware attention reward model that scores subgraph triples based on their semantic relevance to the query. Then, we select the highest score subgraph and enrich subgraph with additional triples from other subgraphs that are highly semantically relevant to the query. Finally, the entities, relations, and triples within the updated subgraph are utilised to expand the original query, thereby enhancing its semantic representation and improving the quality of LLMs' generation. We evaluate QMKGF on the SQuAD, IIRC, Culture, HotpotQA, and MuSiQue datasets. On the HotpotQA dataset, our method achieves a ROUGE-1 score of 64.98\\%, surpassing the BGE-Rerank approach by 9.72 percentage points (from 55.26\\% to 64.98\\%). Experimental results demonstrate the effectiveness and superiority of the QMKGF approach.",
      "authors": [
        "Qikai Wei and Huansheng Ning and Chunlong Han and Jianguo Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T02:22:54+00:00",
          "link": "https://arxiv.org/abs/2507.16826v1",
          "size": "636kb",
          "version": "v1"
        }
      ],
      "title": "A Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval-Augmented Generation in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16826",
        "HTML": "https://arxiv.org/html/2507.16826v1",
        "PDF": "https://arxiv.org/pdf/2507.16826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper details a method for enhancing Retrieval Augmented Generation using knowledge graphs, which may involve some data processing in terms of extracting entities and relations. However, the primary focus is on improving RAG rather than core LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16829",
      "abstract": "Recommenders are significantly shaping online information consumption. While effective at personalizing content, these systems increasingly face criticism for propagating irrelevant, unwanted, and even harmful recommendations. Such content degrades user satisfaction and contributes to significant societal issues, including misinformation, radicalization, and erosion of user trust. Although platforms offer mechanisms to mitigate exposure to undesired content, these mechanisms are often insufficiently effective and slow to adapt to users' feedback. This paper introduces an intuitive, model-agnostic, and distribution-free method that uses conformal risk control to provably bound unwanted content in personalized recommendations by leveraging simple binary feedback on items. We also address a limitation of traditional conformal risk control approaches, i.e., the fact that the recommender can provide a smaller set of recommended items, by leveraging implicit feedback on consumed items to expand the recommendation set while ensuring robust risk mitigation. Our experimental evaluation on data coming from a popular online video-sharing platform demonstrates that our approach ensures an effective and controllable reduction of unwanted recommendations with minimal effort. The source code is available here: https://github.com/geektoni/mitigating-harm-recsys.",
      "authors": [
        "Giovanni De Toni",
        "Erasmo Purificato",
        "Emilia G\\'omez",
        "Bruno Lepri",
        "Andrea Passerini",
        "and Cristian Consonni"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:27:35+00:00",
          "link": "https://arxiv.org/abs/2507.16829v1",
          "size": "2162kb",
          "version": "v1"
        }
      ],
      "title": "You Don't Bring Me Flowers: Mitigating Unwanted Recommendations Through Conformal Risk Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16829",
        "HTML": "https://arxiv.org/html/2507.16829v1",
        "PDF": "https://arxiv.org/pdf/2507.16829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a method for controlling unwanted recommendations in recommender systems, which does not pertain to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16833",
      "abstract": "Self-driving laboratories (SDLs) have shown promise to accelerate materials discovery by integrating machine learning with automated experimental platforms. However, errors in the capture of input parameters may corrupt the features used to model system performance, compromising current and future campaigns. This study develops an automated workflow to systematically detect noisy features, determine sample-feature pairings that can be corrected, and finally recover the correct feature values. A systematic study is then performed to examine how dataset size, noise intensity, and feature value distribution affect both the detectability and recoverability of noisy features. In general, high-intensity noise and large training datasets are conducive to the detection and correction of noisy features. Low-intensity noise reduces detection and recovery but can be compensated for by larger clean training data sets. Detection and correction results vary between features with continuous and dispersed feature distributions showing greater recoverability compared to features with discrete or narrow distributions. This systematic study not only demonstrates a model agnostic framework for rational data recovery in the presence of noise, limited data, and differing feature distributions but also provides a tangible benchmark of kNN imputation in materials data sets. Ultimately, it aims to enhance data quality and experimental precision in automated materials discovery.",
      "authors": [
        "Qiuyu Shi",
        "Kangming Li",
        "Yao Fehlis",
        "Daniel Persaud",
        "Robert Black",
        "Jason Hattrick-Simpers"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:35:56+00:00",
          "link": "https://arxiv.org/abs/2507.16833v1",
          "size": "747kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Frontiers of kNN Noisy Feature Detection and Recovery for Self-Driving Labs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16833",
        "PDF": "https://arxiv.org/pdf/2507.16833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores noisy feature detection and recovery in self-driving laboratories for materials discovery, without connection to LLM training data processing or dataset creation/engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16839",
      "abstract": "This paper presents a methodology to process large-scale naturalistic driving studies (NDS) to describe the driving behavior for five vehicle metrics, including speed, speeding, lane keeping, following distance, and headway, contextualized by roadway characteristics, vehicle classes, and driver demographics. Such descriptions of normative driving behaviors can aid in the development of vehicle safety and intelligent transportation systems. The methodology is demonstrated using data from the Second Strategic Highway Research Program (SHRP 2) NDS, which includes over 34 million miles of driving across more than 3,400 drivers. Summaries of each driving metric were generated using vehicle, GPS, and forward radar data. Additionally, interactive online analytics tools were developed to visualize and compare driving behavior across groups through dynamic data selection and grouping. For example, among drivers on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit by 7.5 to 15 mph slightly more often than their male counterparts, and younger drivers maintained headways under 1.5 seconds more frequently than older drivers. This work supports better vehicle systems and safer infrastructure by quantifying normative driving behaviors and offers a methodology for analyzing NDS datasets for cross group comparisons.",
      "authors": [
        "Gregory Beale and Gibran Ali"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:40:44+00:00",
          "link": "https://arxiv.org/abs/2507.16839v1",
          "size": "353kb",
          "version": "v1"
        }
      ],
      "title": "Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16839",
        "HTML": "https://arxiv.org/html/2507.16839v1",
        "PDF": "https://arxiv.org/pdf/2507.16839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study processes driving behavior data from NDS for vehicle system development, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16840",
      "abstract": "The rapid evolution of digital currency trading, fueled by the integration of blockchain technology, has led to both innovation and the emergence of smart Ponzi schemes. A smart Ponzi scheme is a fraudulent investment operation in smart contract that uses funds from new investors to pay returns to earlier investors. Traditional Ponzi scheme detection methods based on deep learning typically rely on fully supervised models, which require large amounts of labeled data. However, such data is often scarce, hindering effective model training. To address this challenge, we propose a novel contrastive learning framework, CASPER (Contrastive Approach for Smart Ponzi detectER with more negative samples), designed to enhance smart Ponzi scheme detection in blockchain transactions. By leveraging contrastive learning techniques, CASPER can learn more effective representations of smart contract source code using unlabeled datasets, significantly reducing both operational costs and system complexity. We evaluate CASPER on the XBlock dataset, where it outperforms the baseline by 2.3% in F1 score when trained with 100% labeled data. More impressively, with only 25% labeled data, CASPER achieves an F1 score nearly 20% higher than the baseline under identical experimental conditions. These results highlight CASPER's potential for effective and cost-efficient detection of smart Ponzi schemes, paving the way for scalable fraud detection solutions in the future.",
      "authors": [
        "Weijia Yang",
        "Tian Lan",
        "Leyuan Liu",
        "Wei Chen",
        "Tianqing Zhu",
        "Sheng Wen",
        "Xiaosong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T01:26:02+00:00",
          "link": "https://arxiv.org/abs/2507.16840v1",
          "size": "3948kb",
          "version": "v1"
        }
      ],
      "title": "CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16840",
        "HTML": "https://arxiv.org/html/2507.16840v1",
        "PDF": "https://arxiv.org/pdf/2507.16840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a contrastive learning framework (CASPER) for detecting smart Ponzi schemes in blockchain transactions, with no mention of language model pretraining, fine-tuning, or training data processing operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16841",
      "abstract": "Inspection of aquaculture net pens is essential for maintaining the structural integrity, biosecurity, and operational efficiency of fish farming systems. Traditional inspection approaches rely on pre-programmed missions or manual control, offering limited adaptability to dynamic underwater conditions and user-specific demands. In this study, we propose AquaChat, a novel Remotely Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs) for intelligent and adaptive net pen inspection. The system features a multi-layered architecture: (1) a high-level planning layer that interprets natural language user commands using an LLM to generate symbolic task plans; (2) a mid-level task manager that translates plans into ROV control sequences; and (3) a low-level motion control layer that executes navigation and inspection tasks with precision. Real-time feedback and event-triggered replanning enhance robustness in challenging aquaculture environments. The framework is validated through experiments in both simulated and controlled aquatic environments representative of aquaculture net pens. Results demonstrate improved task flexibility, inspection accuracy, and operational efficiency. AquaChat illustrates the potential of integrating language-based AI with marine robotics to enable intelligent, user-interactive inspection systems for sustainable aquaculture operations.",
      "authors": [
        "Waseem Akram",
        "Muhayy Ud Din",
        "Abdelhaleem Saad",
        "Irfan Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:39:12+00:00",
          "link": "https://arxiv.org/abs/2507.16841v1",
          "size": "25587kb",
          "version": "v1"
        }
      ],
      "title": "AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16841",
        "HTML": "https://arxiv.org/html/2507.16841v1",
        "PDF": "https://arxiv.org/pdf/2507.16841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses AquaChat, an ROV framework utilizing LLMs for inspection tasks in aquaculture, focusing on task flexibility and control layers without addressing training data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16842",
      "abstract": "The intrinsic compliance and high degree of freedom (DoF) of redundant soft manipulators facilitate safe interaction and flexible task execution. However, effective kinematic control remains highly challenging, as it must handle deformations caused by unknown external loads and avoid actuator saturation due to improper null-space regulation - particularly in confined environments. In this paper, we propose a Sensor-Space Imitation Learning Kinematic Control (SS-ILKC) framework to enable robust kinematic control under actuator saturation and restrictive environmental constraints. We employ a dual-learning strategy: a multi-goal sensor-space control framework based on reinforcement learning principle is trained in simulation to develop robust control policies for open spaces, while a generative adversarial imitation learning approach enables effective policy learning from sparse expert demonstrations for confined spaces. To enable zero-shot real-world deployment, a pre-processed sim-to-real transfer mechanism is proposed to mitigate the simulation-to-reality gap and accurately characterize actuator saturation limits. Experimental results demonstrate that our method can effectively control a pneumatically actuated soft manipulator, achieving precise path-following and object manipulation in confined environments under unknown loading conditions.",
      "authors": [
        "Yinan Meng",
        "Kun Qian",
        "Jiong Yang",
        "Renbo Su",
        "Zhenhong Li",
        "Charlie C.L. Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:04:12+00:00",
          "link": "https://arxiv.org/abs/2507.16842v1",
          "size": "21631kb",
          "version": "v1"
        }
      ],
      "title": "Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16842",
        "HTML": "https://arxiv.org/html/2507.16842v1",
        "PDF": "https://arxiv.org/pdf/2507.16842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on kinematic control of soft manipulators using a sensor-space learning framework, with no connection to LLM training data or any related data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16843",
      "abstract": "In the design of customer relationship management (CRM) systems, accurately identifying customer types and offering personalized services are key to enhancing customer satisfaction and loyalty. However, this process faces the challenge of discerning customer voices and intentions, and general pre-trained automatic speech recognition (ASR) models make it difficult to effectively address industry-specific speech recognition tasks. To address this issue, we innovatively proposed a solution for fine-tuning industry-specific ASR models, which significantly improved the performance of the fine-tuned ASR models in industry applications. Experimental results show that our method substantially improves the crucial auxiliary role of the ASR model in industry CRM systems, and this approach has also been adopted in actual industrial applications.",
      "authors": [
        "Zhongsheng Wang",
        "Sijie Wang",
        "Jia Wang",
        "Yung-I Liang",
        "Yuxi Zhang",
        "and Jiamou Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:39:09+00:00",
          "link": "https://arxiv.org/abs/2507.16843v1",
          "size": "1837kb",
          "version": "v1"
        }
      ],
      "title": "Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16843",
        "HTML": "https://arxiv.org/html/2507.16843v1",
        "PDF": "https://arxiv.org/pdf/2507.16843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions fine-tuning ASR models for CRM systems, but the focus is on improving speech recognition rather than LLMs, with minimal direct discussion on training data processing techniques relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16844",
      "abstract": "We introduce TD-Interpreter, a specialized ML tool that assists engineers in understanding complex timing diagrams (TDs), originating from a third party, during their design and verification process. TD-Interpreter is a visual question-answer environment which allows engineers to input a set of TDs and ask design and verification queries regarding these TDs. We implemented TD-Interpreter with multimodal learning by fine-tuning LLaVA, a lightweight 7B Multimodal Large Language Model (MLLM). To address limited training data availability, we developed a synthetic data generation workflow that aligns visual information with its textual interpretation. Our experimental evaluation demonstrates the usefulness of TD-Interpreter which outperformed untuned GPT-4o by a large margin on the evaluated benchmarks.",
      "authors": [
        "Jie He",
        "Vincent Theo Willem Kenbeek",
        "Zhantao Yang",
        "Meixun Qu",
        "Ezio Bartocci",
        "Dejan Ni\\v{c}kovi\\'c",
        "and Radu Grosu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:52:29+00:00",
          "link": "https://arxiv.org/abs/2507.16844v1",
          "size": "3363kb",
          "version": "v1"
        }
      ],
      "title": "TD-Interpreter: Enhancing the Understanding of Timing Diagrams with Visual-Language Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16844",
        "HTML": "https://arxiv.org/html/2507.16844v1",
        "PDF": "https://arxiv.org/pdf/2507.16844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents TD-Interpreter, which employs synthetic data generation for fine-tuning a multimodal LLM (LLaVA) to enhance timing diagram understanding. Although it involves dataset-related processing, its primary focus is not on LLM training data processing but visual-language learning applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16846",
      "abstract": "The core of the freeway merging control problem lies in dynamic queue propagation and dissipation linked to merging vehicle behavior. Traditionally, queuing is modeled through demand-supply interactions with time varying demand and fixed capacity. However, field observations show flow rates decrease during congestion at freeway merges due to the impact of intersecting traffic, a factor overlooked in fundamental diagrams. This manuscript introduces an analytical approach to characterize and control the dynamic multi-stage merging of autonomous vehicles, prioritizing traffic efficiency and safety. For the first time, the effective discharge rate at the merging point, reduced by the multi-stage dynamic merging process, is analytically derived using a closed form formulation. Leveraging this expression, performance metrics such as queue length and traffic delay are derived as the first objective. Additionally, a crash risk function is established to quantitatively assess potential collisions during the merging process, serving as the second objective. Finally, the problem is formulated as a dynamic programming model to jointly minimize delay and crash risk, with the merging location and speed as decision variables. Given the terminal state, the ramp vehicle merging task is formulated as a recursive optimization problem, employing backward induction to find the minimum cost solution. Numerical experiments using the NGSIM dataset validate the derived effective discharge rate. The results indicate that the proposed model outperforms two benchmark algorithms, leading to a more efficient and safer merging process.",
      "authors": [
        "Qing Tang and Xianbiao Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:19:38+00:00",
          "link": "https://arxiv.org/abs/2507.16846v1",
          "size": "2391kb",
          "version": "v1"
        }
      ],
      "title": "Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16846",
        "PDF": "https://arxiv.org/pdf/2507.16846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses freeway merging control for autonomous vehicles using state-dependent discharge rates. It does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16847",
      "abstract": "Social media platforms serve as a significant medium for sharing personal emotions, daily activities, and various life events, ensuring individuals stay informed about the latest developments. From the initiation of an account, users progressively expand their circle of friends or followers, engaging actively by posting, commenting, and sharing content. Over time, user behavior on these platforms evolves, influenced by demographic attributes and the networks they form. In this study, we present a novel approach that leverages open-source models Llama-3-Instruct, Mistral-7B-Instruct, Gemma-7B-IT through prompt engineering, combined with GPT-2, BERT, and RoBERTa using a joint embedding technique, to analyze and predict the evolution of user behavior on social media over their lifetime. Our experiments demonstrate the potential of these models to forecast future stages of a user's social evolution, including network changes, future connections, and shifts in user activities. Experimental results highlight the effectiveness of our approach, with GPT-2 achieving the lowest perplexity (8.21) in a Cross-modal configuration, outperforming RoBERTa (9.11) and BERT, and underscoring the importance of leveraging Cross-modal configurations for superior performance. This approach addresses critical challenges in social media, such as friend recommendations and activity predictions, offering insights into the trajectory of user behavior. By anticipating future interactions and activities, this research aims to provide early warnings about potential negative outcomes, enabling users to make informed decisions and mitigate risks in the long term.",
      "authors": [
        "Ismail Hossain",
        "Sai Puppala",
        "Md Jahangir Alam",
        "Sajedul Talukder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:07:07+00:00",
          "link": "https://arxiv.org/abs/2507.16847v1",
          "size": "8681kb",
          "version": "v1"
        }
      ],
      "title": "EVOLVE-X: Embedding Fusion and Language Prompting for User Evolution Forecasting on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16847",
        "HTML": "https://arxiv.org/html/2507.16847v1",
        "PDF": "https://arxiv.org/pdf/2507.16847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for forecasting user evolution on social media using language models but does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16848",
      "abstract": "In the human-bot symbiotic information ecosystem, social bots play key roles in spreading and correcting disinformation. Understanding their influence is essential for risk control and better governance. However, current studies often rely on simplistic user and network modeling, overlook the dynamic behavior of bots, and lack quantitative evaluation of correction strategies. To fill these gaps, we propose MADD, a Multi Agent based framework for Disinformation Dissemination. MADD constructs a more realistic propagation network by integrating the Barabasi Albert Model for scale free topology and the Stochastic Block Model for community structures, while designing node attributes based on real world user data. Furthermore, MADD incorporates both malicious and legitimate bots, with their controlled dynamic participation allows for quantitative analysis of correction strategies. We evaluate MADD using individual and group level metrics. We experimentally verify the real world consistency of MADD user attributes and network structure, and we simulate the dissemination of six disinformation topics, demonstrating the differential effects of fact based and narrative based correction strategies.",
      "authors": [
        "Boyu Qiao",
        "Kun Li",
        "Wei Zhou",
        "Songlin Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:15:17+00:00",
          "link": "https://arxiv.org/abs/2507.16848v1",
          "size": "12461kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Simulation Framework for Disinformation Dissemination and Correction With Social Bots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16848",
        "PDF": "https://arxiv.org/pdf/2507.16848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework to understand disinformation dissemination with social bots and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16849",
      "abstract": "We propose a vision transformer (ViT)-based deep learning framework to refine disaster-affected area segmentation from remote sensing imagery, aiming to support and enhance the Emergent Value Added Product (EVAP) developed by the Taiwan Space Agency (TASA). The process starts with a small set of manually annotated regions. We then apply principal component analysis (PCA)-based feature space analysis and construct a confidence index (CI) to expand these labels, producing a weakly supervised training set. These expanded labels are then used to train ViT-based encoder-decoder models with multi-band inputs from Sentinel-2 and Formosat-5 imagery. Our architecture supports multiple decoder variants and multi-stage loss strategies to improve performance under limited supervision. During the evaluation, model predictions are compared with higher-resolution EVAP output to assess spatial coherence and segmentation consistency. Case studies on the 2022 Poyang Lake drought and the 2023 Rhodes wildfire demonstrate that our framework improves the smoothness and reliability of segmentation results, offering a scalable approach for disaster mapping when accurate ground truth is unavailable.",
      "authors": [
        "Yi-Shan Chu",
        "Hsuan-Cheng Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:48:07+00:00",
          "link": "https://arxiv.org/abs/2507.16849v1",
          "size": "9413kb",
          "version": "v1"
        }
      ],
      "title": "Post-Disaster Affected Area Segmentation with a Vision Transformer (ViT)-based EVAP Model using Sentinel-2 and Formosat-5 Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16849",
        "HTML": "https://arxiv.org/html/2507.16849v1",
        "PDF": "https://arxiv.org/pdf/2507.16849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses post-disaster area segmentation using remote sensing imagery with a Vision Transformer-based model. It does not mention any process related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16850",
      "abstract": "Monocular 3D human pose estimation remains a challenging and ill-posed problem, particularly in real-time settings and unconstrained environments. While direct imageto-3D approaches require large annotated datasets and heavy models, 2D-to-3D lifting offers a more lightweight and flexible alternative-especially when enhanced with prior knowledge. In this work, we propose a framework that combines real-time 2D keypoint detection with geometry-aware 2D-to-3D lifting, explicitly leveraging known camera intrinsics and subject-specific anatomical priors. Our approach builds on recent advances in self-calibration and biomechanically-constrained inverse kinematics to generate large-scale, plausible 2D-3D training pairs from MoCap and synthetic datasets. We discuss how these ingredients can enable fast, personalized, and accurate 3D pose estimation from monocular images without requiring specialized hardware. This proposal aims to foster discussion on bridging data-driven learning and model-based priors to improve accuracy, interpretability, and deployability of 3D human motion capture on edge devices in the wild.",
      "authors": [
        "Mohamed Adjel (LAAS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:18:23+00:00",
          "link": "https://arxiv.org/abs/2507.16850v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Toward a Real-Time Framework for Accurate Monocular 3D Human Pose Estimation with Geometric Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16850",
        "PDF": "https://arxiv.org/pdf/2507.16850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on monocular 3D human pose estimation and does not address any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16851",
      "abstract": "Crack detection is an important task in computer vision. Despite impressive in-dataset performance, deep learning-based methods still struggle in generalizing to unseen domains. The thin structure property of cracks is usually overlooked by previous methods. In this work, we introduce CrackCue, a novel method for robust crack detection based on coarse-to-fine crack cue generation. The core concept lies on leveraging the thin structure property to generate a robust crack cue, guiding the crack detection. Specifically, we first employ a simple max-pooling and upsampling operation on the crack image. This results in a coarse crack-free background, based on which a fine crack-free background can be obtained via a reconstruction network. The difference between the original image and fine crack-free background provides a fine crack cue. This fine cue embeds robust crack prior information which is unaffected by complex backgrounds, shadow, and varied lighting. As a plug-and-play method, we incorporate the proposed CrackCue into three advanced crack detection networks. Extensive experimental results demonstrate that the proposed CrackCue significantly improves the generalization ability and robustness of the baseline methods. The source code will be publicly available.",
      "authors": [
        "Zelong Liu",
        "Yuliang Gu",
        "Zhichao Sun",
        "Huachao Zhu",
        "Xin Xiao",
        "Bo Du",
        "Laurent Najman (LIGM)",
        "Yongchao Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:36:05+00:00",
          "link": "https://arxiv.org/abs/2507.16851v1",
          "size": "2751kb",
          "version": "v1"
        }
      ],
      "title": "Coarse-to-fine crack cue for robust crack detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16851",
        "PDF": "https://arxiv.org/pdf/2507.16851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on crack detection in computer vision and does not discuss topics related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16852",
      "abstract": "Cyber Threat Intelligence (CTI) mining involves extracting structured insights from unstructured threat data, enabling organizations to understand and respond to evolving adversarial behavior. A key task in CTI mining is mapping threat descriptions to MITRE ATT\\&CK techniques. However, this process is often performed manually, requiring expert knowledge and substantial effort. Automated approaches face two major challenges: the scarcity of high-quality labeled CTI data and class imbalance, where many techniques have very few examples. While domain-specific Large Language Models (LLMs) such as SecureBERT have shown improved performance, most recent work focuses on model architecture rather than addressing the data limitations. In this work, we present SynthCTI, a data augmentation framework designed to generate high-quality synthetic CTI sentences for underrepresented MITRE ATT\\&CK techniques. Our method uses a clustering-based strategy to extract semantic context from training data and guide an LLM in producing synthetic CTI sentences that are lexically diverse and semantically faithful. We evaluate SynthCTI on two publicly available CTI datasets, CTI-to-MITRE and TRAM, using LLMs with different capacity. Incorporating synthetic data leads to consistent macro-F1 improvements: for example, ALBERT improves from 0.35 to 0.52 (a relative gain of 48.6\\%), and SecureBERT reaches 0.6558 (up from 0.4412). Notably, smaller models augmented with SynthCTI outperform larger models trained without augmentation, demonstrating the value of data generation methods for building efficient and effective CTI classification systems.",
      "authors": [
        "\\'Alvaro Ruiz-R\\'odenas",
        "Jaime Pujante S\\'aez",
        "Daniel Garc\\'ia-Algora",
        "Mario Rodr\\'iguez B\\'ejar",
        "Jorge Blasco and Jos\\'e Luis Hern\\'andez-Ramos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:22:39+00:00",
          "link": "https://arxiv.org/abs/2507.16852v1",
          "size": "1974kb",
          "version": "v1"
        }
      ],
      "title": "SynthCTI: LLM-Driven Synthetic CTI Generation to enhance MITRE Technique Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16852",
        "HTML": "https://arxiv.org/html/2507.16852v1",
        "PDF": "https://arxiv.org/pdf/2507.16852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents SynthCTI, a framework for data augmentation, which generates synthetic CTI sentences to address data scarcity and class imbalance in CTI mapping tasks. This is a direct contribution to LLM training data processing, specifically in data generation and improving data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16853",
      "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled the development of mobile agents that can understand visual inputs and follow user instructions, unlocking new possibilities for automating complex tasks on mobile devices. However, applying these models to real-world mobile scenarios remains a significant challenge due to the long-horizon task execution, difficulty in error recovery, and the cold-start problem in unfamiliar environments. To address these challenges, we propose MobileUse, a GUI agent designed for robust and adaptive mobile task execution. To improve resilience in long-horizon tasks and dynamic environments, we introduce a hierarchical reflection architecture that enables the agent to self-monitor, detect, and recover from errors across multiple temporal scales-ranging from individual actions to overall task completion-while maintaining efficiency through a reflection-on-demand strategy. To tackle cold-start issues, we further introduce a proactive exploration module, which enriches the agent's understanding of the environment through self-planned exploration. Evaluations on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse establishes new state-of-the-art performance, achieving success rates of 62.9% and 44.2%, respectively. To facilitate real-world applications, we release an out-of-the-box toolkit for automated task execution on physical mobile devices, which is available at https://github.com/MadeAgents/mobile-use.",
      "authors": [
        "Ning Li",
        "Xiangmou Qu",
        "Jiamu Zhou",
        "Jun Wang",
        "Muning Wen",
        "Kounianhua Du",
        "Xingyu Lou",
        "Qiuying Peng",
        "Jun Wang",
        "Weinan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:37:05+00:00",
          "link": "https://arxiv.org/abs/2507.16853v1",
          "size": "1845kb",
          "version": "v1"
        }
      ],
      "title": "MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16853",
        "HTML": "https://arxiv.org/html/2507.16853v1",
        "PDF": "https://arxiv.org/pdf/2507.16853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces MobileUse, a GUI agent for mobile task execution, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16854",
      "abstract": "Multimodal aspect-based sentiment analysis(MABSA) seeks to identify aspect terms within paired image-text data and determine their fine grained sentiment polarities, representing a fundamental task for improving the effectiveness of applications such as product review systems and public opinion monitoring. Existing methods face challenges such as cross modal alignment noise and insufficient consistency in fine-grained representations. While global modality alignment methods often overlook the connection between aspect terms and their corresponding local visual regions, bridging the representation gap between text and images remains a challenge. To address these limitations, this paper introduces an end to end Contrastive Learning framework with Adaptive Multi-loss and Progressive Attention Fusion(CLAMP). The framework is composed of three novel modules: Progressive Attention Fusion network, Multi-task Contrastive Learning, and Adaptive Multi-loss Aggregation. The Progressive Attention Fusion network enhances fine-grained alignment between textual features and image regions via hierarchical, multi-stage cross modal interactions, effectively suppressing irrelevant visual noise. Secondly, multi-task contrastive learning combines global modal contrast and local granularity alignment to enhance cross modal representation consistency. Adaptive Multi-loss Aggregation employs a dynamic uncertainty based weighting mechanism to calibrate loss contributions according to each task's uncertainty, thereby mitigating gradient interference. Evaluation on standard public benchmarks demonstrates that CLAMP consistently outperforms the vast majority of existing state of the art methods.",
      "authors": [
        "Xiaoqiang He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:49:57+00:00",
          "link": "https://arxiv.org/abs/2507.16854v1",
          "size": "5003kb",
          "version": "v1"
        }
      ],
      "title": "CLAMP: Contrastive Learning with Adaptive Multi-loss and Progressive Fusion for Multimodal Aspect-Based Sentiment Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16854",
        "PDF": "https://arxiv.org/pdf/2507.16854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on multimodal aspect-based sentiment analysis using a contrastive learning framework, which does not involve LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16856",
      "abstract": "As vision-language models (VLMs) are increasingly deployed in real-world applications, new safety risks arise from the subtle interplay between images and text. In particular, seemingly innocuous inputs can combine to reveal harmful intent, leading to unsafe model responses. Despite increasing attention to multimodal safety, previous approaches based on post hoc filtering or static refusal prompts struggle to detect such latent risks, especially when harmfulness emerges only from the combination of inputs. We propose SIA (Safety via Intent Awareness), a training-free prompt engineering framework that proactively detects and mitigates harmful intent in multimodal inputs. SIA employs a three-stage reasoning process: (1) visual abstraction via captioning, (2) intent inference through few-shot chain-of-thought prompting, and (3) intent-conditioned response refinement. Rather than relying on predefined rules or classifiers, SIA dynamically adapts to the implicit intent inferred from the image-text pair. Through extensive experiments on safety-critical benchmarks including SIUO, MM-SafetyBench, and HoliSafe, we demonstrate that SIA achieves substantial safety improvements, outperforming prior methods. Although SIA shows a minor reduction in general reasoning accuracy on MMStar, the corresponding safety gains highlight the value of intent-aware reasoning in aligning VLMs with human-centric values.",
      "authors": [
        "Youngjin Na",
        "Sangheon Jeong",
        "and Youngwan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:59:50+00:00",
          "link": "https://arxiv.org/abs/2507.16856v1",
          "size": "2168kb",
          "version": "v1"
        }
      ],
      "title": "SIA: Enhancing Safety via Intent Awareness for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16856",
        "HTML": "https://arxiv.org/html/2507.16856v1",
        "PDF": "https://arxiv.org/pdf/2507.16856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a safety framework for vision-language models through intent awareness, focusing on prompt engineering for safety. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16857",
      "abstract": "This study investigates potential indicators of coordinated influence activity among users participating in both r/Sino and r/China, two ideologically divergent Reddit communities focused on Chinese political discourse. Topic modeling and sentiment analysis are applied to all posts and comments authored by dual-subreddit users to construct a user-topic sentiment matrix. Individual sentiment patterns are compared to global topic baselines derived from the broader r/Sino and r/China populations. Behavioral profiling is performed using full user activity histories and metadata, incorporating measures such as lexical diversity, language consistency, account age, posting frequency, and karma distribution. Users exhibiting multiple behavioral anomalies are identified and examined within a subreddit co-participation network to assess structural overlap. The combined linguistic and behavioral analysis enables the identification of patterns consistent with inauthentic or strategically structured participation. These findings demonstrate the utility of integrating content and activity-based signals in the analysis of online influence behavior within contested information environments.",
      "authors": [
        "Manon Pilaud and Ian McCulloh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:21:17+00:00",
          "link": "https://arxiv.org/abs/2507.16857v1",
          "size": "1326kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Subreddit Behavior as Open-Source Indicators of Coordinated Influence: A Case Study of r/Sino & r/China",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16857",
        "PDF": "https://arxiv.org/pdf/2507.16857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates coordinated influence activities on Reddit using content analysis and user behavior profiling. There is no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16858",
      "abstract": "Following the 2024 U.S. presidential election, Democratic lawmakers and their supporters increasingly migrated from mainstream social media plat-forms like X (formerly Twitter) to decentralized alternatives such as Bluesky. This study investigates how Congressional Democrats use Bluesky to form networks of influence and disseminate political messaging in a platform environment that lacks algorithmic amplification. We employ a mixed-methods approach that combines social network analysis, expo-nential random graph modeling (ERGM), and transformer-based topic mod-eling (BERTopic) to analyze follows, mentions, reposts, and discourse pat-terns among 182 verified Democratic members of Congress. Our findings show that while party leaders such as Hakeem Jeffries and Elizabeth War-ren dominate visibility metrics, overlooked figures like Marcy Kaptur, Donald Beyer, and Dwight Evans occupy structurally central positions, suggesting latent influence within the digital party ecosystem. ERGM re-sults reveal significant homophily along ideological, state, and leadership lines, with Senate leadership exhibiting lower connectivity. Topic analysis identifies both shared themes (e.g., reproductive rights, foreign conflicts) and subgroup-specific issues, with The Squad showing the most distinct discourse profile. These results demonstrate the potential of decentralized platforms to reshape intra-party communication dynamics and highlight the need for continued computational research on elite political behavior in emerging digital environments.",
      "authors": [
        "Gordon Hew and Ian McCulloh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:25:29+00:00",
          "link": "https://arxiv.org/abs/2507.16858v1",
          "size": "3245kb",
          "version": "v1"
        }
      ],
      "title": "Who Leads in the Shadows? ERGM and Centrality Analysis of Congressional Democrats on Bluesky",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16858",
        "PDF": "https://arxiv.org/pdf/2507.16858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes network and discourse patterns among Congressional Democrats on Bluesky, a social media platform. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16859",
      "abstract": "Fatigue detection plays a critical role in safety-critical applications such as aviation, mining, and long-haul transport. However, most existing methods rely on high-end sensors and controlled environments, limiting their applicability in real world settings. This paper formally defines a practical yet underexplored problem setting for real world fatigue detection, where systems operating with context-appropriate sensors aim to leverage knowledge from differently instrumented sources including those using impractical sensors deployed in controlled environments. To tackle this challenge, we propose a heterogeneous and multi-source fatigue detection framework that adaptively utilizes the available modalities in the target domain while benefiting from the diverse configurations present in source domains. Our experiments, conducted using a realistic field-deployed sensor setup and two publicly available datasets, demonstrate the practicality, robustness, and improved generalization of our approach, paving the practical way for effective fatigue monitoring in sensor-constrained scenarios.",
      "authors": [
        "Luobin Cui",
        "Yanlai Wu",
        "Tang Ying and Weikai Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:22:18+00:00",
          "link": "https://arxiv.org/abs/2507.16859v1",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging multi-source and heterogeneous signals for fatigue detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16859",
        "HTML": "https://arxiv.org/html/2507.16859v1",
        "PDF": "https://arxiv.org/pdf/2507.16859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research defines a framework for fatigue detection using multi-source data and sensors. The focus is on real-world detection setups, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16860",
      "abstract": "Large Language Models (LLMs) have made it easier to create realistic fake profiles on platforms like LinkedIn. This poses a significant risk for text-based fake profile detectors. In this study, we evaluate the robustness of existing detectors against LLM-generated profiles. While highly effective in detecting manually created fake profiles (False Accept Rate: 6-7%), the existing detectors fail to identify GPT-generated profiles (False Accept Rate: 42-52%). We propose GPT-assisted adversarial training as a countermeasure, restoring the False Accept Rate to between 1-7% without impacting the False Reject Rates (0.5-2%). Ablation studies revealed that detectors trained on combined numerical and textual embeddings exhibit the highest robustness, followed by those using numerical-only embeddings, and lastly those using textual-only embeddings. Complementary analysis on the ability of prompt-based GPT-4Turbo and human evaluators affirms the need for robust automated detectors such as the one proposed in this study.",
      "authors": [
        "Apoorva Gulati",
        "Rajesh Kumar",
        "Vinti Agarwal",
        "Aditya Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:23:52+00:00",
          "link": "https://arxiv.org/abs/2507.16860v1",
          "size": "441kb",
          "version": "v1"
        }
      ],
      "title": "Weak Links in LinkedIn: Enhancing Fake Profile Detection in the Age of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16860",
        "HTML": "https://arxiv.org/html/2507.16860v1",
        "PDF": "https://arxiv.org/pdf/2507.16860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing fake profile detection using GPT-assisted training, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16861",
      "abstract": "Integrating LiDAR and camera inputs into a unified Bird's-Eye-View (BEV) representation is crucial for enhancing 3D perception capabilities of autonomous vehicles. However, current methods are often affected by misalignment between camera and LiDAR features. This misalignment leads to inaccurate depth supervision in camera branch and erroneous fusion during cross-modal feature aggregation. The root cause of this misalignment lies in projection errors, stemming from minor extrinsic calibration inaccuracies and rolling shutter effect of LiDAR during vehicle motion. In this work, our key insight is that these projection errors are predominantly concentrated at object-background boundaries, which are readily identified by 2D detectors. Based on this, our main motivation is to utilize 2D object priors to pre-align cross-modal features before fusion. To address local misalignment, we propose Prior Guided Depth Calibration (PGDC), which leverages 2D priors to correct local misalignment and preserve correct cross-modal feature pairs. To resolve global misalignment, we introduce Discontinuity Aware Geometric Fusion (DAGF) to process calibrated results from PGDC, suppressing noise and explicitly enhancing sharp transitions at object-background boundaries. To effectively utilize these transition-aware depth representations, we incorporate Structural Guidance Depth Modulator (SGDM), using a gated attention mechanism to efficiently fuse aligned depth and image features. Our proposed method achieves state-of-the-art performance on nuScenes validation dataset, with its mAP and NDS reaching 71.5% and 73.6% respectively.",
      "authors": [
        "Xiang Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T18:12:22+00:00",
          "link": "https://arxiv.org/abs/2507.16861v1",
          "size": "14189kb",
          "version": "v1"
        }
      ],
      "title": "Look Before You Fuse: 2D-Guided Cross-Modal Alignment for Robust 3D Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16861",
        "HTML": "https://arxiv.org/html/2507.16861v1",
        "PDF": "https://arxiv.org/pdf/2507.16861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on 3D detection for autonomous vehicles using LiDAR and camera data fusion, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16863",
      "abstract": "Achieving human-like perception and reasoning in Multimodal Large Language Models (MLLMs) remains a central challenge in artificial intelligence. While recent research has primarily focused on enhancing reasoning capabilities in MLLMs, a fundamental question persists: Can Multimodal Large Language Models truly perceive the world as humans do? This paper shifts focus from reasoning to perception. Rather than constructing benchmarks specifically for reasoning, we introduce the Turing Eye Test (TET), a challenging perception-oriented benchmark comprising four diagnostic tasks that evaluate MLLMs' performance on synthetic images that humans process intuitively. Our findings reveal that state-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks trivial for humans. Both in-context learning and training on language backbone-effective for previous benchmarks-fail to improve performance on our tasks, while fine-tuning the vision tower enables rapid adaptation, suggesting that our benchmark poses challenges for vision tower generalization rather than for the knowledge and reasoning capabilities of the language backbone-a key gap between current MLLMs and human perception. We release a representative subset of TET tasks in this version, and will introduce more diverse tasks and methods to enhance visual generalization in future work.",
      "authors": [
        "Hongcheng Gao",
        "Zihao Huang",
        "Lin Xu",
        "Jingyi Tang",
        "Xinhao Li",
        "Yue Liu",
        "Haoyang Li",
        "Taihang Hu",
        "Minhua Lin",
        "Xinlong Yang",
        "Ge Wu",
        "Balong Bi",
        "Hongyu Chen",
        "Wentao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T21:50:16+00:00",
          "link": "https://arxiv.org/abs/2507.16863v1",
          "size": "7165kb",
          "version": "v1"
        }
      ],
      "title": "Pixels, Patterns, but No Poetry: To See The World like Humans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16863",
        "HTML": "https://arxiv.org/html/2507.16863v1",
        "PDF": "https://arxiv.org/pdf/2507.16863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces the Turing Eye Test benchmark for perception in MLLMs, it does not focus on the creation or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16864",
      "abstract": "Multi-step reasoning is a fundamental challenge in artificial intelligence, with applications ranging from mathematical problem-solving to decision-making in dynamic environments. Reinforcement Learning (RL) has shown promise in enabling agents to perform multi-step reasoning by optimizing long-term rewards. However, conventional RL methods struggle with complex reasoning tasks due to issues such as credit assignment, high-dimensional state representations, and stability concerns. Recent advancements in Transformer architectures and hyperbolic geometry have provided novel solutions to these challenges. This paper introduces a new framework that integrates hyperbolic Transformers into RL for multi-step reasoning. The proposed approach leverages hyperbolic embeddings to model hierarchical structures effectively. We present theoretical insights, algorithmic details, and experimental results that include Frontier Math and nonlinear optimal control problems. Compared to RL with vanilla transformer, the hyperbolic RL largely improves accuracy by (32%~44%) on FrontierMath benchmark, (43%~45%) on nonlinear optimal control benchmark, while achieving impressive reduction in computational time by (16%~32%) on FrontierMath benchmark, (16%~17%) on nonlinear optimal control benchmark. Our work demonstrates the potential of hyperbolic Transformers in reinforcement learning, particularly for multi-step reasoning tasks that involve hierarchical structures.",
      "authors": [
        "Tao Xu",
        "Dung-Yang Lee and Momiao Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T21:59:05+00:00",
          "link": "https://arxiv.org/abs/2507.16864v1",
          "size": "1199kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning in hyperbolic space for multi-step reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16864",
        "PDF": "https://arxiv.org/pdf/2507.16864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves reinforcement learning with hyperbolic geometry and Transformers for multi-step reasoning, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16865",
      "abstract": "Inertial Measurement Unit (IMU) has become a key technology for achieving low-cost and precise positioning. However, traditional CNN-based inertial positioning methods struggle to capture the nonlinear motion characteristics and long-term dependencies in IMU data. To address this limitation, we propose a novel inertial positioning network with a generic backbone called ResChebyKAN, which leverages the nonlinear approximation capabilities of Chebyshev polynomials to model complex motion patterns. Additionally, we introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively capture contextual information and enhance long-term dependency modeling. Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD, IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore, we release a preprocessed dataset and empirically show that removing the gravity component from acceleration data significantly improves inertial positioning performance.",
      "authors": [
        "Shanshan Zhang",
        "Tianshui Wen",
        "Siyue Wang",
        "Qi Zhang",
        "Ziheng Zhou",
        "Huiru Zheng",
        "Lingxiang Zheng",
        "Yu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T00:24:06+00:00",
          "link": "https://arxiv.org/abs/2507.16865v1",
          "size": "781kb",
          "version": "v1"
        }
      ],
      "title": "ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16865",
        "HTML": "https://arxiv.org/html/2507.16865v1",
        "PDF": "https://arxiv.org/pdf/2507.16865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on inertial odometry using a neural network architecture and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16867",
      "abstract": "This paper introduces DiffCarl, a diffusion-modeled carbon- and risk-aware reinforcement learning algorithm for intelligent operation of multi-microgrid systems. With the growing integration of renewables and increasing system complexity, microgrid communities face significant challenges in real-time energy scheduling and optimization under uncertainty. DiffCarl integrates a diffusion model into a deep reinforcement learning (DRL) framework to enable adaptive energy scheduling under uncertainty and explicitly account for carbon emissions and operational risk. By learning action distributions through a denoising generation process, DiffCarl enhances DRL policy expressiveness and enables carbon- and risk-aware scheduling in dynamic and uncertain microgrid environments. Extensive experimental studies demonstrate that it outperforms classic algorithms and state-of-the-art DRL solutions, with 2.3-30.1% lower operational cost. It also achieves 28.7% lower carbon emissions than those of its carbon-unaware variant and reduces performance variability. These results highlight DiffCarl as a practical and forward-looking solution. Its flexible design allows efficient adaptation to different system configurations and objectives to support real-world deployment in evolving energy systems.",
      "authors": [
        "Yunyi Zhao",
        "Wei Zhang",
        "Cheng Xiang",
        "Hongyang Du",
        "Dusit Niyato",
        "Shuhua Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T03:27:07+00:00",
          "link": "https://arxiv.org/abs/2507.16867v1",
          "size": "1106kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion-Modeled Reinforcement Learning for Carbon and Risk-Aware Microgrid Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16867",
        "HTML": "https://arxiv.org/html/2507.16867v1",
        "PDF": "https://arxiv.org/pdf/2507.16867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reinforcement learning for microgrid optimization, with no discussion of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16869",
      "abstract": "With the rapid development of AI-generated content (AIGC), video generation has emerged as one of its most dynamic and impactful subfields. In particular, the advancement of video generation foundation models has led to growing demand for controllable video generation methods that can more accurately reflect user intent. Most existing foundation models are designed for text-to-video generation, where text prompts alone are often insufficient to express complex, multi-modal, and fine-grained user requirements. This limitation makes it challenging for users to generate videos with precise control using current models. To address this issue, recent research has explored the integration of additional non-textual conditions, such as camera motion, depth maps, and human pose, to extend pretrained video generation models and enable more controllable video synthesis. These approaches aim to enhance the flexibility and practical applicability of AIGC-driven video generation systems. In this survey, we provide a systematic review of controllable video generation, covering both theoretical foundations and recent advances in the field. We begin by introducing the key concepts and commonly used open-source video generation models. We then focus on control mechanisms in video diffusion models, analyzing how different types of conditions can be incorporated into the denoising process to guide generation. Finally, we categorize existing methods based on the types of control signals they leverage, including single-condition generation, multi-condition generation, and universal controllable generation. For a complete list of the literature on controllable video generation reviewed, please visit our curated repository at https://github.com/mayuelala/Awesome-Controllable-Video-Generation.",
      "authors": [
        "Yue Ma",
        "Kunyu Feng",
        "Zhongyuan Hu",
        "Xinyu Wang",
        "Yucheng Wang",
        "Mingzhe Zheng",
        "Xuanhua He",
        "Chenyang Zhu",
        "Hongyu Liu",
        "Yingqing He",
        "Zeyu Wang",
        "Zhifeng Li",
        "Xiu Li",
        "Wei Liu",
        "Dan Xu",
        "Linfeng Zhang",
        "Qifeng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T06:05:34+00:00",
          "link": "https://arxiv.org/abs/2507.16869v1",
          "size": "8892kb",
          "version": "v1"
        }
      ],
      "title": "Controllable Video Generation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16869",
        "HTML": "https://arxiv.org/html/2507.16869v1",
        "PDF": "https://arxiv.org/pdf/2507.16869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey addresses controllable video generation methods and models, which do not pertain to LLM training data processing. It focuses more on generation mechanisms and control in the AIGC domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16870",
      "abstract": "APIs (Application Programming Interfaces) or Web Services are the foundational building blocks that enable interconnected systems. However this proliferation of APIs has also introduced security challenges that require systematic and scalable solutions for secure authentication and authorization. This paper presents the fundamentals necessary for building a such a token-based API security system. It discusses the components necessary, the integration of OAuth 2.0, extensibility of the token architectures, necessary cryptographic foundations, and persistence strategies to ensure secure and resilient operations. In addition to architectural concerns, the paper explores best practices for token lifecycle management, scope definition, expiration policies, and revocation mechanisms, all framed within a real-world scenario. By adhering to these principles, developers can establish a robust baseline while maintaining the flexibility to customize their domain-specific requirements. The approach does not claim to cover all variations necessary for diverse architectures but instead focuses on key principles essential for any standard API token authentication system. Throughout, the paper emphasizes balancing practical considerations with security imperatives and uses key concepts such as the CIA triad, OAuth standards, secure token life cycle, and practices for protecting sensitive user and application data. The intent is to equip developers with the foundational knowledge necessary to build secure, scalable token-based API security systems ready to handle the evolving threat landscape.",
      "authors": [
        "Senthilkumar Gopal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T06:14:14+00:00",
          "link": "https://arxiv.org/abs/2507.16870v1",
          "size": "544kb",
          "version": "v1"
        }
      ],
      "title": "Building a robust OAuth token based API Security: A High level Overview",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16870",
        "HTML": "https://arxiv.org/html/2507.16870v1",
        "PDF": "https://arxiv.org/pdf/2507.16870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses building a secure token-based API security system using OAuth, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16871",
      "abstract": "Recent work has identified non-compact symmetric spaces U/H as a promising class of homogeneous manifolds to develop a geometrically consistent theory of neural networks. An initial implementation of these concepts has been presented in a twin paper under the moniker of Cartan Neural Networks, showing both the feasibility and the performance of these geometric concepts in a machine learning context. The current paper expands on the mathematical structures underpinning Cartan Neural Networks, detailing the geometric properties of the layers and how the maps between layers interact with such structures to make Cartan Neural Networks covariant and geometrically interpretable. Together, these twin papers constitute a first step towards a fully geometrically interpretable theory of neural networks exploiting group-theoretic structures",
      "authors": [
        "Pietro Giuseppe Fr\\'e",
        "Federico Milanesio",
        "Guido Sanguinetti",
        "Matteo Santoro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "High Energy Physics - Theory (hep-th)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T07:34:53+00:00",
          "link": "https://arxiv.org/abs/2507.16871v1",
          "size": "866kb",
          "version": "v1"
        }
      ],
      "title": "Navigation through Non-Compact Symmetric Spaces: a mathematical perspective on Cartan Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16871",
        "HTML": "https://arxiv.org/html/2507.16871v1",
        "PDF": "https://arxiv.org/pdf/2507.16871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus on mathematical theories for neural network architecture does not connect to the LLM training data processing domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16872",
      "abstract": "Model compression is crucial for minimizing memory storage and accelerating inference in deep learning (DL) models, including recent foundation models like large language models (LLMs). Users can access different compressed model versions according to their resources and budget. However, while existing compression operations primarily focus on optimizing the trade-off between resource efficiency and model performance, the privacy risks introduced by compression remain overlooked and insufficiently understood.\n  In this work, through the lens of membership inference attack (MIA), we propose CompLeak, the first privacy risk evaluation framework examining three widely used compression configurations that are pruning, quantization, and weight clustering supported by the commercial model compression framework of Google's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has three variants, given available access to the number of compressed models and original model. CompLeakNR starts by adopting existing MIA methods to attack a single compressed model, and identifies that different compressed models influence members and non-members differently. When the original model and one compressed model are available, CompLeakSR leverages the compressed model as a reference to the original model and uncovers more privacy by combining meta information (e.g., confidence vector) from both models. When multiple compressed models are available with/without accessing the original model, CompLeakMR innovatively exploits privacy leakage info from multiple compressed versions to substantially signify the overall privacy leakage. We conduct extensive experiments on seven diverse model architectures (from ResNet to foundation models of BERT and GPT-2), and six image and textual benchmark datasets.",
      "authors": [
        "Na Li and Yansong Gao and Hongsheng Hu and Boyu Kuang and Anmin Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T08:02:46+00:00",
          "link": "https://arxiv.org/abs/2507.16872v1",
          "size": "15488kb",
          "version": "v1"
        }
      ],
      "title": "CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16872",
        "HTML": "https://arxiv.org/html/2507.16872v1",
        "PDF": "https://arxiv.org/pdf/2507.16872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper addresses privacy issues in model compression, it does not contribute to LLM training data processing or the creation/engineering of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16873",
      "abstract": "The exponential growth of video content has made personalized video highlighting an essential task, as user preferences are highly variable and complex. Existing video datasets, however, often lack personalization, relying on isolated videos or simple text queries that fail to capture the intricacies of user behavior. In this work, we introduce HIPPO-Video, a novel dataset for personalized video highlighting, created using an LLM-based user simulator to generate realistic watch histories reflecting diverse user preferences. The dataset includes 2,040 (watch history, saliency score) pairs, covering 20,400 videos across 170 semantic categories. To validate our dataset, we propose HiPHer, a method that leverages these personalized watch histories to predict preference-conditioned segment-wise saliency scores. Through extensive experiments, we demonstrate that our method outperforms existing generic and query-based approaches, showcasing its potential for highly user-centric video highlighting in real-world scenarios.",
      "authors": [
        "Jeongeun Lee",
        "Youngjae Yu",
        "Dongha Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T08:24:33+00:00",
          "link": "https://arxiv.org/abs/2507.16873v1",
          "size": "3262kb",
          "version": "v1"
        }
      ],
      "title": "HIPPO-Video: Simulating Watch Histories with Large Language Models for Personalized Video Highlighting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16873",
        "HTML": "https://arxiv.org/html/2507.16873v1",
        "PDF": "https://arxiv.org/pdf/2507.16873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces HIPPO-Video, a dataset for personalized video highlighting using an LLM-based user simulator to create watch histories. While it involves data generation via simulation, the focus is more on personalizing video highlights rather than training LLMs directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16874",
      "abstract": "Multi-Agent Pathfinding (MAPF) is the problem of finding paths for a set of agents such that each agent reaches its desired destination while avoiding collisions with the other agents. Many MAPF solvers are designed to run offline, that is, first generate paths for all agents and then execute them. Real-Time MAPF (RT-MAPF) embodies a realistic MAPF setup in which one cannot wait until a complete path for each agent has been found before they start to move. Instead, planning and execution are interleaved, where the agents must commit to a fixed number of steps in a constant amount of computation time, referred to as the planning budget. Existing solutions to RT-MAPF iteratively call windowed versions of MAPF algorithms in every planning period, without explicitly considering the size of the planning budget. We address this gap and explore different policies for allocating the planning budget in windowed versions of standard MAPF algorithms, namely Prioritized Planning (PrP) and MAPF-LNS2. Our exploration shows that the baseline approach in which all agents draw from a shared planning budget pool is ineffective in over-constrained situations. Instead, policies that distribute the planning budget over the agents are able to solve more problems with a smaller makespan.",
      "authors": [
        "Raz Beck and Roni Stern"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T08:32:55+00:00",
          "link": "https://arxiv.org/abs/2507.16874v1",
          "size": "531kb",
          "version": "v1"
        }
      ],
      "title": "Budget Allocation Policies for Real-Time Multi-Agent Path Finding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16874",
        "HTML": "https://arxiv.org/html/2507.16874v1",
        "PDF": "https://arxiv.org/pdf/2507.16874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with Budget Allocation Policies for Real-Time Multi-Agent Path Finding, which does not pertain to LLM training data processing or any relevant data operations such as collection or generation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16877",
      "abstract": "Referring Expression Comprehension (REC) aims to localize specified entities or regions in an image based on natural language descriptions. While existing methods handle single-entity localization, they often ignore complex inter-entity relationships in multi-entity scenes, limiting their accuracy and reliability. Additionally, the lack of high-quality datasets with fine-grained, paired image-text-relation annotations hinders further progress. To address this challenge, we first construct a relation-aware, multi-entity REC dataset called ReMeX, which includes detailed relationship and textual annotations. We then propose ReMeREC, a novel framework that jointly leverages visual and textual cues to localize multiple entities while modeling their inter-relations. To address the semantic ambiguity caused by implicit entity boundaries in language, we introduce the Text-adaptive Multi-entity Perceptron (TMP), which dynamically infers both the quantity and span of entities from fine-grained textual cues, producing distinctive representations. Additionally, our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and global scene understanding. To further improve language comprehension for fine-grained prompts, we also construct a small-scale auxiliary dataset, EntityText, generated using large language models. Experiments on four benchmark datasets show that ReMeREC achieves state-of-the-art performance in multi-entity grounding and relation prediction, outperforming existing approaches by a large margin.",
      "authors": [
        "Yizhi Hu",
        "Zezhao Tian",
        "Xingqun Qi",
        "Chen Su",
        "Bingkun Yang",
        "Junhui Yin",
        "Muyi Sun",
        "Man Zhang",
        "Zhenan Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T11:23:48+00:00",
          "link": "https://arxiv.org/abs/2507.16877v1",
          "size": "14411kb",
          "version": "v1"
        }
      ],
      "title": "ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16877",
        "HTML": "https://arxiv.org/html/2507.16877v1",
        "PDF": "https://arxiv.org/pdf/2507.16877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset, ReMeX, for relation-aware multi-entity referring expression comprehension. While it involves dataset creation using LLMs, its focus is not directly on LLM training data processing but more on image-text relationship modeling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16878",
      "abstract": "Recent advances in large language models (LLMs) have improved reasoning in text and image domains, yet achieving robust video reasoning remains a significant challenge. Existing video benchmarks mainly assess shallow understanding and reasoning and allow models to exploit global context, failing to rigorously evaluate true causal and stepwise reasoning. We present CausalStep, a benchmark designed for explicit stepwise causal reasoning in videos. CausalStep segments videos into causally linked units and enforces a strict stepwise question-answer (QA) protocol, requiring sequential answers and preventing shortcut solutions. Each question includes carefully constructed distractors based on error type taxonomy to ensure diagnostic value. The benchmark features 100 videos across six categories and 1,852 multiple-choice QA pairs. We introduce seven diagnostic metrics for comprehensive evaluation, enabling precise diagnosis of causal reasoning capabilities. Experiments with leading proprietary and open-source models, as well as human baselines, reveal a significant gap between current models and human-level stepwise reasoning. CausalStep provides a rigorous benchmark to drive progress in robust and interpretable video reasoning.",
      "authors": [
        "Xuchen Li",
        "Xuzhao Li",
        "Shiyu Hu",
        "Kaiqi Huang",
        "Wentao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T12:29:13+00:00",
          "link": "https://arxiv.org/abs/2507.16878v1",
          "size": "2526kb",
          "version": "v1"
        }
      ],
      "title": "CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16878",
        "HTML": "https://arxiv.org/html/2507.16878v1",
        "PDF": "https://arxiv.org/pdf/2507.16878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents CausalStep, a benchmark for causal reasoning in videos, which doesn't address training data processing for LLMs. It focuses on video reasoning evaluation and not on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16880",
      "abstract": "Text-to-image diffusion models (DMs) have achieved remarkable success in image generation. However, concerns about data privacy and intellectual property remain due to their potential to inadvertently memorize and replicate training data. Recent mitigation efforts have focused on identifying and pruning weights responsible for triggering replication, based on the assumption that memorization can be localized. Our research assesses the robustness of these pruning-based approaches. We demonstrate that even after pruning, minor adjustments to text embeddings of input prompts are sufficient to re-trigger data replication, highlighting the fragility of these defenses. Furthermore, we challenge the fundamental assumption of memorization locality, by showing that replication can be triggered from diverse locations within the text embedding space, and follows different paths in the model. Our findings indicate that existing mitigation strategies are insufficient and underscore the need for methods that truly remove memorized content, rather than attempting to suppress its retrieval. As a first step in this direction, we introduce a novel adversarial fine-tuning method that iteratively searches for replication triggers and updates the model to increase robustness. Through our research, we provide fresh insights into the nature of memorization in text-to-image DMs and a foundation for building more trustworthy and compliant generative AI.",
      "authors": [
        "Antoni Kowalczuk",
        "Dominik Hintersdorf",
        "Lukas Struppek",
        "Kristian Kersting",
        "Adam Dziedzic",
        "Franziska Boenisch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T15:02:38+00:00",
          "link": "https://arxiv.org/abs/2507.16880v1",
          "size": "17925kb",
          "version": "v1"
        }
      ],
      "title": "Finding Dori: Memorization in Text-to-Image Diffusion Models Is Less Local Than Assumed",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16880",
        "HTML": "https://arxiv.org/html/2507.16880v1",
        "PDF": "https://arxiv.org/pdf/2507.16880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores memorization in text-to-image diffusion models and proposes adversarial fine-tuning to address memorization issues. It focuses on diffusion models and does not contribute to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16881",
      "abstract": "Probabilistic encoding introduces Gaussian noise into neural networks, enabling a smooth transition from deterministic to uncertain states and enhancing generalization ability. However, the randomness of Gaussian noise distorts point-based distance measurements in classification tasks. To mitigate this issue, we propose a confidence optimization probabilistic encoding (CPE) method that improves distance reliability and enhances representation learning. Specifically, we refine probabilistic encoding with two key strategies: First, we introduce a confidence-aware mechanism to adjust distance calculations, ensuring consistency and reliability in probabilistic encoding classification tasks. Second, we replace the conventional KL divergence-based variance regularization, which relies on unreliable prior assumptions, with a simpler L2 regularization term to directly constrain variance. The method we proposed is model-agnostic, and extensive experiments on natural language classification tasks demonstrate that our method significantly improves performance and generalization on both the BERT and the RoBERTa model.",
      "authors": [
        "Pengjiu Xia",
        "Yidian Huang",
        "Wenchao Wei",
        "Yuwen Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T15:32:27+00:00",
          "link": "https://arxiv.org/abs/2507.16881v1",
          "size": "489kb",
          "version": "v1"
        }
      ],
      "title": "Confidence Optimization for Probabilistic Encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16881",
        "HTML": "https://arxiv.org/html/2507.16881v1",
        "PDF": "https://arxiv.org/pdf/2507.16881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a confidence optimization probabilistic encoding method for neural networks to enhance generalization. It does not address LLM training data processing, focusing instead on representation learning improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16884",
      "abstract": "Generative models like Flow Matching have achieved state-of-the-art performance but are often hindered by a computationally expensive iterative sampling process. To address this, recent work has focused on few-step or one-step generation by learning the average velocity field, which directly maps noise to data. MeanFlow, a leading method in this area, learns this field by enforcing a differential identity that connects the average and instantaneous velocities. In this work, we argue that this differential formulation is a limiting special case of a more fundamental principle. We return to the first principles of average velocity and leverage the additivity property of definite integrals. This leads us to derive a novel, purely algebraic identity we term Interval Splitting Consistency. This identity establishes a self-referential relationship for the average velocity field across different time intervals without resorting to any differential operators. Based on this principle, we introduce SplitMeanFlow, a new training framework that enforces this algebraic consistency directly as a learning objective. We formally prove that the differential identity at the core of MeanFlow is recovered by taking the limit of our algebraic consistency as the interval split becomes infinitesimal. This establishes SplitMeanFlow as a direct and more general foundation for learning average velocity fields. From a practical standpoint, our algebraic approach is significantly more efficient, as it eliminates the need for JVP computations, resulting in simpler implementation, more stable training, and broader hardware compatibility. One-step and two-step SplitMeanFlow models have been successfully deployed in large-scale speech synthesis products (such as Doubao), achieving speedups of 20x.",
      "authors": [
        "Yi Guo",
        "Wei Wang",
        "Zhihang Yuan",
        "Rong Cao",
        "Kuan Chen",
        "Zhengyang Chen",
        "Yuanyuan Huo",
        "Yang Zhang",
        "Yuping Wang",
        "Shouda Liu",
        "Yuxuan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T16:26:58+00:00",
          "link": "https://arxiv.org/abs/2507.16884v1",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "title": "SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16884",
        "HTML": "https://arxiv.org/html/2507.16884v1",
        "PDF": "https://arxiv.org/pdf/2507.16884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces SplitMeanFlow, a generative modeling framework to optimize generative models' efficiency. It does not discuss any aspects of LLM training data processing, focusing on generative models instead."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16886",
      "abstract": "Spatial transcriptomics (ST) has revolutionized biomedical research by enabling high resolution gene expression profiling within tissues. However, the high cost and scarcity of high resolution ST data remain significant challenges. We present Single-shot Sparser-to-Sparse (S2S-ST), a novel framework for accurate ST imputation that requires only a single and low-cost sparsely sampled ST dataset alongside widely available natural images for co-training. Our approach integrates three key innovations: (1) a sparser-to-sparse self-supervised learning strategy that leverages intrinsic spatial patterns in ST data, (2) cross-domain co-learning with natural images to enhance feature representation, and (3) a Cascaded Data Consistent Imputation Network (CDCIN) that iteratively refines predictions while preserving sampled gene data fidelity. Extensive experiments on diverse tissue types, including breast cancer, liver, and lymphoid tissue, demonstrate that our method outperforms state-of-the-art approaches in imputation accuracy. By enabling robust ST reconstruction from sparse inputs, our framework significantly reduces reliance on costly high resolution data, facilitating potential broader adoption in biomedical research and clinical applications.",
      "authors": [
        "Yaoyu Fang",
        "Jiahe Qian",
        "Xinkun Wang",
        "Lee A. Cooper",
        "Bo Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T17:58:38+00:00",
          "link": "https://arxiv.org/abs/2507.16886v1",
          "size": "6207kb",
          "version": "v1"
        }
      ],
      "title": "Sparser2Sparse: Single-shot Sparser-to-Sparse Learning for Spatial Transcriptomics Imputation with Natural Image Co-learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16886",
        "HTML": "https://arxiv.org/html/2507.16886v1",
        "PDF": "https://arxiv.org/pdf/2507.16886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents S2S-ST, a framework for spatial transcriptomics imputation, which involves natural image co-learning and biomedical data processing. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16887",
      "abstract": "The rapid advancement of pre-trained language models (PLMs) has demonstrated promising results for various code-related tasks. However, their effectiveness in detecting real-world vulnerabilities remains a critical challenge. % for the security community. While existing empirical studies evaluate PLMs for vulnerability detection (VD), their inadequate consideration in data preparation, evaluation setups, and experimental settings undermines the accuracy and comprehensiveness of evaluations. This paper introduces RevisitVD, an extensive evaluation of 17 PLMs spanning smaller code-specific PLMs and large-scale PLMs using newly constructed datasets. Specifically, we compare the performance of PLMs under both fine-tuning and prompt engineering, assess their effectiveness and generalizability across various training and testing settings, and analyze their robustness against code normalization, abstraction, and semantic-preserving transformations.\n  Our findings reveal that, for VD tasks, PLMs incorporating pre-training tasks designed to capture the syntactic and semantic patterns of code outperform both general-purpose PLMs and those solely pre-trained or fine-tuned on large code corpora. However, these models face notable challenges in real-world scenarios, such as difficulties in detecting vulnerabilities with complex dependencies, handling perturbations introduced by code normalization and abstraction, and identifying semantic-preserving vulnerable code transformations. Also, the truncation caused by the limited context windows of PLMs can lead to a non-negligible amount of labeling errors. This study underscores the importance of thorough evaluations of model performance in practical scenarios and outlines future directions to help enhance the effectiveness of PLMs for realistic VD applications.",
      "authors": [
        "Youpeng Li",
        "Weiliang Qi",
        "Xuyu Wang",
        "Fuxun Yu",
        "Xinda Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T17:58:49+00:00",
          "link": "https://arxiv.org/abs/2507.16887v1",
          "size": "159kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Pre-trained Language Models for Vulnerability Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16887",
        "HTML": "https://arxiv.org/html/2507.16887v1",
        "PDF": "https://arxiv.org/pdf/2507.16887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of pre-trained language models (PLMs) for vulnerability detection with newly constructed datasets, which involves some aspect of data processing for fine-tuning. However, its primary focus is on model evaluation and performance improvement in VD tasks, rather than on training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16922",
      "abstract": "A broad range of NLP tasks involve selecting relevant text spans from given source texts. Despite this shared objective, such \\textit{content selection} tasks have traditionally been studied in isolation, each with its own modeling approaches, datasets, and evaluation metrics. In this work, we propose \\textit{instruction-guided content selection (IGCS)} as a beneficial unified framework for such settings, where the task definition and any instance-specific request are encapsulated as instructions to a language model. To promote this framework, we introduce \\igcsbench{}, the first unified benchmark covering diverse content selection tasks. Further, we create a large generic synthetic dataset that can be leveraged for diverse content selection tasks, and show that transfer learning with these datasets often boosts performance, whether dedicated training for the targeted task is available or not. Finally, we address generic inference time issues that arise in LLM-based modeling of content selection, assess a generic evaluation metric, and overall propose the utility of our resources and methods for future content selection models. Models and datasets available at https://github.com/shmuelamar/igcs.",
      "authors": [
        "Shmuel Amar",
        "Ori Shapira",
        "Aviv Slobodkin and Ido Dagan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:02:54+00:00",
          "link": "https://arxiv.org/abs/2507.16922v1",
          "size": "1681kb",
          "version": "v1"
        }
      ],
      "title": "A Unifying Scheme for Extractive Content Selection Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16922",
        "HTML": "https://arxiv.org/html/2507.16922v1",
        "PDF": "https://arxiv.org/pdf/2507.16922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a synthetic dataset and a unified benchmark for extractive content selection tasks, directly contributing to the creation and processing of training data, which is a key component of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16923",
      "abstract": "This paper addresses the benefit allocation in a mixed-energy truck platoon composed of fuel-powered and electric trucks. The interactions among trucks during platoon formation are modeled as a coalitional game with transferable utility. We first design a stable payoff allocation scheme that accounts for truck heterogeneity in energy savings and platoon roles (leader or follower), establishing core-stability conditions to ensure that no subset of trucks has an incentive to deviate for greater benefit. To enhance payoff fairness, we then propose a closed-form, Shapley value-based allocation approach that is computationally efficient and independent of the platoon size. Sufficient conditions under which the allocation is both fair and core-stable are provided. In scenarios where the Shapley value falls outside the core, we develop an alternative allocation based on the stable payoff that minimizes the mean relative deviation from the Shapley value while preserving core stability. This deviation is further proved to be upper-bounded by $1$, showing a favorable trade-off between stability and fairness. Finally, extensive numerical studies validate the theoretical results and demonstrate the effectiveness of the proposed framework in facilitating stable, equitable, and sustainable cooperation in mixed-energy truck platooning.",
      "authors": [
        "Ting Bai",
        "Karl Henrik Johansson",
        "Jonas M{\\aa}rtensson",
        "and Andreas A. Malikopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:03:47+00:00",
          "link": "https://arxiv.org/abs/2507.16923v1",
          "size": "3129kb",
          "version": "v1"
        }
      ],
      "title": "Stable and Fair Benefit Allocation in Mixed-Energy Truck Platooning: A Coalitional Game Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16923",
        "HTML": "https://arxiv.org/html/2507.16923v1",
        "PDF": "https://arxiv.org/pdf/2507.16923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses benefit allocation in mixed-energy truck platooning using a coalitional game approach, which does not pertain to LLM training data processing or relevant data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16924",
      "abstract": "Faced with increasing penetration of distributed energy resources and fast development of distribution grid energy management, topology identification of distribution grid becomes an important and fundamental task. As the underlying grid topology is usually unknown or incomplete to the utilities, it is becoming a fundamental task to efficiently identify the distribution grid network topology using limited measurements. A fast and accurate topology identification can help achieving the tasks of load monitoring, operation and control of power distribution system as well as outage detection. In this paper, we propose a novel and ultra-fast topology identification method. By adapting the subset sum method with a hierarchical structure, the overall grid topology can be inferred from fewer samples of smart meter power measurements. Such techniques can be applied in real time under the scenarios with fast topology change, and the proposed hierarchical algorithm is also robust against measurement noises.",
      "authors": [
        "Yueyao Xu",
        "Yize Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:06:59+00:00",
          "link": "https://arxiv.org/abs/2507.16924v1",
          "size": "126kb",
          "version": "v1"
        }
      ],
      "title": "Fast Distribution Grid Topology Estimation via Subset Sum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16924",
        "HTML": "https://arxiv.org/html/2507.16924v1",
        "PDF": "https://arxiv.org/pdf/2507.16924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is focused on distribution grid topology estimation, which is unrelated to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16933",
      "abstract": "Large language models can be quantized to reduce inference time latency, model size, and energy consumption, thereby delivering a better user experience at lower cost. A challenge exists to deliver quantized models with minimal loss of accuracy in reasonable time, and in particular to do so without requiring mechanisms incompatible with specialized inference accelerators. Here, we demonstrate a simple, end-to-end quantization-aware training approach that, with an increase in total model training budget of less than 0.1%, outperforms the leading published quantization methods by large margins on several modern benchmarks, with both base and instruct model variants. The approach easily generalizes across different model architectures, can be applied to activations, cache, and weights, and requires the introduction of no additional operations to the model other than the quantization itself.",
      "authors": [
        "Steven K. Esser",
        "Jeffrey L. McKinstry",
        "Deepika Bablani",
        "Rathinakumar Appuswamy",
        "Dharmendra S. Modha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:17:53+00:00",
          "link": "https://arxiv.org/abs/2507.16933v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "SiLQ: Simple Large Language Model Quantization-Aware Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16933",
        "HTML": "https://arxiv.org/html/2507.16933v1",
        "PDF": "https://arxiv.org/pdf/2507.16933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantization-aware training techniques to optimize LLM performance, primarily addressing model efficiency rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16937",
      "abstract": "Spiking Neural Networks (SNNs) draw inspiration from biological neurons to create realistic models for brain-like computation, demonstrating effectiveness in processing temporal information with energy efficiency and biological realism. Most existing SNNs assume a single time constant for neuronal membrane voltage dynamics, modeled by first-order ordinary differential equations (ODEs) with Markovian characteristics. Consequently, the voltage state at any time depends solely on its immediate past value, potentially limiting network expressiveness. Real neurons, however, exhibit complex dynamics influenced by long-term correlations and fractal dendritic structures, suggesting non-Markovian behavior. Motivated by this, we propose the Fractional SPIKE Differential Equation neural network (fspikeDE), which captures long-term dependencies in membrane voltage and spike trains through fractional-order dynamics. These fractional dynamics enable more expressive temporal patterns beyond the capability of integer-order models. For efficient training of fspikeDE, we introduce a gradient descent algorithm that optimizes parameters by solving an augmented fractional-order ODE (FDE) backward in time using adjoint sensitivity methods. Extensive experiments on diverse image and graph datasets demonstrate that fspikeDE consistently outperforms traditional SNNs, achieving superior accuracy, comparable energy efficiency, reduced training memory usage, and enhanced robustness against noise. Our approach provides a novel open-sourced computational toolbox for fractional-order SNNs, widely applicable to various real-world tasks.",
      "authors": [
        "Chengjie Ge",
        "Yufeng Peng",
        "Xueyang Fu",
        "Qiyu Kang",
        "Xuhao Li",
        "Qixin Zhang",
        "Junhao Ren",
        "Zheng-Jun Zha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:20:56+00:00",
          "link": "https://arxiv.org/abs/2507.16937v1",
          "size": "304kb",
          "version": "v1"
        }
      ],
      "title": "Fractional Spike Differential Equations Neural Network with Efficient Adjoint Parameters Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16937",
        "HTML": "https://arxiv.org/html/2507.16937v1",
        "PDF": "https://arxiv.org/pdf/2507.16937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel neural network architecture for spiking neural networks and does not address any aspects related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16938",
      "abstract": "We present a stationary iteration based upon a block splitting for a class of indefinite least squares problem. Convergence of the proposed method is investigated and optimal value of the involving parameter is used. The induced preconditioner is applied to accelerate the convergence of the GMRES method for solving the problem. We also analysed the eigenpair distribution of the preconditioned matrix. Some numerical are presented to show the effectiveness of the preconditioner. Numerical comparison with other well-known methods are also presented.",
      "authors": [
        "Davod Khojasteh Salkuyeh"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:22:51+00:00",
          "link": "https://arxiv.org/abs/2507.16938v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "A parameterized block-splitting preconditioner for indefinite least squares problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16938",
        "HTML": "https://arxiv.org/html/2507.16938v1",
        "PDF": "https://arxiv.org/pdf/2507.16938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper revolves around numerical methods and preconditioners for least squares problems, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16940",
      "abstract": "Recent advancements in Large Language Models (LLMs) have catalyzed a paradigm shift from static prediction systems to agentic AI agents capable of reasoning, interacting with tools, and adapting to complex tasks. While LLM-based agentic systems have shown promise across many domains, their application to medical imaging remains in its infancy. In this work, we introduce AURA, the first visual linguistic explainability agent designed specifically for comprehensive analysis, explanation, and evaluation of medical images. By enabling dynamic interactions, contextual explanations, and hypothesis testing, AURA represents a significant advancement toward more transparent, adaptable, and clinically aligned AI systems. We highlight the promise of agentic AI in transforming medical image analysis from static predictions to interactive decision support. Leveraging Qwen-32B, an LLM-based architecture, AURA integrates a modular toolbox comprising: (i) a segmentation suite with phase grounding, pathology segmentation, and anatomy segmentation to localize clinically meaningful regions; (ii) a counterfactual image-generation module that supports reasoning through image-level explanations; and (iii) a set of evaluation tools including pixel-wise difference-map analysis, classification, and advanced state-of-the-art components to assess diagnostic relevance and visual interpretability.",
      "authors": [
        "Nima Fathi",
        "Amar Kumar",
        "Tal Arbel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:24:18+00:00",
          "link": "https://arxiv.org/abs/2507.16940v1",
          "size": "17263kb",
          "version": "v1"
        }
      ],
      "title": "AURA: A Multi-Modal Medical Agent for Understanding, Reasoning & Annotation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16940",
        "HTML": "https://arxiv.org/html/2507.16940v1",
        "PDF": "https://arxiv.org/pdf/2507.16940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses AURA, a multi-modal agent for medical image analysis. It does not cover any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16941",
      "abstract": "This paper presents a reinforcement learning (RL) environment for developing an autonomous underwater robotic coral sampling agent, a crucial coral reef conservation and research task. Using software-in-the-loop (SIL) and hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI) controller is developed using a digital twin (DT) in simulation and subsequently verified in physical experiments. An underwater motion capture (MOCAP) system provides real-time 3D position and orientation feedback during verification testing for precise synchronization between the digital and physical domains. A key novelty of this approach is the combined use of a general-purpose game engine for simulation, deep RL, and real-time underwater motion capture for an effective zero-shot sim-to-real strategy.",
      "authors": [
        "Daniel Correa",
        "Tero Kaarlela",
        "Jose Fuentes",
        "Paulo Padrao",
        "Alain Duran",
        "Leonardo Bobadilla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:24:23+00:00",
          "link": "https://arxiv.org/abs/2507.16941v1",
          "size": "1085kb",
          "version": "v1"
        }
      ],
      "title": "Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16941",
        "HTML": "https://arxiv.org/html/2507.16941v1",
        "PDF": "https://arxiv.org/pdf/2507.16941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on multi-agent reinforcement learning for robotic coral sample collection, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16946",
      "abstract": "Anomaly detection (AD) identifies the defect regions of a given image. Recent works have studied AD, focusing on learning AD without abnormal images, with long-tailed distributed training data, and using a unified model for all classes. In addition, online AD learning has also been explored. In this work, we expand in both directions to a realistic setting by considering the novel task of long-tailed online AD (LTOAD). We first identified that the offline state-of-the-art LTAD methods cannot be directly applied to the online setting. Specifically, LTAD is class-aware, requiring class labels that are not available in the online setting. To address this challenge, we propose a class-agnostic framework for LTAD and then adapt it to our online learning setting. Our method outperforms the SOTA baselines in most offline LTAD settings, including both the industrial manufacturing and the medical domain. In particular, we observe +4.63% image-AUROC on MVTec even compared to methods that have access to class labels and the number of classes. In the most challenging long-tailed online setting, we achieve +0.53% image-AUROC compared to baselines. Our LTOAD benchmark is released here: https://doi.org/10.5281/zenodo.16283852 .",
      "authors": [
        "Chiao-An Yang",
        "Kuan-Chuan Peng",
        "Raymond A. Yeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:35:50+00:00",
          "link": "https://arxiv.org/abs/2507.16946v1",
          "size": "4603kb",
          "version": "v1"
        }
      ],
      "title": "Toward Long-Tailed Online Anomaly Detection through Class-Agnostic Concepts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16946",
        "HTML": "https://arxiv.org/html/2507.16946v1",
        "PDF": "https://arxiv.org/pdf/2507.16946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on anomaly detection in images, specifically in a new setting called long-tailed online anomaly detection (LTOAD). It does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16947",
      "abstract": "We evaluate the impact of large language model-based clinical decision support in live care. In partnership with Penda Health, a network of primary care clinics in Nairobi, Kenya, we studied AI Consult, a tool that serves as a safety net for clinicians by identifying potential documentation and clinical decision-making errors. AI Consult integrates into clinician workflows, activating only when needed and preserving clinician autonomy. We conducted a quality improvement study, comparing outcomes for 39,849 patient visits performed by clinicians with or without access to AI Consult across 15 clinics. Visits were rated by independent physicians to identify clinical errors. Clinicians with access to AI Consult made relatively fewer errors: 16% fewer diagnostic errors and 13% fewer treatment errors. In absolute terms, the introduction of AI Consult would avert diagnostic errors in 22,000 visits and treatment errors in 29,000 visits annually at Penda alone. In a survey of clinicians with AI Consult, all clinicians said that AI Consult improved the quality of care they delivered, with 75% saying the effect was \"substantial\". These results required a clinical workflow-aligned AI Consult implementation and active deployment to encourage clinician uptake. We hope this study demonstrates the potential for LLM-based clinical decision support tools to reduce errors in real-world settings and provides a practical framework for advancing responsible adoption.",
      "authors": [
        "Robert Korom",
        "Sarah Kiptinness",
        "Najib Adan",
        "Kassim Said",
        "Catherine Ithuli",
        "Oliver Rotich",
        "Boniface Kimani",
        "Irene King'ori",
        "Stellah Kamau",
        "Elizabeth Atemba",
        "Muna Aden",
        "Preston Bowman",
        "Michael Sharman",
        "Rebecca Soskin Hicks",
        "Rebecca Distler",
        "Johannes Heidecke",
        "Rahul K. Arora",
        "Karan Singhal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:37:33+00:00",
          "link": "https://arxiv.org/abs/2507.16947v1",
          "size": "9795kb",
          "version": "v1"
        }
      ],
      "title": "AI-based Clinical Decision Support for Primary Care: A Real-World Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16947",
        "HTML": "https://arxiv.org/html/2507.16947v1",
        "PDF": "https://arxiv.org/pdf/2507.16947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates the impact of LLM-based decision support tools in clinical settings. The focus is on decision-making and error reduction in healthcare, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16951",
      "abstract": "Conversational Information Retrieval (CIR) systems, while offering intuitive access to information, face a significant challenge: reliably handling unanswerable questions to prevent the generation of misleading or hallucinated content. Traditional approaches often rely on external classifiers, which can introduce inconsistencies with the core generative Large Language Models (LLMs). This paper introduces Self-Aware LLM for Unanswerability (SALU), a novel approach that deeply integrates unanswerability detection directly within the LLM's generative process. SALU is trained using a multi-task learning framework for both standard Question Answering (QA) and explicit abstention generation for unanswerable queries. Crucially, it incorporates a confidence-score-guided reinforcement learning with human feedback (RLHF) phase, which explicitly penalizes hallucinated responses and rewards appropriate abstentions, fostering intrinsic self-awareness of knowledge boundaries. Through extensive experiments on our custom-built C-IR_Answerability dataset, SALU consistently outperforms strong baselines, including hybrid LLM-classifier systems, in overall accuracy for correctly answering or abstaining from questions. Human evaluation further confirms SALU's superior reliability, achieving high scores in factuality, appropriate abstention, and, most importantly, a dramatic reduction in hallucination, demonstrating its ability to robustly \"know when to say 'I don't know'.\"",
      "authors": [
        "Shuyuan Lin",
        "Lei Duan",
        "Philip Hughes",
        "Yuxuan Sheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:44:18+00:00",
          "link": "https://arxiv.org/abs/2507.16951v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "Harnessing RLHF for Robust Unanswerability Recognition and Trustworthy Response Generation in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16951",
        "HTML": "https://arxiv.org/html/2507.16951v1",
        "PDF": "https://arxiv.org/pdf/2507.16951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses LLMs and introduces a novel approach using reinforcement learning and human feedback, it mainly focuses on response generation for unanswerability recognition rather than training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16952",
      "abstract": "This study investigates the effectiveness of several machine learning algorithms for static malware detection using the EMBER dataset, which contains feature representations of Portable Executable (PE) files. We evaluate eight classification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees, HistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three preprocessing settings: original feature space, Principal Component Analysis (PCA), and Linear Discriminant Analysis (LDA). The models are assessed on accuracy, precision, recall, F1 score, and AUC to examine both predictive performance and robustness. Ensemble methods, especially LightGBM and XGBoost, show the best overall performance across all configurations, with minimal sensitivity to PCA and consistent generalization. LDA improves KNN performance but significantly reduces accuracy for boosting models. TabNet, while promising in theory, underperformed under feature reduction, likely due to architectural sensitivity to input structure. The analysis is supported by detailed exploratory data analysis (EDA), including mutual information ranking, PCA or t-SNE visualizations, and outlier detection using Isolation Forest and Local Outlier Factor (LOF), which confirm the discriminatory capacity of key features in the EMBER dataset. The results suggest that boosting models remain the most reliable choice for high-dimensional static malware detection, and that dimensionality reduction should be applied selectively based on model type. This work provides a benchmark for comparing classification models and preprocessing strategies in malware detection tasks and contributes insights that can guide future system development and real-world deployment.",
      "authors": [
        "Md Min-Ha-Zul Abedin and Tazqia Mehrub"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:45:10+00:00",
          "link": "https://arxiv.org/abs/2507.16952v1",
          "size": "942kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16952",
        "PDF": "https://arxiv.org/pdf/2507.16952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates machine learning models for malware detection using the EMBER dataset. It involves model comparisons for classification tasks, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16963",
      "abstract": "The growing adoption of inverter-based resources (IBRs) has introduced unprecedented dynamics in power systems, resulting in oscillations across a broad spectrum of frequencies. Communication delay between the plant-level control and the inverter-level control in IBR plants has been recognized as one of the causes of such oscillations and a factor that impacts the system's stability. The control signals from the plant-level controller also experience sampling, with the sampled values held constant by the hold elements for the duration of the sampling period. This also has a bearing on the response of IBR plants. In this paper, we analyze the impacts of communication delay and sampling of control signals between plant-level control and inverter-level control of grid-following IBR plants on the small-signal stability of power systems. The underlying fundamentals of communication delay and sampling are revisited to explain the observed responses. Our findings emphasize the unique effects of communication delay and sampling period on the stability of IBR-rich power systems and suggest strategies to mitigate their detrimental impacts. The work also highlights the need for more accurate approaches for small-signal stability analysis of such systems.",
      "authors": [
        "Saugat Ghimire",
        "Vaithianathan \"Mani\" Venkatasubramanian and Gilles Torresan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:06:41+00:00",
          "link": "https://arxiv.org/abs/2507.16963v1",
          "size": "2375kb",
          "version": "v1"
        }
      ],
      "title": "Impact of Communication Delay and Sampling on Small-Signal Stability of IBR-rich Power Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16963",
        "HTML": "https://arxiv.org/html/2507.16963v1",
        "PDF": "https://arxiv.org/pdf/2507.16963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The subject of the paper is the impact of communication delay and sampling on power system stability, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16964",
      "abstract": "Solving partial differential equations (PDEs) on complex domains can present significant computational challenges. The Diffuse Domain Method (DDM) is an alternative that reformulates the partial differential equations on a larger, simpler domain. The original geometry is embedded into the problem by representing it with a phase-field function. This paper introduces ddfem, an extensible Python package to provide a framework for transforming PDEs into a Diffuse Domain formulation. We aim to make the application of a variety of different Diffuse Domain approaches more accessible and straightforward to use. The ddfem package includes features to intuitively define complex domains by combining signed distance functions and provides a number of DDM transformers for general second evolution equations. In addition, we present a new approach for combining multiple boundary conditions of different types on distinct boundary segments. This is achieved by applying a normalised weighting, derived from multiple phase fields, to combine the additional boundary terms in the Diffuse Domain formulations. The domain definition and Diffuse Domain transformation provided by our package are designed to be compatible with a wide range of existing finite element solvers without requiring code alterations. Both the original (non-linear) PDEs provided by the user and the resulting transformed PDEs on the extended domain are defined using the Unified Form Language UFL which is a domain specific language used by a number of software packages. Our experiments were carried out using the Dune-Fem framework.",
      "authors": [
        "Luke Benfield",
        "Andreas Dedner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:08:18+00:00",
          "link": "https://arxiv.org/abs/2507.16964v1",
          "size": "7907kb",
          "version": "v1"
        }
      ],
      "title": "DDFEM: A Python Package for Diffuse Domain Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16964",
        "HTML": "https://arxiv.org/html/2507.16964v1",
        "PDF": "https://arxiv.org/pdf/2507.16964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a Python package for solving PDEs using the Diffuse Domain Method, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16969",
      "abstract": "Recent studies have demonstrated the vulnerability of sequential recommender systems to Model Extraction Attacks (MEAs). MEAs collect responses from recommender systems to replicate their functionality, enabling unauthorized deployments and posing critical privacy and security risks. Black-box attacks in prior MEAs are ineffective at exposing recommender system vulnerabilities due to random sampling in data selection, which leads to misaligned synthetic and real-world distributions. To overcome this limitation, we propose LLM4MEA, a novel model extraction method that leverages Large Language Models (LLMs) as human-like rankers to generate data. It generates data through interactions between the LLM ranker and target recommender system. In each interaction, the LLM ranker analyzes historical interactions to understand user behavior, and selects items from recommendations with consistent preferences to extend the interaction history, which serves as training data for MEA. Extensive experiments demonstrate that LLM4MEA significantly outperforms existing approaches in data quality and attack performance, reducing the divergence between synthetic and real-world data by up to 64.98% and improving MEA performance by 44.82% on average. From a defensive perspective, we propose a simple yet effective defense strategy and identify key hyperparameters of recommender systems that can mitigate the risk of MEAs.",
      "authors": [
        "Shilong Zhao",
        "Fei Sun",
        "Kaike Zhang",
        "Shaoling Jing",
        "Du Su",
        "Zhichao Shi",
        "Zhiyi Yin",
        "Huawei Shen and Xueqi Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:20:23+00:00",
          "link": "https://arxiv.org/abs/2507.16969v1",
          "size": "721kb",
          "version": "v1"
        }
      ],
      "title": "LLM4MEA: Data-free Model Extraction Attacks on Sequential Recommenders via Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16969",
        "HTML": "https://arxiv.org/html/2507.16969v1",
        "PDF": "https://arxiv.org/pdf/2507.16969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a model extraction attack method using LLMs but focuses more on attack methodology rather than contributing directly to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16971",
      "abstract": "Accessing knowledge via multilingual natural-language interfaces is one of the emerging challenges in the field of information retrieval and related ones. Structured knowledge stored in knowledge graphs can be queried via a specific query language (e.g., SPARQL). Therefore, one needs to transform natural-language input into a query to fulfill an information need. Prior approaches mostly focused on combining components (e.g., rule-based or neural-based) that solve downstream tasks and come up with an answer at the end. We introduce mKGQAgent, a human-inspired framework that breaks down the task of converting natural language questions into SPARQL queries into modular, interpretable subtasks. By leveraging a coordinated LLM agent workflow for planning, entity linking, and query refinement - guided by an experience pool for in-context learning - mKGQAgent efficiently handles multilingual KGQA. Evaluated on the DBpedia- and Corporate-based KGQA benchmarks within the Text2SPARQL challenge 2025, our approach took first place among the other participants. This work opens new avenues for developing human-like reasoning systems in multilingual semantic parsing.",
      "authors": [
        "Aleksandr Perevalov",
        "Andreas Both"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:23:03+00:00",
          "link": "https://arxiv.org/abs/2507.16971v1",
          "size": "152kb",
          "version": "v1"
        }
      ],
      "title": "Text-to-SPARQL Goes Beyond English: Multilingual Question Answering Over Knowledge Graphs through Human-Inspired Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16971",
        "HTML": "https://arxiv.org/html/2507.16971v1",
        "PDF": "https://arxiv.org/pdf/2507.16971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on converting multilingual natural language questions into SPARQL queries for knowledge graph querying, not on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16974",
      "abstract": "Enabling farmers to access accurate agriculture-related information in their native languages in a timely manner is crucial for the success of the agriculture field. Although large language models (LLMs) can be used to implement Question Answering (QA) systems, simply using publicly available general-purpose LLMs in agriculture typically offer generic advisories, lacking precision in local and multilingual contexts due to insufficient domain-specific training and scarcity of high-quality, region-specific datasets. Our study addresses these limitations by generating multilingual synthetic agricultural datasets (English, Hindi, Punjabi) from agriculture-specific documents and fine-tuning language-specific LLMs. Our evaluation on curated multilingual datasets demonstrates significant improvements in factual accuracy, relevance, and agricultural consensus for the fine-tuned models compared to their baseline counterparts. These results highlight the efficacy of synthetic data-driven, language-specific fine-tuning as an effective strategy to improve the performance of LLMs in agriculture, especially in multilingual and low-resource settings. By enabling more accurate and localized agricultural advisory services, this study provides a meaningful step toward bridging the knowledge gap in AI-driven agricultural solutions for diverse linguistic communities.",
      "authors": [
        "Rishemjit Kaur",
        "Arshdeep Singh Bhankhar",
        "Surangika Ranathunga",
        "Jashanpreet Singh Salh",
        "Sudhir Rajput",
        "Vidhi",
        "Kashish Mahendra",
        "Bhavika Berwal",
        "Ritesh Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:25:10+00:00",
          "link": "https://arxiv.org/abs/2507.16974v1",
          "size": "47kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Synthetic Data for Question Answering with Multilingual LLMs in the Agricultural Domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16974",
        "HTML": "https://arxiv.org/html/2507.16974v1",
        "PDF": "https://arxiv.org/pdf/2507.16974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper contributes to training data processing by generating multilingual synthetic datasets for fine-tuning LLMs in the agricultural domain, improving their relevance and factual accuracy."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16982",
      "abstract": "This paper proposes a method to generalize the equations estimating the inductance of square-shape planar windings to rectangle shape. This is done by utilizing the optimal p-norm of the Generalized Mean Value or Power Mean (PM). Three well-established equations with verified accuracy are examined, namely Wheeler, Rosa, and the Monomial, which by definition consider only regular polygons. One critical parameter of the original equations is the outer-side length of the winding, which for the rectangle case, can be substituted by the PM of the two outer-side lengths, without the need for any further modifications. A methodology to select the optimal p-norm for the PM is presented in terms of achieving the best accuracy for this estimation. The selection of the optimal p is based on results from datasets containing more than 2600 simulations of different rectangle-shaped windings. Finally, the estimation accuracy is verified by laboratory measurements for a selection of planar inductors.",
      "authors": [
        "Theofilos Papadopoulos and Antonios Antonopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:41:04+00:00",
          "link": "https://arxiv.org/abs/2507.16982v1",
          "size": "10303kb",
          "version": "v1"
        }
      ],
      "title": "Extension of Simple and Accurate Inductance Estimation for Rectangular Planar Windings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16982",
        "HTML": "https://arxiv.org/html/2507.16982v1",
        "PDF": "https://arxiv.org/pdf/2507.16982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with the estimation of inductance for rectangular planar windings and does not relate to any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16983",
      "abstract": "Rehabilitation technology is a natural setting to study the shared learning and decision-making of human and machine agents. In this work, we explore the use of Hierarchical Reinforcement Learning (HRL) to develop adaptive control strategies for lower-limb exoskeletons, aiming to enhance mobility and autonomy for individuals with motor impairments. Inspired by prominent models of biological sensorimotor processing, our investigated HRL approach breaks down the complex task of exoskeleton control adaptation into a higher-level framework for terrain strategy adaptation and a lower-level framework for providing predictive information; this latter element is implemented via the continual learning of general value functions (GVFs). GVFs generated temporal abstractions of future signal values from multiple wearable lower-limb sensors, including electromyography, pressure insoles, and goniometers. We investigated two methods for incorporating actual and predicted sensor signals into a policy network with the intent to improve the decision-making capacity of the control system of a lower-limb exoskeleton during ambulation across varied terrains. As a key result, we found that the addition of predictions made from GVFs increased overall network accuracy. Terrain-specific performance increases were seen while walking on even ground, uneven ground, up and down ramps, and turns, terrains that are often misclassified without predictive information. This suggests that predictive information can aid decision-making during uncertainty, e.g., on terrains that have a high chance of being misclassified. This work, therefore, contributes new insights into the nuances of HRL and the future development of exoskeletons to facilitate safe transitioning and traversing across different walking environments.",
      "authors": [
        "Sonny T. Jones",
        "Grange M. Simpson",
        "Patrick M. Pilarski",
        "Ashley N. Dalrymple"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:47:04+00:00",
          "link": "https://arxiv.org/abs/2507.16983v1",
          "size": "1257kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Reinforcement Learning Framework for Adaptive Walking Control Using General Value Functions of Lower-Limb Sensor Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16983",
        "HTML": "https://arxiv.org/html/2507.16983v1",
        "PDF": "https://arxiv.org/pdf/2507.16983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work deals with hierarchical reinforcement learning for adaptive walking control in exoskeletons, focusing on sensor signal processing, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16988",
      "abstract": "Accurate characterization of modern on-chip antennas remains challenging, as current probe-station techniques offer limited angular coverage, rely on bespoke hardware, and require frequent manual alignment. This research introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a portable, state-of-the-art, and autonomous system based on collaborative robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar modules without dedicated anechoic facilities. The system is designed to address the challenges of testing radar modules mounted in diverse real-world configurations, including vehicles, UAVs, AR/VR headsets, and biomedical devices, where traditional measurement setups are impractical. A 7-degree-of-freedom Franka cobot holds the receiver probe and performs collision-free manipulation across a hemispherical spatial domain, guided by real-time motion planning and calibration accuracy with RMS error below 0.9 mm. The system achieves an angular resolution upto 2.5 degree and integrates seamlessly with RF instrumentation for near- and far-field power measurements. Experimental scans of a 60 GHz radar module show a mean absolute error of less than 2 dB compared to full-wave electromagnetic simulations ground truth. Benchmarking against baseline method demonstrates 36.5% lower mean absolute error, highlighting RAPTAR accuracy and repeatability.",
      "authors": [
        "Maaz Qureshi",
        "Mohammad Omid Bagheri",
        "Abdelrahman Elbadrawy",
        "William Melek",
        "and George Shaker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:52:05+00:00",
          "link": "https://arxiv.org/abs/2507.16988v1",
          "size": "7883kb",
          "version": "v1"
        }
      ],
      "title": "RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16988",
        "HTML": "https://arxiv.org/html/2507.16988v1",
        "PDF": "https://arxiv.org/pdf/2507.16988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on RAPTAR, a system for 3D measurement of radar modules, which is unrelated to LLM training data processing concepts like dataset creation or data quality enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16989",
      "abstract": "Large Language Models (LLMs) can exhibit latent biases towards specific nationalities even when explicit demographic markers are not present. In this work, we introduce a novel name-based benchmarking approach derived from the Bias Benchmark for QA (BBQ) dataset to investigate the impact of substituting explicit nationality labels with culturally indicative names, a scenario more reflective of real-world LLM applications. Our novel approach examines how this substitution affects both bias magnitude and accuracy across a spectrum of LLMs from industry leaders such as OpenAI, Google, and Anthropic. Our experiments show that small models are less accurate and exhibit more bias compared to their larger counterparts. For instance, on our name-based dataset and in the ambiguous context (where the correct choice is not revealed), Claude Haiku exhibited the worst stereotypical bias scores of 9%, compared to only 3.5% for its larger counterpart, Claude Sonnet, where the latter also outperformed it by 117.7% in accuracy. Additionally, we find that small models retain a larger portion of existing errors in these ambiguous contexts. For example, after substituting names for explicit nationality references, GPT-4o retains 68% of the error rate versus 76% for GPT-4o-mini, with similar findings for other model providers, in the ambiguous context. Our research highlights the stubborn resilience of biases in LLMs, underscoring their profound implications for the development and deployment of AI systems in diverse, global contexts.",
      "authors": [
        "Giulio Pelosio",
        "Devesh Batra",
        "No\\'emie Bovey",
        "Robert Hankache",
        "Cristovao Iglesias",
        "Greig Cowan",
        "Raad Khraishi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:54:49+00:00",
          "link": "https://arxiv.org/abs/2507.16989v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Obscured but Not Erased: Evaluating Nationality Bias in LLMs via Name-Based Bias Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16989",
        "PDF": "https://arxiv.org/pdf/2507.16989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper uses a dataset to evaluate nationality bias in LLMs, the primary focus is on bias detection rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16991",
      "abstract": "PyG (PyTorch Geometric) has evolved significantly since its initial release, establishing itself as a leading framework for Graph Neural Networks. In this paper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensive update that introduces substantial improvements in scalability and real-world application capabilities. We detail the framework's enhanced architecture, including support for heterogeneous and temporal graphs, scalable feature/graph stores, and various optimizations, enabling researchers and practitioners to tackle large-scale graph learning problems efficiently. Over the recent years, PyG has been supporting graph learning in a large variety of application areas, which we will summarize, while providing a deep dive into the important areas of relational deep learning and large language modeling.",
      "authors": [
        "Matthias Fey",
        "Jinu Sunil",
        "Akihiro Nitta",
        "Rishi Puri",
        "Manan Shah",
        "Bla\\v{z} Stojanovi\\v{c}",
        "Ramona Bendias",
        "Alexandria Barghi",
        "Vid Kocijan",
        "Zecheng Zhang",
        "Xinwei He",
        "Jan Eric Lenssen",
        "Jure Leskovec"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:55:09+00:00",
          "link": "https://arxiv.org/abs/2507.16991v1",
          "size": "4575kb",
          "version": "v1"
        }
      ],
      "title": "PyG 2.0: Scalable Learning on Real World Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16991",
        "HTML": "https://arxiv.org/html/2507.16991v1",
        "PDF": "https://arxiv.org/pdf/2507.16991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses updates in PyTorch Geometric for graph neural networks with applications in large language modeling, but it lacks specific contributions to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16996",
      "abstract": "With billions of users and an immense volume of daily uploads, YouTube has become an attractive target for cybercriminals aiming to leverage its vast audience. The platform's openness and trustworthiness provide an ideal environment for deceptive campaigns that can operate under the radar of conventional security tools. This paper explores how cybercriminals exploit YouTube to disseminate malware, focusing on campaigns that promote free software or game cheats. It discusses deceptive video demonstrations and the techniques behind malware delivery. Additionally, the paper presents a new evasion technique that abuses YouTube's multilingual metadata capabilities to circumvent automated detection systems. Findings indicate that this method is increasingly being used in recent malicious videos to avoid detection and removal.",
      "authors": [
        "Iman Vakilinia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:08:49+00:00",
          "link": "https://arxiv.org/abs/2507.16996v1",
          "size": "5663kb",
          "version": "v1"
        }
      ],
      "title": "From Cracks to Crooks: YouTube as a Vector for Malware Distribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16996",
        "HTML": "https://arxiv.org/html/2507.16996v1",
        "PDF": "https://arxiv.org/pdf/2507.16996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses cybersecurity issues related to YouTube as a malware distribution vector, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17000",
      "abstract": "Existing saliency-guided training approaches improve model generalization by incorporating a loss term that compares the model's class activation map (CAM) for a sample's true-class ({\\it i.e.}, correct-label class) against a human reference saliency map. However, prior work has ignored the false-class CAM(s), that is the model's saliency obtained for incorrect-label class. We hypothesize that in binary tasks the true and false CAMs should diverge on the important classification features identified by humans (and reflected in human saliency maps). We use this hypothesis to motivate three new saliency-guided training methods incorporating both true- and false-class model's CAM into the training strategy and a novel post-hoc tool for identifying important features. We evaluate all introduced methods on several diverse binary close-set and open-set classification tasks, including synthetic face detection, biometric presentation attack detection, and classification of anomalies in chest X-ray scans, and find that the proposed methods improve generalization capabilities of deep learning models over traditional (true-class CAM only) saliency-guided training approaches. We offer source codes and model weights\\footnote{GitHub repository link removed to preserve anonymity} to support reproducible research.",
      "authors": [
        "Jacob Piland",
        "Chris Sweet",
        "Adam Czajka"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:17:08+00:00",
          "link": "https://arxiv.org/abs/2507.17000v1",
          "size": "1254kb",
          "version": "v1"
        }
      ],
      "title": "Divisive Decisions: Improving Salience-Based Training for Generalization in Binary Classification Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17000",
        "HTML": "https://arxiv.org/html/2507.17000v1",
        "PDF": "https://arxiv.org/pdf/2507.17000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving saliency-based training methods for generalization in binary classification tasks, without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17001",
      "abstract": "Most existing methods for adapting models to out-of-distribution (OOD) domains rely on invariant representation learning to eliminate the influence of biased features. However, should bias always be eliminated -- and if not, when should it be retained, and how can it be leveraged? To address these questions, we first present a theoretical analysis that explores the conditions under which biased features can be identified and effectively utilized. Building on this theoretical foundation, we introduce a novel framework that strategically leverages bias to complement invariant representations during inference. The framework comprises two key components that leverage bias in both direct and indirect ways: (1) using invariance as guidance to extract predictive ingredients from bias, and (2) exploiting identified bias to estimate the environmental condition and then use it to explore appropriate bias-aware predictors to alleviate environment gaps. We validate our approach through experiments on both synthetic datasets and standard domain generalization benchmarks. Results consistently demonstrate that our method outperforms existing approaches, underscoring its robustness and adaptability.",
      "authors": [
        "Yan Li",
        "Guangyi Chen",
        "Yunlong Deng",
        "Zijian Li",
        "Zeyu Tang",
        "Anpeng Wu",
        "Kun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:17:48+00:00",
          "link": "https://arxiv.org/abs/2507.17001v1",
          "size": "477kb",
          "version": "v1"
        }
      ],
      "title": "Should Bias Always be Eliminated? A Principled Framework to Use Data Bias for OOD Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17001",
        "HTML": "https://arxiv.org/html/2507.17001v1",
        "PDF": "https://arxiv.org/pdf/2507.17001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores using data bias for out-of-distribution generation and domain adaptation, which does not relate to the processes involved in LLM training data preparation or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17007",
      "abstract": "This paper presents a vulnerability assessment activity that we carried out on PosteID, the implementation of the Italian Public Digital Identity System (SPID) by Poste Italiane. The activity led to the discovery of a critical privilege escalation vulnerability, which was eventually patched. The overall analysis and disclosure process represents a valuable case study for the community of ethical hackers. In this work, we present both the technical steps and the details of the disclosure process.",
      "authors": [
        "Gabriele Costa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:38:51+00:00",
          "link": "https://arxiv.org/abs/2507.17007v1",
          "size": "415kb",
          "version": "v1"
        }
      ],
      "title": "The Postman: A Journey of Ethical Hacking in PosteID/SPID Borderland",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17007",
        "HTML": "https://arxiv.org/html/2507.17007v1",
        "PDF": "https://arxiv.org/pdf/2507.17007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses ethical hacking and vulnerability assessments for digital identity systems, which is not pertinent to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17008",
      "abstract": "Most sign language handshape datasets are severely limited and unbalanced, posing significant challenges to effective model training. In this paper, we explore the effectiveness of augmenting the training data of a handshape classifier by generating synthetic data. We use an EfficientNet classifier trained on the RWTH German sign language handshape dataset, which is small and heavily unbalanced, applying different strategies to combine generated and real images. We compare two Generative Adversarial Networks (GAN) architectures for data generation: ReACGAN, which uses label information to condition the data generation process through an auxiliary classifier, and SPADE, which utilizes spatially-adaptive normalization to condition the generation on pose information. ReACGAN allows for the generation of realistic images that align with specific handshape labels, while SPADE focuses on generating images with accurate spatial handshape configurations. Our proposed techniques improve the current state-of-the-art accuracy on the RWTH dataset by 5%, addressing the limitations of small and unbalanced datasets. Additionally, our method demonstrates the capability to generalize across different sign language datasets by leveraging pose-based generation trained on the extensive HaGRID dataset. We achieve comparable performance to single-source trained classifiers without the need for retraining the generator.",
      "authors": [
        "Gaston Gustavo Rios",
        "Pedro Dal Bianco",
        "Franco Ronchetti",
        "Facundo Quiroga",
        "Oscar Stanchi",
        "Santiago Ponte Ah\\'on",
        "Waldo Hasperu\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:41:29+00:00",
          "link": "https://arxiv.org/abs/2507.17008v1",
          "size": "2494kb",
          "version": "v1"
        }
      ],
      "title": "Bringing Balance to Hand Shape Classification: Mitigating Data Imbalance Through Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17008",
        "HTML": "https://arxiv.org/html/2507.17008v1",
        "PDF": "https://arxiv.org/pdf/2507.17008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mitigating data imbalance for handshape classification using generative models, which is specific to sign language datasets and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17009",
      "abstract": "Suicide remains a pressing global health crisis, with over 720,000 deaths annually and millions more affected by suicide ideation (SI) and suicide attempts (SA). Early identification of suicidality-related factors (SrFs), including SI, SA, exposure to suicide (ES), and non-suicidal self-injury (NSSI), is critical for timely intervention. While prior studies have applied AI to detect SrFs in clinical notes, most treat suicidality as a binary classification task, overlooking the complexity of cooccurring risk factors. This study explores the use of generative large language models (LLMs), specifically GPT-3.5 and GPT-4.5, for multi-label classification (MLC) of SrFs from psychiatric electronic health records (EHRs). We present a novel end to end generative MLC pipeline and introduce advanced evaluation methods, including label set level metrics and a multilabel confusion matrix for error analysis. Finetuned GPT-3.5 achieved top performance with 0.94 partial match accuracy and 0.91 F1 score, while GPT-4.5 with guided prompting showed superior performance across label sets, including rare or minority label sets, indicating a more balanced and robust performance. Our findings reveal systematic error patterns, such as the conflation of SI and SA, and highlight the models tendency toward cautious over labeling. This work not only demonstrates the feasibility of using generative AI for complex clinical classification tasks but also provides a blueprint for structuring unstructured EHR data to support large scale clinical research and evidence based medicine.",
      "authors": [
        "Ming Huang",
        "Zehan Li",
        "Yan Hu",
        "Wanjing Wang",
        "Andrew Wen",
        "Scott Lane",
        "Salih Selek",
        "Lokesh Shahani",
        "Rodrigo Machado-Vieira",
        "Jair Soares",
        "Hua Xu",
        "Hongfang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:44:44+00:00",
          "link": "https://arxiv.org/abs/2507.17009v1",
          "size": "929kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Label Classification with Generative AI Models in Healthcare: A Case Study of Suicidality and Risk Factors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17009",
        "PDF": "https://arxiv.org/pdf/2507.17009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using generative LLMs for multi-label classification in healthcare, focusing on model performance rather than specific contributions to LLM training data processing such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17010",
      "abstract": "In the era of synthetic media, deepfake manipulations pose a significant threat to information integrity. To address this challenge, we propose TrustDefender, a two-stage framework comprising (i) a lightweight convolutional neural network (CNN) that detects deepfake imagery in real-time extended reality (XR) streams, and (ii) an integrated succinct zero-knowledge proof (ZKP) protocol that validates detection results without disclosing raw user data. Our design addresses both the computational constraints of XR platforms while adhering to the stringent privacy requirements in sensitive settings. Experimental evaluations on multiple benchmark deepfake datasets demonstrate that TrustDefender achieves 95.3% detection accuracy, coupled with efficient proof generation underpinned by rigorous cryptography, ensuring seamless integration with high-performance artificial intelligence (AI) systems. By fusing advanced computer vision models with provable security mechanisms, our work establishes a foundation for reliable AI in immersive and privacy-sensitive applications.",
      "authors": [
        "H M Mohaimanul Islam",
        "Huynh Q. N. Vo",
        "Aditya Rane"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:47:46+00:00",
          "link": "https://arxiv.org/abs/2507.17010v1",
          "size": "684kb",
          "version": "v1"
        }
      ],
      "title": "Towards Trustworthy AI: Secure Deepfake Detection using CNNs and Zero-Knowledge Proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17010",
        "HTML": "https://arxiv.org/html/2507.17010v1",
        "PDF": "https://arxiv.org/pdf/2507.17010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for deepfake detection and privacy validation, which does not contribute to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17011",
      "abstract": "This paper introduces an innovative Energy-Autonomous Wireless Sensing Node (EAWSN) that addresses power constraints by harnessing ambient light for energy. It combines this energy harvesting capability with the Time Domain to Digital Conversion (TDDC) technique for efficient and accurate measurements of resistive sensors. Bluetooth Low Energy (BLE) communication ensures data can be transmitted wirelessly to a base station, providing a promising solution for various applications, particularly in environments with limited access to wired power sources, enabling long-term, maintenance-free operation by eliminating batteries. Experimental results showed a linear relationship between the test resistance R_m and the measured number of clock pulses N_m within the sensor's operating range.",
      "authors": [
        "Mario Costanza",
        "Antonino Pagano",
        "Samuel Margueron",
        "Ilenia Tinnirello",
        "Roberto La Rosa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:48:04+00:00",
          "link": "https://arxiv.org/abs/2507.17011v1",
          "size": "1200kb",
          "version": "v1"
        }
      ],
      "title": "An Energy-Autonomous and Battery-Free Resistive Sensor using a Time-Domain to Digital Conversion with Bluetooth Low Energy connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17011",
        "PDF": "https://arxiv.org/pdf/2507.17011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an energy-autonomous sensing node for resistive sensors, which is unrelated to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17012",
      "abstract": "Interest in sustainability information has surged in recent years. However, the data required for a life cycle assessment (LCA) that maps the materials and processes from product manufacturing to disposal into environmental impacts (EI) are often unavailable. Here we reimagine conventional LCA by introducing multimodal AI agents that emulate interactions between LCA experts and stakeholders like product managers and engineers to calculate the cradle-to-gate (production) carbon emissions of electronic devices. The AI agents iteratively generate a detailed life-cycle inventory leveraging a custom data abstraction and software tools that extract information from online text and images from repair communities and government certifications. This approach reduces weeks or months of expert time to under one minute and closes data availability gaps while yielding carbon footprint estimates within 19% of expert LCAs with zero proprietary data. Additionally, we develop a method to directly estimate EI by comparing an input to a cluster of products with similar descriptions and known carbon footprints. This runs in 3 ms on a laptop with a MAPE of 12.28% on electronic products. Further, we develop a data-driven method to generate emission factors. We use the properties of an unknown material to represent it as a weighted sum of emission factors for similar materials. Compared to human experts picking the closest LCA database entry, this improves MAPE by 120.26%. We analyze the data and compute scaling of this approach and discuss its implications for future LCA workflows.",
      "authors": [
        "Zhihan Zhang",
        "Alexander Metzger",
        "Yuxuan Mei",
        "Felix H\\\"ahnlein",
        "Zachary Englhardt",
        "Tingyu Cheng",
        "Gregory D. Abowd",
        "Shwetak Patel",
        "Adriana Schulz",
        "Vikram Iyer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:49:25+00:00",
          "link": "https://arxiv.org/abs/2507.17012v1",
          "size": "9136kb",
          "version": "v1"
        }
      ],
      "title": "Towards Autonomous Sustainability Assessment via Multimodal AI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17012",
        "HTML": "https://arxiv.org/html/2507.17012v1",
        "PDF": "https://arxiv.org/pdf/2507.17012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on sustainability assessment using multimodal AI agents, with no contributions to the processes or techniques related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17013",
      "abstract": "The Laplace approximation provides a scalable and efficient means of quantifying weight-space uncertainty in deep neural networks, enabling the application of Bayesian tools such as predictive uncertainty and model selection via Occam's razor. In this work, we introduce laplax, a new open-source Python package for performing Laplace approximations with jax. Designed with a modular and purely functional architecture and minimal external dependencies, laplax offers a flexible and researcher-friendly framework for rapid prototyping and experimentation. Its goal is to facilitate research on Bayesian neural networks, uncertainty quantification for deep learning, and the development of improved Laplace approximation techniques.",
      "authors": [
        "Tobias Weber",
        "B\\'alint Mucs\\'anyi",
        "Lenard Rommel",
        "Thomas Christie",
        "Lars Kas\\\"uschke",
        "Marvin Pf\\\"ortner",
        "Philipp Hennig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:49:30+00:00",
          "link": "https://arxiv.org/abs/2507.17013v1",
          "size": "324kb",
          "version": "v1"
        }
      ],
      "title": "laplax -- Laplace Approximations with JAX",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17013",
        "HTML": "https://arxiv.org/html/2507.17013v1",
        "PDF": "https://arxiv.org/pdf/2507.17013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Laplace approximations using JAX, a technique related to Bayesian neural networks and uncertainty quantification. It does not address any data processing aspects related to LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17015",
      "abstract": "Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the \"better\" response. This approach can provide feedback for domains where other hard-coded metrics are difficult to obtain (e.g., chat response quality), thereby helping model evaluation or training. However, for some domains high-quality pairwise comparisons can be tricky to obtain - from AI and humans. For example, for responses with many factual statements, annotators may disproportionately weigh writing quality rather than underlying facts. In this work, we explore augmenting standard AI annotator systems with additional tools to improve performance on three challenging response domains: long-form factual, math and code tasks. We propose a tool-using agentic system to provide higher quality feedback on these domains. Our system uses web-search and code execution to ground itself based on external validation, independent of the LLM's internal knowledge and biases. We provide extensive experimental results evaluating our method across the three targeted response domains as well as general annotation tasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as three new datasets for domains with saturated pre-existing datasets. Our results indicate that external tools can indeed improve performance in many, but not all, cases. More generally, our experiments highlight the sensitivity of performance to simple parameters (e.g., prompt) and the need for improved (non-saturated) annotator benchmarks. We share our code at https://github.com/apple/ml-agent-evaluator.",
      "authors": [
        "Arduin Findeis",
        "Floris Weers",
        "Guoli Yin",
        "Ke Ye",
        "Ruoming Pang",
        "Tom Gunter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.17015v1",
          "size": "3350kb",
          "version": "v1"
        }
      ],
      "title": "Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17015",
        "HTML": "https://arxiv.org/html/2507.17015v1",
        "PDF": "https://arxiv.org/pdf/2507.17015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a system using external validation tools to improve annotation quality\u2014potentially affecting the quality of training data\u2014its focus is primarily on model evaluation and annotation, rather than directly on the data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17016",
      "abstract": "In recent years, the application of Large Language Models (LLMs) to time series forecasting (TSF) has garnered significant attention among researchers. This study presents a new frame of LLMs named CGF-LLM using GPT-2 combined with fuzzy time series (FTS) and causal graph to predict multivariate time series, marking the first such architecture in the literature. The key objective is to convert numerical time series into interpretable forms through the parallel application of fuzzification and causal analysis, enabling both semantic understanding and structural insight as input for the pretrained GPT-2 model. The resulting textual representation offers a more interpretable view of the complex dynamics underlying the original time series. The reported results confirm the effectiveness of our proposed LLM-based time series forecasting model, as demonstrated across four different multivariate time series datasets. This initiative paves promising future directions in the domain of TSF using LLMs based on FTS.",
      "authors": [
        "Omid Orang",
        "Patricia O. Lucas",
        "Gabriel I. F. Paiva",
        "Petronio C. L. Silva",
        "Felipe Augusto Rocha da Silva",
        "Adriano Alonso Veloso",
        "Frederico Gadelha Guimaraes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:03:13+00:00",
          "link": "https://arxiv.org/abs/2507.17016v1",
          "size": "714kb",
          "version": "v1"
        }
      ],
      "title": "Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17016",
        "HTML": "https://arxiv.org/html/2507.17016v1",
        "PDF": "https://arxiv.org/pdf/2507.17016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for time series forecasting using LLMs, focusing on architecture and applications, without engaging in training data processing tasks relevant to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17017",
      "abstract": "We introduce an algorithm that releases a pure differentially private sparse histogram over $n$ participants drawn from a domain of size $d \\gg n$. Our method attains the optimal $\\ell_\\infty$-estimation error and runs in strictly $O(n \\ln \\ln d)$ time in the word-RAM model, thereby improving upon the previous best known deterministic-time bound of $\\tilde{O}(n^2)$ and resolving the open problem of breaking this quadratic barrier (Balcer and Vadhan, 2019). Central to our algorithm is a novel private item blanket technique with target-length padding, which transforms the approximate differentially private stability-based histogram algorithm into a pure differentially private one.",
      "authors": [
        "Florian Kerschbaum",
        "Steven Lee",
        "Hao Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:17:59+00:00",
          "link": "https://arxiv.org/abs/2507.17017v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Pure Differentially Private Sparse Histograms in Near-Linear Deterministic Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17017",
        "HTML": "https://arxiv.org/html/2507.17017v1",
        "PDF": "https://arxiv.org/pdf/2507.17017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an algorithm for releasing differentially private sparse histograms. It does not relate to LLM training data processing activities or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17019",
      "abstract": "Uncertainty quantification and inverse problems governed by partial differential equations (PDEs) are central to a wide range of scientific and engineering applications. In this second part of a two part series, we extend Bilevel Local Operator Learning (BiLO) for PDE-constrained optimization problems developed in Part 1 to the Bayesian inference framework. At the lower level, we train a network to approximate the local solution operator by minimizing the local operator loss with respect to the weights of the neural network. At the upper level, we sample the PDE parameters from the posterior distribution. We achieve efficient sampling through gradient-based Markov Chain Monte Carlo (MCMC) methods and low-rank adaptation (LoRA). Compared with existing methods based on Bayesian neural networks, our approach bypasses the challenge of sampling in the high-dimensional space of neural network weights and does not require specifying a prior distribution on the neural network solution. Instead, uncertainty propagates naturally from the data through the PDE constraints. By enforcing strong PDE constraints, the proposed method improves the accuracy of both parameter inference and uncertainty quantification. We analyze the dynamic error of the gradient in the MCMC sampler and the static error in the posterior distribution due to inexact minimization of the lower level problem and demonstrate a direct link between the tolerance for solving the lower level problem and the accuracy of the resulting uncertainty quantification. Through numerical experiments across a variety of PDE models, we demonstrate that our method delivers accurate inference and quantification of uncertainties while maintaining high computational efficiency.",
      "authors": [
        "Ray Zirui Zhang",
        "Christopher E. Miles",
        "Xiaohui Xie",
        "John S. Lowengrub"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:20:20+00:00",
          "link": "https://arxiv.org/abs/2507.17019v1",
          "size": "2073kb",
          "version": "v1"
        }
      ],
      "title": "BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part II: Efficient Uncertainty Quantification with Low-Rank Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17019",
        "HTML": "https://arxiv.org/html/2507.17019v1",
        "PDF": "https://arxiv.org/pdf/2507.17019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around uncertainty quantification in PDE inverse problems using neural networks, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17020",
      "abstract": "Artificial Intelligence (AI) has received unprecedented attention in recent years, raising ethical concerns about the development and use of AI technology. In the present article, we advocate that these concerns stem from a blurred understanding of AI, how it can be used, and how it has been interpreted in society. We explore the concept of AI based on three descriptive facets and consider ethical issues related to each facet. Finally, we propose a framework for the ethical assessment of the use of AI.",
      "authors": [
        "Flavio Soares Correa da Silva"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:21:37+00:00",
          "link": "https://arxiv.org/abs/2507.17020v1",
          "size": "26kb",
          "version": "v1"
        }
      ],
      "title": "Ethics through the Facets of Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17020",
        "HTML": "https://arxiv.org/html/2507.17020v1",
        "PDF": "https://arxiv.org/pdf/2507.17020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the ethical assessment framework for AI but does not address LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17024",
      "abstract": "A growing body of work on visualization affordances highlights how specific design choices shape reader takeaways from information visualizations. However, mapping the relationship between design choices and reader conclusions often requires labor-intensive crowdsourced studies, generating large corpora of free-response text for analysis. To address this challenge, we explored alternative scalable research methodologies to assess chart affordances. We test four elicitation methods from human-subject studies: free response, visualization ranking, conclusion ranking, and salience rating, and compare their effectiveness in eliciting reader interpretations of line charts, dot plots, and heatmaps. Overall, we find that while no method fully replicates affordances observed in free-response conclusions, combinations of ranking and rating methods can serve as an effective proxy at a broad scale. The two ranking methodologies were influenced by participant bias towards certain chart types and the comparison of suggested conclusions. Rating conclusion salience could not capture the specific variations between chart types observed in the other methods. To supplement this work, we present a case study with GPT-4o, exploring the use of large language models (LLMs) to elicit human-like chart interpretations. This aligns with recent academic interest in leveraging LLMs as proxies for human participants to improve data collection and analysis efficiency. GPT-4o performed best as a human proxy for the salience rating methodology but suffered from severe constraints in other areas. Overall, the discrepancies in affordances we found between various elicitation methodologies, including GPT-4o, highlight the importance of intentionally selecting and combining methods and evaluating trade-offs.",
      "authors": [
        "Chase Stokes",
        "Kylie Lin",
        "and Cindy Xiong Bearfield"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:27:16+00:00",
          "link": "https://arxiv.org/abs/2507.17024v1",
          "size": "13412kb",
          "version": "v1"
        }
      ],
      "title": "Write, Rank, or Rate: Comparing Methods for Studying Visualization Affordances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17024",
        "HTML": "https://arxiv.org/html/2507.17024v1",
        "PDF": "https://arxiv.org/pdf/2507.17024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the use of LLMs like GPT-4o for evaluating chart interpretations, which indirectly relates to data collection and analysis. However, the primary focus is on visualization methods, not explicitly on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17025",
      "abstract": "Efficient text embedding is crucial for large-scale natural language processing (NLP) applications, where storage and computational efficiency are key concerns. In this paper, we explore how using binary representations (barcodes) instead of real-valued features can be used for NLP embeddings derived from machine learning models such as BERT. Thresholding is a common method for converting continuous embeddings into binary representations, often using a fixed threshold across all features. We propose a Coordinate Search-based optimization framework that instead identifies the optimal threshold for each feature, demonstrating that feature-specific thresholds lead to improved performance in binary encoding. This ensures that the binary representations are both accurate and efficient, enhancing performance across various features. Our optimal barcode representations have shown promising results in various NLP applications, demonstrating their potential to transform text representation. We conducted extensive experiments and statistical tests on different NLP tasks and datasets to evaluate our approach and compare it to other thresholding methods. Binary embeddings generated using using optimal thresholds found by our method outperform traditional binarization methods in accuracy. This technique for generating binary representations is versatile and can be applied to any features, not just limited to NLP embeddings, making it useful for a wide range of domains in machine learning applications.",
      "authors": [
        "Soumen Sinha",
        "Shahryar Rahnamayan",
        "and Azam Asilian Bidgoli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:29:34+00:00",
          "link": "https://arxiv.org/abs/2507.17025v1",
          "size": "1511kb",
          "version": "v1"
        }
      ],
      "title": "Evolutionary Feature-wise Thresholding for Binary Representation of NLP Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17025",
        "HTML": "https://arxiv.org/html/2507.17025v1",
        "PDF": "https://arxiv.org/pdf/2507.17025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper deals with NLP embeddings and their binary representation, which relates to data processing. However, it does not focus on training data processing for LLMs specifically, thus making only a peripheral contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17029",
      "abstract": "We propose StreamME, a method focuses on fast 3D avatar reconstruction. The StreamME synchronously records and reconstructs a head avatar from live video streams without any pre-cached data, enabling seamless integration of the reconstructed appearance into downstream applications. This exceptionally fast training strategy, which we refer to as on-the-fly training, is central to our approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating the reliance on MLPs in deformable 3DGS and relying solely on geometry, which significantly improves the adaptation speed to facial expression. To further ensure high efficiency in on-the-fly training, we introduced a simplification strategy based on primary points, which distributes the point clouds more sparsely across the facial surface, optimizing points number while maintaining rendering quality. Leveraging the on-the-fly training capabilities, our method protects the facial privacy and reduces communication bandwidth in VR system or online conference. Additionally, it can be directly applied to downstream application such as animation, toonify, and relighting. Please refer to our project page for more details: https://songluchuan.github.io/StreamME/.",
      "authors": [
        "Luchuan Song",
        "Yang Zhou",
        "Zhan Xu",
        "Yi Zhou",
        "Deepali Aneja",
        "Chenliang Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:33:30+00:00",
          "link": "https://arxiv.org/abs/2507.17029v1",
          "size": "25331kb",
          "version": "v1"
        }
      ],
      "title": "StreamME: Simplify 3D Gaussian Avatar within Live Stream",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17029",
        "HTML": "https://arxiv.org/html/2507.17029v1",
        "PDF": "https://arxiv.org/pdf/2507.17029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for fast 3D avatar reconstruction and does not address LLM training data processing or relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17033",
      "abstract": "As power consumption from AI training and inference continues to increase, AI accelerators are being integrated directly into the CPU. Intel's Advanced Matrix Extensions (AMX) is one such example, debuting on the 4th generation Intel Xeon Scalable CPU. We discover a timing side and covert channel, GATEBLEED, caused by the aggressive power gating utilized to keep the CPU within operating limits. We show that the GATEBLEED side channel is a threat to AI privacy as many ML models such as transformers and CNNs make critical computationally-heavy decisions based on private values like confidence thresholds and routing logits. Timing delays from selective powering down of AMX components mean that each matrix multiplication is a potential leakage point when executed on the AMX accelerator. Our research identifies over a dozen potential gadgets across popular ML libraries (HuggingFace, PyTorch, TensorFlow, etc.), revealing that they can leak sensitive and private information. GATEBLEED poses a risk for local and remote timing inference, even under previous protective measures. GATEBLEED can be used as a high performance, stealthy remote covert channel and a generic magnifier for timing transmission channels, capable of bypassing traditional cache defenses to leak arbitrary memory addresses and evading state of the art microarchitectural attack detectors under realistic network conditions and system configurations in which previous attacks fail. We implement an end-to-end microarchitectural inference attack on a transformer model optimized with Intel AMX, achieving a membership inference accuracy of 81% and a precision of 0.89. In a CNN-based or transformer-based mixture-of-experts model optimized with Intel AMX, we leak expert choice with 100% accuracy.",
      "authors": [
        "Joshua Kalyanapu",
        "Farshad Dizani",
        "Darsh Asher",
        "Azam Ghanbari",
        "Rosario Cammarota",
        "Aydin Aysu",
        "Samira Mirbagher Ajorpaz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:41:43+00:00",
          "link": "https://arxiv.org/abs/2507.17033v1",
          "size": "769kb",
          "version": "v1"
        }
      ],
      "title": "GATEBLEED: Exploiting On-Core Accelerator Power Gating for High Performance & Stealthy Attacks on AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17033",
        "PDF": "https://arxiv.org/pdf/2507.17033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the GATEBLEED side channel as a security vulnerability in AI model computations. It focuses on timing inference and security threats, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17036",
      "abstract": "Motivated by applications such as sparse PCA, in this paper we present provably-accurate one-pass algorithms for the sparse approximation of the top eigenvectors of extremely massive matrices based on a single compact linear sketch. The resulting compressive-sensing-based approaches can approximate the leading eigenvectors of huge approximately low-rank matrices that are too large to store in memory based on a single pass over its entries while utilizing a total memory footprint on the order of the much smaller desired sparse eigenvector approximations. Finally, the compressive sensing recovery algorithm itself (which takes the gathered compressive matrix measurements as input, and then outputs sparse approximations of its top eigenvectors) can also be formulated to run in a time which principally depends on the size of the sought sparse approximations, making its runtime sublinear in the size of the large matrix whose eigenvectors one aims to approximate. Preliminary experiments on huge matrices having $\\sim 10^{16}$ entries illustrate the developed theory and demonstrate the practical potential of the proposed approach.",
      "authors": [
        "Edem Boahen",
        "Simone Brugiapaglia",
        "Hung-Hsu Chou",
        "Mark Iwen and Felix Krahmer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Data Structures and Algorithms (cs.DS)",
        "Numerical Analysis (cs.NA)",
        "Information Theory (math.IT)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:46:40+00:00",
          "link": "https://arxiv.org/abs/2507.17036v1",
          "size": "1435kb",
          "version": "v1"
        }
      ],
      "title": "Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge Low-Rank Matrices? Yes, $MAM^*$!",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17036",
        "HTML": "https://arxiv.org/html/2507.17036v1",
        "PDF": "https://arxiv.org/pdf/2507.17036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents algorithms for sparse approximation of top eigenvectors of large matrices, which pertains to compressive sensing and matrix operations, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17038",
      "abstract": "In recent years, the number of remote satellites orbiting the Earth has grown significantly, streaming vast amounts of high-resolution visual data to support diverse applications across civil, public, and military domains. Among these applications, the generation and updating of spatial maps of the built environment have become critical due to the extensive coverage and detailed imagery provided by satellites. However, reconstructing spatial maps from satellite imagery is a complex computer vision task, requiring the creation of high-level object representations, such as primitives, to accurately capture the built environment. While the past decade has witnessed remarkable advancements in object detection and representation using visual data, primitives-based object representation remains a persistent challenge in computer vision. Consequently, high-quality spatial maps often rely on labor-intensive and manual processes. This paper introduces a novel deep learning methodology leveraging Graph Convolutional Networks (GCNs) to address these challenges in building footprint reconstruction. The proposed approach enhances performance by incorporating geometric regularity into building boundaries, integrating multi-scale and multi-resolution features, and embedding Attraction Field Maps into the network. These innovations provide a scalable and precise solution for automated building footprint extraction from a single satellite image, paving the way for impactful applications in urban planning, disaster management, and large-scale spatial analysis. Our model, Decoupled-PolyGCN, outperforms existing methods by 6% in AP and 10% in AR, demonstrating its ability to deliver accurate and regularized building footprints across diverse and challenging scenarios.",
      "authors": [
        "Muhammad Kamran",
        "Mohammad Moein Sheikholeslami",
        "Andreas Wichmann",
        "Gunho Sohn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:53:03+00:00",
          "link": "https://arxiv.org/abs/2507.17038v1",
          "size": "5624kb",
          "version": "v1"
        }
      ],
      "title": "Transformer Based Building Boundary Reconstruction using Attraction Field Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17038",
        "HTML": "https://arxiv.org/html/2507.17038v1",
        "PDF": "https://arxiv.org/pdf/2507.17038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a method for building boundary reconstruction using satellite images with Transformer and GCNs, focusing on computer vision tasks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17047",
      "abstract": "Video data, especially long-form video, is extremely dense and high-dimensional. Text-based summaries of video content offer a way to represent query-relevant content in a much more compact manner than raw video. In addition, textual representations are easily ingested by state-of-the-art large language models (LLMs), which enable reasoning over video content to answer complex natural language queries. To solve this issue, we rely on the progressive construction of a text-based memory by a video captioner operating on shorter chunks of the video, where spatio-temporal modeling is computationally feasible. We explore ways to improve the quality of the activity log comprised solely of short video captions. Because the video captions tend to be focused on human actions, and questions may pertain to other information in the scene, we seek to enrich the memory with static scene descriptions using Vision Language Models (VLMs). Our video understanding system relies on the LaViLa video captioner in combination with a LLM to answer questions about videos. We first explored different ways of partitioning the video into meaningful segments such that the textual descriptions more accurately reflect the structure of the video content. Furthermore, we incorporated static scene descriptions into the captioning pipeline using LLaVA VLM, resulting in a more detailed and complete caption log and expanding the space of questions that are answerable from the textual memory. Finally, we have successfully fine-tuned the LaViLa video captioner to produce both action and scene captions, significantly improving the efficiency of the captioning pipeline compared to using separate captioning models for the two tasks. Our model, controllable hybrid captioner, can alternate between different types of captions according to special input tokens that signals scene changes detected in the video.",
      "authors": [
        "Kuleen Sasse",
        "Efsun Sarioglu Kayi",
        "Arun Reddy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:09:00+00:00",
          "link": "https://arxiv.org/abs/2507.17047v1",
          "size": "1109kb",
          "version": "v1"
        }
      ],
      "title": "Controllable Hybrid Captioner for Improved Long-form Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17047",
        "HTML": "https://arxiv.org/html/2507.17047v1",
        "PDF": "https://arxiv.org/pdf/2507.17047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning a model for video captioning, which enhances quality via incorporation of static scene descriptions. It relates to data processing but is primarily focused on improving video understanding rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17049",
      "abstract": "Visual Language Action (VLA) models are a multi-modal class of Artificial Intelligence (AI) systems that integrate visual perception, natural language understanding, and action planning to enable agents to interpret their environment, comprehend instructions, and perform embodied tasks autonomously. Recently, significant progress has been made to advance this field. These kinds of models are typically evaluated through task success rates, which fail to capture the quality of task execution and the mode's confidence in its decisions. In this paper, we propose eight uncertainty metrics and five quality metrics specifically designed for VLA models for robotic manipulation tasks. We assess their effectiveness through a large-scale empirical study involving 908 successful task executions from three state-of-the-art VLA models across four representative robotic manipulation tasks. Human domain experts manually labeled task quality, allowing us to analyze the correlation between our proposed metrics and expert judgments. The results reveal that several metrics show moderate to strong correlation with human assessments, highlighting their utility for evaluating task quality and model confidence. Furthermore, we found that some of the metrics can discriminate between high-, medium-, and low-quality executions from unsuccessful tasks, which can be interesting when test oracles are not available. Our findings challenge the adequacy of current evaluation practices that rely solely on binary success rates and pave the way for improved real-time monitoring and adaptive enhancement of VLA-enabled robotic systems.",
      "authors": [
        "Pablo Valle",
        "Chengjie Lu",
        "Shaukat Ali and Aitor Arrieta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:15:59+00:00",
          "link": "https://arxiv.org/abs/2507.17049v1",
          "size": "6737kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17049",
        "HTML": "https://arxiv.org/html/2507.17049v1",
        "PDF": "https://arxiv.org/pdf/2507.17049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on evaluating metrics for Visual Language Action models in robotic tasks, which does not involve any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17050",
      "abstract": "In this paper, we introduce VideoNarrator, a novel training-free pipeline designed to generate dense video captions that offer a structured snapshot of video content. These captions offer detailed narrations with precise timestamps, capturing the nuances present in each segment of the video. Despite advancements in multimodal large language models (MLLMs) for video comprehension, these models often struggle with temporally aligned narrations and tend to hallucinate, particularly in unfamiliar scenarios. VideoNarrator addresses these challenges by leveraging a flexible pipeline where off-the-shelf MLLMs and visual-language models (VLMs) can function as caption generators, context providers, or caption verifiers. Our experimental results demonstrate that the synergistic interaction of these components significantly enhances the quality and accuracy of video narrations, effectively reducing hallucinations and improving temporal alignment. This structured approach not only enhances video understanding but also facilitates downstream tasks such as video summarization and video question answering, and can be potentially extended for advertising and marketing applications.",
      "authors": [
        "Tz-Ying Wu",
        "Tahani Trigui",
        "Sharath Nittur Sridhar",
        "Anand Bodas",
        "Subarna Tripathi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:16:37+00:00",
          "link": "https://arxiv.org/abs/2507.17050v1",
          "size": "597kb",
          "version": "v1"
        }
      ],
      "title": "Toward Scalable Video Narration: A Training-free Approach Using Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17050",
        "HTML": "https://arxiv.org/html/2507.17050v1",
        "PDF": "https://arxiv.org/pdf/2507.17050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a pipeline for generating video captions using multimodal language models, improving video narration quality. However, the focus is on video comprehension and alignment, not specifically on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17051",
      "abstract": "In this article we propose new discretization-consistent expressions for the sub-filter stress (SFS) tensor in discrete LES, where the filter is induced by the discretization. We introduce a new two-grid filter that allows us to exactly compute the SFS tensor when DNS data is available. This new filter satisfies a \"filter-swap\" property, such that filtering and finite differencing can be interchanged and the resulting commutator expressions are of structural form (they can be written as the discrete divergence of an SFS tensor). For 1D conservation laws such as Burgers' equation, the resulting discretization-consistent SFS expression is markedly different from the commonly used (discretization-inconsistent) expression $\\overline{u u} - \\bar{u} \\bar{u}$. For the 3D incompressible Navier-Stokes equations, we propose three new two-grid filters, based on either volume- or surface-averaging, each inducing new discretization-consistent commutator expressions. We show that volume-averaging is required to obtain a commutator expression of structural form. However, the resulting SFS tensor is shown to be non-symmetric. Based on DNS results, we show that the non-symmetric part of the SFS tensor plays an important role in the discrete LES equation. When the non-symmetric part is included, our SFS expressions give zero a-posteriori error in LES, while existing SFS expressions give errors that increase over time. We propose to use a class of non-symmetric tensor-basis closure models to approximate the new exact SFS expressions.",
      "authors": [
        "Syver D{\\o}ving Agdestein and Roel Verstappen and Benjamin Sanderse"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:20:23+00:00",
          "link": "https://arxiv.org/abs/2507.17051v1",
          "size": "2746kb",
          "version": "v1"
        }
      ],
      "title": "Exact closure for discrete large-eddy simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17051",
        "HTML": "https://arxiv.org/html/2507.17051v1",
        "PDF": "https://arxiv.org/pdf/2507.17051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for improving large-eddy simulation discretization, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17053",
      "abstract": "This paper presents a matrix-free approach for implementing the shifted boundary method (SBM) in finite element analysis. The SBM is a versatile technique for solving partial differential equations on complex geometries by shifting boundary conditions to nearby surrogate boundaries. We focus on the efficient evaluation of shifted boundary operators using precomputed data and tensor-product structures. The proposed method avoids the explicit assembly of global matrices, achieving a computational complexity of $O(p^{2d-1})$ per face for the evaluation of shifted boundary contributions on elements of polynomial degree $p$ in $d$ dimensions. Numerical experiments validate the accuracy and efficiency of the approach, demonstrating its scalability and applicability to high-order finite element methods for both continuous and discontinuous Galerkin formulations. We compare the performance of the proposed method with a matrix-free CutFEM implementation.",
      "authors": [
        "Micha{\\l} Wichrowski"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:24:16+00:00",
          "link": "https://arxiv.org/abs/2507.17053v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "Matrix-Free Evaluation of High-Order Shifted Boundary Finite Element Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17053",
        "PDF": "https://arxiv.org/pdf/2507.17053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses computational techniques in finite element analysis, specifically for shifted boundaries, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17054",
      "abstract": "Multi-Agent Path Finding (MAPF) is the problem of finding a set of collision-free paths, one for each agent in a shared environment. Its objective is to minimize the sum of path costs (SOC), where the path cost of each agent is defined as the travel time from its start location to its target location. Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for bounded-suboptimal MAPF, with the SOC of the solution being at most a user-specified factor $w$ away from optimal. EECBS maintains sets of paths and a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of paths whose SOC is at most $w \\cdot LB$ and introduces constraints to resolve collisions. For each path in a set, EECBS maintains a lower bound on its optimal path that satisfies constraints. By finding an individually bounded-suboptimal path with cost at most a threshold of $w$ times its lower bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up EECBS, previous work uses flex distribution to increase the threshold. Though EECBS with flex distribution guarantees to find a bounded-suboptimal solution, increasing the thresholds may push the SOC beyond $w \\cdot LB$, forcing EECBS to switch among different sets of paths instead of resolving collisions on a particular set of paths, and thus reducing efficiency. To address this issue, we propose Conflict-Based Flex Distribution that distributes flex in proportion to the number of collisions. We also estimate the delays needed to satisfy constraints and propose Delay-Based Flex Distribution. On top of that, we propose Mixed-Strategy Flex Distribution, combining both in a hierarchical framework. We prove that EECBS with our new flex distribution mechanisms is complete and bounded-suboptimal. Our experiments show that our approaches outperform the original (greedy) flex distribution.",
      "authors": [
        "Shao-Hung Chan",
        "Thomy Phan",
        "Jiaoyang Li",
        "Sven Koenig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:25:29+00:00",
          "link": "https://arxiv.org/abs/2507.17054v1",
          "size": "955kb",
          "version": "v1"
        }
      ],
      "title": "New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17054",
        "HTML": "https://arxiv.org/html/2507.17054v1",
        "PDF": "https://arxiv.org/pdf/2507.17054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithms for Multi-Agent Path Finding, particularly focusing on mechanisms for improving efficiency through flex distribution. There is no mention of LLM training data processing or any related data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17055",
      "abstract": "Smart electric wheelchairs can improve user experience by supporting the driver with shared control. State-of-the-art work showed the potential of shared control in improving safety in navigation for non-holonomic robots. However, for holonomic systems, current approaches often lead to unintuitive behavior for the user and fail to utilize the full potential of omnidirectional driving. Therefore, we propose a reinforcement learning-based method, which takes a 2D user input and outputs a 3D motion while ensuring user comfort and reducing cognitive load on the driver. Our approach is trained in Isaac Gym and tested in simulation in Gazebo. We compare different RL agent architectures and reward functions based on metrics considering cognitive load and user comfort. We show that our method ensures collision-free navigation while smartly orienting the wheelchair and showing better or competitive smoothness compared to a previous non-learning-based method. We further perform a sim-to-real transfer and demonstrate, to the best of our knowledge, the first real-world implementation of RL-based shared control for an omnidirectional mobility platform.",
      "authors": [
        "Jannis B\\\"ahler",
        "Diego Paez-Granados",
        "Jorge Pe\\~na-Queralta"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:31:11+00:00",
          "link": "https://arxiv.org/abs/2507.17055v1",
          "size": "2195kb",
          "version": "v1"
        }
      ],
      "title": "Shared Control of Holonomic Wheelchairs through Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17055",
        "HTML": "https://arxiv.org/html/2507.17055v1",
        "PDF": "https://arxiv.org/pdf/2507.17055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on reinforcement learning-based control systems for smart electric wheelchairs, specifically through shared control mechanisms. It doesn't relate to LLM training data processing or any relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17056",
      "abstract": "Offline reinforcement learning (RL) holds great promise for deriving optimal policies from observational data, but challenges related to interpretability and evaluation limit its practical use in safety-critical domains. Interpretability is hindered by the black-box nature of unconstrained RL policies, while evaluation -- typically performed off-policy -- is sensitive to large deviations from the data-collecting behavior policy, especially when using methods based on importance sampling. To address these challenges, we propose a simple yet practical alternative: deriving treatment policies from the most frequently chosen actions in each patient state, as estimated by an interpretable model of the behavior policy. By using a tree-based model, which is specifically designed to exploit patterns in the data, we obtain a natural grouping of states with respect to treatment. The tree structure ensures interpretability by design, while varying the number of actions considered controls the degree of overlap with the behavior policy, enabling reliable off-policy evaluation. This pragmatic approach to policy development standardizes frequent treatment patterns, capturing the collective clinical judgment embedded in the data. Using real-world examples in rheumatoid arthritis and sepsis care, we demonstrate that policies derived under this framework can outperform current practice, offering interpretable alternatives to those obtained via offline RL.",
      "authors": [
        "Anton Matsson and Yaochen Rao and Heather J. Litman and Fredrik D. Johansson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:34:35+00:00",
          "link": "https://arxiv.org/abs/2507.17056v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "Pragmatic Policy Development via Interpretable Behavior Cloning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17056",
        "HTML": "https://arxiv.org/html/2507.17056v1",
        "PDF": "https://arxiv.org/pdf/2507.17056"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses interpretability and evaluation in offline reinforcement learning, offering an interpretable approach to policy development in medical applications. It doesn't discuss LLM training data processing or any pertinent data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17061",
      "abstract": "Large language model (LLM) agents have shown increasing promise for collaborative task completion. However, existing multi-agent frameworks often rely on static workflows, fixed roles, and limited inter-agent communication, reducing their effectiveness in open-ended, high-complexity domains. This paper proposes a coordination framework that enables adaptiveness through three core mechanisms: dynamic task routing, bidirectional feedback, and parallel agent evaluation. The framework allows agents to reallocate tasks based on confidence and workload, exchange structured critiques to iteratively improve outputs, and crucially compete on high-ambiguity subtasks with evaluator-driven selection of the most suitable result. We instantiate these principles in a modular architecture and demonstrate substantial improvements in factual coverage, coherence, and efficiency over static and partially adaptive baselines. Our findings highlight the benefits of incorporating both adaptiveness and structured competition in multi-agent LLM systems.",
      "authors": [
        "Chengxuan Xia",
        "Qianye Wu",
        "Sixuan Tian",
        "Yilun Hao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:42:51+00:00",
          "link": "https://arxiv.org/abs/2507.17061v1",
          "size": "1297kb",
          "version": "v1"
        }
      ],
      "title": "Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17061",
        "HTML": "https://arxiv.org/html/2507.17061v1",
        "PDF": "https://arxiv.org/pdf/2507.17061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for multi-agent LLM systems to enhance task completion through adaptiveness and coordination. However, the focus is on agent coordination rather than data processing mechanisms, only tangentially related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17062",
      "abstract": "We explore a novel way to numerically resolve the scaling behavior of finite-time singularities in solutions of nonlinear parabolic PDEs. The Runge--Kutta--Legendre (RKL) and Runge--Kutta--Gegenbauer (RKG) super-time-stepping methods were originally developed for nonlinear complex physics problems with diffusion. These are multi-stage single step second-order, forward-in-time methods with no implicit solves. The advantage is that the timestep size for stability scales with stage number $s$ as $\\mathcal{O}(s^2)$. Many interesting nonlinear PDEs have finite-time singularities, and the presence of diffusion often limits one to using implicit or semi-implicit timestep methods for stability constraints. Finite-time singularities are particularly challenging due to the large range of scales that one desires to resolve, often with adaptive spatial grids and adaptive timesteps. Here we show two examples of nonlinear PDEs for which the self-similar singularity structure has time and space scales that are resolvable using the RKL and RKG methods, without forcing even smaller timesteps. Compared to commonly-used implicit numerical methods, we achieve significantly smaller run time while maintaining comparable accuracy. We also prove numerical monotonicity for both the RKL and RKG methods under their linear stability conditions for the constant coefficient heat equation, in the case of infinite domain and periodic boundary condition, leading to a theoretical guarantee of the superiority of the RKL and RKG methods over traditional super-time-stepping methods, such as the Runge-Kutta-Chebyshev (RKC) and the orthogonal Runge-Kutta-Chebyshev (ROCK) methods.",
      "authors": [
        "Zheng Tan",
        "Tariq D. Aslam",
        "Andrea L. Bertozzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:46:50+00:00",
          "link": "https://arxiv.org/abs/2507.17062v1",
          "size": "2157kb",
          "version": "v1"
        }
      ],
      "title": "Explicit Monotone Stable Super-Time-Stepping Methods for Finite Time Singularities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17062",
        "HTML": "https://arxiv.org/html/2507.17062v1",
        "PDF": "https://arxiv.org/pdf/2507.17062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores numerical methods for solving parabolic PDEs with finite-time singularities, particularly through super-time-stepping methods. It doesn't pertain to LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17063",
      "abstract": "We study a version of the metric facility location problem (or, equivalently, variants of the committee selection problem) in which we must choose $k$ facilities in an arbitrary metric space to serve some set of clients $C$. We consider four different objectives, where each client $i\\in C$ attempts to minimize either the sum or the maximum of its distance to the chosen facilities, and where the overall objective either considers the sum or the maximum of the individual client costs. Rather than optimizing a single objective at a time, we study how compatible these objectives are with each other, and show the existence of solutions which are simultaneously close-to-optimum for any pair of the above objectives. Our results show that when choosing a set of facilities or a representative committee, it is often possible to form a solution which is good for several objectives at the same time, instead of sacrificing one desideratum to achieve another.",
      "authors": [
        "Yue Han",
        "Elliot Anshelevich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:47:35+00:00",
          "link": "https://arxiv.org/abs/2507.17063v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Compatibility of Max and Sum Objectives for Committee Selection and $k$-Facility Location",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17063",
        "HTML": "https://arxiv.org/html/2507.17063v1",
        "PDF": "https://arxiv.org/pdf/2507.17063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the metric facility location problem and compatibility of objectives in facility location, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17064",
      "abstract": "With the advent of modern technology, critical infrastructure, communications, and national security depend increasingly on space-based assets. These assets, along with associated assets like data relay systems and ground stations, are, therefore, in serious danger of cyberattacks. Strong security defenses are essential to ensure data integrity, maintain secure operations, and protect assets in space and on the ground against various threats. Previous research has found discrete vulnerabilities in space systems and suggested specific solutions to address them. Such research has yielded valuable insights, but lacks a thorough examination of space cyberattack vectors and a rigorous assessment of the efficacy of mitigation techniques. This study tackles this issue by taking a comprehensive approach to analyze the range of possible space cyber-attack vectors, which include ground, space, satellite, and satellite constellations. In order to address the particular threats, the study also assesses the efficacy of mitigation measures that are linked with space infrastructures and proposes a Risk Scoring Framework. Based on the analysis, this paper identifies potential research challenges for developing and testing cutting-edge technology solutions, encouraging robust cybersecurity measures needed in space.",
      "authors": [
        "Nafisa Anjum",
        "Tasnuva Farheen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:51:31+00:00",
          "link": "https://arxiv.org/abs/2507.17064v1",
          "size": "222kb",
          "version": "v1"
        }
      ],
      "title": "SoK: Securing the Final Frontier for Cybersecurity in Space-Based Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17064",
        "PDF": "https://arxiv.org/pdf/2507.17064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses cybersecurity in space-based infrastructure and does not discuss anything related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17066",
      "abstract": "Synthetic tabular data is essential for machine learning workflows, especially for expanding small or imbalanced datasets and enabling privacy-preserving data sharing. However, state-of-the-art generative models (GANs, VAEs, diffusion models) rely on large datasets with thousands of examples. In low-data settings, often the primary motivation for synthetic data, these models can overfit, leak sensitive records, and require frequent retraining. Recent work uses large pre-trained transformers to generate rows via in-context learning (ICL), which needs only a few seed examples and no parameter updates, avoiding retraining. But ICL repeats seed rows verbatim, introducing a new privacy risk that has only been studied in text. The severity of this risk in tabular synthesis-where a single row may identify a person-remains unclear. We address this gap with the first benchmark of three foundation models (GPT-4o-mini, LLaMA 3.3 70B, TabPFN v2) against four baselines on 35 real-world tables from health, finance, and policy. We evaluate statistical fidelity, downstream utility, and membership inference leakage. Results show foundation models consistently have the highest privacy risk. LLaMA 3.3 70B reaches up to 54 percentage points higher true-positive rate at 1% FPR than the safest baseline. GPT-4o-mini and TabPFN are also highly vulnerable. We plot the privacy-utility frontier and show that CTGAN and GPT-4o-mini offer better tradeoffs. A factorial study finds that three zero-cost prompt tweaks-small batch size, low temperature, and using summary statistics-can reduce worst-case AUC by 14 points and rare-class leakage by up to 39 points while maintaining over 90% fidelity. Our benchmark offers a practical guide for safer low-data synthesis with foundation models.",
      "authors": [
        "Jessup Byun",
        "Xiaofeng Lin",
        "Joshua Ward",
        "Guang Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:59:08+00:00",
          "link": "https://arxiv.org/abs/2507.17066v1",
          "size": "701kb",
          "version": "v1"
        }
      ],
      "title": "Risk In Context: Benchmarking Privacy Leakage of Foundation Models in Synthetic Tabular Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17066",
        "HTML": "https://arxiv.org/html/2507.17066v1",
        "PDF": "https://arxiv.org/pdf/2507.17066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper benchmarks privacy leakage in synthetic tabular data generation with foundation models. While it evaluates privacy risks and offers a guide for synthesis, its focus is more on model evaluations rather than direct contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17070",
      "abstract": "Recent advancements in Deep Reinforcement Learning (DRL) have demonstrated its applicability across various domains, including robotics, healthcare, energy optimization, and autonomous driving. However, a critical question remains: How robust are DRL models when exposed to adversarial attacks? While existing defense mechanisms such as adversarial training and distillation enhance the resilience of DRL models, there remains a significant research gap regarding the integration of multiple defenses in autonomous driving scenarios specifically. This paper addresses this gap by proposing a novel ensemble-based defense architecture to mitigate adversarial attacks in autonomous driving. Our evaluation demonstrates that the proposed architecture significantly enhances the robustness of DRL models. Compared to the baseline under FGSM attacks, our ensemble method improves the mean reward from 5.87 to 18.38 (over 213% increase) and reduces the mean collision rate from 0.50 to 0.09 (an 82% decrease) in the highway scenario and merge scenario, outperforming all standalone defense strategies.",
      "authors": [
        "Adithya Mohan",
        "Dominik R\\\"o{\\ss}le",
        "Daniel Cremers and Torsten Sch\\\"on"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:15:11+00:00",
          "link": "https://arxiv.org/abs/2507.17070v1",
          "size": "528kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Robustness in Deep Reinforcement Learning with an Ensemble Defense Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17070",
        "HTML": "https://arxiv.org/html/2507.17070v1",
        "PDF": "https://arxiv.org/pdf/2507.17070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research proposes an ensemble defense approach for enhancing robustness in deep reinforcement learning models against adversarial attacks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17071",
      "abstract": "Due to environmental changes and sensor aging, sensor drift challenges the performance of electronic nose systems in gas classification during real-world deployment. Previous studies using the UCI Gas Sensor Array Drift Dataset reported promising drift compensation results but lacked robust statistical experimental validation and may overcompensate for sensor drift, losing class-related variance.To address these limitations and improve sensor drift compensation with statistical rigor, we first designed two domain adaptation tasks based on the same electronic nose dataset: using the first batch to predict the remaining batches, simulating a controlled laboratory setting; and predicting the next batch using all prior batches, simulating continuous training data updates for online training. We then systematically tested three methods: our proposed novel Knowledge Distillation (KD) method, the benchmark method Domain Regularized Component Analysis (DRCA), and a hybrid method KD-DRCA, across 30 random test set partitions on the UCI dataset. We showed that KD consistently outperformed both DRCA and KD-DRCA, achieving up to an 18% improvement in accuracy and 15% in F1-score, demonstrating KD's superior effectiveness in drift compensation. This is the first application of KD for electronic nose drift mitigation, significantly outperforming the previous state-of-the-art DRCA method and enhancing the reliability of sensor drift compensation in real-world environments.",
      "authors": [
        "Juntao Lin",
        "Xianghao Zhan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:16:03+00:00",
          "link": "https://arxiv.org/abs/2507.17071v1",
          "size": "6947kb",
          "version": "v1"
        }
      ],
      "title": "Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17071",
        "HTML": "https://arxiv.org/html/2507.17071v1",
        "PDF": "https://arxiv.org/pdf/2507.17071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sensor drift compensation in gas recognition using electronic noses, employing knowledge distillation techniques. It does not contribute to LLM training data processing, as it does not involve data processing operations for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17074",
      "abstract": "The advent of quantum computing threatens the security of classical public-key cryptographic systems, prompting the transition to post-quantum cryptography (PQC). While PQC has been analyzed in theory, its performance in practical wireless communication environments remains underexplored. This paper presents a detailed implementation and performance evaluation of NIST-selected PQC algorithms in user equipment (UE) to UE communications over 5G networks. Using a full 5G emulation stack (Open5GS and UERANSIM) and PQC-enabled TLS 1.3 via BoringSSL and liboqs, we examine key encapsulation mechanisms and digital signature schemes across realistic network conditions. We evaluate performance based on handshake latency, CPU and memory usage, bandwidth, and retransmission rates, under varying cryptographic configurations and client loads. Our findings show that ML-KEM with ML-DSA offers the best efficiency for latency-sensitive applications, while SPHINCS+ and HQC combinations incur higher computational and transmission overheads, making them unsuitable for security-critical but time-sensitive 5G scenarios.",
      "authors": [
        "Sanzida Hoque",
        "Abdullah Aydeger",
        "Engin Zeydan",
        "and Madhusanka Liyanage"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:21:16+00:00",
          "link": "https://arxiv.org/abs/2507.17074v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of Post-Quantum Cryptography in User Equipment in 5G and Beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17074",
        "HTML": "https://arxiv.org/html/2507.17074v1",
        "PDF": "https://arxiv.org/pdf/2507.17074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the practical implementation of post-quantum cryptography algorithms in 5G networks. It does not involve training data processing related to LLMs, but rather focuses on cryptography and communication systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17075",
      "abstract": "Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex problems that were previously out of reach. To ensure LLMs do not assist with harmful requests, safety alignment fine-tuning is necessary in the post-training phase. However, safety alignment fine-tuning has recently been shown to significantly degrade reasoning abilities, a phenomenon known as the \"Safety Tax\". In this work, we show that using LoRA for SFT on refusal datasets effectively aligns the model for safety without harming its reasoning capabilities. This is because restricting the safety weight updates to a low-rank space minimizes the interference with the reasoning weights. Our extensive experiments across four benchmarks covering math, science, and coding show that this approach produces highly safe LLMs -- with safety levels comparable to full-model fine-tuning -- without compromising their reasoning abilities. Additionally, we observe that LoRA induces weight updates with smaller overlap with the initial weights compared to full-model fine-tuning. We also explore methods that further reduce such overlap -- via regularization or during weight merging -- and observe some improvement on certain tasks. We hope this result motivates designing approaches that yield more consistent improvements in the reasoning-safety trade-off.",
      "authors": [
        "Yihao Xue",
        "Baharan Mirzasoleiman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:25:16+00:00",
          "link": "https://arxiv.org/abs/2507.17075v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "LoRA is All You Need for Safety Alignment of Reasoning LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17075",
        "HTML": "https://arxiv.org/html/2507.17075v1",
        "PDF": "https://arxiv.org/pdf/2507.17075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses safety alignment fine-tuning of reasoning LLMs, it primarily focuses on maintaining reasoning abilities during alignment, using techniques like LoRA. It does not feature extensive treatment of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17079",
      "abstract": "Few-shot learning (FSL) enables object detection models to recognize novel classes given only a few annotated examples, thereby reducing expensive manual data labeling. This survey examines recent FSL advances for video and 3D object detection. For video, FSL is especially valuable since annotating objects across frames is more laborious than for static images. By propagating information across frames, techniques like tube proposals and temporal matching networks can detect new classes from a couple examples, efficiently leveraging spatiotemporal structure. FSL for 3D detection from LiDAR or depth data faces challenges like sparsity and lack of texture. Solutions integrate FSL with specialized point cloud networks and losses tailored for class imbalance. Few-shot 3D detection enables practical autonomous driving deployment by minimizing costly 3D annotation needs. Core issues in both domains include balancing generalization and overfitting, integrating prototype matching, and handling data modality properties. In summary, FSL shows promise for reducing annotation requirements and enabling real-world video, 3D, and other applications by efficiently leveraging information across feature, temporal, and data modalities. By comprehensively surveying recent advancements, this paper illuminates FSL's potential to minimize supervision needs and enable deployment across video, 3D, and other real-world applications.",
      "authors": [
        "Md Meftahul Ferdaus",
        "Kendall N. Niles",
        "Joe Tom",
        "Mahdi Abdelguerfi",
        "Elias Ioup"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:37:20+00:00",
          "link": "https://arxiv.org/abs/2507.17079v1",
          "size": "35115kb",
          "version": "v1"
        }
      ],
      "title": "Few-Shot Learning in Video and 3D Object Detection: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17079",
        "HTML": "https://arxiv.org/html/2507.17079v1",
        "PDF": "https://arxiv.org/pdf/2507.17079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on few-shot learning for video and 3D object detection, emphasizing minimizing supervision needs. It does not relate to data processing for LLMs, instead addressing object detection challenges."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17080",
      "abstract": "Multimodal learning plays a critical role in e-commerce recommendation platforms today, enabling accurate recommendations and product understanding. However, existing vision-language models, such as CLIP, face key challenges in e-commerce recommendation systems: 1) Weak object-level alignment, where global image embeddings fail to capture fine-grained product attributes, leading to suboptimal retrieval performance; 2) Ambiguous textual representations, where product descriptions often lack contextual clarity, affecting cross-modal matching; and 3) Domain mismatch, as generic vision-language models may not generalize well to e-commerce-specific data. To address these limitations, we propose a framework, VL-CLIP, that enhances CLIP embeddings by integrating Visual Grounding for fine-grained visual understanding and an LLM-based agent for generating enriched text embeddings. Visual Grounding refines image representations by localizing key products, while the LLM agent enhances textual features by disambiguating product descriptions. Our approach significantly improves retrieval accuracy, multimodal retrieval effectiveness, and recommendation quality across tens of millions of items on one of the largest e-commerce platforms in the U.S., increasing CTR by 18.6%, ATC by 15.5%, and GMV by 4.0%. Additional experimental results show that our framework outperforms vision-language models, including CLIP, FashionCLIP, and GCL, in both precision and semantic alignment, demonstrating the potential of combining object-aware visual grounding and LLM-enhanced text representation for robust multimodal recommendations.",
      "authors": [
        "Ramin Giahi",
        "Kehui Yao",
        "Sriram Kollipara",
        "Kai Zhao",
        "Vahid Mirjalili",
        "Jianpeng Xu",
        "Topojoy Biswas",
        "Evren Korpeoglu",
        "Kannan Achan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:45:43+00:00",
          "link": "https://arxiv.org/abs/2507.17080v1",
          "size": "20164kb",
          "version": "v1"
        }
      ],
      "title": "VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17080",
        "HTML": "https://arxiv.org/html/2507.17080v1",
        "PDF": "https://arxiv.org/pdf/2507.17080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework, VL-CLIP, for improving multimodal recommendations via visual grounding and LLM-augmented embeddings. While it involves LLMs, the focus is not on LLM training data processing but on enhancing recommendations through augmented embeddings."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17083",
      "abstract": "Multimodal 3D occupancy prediction has garnered significant attention for its potential in autonomous driving. However, most existing approaches are single-modality: camera-based methods lack depth information, while LiDAR-based methods struggle with occlusions. Current lightweight methods primarily rely on the Lift-Splat-Shoot (LSS) pipeline, which suffers from inaccurate depth estimation and fails to fully exploit the geometric and semantic information of 3D LiDAR points. Therefore, we propose a novel multimodal occupancy prediction network called SDG-OCC, which incorporates a joint semantic and depth-guided view transformation coupled with a fusion-to-occupancy-driven active distillation. The enhanced view transformation constructs accurate depth distributions by integrating pixel semantics and co-point depth through diffusion and bilinear discretization. The fusion-to-occupancy-driven active distillation extracts rich semantic information from multimodal data and selectively transfers knowledge to image features based on LiDAR-identified regions. Finally, for optimal performance, we introduce SDG-Fusion, which uses fusion alone, and SDG-KL, which integrates both fusion and distillation for faster inference. Our method achieves state-of-the-art (SOTA) performance with real-time processing on the Occ3D-nuScenes dataset and shows comparable performance on the more challenging SurroundOcc-nuScenes dataset, demonstrating its effectiveness and robustness. The code will be released at https://github.com/DzpLab/SDGOCC.",
      "authors": [
        "Zaipeng Duan",
        "Chenxu Dang",
        "Xuzhong Hu",
        "Pei An",
        "Junfeng Ding",
        "Jie Zhan",
        "Yunbiao Xu",
        "Jie Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:49:40+00:00",
          "link": "https://arxiv.org/abs/2507.17083v1",
          "size": "9643kb",
          "version": "v1"
        }
      ],
      "title": "SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17083",
        "HTML": "https://arxiv.org/html/2507.17083v1",
        "PDF": "https://arxiv.org/pdf/2507.17083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multimodal 3D occupancy prediction methodology for autonomous driving using semantic and depth information, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17085",
      "abstract": "Manipulating clusters of deformable objects presents a substantial challenge with widespread applicability, but requires contact-rich whole-arm interactions. A potential solution must address the limited capacity for realistic model synthesis, high uncertainty in perception, and the lack of efficient spatial abstractions, among others. We propose a novel framework for learning model-free policies integrating two modalities: 3D point clouds and proprioceptive touch indicators, emphasising manipulation with full body contact awareness, going beyond traditional end-effector modes. Our reinforcement learning framework leverages a distributional state representation, aided by kernel mean embeddings, to achieve improved training efficiency and real-time inference. Furthermore, we propose a novel context-agnostic occlusion heuristic to clear deformables from a target region for exposure tasks. We deploy the framework in a power line clearance scenario and observe that the agent generates creative strategies leveraging multiple arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy transfer, allowing the arm to clear real branches with unknown occlusion patterns, unseen topology, and uncertain dynamics.",
      "authors": [
        "Jayadeep Jacob",
        "Wenzheng Zhang",
        "Houston Warren",
        "Paulo Borges",
        "Tirthankar Bandyopadhyay",
        "Fabio Ramos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:58:30+00:00",
          "link": "https://arxiv.org/abs/2507.17085v1",
          "size": "6353kb",
          "version": "v1"
        }
      ],
      "title": "Deformable Cluster Manipulation via Whole-Arm Policy Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17085",
        "HTML": "https://arxiv.org/html/2507.17085v1",
        "PDF": "https://arxiv.org/pdf/2507.17085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses the challenges in manipulating clusters of deformable objects through reinforcement learning, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17087",
      "abstract": "Optimizing parallel programs for distributed heterogeneous systems remains a complex task, often requiring significant code modifications. Task-based programming systems improve modularity by separating performance decisions from core application logic, but their mapping interfaces are often too low-level. In this work, we introduce Mapple, a high-level, declarative programming interface for mapping distributed applications. Mapple provides transformation primitives to resolve dimensionality mismatches between iteration and processor spaces, including a key primitive, decompose, that helps minimize communication volume. We implement Mapple on top of the Legion runtime by translating Mapple mappers into its low-level C++ interface. Across nine applications, including six matrix multiplication algorithms and three scientific computing workloads, Mapple reduces mapper code size by 14X and enables performance improvements of up to 1.34X over expert-written C++ mappers. In addition, the decompose primitive achieves up to 1.83X improvement over existing dimensionality-resolution heuristics. These results demonstrate that Mapple simplifies the development of high-performance mappers for distributed applications.",
      "authors": [
        "Anjiang Wei",
        "Rohan Yadav",
        "Hang Song",
        "Wonchan Lee",
        "Ke Wang",
        "Alex Aiken"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:01:07+00:00",
          "link": "https://arxiv.org/abs/2507.17087v1",
          "size": "610kb",
          "version": "v1"
        }
      ],
      "title": "Mapple: A Domain-Specific Language for Mapping Distributed Heterogeneous Parallel Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17087",
        "HTML": "https://arxiv.org/html/2507.17087v1",
        "PDF": "https://arxiv.org/pdf/2507.17087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Mapple, a domain-specific language for optimizing parallel programs in distributed systems. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17088",
      "abstract": "Vision-language models (VLMs) demonstrate impressive zero-shot and few-shot learning capabilities, making them essential for several downstream tasks. However, fine-tuning these models at scale remains challenging, particularly in federated environments where data is decentralized and non-iid across clients. Existing parameter-efficient tuning methods like LoRA (Low-Rank Adaptation) reduce computational overhead but struggle with heterogeneous client data, leading to suboptimal generalization. To address these challenges, we propose FedVLM, a federated LoRA fine-tuning framework that enables decentralized adaptation of VLMs while preserving model privacy and reducing reliance on centralized training. To further tackle data heterogeneity, we introduce personalized LoRA (pLoRA), which dynamically adapts LoRA parameters to each client's unique data distribution, significantly improving local adaptation while maintaining global model aggregation. Experiments on the RLAIF-V dataset show that pLoRA improves client-specific performance by 24.5% over standard LoRA, demonstrating superior adaptation in non-iid settings. FedVLM provides a scalable and efficient solution for fine-tuning VLMs in federated settings, advancing personalized adaptation in distributed learning scenarios.",
      "authors": [
        "Arkajyoti Mitra (1)",
        "Afia Anjum (1)",
        "Paul Agbaje (1)",
        "Mert Pes\\'e (2)",
        "Habeeb Olufowobi (1) ((1) University of Texas at Arlington",
        "(2) Clemson University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:05:02+00:00",
          "link": "https://arxiv.org/abs/2507.17088v1",
          "size": "2660kb",
          "version": "v1"
        }
      ],
      "title": "FedVLM: Scalable Personalized Vision-Language Models through Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17088",
        "HTML": "https://arxiv.org/html/2507.17088v1",
        "PDF": "https://arxiv.org/pdf/2507.17088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While primarily focused on vision-language models (VLMs), this paper discusses personalized federated learning fine-tuning methods. It touches on data decentralization but not specific LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17089",
      "abstract": "Researchers have increasingly adopted Transformer-based models for inertial odometry. While Transformers excel at modeling long-range dependencies, their limited sensitivity to local, fine-grained motion variations and lack of inherent inductive biases often hinder localization accuracy and generalization. Recent studies have shown that incorporating large-kernel convolutions and Transformer-inspired architectural designs into CNN can effectively expand the receptive field, thereby improving global motion perception. Motivated by these insights, we propose a novel CNN-based module called the Dual-wing Adaptive Dynamic Mixer (DADM), which adaptively captures both global motion patterns and local, fine-grained motion features from dynamic inputs. This module dynamically generates selective weights based on the input, enabling efficient multi-scale feature aggregation. To further improve temporal modeling, we introduce the Spatio-Temporal Gating Unit (STGU), which selectively extracts representative and task-relevant motion features in the temporal domain. This unit addresses the limitations of temporal modeling observed in existing CNN approaches. Built upon DADM and STGU, we present a new CNN-based inertial odometry backbone, named Next Era of Inertial Odometry (IONext). Extensive experiments on six public datasets demonstrate that IONext consistently outperforms state-of-the-art (SOTA) Transformer- and CNN-based methods. For instance, on the RNIN dataset, IONext reduces the average ATE by 10% and the average RTE by 12% compared to the representative model iMOT.",
      "authors": [
        "Shanshan Zhang",
        "Siyue Wang",
        "Tianshui Wen",
        "Qi Zhang",
        "Ziheng Zhou",
        "Lingxiang Zheng",
        "Yu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:09:36+00:00",
          "link": "https://arxiv.org/abs/2507.17089v1",
          "size": "2847kb",
          "version": "v1"
        }
      ],
      "title": "IONext: Unlocking the Next Era of Inertial Odometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17089",
        "HTML": "https://arxiv.org/html/2507.17089v1",
        "PDF": "https://arxiv.org/pdf/2507.17089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presents IONext, a CNN-based approach for inertial odometry, emphasizing motion modeling improvements, not related to any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17093",
      "abstract": "Background: Fuzzers are often guided by coverage, making the estimation of maximum achievable coverage a key concern in fuzzing. However, achieving 100% coverage is infeasible for most real-world software systems, regardless of effort. While static reachability analysis can provide an upper bound, it is often highly inaccurate. Recently, statistical estimation methods based on species richness estimators from biostatistics have been proposed as a potential solution. Yet, the lack of reliable benchmarks with labeled ground truth has limited rigorous evaluation of their accuracy.\n  Objective: This work examines the reliability of reachability estimators from two axes: addressing the lack of labeled ground truth and evaluating their reliability on real-world programs.\n  Methods: (1) To address the challenge of labeled ground truth, we propose an evaluation framework that synthetically generates large programs with complex control flows, ensuring well-defined reachability and providing ground truth for evaluation. (2) To address the criticism from use of synthetic benchmarks, we adapt a reliability check for reachability estimators on real-world benchmarks without labeled ground truth -- by varying the size of sampling units, which, in theory, should not affect the estimate.\n  Results: These two studies together will help answer the question of whether current reachability estimators are reliable, and defines a protocol to evaluate future improvements in reachability estimation.",
      "authors": [
        "Danushka Liyanage",
        "Nelum Attanayake",
        "Zijian Luo",
        "Rahul Gopinath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:18:29+00:00",
          "link": "https://arxiv.org/abs/2507.17093v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Assessing Reliability of Statistical Maximum Coverage Estimators in Fuzzing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17093",
        "HTML": "https://arxiv.org/html/2507.17093v1",
        "PDF": "https://arxiv.org/pdf/2507.17093"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fuzzing and maximum coverage estimators, with no connection to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17094",
      "abstract": "Graph-based Approximate Nearest Neighbor Search (ANNS) is widely adopted in numerous applications, such as recommendation systems, natural language processing, and computer vision. While recent works on GPU-based acceleration have significantly advanced ANNS performance, the ever-growing scale of datasets now demands efficient multi-GPU solutions. However, the design of existing works overlooks multi-GPU scalability, resulting in naive approaches that treat additional GPUs as a means to extend memory capacity for large datasets. This inefficiency arises from partitioning the dataset and independently searching for data points similar to the queries in each GPU. We therefore propose PathWeaver, a novel multi-GPU framework designed to scale and accelerate ANNS for large datasets. First, we propose pipelining-based path extension, a GPU-aware pipelining mechanism that reduces prior work's redundant search iterations by leveraging GPU-to-GPU communication. Second, we design ghost staging that leverages a representative dataset to identify optimal query starting points, reducing the search space for challenging queries. Finally, we introduce direction-guided selection, a data selection technique that filters irrelevant points early in the search process, minimizing unnecessary memory accesses and distance computations. Comprehensive evaluations across diverse datasets demonstrate that PathWeaver achieves 3.24$\\times$ geomean speedup and up to 5.30$\\times$ speedup on 95% recall rate over state-of-the-art multi-GPU-based ANNS frameworks.",
      "authors": [
        "Sukjin Kim",
        "Seongyeon Park",
        "Si Ung Noh",
        "Junguk Hong",
        "Taehee Kwon",
        "Hunseong Lim",
        "and Jinho Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:19:27+00:00",
          "link": "https://arxiv.org/abs/2507.17094v1",
          "size": "2125kb",
          "version": "v1"
        }
      ],
      "title": "PathWeaver: A High-Throughput Multi-GPU System for Graph-Based Approximate Nearest Neighbor Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17094",
        "HTML": "https://arxiv.org/html/2507.17094v1",
        "PDF": "https://arxiv.org/pdf/2507.17094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a multi-GPU system for graph-based approximate nearest neighbor search, which does not relate to any aspect of LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17096",
      "abstract": "We propose Zeroth-Order Random Matrix Search for Learning from Demonstrations (ZORMS-LfD). ZORMS-LfD enables the costs, constraints, and dynamics of constrained optimal control problems, in both continuous and discrete time, to be learned from expert demonstrations without requiring smoothness of the learning-loss landscape. In contrast, existing state-of-the-art first-order methods require the existence and computation of gradients of the costs, constraints, dynamics, and learning loss with respect to states, controls and/or parameters. Most existing methods are also tailored to discrete time, with constrained problems in continuous time receiving only cursory attention. We demonstrate that ZORMS-LfD matches or surpasses the performance of state-of-the-art methods in terms of both learning loss and compute time across a variety of benchmark problems. On unconstrained continuous-time benchmark problems, ZORMS-LfD achieves similar loss performance to state-of-the-art first-order methods with an over $80$\\% reduction in compute time. On constrained continuous-time benchmark problems where there is no specialized state-of-the-art method, ZORMS-LfD is shown to outperform the commonly used gradient-free Nelder-Mead optimization method.",
      "authors": [
        "Olivia Dry",
        "Timothy L. Molloy",
        "Wanxin Jin",
        "Iman Shames"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Numerical Analysis (math.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:23:01+00:00",
          "link": "https://arxiv.org/abs/2507.17096v1",
          "size": "2586kb",
          "version": "v1"
        }
      ],
      "title": "ZORMS-LfD: Learning from Demonstrations with Zeroth-Order Random Matrix Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17096",
        "HTML": "https://arxiv.org/html/2507.17096v1",
        "PDF": "https://arxiv.org/pdf/2507.17096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces ZORMS-LfD for learning from demonstrations in constrained control problems, which is not pertinent to LLM training data processing or dataset management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17107",
      "abstract": "Reinforcement learning (RL) is a key post-pretraining step for aligning large language models (LLMs) with complex tasks and human preferences. While it is often assumed that RL fine-tuning requires updating most of a model's parameters, we challenge this assumption with a surprising finding: RL fine-tuning consistently modifies only a small subnetwork (typically 5-30% of weights), leaving most parameters unchanged. We call this phenomenon RL-induced parameter update sparsity. It arises naturally, without any sparsity constraints or parameter-efficient tuning, and appears across multiple RL algorithms (e.g., PPO, DPO, SimPO, PRIME) and model families (e.g., OpenAI, Meta, and open-source LLMs). Moreover, the subnetworks updated by RL show substantial overlap across different seeds, datasets, and algorithms-far exceeding chance-suggesting a partially transferable structure in the pretrained model. We show that fine-tuning only this sparse subnetwork recovers full model performance and yields parameters nearly identical to the fully fine-tuned model. Our analysis suggests this sparsity emerges because RL operates near the model's original distribution, requiring only targeted changes. KL penalties, gradient clipping, and on-policy dynamics have limited effect on the sparsity pattern. These findings shed new light on how RL adapts models: not by shifting all weights, but by focusing training on a small, consistently updated subnetwork. This insight enables more efficient RL methods and reframes sparsity through the lens of the lottery ticket hypothesis.",
      "authors": [
        "Andrii Balashov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:02:17+00:00",
          "link": "https://arxiv.org/abs/2507.17107v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning Fine-Tunes a Sparse Subnetwork in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17107",
        "HTML": "https://arxiv.org/html/2507.17107v1",
        "PDF": "https://arxiv.org/pdf/2507.17107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses primarily on RL fine-tuning techniques for LLMs, it touches upon fine-tuning and parameter updates, partially relating to the broader area of LLM training methodologies but not directly contributing to training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17110",
      "abstract": "This paper proposes a transient stability-driven planning framework for the optimal sizing problem of resilient AC/DC hybrid microgrids (HMGs) under different types of contingencies, capturing frequency and voltage stability requirements as well as the frequency-voltage coupling dynamics of AC/DC interlinking converters (ICs). The planning model is formulated into a defender-attacker-defender (DAD) architecture, which can be further merged into two levels, i.e., upper-level and low-level problems, and then iteratively solved by an enhanced genetic algorithm with sparsity calculation and local search. Regarding the operation stage, a novel transient stability-constrained optimal power flow (TSC-OPF) algorithm is proposed for static and transient operations of HMGs, capturing governor dynamics and automatic voltage regulator of conventional generators as well as the droop control dynamics of inverter-based resources (IBRs) for frequency control and voltage control, respectively. Furthermore, a Lyapunov optimisation approach is developed to capture the time-coupling property of energy storages (ESs) and then allow the TSC-OPF to be solved on an hourly basis with a second-scale resolution, achieving the co-optimisation of static and transient stability requirements. Case studies have been conducted to verify the effectiveness of the proposed planning framework in obtaining cost-effective investment decisions for various resources while respecting transient stability requirements under different contingencies.",
      "authors": [
        "Yi Wang",
        "Goran Strbac"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:18:31+00:00",
          "link": "https://arxiv.org/abs/2507.17110v1",
          "size": "1381kb",
          "version": "v1"
        }
      ],
      "title": "Transient Stability-Driven Planning for the Optimal Sizing of Resilient AC/DC Hybrid Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17110",
        "HTML": "https://arxiv.org/html/2507.17110v1",
        "PDF": "https://arxiv.org/pdf/2507.17110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimal sizing of resilient AC/DC hybrid microgrids, capturing frequency and voltage stability, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17112",
      "abstract": "Cross-domain recommendation (CDR) aims to alleviate the data sparsity by transferring knowledge across domains. Disentangled representation learning provides an effective solution to model complex user preferences by separating intra-domain features (domain-shared and domain-specific features), thereby enhancing robustness and interpretability. However, disentanglement-based CDR methods employing generative modeling or GNNs with contrastive objectives face two key challenges: (i) pre-separation strategies decouple features before extracting collaborative signals, disrupting intra-domain interactions and introducing noise; (ii) unsupervised disentanglement objectives lack explicit task-specific guidance, resulting in limited consistency and suboptimal alignment. To address these challenges, we propose DGCDR, a GNN-enhanced encoder-decoder framework. To handle challenge (i), DGCDR first applies GNN to extract high-order collaborative signals, providing enriched representations as a robust foundation for disentanglement. The encoder then dynamically disentangles features into domain-shared and -specific spaces, preserving collaborative information during the separation process. To handle challenge (ii), the decoder introduces an anchor-based supervision that leverages hierarchical feature relationships to enhance intra-domain consistency and cross-domain alignment. Extensive experiments on real-world datasets demonstrate that DGCDR achieves state-of-the-art performance, with improvements of up to 11.59% across key metrics. Qualitative analyses further validate its superior disentanglement quality and transferability. Our source code and datasets are available on GitHub for further comparison.",
      "authors": [
        "Yuhan Wang",
        "Qing Xie",
        "Zhifeng Bao",
        "Mengzi Tang",
        "Lin Li",
        "Yongjian Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.17112v1",
          "size": "1740kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Transferability and Consistency in Cross-Domain Recommendations via Supervised Disentanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17112",
        "HTML": "https://arxiv.org/html/2507.17112v1",
        "PDF": "https://arxiv.org/pdf/2507.17112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses cross-domain recommendation using supervised disentanglement, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17114",
      "abstract": "This study examines the social media uptake of scientific journals on two different platforms - X and WeChat - by comparing the adoption of X among journals indexed in the Science Citation Index-Expanded (SCIE) with the adoption of WeChat among journals indexed in the Chinese Science Citation Database (CSCD). The findings reveal substantial differences in platform adoption and user engagement, shaped by local contexts. While only 22.7% of SCIE journals maintain an X account, 84.4% of CSCD journals have a WeChat official account. Journals in Life Sciences & Biomedicine lead in uptake on both platforms, whereas those in Technology and Physical Sciences show high WeChat uptake but comparatively lower presence on X. User engagement on both platforms is dominated by low-effort interactions rather than more conversational behaviors. Correlation analyses indicate weak-to-moderate relationships between bibliometric indicators and social media metrics, confirming that online engagement reflects a distinct dimension of journal impact, whether on an international or a local platform. These findings underscore the need for broader social media metric frameworks that incorporate locally dominant platforms, thereby offering a more comprehensive understanding of science communication practices across diverse social media and contexts.",
      "authors": [
        "Ting Cong",
        "Er-Te Zheng",
        "Zekun Han",
        "Zhichao Fang",
        "Rodrigo Costas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:33:30+00:00",
          "link": "https://arxiv.org/abs/2507.17114v1",
          "size": "1159kb",
          "version": "v1"
        }
      ],
      "title": "Social media uptake of scientific journals: A comparison between X and WeChat",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17114",
        "PDF": "https://arxiv.org/pdf/2507.17114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines social media uptake of scientific journals on X and WeChat, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17116",
      "abstract": "Probabilistic graphical modeling is a branch of machine learning that uses probability distributions to describe the world, make predictions, and support decision-making under uncertainty. Underlying this modeling framework is an elegant body of theory that bridges two mathematical traditions: probability and graph theory. This framework provides compact yet expressive representations of joint probability distributions, yielding powerful generative models for probabilistic reasoning.\n  This tutorial provides a concise introduction to the formalisms, methods, and applications of this modeling framework. After a review of basic probability and graph theory, we explore three dominant themes: (1) the representation of multivariate distributions in the intuitive visual language of graphs, (2) algorithms for learning model parameters and graphical structures from data, and (3) algorithms for inference, both exact and approximate.",
      "authors": [
        "Jacqueline Maasch",
        "Willie Neiswanger",
        "Stefano Ermon",
        "Volodymyr Kuleshov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:36:44+00:00",
          "link": "https://arxiv.org/abs/2507.17116v1",
          "size": "4068kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Graphical Models: A Concise Tutorial",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17116",
        "PDF": "https://arxiv.org/pdf/2507.17116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This is a tutorial on probabilistic graphical models, focusing on the theory and methods of probabilistic reasoning, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17118",
      "abstract": "AI has become integral to safety-critical areas like autonomous driving systems (ADS) and robotics. The architecture of recent autonomous systems are trending toward end-to-end (E2E) monolithic architectures such as large language models (LLMs) and vision language models (VLMs). In this paper, we review different architectural solutions and then evaluate the efficacy of common safety analyses such as failure modes and effect analysis (FMEA) and fault tree analysis (FTA). We show how these techniques can be improved for the intricate nature of the foundational models, particularly in how they form and utilize latent representations. We introduce HySAFE-AI, Hybrid Safety Architectural Analysis Framework for AI Systems, a hybrid framework that adapts traditional methods to evaluate the safety of AI systems. Lastly, we offer hints of future work and suggestions to guide the evolution of future AI safety standards.",
      "authors": [
        "Mandar Pitale",
        "Jelena Frtunikj",
        "Abhinaw Priyadershi",
        "Vasu Singh",
        "Maria Spence"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:41:51+00:00",
          "link": "https://arxiv.org/abs/2507.17118v1",
          "size": "700kb",
          "version": "v1"
        }
      ],
      "title": "HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17118",
        "HTML": "https://arxiv.org/html/2507.17118v1",
        "PDF": "https://arxiv.org/pdf/2507.17118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on safety architectural analysis and hybrid frameworks for evaluating AI systems, which do not relate to LLM training data processing as it doesn't involve data operations like collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17120",
      "abstract": "Large language models (LLMs) have become increasingly popular in various areas, traditional business gradually shifting from rule-based systems to LLM-based solutions. However, the inference of LLMs is resource-intensive or latency-sensitive, posing significant challenges for serving systems. Existing LLM serving systems often use static or continuous batching strategies, which can lead to inefficient GPU memory utilization and increased latency, especially under heterogeneous workloads. These methods may also struggle to adapt to dynamic workload fluctuations, resulting in suboptimal throughput and potential service level objective (SLO) violations. In this paper, we introduce BucketServe, a bucket-based dynamic batching framework designed to optimize LLM inference performance. By grouping requests into size-homogeneous buckets based on sequence length, BucketServe minimizes padding overhead and optimizes GPU memory usage through real-time batch size adjustments preventing out-of-memory (OOM) errors. It introduces adaptive bucket splitting/merging and priority-aware scheduling to mitigate resource fragmentation and ensure SLO compliance. Experiment shows that BucketServe significantly outperforms UELLM in throughput, achieving up to 3.58x improvement. It can also handle 1.93x more request load under the SLO attainment of 80% compared with DistServe and demonstrates 1.975x higher system load capacity compared to the UELLM.",
      "authors": [
        "Wanyi Zheng",
        "Minxian Xu",
        "Shengye Song",
        "Kejiang Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:51:48+00:00",
          "link": "https://arxiv.org/abs/2507.17120v1",
          "size": "832kb",
          "version": "v1"
        }
      ],
      "title": "BucketServe: Bucket-Based Dynamic Batching for Smart and Efficient LLM Inference Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17120",
        "HTML": "https://arxiv.org/html/2507.17120v1",
        "PDF": "https://arxiv.org/pdf/2507.17120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces BucketServe, a framework for optimizing LLM inference performance, focusing on batching strategies during inference, not on any aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17121",
      "abstract": "Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, and early diagnosis through automated retinal image analysis can significantly reduce the risk of blindness. This paper presents a robust deep learning framework for both binary and five-class DR classification, leveraging transfer learning and extensive data augmentation to address the challenges of class imbalance and limited training data. We evaluate a range of pretrained convolutional neural network architectures, including variants of ResNet and EfficientNet, on the APTOS 2019 dataset.\n  For binary classification, our proposed model achieves a state-of-the-art accuracy of 98.9%, with a precision of 98.6%, recall of 99.3%, F1-score of 98.9%, and an AUC of 99.4%. In the more challenging five-class severity classification task, our model obtains a competitive accuracy of 84.6% and an AUC of 94.1%, outperforming several existing approaches. Our findings also demonstrate that EfficientNet-B0 and ResNet34 offer optimal trade-offs between accuracy and computational efficiency across both tasks.\n  These results underscore the effectiveness of combining class-balanced augmentation with transfer learning for high-performance DR diagnosis. The proposed framework provides a scalable and accurate solution for DR screening, with potential for deployment in real-world clinical environments.",
      "authors": [
        "Faisal Ahmed",
        "Mohammad Alfrad Nobel Bhuiyan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:52:27+00:00",
          "link": "https://arxiv.org/abs/2507.17121v1",
          "size": "139kb",
          "version": "v1"
        }
      ],
      "title": "Robust Five-Class and binary Diabetic Retinopathy Classification Using Transfer Learning and Data Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17121",
        "HTML": "https://arxiv.org/html/2507.17121v1",
        "PDF": "https://arxiv.org/pdf/2507.17121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses diabetic retinopathy classification using transfer learning and data augmentation for deep learning but lacks any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17123",
      "abstract": "The rapid diagnosis of infectious diseases, such as monkeypox, is crucial for effective containment and treatment, particularly in resource-constrained environments. This study presents an AI-driven diagnostic tool developed for deployment on the NVIDIA Jetson Orin Nano, leveraging the pre-trained MobileNetV2 architecture for binary classification. The model was trained on the open-source Monkeypox Skin Lesion Dataset, achieving a 93.07% F1-Score, which reflects a well-balanced performance in precision and recall. To optimize the model, the TensorRT framework was used to accelerate inference for FP32 and to perform post-training quantization for FP16 and INT8 formats. TensorRT's mixed-precision capabilities enabled these optimizations, which reduced the model size, increased inference speed, and lowered power consumption by approximately a factor of two, all while maintaining the original accuracy. Power consumption analysis confirmed that the optimized models used significantly less energy during inference, reinforcing their suitability for deployment in resource-constrained environments. The system was deployed with a Wi-Fi Access Point (AP) hotspot and a web-based interface, enabling users to upload and analyze images directly through connected devices such as mobile phones. This setup ensures simple access and seamless connectivity, making the tool practical for real-world applications. These advancements position the diagnostic tool as an efficient, scalable, and energy-conscious solution to address diagnosis challenges in underserved regions, paving the way for broader adoption in low-resource healthcare settings.",
      "authors": [
        "Jacob M. Delgado-L\\'opez",
        "Ricardo A. Morell-Rodriguez",
        "Sebasti\\'an O. Espinosa-Del Rosario",
        "Wilfredo E. Lugo-Beauchamp"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:53:31+00:00",
          "link": "https://arxiv.org/abs/2507.17123v1",
          "size": "274kb",
          "version": "v1"
        }
      ],
      "title": "Computer Vision for Real-Time Monkeypox Diagnosis on Embedded Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17123",
        "HTML": "https://arxiv.org/html/2507.17123v1",
        "PDF": "https://arxiv.org/pdf/2507.17123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves real-time diagnosis of monkeypox using computer vision with model optimization techniques, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17125",
      "abstract": "Skin cancer is one of the most prevalent and preventable types of cancer, yet its early detection remains a challenge, particularly in resource-limited settings where access to specialized healthcare is scarce. This study proposes an AI-driven diagnostic tool optimized for embedded systems to address this gap. Using transfer learning with the MobileNetV2 architecture, the model was adapted for binary classification of skin lesions into \"Skin Cancer\" and \"Other.\" The TensorRT framework was employed to compress and optimize the model for deployment on the NVIDIA Jetson Orin Nano, balancing performance with energy efficiency. Comprehensive evaluations were conducted across multiple benchmarks, including model size, inference speed, throughput, and power consumption. The optimized models maintained their performance, achieving an F1-Score of 87.18% with a precision of 93.18% and recall of 81.91%. Post-compression results showed reductions in model size of up to 0.41, along with improvements in inference speed and throughput, and a decrease in energy consumption of up to 0.93 in INT8 precision. These findings validate the feasibility of deploying high-performing, energy-efficient diagnostic tools on resource-constrained edge devices. Beyond skin cancer detection, the methodologies applied in this research have broader applications in other medical diagnostics and domains requiring accessible, efficient AI solutions. This study underscores the potential of optimized AI systems to revolutionize healthcare diagnostics, thereby bridging the divide between advanced technology and underserved regions.",
      "authors": [
        "Jacob M. Delgado-L\\'opez",
        "Andrea P. Seda-Hernandez",
        "Juan D. Guadalupe-Rosado",
        "Luis E. Fernandez Ramirez",
        "Miguel Giboyeaux-Camilo",
        "Wilfredo E. Lugo-Beauchamp"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:02:24+00:00",
          "link": "https://arxiv.org/abs/2507.17125v1",
          "size": "603kb",
          "version": "v1"
        }
      ],
      "title": "Model Compression Engine for Wearable Devices Skin Cancer Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17125",
        "HTML": "https://arxiv.org/html/2507.17125v1",
        "PDF": "https://arxiv.org/pdf/2507.17125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses model compression and optimization for skin cancer diagnostics on wearable devices, focusing on AI deployment methods rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17127",
      "abstract": "Scientific retractions reflect issues within the scientific record, arising from human error or misconduct. Although gender differences in retraction rates have been previously observed in various contexts, no comprehensive study has explored this issue across all fields of science. This study examines gender disparities in scientific misconduct or errors, specifically focusing on differences in retraction rates between male and female first authors in relation to their research productivity. Using a dataset comprising 11,622 retracted articles and 19,475,437 non-retracted articles from the Web of Science and Retraction Watch, we investigate gender differences in retraction rates from the perspectives of retraction reasons, subject fields, and countries. Our findings indicate that male first authors have higher retraction rates, particularly for scientific misconduct such as plagiarism, authorship disputes, ethical issues, duplication, and fabrication/falsification. No significant gender differences were found in retractions attributed to mistakes. Furthermore, male first authors experience significantly higher retraction rates in biomedical and health sciences, as well as in life and earth sciences, whereas female first authors have higher retraction rates in mathematics and computer science. Similar patterns are observed for corresponding authors. Understanding these gendered patterns of retraction may contribute to strategies aimed at reducing their prevalence.",
      "authors": [
        "Er-Te Zheng",
        "Hui-Zhen Fu",
        "Mike Thelwall",
        "Zhichao Fang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:04:21+00:00",
          "link": "https://arxiv.org/abs/2507.17127v1",
          "size": "1628kb",
          "version": "v1"
        }
      ],
      "title": "Do male leading authors retract more articles than female leading authors?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17127",
        "PDF": "https://arxiv.org/pdf/2507.17127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates gender differences in scientific retraction rates, which does not relate to LLM training data processing or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17128",
      "abstract": "The interactions within cloud-native applications are complex, with a constantly changing number of services and loads, posing higher demands on auto-scaling approach. This mainly involves several challenges such as microservices dependency analysis, performance profiling, anomaly detection, workload characterization and task co-location. Therefore, some advanced algorithms have been investigated into auto-scaling cloud-native applications to optimize system and application performance. These algorithms can learn from historical data and appropriately adjust resource allocation based on the current environment and load conditions to optimize resource utilization and system performance. In this paper, we systematically review the literature on state-of-the-art auto-scaling approaches for cloud-native applications from 2020, and further explore the technological evolution. Additionally, we propose a detailed taxonomy to categorize current research from five perspectives, including infrastructure, architecture, scaling methods, optimization objectives, and behavior modeling. Then, we provide a comprehensive comparison and in-depth discussion of the key features, advantages, limitations, and application scenarios of each approach, considering their performance in diverse environments and under various conditions. Finally, we summarize the current state of research in this field, identify the gaps and unresolved challenges, and emphasize promising directions for future exploration, particularly in areas such as the application of large models, microservice dependency management, and the use of meta-learning techniques to enhance model applicability and adaptability across different environments.",
      "authors": [
        "Minxian Xu",
        "Linfeng Wen",
        "Junhan Liao",
        "Huaming Wu",
        "Kejiang Ye",
        "Chengzhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:04:40+00:00",
          "link": "https://arxiv.org/abs/2507.17128v1",
          "size": "2125kb",
          "version": "v1"
        }
      ],
      "title": "Auto-scaling Approaches for Cloud-native Applications: A Survey and Taxonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17128",
        "HTML": "https://arxiv.org/html/2507.17128v1",
        "PDF": "https://arxiv.org/pdf/2507.17128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey reviews auto-scaling approaches for cloud-native applications, focusing on system performance optimization, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17129",
      "abstract": "Polarforming is a promising technique that enables dynamic adjustment of antenna polarization to mitigate depolarization effects commonly encountered during electromagnetic (EM) wave propagation. In this letter, we investigate the polarforming design for secure wireless communication systems, where the base station (BS) is equipped with polarization-reconfigurable antennas (PRAs) and can flexibly adjust the antenna polarization to transmit confidential information to a legitimate user in the presence of an eavesdropper. To maximize the achievable secrecy rate, we propose an efficient iterative algorithm to jointly optimize transmit beamforming and polarforming, where beamforming exploits spatial degrees of freedom (DoFs) to steer the transmit beam toward the user, while polarforming leverages polarization DoFs to align the polarization state of the EM wave received by the user with that of its antenna. Simulation results demonstrate that, compared to conventional fixed-polarization antenna (FPA) systems, polarforming can fully exploit the DoFs in antenna polarization optimization to significantly enhance the security performance of wireless communication systems.",
      "authors": [
        "Jingze Ding",
        "Zijian Zhou",
        "Bingli Jiao",
        "Rui Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:06:18+00:00",
          "link": "https://arxiv.org/abs/2507.17129v1",
          "size": "867kb",
          "version": "v1"
        }
      ],
      "title": "Secure Wireless Communication via Polarforming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17129",
        "HTML": "https://arxiv.org/html/2507.17129v1",
        "PDF": "https://arxiv.org/pdf/2507.17129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses polarforming for secure wireless communication, which is not relevant to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17130",
      "abstract": "This paper presents a novel spherical target-based LiDAR-camera extrinsic calibration method designed for outdoor environments with multi-robot systems, considering both target and sensor corruption. The method extracts the 2D ellipse center from the image and the 3D sphere center from the pointcloud, which are then paired to compute the transformation matrix. Specifically, the image is first decomposed using the Segment Anything Model (SAM). Then, a novel algorithm extracts an ellipse from a potentially corrupted sphere, and the extracted center of ellipse is corrected for errors caused by the perspective projection model. For the LiDAR pointcloud, points on the sphere tend to be highly noisy due to the absence of flat regions. To accurately extract the sphere from these noisy measurements, we apply a hierarchical weighted sum to the accumulated pointcloud. Through experiments, we demonstrated that the sphere can be robustly detected even under both types of corruption, outperforming other targets. We evaluated our method using three different types of LiDARs (spinning, solid-state, and non-repetitive) with cameras positioned in three different locations. Furthermore, we validated the robustness of our method to target corruption by experimenting with spheres subjected to various types of degradation. These experiments were conducted in both a planetary test and a field environment. Our code is available at https://github.com/sparolab/MARSCalib.",
      "authors": [
        "Seokhwan Jeong",
        "Hogyun Kim and Younggun Cho"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:11:12+00:00",
          "link": "https://arxiv.org/abs/2507.17130v1",
          "size": "1771kb",
          "version": "v1"
        }
      ],
      "title": "MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17130",
        "HTML": "https://arxiv.org/html/2507.17130v1",
        "PDF": "https://arxiv.org/pdf/2507.17130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a multi-robot calibration method for LiDAR-camera systems, focusing on robotic vision applications, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17131",
      "abstract": "Large language model (LLM) agents often struggle in environments where rules and required domain knowledge frequently change, such as regulatory compliance and user risk screening. Current approaches, like offline fine-tuning and standard prompting, are insufficient because they cannot effectively adapt to new knowledge during actual operation. To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time. ARIA assesses its own uncertainty through structured self-dialogue, proactively identifying knowledge gaps and requesting targeted explanations or corrections from human experts. It then systematically updates an internal, timestamped knowledge repository with provided human guidance, detecting and resolving conflicting or outdated knowledge through comparisons and clarification queries. We evaluate ARIA on the realistic customer due diligence name screening task on TikTok Pay, alongside publicly available dynamic knowledge tasks. Results demonstrate significant improvements in adaptability and accuracy compared to baselines using standard offline fine-tuning and existing self-improving agents. ARIA is deployed within TikTok Pay serving over 150 million monthly active users, confirming its practicality and effectiveness for operational use in rapidly evolving environments.",
      "authors": [
        "Yufei He",
        "Ruoyu Li",
        "Alex Chen",
        "Yue Liu",
        "Yulin Chen",
        "Yuan Sui",
        "Cheng Chen",
        "Yi Zhu",
        "Luca Luo",
        "Frank Yang",
        "Bryan Hooi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:12:32+00:00",
          "link": "https://arxiv.org/abs/2507.17131v1",
          "size": "463kb",
          "version": "v1"
        }
      ],
      "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17131",
        "HTML": "https://arxiv.org/html/2507.17131v1",
        "PDF": "https://arxiv.org/pdf/2507.17131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on the Adaptive Reflective Interactive Agent (ARIA) which enhances LLM adaptability with human guidance at test time, but it primarily addresses dynamic knowledge updating rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17132",
      "abstract": "With the rapid development of the construction industry, issues such as harsh working environments, high-intensity and high-risk tasks, and labor shortages have become increasingly prominent. This drives higher demands for construction robots in terms of low energy consumption, high mobility, and high load capacity. This paper focuses on the design and optimization of leg structures for construction robots, aiming to improve their dynamic performance, reduce energy consumption, and enhance load-bearing capabilities. Firstly, based on the leg configuration of ants in nature, we design a structure for the robot's leg. Secondly, we propose a novel structural optimization method. Using the Lagrangian approach, a dynamic model of the leg was established. Combining the dynamic model with the leg's motion trajectory, we formulated multiple dynamic evaluation metrics and conducted a comprehensive optimization study on the geometric parameters of each leg segment. The results show that the optimized leg structure reduces peak joint torques and energy consumption by over 20%. Finally, dynamic simulation experiments were conducted using ADAMS. The results demonstrate a significant reduction in the driving power of each joint after optimization, validating the effectiveness and rationality of the proposed strategy. This study provides a theoretical foundation and technical support for the design of heavy-load, high-performance construction robots.",
      "authors": [
        "Xiao Liu",
        "Xianlong Yang",
        "Weijun Wang",
        "Wei Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:12:35+00:00",
          "link": "https://arxiv.org/abs/2507.17132v1",
          "size": "3440kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17132",
        "HTML": "https://arxiv.org/html/2507.17132v1",
        "PDF": "https://arxiv.org/pdf/2507.17132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around optimizing legged mechanisms for construction robots and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17133",
      "abstract": "In recent years, the Mixture-of-Experts (MoE) architecture has been widely applied to large language models (LLMs), providing a promising solution that activates only a subset of the model's parameters during computation, thereby reducing overall memory requirements and allowing for faster inference compared to dense models. Despite these advantages, existing systems still face issues of low efficiency due to static model placement and lack of dynamic workloads adaptation. This leads to suboptimal resource utilization and increased latency, especially during bursty requests periods.\n  To address these challenges, this paper introduces BrownoutServe, a novel serving framework designed to optimize inference efficiency and maintain service reliability for MoE-based LLMs under dynamic computational demands and traffic conditions. BrownoutServe introduces \"united experts\" that integrate knowledge from multiple experts, reducing the times of expert access and inference latency. Additionally, it proposes a dynamic brownout mechanism to adaptively adjust the processing of certain tokens, optimizing inference performance while guaranteeing service level objectives (SLOs) are met. Our evaluations show the effectiveness of BrownoutServe under various workloads: it achieves up to 2.07x throughput improvement compared to vLLM and reduces SLO violations by 90.28%, showcasing its robustness under bursty traffic while maintaining acceptable inference accuracy.",
      "authors": [
        "Jianmin Hu",
        "Minxian Xu",
        "Kejiang Ye",
        "Chengzhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:14:18+00:00",
          "link": "https://arxiv.org/abs/2507.17133v1",
          "size": "948kb",
          "version": "v1"
        }
      ],
      "title": "BrownoutServe: SLO-Aware Inference Serving under Bursty Workloads for MoE-based LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17133",
        "HTML": "https://arxiv.org/html/2507.17133v1",
        "PDF": "https://arxiv.org/pdf/2507.17133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses BrownoutServe, a serving framework aimed at inference efficiency for MoE-based LLMs, without addressing any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17134",
      "abstract": "Global health emergencies, such as the COVID-19 pandemic, have exposed critical weaknesses in traditional medical supply chains, including inefficiencies in resource allocation, lack of transparency, and poor adaptability to dynamic disruptions. This paper presents a novel hybrid framework that integrates blockchain technology with a decentralized, large language model (LLM) powered multi-agent negotiation system to enhance the resilience and accountability of medical supply chains during crises. In this system, autonomous agents-representing manufacturers, distributors, and healthcare institutions-engage in structured, context-aware negotiation and decision-making processes facilitated by LLMs, enabling rapid and ethical allocation of scarce medical resources. The off-chain agent layer supports adaptive reasoning and local decision-making, while the on-chain blockchain layer ensures immutable, transparent, and auditable enforcement of decisions via smart contracts. The framework also incorporates a formal cross-layer communication protocol to bridge decentralized negotiation with institutional enforcement. A simulation environment emulating pandemic scenarios evaluates the system's performance, demonstrating improvements in negotiation efficiency, fairness of allocation, supply chain responsiveness, and auditability. This research contributes an innovative approach that synergizes blockchain trust guarantees with the adaptive intelligence of LLM-driven agents, providing a robust and scalable solution for critical supply chain coordination under uncertainty.",
      "authors": [
        "Mariam ALMutairi",
        "Hyungmin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:14:42+00:00",
          "link": "https://arxiv.org/abs/2507.17134v1",
          "size": "1172kb",
          "version": "v1"
        }
      ],
      "title": "Resilient Multi-Agent Negotiation for Medical Supply Chains:Integrating LLMs and Blockchain for Transparent Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17134",
        "HTML": "https://arxiv.org/html/2507.17134v1",
        "PDF": "https://arxiv.org/pdf/2507.17134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores a hybrid framework using LLMs and blockchain for medical supply chains, emphasizing negotiation and transparency rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17135",
      "abstract": "Diffusion models have achieved remarkable success in generative tasks but suffer from high computational costs due to their iterative sampling process and quadratic attention costs. Existing training-free acceleration strategies that reduce per-step computation cost, while effectively reducing sampling time, demonstrate low faithfulness compared to the original baseline. We hypothesize that this fidelity gap arises because (a) different prompts correspond to varying denoising trajectory, and (b) such methods do not consider the underlying ODE formulation and its numerical solution. In this paper, we propose Stability-guided Adaptive Diffusion Acceleration (SADA), a novel paradigm that unifies step-wise and token-wise sparsity decisions via a single stability criterion to accelerate sampling of ODE-based generative models (Diffusion and Flow-matching). For (a), SADA adaptively allocates sparsity based on the sampling trajectory. For (b), SADA introduces principled approximation schemes that leverage the precise gradient information from the numerical ODE solver. Comprehensive evaluations on SD-2, SDXL, and Flux using both EDM and DPM++ solvers reveal consistent $\\ge 1.8\\times$ speedups with minimal fidelity degradation (LPIPS $\\leq 0.10$ and FID $\\leq 4.5$) compared to unmodified baselines, significantly outperforming prior methods. Moreover, SADA adapts seamlessly to other pipelines and modalities: It accelerates ControlNet without any modifications and speeds up MusicLDM by $1.8\\times$ with $\\sim 0.01$ spectrogram LPIPS.",
      "authors": [
        "Ting Jiang and Yixiao Wang and Hancheng Ye and Zishan Shao and Jingwei Sun and Jingyang Zhang and Zekai Chen and Jianyi Zhang and Yiran Chen and Hai Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:15:45+00:00",
          "link": "https://arxiv.org/abs/2507.17135v1",
          "size": "16381kb",
          "version": "v1"
        }
      ],
      "title": "SADA: Stability-guided Adaptive Diffusion Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17135",
        "HTML": "https://arxiv.org/html/2507.17135v1",
        "PDF": "https://arxiv.org/pdf/2507.17135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on accelerating diffusion models in generative tasks, which is unrelated to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17136",
      "abstract": "In the construction industry, traditional methods fail to meet the modern demands for efficiency and quality. The curtain wall installation is a critical component of construction projects. We design a hydraulically driven robotic arm for curtain wall installation and a dynamic parameter identification method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic arm structural parameters and integrate hydraulic cylinder dynamics to construct a composite parametric system driven by a Stribeck friction model. By designing high-signal-to-noise ratio displacement excitation signals for hydraulic cylinders and combining Fourier series to construct optimal excitation trajectories that satisfy joint constraints, this method effectively excites the characteristics of each parameter in the minimal parameter set of the dynamic model of the robotic arm. On this basis, a hierarchical progressive parameter identification strategy is proposed: least squares estimation is employed to separately identify and jointly calibrate the dynamic parameters of both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves for each joint. Experimental validation on a robotic arm platform demonstrates residual standard deviations below 0.4 Nm between theoretical and measured joint torques, confirming high-precision dynamic parameter identification for the hydraulic-driven curtain wall installation robotic arm. This significantly contributes to enhancing the intelligence level of curtain wall installation operations.",
      "authors": [
        "Xiao Liu",
        "Yunxiao Cheng",
        "Weijun Wang",
        "Tianlun Huang",
        "Wei Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:17:27+00:00",
          "link": "https://arxiv.org/abs/2507.17136v1",
          "size": "3122kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17136",
        "HTML": "https://arxiv.org/html/2507.17136v1",
        "PDF": "https://arxiv.org/pdf/2507.17136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on dynamic parameter identification for a robotic arm used in curtain wall installation, a topic unrelated to LLM training data processing. It deals with construction robotics rather than any aspect of data processing related to pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17139",
      "abstract": "We present a first study of the effects of frame time variations, in both deviation around mean frame times and period of fluctuation, on task performance in a virtual environment (VE). Chosen are open and closed loop tasks that are typical for current applications or likely to be prominent in future ones. The results show that at frame times in the range deemed acceptable for many applications, fairly large deviations in amplitude over a fairly wide range of periods do not significantly affect task performance. However, at a frame time often considered a minimum for immersive VR, frame time variations do produce significant effects on closed loop task performance. The results will be of use to designers of VEs and immersive applications, who often must control frame time variations due to large fluctuations of complexity (graphical and otherwise) in the VE.",
      "authors": [
        "Benjamin Watson",
        "Victoria Spaulding",
        "Neff Walker",
        "William Ribarsky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:22:51+00:00",
          "link": "https://arxiv.org/abs/2507.17139v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of the effects of frame time variation on VR task performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17139",
        "PDF": "https://arxiv.org/pdf/2507.17139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the effects of frame time variation on VR task performance, a topic that does not pertain to LLM training data processing. It is centered around virtual environment design and performance, not data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17140",
      "abstract": "In the context of labor shortages and rising costs, construction robots are regarded as the key to revolutionizing traditional construction methods and improving efficiency and quality in the construction industry. In order to ensure that construction robots can perform tasks efficiently and accurately in complex construction environments, traditional single-objective trajectory optimization methods are difficult to meet the complex requirements of the changing construction environment. Therefore, we propose a multi-objective trajectory optimization for the robotic arm used in the curtain wall installation. First, we design a robotic arm for curtain wall installation, integrating serial, parallel, and folding arm elements, while considering its physical properties and motion characteristics. In addition, this paper proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO) that incorporates a focus operator screening mechanism to accelerate the convergence of the algorithm towards the Pareto front, thereby effectively balancing the multi-objective constraints of construction robots. The proposed algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive trials on the DTLZ3 and WFG3 test functions, showing significantly better convergence efficiency than the other algorithms. Finally, we conduct two sets of experiments on the designed robotic arm platform, which confirm the efficiency and practicality of the NSGA-III-FO algorithm in solving multi-objective trajectory planning problems for curtain wall installation tasks.",
      "authors": [
        "Xiao Liu",
        "Yunxiao Cheng",
        "Weijun Wang",
        "Tianlun Huang",
        "Zhiyong Wang",
        "Wei Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:23:34+00:00",
          "link": "https://arxiv.org/abs/2507.17140v1",
          "size": "5614kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17140",
        "HTML": "https://arxiv.org/html/2507.17140v1",
        "PDF": "https://arxiv.org/pdf/2507.17140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on multi-objective trajectory planning for robotic arms in curtain wall installation, which does not relate to LLM training data processing. It primarily discusses algorithms for robotic trajectory optimization."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17141",
      "abstract": "Building general-purpose intelligent robots has long been a fundamental goal of robotics. A promising approach is to mirror the evolutionary trajectory of humans: learning through continuous interaction with the environment, with early progress driven by the imitation of human behaviors. Achieving this goal presents three core challenges: (1) designing safe robotic hardware with human-level physical capabilities; (2) developing an intuitive and scalable whole-body teleoperation interface for data collection; and (3) creating algorithms capable of learning whole-body visuomotor policies from human demonstrations. To address these challenges in a unified framework, we propose Astribot Suite, a robot learning suite for whole-body manipulation aimed at general daily tasks across diverse environments. We demonstrate the effectiveness of our system on a wide range of activities that require whole-body coordination, extensive reachability, human-level dexterity, and agility. Our results show that Astribot's cohesive integration of embodiment, teleoperation interface, and learning pipeline marks a significant step towards real-world, general-purpose whole-body robotic manipulation, laying the groundwork for the next generation of intelligent robots.",
      "authors": [
        "Guang Gao",
        "Jianan Wang",
        "Jinbo Zuo",
        "Junnan Jiang",
        "Jingfan Zhang",
        "Xianwen Zeng",
        "Yuejiang Zhu",
        "Lianyang Ma",
        "Ke Chen",
        "Minhua Sheng",
        "Ruirui Zhang",
        "Zhaohui An"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:23:41+00:00",
          "link": "https://arxiv.org/abs/2507.17141v1",
          "size": "12540kb",
          "version": "v1"
        }
      ],
      "title": "Towards Human-level Intelligence via Human-like Whole-Body Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17141",
        "HTML": "https://arxiv.org/html/2507.17141v1",
        "PDF": "https://arxiv.org/pdf/2507.17141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research aims at developing general-purpose intelligent robots through whole-body manipulation, unrelated to LLM training data processing. It involves robotics and not any aspect of data processing in the context of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17144",
      "abstract": "Flapping-wing drones have attracted significant attention due to their biomimetic flight. They are considered more human-friendly due to their characteristics such as low noise and flexible wings, making them suitable for human-drone interactions. However, few studies have explored the practical interaction between humans and flapping-wing drones. On establishing a physical interaction system with flapping-wing drones, we can acquire inspirations from falconers who guide birds of prey to land on their arms. This interaction interprets the human body as a dynamic landing platform, which can be utilized in various scenarios such as crowded or spatially constrained environments. Thus, in this study, we propose a falconry-like interaction system in which a flapping-wing drone performs a palm landing motion on a human hand. To achieve a safe approach toward humans, we design a trajectory planning method that considers both physical and psychological factors of the human safety such as the drone's velocity and distance from the user. We use a commercial flapping platform with our implemented motion planning and conduct experiments to evaluate the palm landing performance and safety. The results demonstrate that our approach enables safe and smooth hand landing interactions. To the best of our knowledge, it is the first time to achieve a contact-based interaction between flapping-wing drones and humans.",
      "authors": [
        "Kazuki Numazato",
        "Keiichiro Kan",
        "Masaki Kitagawa",
        "Yunong Li",
        "Johannes Kubel and Moju Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:25:03+00:00",
          "link": "https://arxiv.org/abs/2507.17144v1",
          "size": "3910kb",
          "version": "v1"
        }
      ],
      "title": "Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17144",
        "HTML": "https://arxiv.org/html/2507.17144v1",
        "PDF": "https://arxiv.org/pdf/2507.17144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with falconry-like palm landing by flapping-wing drones using human gesture interaction, which is not relevant to LLM training data processing. It addresses human-drone interaction and safety rather than language model data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17147",
      "abstract": "Role-Playing Language Agents (RPLAs) have emerged as a significant application direction for Large Language Models (LLMs). Existing approaches typically rely on prompt engineering or supervised fine-tuning to enable models to imitate character behaviors in specific scenarios, but often neglect the underlying \\emph{cognitive} mechanisms driving these behaviors. Inspired by cognitive psychology, we introduce \\textbf{CogDual}, a novel RPLA adopting a \\textit{cognize-then-respond } reasoning paradigm. By jointly modeling external situational awareness and internal self-awareness, CogDual generates responses with improved character consistency and contextual alignment. To further optimize the performance, we employ reinforcement learning with two general-purpose reward schemes designed for open-domain text generation. Extensive experiments on the CoSER benchmark, as well as Cross-MR and LifeChoice, demonstrate that CogDual consistently outperforms existing baselines and generalizes effectively across diverse role-playing tasks.",
      "authors": [
        "Cheng Liu",
        "Yifei Lu",
        "Fanghua Ye",
        "Jian Li",
        "Xingyu Chen",
        "Feiliang Ren",
        "Zhaopeng Tu",
        "Xiaolong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.17147v1",
          "size": "429kb",
          "version": "v1"
        }
      ],
      "title": "CogDual: Enhancing Dual Cognition of LLMs via Reinforcement Learning with Implicit Rule-Based Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17147",
        "PDF": "https://arxiv.org/pdf/2507.17147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the cognitive mechanisms and response generation in role-playing language agents using reinforcement learning. It does not address training data processing aspects for LLMs such as data collection, filtration, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17149",
      "abstract": "The significant morphological and distributional variability among subcellular components poses a long-standing challenge for learning-based organelle segmentation models, significantly increasing the risk of biased feature learning. Existing methods often rely on single mapping relationships, overlooking feature diversity and thereby inducing biased training. Although the Segment Anything Model (SAM) provides rich feature representations, its application to subcellular scenarios is hindered by two key challenges: (1) The variability in subcellular morphology and distribution creates gaps in the label space, leading the model to learn spurious or biased features. (2) SAM focuses on global contextual understanding and often ignores fine-grained spatial details, making it challenging to capture subtle structural alterations and cope with skewed data distributions. To address these challenges, we introduce ScSAM, a method that enhances feature robustness by fusing pre-trained SAM with Masked Autoencoder (MAE)-guided cellular prior knowledge to alleviate training bias from data imbalance. Specifically, we design a feature alignment and fusion module to align pre-trained embeddings to the same feature space and efficiently combine different representations. Moreover, we present a cosine similarity matrix-based class prompt encoder to activate class-specific features to recognize subcellular categories. Extensive experiments on diverse subcellular image datasets demonstrate that ScSAM outperforms state-of-the-art methods.",
      "authors": [
        "Bo Fang",
        "Jianan Fan",
        "Dongnan Liu",
        "Hang Chang",
        "Gerald J.Shami",
        "Filip Braet",
        "Weidong Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:28:43+00:00",
          "link": "https://arxiv.org/abs/2507.17149v1",
          "size": "7121kb",
          "version": "v1"
        }
      ],
      "title": "ScSAM: Debiasing Morphology and Distributional Variability in Subcellular Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17149",
        "HTML": "https://arxiv.org/html/2507.17149v1",
        "PDF": "https://arxiv.org/pdf/2507.17149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about debiasing morphology and enhancing segmentation models in subcellular semantic segmentation. It does not relate to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17151",
      "abstract": "Neural operators offer a powerful paradigm for solving partial differential equations (PDEs) that cannot be solved analytically by learning mappings between function spaces. However, there are two main bottlenecks in training neural operators: they require a significant amount of training data to learn these mappings, and this data needs to be labeled, which can only be accessed via expensive simulations with numerical solvers. To alleviate both of these issues simultaneously, we propose PICore, an unsupervised coreset selection framework that identifies the most informative training samples without requiring access to ground-truth PDE solutions. PICore leverages a physics-informed loss to select unlabeled inputs by their potential contribution to operator learning. After selecting a compact subset of inputs, only those samples are simulated using numerical solvers to generate labels, reducing annotation costs. We then train the neural operator on the reduced labeled dataset, significantly decreasing training time as well. Across four diverse PDE benchmarks and multiple coreset selection strategies, PICore achieves up to 78% average increase in training efficiency relative to supervised coreset selection methods with minimal changes in accuracy. We provide code at https://github.com/Asatheesh6561/PICore.",
      "authors": [
        "Anirudh Satheesh",
        "Anant Khandelwal",
        "Mucong Ding",
        "Radu Balan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:32:44+00:00",
          "link": "https://arxiv.org/abs/2507.17151v1",
          "size": "387kb",
          "version": "v1"
        }
      ],
      "title": "PICore: Physics-Informed Unsupervised Coreset Selection for Data Efficient Neural Operator Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17151",
        "HTML": "https://arxiv.org/html/2507.17151v1",
        "PDF": "https://arxiv.org/pdf/2507.17151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes an unsupervised coreset selection framework, which is a data-efficient training approach that selects informative samples for neural operator training. While it involves data selection, it is not specifically focused on LLMs or language data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17152",
      "abstract": "Predicting the future motion of road participants is a critical task in autonomous driving. In this work, we address the challenge of low-quality generation of low-probability modes in multi-agent joint prediction. To tackle this issue, we propose a two-stage multi-agent interactive prediction framework named \\textit{keypoint-guided joint prediction after classification-aware marginal proposal} (JAM). The first stage is modeled as a marginal prediction process, which classifies queries by trajectory type to encourage the model to learn all categories of trajectories, providing comprehensive mode information for the joint prediction module. The second stage is modeled as a joint prediction process, which takes the scene context and the marginal proposals from the first stage as inputs to learn the final joint distribution. We explicitly introduce key waypoints to guide the joint prediction module in better capturing and leveraging the critical information from the initial predicted trajectories. We conduct extensive experiments on the real-world Waymo Open Motion Dataset interactive prediction benchmark. The results show that our approach achieves competitive performance. In particular, in the framework comparison experiments, the proposed JAM outperforms other prediction frameworks and achieves state-of-the-art performance in interactive trajectory prediction. The code is available at https://github.com/LinFunster/JAM to facilitate future research.",
      "authors": [
        "Fangze Lin",
        "Ying He",
        "Fei Yu and Hong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:35:04+00:00",
          "link": "https://arxiv.org/abs/2507.17152v1",
          "size": "4879kb",
          "version": "v1"
        }
      ],
      "title": "JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17152",
        "HTML": "https://arxiv.org/html/2507.17152v1",
        "PDF": "https://arxiv.org/pdf/2507.17152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on predicting future motion in autonomous driving scenarios through a two-stage prediction framework. It does not contribute to LLM training data processing or involve techniques relevant to linguistic data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17155",
      "abstract": "Micro motors can be used in numerous fields like Micro medical testing and treatment. To achieve a smaller size, micro piezoelectric motors in laboratories often omit the outer casing, which can lead to functional defects such as rotation only in one fixed direction or the need for external weights (which are not counted within the motors volume) to increase preload. However, this significantly reduces the practical value of micro piezoelectric motors. This paper proposes a new driving principle for piezoelectric motors to design a micro piezoelectric motor that can rotate at a wide range of angles (e.g. up to 80)without increasing the motors casing and does not require external weights, with a stator thickness of only 0.8 mm. This motor has significant application potential in OCT endoscopes and thrombectomy grinding heads",
      "authors": [
        "Haijia Yu",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:42:42+00:00",
          "link": "https://arxiv.org/abs/2507.17155v1",
          "size": "1171kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Angle Rotational Actuation in a 0.8-mm-Thick Preload-Free Piezoelectric Micromotor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17155",
        "HTML": "https://arxiv.org/html/2507.17155v1",
        "PDF": "https://arxiv.org/pdf/2507.17155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the design of a piezoelectric micromotor for potential medical applications. It does not relate to LLM training data processing or any aspects of data processing for machine learning models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17156",
      "abstract": "With the rising volume of railroad transportation, the traditional track inspection mainly relies on manual inspection and large-scale inspection equipment, which not only has low inspection frequency and lagging response, but also has the defects of high risk, high cost and easy to miss inspection. To this end, this study designs and realizes a maintenance-free railroad track wireless monitoring system based on LoRa module LM401. Each monitoring node consists of an STM32 microcontroller, an LM401 LoRa transceiver, a low-power ADXL362 triaxial acceleration sensor, a digital temperature sensor (LMT85), and a digital barometric pressure sensor (RSCM17100KP101). The system collects vibration data through the SPI1 interface at the node end, periodically reads the temperature and barometric pressure information, and packages and sends the data to a centralized gateway within a range of 500 m using the LoRa star topology; the gateway then uploads the data in real time to a cloud server through a 4G module, which supports the MQTT protocol. MQTT protocol is supported. Laboratory tests and field deployments show that the system can realize acceleration resolution of 0.01 g, reduce maintenance cost by about 70%, and improve monitoring efficiency by more than 5 times. The system provides a reliable means for intelligent rail health management, and in the future, it is planned to introduce RF energy collection technology to realize automatic wake-up without battery, and expand to urban bridges, tunnels and environmental monitoring and other multi-scenario applications.",
      "authors": [
        "Honglin Zhang",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:42:50+00:00",
          "link": "https://arxiv.org/abs/2507.17156v1",
          "size": "703kb",
          "version": "v1"
        }
      ],
      "title": "Maintenance-free condition monitoring system based on lora",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17156",
        "HTML": "https://arxiv.org/html/2507.17156v1",
        "PDF": "https://arxiv.org/pdf/2507.17156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the design of a maintenance-free monitoring system for railroad tracks using LoRa technology. It does not address any aspect of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17157",
      "abstract": "Existing image contrast enhancement methods are typically designed for specific tasks such as under-/over-exposure correction, low-light and backlit image enhancement, etc. The learned models, however, exhibit poor generalization performance across different tasks, even across different datasets of a specific task. It is important to explore whether we can learn a universal and generalized model for various contrast enhancement tasks. In this work, we observe that the common key factor of these tasks lies in the need of exposure and contrast adjustment, which can be well-addressed if high-dynamic range (HDR) inputs are available. We hence collect 46,928 HDR raw images from public sources, and render 328,496 sRGB images to build multi-exposure sequences (MES) and the corresponding pseudo sRGB ground-truths via multi-exposure fusion. Consequently, we train a network to generate an MES from a single sRGB image, followed by training another network to fuse the generated MES into an enhanced image. Our proposed method, namely UNiversal Image Contrast Enhancer (UNICE), is free of costly human labeling. However, it demonstrates significantly stronger generalization performance than existing image contrast enhancement methods across and within different tasks, even outperforming manually created ground-truths in multiple no-reference image quality metrics. The dataset, code and model are available at https://github.com/BeyondHeaven/UNICE.",
      "authors": [
        "Ruodai Cui",
        "Lei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:43:09+00:00",
          "link": "https://arxiv.org/abs/2507.17157v1",
          "size": "25261kb",
          "version": "v1"
        }
      ],
      "title": "UNICE: Training A Universal Image Contrast Enhancer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17157",
        "HTML": "https://arxiv.org/html/2507.17157v1",
        "PDF": "https://arxiv.org/pdf/2507.17157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a universal image contrast enhancement method and dataset, focusing on image processing tasks rather than LLM training, and thus is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17158",
      "abstract": "Ocular biometrics in the visible spectrum have emerged as a prominent modality due to their high accuracy, resistance to spoofing, and non-invasive nature. However, morphing attacks, synthetic biometric traits created by blending features from multiple individuals, threaten biometric system integrity. While extensively studied for near-infrared iris and face biometrics, morphing in visible-spectrum ocular data remains underexplored. Simulating such attacks demands advanced generation models that handle uncontrolled conditions while preserving detailed ocular features like iris boundaries and periocular textures. To address this gap, we introduce DOOMGAN, that encompasses landmark-driven encoding of visible ocular anatomy, attention-guided generation for realistic morph synthesis, and dynamic weighting of multi-faceted losses for optimized convergence. DOOMGAN achieves over 20% higher attack success rates than baseline methods under stringent thresholds, along with 20% better elliptical iris structure generation and 30% improved gaze consistency. We also release the first comprehensive ocular morphing dataset to support further research in this domain.",
      "authors": [
        "Bharath Krishnamurthy and Ajita Rattani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:43:49+00:00",
          "link": "https://arxiv.org/abs/2507.17158v1",
          "size": "23871kb",
          "version": "v1"
        }
      ],
      "title": "DOOMGAN:High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17158",
        "HTML": "https://arxiv.org/html/2507.17158v1",
        "PDF": "https://arxiv.org/pdf/2507.17158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces DOOMGAN for generating synthetic biometric traits in ocular biometrics. Although it involves dataset creation, its focus is on biometric system security, not LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17161",
      "abstract": "Modern network intrusion detection systems (NIDS) frequently utilize the predictive power of complex deep learning models. However, the \"black-box\" nature of such deep learning methods adds a layer of opaqueness that hinders the proper understanding of detection decisions, trust in the decisions and prevent timely countermeasures against such attacks. Explainable AI (XAI) methods provide a solution to this problem by providing insights into the causes of the predictions. The majority of the existing XAI methods provide explanations which are not convenient to convert into actionable countermeasures. In this work, we propose a novel diffusion-based counterfactual explanation framework that can provide actionable explanations for network intrusion attacks. We evaluated our proposed algorithm against several other publicly available counterfactual explanation algorithms on 3 modern network intrusion datasets. To the best of our knowledge, this work also presents the first comparative analysis of existing counterfactual explanation algorithms within the context of network intrusion detection systems. Our proposed method provide minimal, diverse counterfactual explanations out of the tested counterfactual explanation algorithms in a more efficient manner by reducing the time to generate explanations. We also demonstrate how counterfactual explanations can provide actionable explanations by summarizing them to create a set of global rules. These rules are actionable not only at instance level but also at the global level for intrusion attacks. These global counterfactual rules show the ability to effectively filter out incoming attack queries which is crucial for efficient intrusion detection and defense mechanisms.",
      "authors": [
        "Vinura Galwaduge",
        "Jagath Samarabandu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.17161v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "Tabular Diffusion based Actionable Counterfactual Explanations for Network Intrusion Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17161",
        "PDF": "https://arxiv.org/pdf/2507.17161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a counterfactual explanation framework for network intrusion detection systems. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17163",
      "abstract": "With a slender redundant body, the tendon-driven robot (TDR) has a large workspace and great maneuverability while working in complex environments. TDR comprises multiple independently controlled robot segments, each with a set of driving tendons. While increasing the number of robot segments enhances dexterity and expands the workspace, this structural expansion also introduces intensified inter-segmental coupling. Therefore, achieving precise TDR control requires more complex models and additional motors. This paper presents a reconfigurable tendon-driven robot (RTR) equipped with innovative lockable joints. Each joint's state (locked/free) can be individually controlled through a pair of antagonistic tendons, and its structure eliminates the need for a continuous power supply to maintain the state. Operators can selectively actuate the targeted robot segments, and this scheme fundamentally eliminates the inter-segmental coupling, thereby avoiding the requirement for complex coordinated control between segments. The workspace of RTR has been simulated and compared with traditional TDRs' workspace, and RTR's advantages are further revealed. The kinematics and statics models of the RTR have been derived and validation experiments have been conducted. Demonstrations have been performed using a seven-joint RTR prototype to show its reconfigurability and moving ability in complex environments with an actuator pack comprising only six motors.",
      "authors": [
        "Botao Lin",
        "Shuang Song and Jiaole Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:09:22+00:00",
          "link": "https://arxiv.org/abs/2507.17163v1",
          "size": "1652kb",
          "version": "v1"
        }
      ],
      "title": "Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17163",
        "HTML": "https://arxiv.org/html/2507.17163v1",
        "PDF": "https://arxiv.org/pdf/2507.17163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reconfigurable tendon-driven robots with lockable joints to eliminate inter-segmental coupling, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17165",
      "abstract": "Continuous Integration (CI) services, such as GitHub Actions, require developers to write YAML-based configurations, which can be tedious and error-prone. Despite the increasing use of Large Language Models (LLMs) to automate software engineering tasks, their ability to generate CI configurations remains underexplored. This paper presents a preliminary study evaluating six LLMs for generating GitHub Actions configurations from natural language descriptions. We assess three general-purpose foundation models (GPT-4o, Llama, and Gemma) and three code-pretrained models (GPT-4.1, Code Llama, and CodeGemma). We also introduce the first labeled dataset of its kind, constructed from GitHub Actions documentation, pairing descriptions with corresponding best-practice YAML configurations. Zero-shot prompting achieves up to 69% similarity with the ground truth, with only 3% perfect matches. Code-pretrained models slightly underperform compared to general-purpose ones in YAML-based CI tasks, revealing LLM limitations for CI configuration generation. Analyzing GPT-4o outputs reveals issues like missing or renamed steps, misinterpreted descriptions, and unnecessary additions that may affect structural and contextual correctness, indicating a gap between generation quality and the precision required for executable CI configurations. Our research offers insights for improving LLM alignment with configuration languages and guiding future efforts on CI automation and tooling support.",
      "authors": [
        "Taher A. Ghaleb and Dulina Rathnayake"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:18:04+00:00",
          "link": "https://arxiv.org/abs/2507.17165v1",
          "size": "298kb",
          "version": "v1"
        }
      ],
      "title": "Can LLMs Write CI? A Study on Automatic Generation of GitHub Actions Configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17165",
        "HTML": "https://arxiv.org/html/2507.17165v1",
        "PDF": "https://arxiv.org/pdf/2507.17165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset for GitHub Actions configurations which could support fine-tuning of LLMs for CI configuration generation. However, the primary focus is on evaluating and improving LLM capabilities for software engineering tasks, not directly on data processing techniques for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17168",
      "abstract": "Large Language Models (LLMs) have made remarkable strides in reasoning tasks, yet their performance often falters on novel and complex problems. Domain-specific continued pretraining (CPT) methods, such as those tailored for mathematical reasoning, have shown promise but lack transferability to broader reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning (GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks, spanning pathfinding, network analysis, numerical computation, and topological reasoning, require sophisticated logical and relational reasoning, making them ideal for teaching diverse reasoning patterns. To achieve this, we introduce GraphPile, the first large-scale corpus specifically designed for CPT using GPR data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes chain-of-thought, program-of-thought, trace of execution, and real-world graph data. Using GraphPile, we train GraphMind on popular base models Llama 3 and 3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in mathematical reasoning and up to 21.2 percent improvement in non-mathematical reasoning tasks such as logical and commonsense reasoning. By being the first to harness GPR for enhancing reasoning patterns and introducing the first dataset of its kind, our work bridges the gap between domain-specific pretraining and universal reasoning capabilities, advancing the adaptability and robustness of LLMs.",
      "authors": [
        "Qifan Zhang",
        "Nuo Chen",
        "Zehua Li",
        "Miao Peng",
        "Jing Tang",
        "Jia Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:19:57+00:00",
          "link": "https://arxiv.org/abs/2507.17168v1",
          "size": "1776kb",
          "version": "v1"
        }
      ],
      "title": "Improving LLMs' Generalized Reasoning Abilities by Graph Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17168",
        "PDF": "https://arxiv.org/pdf/2507.17168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces GraphPile, a large dataset specifically designed for continued pretraining of LLMs on graph problem reasoning. This represents a direct contribution to LLM training data processing through the creation of a new high-quality dataset."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17170",
      "abstract": "Quantum state preparation (QSP) is a fundamental task in quantum computing and quantum information processing. It is critical to the execution of many quantum algorithms, including those in quantum machine learning. In this paper, we propose a family of efficient QSP algorithms tailored to different numbers of available ancilla qubits - ranging from no ancilla qubits, to a single ancilla qubit, to a sufficiently large number of ancilla qubits. Our algorithms are based on a novel decision diagram that is fundamentally different from the approaches used in previous QSP algorithms. Specifically, our approach exploits the power of Local Invertible Map Tensor Decision Diagrams (LimTDDs) - a highly compact representation of quantum states that combines tensor networks and decision diagrams to reduce quantum circuit complexity. Extensive experiments demonstrate that our methods significantly outperform existing approaches and exhibit better scalability for large-scale quantum states, both in terms of runtime and gate complexity. Furthermore, our method shows exponential improvement in best-case scenarios. This paper is an extended version of [1], with three more algorithms proposed.",
      "authors": [
        "Xin Hong",
        "Aochu Dai",
        "Chenjian Li",
        "Sanjiang Li",
        "Shenggang Ying",
        "and Mingsheng Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:34:44+00:00",
          "link": "https://arxiv.org/abs/2507.17170v1",
          "size": "1134kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Quantum State Preparation using LimTDD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17170",
        "PDF": "https://arxiv.org/pdf/2507.17170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum state preparation using a novel decision diagram, which is unrelated to processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17171",
      "abstract": "Since the introduction of Digital Engineering (DE) as a well-defined concept in 2018, organizations and industry groups have been working to interpret the DE concepts to establish consistent meta-models of those interrelated concepts for integration into their DE processes and tools. To reach the breadth and depth of DE concept definitions, the interpretation of international standard sources is necessary, including ISO/IEC/IEEE 15288, 24765, 42000-series, 15408, 15206, 27000-series, and 25000-series, to effectively model the knowledge domain where digital engineering applies. The harmonization of the concepts used in these international standards continues to improve with each revision, but it may be more effectively accomplished by relying on the descriptive logic formalized in the Web Ontology Language (OWL 2 DL). This paper presents a verified and consistent ontology based on the Basic Formal Ontology (BFO) and Common Core Ontologies (CCO) that defines Seamless Digital Engineering as a digital tooling paradigm that relies on formal verification of digital interfaces to provide a system-level qualification of the assured integrity of a Digital Engineering Environment. The present work defines classes and equivalence axioms, while using only the BFO- and CCO-defined object properties that relate them, to provide a baseline analysis that may inform future DE-related ontology development, using a case study to formally define the `seamless' quality in relation to the updated ISO 25010 SQuaRE product quality model. We identified ISO meta-model inconsistencies that are resolvable using the BFO/CCO ontological framework, and define `seamless' as both a system integration quality and a Human-Computer Interface quality-in-use, working to disambiguate this concept in the context of DE.",
      "authors": [
        "James S. Wheaton and Daniel R. Herber"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:35:16+00:00",
          "link": "https://arxiv.org/abs/2507.17171v1",
          "size": "4797kb",
          "version": "v1"
        }
      ],
      "title": "Ontological Definition of Seamless Digital Engineering Based on ISO/IEC 25000-Series SQuaRE Product Quality Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17171",
        "HTML": "https://arxiv.org/html/2507.17171v1",
        "PDF": "https://arxiv.org/pdf/2507.17171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an ontological framework for seamless digital engineering, but does not engage with any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17174",
      "abstract": "Despite the widespread use of Uniform Manifold Approximation and Projection (UMAP), the impact of its stochastic optimization process on the results remains underexplored. We observed that it often produces unstable results where the projections of data points are determined mostly by chance rather than reflecting neighboring structures. To address this limitation, we introduce (r,d)-stability to UMAP: a framework that analyzes the stochastic positioning of data points in the projection space. To assess how stochastic elements, specifically initial projection positions and negative sampling, impact UMAP results, we introduce \"ghosts\", or duplicates of data points representing potential positional variations due to stochasticity. We define a data point's projection as (r,d)-stable if its ghosts perturbed within a circle of radius r in the initial projection remain confined within a circle of radius d for their final positions. To efficiently compute the ghost projections, we develop an adaptive dropping scheme that reduces a runtime up to 60% compared to an unoptimized baseline while maintaining approximately 90% of unstable points. We also present a visualization tool that supports the interactive exploration of the (r,d)-stability of data points. Finally, we demonstrate the effectiveness of our framework by examining the stability of projections of real-world datasets and present usage guidelines for the effective use of our framework.",
      "authors": [
        "Myeongwon Jung",
        "Takanori Fujiwara",
        "and Jaemin Jo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:40:53+00:00",
          "link": "https://arxiv.org/abs/2507.17174v1",
          "size": "7850kb",
          "version": "v1"
        }
      ],
      "title": "GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17174",
        "HTML": "https://arxiv.org/html/2507.17174v1",
        "PDF": "https://arxiv.org/pdf/2507.17174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a new framework for analyzing the stochastic behavior of UMAP, a dimensionality reduction technique. It does not address any aspect of LLM training data processing such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17176",
      "abstract": "With the high density of printed circuit board (PCB) design and the high speed of production, the traditional PCB defect detection model is difficult to take into account the accuracy and computational cost, and cannot meet the requirements of high accuracy and real-time detection of tiny defects. Therefore, in this paper, a multi-scale PCB defect detection method is improved with YOLOv8 using a comprehensive strategy of tiny target sensitivity strategy, network lightweighting and adaptive pruning, which is able to improve the detection speed and accuracy by optimizing the backbone network, the neck network and the detection head, the loss function and the adaptive pruning rate. Firstly, a Ghost-HGNetv2 structure with fewer parameters is used in the backbone network, and multilevel features are used to extract image semantic features to discover accurate defects. Secondly, we integrate C2f-Faster with small number of parameters in the neck section to enhance the ability of multi-level feature fusion. Next, in the Head part, we design a new GCDetect detection head, which allows the prediction of bounding boxes and categories to share the weights of GroupConv, and uses a small number of grouping convolutions to accomplish the regression and classification tasks, which significantly reduces the number of parameters while maintaining the accuracy of detection. We also design the Inner-MPDIoU boundary loss function to improve the detection and localization of tiny targets. Finally, the model was pruned by an optimized adaptive pruning rate to further reduce the complexity of the model. Experimental results show that the model exhibits advantages in terms of accuracy and speed. On the publicly available PCB defect dataset, mAP0.5 reaches 99.32% and mAP0.5:0.9 reaches 75.18%, which is 10.13% higher compared to YOLOv8n.",
      "authors": [
        "Li Pingzhen",
        "Xu Sheng",
        "Chen Jing",
        "Su Chengyue"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:47:00+00:00",
          "link": "https://arxiv.org/abs/2507.17176v1",
          "size": "1779kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Scale PCB Defect Detection with YOLOv8 Network Improved via Pruning and Lightweight Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17176",
        "PDF": "https://arxiv.org/pdf/2507.17176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving PCB defect detection models using the YOLOv8 network. It emphasizes model architecture and optimization techniques, with no focus on data processing related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17177",
      "abstract": "In social networks, it is often of interest to identify the most influential users who can successfully spread information to others. This is particularly important for marketing (e.g., targeting influencers for a marketing campaign) and to understand the dynamics of information diffusion (e.g., who is the most central user in the spreading of a certain type of information). However, different opinions often split the audience and make the network polarised. In polarised networks, information becomes soiled within communities in the network, and the most influential user within a network might not be the most influential across all communities. Additionally, influential users and their influence may change over time as users may change their opinion or choose to decrease or halt their engagement on the subject. In this work, we aim to study the temporal dynamics of users' influence in a polarised social network. We compare the stability of influence ranking using temporal centrality measures, while extending them to account for community structure across a number of network evolution behaviours. We show that we can successfully aggregate nodes into influence bands, and how to aggregate centrality scores to analyse the influence of communities over time. A modified version of the temporal independent cascade model and the temporal degree centrality perform the best in this setting, as they are able to reliably isolate nodes into their bands.",
      "authors": [
        "Caroline B. Pena",
        "David J.P. O'Sullivan",
        "P\\'adraig MacCarron",
        "Akrati Saxena"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:51:07+00:00",
          "link": "https://arxiv.org/abs/2507.17177v1",
          "size": "46282kb",
          "version": "v1"
        }
      ],
      "title": "Dynamics of temporal influence in polarised networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17177",
        "HTML": "https://arxiv.org/html/2507.17177v1",
        "PDF": "https://arxiv.org/pdf/2507.17177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the dynamics of user influence in polarised networks. It does not make any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17178",
      "abstract": "Although large language models (LLMs) have made significant progress in understanding Structured Knowledge (SK) like KG and Table, existing evaluations for SK understanding are non-rigorous (i.e., lacking evaluations of specific capabilities) and focus on a single type of SK. Therefore, we aim to propose a more comprehensive and rigorous structured knowledge understanding benchmark to diagnose the shortcomings of LLMs. In this paper, we introduce SKA-Bench, a Structured Knowledge Augmented QA Benchmark that encompasses four widely used structured knowledge forms: KG, Table, KG+Text, and Table+Text. We utilize a three-stage pipeline to construct SKA-Bench instances, which includes a question, an answer, positive knowledge units, and noisy knowledge units. To evaluate the SK understanding capabilities of LLMs in a fine-grained manner, we expand the instances into four fundamental ability testbeds: Noise Robustness, Order Insensitivity, Information Integration, and Negative Rejection. Empirical evaluations on 8 representative LLMs, including the advanced DeepSeek-R1, indicate that existing LLMs still face significant challenges in understanding structured knowledge, and their performance is influenced by factors such as the amount of noise, the order of knowledge units, and hallucination phenomenon. Our dataset and code are available at https://github.com/Lza12a/SKA-Bench.",
      "authors": [
        "Zhiqiang Liu",
        "Enpei Niu",
        "Yin Hua",
        "Mengshu Sun",
        "Lei Liang",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T03:52:24+00:00",
          "link": "https://arxiv.org/abs/2507.17178v1",
          "size": "2029kb",
          "version": "v1"
        }
      ],
      "title": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17178",
        "HTML": "https://arxiv.org/html/2507.17178v1",
        "PDF": "https://arxiv.org/pdf/2507.17178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces SKA-Bench, a benchmark for evaluating structured knowledge understanding in LLMs, focusing on evaluation methodologies rather than training data processing per se. While it involves dataset creation, its main focus is not on data processing for training purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17180",
      "abstract": "Data perturbation-based privacy-preserving methods have been widely adopted in various scenarios due to their efficiency and the elimination of the need for a trusted third party. However, these methods primarily focus on individual statistical indicators, neglecting the overall quality of the collected data from a distributional perspective. Consequently, they often fall short of meeting the diverse statistical analysis requirements encountered in practical data analysis. As a promising sensitive data perturbation method, negative survey methods is able to complete the task of collecting sensitive information distribution while protecting personal privacy. Yet, existing negative survey methods are primarily designed for discrete sensitive information and are inadequate for real-valued data distributions. To bridge this gap, this paper proposes a novel real-value negative survey model, termed RVNS, for the first time in the field of real-value sensitive information collection. The RVNS model exempts users from the necessity of discretizing their data and only requires them to sample a set of data from a range that deviates from their actual sensitive details, thereby preserving the privacy of their genuine information. Moreover, to accurately capture the distribution of sensitive information, an optimization problem is formulated, and a novel approach is employed to solve it. Rigorous theoretical analysis demonstrates that the RVNS model conforms to the differential privacy model, ensuring robust privacy preservation. Comprehensive experiments conducted on both synthetic and real-world datasets further validate the efficacy of the proposed method.",
      "authors": [
        "Hao Jiang",
        "Quan Zhou",
        "Dongdong Zhao",
        "Shangshang Yang",
        "Wenjian Luo",
        "and Xingyi Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:05:33+00:00",
          "link": "https://arxiv.org/abs/2507.17180v1",
          "size": "3281kb",
          "version": "v1"
        }
      ],
      "title": "A Privacy-Preserving Data Collection Method for Diversified Statistical Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17180",
        "HTML": "https://arxiv.org/html/2507.17180v1",
        "PDF": "https://arxiv.org/pdf/2507.17180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a privacy-preserving method for data collection aimed at various statistical analyses, not specifically related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17182",
      "abstract": "The quality assessment of AI-generated content (AIGC) faces multi-dimensional challenges, that span from low-level visual perception to high-level semantic understanding. Existing methods generally rely on single-level visual features, limiting their ability to capture complex distortions in AIGC images. To address this limitation, a multi-level visual representation paradigm is proposed with three stages, namely multi-level feature extraction, hierarchical fusion, and joint aggregation. Based on this paradigm, two networks are developed. Specifically, the Multi-Level Global-Local Fusion Network (MGLF-Net) is designed for the perceptual quality assessment, extracting complementary local and global features via dual CNN and Transformer visual backbones. The Multi-Level Prompt-Embedded Fusion Network (MPEF-Net) targets Text-to-Image correspondence by embedding prompt semantics into the visual feature fusion process at each feature level. The fused multi-level features are then aggregated for final evaluation. Experiments on benchmarks demonstrate outstanding performance on both tasks, validating the effectiveness of the proposed multi-level visual assessment paradigm.",
      "authors": [
        "Linghe Meng",
        "Jiarun Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:12:32+00:00",
          "link": "https://arxiv.org/abs/2507.17182v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Fusion and Joint Aggregation: A Multi-Level Feature Representation Method for AIGC Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17182",
        "PDF": "https://arxiv.org/pdf/2507.17182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on image quality assessment for AI-generated content using multi-level feature representation, which is outside the scope of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17183",
      "abstract": "Understanding and predicting the behavior of large-scale multi-agents in games remains a fundamental challenge in multi-agent systems. This paper examines the role of heterogeneity in equilibrium formation by analyzing how smooth regret-matching drives a large number of heterogeneous agents with diverse initial policies toward unified behavior. By modeling the system state as a probability distribution of regrets and analyzing its evolution through the continuity equation, we uncover a key phenomenon in diverse multi-agent settings: the variance of the regret distribution diminishes over time, leading to the disappearance of heterogeneity and the emergence of consensus among agents. This universal result enables us to prove convergence to quantal response equilibria in both competitive and cooperative multi-agent settings. Our work advances the theoretical understanding of multi-agent learning and offers a novel perspective on equilibrium selection in diverse game-theoretic scenarios.",
      "authors": [
        "Die Hu",
        "Shuyue Hu",
        "Chunjiang Mu",
        "Shiqi Fan",
        "Chen Chu",
        "Jinzhuo Liu",
        "Zhen Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:13:56+00:00",
          "link": "https://arxiv.org/abs/2507.17183v1",
          "size": "4261kb",
          "version": "v1"
        }
      ],
      "title": "Regret Minimization in Population Network Games: Vanishing Heterogeneity and Convergence to Equilibria",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17183",
        "HTML": "https://arxiv.org/html/2507.17183v1",
        "PDF": "https://arxiv.org/pdf/2507.17183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with regret minimization and convergence in multi-agent network games, which is unrelated to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17184",
      "abstract": "In the current practices of both industry and academia, the convergence and accuracy of finite element calculations are closely related to the methods and quality of mesh generation. For years, the research on high-quality mesh generation in the domestic academic field has mainly referred to the local quality of quadrilaterals and hexahedrons approximating that of squares and cubes. The main contribution of this paper is to propose a brand-new research direction and content: it is necessary to explore and study the influence of the overall global arrangement structure and pattern of super structured quadrilateral meshes on the convergence and calculation accuracy of finite element calculations. Through the research in this new field, it can help solve the non-rigorous state of serious reliance on \"experience\" in the mesh generation stage during simulation in the current industry and academia, and make clear judgments on which global arrangements of mesh generation can ensure the convergence of finite element calculations. In order to generate and design super-structured quadrilateral meshes with controllable overall arrangement structures, a large number of modern two-dimensional and three-dimensional geometric topology theories are required, such as moduli space, Teichm\\\"uller space, harmonic foliations, dynamical systems, surface mappings, meromorphic quadratic differentials, surface mappings, etc.",
      "authors": [
        "Hui Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:16:15+00:00",
          "link": "https://arxiv.org/abs/2507.17184v1",
          "size": "5514kb",
          "version": "v1"
        }
      ],
      "title": "A Scientist Question: Research on the Impact of Super Structured Quadrilateral Meshes on Convergence and Accuracy of Finite Element Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17184",
        "PDF": "https://arxiv.org/pdf/2507.17184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research pertains to mesh generation for finite element analysis, which does not contribute to the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17185",
      "abstract": "In dermoscopic images, which allow visualization of surface skin structures not visible to the naked eye, lesion shape offers vital insights into skin diseases. In clinically practiced methods, asymmetric lesion shape is one of the criteria for diagnosing melanoma. Initially, we labeled data for a non-annotated dataset with symmetrical information based on clinical assessments. Subsequently, we propose a supporting technique, a supervised learning image processing algorithm, to analyze the geometrical pattern of lesion shape, aiding non-experts in understanding the criteria of an asymmetric lesion. We then utilize a pre-trained convolutional neural network (CNN) to extract shape, color, and texture features from dermoscopic images for training a multiclass support vector machine (SVM) classifier, outperforming state-of-the-art methods from the literature. In the geometry-based experiment, we achieved a 99.00% detection rate for dermatological asymmetric lesions. In the CNN-based experiment, the best performance is found with 94% Kappa Score, 95% Macro F1-score, and 97% Weighted F1-score for classifying lesion shapes (Asymmetric, Half-Symmetric, and Symmetric).",
      "authors": [
        "M. A. Rasel",
        "Sameem Abdul Kareem",
        "Zhenli Kwan",
        "Nik Aimee Azizah Faheem",
        "Winn Hui Han",
        "Rebecca Kai Jan Choong",
        "Shin Shen Yong",
        "Unaizah Obaidellah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:17:57+00:00",
          "link": "https://arxiv.org/abs/2507.17185v1",
          "size": "769kb",
          "version": "v1"
        }
      ],
      "title": "Asymmetric Lesion Detection with Geometric Patterns and CNN-SVM Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17185",
        "PDF": "https://arxiv.org/pdf/2507.17185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates an image processing algorithm for lesion detection in dermoscopic images, focusing on CNN-SVM classification, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17186",
      "abstract": "The booming development of AI agents presents unprecedented opportunities for automating complex tasks across various domains. However, their multi-step, multi-tool collaboration capabilities in the financial sector remain underexplored. This paper introduces FinGAIA, an end-to-end benchmark designed to evaluate the practical abilities of AI agents in the financial domain. FinGAIA comprises 407 meticulously crafted tasks, spanning seven major financial sub-domains: securities, funds, banking, insurance, futures, trusts, and asset management. These tasks are organized into three hierarchical levels of scenario depth: basic business analysis, asset decision support, and strategic risk management. We evaluated 10 mainstream AI agents in a zero-shot setting. The best-performing agent, ChatGPT, achieved an overall accuracy of 48.9\\%, which, while superior to non-professionals, still lags financial experts by over 35 percentage points. Error analysis has revealed five recurring failure patterns: Cross-modal Alignment Deficiency, Financial Terminological Bias, Operational Process Awareness Barrier, among others. These patterns point to crucial directions for future research. Our work provides the first agent benchmark closely related to the financial domain, aiming to objectively assess and promote the development of agents in this crucial field. Partial data is available at https://github.com/SUFE-AIFLM-Lab/FinGAIA.",
      "authors": [
        "Lingfeng Zeng",
        "Fangqi Lou",
        "Zixuan Wang",
        "Jiajie Xu",
        "Jinyi Niu",
        "Mengping Li",
        "Yifan Dong",
        "Qi Qi",
        "Wei Zhang",
        "Ziwei Yang",
        "Jun Han",
        "Ruilun Feng",
        "Ruiqi Hu",
        "Lejie Zhang",
        "Zhengbo Feng",
        "Yicheng Ren",
        "Xin Guo",
        "Zhaowei Liu",
        "Dongpo Cheng",
        "Weige Cai",
        "Liwen Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:19:16+00:00",
          "link": "https://arxiv.org/abs/2507.17186v1",
          "size": "8681kb",
          "version": "v1"
        }
      ],
      "title": "FinGAIA: An End-to-End Benchmark for Evaluating AI Agents in Finance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17186",
        "HTML": "https://arxiv.org/html/2507.17186v1",
        "PDF": "https://arxiv.org/pdf/2507.17186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "FinGAIA is a benchmark for evaluating AI agents in finance, not contributing to LLM training data processing operations such as data collection or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17188",
      "abstract": "This work tackles the physical layer security (PLS) problem of maximizing the secrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy constraints. Unlike prior studies that assume uniform UAV capabilities or overlook energy-security trade-offs, we consider a realistic scenario where UAVs with diverse payloads and computation resources collaborate to serve ground terminals in the presence of eavesdroppers. To manage the complex coupling between UAV motion and communication, we propose a hierarchical optimization framework. The inner layer uses a semidefinite relaxation (SDR)-based S2DC algorithm combining penalty functions and difference-of-convex (d.c.) programming to solve the secrecy precoding problem with fixed UAV positions. The outer layer introduces a Large Language Model (LLM)-guided heuristic multi-agent reinforcement learning approach (LLM-HeMARL) for trajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics policy generated by the LLM, enabling UAVs to learn energy-aware, security-driven trajectories without the inference overhead of real-time LLM calls. The simulation results show that our method outperforms existing baselines in secrecy rate and energy efficiency, with consistent robustness across varying UAV swarm sizes and random seeds.",
      "authors": [
        "Lijie Zheng",
        "Ji He",
        "Shih Yu Chang",
        "Yulong Shen and Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:22:57+00:00",
          "link": "https://arxiv.org/abs/2507.17188v1",
          "size": "1246kb",
          "version": "v1"
        }
      ],
      "title": "LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17188",
        "HTML": "https://arxiv.org/html/2507.17188v1",
        "PDF": "https://arxiv.org/pdf/2507.17188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on UAV networks for secure communication, with no mention of LLM training data processing or related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17189",
      "abstract": "The increasing frequency of extreme weather events due to global climate change urges accurate weather prediction. Recently, great advances have been made by the \\textbf{end-to-end methods}, thanks to deep learning techniques, but they face limitations of \\textit{representation inconsistency} in multivariable integration and struggle to effectively capture the dependency between variables, which is required in complex weather systems. Treating different variables as distinct modalities and applying a \\textbf{two-stage training approach} from multimodal models can partially alleviate this issue, but due to the inconformity in training tasks between the two stages, the results are often suboptimal. To address these challenges, we propose an implicit two-stage training method, configuring separate encoders and decoders for each variable. In detailed, in the first stage, the Translator is frozen while the Encoders and Decoders learn a shared latent space, in the second stage, the Encoders and Decoders are frozen, and the Translator captures inter-variable interactions for prediction. Besides, by introducing a self-attention mechanism for multivariable fusion in the latent space, the performance achieves further improvements. Empirically, extensive experiments show the state-of-the-art performance of our method. Specifically, it reduces the MSE for near-surface air temperature and relative humidity predictions by 28.82\\% and 23.39\\%, respectively. The source code is available at https://github.com/ShremG/Met2Net.",
      "authors": [
        "Shaohan Li",
        "Hao Yang",
        "Min Chen",
        "Xiaolin Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:26:56+00:00",
          "link": "https://arxiv.org/abs/2507.17189v1",
          "size": "14249kb",
          "version": "v1"
        }
      ],
      "title": "Met$^2$Net: A Decoupled Two-Stage Spatio-Temporal Forecasting Model for Complex Meteorological Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17189",
        "HTML": "https://arxiv.org/html/2507.17189v1",
        "PDF": "https://arxiv.org/pdf/2507.17189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a spatio-temporal forecasting model for meteorological systems, without any connection to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17192",
      "abstract": "When synthesizing identities as face recognition training data, it is generally believed that large inter-class separability and intra-class attribute variation are essential for synthesizing a quality dataset. % This belief is generally correct, and this is what we aim for. However, when increasing intra-class variation, existing methods overlook the necessity of maintaining intra-class identity consistency. % To address this and generate high-quality face training data, we propose Vec2Face+, a generative model that creates images directly from image features and allows for continuous and easy control of face identities and attributes. Using Vec2Face+, we obtain datasets with proper inter-class separability and intra-class variation and identity consistency using three strategies: 1) we sample vectors sufficiently different from others to generate well-separated identities; 2) we propose an AttrOP algorithm for increasing general attribute variations; 3) we propose LoRA-based pose control for generating images with profile head poses, which is more efficient and identity-preserving than AttrOP. % Our system generates VFace10K, a synthetic face dataset with 10K identities, which allows an FR model to achieve state-of-the-art accuracy on seven real-world test sets. Scaling the size to 4M and 12M images, the corresponding VFace100K and VFace300K datasets yield higher accuracy than the real-world training dataset, CASIA-WebFace, on five real-world test sets. This is the first time a synthetic dataset beats the CASIA-WebFace in average accuracy. In addition, we find that only 1 out of 11 synthetic datasets outperforms random guessing (\\emph{i.e., 50\\%}) in twin verification and that models trained with synthetic identities are more biased than those trained with real identities. Both are important aspects for future investigation.",
      "authors": [
        "Haiyu Wu",
        "Jaskirat Singh",
        "Sicong Tian",
        "Liang Zheng",
        "Kevin W. Bowyer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:34:56+00:00",
          "link": "https://arxiv.org/abs/2507.17192v1",
          "size": "10995kb",
          "version": "v1"
        }
      ],
      "title": "Vec2Face+ for Face Dataset Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17192",
        "HTML": "https://arxiv.org/html/2507.17192v1",
        "PDF": "https://arxiv.org/pdf/2507.17192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents Vec2Face+, a generative model that creates synthetic face datasets, demonstrating a significant contribution to the generation of new datasets for training, which is a core aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17194",
      "abstract": "Optimal transmission switching (OTS) improves optimal power flow (OPF) by selectively opening transmission lines, but its mixed-integer formulation increases computational complexity, especially on large grids. To deal with this, we propose a dispatch-aware deep neural network (DA-DNN) that accelerates DC-OTS without relying on pre-solved labels. DA-DNN predicts line states and passes them through a differentiable DC-OPF layer, using the resulting generation cost as the loss function so that all physical network constraints are enforced throughout training and inference. In addition, we adopt a customized weight-bias initialization that keeps every forward pass feasible from the first iteration, which allows stable learning on large grids. Once trained, the proposed DA-DNN produces a provably feasible topology and dispatch pair in the same time as solving the DCOPF, whereas conventional mixed-integer solvers become intractable. As a result, the proposed method successfully captures the economic advantages of OTS while maintaining scalability.",
      "authors": [
        "Minsoo Kim",
        "Jip Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:39:29+00:00",
          "link": "https://arxiv.org/abs/2507.17194v1",
          "size": "191kb",
          "version": "v1"
        }
      ],
      "title": "Dispatch-Aware Deep Neural Network for Optimal Transmission Switching: Toward Real-Time and Feasibility Guaranteed Operation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17194",
        "HTML": "https://arxiv.org/html/2507.17194v1",
        "PDF": "https://arxiv.org/pdf/2507.17194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses power grid optimization using neural networks, without any contribution or mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17195",
      "abstract": "Timely and efficient dissemination of server status is critical in compute-first networking systems, where user tasks arrive dynamically and computing resources are limited and stochastic. In such systems, the access point plays a key role in forwarding tasks to a server based on its latest received server status. However, modeling the task-success probability suffering the factors of stochastic arrivals, limited server capacity, and bidirectional link delays. Therefore, we introduce a unified analytical framework that abstracts the AP forwarding rule as a single probability and models all network and waiting delays via their Laplace transforms. This approach yields a closed form expression for the end to end task success probability, together with upper and lower bounds that capture Erlang loss blocking, information staleness, and random uplink/downlink delays. We validate our results through simulations across a wide range of parameters, showing that theoretical predictions and bounds consistently enclose observed success rates. Our framework requires only two interchangeable inputs (the forwarding probability and the delay transforms), making it readily adaptable to alternative forwarding policies and delay distributions. Experiments demonstrate that our bounds are able to achieve accuracy within 0.01 (upper bound) and 0.016 (lower bound) of the empirical task success probability.",
      "authors": [
        "Jianpeng Qi",
        "Chao Liu",
        "Rui Wang",
        "Junyu Dong",
        "Yanwei Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:41:01+00:00",
          "link": "https://arxiv.org/abs/2507.17195v1",
          "size": "570kb",
          "version": "v1"
        }
      ],
      "title": "Closed-Form and Boundary Expressions for Task-Success Probability in Status-Driven Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17195",
        "HTML": "https://arxiv.org/html/2507.17195v1",
        "PDF": "https://arxiv.org/pdf/2507.17195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analytical frameworks for task success probability in network systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17199",
      "abstract": "LLM-powered search services have driven data integration as a significant trend. However, this trend's progress is fundamentally hindered, despite the fact that combining individual knowledge can significantly improve the relevance and quality of responses in specialized queries and make AI more professional at providing services. Two key bottlenecks are private data repositories' locality constraints and the need to maintain compatibility with mainstream search techniques, particularly Hierarchical Navigable Small World (HNSW) indexing for high-dimensional vector spaces. In this work, we develop a secure and privacy-preserving aggregated approximate nearest neighbor search (SP-A$^2$NN) with HNSW compatibility under a threshold-based searchable sharing primitive. A sharable bitgraph structure is constructed and extended to support searches and dynamical insertions over shared data without compromising the underlying graph topology. The approach reduces the complexity of a search from $O(n^2)$ to $O(n)$ compared to naive (undirected) graph-sharing approach when organizing graphs in the identical HNSW manner.\n  On the theoretical front, we explore a novel security analytical framework that incorporates privacy analysis via reductions. The proposed leakage-guessing proof system is built upon an entirely different interactive game that is independent of existing coin-toss game design. Rather than being purely theoretical, this system is rooted in existing proof systems but goes beyond them to specifically address leakage concerns and standardize leakage analysis -- one of the most critical security challenges with AI's rapid development.",
      "authors": [
        "Ruoyang Rykie Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:45:01+00:00",
          "link": "https://arxiv.org/abs/2507.17199v1",
          "size": "788kb",
          "version": "v1"
        }
      ],
      "title": "Threshold-Protected Searchable Sharing: Privacy Preserving Aggregated-ANN Search for Collaborative RAG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17199",
        "HTML": "https://arxiv.org/html/2507.17199v1",
        "PDF": "https://arxiv.org/pdf/2507.17199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses privacy-preserving search over high-dimensional vectors in collaborative AI but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17202",
      "abstract": "Designing high-quality presentation slides can be challenging for non-experts due to the complexity involved in navigating various design choices. Numerous automated tools can suggest layouts and color schemes, yet often lack the ability to refine their own output, which is a key aspect in real-world workflows. We propose DesignLab, which separates the design process into two roles, the design reviewer, who identifies design-related issues, and the design contributor who corrects them. This decomposition enables an iterative loop where the reviewer continuously detects issues and the contributor corrects them, allowing a draft to be further polished with each iteration, reaching qualities that were unattainable. We fine-tune large language models for these roles and simulate intermediate drafts by introducing controlled perturbations, enabling the design reviewer learn design errors and the contributor learn how to fix them. Our experiments show that DesignLab outperforms existing design-generation methods, including a commercial tool, by embracing the iterative nature of designing which can result in polished, professional slides.",
      "authors": [
        "Jooyeol Yun",
        "Heng Wang",
        "Yotaro Shimose",
        "Jaegul Choo",
        "Shingo Takamatsu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:49:48+00:00",
          "link": "https://arxiv.org/abs/2507.17202v1",
          "size": "4544kb",
          "version": "v1"
        }
      ],
      "title": "DesignLab: Designing Slides Through Iterative Detection and Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17202",
        "HTML": "https://arxiv.org/html/2507.17202v1",
        "PDF": "https://arxiv.org/pdf/2507.17202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning LLMs for a specific application (designing slides) but is primarily focused on model behavior and task design, not on training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17204",
      "abstract": "Effective content moderation is essential for video platforms to safeguard user experience and uphold community standards. While traditional video classification models effectively handle well-defined moderation tasks, they struggle with complicated scenarios such as implicit harmful content and contextual ambiguity. Multimodal large language models (MLLMs) offer a promising solution to these limitations with their superior cross-modal reasoning and contextual understanding. However, two key challenges hinder their industrial adoption. First, the high computational cost of MLLMs makes full-scale deployment impractical. Second, adapting generative models for discriminative classification remains an open research problem. In this paper, we first introduce an efficient method to transform a generative MLLM into a multimodal classifier using minimal discriminative training data. To enable industry-scale deployment, we then propose a router-ranking cascade system that integrates MLLMs with a lightweight router model. Offline experiments demonstrate that our MLLM-based approach improves F1 score by 66.50% over traditional classifiers while requiring only 2% of the fine-tuning data. Online evaluations show that our system increases automatic content moderation volume by 41%, while the cascading deployment reduces computational cost to only 1.5% of direct full-scale deployment.",
      "authors": [
        "Zixuan Wang",
        "Jinghao Shi",
        "Hanzhong Liang",
        "Xiang Shen",
        "Vera Wen",
        "Zhiqian Chen",
        "Yifan Wu",
        "Zhixin Zhang",
        "Hongyu Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:52:58+00:00",
          "link": "https://arxiv.org/abs/2507.17204v1",
          "size": "911kb",
          "version": "v1"
        }
      ],
      "title": "Filter-And-Refine: A MLLM Based Cascade System for Industrial-Scale Video Content Moderation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17204",
        "HTML": "https://arxiv.org/html/2507.17204v1",
        "PDF": "https://arxiv.org/pdf/2507.17204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on adapting MLLMs for video content moderation, involving some data processing steps like reducing fine-tuning data, but does not focus on LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17205",
      "abstract": "The design of restorative dental crowns from intraoral scans is labor-intensive for dental technicians. To address this challenge, we propose a novel voxel-based framework for automated dental crown design (VBCD). The VBCD framework generates an initial coarse dental crown from voxelized intraoral scans, followed by a fine-grained refiner incorporating distance-aware supervision to improve accuracy and quality. During the training stage, we employ the Curvature and Margin line Penalty Loss (CMPL) to enhance the alignment of the generated crown with the margin line. Additionally, a positional prompt based on the FDI tooth numbering system is introduced to further improve the accuracy of the generated dental crowns. Evaluation on a large-scale dataset of intraoral scans demonstrated that our approach outperforms existing methods, providing a robust solution for personalized dental crown design.",
      "authors": [
        "Linda Wei",
        "Chang Liu",
        "Wenran Zhang",
        "Zengji Zhang",
        "Shaoting Zhang",
        "Hongsheng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:53:38+00:00",
          "link": "https://arxiv.org/abs/2507.17205v1",
          "size": "2898kb",
          "version": "v1"
        }
      ],
      "title": "VBCD: A Voxel-Based Framework for Personalized Dental Crown Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17205",
        "HTML": "https://arxiv.org/html/2507.17205v1",
        "PDF": "https://arxiv.org/pdf/2507.17205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for dental crown design using voxel-based methods, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17209",
      "abstract": "Modern scientific discovery faces growing challenges in integrating vast and heterogeneous knowledge critical to breakthroughs in biomedicine and drug development. Traditional hypothesis-driven research, though effective, is constrained by human cognitive limits, the complexity of biological systems, and the high cost of trial-and-error experimentation. Deep learning models, especially graph neural networks (GNNs), have accelerated prediction generation, but the sheer volume of outputs makes manual selection for validation unscalable. Large language models (LLMs) offer promise in filtering and hypothesis generation, yet suffer from hallucinations and lack grounding in structured knowledge, limiting their reliability. To address these issues, we propose HypoChainer, a collaborative visualization framework that integrates human expertise, LLM-driven reasoning, and knowledge graphs (KGs) to enhance hypothesis generation and validation. HypoChainer operates in three stages: First, exploration and contextualization -- experts use retrieval-augmented LLMs (RAGs) and dimensionality reduction to navigate large-scale GNN predictions, assisted by interactive explanations. Second, hypothesis chain formation -- experts iteratively examine KG relationships around predictions and semantically linked entities, refining hypotheses with LLM and KG suggestions. Third, validation prioritization -- refined hypotheses are filtered based on KG-supported evidence to identify high-priority candidates for experimentation, with visual analytics further strengthening weak links in reasoning. We demonstrate HypoChainer's effectiveness through case studies in two domains and expert interviews, highlighting its potential to support interpretable, scalable, and knowledge-grounded scientific discovery.",
      "authors": [
        "Haoran Jiang",
        "Shaohan Shi",
        "Yunjie Yao",
        "Chang Jiang",
        "Quan Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:02:54+00:00",
          "link": "https://arxiv.org/abs/2507.17209v1",
          "size": "5350kb",
          "version": "v1"
        }
      ],
      "title": "HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17209",
        "PDF": "https://arxiv.org/pdf/2507.17209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hypothesis generation and validation in scientific discovery using LLMs and knowledge graphs, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17210",
      "abstract": "This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera extrinsic calibration tool based on a custom-made 3D target. FAST-Calib supports both mechanical and solid-state LiDARs by leveraging an efficient and reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It also compensates for edge dilation artifacts caused by LiDAR spot spread through ellipse fitting, and supports joint optimization across multiple scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and Mid360), each paired with a wide-angle camera. Experimental results demonstrate superior accuracy and robustness compared to existing methods. With point-to-point registration errors consistently below 6.5mm and total processing time under 0.7s, FAST-Calib provides an efficient, accurate, and target-based automatic calibration pipeline. We have open-sourced our code and dataset on GitHub to benefit the robotics community.",
      "authors": [
        "Chunran Zheng and Fu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:06:34+00:00",
          "link": "https://arxiv.org/abs/2507.17210v1",
          "size": "3177kb",
          "version": "v1"
        }
      ],
      "title": "FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17210",
        "HTML": "https://arxiv.org/html/2507.17210v1",
        "PDF": "https://arxiv.org/pdf/2507.17210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses LiDAR-camera calibration in robotics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17214",
      "abstract": "Bringing AI to vehicles and enabling them as sensing platforms is key to transforming maintenance from reactive to proactive. Now is the time to integrate AI copilots that speak both languages: machine and driver. This article offers a conceptual and technical perspective intended to spark interdisciplinary dialogue and guide future research and development in intelligent vehicle systems, predictive maintenance, and AI-powered user interaction.",
      "authors": [
        "Amod Kant Agrawal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:12:04+00:00",
          "link": "https://arxiv.org/abs/2507.17214v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17214",
        "HTML": "https://arxiv.org/html/2507.17214v1",
        "PDF": "https://arxiv.org/pdf/2507.17214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI integration in vehicles for predictive maintenance, which does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17215",
      "abstract": "Motif counting is a fundamental problem in network analysis, and there is a rich literature of theoretical and applied algorithms for this problem. Given a large input network $G$, a motif $H$ is a small \"pattern\" graph indicative of special local structure. Motif/pattern mining involves finding all matches of this pattern in the input $G$. The simplest, yet challenging, case of motif counting is when $H$ has three vertices, often called a \"triadic\" query. Recent work has focused on \"temporal graph mining\", where the network $G$ has edges with timestamps (and directions) and $H$ has time constraints.\n  Inspired by concepts in logic and database theory, we introduce the study of \"thresholded First Order Logic (FOL) Motif Analysis\" for massive temporal networks. A typical triadic motif query asks for the existence of three vertices that form a desired temporal pattern. An \"FOL\" motif query is obtained by having both existential and thresholded universal quantifiers. This allows for query semantics that can mine richer information from networks. A typical triadic query would be \"find all triples of vertices $u,v,w$ such that they form a triangle within one hour\". A thresholded FOL query can express \"find all pairs $u,v$ such that for half of $w$ where $(u,w)$ formed an edge, $(v,w)$ also formed an edge within an hour\".\n  We design the first algorithm, FOLTY, for mining thresholded FOL triadic queries. The theoretical running time of FOLTY matches the best known running time for temporal triangle counting in sparse graphs. We give an efficient implementation of FOLTY using specialized temporal data structures. FOLTY has excellent empirical behavior, and can answer triadic FOL queries on graphs with nearly 70M edges is less than hour on commodity hardware. Our work has the potential to start a new research direction in the classic well-studied problem of motif analysis.",
      "authors": [
        "Omkar Bhalerao",
        "Yunjie Pan",
        "C. Seshadhri",
        "Nishil Talati"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Data Structures and Algorithms (cs.DS)",
        "Information Retrieval (cs.IR)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:12:23+00:00",
          "link": "https://arxiv.org/abs/2507.17215v1",
          "size": "1628kb",
          "version": "v1"
        }
      ],
      "title": "Triadic First-Order Logic Queries in Temporal Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17215",
        "HTML": "https://arxiv.org/html/2507.17215v1",
        "PDF": "https://arxiv.org/pdf/2507.17215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an algorithm for motif analysis in temporal networks without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17216",
      "abstract": "People increasingly rely on Large Language Models (LLMs) for moral advice, which may influence humans' decisions. Yet, little is known about how closely LLMs align with human moral judgments. To address this, we introduce the Moral Dilemma Dataset, a benchmark of 1,618 real-world moral dilemmas paired with a distribution of human moral judgments consisting of a binary evaluation and a free-text rationale. We treat this problem as a pluralistic distributional alignment task, comparing the distributions of LLM and human judgments across dilemmas. We find that models reproduce human judgments only under high consensus; alignment deteriorates sharply when human disagreement increases. In parallel, using a 60-value taxonomy built from 3,783 value expressions extracted from rationales, we show that LLMs rely on a narrower set of moral values than humans. These findings reveal a pluralistic moral gap: a mismatch in both the distribution and diversity of values expressed. To close this gap, we introduce Dynamic Moral Profiling (DMP), a Dirichlet-based sampling method that conditions model outputs on human-derived value profiles. DMP improves alignment by 64.3% and enhances value diversity, offering a step toward more pluralistic and human-aligned moral guidance from LLMs.",
      "authors": [
        "Giuseppe Russo",
        "Debora Nozza",
        "Paul R\\\"ottger",
        "Dirk Hovy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:26:17+00:00",
          "link": "https://arxiv.org/abs/2507.17216v1",
          "size": "579kb",
          "version": "v1"
        }
      ],
      "title": "The Pluralistic Moral Gap: Understanding Judgment and Value Differences between Humans and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17216",
        "HTML": "https://arxiv.org/html/2507.17216v1",
        "PDF": "https://arxiv.org/pdf/2507.17216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the Moral Dilemma Dataset for assessing moral judgment alignment between humans and LLMs, which involves data collection for fine-tuning LLMs but primarily focuses on moral alignment rather than data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17218",
      "abstract": "Communicating the complexity of oceanic phenomena-such as hypoxia and acidification-poses a persistent challenge for marine science. Despite advances in sensing technologies and computational models, conventional formats like static visualizations and text-based reports often fall short in conveying the dynamics of ocean changes. To address this gap, we present OceanVive, an immersive and interactive visualization system that transforms complex ocean datasets into navigable spatial narratives. OceanVive incorporates an exploratory panel on a table-sized tablet for managing immersive content on a large screen and integrates adaptive visual encodings, contextual storytelling, and intuitive navigation pathways to support effective communication. We validate the system through expert interviews, demonstrating its potential to enhance science communication and promote deeper public understanding.",
      "authors": [
        "Yang Ouyang",
        "Yuchen Wu",
        "Xiyuan Wang",
        "Laixin Xie",
        "Weicong Cheng",
        "Jianping Gan",
        "Quan Li",
        "Xiaojuan Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:29:27+00:00",
          "link": "https://arxiv.org/abs/2507.17218v1",
          "size": "6208kb",
          "version": "v1"
        }
      ],
      "title": "OceanVive: An Immersive Visualization System for Communicating Complex Oceanic Phenomena",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17218",
        "HTML": "https://arxiv.org/html/2507.17218v1",
        "PDF": "https://arxiv.org/pdf/2507.17218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on OceanVive, an immersive visualization system for oceanic datasets and enhancing science communication. It does not address any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17219",
      "abstract": "The wood processing industry, particularly in facilities such as sawmills and MDF production lines, requires accurate and efficient identification of species and thickness of the wood. Although traditional methods rely heavily on expert human labor, they are slow, inconsistent, and prone to error, especially when processing large volumes. This study focuses on practical and cost-effective machine learning frameworks that automate the estimation of timber log diameter using standard RGB images captured under real-world working conditions. We employ the YOLOv5 object detection algorithm, fine-tuned on a public dataset (TimberSeg 1.0), to detect individual timber logs and estimate thickness through bounding-box dimensions. Unlike previous methods that require expensive sensors or controlled environments, this model is trained on images taken in typical industrial sheds during timber delivery. Experimental results show that the model achieves a mean Average Precision (mAP@0.5) of 0.64, demonstrating reliable log detection even with modest computing resources. This lightweight, scalable solution holds promise for practical integration into existing workflows, including on-site inventory management and preliminary sorting, particularly in small and medium-sized operations.",
      "authors": [
        "Fatemeh Hasanzadeh Fard",
        "Sanaz Hasanzadeh Fard",
        "Mehdi Jonoobi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:29:28+00:00",
          "link": "https://arxiv.org/abs/2507.17219v1",
          "size": "3564kb",
          "version": "v1"
        }
      ],
      "title": "A Low-Cost Machine Learning Approach for Timber Diameter Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17219",
        "HTML": "https://arxiv.org/html/2507.17219v1",
        "PDF": "https://arxiv.org/pdf/2507.17219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores a machine learning approach for estimating timber diameter, emphasizing model application in the wood processing industry, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17220",
      "abstract": "Recent studies have explored pretrained (foundation) models for vision-based robotic navigation, aiming to achieve generalizable navigation and positive transfer across diverse environments while enhancing zero-shot performance in unseen settings. In this work, we introduce PIG-Nav (Pretrained Image-Goal Navigation), a new approach that further investigates pretraining strategies for vision-based navigation models and contributes in two key areas. Model-wise, we identify two critical design choices that consistently improve the performance of pretrained navigation models: (1) integrating an early-fusion network structure to combine visual observations and goal images via appropriately pretrained Vision Transformer (ViT) image encoder, and (2) introducing suitable auxiliary tasks to enhance global navigation representation learning, thus further improving navigation performance. Dataset-wise, we propose a novel data preprocessing pipeline for efficiently labeling large-scale game video datasets for navigation model training. We demonstrate that augmenting existing open navigation datasets with diverse gameplay videos improves model performance. Our model achieves an average improvement of 22.6% in zero-shot settings and a 37.5% improvement in fine-tuning settings over existing visual navigation foundation models in two complex simulated environments and one real-world environment. These results advance the state-of-the-art in pretrained image-goal navigation models. Notably, our model maintains competitive performance while requiring significantly less fine-tuning data, highlighting its potential for real-world deployment with minimal labeled supervision.",
      "authors": [
        "Jiansong Wan",
        "Chengming Zhou",
        "Jinkua Liu",
        "Xiangge Huang",
        "Xiaoyu Chen",
        "Xiaohan Yi",
        "Qisen Yang",
        "Baiting Zhu",
        "Xin-Qiang Cai",
        "Lixing Liu",
        "Rushuai Yang",
        "Chuheng Zhang",
        "Sherif Abdelfattah",
        "Hayong Shin",
        "Pushi Zhang",
        "Li Zhao",
        "Jiang Bian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:34:20+00:00",
          "link": "https://arxiv.org/abs/2507.17220v1",
          "size": "2436kb",
          "version": "v1"
        }
      ],
      "title": "PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17220",
        "HTML": "https://arxiv.org/html/2507.17220v1",
        "PDF": "https://arxiv.org/pdf/2507.17220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel data preprocessing pipeline for labeling datasets for navigation model training. However, its primary focus is on model design for image-goal navigation rather than LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17221",
      "abstract": "Driven by the ``scale-is-everything'' paradigm, modern machine learning increasingly demands ever-larger datasets and models, yielding prohibitive computational and storage requirements. Dataset distillation mitigates this by compressing an original dataset into a small set of synthetic samples, while preserving its full utility. Yet, existing methods either maximize performance under fixed storage budgets or pursue suitable synthetic data representations for redundancy removal, without jointly optimizing both objectives. In this work, we propose a joint rate-utility optimization method for dataset distillation. We parameterize synthetic samples as optimizable latent codes decoded by extremely lightweight networks. We estimate the Shannon entropy of quantized latents as the rate measure and plug any existing distillation loss as the utility measure, trading them off via a Lagrange multiplier. To enable fair, cross-method comparisons, we introduce bits per class (bpc), a precise storage metric that accounts for sample, label, and decoder parameter costs. On CIFAR-10, CIFAR-100, and ImageNet-128, our method achieves up to $170\\times$ greater compression than standard distillation at comparable accuracy. Across diverse bpc budgets, distillation losses, and backbone architectures, our approach consistently establishes better rate-utility trade-offs.",
      "authors": [
        "Youneng Bao",
        "Yiping Liu",
        "Zhuo Chen",
        "Yongsheng Liang",
        "Mu Li",
        "Kede Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:40:52+00:00",
          "link": "https://arxiv.org/abs/2507.17221v1",
          "size": "17055kb",
          "version": "v1"
        }
      ],
      "title": "Dataset Distillation as Data Compression: A Rate-Utility Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17221",
        "HTML": "https://arxiv.org/html/2507.17221v1",
        "PDF": "https://arxiv.org/pdf/2507.17221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses dataset distillation as a method of data compression, emphasizing joint rate-utility optimization to improve dataset compactness and utility. While relevant to dataset management, it is not directly focused on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17222",
      "abstract": "In this paper, we revisit the formal verification problem for stochastic dynamical systems over finite horizon using barrier certificates. Most existing work on this topic focuses on safety properties by constructing barrier certificates based on the notion of $c$-martingales. In this work, we first provide a new insight into the conditions of existing martingale-based barrier certificates from the perspective of dynamic programming operators. Specifically, we show that the existing conditions essentially provide a bound on the dynamic programming solution, which exactly characterizes the safety probability. Based on this new perspective, we demonstrate that the barrier conditions in existing approaches are unnecessarily conservative over unsafe states. To address this, we propose a new set of safety barrier certificate conditions that are strictly less conservative than existing ones, thereby providing tighter probability bounds for safety verification. We further extend our approach to the case of reach-avoid specifications by providing a set of new barrier certificate conditions. We also illustrate how to search for these new barrier certificates using sum-of-squares (SOS) programming. Finally, we use two numerical examples to demonstrate the advantages of our method compared to existing approaches.",
      "authors": [
        "Yu Chen",
        "Shaoyuan Li and Xiang Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:43:01+00:00",
          "link": "https://arxiv.org/abs/2507.17222v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "On the Construction of Barrier Certificate: A Dynamic Programming Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17222",
        "PDF": "https://arxiv.org/pdf/2507.17222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work addresses formal verification of stochastic dynamical systems using barrier certificates, focusing on safety verification rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17226",
      "abstract": "Generative AI is disrupting computing education. Most interventions focus on teaching GenAI use rather than helping students understand how AI changes their programming process. We designed and deployed a novel comparative video reflection assignment adapting the Describe, Examine, then Articulate Learning (DEAL) framework. In an introductory software engineering course, students recorded themselves programming during their team project two times: first without, then with using generative AI. Students then analyzed their own videos using a scaffolded set of reflection questions, including on their programming process and human, internet, and AI help-seeking. We conducted a qualitative thematic analysis of the reflections, finding students developed insights about planning, debugging, and help-seeking behaviors that transcended AI use. Students reported learning to slow down and understand before writing or generating code, recognized patterns in their problem-solving approaches, and articulated specific process improvements. Students also learned and reflected on AI limits and downsides, and strategies to use AI more critically, including better prompting but also to benefit their learning instead of just completing tasks. Unexpectedly, the comparative reflection also scaffolded reflection on programming not involving AI use, and even led to students spontaneously setting future goals to adopt video and other regular reflection. This work demonstrates structured reflection on programming session videos can develop metacognitive skills essential for programming with and without generative AI and also lifelong learning in our evolving field.",
      "authors": [
        "Sarah \"Magz\" Fernandez",
        "Greg L Nelson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:47:46+00:00",
          "link": "https://arxiv.org/abs/2507.17226v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "A \"watch your replay videos\" reflection assignment on comparing programming without versus with generative AI: learning about programming, critical AI use and limitations, and reflection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17226",
        "HTML": "https://arxiv.org/html/2507.17226v1",
        "PDF": "https://arxiv.org/pdf/2507.17226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a reflection assignment for programming with generative AI in computing education, but it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17228",
      "abstract": "Split Learning (SL) is an emerging privacy-preserving machine learning technique that enables resource constrained edge devices to participate in model training by partitioning a model into client-side and server-side sub-models. While SL reduces computational overhead on edge devices, it encounters significant challenges in heterogeneous environments where devices vary in computing resources, communication capabilities, environmental conditions, and privacy requirements. Although recent studies have explored heterogeneous SL frameworks that optimize split points for devices with varying resource constraints, they often neglect personalized privacy requirements and local model customization under varying environmental conditions. To address these limitations, we propose P3SL, a Personalized Privacy-Preserving Split Learning framework designed for heterogeneous, resource-constrained edge device systems. The key contributions of this work are twofold. First, we design a personalized sequential split learning pipeline that allows each client to achieve customized privacy protection and maintain personalized local models tailored to their computational resources, environmental conditions, and privacy needs. Second, we adopt a bi-level optimization technique that empowers clients to determine their own optimal personalized split points without sharing private sensitive information (i.e., computational resources, environmental conditions, privacy requirements) with the server. This approach balances energy consumption and privacy leakage risks while maintaining high model accuracy. We implement and evaluate P3SL on a testbed consisting of 7 devices including 4 Jetson Nano P3450 devices, 2 Raspberry Pis, and 1 laptop, using diverse model architectures and datasets under varying environmental conditions.",
      "authors": [
        "Wei Fan",
        "JinYi Yoon",
        "Xiaochang Li",
        "Huajie Shao",
        "and Bo Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:50:33+00:00",
          "link": "https://arxiv.org/abs/2507.17228v1",
          "size": "3083kb",
          "version": "v1"
        }
      ],
      "title": "P3SL: Personalized Privacy-Preserving Split Learning on Heterogeneous Edge Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17228",
        "HTML": "https://arxiv.org/html/2507.17228v1",
        "PDF": "https://arxiv.org/pdf/2507.17228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a framework for personalized, privacy-preserving split learning on edge devices, focusing on privacy and computational optimization, without addressing LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17230",
      "abstract": "Students continue their education when they feel their learning is meaningful and relevant for their future careers. Computing educators now face the challenge of preparing students for careers increasingly shaped by generative AI (GenAI) with the goals of supporting their learning, motivation, ethics, and career development. Our longitudinal qualitative study of students in a GenAI-integrated creative media course shows how this is a \"wicked\" problem: progress on one goal can then impede progress on other goals. Students developed concerning patterns despite extensive instruction in critical and ethical GenAI use including prompt engineering, ethics and bias, and industry panels on GenAI's career impact. We present an analysis of two students' experiences to showcase this complexity. Increasing GenAI use skills can lower ethics; for example, Pat started from purposefully avoiding GenAI use, to dependency. He described himself as a \"notorious cheater\" who now uses GenAi to \"get all the right answers\" while acknowledging he's learning less. Increasing ethical awareness can lower the learning of GenAI use skills; for example, Jay's newfound environmental concerns led to self-imposed usage limits that impeded skill development, and new serious fears that GenAI would eliminate creative careers they had been passionate about. Increased GenAI proficiency, a potential career skill, did not improve their career confidence. These findings suggest that supporting student development in the GenAI era is a \"wicked\" problem requiring multi-dimensional evaluation and design, rather than optimizing learning, GenAI skills, ethics, or career motivation individually.",
      "authors": [
        "Clara Scalzer",
        "Saurav Pokhrel",
        "Sara Hunt",
        "Greg L Nelson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:53:54+00:00",
          "link": "https://arxiv.org/abs/2507.17230v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Designing for Learning with Generative AI is a Wicked Problem: An Illustrative Longitudinal Qualitative Case Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17230",
        "HTML": "https://arxiv.org/html/2507.17230v1",
        "PDF": "https://arxiv.org/pdf/2507.17230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the challenges of integrating generative AI into education, focusing on ethics and career impacts, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17232",
      "abstract": "Large Language Models (LLMs) are trained on a vast amount of procedural texts, but they do not directly observe real-world phenomena. In the context of cooking recipes, this poses a challenge, as intermediate states of ingredients are often omitted, making it difficult for models to track ingredient states and understand recipes accurately. In this paper, we apply state probing, a method for evaluating a language model's understanding of the world, to the domain of cooking. We propose a new task and dataset for evaluating how well LLMs can recognize intermediate ingredient states during cooking procedures. We first construct a new Japanese recipe dataset with clear and accurate annotations of ingredient state changes, collected from well-structured and controlled recipe texts. Using this dataset, we design three novel tasks to evaluate whether LLMs can track ingredient state transitions and identify ingredients present at intermediate steps. Our experiments with widely used LLMs, such as Llama3.1-70B and Qwen2.5-72B, show that learning ingredient state knowledge improves their understanding of cooking processes, achieving performance comparable to commercial LLMs.",
      "authors": [
        "Mashiro Toyooka",
        "Kiyoharu Aizawa and Yoko Yamakata"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:56:20+00:00",
          "link": "https://arxiv.org/abs/2507.17232v1",
          "size": "1846kb",
          "version": "v1"
        }
      ],
      "title": "A Highly Clean Recipe Dataset with Ingredient States Annotation for State Probing Task",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17232",
        "HTML": "https://arxiv.org/html/2507.17232v1",
        "PDF": "https://arxiv.org/pdf/2507.17232"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a new task and highly annotated recipe dataset to evaluate LLMs' understanding of ingredient states, directly contributing to data creation and processing for evaluating and potentially training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17233",
      "abstract": "Higher-order constructs enable more expressive and concise code by allowing procedures to be parameterized by other procedures. Assertions allow expressing partial program specifications, which can be verified either at compile time (statically) or run time (dynamically). In higher-order programs, assertions can also describe higher-order arguments. While in the context of (C)LP, run-time verification of higher-order assertions has received some attention, compile-time verification remains relatively unexplored. We propose a novel approach for statically verifying higher-order (C)LP programs with higher-order assertions. Although we use the Ciao assertion language for illustration, our approach is quite general and we believe is applicable to similar contexts. Higher-order arguments are described using predicate properties -- a special kind of property which exploits the (Ciao) assertion language. We refine the syntax and semantics of these properties and introduce an abstract criterion to determine conformance to a predicate property at compile time, based on a semantic order relation comparing the predicate property with the predicate assertions. We then show how to handle these properties using an abstract interpretation-based static analyzer for programs with first-order assertions by reducing predicate properties to first-order properties. Finally, we report on a prototype implementation and evaluate it through various examples within the Ciao system.",
      "authors": [
        "Marco Ciccal\\`e",
        "Daniel Jurjo-Rivas",
        "Jose F. Morales",
        "Pedro L\\'opez-Garc\\'ia",
        "Manuel V. Hermenegildo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:57:15+00:00",
          "link": "https://arxiv.org/abs/2507.17233v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Hiord: An Approach to the Specification and Verification of Higher-Order (C)LP Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17233",
        "HTML": "https://arxiv.org/html/2507.17233v1",
        "PDF": "https://arxiv.org/pdf/2507.17233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on higher-order (C)LP programs and their verification, with no mention of LLM training data processing or any data operations relevant to pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17234",
      "abstract": "Automatic generation of radiology reports has the potential to alleviate radiologists' significant workload, yet current methods struggle to deliver clinically reliable conclusions. In particular, most prior approaches focus on producing fluent text without effectively ensuring the factual correctness of the reports and often rely on single-view images, limiting diagnostic comprehensiveness. We propose CLARIFID, a novel framework that directly optimizes diagnostic correctness by mirroring the two-step workflow of experts. Specifically, CLARIFID (1) learns the logical flow from Findings to Impression through section-aware pretraining, (2) is fine-tuned with Proximal Policy Optimization in which the CheXbert F1 score of the Impression section serves as the reward, (3) enforces reasoning-aware decoding that completes \"Findings\" before synthesizing the \"Impression\", and (4) fuses multiple chest X-ray views via a vision-transformer-based multi-view encoder. During inference, we apply a reasoning-aware next-token forcing strategy followed by report-level re-ranking, ensuring that the model first produces a comprehensive Findings section before synthesizing the Impression and thereby preserving coherent clinical reasoning. Experimental results on the MIMIC-CXR dataset demonstrate that our method achieves superior clinical efficacy and outperforms existing baselines on both standard NLG metrics and clinically aware scores.",
      "authors": [
        "Kyeongkyu Lee",
        "Seonghwan Yoon",
        "Hongki Lim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.17234v1",
          "size": "486kb",
          "version": "v1"
        }
      ],
      "title": "CLARIFID: Improving Radiology Report Generation by Reinforcing Clinically Accurate Impressions and Enforcing Detailed Findings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17234",
        "HTML": "https://arxiv.org/html/2507.17234v1",
        "PDF": "https://arxiv.org/pdf/2507.17234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for improving radiology report generation with techniques optimizing clinical accuracy, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17235",
      "abstract": "The increasing complexity of quantum software presents significant challenges for software verification and validation, particularly in the context of unit testing. This work presents a comprehensive study on quantum-centric unit tests, comparing traditional statistical approaches with tests specifically designed for quantum circuits. These include tests that run only on a classical computer, such as the Statevector test, as well as those executable on quantum hardware, such as the Swap test and the novel Inverse test. Through an empirical study and detailed analysis on 1,796,880 mutated quantum circuits, we investigate (a) each test's ability to detect subtle discrepancies between the expected and actual states of a quantum circuit, and (b) the number of measurements required to achieve high reliability. The results demonstrate that quantum-centric tests, particularly the Statevector test and the Inverse test, provide clear advantages in terms of precision and efficiency, reducing both false positives and false negatives compared to statistical tests. This work contributes to the development of more robust and scalable strategies for testing quantum software, supporting the future adoption of fault-tolerant quantum computers and promoting more reliable practices in quantum software engineering.",
      "authors": [
        "Andriy Miranskyy",
        "Jos\\'e Campos",
        "Anila Mjeda",
        "Lei Zhang",
        "Ignacio Garc\\'ia Rodr\\'iguez de Guzm\\'an"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:05:24+00:00",
          "link": "https://arxiv.org/abs/2507.17235v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "On the Feasibility of Quantum Unit Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17235",
        "HTML": "https://arxiv.org/html/2507.17235v1",
        "PDF": "https://arxiv.org/pdf/2507.17235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study centers on quantum software unit testing, providing strategies for testing quantum circuits rather than addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17239",
      "abstract": "Foundation models have recently gained tremendous popularity in medical image analysis. State-of-the-art methods leverage either paired image-text data via vision-language pre-training or unpaired image data via self-supervised pre-training to learn foundation models with generalizable image features to boost downstream task performance. However, learning foundation models exclusively on either paired or unpaired image data limits their ability to learn richer and more comprehensive image features. In this paper, we investigate a novel task termed semi-supervised vision-language pre-training, aiming to fully harness the potential of both paired and unpaired image data for foundation model learning. To this end, we propose MaskedCLIP, a synergistic masked image modeling and contrastive language-image pre-training framework for semi-supervised vision-language pre-training. The key challenge in combining paired and unpaired image data for learning a foundation model lies in the incompatible feature spaces derived from these two types of data. To address this issue, we propose to connect the masked feature space with the CLIP feature space with a bridge transformer. In this way, the more semantic specific CLIP features can benefit from the more general masked features for semantic feature extraction. We further propose a masked knowledge distillation loss to distill semantic knowledge of original image features in CLIP feature space back to the predicted masked image features in masked feature space. With this mutually interactive design, our framework effectively leverages both paired and unpaired image data to learn more generalizable image features for downstream tasks. Extensive experiments on retinal image analysis demonstrate the effectiveness and data efficiency of our method.",
      "authors": [
        "Lei Zhu",
        "Jun Zhou",
        "Rick Siow Mong Goh",
        "Yong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:15:54+00:00",
          "link": "https://arxiv.org/abs/2507.17239v1",
          "size": "208kb",
          "version": "v1"
        }
      ],
      "title": "MaskedCLIP: Bridging the Masked and CLIP Space for Semi-Supervised Medical Vision-Language Pre-training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17239",
        "HTML": "https://arxiv.org/html/2507.17239v1",
        "PDF": "https://arxiv.org/pdf/2507.17239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a semi-supervised pretraining framework for medical vision-language models, involving data processing through a bridge transformer, but focuses mainly on model architecture rather than on data processing advances typical in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17240",
      "abstract": "Image Quality Assessment (IQA) models are employed in many practical image and video processing pipelines to reduce storage, minimize transmission costs, and improve the Quality of Experience (QoE) of millions of viewers. These models are sensitive to a diverse range of image distortions and can accurately predict image quality as judged by human viewers. Recent advancements in generative models have resulted in a significant influx of \"GenAI\" content on the internet. Existing methods for detecting GenAI content have progressed significantly with improved generalization performance on images from unseen generative models. Here, we leverage the capabilities of existing IQA models, which effectively capture the manifold of real images within a bandpass statistical space, to distinguish between real and AI-generated images. We investigate the generalization ability of these perceptual classifiers to the task of GenAI image detection and evaluate their robustness against various image degradations. Our results show that a two-layer network trained on the feature space of IQA models demonstrates state-of-the-art performance in detecting fake images across generative models, while maintaining significant robustness against image degradations.",
      "authors": [
        "Krishna Srikar Durbha",
        "Asvin Kumar Venkataramanan",
        "Rajesh Sureddi",
        "Alan C. Bovik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:18:09+00:00",
          "link": "https://arxiv.org/abs/2507.17240v1",
          "size": "13589kb",
          "version": "v1"
        }
      ],
      "title": "Perceptual Classifiers: Detecting Generative Images using Perceptual Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17240",
        "HTML": "https://arxiv.org/html/2507.17240v1",
        "PDF": "https://arxiv.org/pdf/2507.17240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about using IQA models for detecting generative images and does not discuss training data processing related to large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17241",
      "abstract": "The widespread adoption of Artificial Intelligence (AI) and Machine Learning (ML) comes with a significant environmental impact, particularly in terms of energy consumption and carbon emissions. This pressing issue highlights the need for innovative solutions to mitigate AI's ecological footprint. One of the key factors influencing the energy consumption of ML model training is the size of the training dataset. ML models are often trained on vast amounts of data continuously generated by sensors and devices distributed across multiple locations. To reduce data transmission costs and enhance privacy, Federated Learning (FL) enables model training without the need to move or share raw data. While FL offers these advantages, it also introduces challenges due to the heterogeneity of data sources (related to volume and quality), computational node capabilities, and environmental impact.\n  This paper contributes to the advancement of Green AI by proposing a data-centric approach to Green Federated Learning. Specifically, we focus on reducing FL's environmental impact by minimizing the volume of training data. Our methodology involves the analysis of the characteristics of federated datasets, the selecting of an optimal subset of data based on quality metrics, and the choice of the federated nodes with the lowest environmental impact. We develop a comprehensive methodology that examines the influence of data-centric factors, such as data quality and volume, on FL training performance and carbon emissions. Building on these insights, we introduce an interactive recommendation system that optimizes FL configurations through data reduction, minimizing environmental impact during training. Applying this methodology to time series classification has demonstrated promising results in reducing the environmental impact of FL tasks.",
      "authors": [
        "Mattia Sabella and Monica Vitali"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:18:15+00:00",
          "link": "https://arxiv.org/abs/2507.17241v1",
          "size": "983kb",
          "version": "v1"
        }
      ],
      "title": "Eco-Friendly AI: Unleashing Data Power for Green Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17241",
        "HTML": "https://arxiv.org/html/2507.17241v1",
        "PDF": "https://arxiv.org/pdf/2507.17241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a data-centric approach to Green Federated Learning by minimizing training data volume to reduce environmental impact. It involves selecting optimal data subsets for quality but focuses primarily on environmental impact mitigation rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17242",
      "abstract": "Brain-computer interface (BCI) technology establishes a direct communication pathway between the brain and external devices. Current visual BCI systems suffer from insufficient information transfer rates (ITRs) for practical use. Spatial information, a critical component of visual perception, remains underexploited in existing systems because the limited spatial resolution of recording methods hinders the capture of the rich spatiotemporal dynamics of brain signals. This study proposed a frequency-phase-space fusion encoding method, integrated with 256-channel high-density electroencephalogram (EEG) recordings, to develop high-speed BCI systems. In the classical frequency-phase encoding 40-target BCI paradigm, the 256-66, 128-32, and 64-21 electrode configurations brought theoretical ITR increases of 83.66%, 79.99%, and 55.50% over the traditional 64-9 setup. In the proposed frequency-phase-space encoding 200-target BCI paradigm, these increases climbed to 195.56%, 153.08%, and 103.07%. The online BCI system achieved an average actual ITR of 472.7 bpm. This study demonstrates the essential role and immense potential of high-density EEG in decoding the spatiotemporal information of visual stimuli.",
      "authors": [
        "Gege Ming (1)",
        "Weihua Pei (2 and 3)",
        "Sen Tian (4)",
        "Xiaogang Chen (5)",
        "Xiaorong Gao (1)",
        "Yijun Wang (2",
        "3 and 6) ((1) Department of Biomedical Engineering",
        "Tsinghua University",
        "(2) Laboratory of Solid-State Optoelectronics Information Technology",
        "Institute of Semiconductors",
        "Chinese Academy of Sciences",
        "(3) School of Future Technology",
        "University of Chinese Academy of Sciences",
        "(4) Suzhou Nianji Intelligent Technology Co.",
        "Ltd.",
        "(5) Institute of Biomedical Engineering",
        "Chinese Academy of Medical Sciences and Peking Union Medical College",
        "(6) Chinese Institute for Brain Research)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Signal Processing (eess.SP)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:18:39+00:00",
          "link": "https://arxiv.org/abs/2507.17242v1",
          "size": "7712kb",
          "version": "v1"
        }
      ],
      "title": "High-Density EEG Enables the Fastest Visual Brain-Computer Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17242",
        "PDF": "https://arxiv.org/pdf/2507.17242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing brain-computer interfaces using EEG, discussing improvements in information transfer rates and encoding methods. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17245",
      "abstract": "The Transformer architecture has revolutionized deep learning, delivering the state-of-the-art performance in areas such as natural language processing, computer vision, and time series prediction. However, its core component, self-attention, has the quadratic time complexity relative to input sequence length, which hinders the scalability of Transformers. The exsiting approaches on optimizing self-attention either discard full-contextual information or lack of flexibility. In this work, we design DistrAttention, an effcient and flexible self-attention mechanism with the full context. DistrAttention achieves this by grouping data on the embedding dimensionality, usually referred to as $d$. We realize DistrAttention with a lightweight sampling and fusion method that exploits locality-sensitive hashing to group similar data. A block-wise grouping framework is further designed to limit the errors introduced by locality sensitive hashing. By optimizing the selection of block sizes, DistrAttention could be easily integrated with FlashAttention-2, gaining high-performance on modern GPUs. We evaluate DistrAttention with extensive experiments. The results show that our method is 37% faster than FlashAttention-2 on calculating self-attention. In ViT inference, DistrAttention is the fastest and the most accurate among approximate self-attention mechanisms. In Llama3-1B, DistrAttention still achieves the lowest inference time with only 1% accuray loss.",
      "authors": [
        "Haolin Jin",
        "Mengbai Xiao",
        "Yuan Yuan",
        "Xiao Zhang",
        "Dongxiao Yu",
        "Guanghui Zhang",
        "Haoliang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:29:38+00:00",
          "link": "https://arxiv.org/abs/2507.17245v1",
          "size": "2423kb",
          "version": "v1"
        }
      ],
      "title": "DistrAttention: An Efficient and Flexible Self-Attention Mechanism on Modern GPUs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17245",
        "HTML": "https://arxiv.org/html/2507.17245v1",
        "PDF": "https://arxiv.org/pdf/2507.17245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details an efficient self-attention mechanism called DistrAttention for improving neural network performance on GPUs. It does not pertain to LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17248",
      "abstract": "Interacting with real-world objects in Mixed Reality (MR) often proves difficult when they are crowded, distant, or partially occluded, hindering straightforward selection and manipulation. We observe that these difficulties stem from performing interaction directly on physical objects, where input is tightly coupled to their physical constraints. Our key insight is to decouple interaction from these constraints by introducing proxies-abstract representations of real-world objects. We embody this concept in Reality Proxy, a system that seamlessly shifts interaction targets from physical objects to their proxies during selection. Beyond facilitating basic selection, Reality Proxy uses AI to enrich proxies with semantic attributes and hierarchical spatial relationships of their corresponding physical objects, enabling novel and previously cumbersome interactions in MR - such as skimming, attribute-based filtering, navigating nested groups, and complex multi object selections - all without requiring new gestures or menu systems. We demonstrate Reality Proxy's versatility across diverse scenarios, including office information retrieval, large-scale spatial navigation, and multi-drone control. An expert evaluation suggests the system's utility and usability, suggesting that proxy-based abstractions offer a powerful and generalizable interaction paradigm for future MR systems.",
      "authors": [
        "Xiaoan Liu",
        "Difan Jia",
        "Xianhao Carton Liu",
        "Mar Gonzalez-Franco",
        "Chen Zhu-Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:34:58+00:00",
          "link": "https://arxiv.org/abs/2507.17248v1",
          "size": "15905kb",
          "version": "v1"
        }
      ],
      "title": "Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17248",
        "HTML": "https://arxiv.org/html/2507.17248v1",
        "PDF": "https://arxiv.org/pdf/2507.17248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents Reality Proxy, an interaction enhancement system in Mixed Reality using abstract representations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17249",
      "abstract": "Harnessing Large Language Models (LLMs) for recommendation systems has emerged as a prominent avenue, drawing substantial research interest. However, existing approaches primarily involve basic prompt techniques for knowledge acquisition, which resemble System-1 thinking. This makes these methods highly sensitive to errors in the reasoning path, where even a small mistake can lead to an incorrect inference. To this end, in this paper, we propose $R^{4}$ec, a reasoning, reflection and refinement framework that evolves the recommendation system into a weak System-2 model. Specifically, we introduce two models: an actor model that engages in reasoning, and a reflection model that judges these responses and provides valuable feedback. Then the actor model will refine its response based on the feedback, ultimately leading to improved responses. We employ an iterative reflection and refinement process, enabling LLMs to facilitate slow and deliberate System-2-like thinking. Ultimately, the final refined knowledge will be incorporated into a recommendation backbone for prediction. We conduct extensive experiments on Amazon-Book and MovieLens-1M datasets to demonstrate the superiority of $R^{4}$ec. We also deploy $R^{4}$ec on a large scale online advertising platform, showing 2.2\\% increase of revenue. Furthermore, we investigate the scaling properties of the actor model and reflection model.",
      "authors": [
        "Hao Gu and Rui Zhong and Yu Xia and Wei Yang and Chi Lu and Peng Jiang and Kun Gai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:36:49+00:00",
          "link": "https://arxiv.org/abs/2507.17249v1",
          "size": "529kb",
          "version": "v1"
        }
      ],
      "title": "R4ec: A Reasoning, Reflection, and Refinement Framework for Recommendation Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17249",
        "HTML": "https://arxiv.org/html/2507.17249v1",
        "PDF": "https://arxiv.org/pdf/2507.17249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for recommendation systems using LLMs that involves reasoning, reflection, and refinement. While it may touch upon data usage, its focus is on improving recommendation system outputs rather than processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17252",
      "abstract": "Current exposure correction methods have three challenges, labor-intensive paired data annotation, limited generalizability, and performance degradation in low-level computer vision tasks. In this work, we introduce an innovative Unsupervised Exposure Correction (UEC) method that eliminates the need for manual annotations, offers improved generalizability, and enhances performance in low-level downstream tasks. Our model is trained using freely available paired data from an emulated Image Signal Processing (ISP) pipeline. This approach does not need expensive manual annotations, thereby minimizing individual style biases from the annotation and consequently improving its generalizability. Furthermore, we present a large-scale Radiometry Correction Dataset, specifically designed to emphasize exposure variations, to facilitate unsupervised learning. In addition, we develop a transformation function that preserves image details and outperforms state-of-the-art supervised methods [12], while utilizing only 0.01% of their parameters. Our work further investigates the broader impact of exposure correction on downstream tasks, including edge detection, demonstrating its effectiveness in mitigating the adverse effects of poor exposure on low-level features. The source code and dataset are publicly available at https://github.com/BeyondHeaven/uec_code.",
      "authors": [
        "Ruodai Cui",
        "Li Niu",
        "Guosheng Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:46:22+00:00",
          "link": "https://arxiv.org/abs/2507.17252v1",
          "size": "6275kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Exposure Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17252",
        "HTML": "https://arxiv.org/html/2507.17252v1",
        "PDF": "https://arxiv.org/pdf/2507.17252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on unsupervised exposure correction for image processing, involving a large-scale dataset for radiometry correction. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17253",
      "abstract": "The increasing demand for fast and cost effective last mile delivery solutions has catalyzed significant advancements in drone based logistics. This research describes the development of an AI integrated drone delivery system, focusing on route optimization, object detection, secure package handling, and real time tracking. The proposed system leverages YOLOv4 Tiny for object detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for real time communication. A comparative analysis of lightweight AI models and hardware components is conducted to determine the optimal configuration for real time UAV based delivery. Key challenges including battery efficiency, regulatory compliance, and security considerations are addressed through the integration of machine learning techniques, IoT devices, and encryption protocols. Preliminary studies demonstrate improvement in delivery time compared to conventional ground based logistics, along with high accuracy recipient authentication through facial recognition. The study also discusses ethical implications and societal acceptance of drone deliveries, ensuring compliance with FAA, EASA and DGCA regulatory standards. Note: This paper presents the architecture, design, and preliminary simulation results of the proposed system. Experimental results, simulation benchmarks, and deployment statistics are currently being acquired. A comprehensive analysis will be included in the extended version of this work.",
      "authors": [
        "Maharshi Shastri and Ujjval Shrivastav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:49:56+00:00",
          "link": "https://arxiv.org/abs/2507.17253v1",
          "size": "1170kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17253",
        "HTML": "https://arxiv.org/html/2507.17253v1",
        "PDF": "https://arxiv.org/pdf/2507.17253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses drone technology in logistics, involving AI for route optimization and object detection. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17255",
      "abstract": "This paper explores the generative capabilities of Autoencoders (AEs) and establishes connections between Variational Autoencoders (VAEs) and Vector Quantized-Variational Autoencoders (VQ-VAEs) through a reformulated training framework. We demonstrate that AEs exhibit generative potential via latent space interpolation and perturbation, albeit limited by undefined regions in the encoding space. To address this, we propose a new VAE-like training method that introduces clustering centers to enhance data compactness and ensure well-defined latent spaces without relying on traditional KL divergence or reparameterization techniques. Experimental results on MNIST, CelebA, and FashionMNIST datasets show smooth interpolative transitions, though blurriness persists. Extending this approach to multiple learnable vectors, we observe a natural progression toward a VQ-VAE-like model in continuous space. However, when the encoder outputs multiple vectors, the model degenerates into a discrete Autoencoder (VQ-AE), which combines image fragments without learning semantic representations. Our findings highlight the critical role of encoding space compactness and dispersion in generative modeling and provide insights into the intrinsic connections between VAEs and VQ-VAEs, offering a new perspective on their design and limitations.",
      "authors": [
        "Songxuan Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:52:00+00:00",
          "link": "https://arxiv.org/abs/2507.17255v1",
          "size": "4194kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking VAE: From Continuous to Discrete Representations Without Probabilistic Assumptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17255",
        "HTML": "https://arxiv.org/html/2507.17255v1",
        "PDF": "https://arxiv.org/pdf/2507.17255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores training methods for autoencoders and VAEs, focusing on generative modeling without probabilistic assumptions. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17257",
      "abstract": "Central to agentic capability and trustworthiness of language model agents (LMAs) is the extent they maintain stable, reliable, identity over time. However, LMAs inherit pathologies from large language models (LLMs) (statelessness, stochasticity, sensitivity to prompts and linguistically-intermediation) which can undermine their identifiability, continuity, persistence and consistency. This attrition of identity can erode their reliability, trustworthiness and utility by interfering with their agentic capabilities such as reasoning, planning and action. To address these challenges, we introduce \\textit{agent identity evals} (AIE), a rigorous, statistically-driven, empirical framework for measuring the degree to which an LMA system exhibit and maintain their agentic identity over time, including their capabilities, properties and ability to recover from state perturbations. AIE comprises a set of novel metrics which can integrate with other measures of performance, capability and agentic robustness to assist in the design of optimal LMA infrastructure and scaffolding such as memory and tools. We set out formal definitions and methods that can be applied at each stage of the LMA life-cycle, and worked examples of how to apply them.",
      "authors": [
        "Elija Perrier",
        "Michael Timothy Bennett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:56:15+00:00",
          "link": "https://arxiv.org/abs/2507.17257v1",
          "size": "7213kb",
          "version": "v1"
        }
      ],
      "title": "Agent Identity Evals: Measuring Agentic Identity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17257",
        "HTML": "https://arxiv.org/html/2507.17257v1",
        "PDF": "https://arxiv.org/pdf/2507.17257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for measuring agent identity in language model agents, but it does not cover LLM training data processing, including pretraining or fine-tuning operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17258",
      "abstract": "Building on prior research on Generative AI (GenAI) and related tools for programming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini, to support novice learners. SCRIPT allows for open-ended interactions and structured guidance through predefined prompts. We evaluated the tool via an experiment with 136 students from an introductory programming course at a large German university and analyzed how students interacted with SCRIPT while solving programming tasks with a focus on their feedback preferences. The results reveal that students' feedback requests seem to follow a specific sequence. Moreover, the chatbot responses aligned well with students' requested feedback types (in 75%), and it adhered to the system prompt constraints. These insights inform the design of GenAI-based learning support systems and highlight challenges in balancing guidance and flexibility in AI-assisted tools.",
      "authors": [
        "Andreas Scholl and Natalie Kiesler"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:56:26+00:00",
          "link": "https://arxiv.org/abs/2507.17258v1",
          "size": "311kb",
          "version": "v1"
        }
      ],
      "title": "Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17258",
        "HTML": "https://arxiv.org/html/2507.17258v1",
        "PDF": "https://arxiv.org/pdf/2507.17258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the use of a chatbot for educational purposes, focusing on feedback interactions. It does not discuss training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17259",
      "abstract": "Large language models (LLMs) are increasingly trained on tabular data, which, unlike unstructured text, often contains personally identifiable information (PII) in a highly structured and explicit format. As a result, privacy risks arise, since sensitive records can be inadvertently retained by the model and exposed through data extraction or membership inference attacks (MIAs). While existing MIA methods primarily target textual content, their efficacy and threat implications may differ when applied to structured data, due to its limited content, diverse data types, unique value distributions, and column-level semantics. In this paper, we present Tab-MIA, a benchmark dataset for evaluating MIAs on tabular data in LLMs and demonstrate how it can be used. Tab-MIA comprises five data collections, each represented in six different encoding formats. Using our Tab-MIA benchmark, we conduct the first evaluation of state-of-the-art MIA methods on LLMs finetuned with tabular data across multiple encoding formats. In the evaluation, we analyze the memorization behavior of pretrained LLMs on structured data derived from Wikipedia tables. Our findings show that LLMs memorize tabular data in ways that vary across encoding formats, making them susceptible to extraction via MIAs. Even when fine-tuned for as few as three epochs, models exhibit high vulnerability, with AUROC scores approaching 90% in most cases. Tab-MIA enables systematic evaluation of these risks and provides a foundation for developing privacy-preserving methods for tabular data in LLMs.",
      "authors": [
        "Eyal German",
        "Sagiv Antebi",
        "Daniel Samira",
        "Asaf Shabtai",
        "Yuval Elovici"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T06:56:34+00:00",
          "link": "https://arxiv.org/abs/2507.17259v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17259",
        "HTML": "https://arxiv.org/html/2507.17259v1",
        "PDF": "https://arxiv.org/pdf/2507.17259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating membership inference attacks on tabular data within LLMs, which pertains to privacy risks and model security rather than training data processing techniques or data quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17262",
      "abstract": "Visual Question Answering (VQA) has been a widely studied topic, with extensive research focusing on how VLMs respond to answerable questions based on real-world images. However, there has been limited exploration of how these models handle unanswerable questions, particularly in cases where they should abstain from providing a response. This research investigates VQA performance on unrealistically generated images or asking unanswerable questions, assessing whether models recognize the limitations of their knowledge or attempt to generate incorrect answers. We introduced a dataset, VisionTrap, comprising three categories of unanswerable questions across diverse image types: (1) hybrid entities that fuse objects and animals, (2) objects depicted in unconventional or impossible scenarios, and (3) fictional or non-existent figures. The questions posed are logically structured yet inherently unanswerable, testing whether models can correctly recognize their limitations. Our findings highlight the importance of incorporating such questions into VQA benchmarks to evaluate whether models tend to answer, even when they should abstain.",
      "authors": [
        "Asir Saadat",
        "Syem Aziz",
        "Shahriar Mahmud",
        "Abdullah Ibne Masud Mahi and Sabbir Ahmed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:00:19+00:00",
          "link": "https://arxiv.org/abs/2507.17262v1",
          "size": "13506kb",
          "version": "v1"
        }
      ],
      "title": "VisionTrap: Unanswerable Questions On Visual Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17262",
        "HTML": "https://arxiv.org/html/2507.17262v1",
        "PDF": "https://arxiv.org/pdf/2507.17262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses Visual Question Answering (VQA) and the handling of unanswerable questions by VLMs, but it does not discuss any aspect of LLM training data processing or relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17264",
      "abstract": "Prompting foundation models (FMs) like large language models (LLMs) have enabled new AI-powered software features (e.g., text summarization) that previously were only possible by fine-tuning FMs. Now, developers are embedding prompts in software, known as prompt programs. The process of prompt programming requires the developer to make many changes to their prompt. Yet, the questions developers ask to update their prompt is unknown, despite the answers to these questions affecting how developers plan their changes. With the growing number of research and commercial prompt programming tools, it is unclear whether prompt programmers' needs are being adequately addressed. We address these challenges by developing a taxonomy of 25 tasks prompt programmers do and 51 questions they ask, measuring the importance of each task and question. We interview 16 prompt programmers, observe 8 developers make prompt changes, and survey 50 developers. We then compare the taxonomy with 48 research and commercial tools. We find that prompt programming is not well-supported: all tasks are done manually, and 16 of the 51 questions -- including a majority of the most important ones -- remain unanswered. Based on this, we outline important opportunities for prompt programming tools.",
      "authors": [
        "Jenny T. Liang",
        "Chenyang Yang",
        "Agnia Sergeyuk",
        "Travis D. Breaux",
        "Brad A. Myers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:01:44+00:00",
          "link": "https://arxiv.org/abs/2507.17264v1",
          "size": "215kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Prompt Programming Tasks and Questions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17264",
        "PDF": "https://arxiv.org/pdf/2507.17264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper is primarily focused on prompt programming for foundation models, it indirectly touches on the importance of prompt datasets and the need for supportive tools, but does not address significant data processing operations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17265",
      "abstract": "We present a novel visualization-driven illumination model for density plots, a new technique to enhance density plots by effectively revealing the detailed structures in high- and medium-density regions and outliers in low-density regions, while avoiding artifacts in the density field's colors. When visualizing large and dense discrete point samples, scatterplots and dot density maps often suffer from overplotting, and density plots are commonly employed to provide aggregated views while revealing underlying structures. Yet, in such density plots, existing illumination models may produce color distortion and hide details in low-density regions, making it challenging to look up density values, compare them, and find outliers. The key novelty in this work includes (i) a visualization-driven illumination model that inherently supports density-plot-specific analysis tasks and (ii) a new image composition technique to reduce the interference between the image shading and the color-encoded density values. To demonstrate the effectiveness of our technique, we conducted a quantitative study, an empirical evaluation of our technique in a controlled study, and two case studies, exploring twelve datasets with up to two million data point samples.",
      "authors": [
        "Xin Chen",
        "Yunhai Wang",
        "Huaiwei Bao",
        "Kecheng Lu",
        "Jaemin Jo",
        "Chi-Wing Fu",
        "Jean-Daniel Fekete"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:02:13+00:00",
          "link": "https://arxiv.org/abs/2507.17265v1",
          "size": "8643kb",
          "version": "v1"
        }
      ],
      "title": "Visualization-Driven Illumination for Density Plots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17265",
        "HTML": "https://arxiv.org/html/2507.17265v1",
        "PDF": "https://arxiv.org/pdf/2507.17265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a visualization-driven technique for density plots, focusing on density field visualization and not related to LLM data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17268",
      "abstract": "Polarization images facilitate image enhancement and 3D reconstruction tasks, but the limited accessibility of polarization cameras hinders their broader application. This gap drives the need for synthesizing photorealistic polarization images.The existing polarization simulator Mitsuba relies on a parametric polarization image formation model and requires extensive 3D assets covering shape and PBR materials, preventing it from generating large-scale photorealistic images. To address this problem, we propose PolarAnything, capable of synthesizing polarization images from a single RGB input with both photorealism and physical accuracy, eliminating the dependency on 3D asset collections. Drawing inspiration from the zero-shot performance of pretrained diffusion models, we introduce a diffusion-based generative framework with an effective representation strategy that preserves the fidelity of polarization properties. Experiments show that our model generates high-quality polarization images and supports downstream tasks like shape from polarization.",
      "authors": [
        "Kailong Zhang",
        "Youwei Lyu",
        "Heng Guo",
        "Si Li",
        "Zhanyu Ma",
        "Boxin Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:09:10+00:00",
          "link": "https://arxiv.org/abs/2507.17268v1",
          "size": "20195kb",
          "version": "v1"
        }
      ],
      "title": "PolarAnything: Diffusion-based Polarimetric Image Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17268",
        "HTML": "https://arxiv.org/html/2507.17268v1",
        "PDF": "https://arxiv.org/pdf/2507.17268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a technique for generating polarization images using diffusion models, which pertains to image synthesis rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17270",
      "abstract": "This experience report analyses a one year project focused on building a distributed real-time analytics system using edge computing and machine learning. The project faced critical setbacks due to a big-bang integration approach, where all components developed by multiple geographically dispersed partners were merged at the final stage. The integration effort resulted in only six minutes of system functionality, far below the expected 40 minutes. Through root cause analysis, the study identifies technical and organisational barriers, including poor communication, lack of early integration testing, and resistance to topdown planning. It also considers psychological factors such as a bias toward fully developed components over mockups. The paper advocates for early mock based deployment, robust communication infrastructures, and the adoption of topdown thinking to manage complexity and reduce risk in reactive, distributed projects. These findings underscore the limitations of traditional Agile methods in such contexts and propose simulation-driven engineering and structured integration cycles as key enablers for future success.",
      "authors": [
        "Alessandro Aneggi",
        "Andrea Janes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:16:45+00:00",
          "link": "https://arxiv.org/abs/2507.17270v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "Lessons from a Big-Bang Integration: Challenges in Edge Computing and Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17270",
        "HTML": "https://arxiv.org/html/2507.17270v1",
        "PDF": "https://arxiv.org/pdf/2507.17270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a report on challenges faced during a system integration project using edge computing and machine learning. It focuses on integration challenges and does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17271",
      "abstract": "Unit tests play a vital role in the software development lifecycle. Recent advances in Large Language Model (LLM)-based approaches have significantly improved automated test generation, garnering attention from both academia and industry. We revisit LLM-based unit test generation from a novel perspective by decoupling prefix generation and assertion generation. To characterize their respective challenges, we define Initialization Complexity and adopt Cyclomatic Complexity to measure the difficulty of prefix and assertion generation, revealing that the former primarily affects compilation success, while the latter influences test coverage. To address these challenges, we propose Seed&Steer, a two-step approach that combines traditional unit testing techniques with the capabilities of large language models. Seed&Steer leverages conventional unit testing tools (e.g., EvoSuite) to generate method invocations with high compilation success rates, which serve as seeds to guide LLMs in constructing effective test contexts. It then introduces branching cues to help LLMs explore diverse execution paths (e.g., normal, boundary, and exception cases) and generate assertions with high coverage. We evaluate Seed&Steer on five real-world Java projects against state-of-the-art baselines. Results show that Seed&Steer improves the compilation pass rate by approximately 7%, successfully compiling 792 and 887 previously failing cases on two LLMs. It also achieves up to ~73% branch and line coverage across focal methods of varying complexity, with coverage improvements ranging from 1.09* to 1.26*. Our code, dataset, and experimental scripts will be publicly released to support future research and reproducibility.",
      "authors": [
        "Shuaiyu Zhou",
        "Zhengran Zeng",
        "Xiaoling Zhou",
        "Rui Xie",
        "Shikun Zhang",
        "Wei Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:16:46+00:00",
          "link": "https://arxiv.org/abs/2507.17271v1",
          "size": "576kb",
          "version": "v1"
        }
      ],
      "title": "Seed&Steer: Guiding Large Language Models with Compilable Prefix and Branch Signals for Unit Test Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17271",
        "HTML": "https://arxiv.org/html/2507.17271v1",
        "PDF": "https://arxiv.org/pdf/2507.17271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Seed&Steer, a method using LLMs for unit test generation, which involves test dataset generation. However, its main focus is on testing methodologies and LLM application in testing, not explicitly on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17273",
      "abstract": "Analyzing large, complex output datasets from Discrete Event Simulations (DES) of warehouse operations to identify bottlenecks and inefficiencies is a critical yet challenging task, often demanding significant manual effort or specialized analytical tools. Our framework integrates Knowledge Graphs (KGs) and Large Language Model (LLM)-based agents to analyze complex Discrete Event Simulation (DES) output data from warehouse operations. It transforms raw DES data into a semantically rich KG, capturing relationships between simulation events and entities. An LLM-based agent uses iterative reasoning, generating interdependent sub-questions. For each sub-question, it creates Cypher queries for KG interaction, extracts information, and self-reflects to correct errors. This adaptive, iterative, and self-correcting process identifies operational issues mimicking human analysis. Our DES approach for warehouse bottleneck identification, tested with equipment breakdowns and process irregularities, outperforms baseline methods. For operational questions, it achieves near-perfect pass rates in pinpointing inefficiencies. For complex investigative questions, we demonstrate its superior diagnostic ability to uncover subtle, interconnected issues. This work bridges simulation modeling and AI (KG+LLM), offering a more intuitive method for actionable insights, reducing time-to-insight, and enabling automated warehouse inefficiency evaluation and diagnosis.",
      "authors": [
        "Rishi Parekh",
        "Saisubramaniam Gopalakrishnan",
        "Zishan Ahmad",
        "Anirudh Deodhar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:18:55+00:00",
          "link": "https://arxiv.org/abs/2507.17273v1",
          "size": "186kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17273",
        "HTML": "https://arxiv.org/html/2507.17273v1",
        "PDF": "https://arxiv.org/pdf/2507.17273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on using LLMs and knowledge graphs to identify bottlenecks in warehouse operations. It does not make a contribution to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17275",
      "abstract": "In inaccessible environments with uncertain task demands, robots often rely on general-purpose tools that lack predefined usage strategies. These tools are not tailored for particular operations, making their longevity highly sensitive to how they are used. This creates a fundamental challenge: how can a robot learn a tool-use policy that both completes the task and prolongs the tool's lifespan? In this work, we address this challenge by introducing a reinforcement learning (RL) framework that incorporates tool lifespan as a factor during policy optimization. Our framework leverages Finite Element Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based on accumulated stress, and integrates the RUL into the RL reward to guide policy learning toward lifespan-guided behavior. To handle the fact that RUL can only be estimated after task execution, we introduce an Adaptive Reward Normalization (ARN) mechanism that dynamically adjusts reward scaling based on estimated RULs, ensuring stable learning signals. We validate our method across simulated and real-world tool use tasks, including Object-Moving and Door-Opening with multiple general-purpose tools. The learned policies consistently prolong tool lifespan (up to 8.01x in simulation) and transfer effectively to real-world settings, demonstrating the practical value of learning lifespan-guided tool use strategies.",
      "authors": [
        "Po-Yen Wu",
        "Cheng-Yu Kuo",
        "Yuki Kadokawa",
        "and Takamitsu Matsubara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:25:04+00:00",
          "link": "https://arxiv.org/abs/2507.17275v1",
          "size": "5112kb",
          "version": "v1"
        }
      ],
      "title": "Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17275",
        "HTML": "https://arxiv.org/html/2507.17275v1",
        "PDF": "https://arxiv.org/pdf/2507.17275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning for tool-use policies to prolong tool lifespan. It centers on RL and tool lifespan without relevance to LLM training data processing or associated methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17281",
      "abstract": "Although SAM-based single-source domain generalization models for medical image segmentation can mitigate the impact of domain shift on the model in cross-domain scenarios, these models still face two major challenges. First, the segmentation of SAM is highly dependent on domain-specific expert-annotated prompts, which prevents SAM from achieving fully automated medical image segmentation and therefore limits its application in clinical settings. Second, providing poor prompts (such as bounding boxes that are too small or too large) to the SAM prompt encoder can mislead SAM into generating incorrect mask results. Therefore, we propose the FA-SAM, a single-source domain generalization framework for medical image segmentation that achieves fully automated SAM. FA-SAM introduces two key innovations: an Auto-prompted Generation Model (AGM) branch equipped with a Shallow Feature Uncertainty Modeling (SUFM) module, and an Image-Prompt Embedding Fusion (IPEF) module integrated into the SAM mask decoder. Specifically, AGM models the uncertainty distribution of shallow features through the SUFM module to generate bounding box prompts for the target domain, enabling fully automated segmentation with SAM. The IPEF module integrates multiscale information from SAM image embeddings and prompt embeddings to capture global and local details of the target object, enabling SAM to mitigate the impact of poor prompts. Extensive experiments on publicly available prostate and fundus vessel datasets validate the effectiveness of FA-SAM and highlight its potential to address the above challenges.",
      "authors": [
        "Huanli Zhuo",
        "Leilei Ma",
        "Haifeng Zhao",
        "Shiwei Zhou",
        "Dengdi Sun",
        "and Yanping Fu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:37:39+00:00",
          "link": "https://arxiv.org/abs/2507.17281v1",
          "size": "3232kb",
          "version": "v1"
        }
      ],
      "title": "Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17281",
        "HTML": "https://arxiv.org/html/2507.17281v1",
        "PDF": "https://arxiv.org/pdf/2507.17281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for automated medical image segmentation and addresses domain generalization challenges, without any mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17285",
      "abstract": "Federated learning is a paradigm of increasing relevance in real world applications, aimed at building a global model across a network of heterogeneous users without requiring the sharing of private data. We focus on model learning over decentralized architectures, where users collaborate directly to update the global model without relying on a central server. In this context, the current paper proposes a novel approach to collaboratively learn probabilistic generative classifiers with a parametric form. The framework is composed by a communication network over a set of local nodes, each of one having its own local data, and a local updating rule. The proposal involves sharing local statistics with neighboring nodes, where each node aggregates the neighbors' information and iteratively learns its own local classifier, which progressively converges to a global model. Extensive experiments demonstrate that the algorithm consistently converges to a globally competitive model across a wide range of network topologies, network sizes, local dataset sizes, and extreme non-i.i.d. data distributions.",
      "authors": [
        "Aritz P\\'erez",
        "Carlos Echegoyen and Guzm\\'an Santaf\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:45:20+00:00",
          "link": "https://arxiv.org/abs/2507.17285v1",
          "size": "383kb",
          "version": "v1"
        }
      ],
      "title": "Decentralized Federated Learning of Probabilistic Generative Classifiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17285",
        "HTML": "https://arxiv.org/html/2507.17285v1",
        "PDF": "https://arxiv.org/pdf/2507.17285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses decentralized federated learning for probabilistic generative classifiers, focusing on model learning and network architectures rather than any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17288",
      "abstract": "This paper describes our Triple X speech recognition system submitted to Task 1 of the Multi-Lingual Conversational Speech Language Modeling (MLC-SLM) Challenge. Our work focuses on optimizing speech recognition accuracy in multilingual conversational scenarios through an innovative encoder-adapter-LLM architecture. This framework harnesses the powerful reasoning capabilities of text-based large language models while incorporating domain-specific adaptations. To further enhance multilingual recognition performance, we adopted a meticulously designed multi-stage training strategy leveraging extensive multilingual audio datasets. Experimental results demonstrate that our approach achieves competitive Word Error Rate (WER) performance on both dev and test sets, obtaining second place in the challenge ranking.",
      "authors": [
        "Miaomiao Gao",
        "Xiaoxiao Xiang and Yiwen Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:48:33+00:00",
          "link": "https://arxiv.org/abs/2507.17288v1",
          "size": "317kb",
          "version": "v1"
        }
      ],
      "title": "Triple X: A LLM-Based Multilingual Speech Recognition System for the INTERSPEECH2025 MLC-SLM Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17288",
        "HTML": "https://arxiv.org/html/2507.17288v1",
        "PDF": "https://arxiv.org/pdf/2507.17288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a multilingual speech recognition system using LLMs, emphasizing an architecture for optimizing recognition accuracy without addressing training data processing for pretraining or fine-tuning of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17289",
      "abstract": "This paper presents Compliance Brain Assistant (CBA), a conversational, agentic AI assistant designed to boost the efficiency of daily compliance tasks for personnel in enterprise environments. To strike a good balance between response quality and latency, we design a user query router that can intelligently choose between (i) FastTrack mode: to handle simple requests that only need additional relevant context retrieved from knowledge corpora; and (ii) FullAgentic mode: to handle complicated requests that need composite actions and tool invocations to proactively discover context across various compliance artifacts, and/or involving other APIs/models for accommodating requests. A typical example would be to start with a user query, use its description to find a specific entity and then use the entity's information to query other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on various real-world privacy/compliance-related queries targeting various personas. We found that CBA substantially improved upon the vanilla LLM's performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full routing-based design against the `fast-track only` and `full-agentic` modes and found that it had a better average match-rate and pass-rate while keeping the run-time approximately the same. This finding validated our hypothesis that the routing mechanism leads to a good trade-off between the two worlds.",
      "authors": [
        "Shitong Zhu",
        "Chenhao Fang",
        "Derek Larson",
        "Neel Reddy Pochareddy",
        "Rajeev Rao",
        "Sophie Zeng",
        "Yanqing Peng",
        "Wendy Summer",
        "Alex Goncalves",
        "Arya Pudota",
        "Herve Robert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:51:10+00:00",
          "link": "https://arxiv.org/abs/2507.17289v1",
          "size": "443kb",
          "version": "v1"
        }
      ],
      "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17289",
        "HTML": "https://arxiv.org/html/2507.17289v1",
        "PDF": "https://arxiv.org/pdf/2507.17289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a conversational AI assistant for compliance tasks, focusing on balancing response quality and latency; it does not involve any contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17290",
      "abstract": "Serendipity plays a pivotal role in enhancing user satisfaction within recommender systems, yet its evaluation poses significant challenges due to its inherently subjective nature and conceptual ambiguity. Current algorithmic approaches predominantly rely on proxy metrics for indirect assessment, often failing to align with real user perceptions, thus creating a gap. With large language models (LLMs) increasingly revolutionizing evaluation methodologies across various human annotation tasks, we are inspired to explore a core research proposition: Can LLMs effectively simulate human users for serendipity evaluation? To address this question, we conduct a meta-evaluation on two datasets derived from real user studies in the e-commerce and movie domains, focusing on three key aspects: the accuracy of LLMs compared to conventional proxy metrics, the influence of auxiliary data on LLM comprehension, and the efficacy of recently popular multi-LLM techniques. Our findings indicate that even the simplest zero-shot LLMs achieve parity with, or surpass, the performance of conventional metrics. Furthermore, multi-LLM techniques and the incorporation of auxiliary data further enhance alignment with human perspectives. Based on our findings, the optimal evaluation by LLMs yields a Pearson correlation coefficient of 21.5\\% when compared to the results of the user study. This research implies that LLMs may serve as potentially accurate and cost-effective evaluators, introducing a new paradigm for serendipity evaluation in recommender systems.",
      "authors": [
        "Li Kang",
        "Yuhan Zhao",
        "Li Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:51:56+00:00",
          "link": "https://arxiv.org/abs/2507.17290v1",
          "size": "158kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Potential of LLMs for Serendipity Evaluation in Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17290",
        "HTML": "https://arxiv.org/html/2507.17290v1",
        "PDF": "https://arxiv.org/pdf/2507.17290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores the use of LLMs for serendipity evaluation in recommender systems, a task unrelated to LLM training data processing, focusing on evaluation rather than data engineering or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17291",
      "abstract": "Probabilistic Logic Programming (PLP) under the Distribution Semantics is a leading approach to practical reasoning under uncertainty. An advantage of the Distribution Semantics is its suitability for implementation as a Prolog or Python library, available through two well-maintained implementations, namely ProbLog and cplint/PITA. However, current formulations of the Distribution Semantics use point-probabilities, making it difficult to express epistemic uncertainty, such as arises from, for example, hierarchical classifications from computer vision models. Belief functions generalize probability measures as non-additive capacities, and address epistemic uncertainty via interval probabilities. This paper introduces interval-based Capacity Logic Programs based on an extension of the Distribution Semantics to include belief functions, and describes properties of the new framework that make it amenable to practical applications.",
      "authors": [
        "Damiano Azzolini",
        "Fabrizio Riguzzi",
        "Theresa Swift"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:52:09+00:00",
          "link": "https://arxiv.org/abs/2507.17291v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Belief Domains into Probabilistic Logic Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17291",
        "HTML": "https://arxiv.org/html/2507.17291v1",
        "PDF": "https://arxiv.org/pdf/2507.17291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on extending Probabilistic Logic Programming by integrating belief functions to express epistemic uncertainty. It does not discuss LLM training data processing or related data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17293",
      "abstract": "Nowadays, machine learning (ML) teams have multiple concurrent ML workflows for different applications. Each workflow typically involves many experiments, iterations, and collaborative activities and commonly takes months and sometimes years from initial data wrangling to model deployment. Organizationally, there is a large amount of intermediate data to be stored, processed, and maintained. \\emph{Data virtualization} becomes a critical technology in an infrastructure to serve ML workflows. In this paper, we present the design and implementation of a data virtualization service, focusing on its service architecture and service operations. The infrastructure currently supports six ML applications, each with more than one ML workflow. The data virtualization service allows the number of applications and workflows to grow in the coming years.",
      "authors": [
        "Saiful Khan",
        "Joyraj Chakraborty",
        "Philip Beaucamp",
        "Niraj Bhujel",
        "Min Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:53:56+00:00",
          "link": "https://arxiv.org/abs/2507.17293v1",
          "size": "1302kb",
          "version": "v1"
        }
      ],
      "title": "Data Virtualization for Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17293",
        "HTML": "https://arxiv.org/html/2507.17293v1",
        "PDF": "https://arxiv.org/pdf/2507.17293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses data virtualization infrastructure for supporting machine learning workflows. It focuses on architecture and operations of a virtualization service, not on LLM training data processing operations such as collection or filtering for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17294",
      "abstract": "Tactile feedback is generally recognized to be crucial for effective interaction with the physical world. However, state-of-the-art Vision-Language-Action (VLA) models lack the ability to interpret and use tactile signals, limiting their effectiveness in contact-rich tasks. Incorporating tactile feedback into these systems is challenging due to the absence of large multi-modal datasets. We present VLA-Touch, an approach that enhances generalist robot policies with tactile sensing \\emph{without fine-tuning} the base VLA. Our method introduces two key innovations: (1) a pipeline that leverages a pretrained tactile-language model that provides semantic tactile feedback for high-level task planning, and (2) a diffusion-based controller that refines VLA-generated actions with tactile signals for contact-rich manipulation. Through real-world experiments, we demonstrate that our dual-level integration of tactile feedback improves task planning efficiency while enhancing execution precision. Code is open-sourced at \\href{https://github.com/jxbi1010/VLA-Touch}{this URL}.",
      "authors": [
        "Jianxin Bi",
        "Kevin Yuchen Ma",
        "Ce Hao",
        "Mike Zheng Shou",
        "Harold Soh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:54:10+00:00",
          "link": "https://arxiv.org/abs/2507.17294v1",
          "size": "4350kb",
          "version": "v1"
        }
      ],
      "title": "VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17294",
        "PDF": "https://arxiv.org/pdf/2507.17294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents VLA-Touch, an approach to enhance Vision-Language-Action models with tactile feedback. It does not address any aspect of LLM training data processing or the creation/processing of datasets for such models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17296",
      "abstract": "Mamba has recently gained widespread attention as a backbone model for point cloud modeling, leveraging a state-space architecture that enables efficient global sequence modeling with linear complexity. However, its lack of local inductive bias limits its capacity to capture fine-grained geometric structures in 3D data. To address this limitation, we propose \\textbf{PointLAMA}, a point cloud pretraining framework that combines task-aware point cloud serialization, a hybrid encoder with integrated Latent Attention and Mamba blocks, and a conditional diffusion mechanism built upon the Mamba backbone. Specifically, the task-aware point cloud serialization employs Hilbert/Trans-Hilbert space-filling curves and axis-wise sorting to structurally align point tokens for classification and segmentation tasks, respectively. Our lightweight Latent Attention block features a Point-wise Multi-head Latent Attention (PMLA) module, which is specifically designed to align with the Mamba architecture by leveraging the shared latent space characteristics of PMLA and Mamba. This enables enhanced local context modeling while preserving overall efficiency. To further enhance representation learning, we incorporate a conditional diffusion mechanism during pretraining, which denoises perturbed feature sequences without relying on explicit point-wise reconstruction. Experimental results demonstrate that PointLAMA achieves competitive performance on multiple benchmark datasets with minimal parameter count and FLOPs, validating its effectiveness for efficient point cloud pretraining.",
      "authors": [
        "Xuanyu Lin",
        "Xiaona Zeng",
        "Xianwei Zheng",
        "Xutao Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:57:35+00:00",
          "link": "https://arxiv.org/abs/2507.17296v1",
          "size": "1852kb",
          "version": "v1"
        }
      ],
      "title": "PointLAMA: Latent Attention meets Mamba for Efficient Point Cloud Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17296",
        "HTML": "https://arxiv.org/html/2507.17296v1",
        "PDF": "https://arxiv.org/pdf/2507.17296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes PointLAMA for efficient point cloud pretraining using a novel model architecture. The focus is on pretraining techniques and model efficiency, not on LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17297",
      "abstract": "Spatial semantic segmentation of sound scenes (S5) involves the accurate identification of active sound classes and the precise separation of their sources from complex acoustic mixtures. Conventional systems rely on a two-stage pipeline - audio tagging followed by label-conditioned source separation - but are often constrained by the absence of fine-grained temporal information critical for effective separation. In this work, we address this limitation by introducing a novel approach for S5 that enhances the synergy between the event detection and source separation stages. Our key contributions are threefold. First, we fine-tune a pre-trained Transformer to detect active sound classes. Second, we utilize a separate instance of this fine-tuned Transformer to perform sound event detection (SED), providing the separation module with detailed, time-varying guidance. Third, we implement an iterative refinement mechanism that progressively enhances separation quality by recursively reusing the separator's output from previous iterations. These advancements lead to significant improvements in both audio tagging and source separation performance, as demonstrated by our system's second-place finish in Task 4 of the DCASE Challenge 2025. Our implementation and model checkpoints are available in our GitHub repository: https://github.com/theMoro/dcase25task4 .",
      "authors": [
        "Tobias Morocutti",
        "Jonathan Greif",
        "Paul Primus",
        "Florian Schmid",
        "Gerhard Widmer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:58:28+00:00",
          "link": "https://arxiv.org/abs/2507.17297v1",
          "size": "1202kb",
          "version": "v1"
        }
      ],
      "title": "On Temporal Guidance and Iterative Refinement in Audio Source Separation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17297",
        "HTML": "https://arxiv.org/html/2507.17297v1",
        "PDF": "https://arxiv.org/pdf/2507.17297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with audio source separation via temporal guidance and iterative refinement methods for spatial semantic segmentation. It does not relate to LLM training data processing or provide methods impacting data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17300",
      "abstract": "In pattern matching on strings, a locate query asks for an enumeration of all the occurrences of a given pattern in a given text. The r-index [Gagie et al., 2018] is a recently presented compressed self index that stores the text and auxiliary information in compressed space. With some modifications, locate queries can be answered in optimal time [Nishimoto & Tabei, 2021], which has recently been proven relevant in practice in the form of Move-r [Bertram et al., 2024]. However, there remains the practical bottleneck of evaluating function $\\Phi$ for every occurrence to report. This motivates enhancing the index by a compressed representation of the suffix array featuring efficient random access, trading off space for faster answering of locate queries [Puglisi & Zhukova, 2021]. In this work, we build upon this idea considering two suitable compression schemes: Relative Lempel-Ziv [Kuruppu et al., 2010], improving the work by Puglisi and Zhukova, and LZ-End [Kreft & Navarro, 2010], introducing a different trade-off where compression is better than for Relative Lempel-Ziv at the cost of slower access times. We enhance both the r-index and Move-r by the compressed suffix arrays and evaluate locate query performance in an experiment. We show that locate queries can be sped up considerably in both the r-index and Move-r, especially if the queried pattern has many occurrences. The choice between two different compression schemes offers new trade-offs regarding index size versus query performance.",
      "authors": [
        "Patrick Dinklage",
        "Johannes Fischer",
        "Lukas Nalbach and Jan Zumbrink"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:01:29+00:00",
          "link": "https://arxiv.org/abs/2507.17300v1",
          "size": "157kb",
          "version": "v1"
        }
      ],
      "title": "RLZ-r and LZ-End-r: Enhancing Move-r",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17300",
        "PDF": "https://arxiv.org/pdf/2507.17300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing pattern matching on strings using compression schemes for improving indexing performance. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17301",
      "abstract": "In deep learning frameworks, weight pruning is a widely used technique for improving computational efficiency by reducing the size of large models. This is especially critical for convolutional operators, which often act as performance bottlenecks in convolutional neural networks (CNNs). However, the effectiveness of pruning heavily depends on how it is implemented, as different methods can significantly impact both computational performance and memory footprint. In this work, we propose a column-wise N:M pruning strategy applied at the tile level and modify XNNPACK to enable efficient execution of pruned models on the RISC-V vector architecture. Additionally, we propose fusing the operations of im2col and data packing to minimize redundant memory accesses and memory overhead. To further optimize performance, we incorporate AITemplate's profiling technique to identify the optimal implementation for each convolutional operator. Our proposed approach effectively increases ResNet inference throughput by as much as 4.0x, and preserves ImageNet top-1 accuracy within 2.1\\% of the dense baseline.",
      "authors": [
        "Chi-Wei Chu",
        "Ding-Yong Hong",
        "Jan-Jan Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.17301v1",
          "size": "431kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Column-Wise N:M Pruning on RISC-V CPU",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17301",
        "HTML": "https://arxiv.org/html/2507.17301v1",
        "PDF": "https://arxiv.org/pdf/2507.17301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a column-wise N:M pruning strategy to improve computational efficiency on RISC-V CPU architectures. It is related to model efficiency rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17304",
      "abstract": "In the context of Industry 4.0, effective monitoring of multiple targets and states during assembly processes is crucial, particularly when constrained to using only visual sensors. Traditional methods often rely on either multiple sensor types or complex hardware setups to achieve high accuracy in monitoring, which can be cost-prohibitive and difficult to implement in dynamic industrial environments. This study presents a novel approach that leverages multiple machine learning models to achieve precise monitoring under the limitation of using a minimal number of visual sensors. By integrating state information from identical timestamps, our method detects and confirms the current stage of the assembly process with an average accuracy exceeding 92%. Furthermore, our approach surpasses conventional methods by offering enhanced error detection and visuali-zation capabilities, providing real-time, actionable guidance to operators. This not only improves the accuracy and efficiency of assembly monitoring but also re-duces dependency on expensive hardware solutions, making it a more practical choice for modern industrial applications.",
      "authors": [
        "Xingjian Zhang",
        "Yutong Duan",
        "Zaishu Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:10:27+00:00",
          "link": "https://arxiv.org/abs/2507.17304v1",
          "size": "692kb",
          "version": "v1"
        }
      ],
      "title": "Learning-based Stage Verification System in Manual Assembly Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17304",
        "PDF": "https://arxiv.org/pdf/2507.17304"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on a machine learning-based system for monitoring assembly stages using visual sensors in industrial settings. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17307",
      "abstract": "Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of large language models by encouraging step-by-step intermediate reasoning during inference. While effective, CoT introduces substantial computational overhead due to its reliance on autoregressive decoding over long token sequences. Existing acceleration strategies either reduce sequence length through early stopping or compressive reward designs, or improve decoding speed via speculative decoding with smaller models. However, speculative decoding suffers from limited speedup when the agreement between small and large models is low, and fails to exploit the potential advantages of small models in producing concise intermediate reasoning. In this paper, we present R-Stitch, a token-level, confidence-based hybrid decoding framework that accelerates CoT inference by switching between a small language model (SLM) and a large language model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to generate tokens by default and delegates to the LLM only when the SLM's confidence falls below a threshold. This design avoids full-sequence rollback and selectively invokes the LLM on uncertain steps, preserving both efficiency and answer quality. R-Stitch is model-agnostic, training-free, and compatible with standard decoding pipelines. Experiments on math reasoning benchmarks demonstrate that R-Stitch achieves up to 85\\% reduction in inference latency with negligible accuracy drop, highlighting its practical effectiveness in accelerating CoT reasoning.",
      "authors": [
        "Zhuokun Chen",
        "Zeren Chen",
        "Jiahao He",
        "Mingkui Tan",
        "Jianfei Cai",
        "and Bohan Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:14:36+00:00",
          "link": "https://arxiv.org/abs/2507.17307v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17307",
        "HTML": "https://arxiv.org/html/2507.17307v1",
        "PDF": "https://arxiv.org/pdf/2507.17307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents R-Stitch, a method for accelerating chain-of-thought reasoning in LLMs by optimizing inference processes. It does not cover aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17309",
      "abstract": "Imitation learning from demonstrations usually suffers from the confounding effects of unmeasured variables (i.e., unmeasured confounders) on the states and actions. If ignoring them, a biased estimation of the policy would be entailed. To break up this confounding gap, in this paper, we take the best of the strong power of instrumental variables (IV) and propose a Confounded Causal Imitation Learning (C2L) model. This model accommodates confounders that influence actions across multiple timesteps, rather than being restricted to immediate temporal dependencies. We develop a two-stage imitation learning framework for valid IV identification and policy optimization. In particular, in the first stage, we construct a testing criterion based on the defined pseudo-variable, with which we achieve identifying a valid IV for the C2L models. Such a criterion entails the sufficient and necessary identifiability conditions for IV validity. In the second stage, with the identified IV, we propose two candidate policy learning approaches: one is based on a simulator, while the other is offline. Extensive experiments verified the effectiveness of identifying the valid IV as well as learning the policy.",
      "authors": [
        "Yan Zeng",
        "Shenglan Nie",
        "Feng Xie",
        "Libo Huang",
        "Peng Wu",
        "and Zhi Geng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:23:34+00:00",
          "link": "https://arxiv.org/abs/2507.17309v1",
          "size": "169kb",
          "version": "v1"
        }
      ],
      "title": "Confounded Causal Imitation Learning with Instrumental Variables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17309",
        "HTML": "https://arxiv.org/html/2507.17309v1",
        "PDF": "https://arxiv.org/pdf/2507.17309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on imitation learning with instrumental variables, addressing issues like confounding variables in demonstrations. It does not involve LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17311",
      "abstract": "Modern Earth science is at an inflection point. The vast, fragmented, and complex nature of Earth system data, coupled with increasingly sophisticated analytical demands, creates a significant bottleneck for rapid scientific discovery. Here we introduce EarthLink, the first AI agent designed as an interactive copilot for Earth scientists. It automates the end-to-end research workflow, from planning and code generation to multi-scenario analysis. Unlike static diagnostic tools, EarthLink can learn from user interaction, continuously refining its capabilities through a dynamic feedback loop. We validated its performance on a number of core scientific tasks of climate change, ranging from model-observation comparisons to the diagnosis of complex phenomena. In a multi-expert evaluation, EarthLink produced scientifically sound analyses and demonstrated an analytical competency that was rated as comparable to specific aspects of a human junior researcher's workflow. Additionally, its transparent, auditable workflows and natural language interface empower scientists to shift from laborious manual execution to strategic oversight and hypothesis generation. EarthLink marks a pivotal step towards an efficient, trustworthy, and collaborative paradigm for Earth system research in an era of accelerating global change.",
      "authors": [
        "Zijie Guo",
        "Jiong Wang",
        "Xiaoyu Yue",
        "Wangxu Wei",
        "Zhe Jiang",
        "Wanghan Xu",
        "Ben Fei",
        "Wenlong Zhang",
        "Xinyu Gu",
        "Lijing Cheng",
        "Jing-Jia Luo",
        "Chao Li",
        "Yaqiang Wang",
        "Tao Chen",
        "Wanli Ouyang",
        "Fenghua Ling",
        "Lei Bai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:29:25+00:00",
          "link": "https://arxiv.org/abs/2507.17311v1",
          "size": "6344kb",
          "version": "v1"
        }
      ],
      "title": "EarthLink: Interpreting Climate Signals with Self-Evolving AI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17311",
        "HTML": "https://arxiv.org/html/2507.17311v1",
        "PDF": "https://arxiv.org/pdf/2507.17311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces EarthLink, an AI agent for Earth science research workflow automation. Although it deals with data processing in Earth sciences, it does not address LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17312",
      "abstract": "Semi-dense feature matching methods have shown strong performance in challenging scenarios. However, the existing pipeline relies on a global search across the entire feature map to establish coarse matches, limiting further improvements in accuracy and efficiency. Motivated by this limitation, we propose a novel pipeline, CasP, which leverages cascaded correspondence priors for guidance. Specifically, the matching stage is decomposed into two progressive phases, bridged by a region-based selective cross-attention mechanism designed to enhance feature discriminability. In the second phase, one-to-one matches are determined by restricting the search range to the one-to-many prior areas identified in the first phase. Additionally, this pipeline benefits from incorporating high-level features, which helps reduce the computational costs of low-level feature extraction. The acceleration gains of CasP increase with higher resolution, and our lite model achieves a speedup of $\\sim2.2\\times$ at a resolution of 1152 compared to the most efficient method, ELoFTR. Furthermore, extensive experiments demonstrate its superiority in geometric estimation, particularly with impressive cross-domain generalization. These advantages highlight its potential for latency-sensitive and high-robustness applications, such as SLAM and UAV systems. Code is available at https://github.com/pq-chen/CasP.",
      "authors": [
        "Peiqi Chen",
        "Lei Yu",
        "Yi Wan",
        "Yingying Pei",
        "Xinyi Liu",
        "Yongxiang Yao",
        "Yingying Zhang",
        "Lixiang Ru",
        "Liheng Zhong",
        "Jingdong Chen",
        "Ming Yang",
        "Yongjun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:29:26+00:00",
          "link": "https://arxiv.org/abs/2507.17312v1",
          "size": "2830kb",
          "version": "v1"
        }
      ],
      "title": "CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17312",
        "HTML": "https://arxiv.org/html/2507.17312v1",
        "PDF": "https://arxiv.org/pdf/2507.17312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a feature matching pipeline for improving semi-dense feature matching, specifically targeting applications like SLAM and UAV systems. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17314",
      "abstract": "Context. Code smells, which are recurring anomalies in design or style, have been extensively researched in professional code. However, their significance in block-based projects created by novices is still largely unknown. Block-based environments such as Scratch offer a unique, data-rich setting to examine how emergent design problems intersect with the cultivation of computational-thinking (CT) skills. Objective. This research explores the connection between CT proficiency and design-level code smells--issues that may hinder software maintenance and evolution--in programs created by Scratch developers. We seek to identify which CT dimensions align most strongly with which code smells and whether task context moderates those associations. Method. A random sample of aprox. 2 million public Scratch projects is mined. Using open-source linters, we extract nine CT scores and 40 code smell indicators from these projects. After rigorous pre-processing, we apply descriptive analytics, robust correlation tests, stratified cross-validation, and exploratory machine-learning models; qualitative spot-checks contextualize quantitative patterns. Impact. The study will deliver the first large-scale, fine-grained map linking specific CT competencies to concrete design flaws and antipatterns. Results are poised to (i) inform evidence-based curricula and automated feedback systems, (ii) provide effect-size benchmarks for future educational interventions, and (iii) supply an open, pseudonymized dataset and reproducible analysis pipeline for the research community. By clarifying how programming habits influence early skill acquisition, the work advances both computing-education theory and practical tooling for sustainable software maintenance and evolution.",
      "authors": [
        "Ricardo Hidalgo Arag\\'on",
        "Jes\\'us M. Gonz\\'alez-Barahona and Gregorio Robles"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:30:06+00:00",
          "link": "https://arxiv.org/abs/2507.17314v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "How Do Code Smells Affect Skill Growth in Scratch Novice Programmers?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17314",
        "HTML": "https://arxiv.org/html/2507.17314v1",
        "PDF": "https://arxiv.org/pdf/2507.17314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates the impact of code smells on skill growth in Scratch programming for novices. It is centered on educational data analysis, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17317",
      "abstract": "This work presents a new iteration of the Human Navigation Simulator (HuNavSim), a novel open-source tool for the simulation of different human-agent navigation behaviors in scenarios with mobile robots. The tool, programmed under the ROS 2 framework, can be used together with different well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main goal is to facilitate the development and evaluation of human-aware robot navigation systems in simulation. In this new version, several features have been improved and new ones added, such as the extended set of actions and conditions that can be combined in Behavior Trees to compound complex and realistic human behaviors.",
      "authors": [
        "Miguel Escudero-Jim\\'enez",
        "No\\'e P\\'erez-Higueras",
        "Andr\\'es Mart\\'inez-Silva",
        "Fernando Caballero",
        "Luis Merino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:31:35+00:00",
          "link": "https://arxiv.org/abs/2507.17317v1",
          "size": "8009kb",
          "version": "v1"
        }
      ],
      "title": "HuNavSim 2.0",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17317",
        "HTML": "https://arxiv.org/html/2507.17317v1",
        "PDF": "https://arxiv.org/pdf/2507.17317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a tool for simulating human-agent navigation behaviors in robotics, which does not relate to LLM training data processing or contribute to relevant data processing operations such as data collection, deduplication, or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17319",
      "abstract": "In this paper, necessary and sufficient conditions for the self-orthogonality of t-generator quasi-cyclic (QC) codes are presented under the Euclidean, Hermitian, and symplectic inner products, respectively. Particularly, by studying the structure of the dual codes of a class of 2-generator QC codes, we derive necessary and sufficient conditions for the QC codes to be dual-containing under the above three inner products. This class of 2-generator QC codes generalizes many known codes in the literature. Based on the above conditions, we construct several quantum stabilizer codes and quantum synchronizable codes with good parameters, some of which share parameters with certain best-known codes listed in Grassl's code table.",
      "authors": [
        "Mengying Gao",
        "Yuhua Sun",
        "Tongjiang Yan",
        "Chun'e Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:32:25+00:00",
          "link": "https://arxiv.org/abs/2507.17319v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Construction of Self-Orthogonal Quasi-Cyclic Codes and Their Application to Quantum Error-Correcting Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17319",
        "HTML": "https://arxiv.org/html/2507.17319v1",
        "PDF": "https://arxiv.org/pdf/2507.17319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the construction of quasi-cyclic codes and their application to quantum error-correcting codes, which is not related to LLM training data processing or the development of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17320",
      "abstract": "Discrete event sequences serve as models for numerous real-world datasets, including publications over time, project milestones, and medication dosing during patient treatments. These event sequences typically exhibit bursty behavior, where events cluster together in rapid succession, interspersed with periods of inactivity. Standard timeline charts with linear time axes fail to adequately represent such data, resulting in cluttered regions during event bursts while leaving other areas unutilized. We introduce EventLines, a novel technique that dynamically adjusts the time scale to match the underlying event distribution, enabling more efficient use of screen space. To address the challenges of non-linear time scaling, EventLines employs the time axis's visual representation itself to communicate the varying scale. We present findings from a crowdsourced graphical perception study that examines how different time scale representations influence temporal perception.",
      "authors": [
        "Yuet Ling Wong",
        "Niklas Elmqvist"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:34:34+00:00",
          "link": "https://arxiv.org/abs/2507.17320v1",
          "size": "613kb",
          "version": "v1"
        }
      ],
      "title": "EventLines: Time Compression for Discrete Event Timelines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17320",
        "HTML": "https://arxiv.org/html/2507.17320v1",
        "PDF": "https://arxiv.org/pdf/2507.17320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "EventLines introduces a technique for time compression in event sequences, which is unrelated to LLM training data processing or the creation and processing of datasets used in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17323",
      "abstract": "Colorectal cancer (CRC) remains a leading cause of cancer-related mortality, underscoring the importance of timely polyp detection and diagnosis. While deep learning models have improved optical-assisted diagnostics, they often demand extensive labeled datasets and yield \"black-box\" outputs with limited interpretability. In this paper, we propose EndoFinder, an online polyp retrieval framework that leverages multi-view scene representations for explainable and scalable CRC diagnosis. First, we develop a Polyp-aware Image Encoder by combining contrastive learning and a reconstruction task, guided by polyp segmentation masks. This self-supervised approach captures robust features without relying on large-scale annotated data. Next, we treat each polyp as a three-dimensional \"scene\" and introduce a Scene Representation Transformer, which fuses multiple views of the polyp into a single latent representation. By discretizing this representation through a hashing layer, EndoFinder enables real-time retrieval from a compiled database of historical polyp cases, where diagnostic information serves as interpretable references for new queries. We evaluate EndoFinder on both public and newly collected polyp datasets for re-identification and pathology classification. Results show that EndoFinder outperforms existing methods in accuracy while providing transparent, retrieval-based insights for clinical decision-making. By contributing a novel dataset and a scalable, explainable framework, our work addresses key challenges in polyp diagnosis and offers a promising direction for more efficient AI-driven colonoscopy workflows. The source code is available at https://github.com/ku262/EndoFinder-Scene.",
      "authors": [
        "Ruijie Yang",
        "Yan Zhu",
        "Peiyao Fu",
        "Yizhe Zhang",
        "Zhihua Wang",
        "Quanlin Li",
        "Pinghong Zhou",
        "Xian Yang and Shuo Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:45:19+00:00",
          "link": "https://arxiv.org/abs/2507.17323v1",
          "size": "14291kb",
          "version": "v1"
        }
      ],
      "title": "EndoFinder: Online Lesion Retrieval for Explainable Colorectal Polyp Diagnosis Leveraging Latent Scene Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17323",
        "HTML": "https://arxiv.org/html/2507.17323v1",
        "PDF": "https://arxiv.org/pdf/2507.17323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "EndoFinder is a framework for colorectal polyp diagnosis leveraging latent scene representations. It does not address data processing techniques or dataset construction for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17324",
      "abstract": "Virtual Reality (VR) has emerged as a transformative technology across industries, yet its security weaknesses, including vulnerabilities, are underinvestigated. This study investigates 334 VR projects hosted on GitHub, examining 1,681 software security weaknesses to understand: what types of weaknesses are prevalent in VR software; {\\em when} and {\\em how} weaknesses are introduced; how long they have survived; and how they have been removed. Due to the limited availability of VR software security weaknesses in public databases (e.g., the National Vulnerability Database or NVD), we prepare the {first systematic} dataset of VR software security weaknesses by introducing a novel framework to collect such weaknesses from GitHub commit data. Our empirical study on the dataset leads to useful insights, including: (i) VR weaknesses are heavily skewed toward user interface weaknesses, followed by resource-related weaknesses; (ii) VR development tools pose higher security risks than VR applications; (iii) VR security weaknesses are often introduced at the VR software birth time.",
      "authors": [
        "Yifan Xu",
        "Jinfu Chen",
        "Zhenyu Qi",
        "Huashan Chen",
        "Junyi Wang",
        "Pengfei Hu",
        "Feng Liu",
        "Sen He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:45:53+00:00",
          "link": "https://arxiv.org/abs/2507.17324v1",
          "size": "5265kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Study on Virtual Reality Software Security Weaknesses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17324",
        "HTML": "https://arxiv.org/html/2507.17324v1",
        "PDF": "https://arxiv.org/pdf/2507.17324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on VR software security weaknesses and introduces a dataset for analyzing them. It does not pertain to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17325",
      "abstract": "The growing integration of power electronic converter-interfaced distributed energy resources into modern power systems presents significant challenges for system monitoring, protection, and control. Grid impedance plays a critical role in the operation and stability assessment of grid-connected inverter systems. This study presents a real-time grid impedance estimation method based on the Discrete Fourier Transform. The proposed method is integrated with the Advanced Angle Estimation Kalman Filter using a Linear Quadratic Regulator current controller (AAEKF-LQR), assisting the use of impedance information for accurate instantaneous phase angle estimation. Simulation results confirm that the proposed impedance estimation method interacts effectively with the AAEKF-LQR controller, maintaining stable system performance under weak grid conditions. The approach also demonstrates the ability to deliver fast and accurate impedance estimation during operational variations in grid conditions, thereby supporting stable inverter operation.",
      "authors": [
        "Phuoc Sang Nguyen",
        "Ghavameddin Nourbakhsh",
        "Gerard Ledwich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:50:18+00:00",
          "link": "https://arxiv.org/abs/2507.17325v1",
          "size": "1323kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Grid impedance estimation method into Advanced Angle Estimation Kalman Filter in GFL inverter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17325",
        "PDF": "https://arxiv.org/pdf/2507.17325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper pertains to grid impedance estimation and inverter control in power systems, with no focus on LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17326",
      "abstract": "Detailed assessment of language impairment following stroke remains a cognitively complex and clinician-intensive task, limiting timely and scalable diagnosis. Automatic Speech Recognition (ASR) foundation models offer a promising pathway to augment human evaluation through intelligent systems, but their effectiveness in the context of speech and language impairment remains uncertain. In this study, we evaluate whether Whisper, a state-of-the-art ASR foundation model, can be applied to transcribe and analyze speech from patients with stroke during a commonly used picture-naming task. We assess both verbatim transcription accuracy and the model's ability to support downstream prediction of language function, which has major implications for outcomes after stroke. Our results show that the baseline Whisper model performs poorly on single-word speech utterances. Nevertheless, fine-tuning Whisper significantly improves transcription accuracy (reducing Word Error Rate by 87.72% in healthy speech and 71.22% in speech from patients). Further, learned representations from the model enable accurate prediction of speech quality (average F1 Macro of 0.74 for healthy, 0.75 for patients). However, evaluations on an unseen (TORGO) dataset reveal limited generalizability, highlighting the inability of Whisper to perform zero-shot transcription of single-word utterances on out-of-domain clinical speech and emphasizing the need to adapt models to specific clinical populations. While challenges remain in cross-domain generalization, these findings highlight the potential of foundation models, when appropriately fine-tuned, to advance automated speech and language assessment and rehabilitation for stroke-related impairments.",
      "authors": [
        "Milena Davudova",
        "Ziyuan Cai",
        "Valentina Giunchiglia",
        "Dragos C. Gruia",
        "Giulia Sanguedolce",
        "Adam Hampshire",
        "Fatemeh Geranmayeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:52:41+00:00",
          "link": "https://arxiv.org/abs/2507.17326v1",
          "size": "686kb",
          "version": "v1"
        }
      ],
      "title": "Application of Whisper in Clinical Practice: the Post-Stroke Speech Assessment during a Naming Task",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17326",
        "HTML": "https://arxiv.org/html/2507.17326v1",
        "PDF": "https://arxiv.org/pdf/2507.17326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning Whisper, an ASR model, for speech transcription accuracy, which involves some data processing but is primarily focused on speech assessment and model performance in a clinical context rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17327",
      "abstract": "With the rapid advancement of large foundation models, AIGC, cloud rendering, and real-time motion capture technologies, digital humans are now capable of achieving synchronized facial expressions and body movements, engaging in intelligent dialogues driven by natural language, and enabling the fast creation of personalized avatars. While current mainstream approaches to digital humans primarily focus on 3D models and 2D video-based representations, interactive 2D cartoon-style digital humans have received relatively less attention. Compared to 3D digital humans that require complex modeling and high rendering costs, and 2D video-based solutions that lack flexibility and real-time interactivity, 2D cartoon-style Live2D models offer a more efficient and expressive alternative. By simulating 3D-like motion through layered segmentation without the need for traditional 3D modeling, Live2D enables dynamic and real-time manipulation. In this technical report, we present CartoonAlive, an innovative method for generating high-quality Live2D digital humans from a single input portrait image. CartoonAlive leverages the shape basis concept commonly used in 3D face modeling to construct facial blendshapes suitable for Live2D. It then infers the corresponding blendshape weights based on facial keypoints detected from the input image. This approach allows for the rapid generation of a highly expressive and visually accurate Live2D model that closely resembles the input portrait, within less than half a minute. Our work provides a practical and scalable solution for creating interactive 2D cartoon characters, opening new possibilities in digital content creation and virtual character animation. The project homepage is https://human3daigc.github.io/CartoonAlive_webpage/.",
      "authors": [
        "Chao He",
        "Jianqiang Ren",
        "Jianjing Xiang",
        "Xiejie Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:52:48+00:00",
          "link": "https://arxiv.org/abs/2507.17327v1",
          "size": "5058kb",
          "version": "v1"
        }
      ],
      "title": "CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17327",
        "HTML": "https://arxiv.org/html/2507.17327v1",
        "PDF": "https://arxiv.org/pdf/2507.17327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a method for generating expressive Live2D models from portraits, focusing on digital content creation and animation. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17328",
      "abstract": "Recent developments in mechanical, aerospace, and structural engineering have driven a growing need for efficient ways to model and analyse structures at much larger and more complex scales than before. While established numerical methods like the Finite Element Method remain reliable, they often struggle with computational cost and scalability when dealing with large and geometrically intricate problems. In recent years, neural network-based methods have shown promise because of their ability to efficiently approximate nonlinear mappings. However, most existing neural approaches are still largely limited to simple domains, which makes it difficult to apply to real-world PDEs involving complex geometries. In this paper, we propose a learning-based domain decomposition method (L-DDM) that addresses this gap. Our approach uses a single, pre-trained neural operator-originally trained on simple domains-as a surrogate model within a domain decomposition scheme, allowing us to tackle large and complicated domains efficiently. We provide a general theoretical result on the existence of neural operator approximations in the context of domain decomposition solution of abstract PDEs. We then demonstrate our method by accurately approximating solutions to elliptic PDEs with discontinuous microstructures in complex geometries, using a physics-pretrained neural operator (PPNO). Our results show that this approach not only outperforms current state-of-the-art methods on these challenging problems, but also offers resolution-invariance and strong generalization to microstructural patterns unseen during training.",
      "authors": [
        "Rui Wu",
        "Nikola Kovachki",
        "Burigede Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:54:36+00:00",
          "link": "https://arxiv.org/abs/2507.17328v1",
          "size": "30017kb",
          "version": "v1"
        }
      ],
      "title": "A Learning-based Domain Decomposition Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17328",
        "HTML": "https://arxiv.org/html/2507.17328v1",
        "PDF": "https://arxiv.org/pdf/2507.17328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concerns a learning-based domain decomposition method for solving PDEs in engineering contexts, which is unrelated to LLM training data processing or associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17332",
      "abstract": "The misaligned human texture across different human parts is one of the main limitations of existing 3D human reconstruction methods. Each human part, such as a jacket or pants, should maintain a distinct texture without blending into others. The structural coherence of human parts serves as a crucial cue to infer human textures in the invisible regions of a single image. However, most existing 3D human reconstruction methods do not explicitly exploit such part segmentation priors, leading to misaligned textures in their reconstructions. In this regard, we present PARTE, which utilizes 3D human part information as a key guide to reconstruct 3D human textures. Our framework comprises two core components. First, to infer 3D human part information from a single image, we propose a 3D part segmentation module (PartSegmenter) that initially reconstructs a textureless human surface and predicts human part labels based on the textureless surface. Second, to incorporate part information into texture reconstruction, we introduce a part-guided texturing module (PartTexturer), which acquires prior knowledge from a pre-trained image generation network on texture alignment of human parts. Extensive experiments demonstrate that our framework achieves state-of-the-art quality in 3D human reconstruction. The project page is available at https://hygenie1228.github.io/PARTE/.",
      "authors": [
        "Hyeongjin Nam",
        "Donghwan Kim",
        "Gyeongsik Moon",
        "Kyoung Mu Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:00:13+00:00",
          "link": "https://arxiv.org/abs/2507.17332v1",
          "size": "24474kb",
          "version": "v1"
        }
      ],
      "title": "PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17332",
        "HTML": "https://arxiv.org/html/2507.17332v1",
        "PDF": "https://arxiv.org/pdf/2507.17332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on part-guided texturing for 3D human reconstruction, involving 3D modeling and visualization techniques, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17333",
      "abstract": "We design a discrete Bernstein--Gelfand--Gelfand (BGG) diagram on polygonal meshes based on the DDR framework; the diagram is made of a discrete Stokes polygonal complex and a tensorised Discrete De Rham complex, and the BGG construction leads to a novel elasticity complex applicable on generic polygonal meshes. Complete homological and analytical properties of the discrete Stokes complex are established, including primal and adjoint consistency estimates as well as Poincar\\'e inequalities. Homological properties of the complexes built from the BGG diagram are also established.",
      "authors": [
        "Daniele A. Di Pietro",
        "J\\'er\\^ome Droniou",
        "Kaibo Hu",
        "Arax Leroy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:01:20+00:00",
          "link": "https://arxiv.org/abs/2507.17333v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "Design and analysis of twisted and BGG Stokes-de Rham polytopal complexes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17333",
        "PDF": "https://arxiv.org/pdf/2507.17333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing discrete Bernstein-Gelfand-Gelfand (BGG) diagrams and elasticity complexes on polygonal meshes, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17334",
      "abstract": "In low-altitude surveillance and early warning systems, detecting weak moving targets remains a significant challenge due to low signal energy, small spatial extent, and complex background clutter. Existing methods struggle with extracting robust features and suffer from the lack of reliable annotations. To address these limitations, we propose a novel Temporal Point-Supervised (TPS) framework that enables high-performance detection of weak targets without any manual annotations.Instead of conventional frame-based detection, our framework reformulates the task as a pixel-wise temporal signal modeling problem, where weak targets manifest as short-duration pulse-like responses. A Temporal Signal Reconstruction Network (TSRNet) is developed under the TPS paradigm to reconstruct these transient signals.TSRNet adopts an encoder-decoder architecture and integrates a Dynamic Multi-Scale Attention (DMSAttention) module to enhance its sensitivity to diverse temporal patterns. Additionally, a graph-based trajectory mining strategy is employed to suppress false alarms and ensure temporal consistency.Extensive experiments on a purpose-built low-SNR dataset demonstrate that our framework outperforms state-of-the-art methods while requiring no human annotations. It achieves strong detection performance and operates at over 1000 FPS, underscoring its potential for real-time deployment in practical scenarios.",
      "authors": [
        "Weihua Gao",
        "Chunxu Ren",
        "Wenlong Niu",
        "Xiaodong Peng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:02:09+00:00",
          "link": "https://arxiv.org/abs/2507.17334v1",
          "size": "5408kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Point-Supervised Signal Reconstruction: A Human-Annotation-Free Framework for Weak Moving Target Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17334",
        "HTML": "https://arxiv.org/html/2507.17334v1",
        "PDF": "https://arxiv.org/pdf/2507.17334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for weak target detection in surveillance systems, focusing on signal reconstruction and detection without human annotations, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17335",
      "abstract": "License plate recognition in open environments is widely applicable across various domains; however, the diversity of license plate types and imaging conditions presents significant challenges. To address the limitations encountered by CNN and CRNN-based approaches in license plate recognition, this paper proposes a unified solution that integrates a lightweight visual encoder with a text decoder, within a pre-training framework tailored for single and double-line Chinese license plates. To mitigate the scarcity of double-line license plate datasets, we constructed a single/double-line license plate dataset by synthesizing images, applying texture mapping onto real scenes, and blending them with authentic license plate images. Furthermore, to enhance the system's recognition accuracy, we introduce a perspective correction network (PTN) that employs license plate corner coordinate regression as an implicit variable, supervised by license plate view classification information. This network offers improved stability, interpretability, and low annotation costs. The proposed algorithm achieves an average recognition accuracy of 99.34% on the corrected CCPD test set under coarse localization disturbance. When evaluated under fine localization disturbance, the accuracy further improves to 99.58%. On the double-line license plate test set, it achieves an average recognition accuracy of 98.70%, with processing speeds reaching up to 167 frames per second, indicating strong practical applicability.",
      "authors": [
        "Guangzhu Xu",
        "Zhi Ke",
        "Pengcheng Zuo",
        "Bangjun Lei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:03:01+00:00",
          "link": "https://arxiv.org/abs/2507.17335v1",
          "size": "1982kb",
          "version": "v1"
        }
      ],
      "title": "TransLPRNet: Lite Vision-Language Network for Single/Dual-line Chinese License Plate Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17335",
        "PDF": "https://arxiv.org/pdf/2507.17335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper constructs a dataset by synthesizing single/double-line Chinese license plate images, which relates to dataset creation, but the primary focus is on license plate recognition, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17336",
      "abstract": "Dynamic 4D Gaussian Splatting (4DGS) effectively extends the high-speed rendering capabilities of 3D Gaussian Splatting (3DGS) to represent volumetric videos. However, the large number of Gaussians, substantial temporal redundancies, and especially the absence of an entropy-aware compression framework result in large storage requirements. Consequently, this poses significant challenges for practical deployment, efficient edge-device processing, and data transmission. In this paper, we introduce a novel end-to-end RD-optimized compression framework tailored for 4DGS, aiming to enable flexible, high-fidelity rendering across varied computational platforms. Leveraging Fully Explicit Dynamic Gaussian Splatting (Ex4DGS), one of the state-of-the-art 4DGS methods, as our baseline, we start from the existing 3DGS compression methods for compatibility while effectively addressing additional challenges introduced by the temporal axis. In particular, instead of storing motion trajectories independently per point, we employ a wavelet transform to reflect the real-world smoothness prior, significantly enhancing storage efficiency. This approach yields significantly improved compression ratios and provides a user-controlled balance between compression efficiency and rendering quality. Extensive experiments demonstrate the effectiveness of our method, achieving up to 91x compression compared to the original Ex4DGS model while maintaining high visual fidelity. These results highlight the applicability of our framework for real-time dynamic scene rendering in diverse scenarios, from resource-constrained edge devices to high-performance environments.",
      "authors": [
        "Hyeongmin Lee",
        "Kyungjune Baek"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:05:13+00:00",
          "link": "https://arxiv.org/abs/2507.17336v1",
          "size": "44518kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17336",
        "HTML": "https://arxiv.org/html/2507.17336v1",
        "PDF": "https://arxiv.org/pdf/2507.17336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research deals with 4D Gaussian Splatting for volumetric videos and focuses on compression techniques, which are not related to LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17338",
      "abstract": "Despite growing interest in active inference for robotic control, its application to complex, long-horizon tasks remains untested. We address this gap by introducing a fully hierarchical active inference architecture for goal-directed behavior in realistic robotic settings. Our model combines a high-level active inference model that selects among discrete skills realized via a whole-body active inference controller. This unified approach enables flexible skill composition, online adaptability, and recovery from task failures without requiring offline training. Evaluated on the Habitat Benchmark for mobile manipulation, our method outperforms state-of-the-art baselines across the three long-horizon tasks, demonstrating for the first time that active inference can scale to the complexity of modern robotics benchmarks.",
      "authors": [
        "Corrado Pezzato",
        "Ozan \\c{C}atal",
        "Toon Van de Maele",
        "Riddhi J. Pitliya",
        "Tim Verbelen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:08:21+00:00",
          "link": "https://arxiv.org/abs/2507.17338v1",
          "size": "6633kb",
          "version": "v1"
        }
      ],
      "title": "Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17338",
        "HTML": "https://arxiv.org/html/2507.17338v1",
        "PDF": "https://arxiv.org/pdf/2507.17338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses active inference in robotics for long-horizon rearrangement tasks and does not involve LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17342",
      "abstract": "Motion forecasting and planning are tasked with estimating the trajectories of traffic agents and the ego vehicle, respectively, to ensure the safety and efficiency of autonomous driving systems in dynamically changing environments. State-of-the-art methods typically adopt a one-query-one-trajectory paradigm, where each query corresponds to a unique trajectory for predicting multi-mode trajectories. While this paradigm can produce diverse motion intentions, it often falls short in modeling the intricate spatiotemporal evolution of trajectories, which can lead to collisions or suboptimal outcomes. To overcome this limitation, we propose DeMo++, a framework that decouples motion estimation into two distinct components: holistic motion intentions to capture the diverse potential directions of movement, and fine spatiotemporal states to track the agent's dynamic progress within the scene and enable a self-refinement capability. Further, we introduce a cross-scene trajectory interaction mechanism to explore the relationships between motions in adjacent scenes. This allows DeMo++ to comprehensively model both the diversity of motion intentions and the spatiotemporal evolution of each trajectory. To effectively implement this framework, we developed a hybrid model combining Attention and Mamba. This architecture leverages the strengths of both mechanisms for efficient scene information aggregation and precise trajectory state sequence modeling. Extensive experiments demonstrate that DeMo++ achieves state-of-the-art performance across various benchmarks, including motion forecasting (Argoverse 2 and nuScenes), motion planning (nuPlan), and end-to-end planning (NAVSIM).",
      "authors": [
        "Bozhou Zhang",
        "Nan Song",
        "Xiatian Zhu",
        "Li Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:11:25+00:00",
          "link": "https://arxiv.org/abs/2507.17342v1",
          "size": "8367kb",
          "version": "v1"
        }
      ],
      "title": "DeMo++: Motion Decoupling for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17342",
        "HTML": "https://arxiv.org/html/2507.17342v1",
        "PDF": "https://arxiv.org/pdf/2507.17342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion forecasting and planning for autonomous driving, with no apparent relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17343",
      "abstract": "Multimodal representation learning seeks to create a unified representation space by integrating diverse data modalities to improve multimodal understanding. Traditional methods often depend on pairwise contrastive learning, which relies on a predefined anchor modality, restricting alignment across all modalities. Recent advances have investigated the simultaneous alignment of multiple modalities, yet several challenges remain, such as limitations imposed by fixed anchor points and instability arising from optimizing the product of singular values. To address the challenges, in this paper, we propose Principled Multimodal Representation Learning (PMRL), a novel framework that achieves simultaneous alignment of multiple modalities without anchor dependency in a more stable manner. Specifically, grounded in the theoretical insight that full alignment corresponds to a rank-1 Gram matrix, PMRL optimizes the dominant singular value of the representation matrix to align modalities along a shared leading direction. We propose a softmax-based loss function that treats singular values as logits to prioritize the largest singular value. Besides, instance-wise contrastive regularization on the leading eigenvectors maintains inter-instance separability and prevents representation collapse. Extensive experiments across diverse tasks demonstrate PMRL's superiority compared to baseline methods. The source code will be publicly available.",
      "authors": [
        "Xiaohao Liu",
        "Xiaobo Xia",
        "See-Kiong Ng",
        "Tat-Seng Chua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:12:25+00:00",
          "link": "https://arxiv.org/abs/2507.17343v1",
          "size": "1434kb",
          "version": "v1"
        }
      ],
      "title": "Principled Multimodal Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17343",
        "HTML": "https://arxiv.org/html/2507.17343v1",
        "PDF": "https://arxiv.org/pdf/2507.17343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is centered on multimodal representation learning, discussing alignment of data modalities without reference to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17346",
      "abstract": "Distributed machine learning in high end-to-end latency and low, varying bandwidth network environments undergoes severe throughput degradation. Due to its low communication requirements, distributed SGD (D-SGD) remains the mainstream optimizer in such challenging networks, but it still suffers from significant throughput reduction. To mitigate these limitations, existing approaches typically employ gradient compression and delayed aggregation to alleviate low bandwidth and high latency, respectively. To address both challenges simultaneously, these strategies are often combined, introducing a complex three-way trade-off among compression ratio, staleness (delayed synchronization steps), and model convergence rate. To achieve the balance under varying bandwidth conditions, an adaptive policy is required to dynamically adjust these parameters. Unfortunately, existing works rely on static heuristic strategies due to the lack of theoretical guidance, which prevents them from achieving this goal. This study fills in this theoretical gap by introducing a new theoretical tool, decomposing the joint optimization problem into a traditional convergence rate analysis with multiple analyzable noise terms. We are the first to reveal that staleness exponentially amplifies the negative impact of gradient compression on training performance, filling a critical gap in understanding how compressed and delayed gradients affect training. Furthermore, by integrating the convergence rate with a network-aware time minimization condition, we propose DeCo-SGD, which dynamically adjusts the compression ratio and staleness based on the real-time network condition and training task. DeCo-SGD achieves up to 5.07 and 1.37 speed-ups over D-SGD and static strategy in high-latency and low, varying bandwidth networks, respectively.",
      "authors": [
        "Rongwei Lu",
        "Jingyan Jiang",
        "Chunyang Li",
        "Haotian Dong",
        "Xingguang Wei",
        "Delin Cai",
        "Zhi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:22:51+00:00",
          "link": "https://arxiv.org/abs/2507.17346v1",
          "size": "2717kb",
          "version": "v1"
        }
      ],
      "title": "DeCo-SGD: Joint Optimization of Delay Staleness and Gradient Compression Ratio for Distributed SGD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17346",
        "HTML": "https://arxiv.org/html/2507.17346v1",
        "PDF": "https://arxiv.org/pdf/2507.17346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses optimization in distributed SGD in challenging networks, without involvement in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17347",
      "abstract": "In the field of food image processing, efficient semantic segmentation techniques are crucial for industrial applications. However, existing large-scale Transformer-based models (such as FoodSAM) face challenges in meeting practical deploymentrequirements due to their massive parameter counts and high computational resource demands. This paper introduces TUNable Adapter module (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that integrates multiscale trainable adapters into the Swin Transformer architecture, achieving high-performance food image segmentation by updating only 4% of the parameters. The core innovation of Swin-TUNA lies in its hierarchical feature adaptation mechanism: it designs separable convolutions in depth and dimensional mappings of varying scales to address the differences in features between shallow and deep networks, combined with a dynamic balancing strategy for tasks-agnostic and task-specific features. Experiments demonstrate that this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and UECFoodPix Complete datasets, respectively, surpassing the fully parameterized FoodSAM model while reducing the parameter count by 98.7% (to only 8.13M). Furthermore, Swin-TUNA exhibits faster convergence and stronger generalization capabilities in low-data scenarios, providing an efficient solution for assembling lightweight food image.",
      "authors": [
        "Haotian Chen",
        "Zhiyong Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:28:25+00:00",
          "link": "https://arxiv.org/abs/2507.17347v1",
          "size": "2271kb",
          "version": "v1"
        }
      ],
      "title": "Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17347",
        "HTML": "https://arxiv.org/html/2507.17347v1",
        "PDF": "https://arxiv.org/pdf/2507.17347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a parameter-efficient tuning method for food image segmentation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17348",
      "abstract": "An ordinal classification (OC) problem corresponds to a special type of classification characterised by the presence of a natural order relationship among the classes. This type of problem can be found in a number of real-world applications, motivating the design and development of many ordinal methodologies over the last years. However, it is important to highlight that the development of the OC field suffers from one main disadvantage: the lack of a comprehensive set of datasets on which novel approaches to the literature have to be benchmarked. In order to approach this objective, this manuscript from the University of C\\'ordoba (UCO), which have previous experience on the OC field, provides the literature with a publicly available repository of tabular data for a robust validation of novel OC approaches, namely TOC-UCO (Tabular Ordinal Classification repository of the UCO). Specifically, this repository includes a set of $46$ tabular ordinal datasets, preprocessed under a common framework and ensured to have a reasonable number of patterns and an appropriate class distribution. We also provide the sources and preprocessing steps of each dataset, along with details on how to benchmark a novel approach using the TOC-UCO repository. For this, indices for $30$ different randomised train-test partitions are provided to facilitate the reproducibility of the experiments.",
      "authors": [
        "Rafael Ayll\\'on-Gavil\\'an",
        "David Guijo-Rubio",
        "Antonio Manuel G\\'omez-Orellana",
        "David Guijo-Rubio",
        "Francisco B\\'erchez-Moreno",
        "V\\'ictor Manuel Vargas-Yun and Pedro A. Guti\\'errez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:28:52+00:00",
          "link": "https://arxiv.org/abs/2507.17348v1",
          "size": "272kb",
          "version": "v1"
        }
      ],
      "title": "TOC-UCO: a comprehensive repository of tabular ordinal classification datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17348",
        "HTML": "https://arxiv.org/html/2507.17348v1",
        "PDF": "https://arxiv.org/pdf/2507.17348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper introduces a repository of tabular ordinal classification datasets, it does not directly address LLM training data processing, which limits its relevance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17351",
      "abstract": "Neural Radiance Field (NeRF) models are implicit neural scene representation methods that offer unprecedented capabilities in novel view synthesis. Semantically-aware NeRFs not only capture the shape and radiance of a scene, but also encode semantic information of the scene. The training of semantically-aware NeRFs typically requires pixel-level class labels, which can be prohibitively expensive to collect. In this work, we explore active learning as a potential solution to alleviate the annotation burden. We investigate various design choices for active learning of semantically-aware NeRF, including selection granularity and selection strategies. We further propose a novel active learning strategy that takes into account 3D geometric constraints in sample selection. Our experiments demonstrate that active learning can effectively reduce the annotation cost of training semantically-aware NeRF, achieving more than 2X reduction in annotation cost compared to random sampling.",
      "authors": [
        "Yuzhe Zhu",
        "Lile Cai",
        "Kangkang Lu",
        "Fayao Liu",
        "Xulei Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:34:09+00:00",
          "link": "https://arxiv.org/abs/2507.17351v1",
          "size": "5653kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Active Learning for Label-Efficient Training of Semantic Neural Radiance Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17351",
        "HTML": "https://arxiv.org/html/2507.17351v1",
        "PDF": "https://arxiv.org/pdf/2507.17351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on active learning for reducing the annotation cost in training semantically-aware Neural Radiance Field models. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17353",
      "abstract": "Accurate road damage detection is crucial for timely infrastructure maintenance and public safety, but existing vision-only datasets and models lack the rich contextual understanding that textual information can provide. To address this limitation, we introduce RoadBench, the first multimodal benchmark for comprehensive road damage understanding. This dataset pairs high resolution images of road damages with detailed textual descriptions, providing a richer context for model training. We also present RoadCLIP, a novel vision language model that builds upon CLIP by integrating domain specific enhancements. It includes a disease aware positional encoding that captures spatial patterns of road defects and a mechanism for injecting road-condition priors to refine the model's understanding of road damages. We further employ a GPT driven data generation pipeline to expand the image to text pairs in RoadBench, greatly increasing data diversity without exhaustive manual annotation. Experiments demonstrate that RoadCLIP achieves state of the art performance on road damage recognition tasks, significantly outperforming existing vision-only models by 19.2%. These results highlight the advantages of integrating visual and textual information for enhanced road condition analysis, setting new benchmarks for the field and paving the way for more effective infrastructure monitoring through multimodal learning.",
      "authors": [
        "Xi Xiao",
        "Yunbei Zhang",
        "Janet Wang",
        "Lin Zhao",
        "Yuxiang Wei",
        "Hengjia Li",
        "Yanshu Li",
        "Xiao Wang",
        "Swalpa Kumar Roy",
        "Hao Xu",
        "and Tianyang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:34:35+00:00",
          "link": "https://arxiv.org/abs/2507.17353v1",
          "size": "1611kb",
          "version": "v1"
        }
      ],
      "title": "RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17353",
        "HTML": "https://arxiv.org/html/2507.17353v1",
        "PDF": "https://arxiv.org/pdf/2507.17353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces RoadBench, which involves expanding datasets with a GPT-driven data generation pipeline. While it contributes to dataset diversity, its main focus is on vision-language models for road damage understanding, not LLM training specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17354",
      "abstract": "Multiparty session types (MPST) are a type-based approach for specifying message-passing distributed systems. They rely on the notion of global type specifying the global behaviour and local types, which are the projections of the global behaviour onto each local participant. An essential property of global types is realisability, i.e., whether the composition of the local behaviours conforms to those specified by the global type. We explore how realisability of MPST relates to their complementability, i.e., whether there exists a global type that describes the complementary behaviour of the original global type. First, we show that if a global type is realisable with p2p communications, then it is realisable with synchronous communications. Second, we show that if a global type is realisable in the synchronous model, then it is complementable, in the sense that there exists a global type that describes the complementary behaviour of the original global type.  Third, we give an algorithm to decide whether a complementable global type, given with an explicit complement, is realisable in p2p. The algorithm is PSPACE in the size of the global type and its complement. As a side contribution, we propose a complementation construction for global types with sender-driven choice with a linear blowup in the size of the global type.",
      "authors": [
        "Cinzia Di Giusto (C and A",
        "I3S)",
        "Etienne Lozes (I3S",
        "Laboratoire I3S - COMRED)",
        "Pascal Urso (I3S",
        "SCALE",
        "Laboratoire I3S - COMRED)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:36:18+00:00",
          "link": "https://arxiv.org/abs/2507.17354v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Realisability and Complementability of Multiparty Session Types",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17354",
        "PDF": "https://arxiv.org/pdf/2507.17354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses multiparty session types related to message-passing distributed systems and does not engage with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17356",
      "abstract": "On music streaming services, listening sessions are often composed of a balance of familiar and new tracks. Recently, sequential recommender systems have adopted cognitive-informed approaches, such as Adaptive Control of Thought-Rational (ACT-R), to successfully improve the prediction of the most relevant tracks for the next user session. However, one limitation of using a model inspired by human memory (or the past), is that it struggles to recommend new tracks that users have not previously listened to. To bridge this gap, here we propose a model that leverages audio information to predict in advance the ACT-R-like activation of new tracks and incorporates them into the recommendation scoring process. We demonstrate the empirical effectiveness of the proposed model using proprietary data, which we publicly release along with the model's source code to foster future research in this field.",
      "authors": [
        "Viet-Tran Anh",
        "Bruno Sguerra",
        "Gabriel Meseguer-Brocal",
        "Lea Briand",
        "Manuel Moussallam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:37:23+00:00",
          "link": "https://arxiv.org/abs/2507.17356v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "\"Beyond the past\": Leveraging Audio and Human Memory for Sequential Music Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17356",
        "HTML": "https://arxiv.org/html/2507.17356v1",
        "PDF": "https://arxiv.org/pdf/2507.17356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a music recommendation model using audio information and human memory simulation, complemented by the release of proprietary data. However, it focuses on music recommendation and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17359",
      "abstract": "The development of X-Ray microscopy (XRM) technology has enabled non-destructive inspection of semiconductor structures for defect identification. Deep learning is widely used as the state-of-the-art approach to perform visual analysis tasks. However, deep learning based models require large amount of annotated data to train. This can be time-consuming and expensive to obtain especially for dense prediction tasks like semantic segmentation. In this work, we explore active learning (AL) as a potential solution to alleviate the annotation burden. We identify two unique challenges when applying AL on semiconductor XRM scans: large domain shift and severe class-imbalance. To address these challenges, we propose to perform contrastive pretraining on the unlabelled data to obtain the initialization weights for each AL cycle, and a rareness-aware acquisition function that favors the selection of samples containing rare classes. We evaluate our method on a semiconductor dataset that is compiled from XRM scans of high bandwidth memory structures composed of logic and memory dies, and demonstrate that our method achieves state-of-the-art performance.",
      "authors": [
        "Lile Cai",
        "Ramanpreet Singh Pahwa",
        "Xun Xu",
        "Jie Wang",
        "Richard Chang",
        "Lining Zhang",
        "Chuan-Sheng Foo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:44:11+00:00",
          "link": "https://arxiv.org/abs/2507.17359v1",
          "size": "612kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Active Learning for Semiconductor Defect Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17359",
        "HTML": "https://arxiv.org/html/2507.17359v1",
        "PDF": "https://arxiv.org/pdf/2507.17359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores active learning for defect segmentation in semiconductor inspection, focusing on challenges such as domain shift and class imbalance. It does not pertain to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17365",
      "abstract": "Multi-step agentic retrieval systems based on large language models (LLMs) have demonstrated remarkable performance in complex information search tasks. However, these systems still face significant challenges in practical applications, particularly in generating factually inconsistent intermediate queries and inefficient search trajectories, which can lead to reasoning deviations or redundant computations. To address these issues, we propose DynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs and multi-reward reinforcement learning (RL). Specifically, our system leverages knowledge graphs as external structured knowledge to guide the search process by explicitly modeling entity relationships, thereby ensuring factual consistency in intermediate queries and mitigating biases from irrelevant information. Furthermore, we employ a multi-reward RL framework for fine-grained control over training objectives such as retrieval accuracy, efficiency, and response quality. This framework promotes the generation of high-quality intermediate queries and comprehensive final answers, while discouraging unnecessary exploration and minimizing information omissions or redundancy. Experimental results demonstrate that our approach achieves state-of-the-art answer accuracy on six multi-hop question answering datasets, matching frontier LLMs while using only small-scale models and limited computational resources. Furthermore, our approach demonstrates strong generalization and robustness across diverse retrieval environments and larger-scale models, highlighting its broad applicability.",
      "authors": [
        "Chuzhan Hao",
        "Wenfeng Feng",
        "Yuewei Zhang",
        "Hao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:58:31+00:00",
          "link": "https://arxiv.org/abs/2507.17365v1",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "title": "DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17365",
        "HTML": "https://arxiv.org/html/2507.17365v1",
        "PDF": "https://arxiv.org/pdf/2507.17365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper deals with enhancing search systems using dynamic knowledge graphs and reinforcement learning. While it involves fine-grained control over training objectives, it primarily focuses on retrieval and search efficiency rather than specific contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17366",
      "abstract": "In this paper, we investigate the problem of distributionally robust source coding, i.e., source coding under uncertainty in the source distribution, discussing both the coding and computational aspects of the problem. We propose two extensions of the so-called Strong Functional Representation Lemma (SFRL), considering the cases where, for a fixed conditional distribution, the marginal inducing the joint coupling belongs to either a finite set of distributions or a Kullback-Leibler divergence sphere (KL-Sphere) centered at a fixed nominal distribution. Using these extensions, we derive distributionally robust coding schemes for both the one-shot and asymptotic regimes, generalizing previous results in the literature. Focusing on the case where the source distribution belongs to a given KL-Sphere, we derive an implicit characterization of the points attaining the robust rate-distortion function (R-RDF), which we later exploit to implement a novel algorithm for computing the R-RDF. Finally, we characterize the analytical expression of the R-RDF for Bernoulli sources, providing a theoretical benchmark to evaluate the estimation performance of the proposed algorithm.",
      "authors": [
        "Giuseppe Serra",
        "Photios A. Stavrou",
        "Marios Kountouris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:01:59+00:00",
          "link": "https://arxiv.org/abs/2507.17366v1",
          "size": "316kb",
          "version": "v1"
        }
      ],
      "title": "On Distributionally Robust Lossy Source Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17366",
        "HTML": "https://arxiv.org/html/2507.17366v1",
        "PDF": "https://arxiv.org/pdf/2507.17366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses distributionally robust source coding and computational schemes, with no discussion on LLM training data or data processing techniques relevant to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17367",
      "abstract": "State-of-the-art methods for semantic segmentation are based on deep neural networks trained on large-scale labeled datasets. Acquiring such datasets would incur large annotation costs, especially for dense pixel-level prediction tasks like semantic segmentation. We consider region-based active learning as a strategy to reduce annotation costs while maintaining high performance. In this setting, batches of informative image regions instead of entire images are selected for labeling. Importantly, we propose that enforcing local spatial diversity is beneficial for active learning in this case, and to incorporate spatial diversity along with the traditional active selection criterion, e.g., data sample uncertainty, in a unified optimization framework for region-based active learning. We apply this framework to the Cityscapes and PASCAL VOC datasets and demonstrate that the inclusion of spatial diversity effectively improves the performance of uncertainty-based and feature diversity-based active learning methods. Our framework achieves $95\\%$ performance of fully supervised methods with only $5-9\\%$ of the labeled pixels, outperforming all state-of-the-art region-based active learning methods for semantic segmentation.",
      "authors": [
        "Lile Cai",
        "Xun Xu",
        "Lining Zhang",
        "Chuan-Sheng Foo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:04:25+00:00",
          "link": "https://arxiv.org/abs/2507.17367v1",
          "size": "7149kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Spatial Diversity for Region-based Active Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17367",
        "HTML": "https://arxiv.org/html/2507.17367v1",
        "PDF": "https://arxiv.org/pdf/2507.17367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on region-based active learning for semantic segmentation, emphasizing reduction of annotation costs. It does not address LLM training data processing or data engineering operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17368",
      "abstract": "Continual learning (CL) with long-tailed data distributions remains a critical challenge for real-world AI systems, where models must sequentially adapt to new classes while retaining knowledge of old ones, despite severe class imbalance. Existing methods struggle to balance stability and plasticity, often collapsing under extreme sample scarcity. To address this, we propose ViRN, a novel CL framework that integrates variational inference (VI) with distributional trilateration for robust long-tailed learning. First, we model class-conditional distributions via a Variational Autoencoder to mitigate bias toward head classes. Second, we reconstruct tail-class distributions via Wasserstein distance-based neighborhood retrieval and geometric fusion, enabling sample-efficient alignment of tail-class representations. Evaluated on six long-tailed classification benchmarks, including speech (e.g., rare acoustic events, accents) and image tasks, ViRN achieves a 10.24% average accuracy gain over state-of-the-art methods.",
      "authors": [
        "Hao Dai",
        "Chong Tang",
        "Jagmohan Chauhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:04:30+00:00",
          "link": "https://arxiv.org/abs/2507.17368v1",
          "size": "87kb",
          "version": "v1"
        }
      ],
      "title": "ViRN: Variational Inference and Distribution Trilateration for Long-Tailed Continual Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17368",
        "HTML": "https://arxiv.org/html/2507.17368v1",
        "PDF": "https://arxiv.org/pdf/2507.17368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on continual learning and handling long-tailed data distributions through variational inference. It does not relate to processing training data for LLMs in any significant way."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17369",
      "abstract": "Understanding API evolution and the introduction of breaking changes (BCs) in software libraries is essential for library maintainers to manage backward compatibility and for researchers to conduct empirical studies on software library evolution. In Java, tools such as JApiCmp and Revapi are commonly used to detect BCs between library releases, but their reliance on binary JARs limits their applicability. This restriction hinders large-scale longitudinal studies of API evolution and fine-grained analyses such as commit-level BC detection. In this paper, we introduce Roseau, a novel static analysis tool that constructs technology-agnostic API models from library code equipped with rich semantic analyses. API models can be analyzed to study API evolution and compared to identify BCs between any two versions of a library (releases, commits, branches, etc.). Unlike traditional approaches, Roseau can build API models from source code or bytecode, and is optimized for large-scale longitudinal analyses of library histories. We assess the accuracy, performance, and suitability of Roseau for longitudinal studies of API evolution, using JApiCmp and Revapi as baselines. We extend and refine an established benchmark of BCs and show that Roseau achieves higher accuracy (F1 = 0.99) than JApiCmp (F1 = 0.86) and Revapi (F1 = 0.91). We analyze 60 popular libraries from Maven Central and find that Roseau delivers excellent performance, detecting BCs between versions in under two seconds, including in libraries with hundreds of thousands of lines of code. We further illustrate the limitations of JApiCmp and Revapi for longitudinal studies and the novel analysis capabilities offered by Roseau by tracking the evolution of Google's Guava API and the introduction of BCs over 14 years and 6,839 commits, reducing analysis times from a few days to a few minutes.",
      "authors": [
        "Corentin Latappy (LaBRI)",
        "Thomas Degueule (LaBRI)",
        "Jean-R\\'emy Falleri (LaBRI)",
        "Romain Robbes (LaBRI)",
        "Lina Ochoa (TU/e)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:07:19+00:00",
          "link": "https://arxiv.org/abs/2507.17369v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "Roseau: Fast, Accurate, Source-based API Breaking Change Analysis in Java",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17369",
        "PDF": "https://arxiv.org/pdf/2507.17369"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on API evolution and breaking change analysis in Java libraries, with no discussion of LLM training data processing or relevant data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17373",
      "abstract": "Source-free object detection adapts a detector pre-trained on a source domain to an unlabeled target domain without requiring access to labeled source data. While this setting is practical as it eliminates the need for the source dataset during domain adaptation, it operates under the restrictive assumption that only pre-defined objects from the source domain exist in the target domain. This closed-set setting prevents the detector from detecting undefined objects. To ease this assumption, we propose Source-Free Unknown Object Detection (SFUOD), a novel scenario which enables the detector to not only recognize known objects but also detect undefined objects as unknown objects. To this end, we propose CollaPAUL (Collaborative tuning and Principal Axis-based Unknown Labeling), a novel framework for SFUOD. Collaborative tuning enhances knowledge adaptation by integrating target-dependent knowledge from the auxiliary encoder with source-dependent knowledge from the pre-trained detector through a cross-domain attention mechanism. Additionally, principal axes-based unknown labeling assigns pseudo-labels to unknown objects by estimating objectness via principal axes projection and confidence scores from model predictions. The proposed CollaPAUL achieves state-of-the-art performances on SFUOD benchmarks, and extensive experiments validate its effectiveness.",
      "authors": [
        "Keon-Hee Park",
        "Seun-An Choe",
        "and Gyeong-Moon Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:16:25+00:00",
          "link": "https://arxiv.org/abs/2507.17373v1",
          "size": "3569kb",
          "version": "v1"
        }
      ],
      "title": "SFUOD: Source-Free Unknown Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17373",
        "HTML": "https://arxiv.org/html/2507.17373v1",
        "PDF": "https://arxiv.org/pdf/2507.17373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The subject of this paper is source-free unknown object detection and domain adaptation for object detectors, which does not relate to LLM training data processing or data operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17376",
      "abstract": "In this paper, we investigate the impact of high-level semantics (evaluation of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction (HRI) in the context of mobile robot deployments. Although semantics has been widely researched in AI, how high-level semantics can benefit the HRT paradigm is underexplored, often fuzzy, and intractable. We applied a semantics-based framework that could reveal different indicators of the environment (i.e. how much semantic information exists) in a mock-up disaster response mission. In such missions, semantics are crucial as the HRT should handle complex situations and respond quickly with correct decisions, where humans might have a high workload and stress. Especially when human operators need to shift their attention between robots and other tasks, they will struggle to build Situational Awareness (SA) quickly. The experiment suggests that the presented semantics: 1) alleviate the perceived workload of human operators; 2) increase the operator's trust in the SA; and 3) help to reduce the reaction time in switching the level of autonomy when needed. Additionally, we find that participants with higher trust in the system are encouraged by high-level semantics to use teleoperation mode more.",
      "authors": [
        "Tianshu Ruan",
        "Aniketh Ramesh",
        "Rustam Stolkin and Manolis Chiou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:19:22+00:00",
          "link": "https://arxiv.org/abs/2507.17376v1",
          "size": "10361kb",
          "version": "v1"
        }
      ],
      "title": "An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17376",
        "HTML": "https://arxiv.org/html/2507.17376v1",
        "PDF": "https://arxiv.org/pdf/2507.17376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores human-robot interaction using semantics-based situational awareness, which is outside the scope of LLM training data processing and does not involve relevant data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17377",
      "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen combinations of known objects and attributes by leveraging knowledge from previously seen compositions. Traditional approaches primarily focus on disentangling attributes and objects, treating them as independent entities during learning. However, this assumption overlooks the semantic constraints and contextual dependencies inside a composition. For example, certain attributes naturally pair with specific objects (e.g., \"striped\" applies to \"zebra\" or \"shirts\" but not \"sky\" or \"water\"), while the same attribute can manifest differently depending on context (e.g., \"young\" in \"young tree\" vs. \"young dog\"). Thus, capturing attribute-object interdependence remains a fundamental yet long-ignored challenge in CZSL. In this paper, we adopt a Conditional Probability Framework (CPF) to explicitly model attribute-object dependencies. We decompose the probability of a composition into two components: the likelihood of an object and the conditional likelihood of its attribute. To enhance object feature learning, we incorporate textual descriptors to highlight semantically relevant image regions. These enhanced object features then guide attribute learning through a cross-attention mechanism, ensuring better contextual alignment. By jointly optimizing object likelihood and conditional attribute likelihood, our method effectively captures compositional dependencies and generalizes well to unseen compositions. Extensive experiments on multiple CZSL benchmarks demonstrate the superiority of our approach. Code is available at here.",
      "authors": [
        "Peng Wu",
        "Qiuxia Lai",
        "Hao Fang",
        "Guo-Sen Xie",
        "Yilong Yin",
        "Xiankai Lu",
        "Wenguan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:20:52+00:00",
          "link": "https://arxiv.org/abs/2507.17377v1",
          "size": "5644kb",
          "version": "v1"
        }
      ],
      "title": "A Conditional Probability Framework for Compositional Zero-shot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17377",
        "HTML": "https://arxiv.org/html/2507.17377v1",
        "PDF": "https://arxiv.org/pdf/2507.17377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on compositional zero-shot learning through a conditional probability framework, which does not pertain to LLM training data processing or involve any related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17378",
      "abstract": "We study superconvergent discretization of the Laplace-Beltrami operator on time-space product manifolds with Neumann temporal boundary values, which arise in the context of dynamic optimal transport on general surfaces. We propose a coupled scheme that combines finite difference methods in time with surface finite element methods in space. By establishing a new summation by parts formula and proving the supercloseness of the semi-discrete solution, we derive superconvergence results for the recovered gradient via post-processing techniques. In addition, our geometric error analysis is implemented within a novel framework based on the approximation of the Riemannian metric. Several numerical examples are provided to validate and illustrate the theoretical results.",
      "authors": [
        "Chengrun Jiang",
        "Guozhi Dong",
        "Hailong Guo",
        "Zuoqiang Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:22:31+00:00",
          "link": "https://arxiv.org/abs/2507.17378v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "An FDM-sFEM scheme on time-space manifolds and its superconvergence analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17378",
        "HTML": "https://arxiv.org/html/2507.17378v1",
        "PDF": "https://arxiv.org/pdf/2507.17378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a numerical scheme for differential equations on time-space manifolds, unrelated to LLM training data processing or any operations pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17379",
      "abstract": "Open-vocabulary mobile manipulation (OVMM) that involves the handling of novel and unseen objects across different workspaces remains a significant challenge for real-world robotic applications. In this paper, we propose a novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named LOVMM, incorporating the large language model (LLM) and vision-language model (VLM) to tackle various mobile manipulation tasks in household environments. Our approach is capable of solving various OVMM tasks with free-form natural language instructions (e.g. \"toss the food boxes on the office room desk to the trash bin in the corner\", and \"pack the bottles from the bed to the box in the guestroom\"). Extensive experiments simulated in complex household environments show strong zero-shot generalization and multi-task learning abilities of LOVMM. Moreover, our approach can also generalize to multiple tabletop manipulation tasks and achieve better success rates compared to other state-of-the-art methods.",
      "authors": [
        "Shen Tan",
        "Dong Zhou",
        "Xiangyu Shao",
        "Junqiao Wang",
        "Guanghui Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:23:15+00:00",
          "link": "https://arxiv.org/abs/2507.17379v1",
          "size": "16010kb",
          "version": "v1"
        }
      ],
      "title": "Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17379",
        "HTML": "https://arxiv.org/html/2507.17379v1",
        "PDF": "https://arxiv.org/pdf/2507.17379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for open-vocabulary mobile manipulation using large language models but does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17382",
      "abstract": "Continual Generalized Category Discovery (C-GCD) faces a critical challenge: incrementally learning new classes from unlabeled data streams while preserving knowledge of old classes. Existing methods struggle with catastrophic forgetting, especially when unlabeled data mixes known and novel categories. We address this by analyzing C-GCD's forgetting dynamics through a Bayesian lens, revealing that covariance misalignment between old and new classes drives performance degradation. Building on this insight, we propose Variational Bayes C-GCD (VB-CGCD), a novel framework that integrates variational inference with covariance-aware nearest-class-mean classification. VB-CGCD adaptively aligns class distributions while suppressing pseudo-label noise via stochastic variational updates. Experiments show VB-CGCD surpasses prior art by +15.21% with the overall accuracy in the final session on standard benchmarks. We also introduce a new challenging benchmark with only 10% labeled data and extended online phases, VB-CGCD achieves a 67.86% final accuracy, significantly higher than state-of-the-art (38.55%), demonstrating its robust applicability across diverse scenarios. Code is available at: https://github.com/daihao42/VB-CGCD",
      "authors": [
        "Hao Dai",
        "Jagmohan Chauhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:25:27+00:00",
          "link": "https://arxiv.org/abs/2507.17382v1",
          "size": "793kb",
          "version": "v1"
        }
      ],
      "title": "Continual Generalized Category Discovery: Learning and Forgetting from a Bayesian Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17382",
        "HTML": "https://arxiv.org/html/2507.17382v1",
        "PDF": "https://arxiv.org/pdf/2507.17382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses category discovery and learning from unlabeled data using a Bayesian approach, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17383",
      "abstract": "Trustworthy robot behavior requires not only high levels of task success but also that the robot can reliably quantify how likely it is to succeed. To this end, we present the first systematic study of confidence calibration in vision-language-action (VLA) foundation models, which map visual observations and natural-language instructions to low-level robot motor commands. We begin with extensive benchmarking to understand the critical relationship between task success and calibration error across multiple datasets and VLA variants, finding that task performance and calibration are not in tension. Next, we introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm that averages confidence across paraphrased instructions and consistently improves calibration. We further analyze calibration over the task time horizon, showing that confidence is often most reliable after making some progress, suggesting natural points for risk-aware intervention. Finally, we reveal differential miscalibration across action dimensions and propose action-wise Platt scaling, a method to recalibrate each action dimension independently to produce better confidence estimates. Our aim in this study is to begin to develop the tools and conceptual understanding necessary to render VLAs both highly performant and highly trustworthy via reliable uncertainty quantification.",
      "authors": [
        "Thomas P Zollo",
        "Richard Zemel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:26:10+00:00",
          "link": "https://arxiv.org/abs/2507.17383v1",
          "size": "15636kb",
          "version": "v1"
        }
      ],
      "title": "Confidence Calibration in Vision-Language-Action Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17383",
        "HTML": "https://arxiv.org/html/2507.17383v1",
        "PDF": "https://arxiv.org/pdf/2507.17383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with confidence calibration in vision-language-action models and does not discuss any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17385",
      "abstract": "In the traditional Application-Specific Integrated Circuit (ASIC) design flow, the concept of timing closure implies to reach convergence during physical synthesis such that, under a given area and power budget, the design works at the targeted frequency. However, security has been largely neglected when evaluating the Quality of Results (QoR) from physical synthesis. In general, commercial place & route tools do not understand security goals. In this work, we propose a modified ASIC design flow that is security-aware and, differently from prior research, does not degrade QoR for the sake of security improvement. Therefore, we propose a first-of-its-kind zero-overhead flow for security closure. Our flow is concerned with two distinct threat models: (i) insertion of Hardware Trojans (HTs) and (ii) physical probing/fault injection. Importantly, the flow is entirely executed within a commercial place & route engine and is scalable. In several metrics, our security-aware flow achieves the best-known results for the ISPD`22 set of benchmark circuits while incurring negligible design overheads due to security-related strategies. Finally, we open source the entire methodology (as a set of scripts) and also share the protected circuits (as design databases) for the benefit of the hardware security community.",
      "authors": [
        "Mohammad Eslami",
        "Ashira Johara",
        "Kyungbin Park",
        "Samuel Pagliarini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:28:15+00:00",
          "link": "https://arxiv.org/abs/2507.17385v1",
          "size": "5485kb",
          "version": "v1"
        }
      ],
      "title": "A Zero-overhead Flow for Security Closure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17385",
        "PDF": "https://arxiv.org/pdf/2507.17385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a security-aware ASIC design flow and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17388",
      "abstract": "Endoscopic video generation is crucial for advancing medical imaging and enhancing diagnostic capabilities. However, prior efforts in this field have either focused on static images, lacking the dynamic context required for practical applications, or have relied on unconditional generation that fails to provide meaningful references for clinicians. Therefore, in this paper, we propose the first conditional endoscopic video generation framework, namely EndoGen. Specifically, we build an autoregressive model with a tailored Spatiotemporal Grid-Frame Patterning (SGP) strategy. It reformulates the learning of generating multiple frames as a grid-based image generation pattern, which effectively capitalizes the inherent global dependency modeling capabilities of autoregressive architectures. Furthermore, we propose a Semantic-Aware Token Masking (SAT) mechanism, which enhances the model's ability to produce rich and diverse content by selectively focusing on semantically meaningful regions during the generation process. Through extensive experiments, we demonstrate the effectiveness of our framework in generating high-quality, conditionally guided endoscopic content, and improves the performance of downstream task of polyp segmentation. Code released at https://www.github.com/CUHK-AIM-Group/EndoGen.",
      "authors": [
        "Xinyu Liu",
        "Hengyu Liu",
        "Cheng Wang",
        "Tianming Liu",
        "Yixuan Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:32:20+00:00",
          "link": "https://arxiv.org/abs/2507.17388v1",
          "size": "3426kb",
          "version": "v1"
        }
      ],
      "title": "EndoGen: Conditional Autoregressive Endoscopic Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17388",
        "HTML": "https://arxiv.org/html/2507.17388v1",
        "PDF": "https://arxiv.org/pdf/2507.17388"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating endoscopic videos using an autoregressive model, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17389",
      "abstract": "Recent advances in code large language models (CodeLLMs) have made them indispensable tools in modern software engineering. However, these models occasionally produce outputs that contain proprietary or sensitive code snippets, raising concerns about potential non-compliant use of training data, and posing risks to privacy and intellectual property. To ensure responsible and compliant deployment of CodeLLMs, training data detection (TDD) has become a critical task. While recent TDD methods have shown promise in natural language settings, their effectiveness on code data remains largely underexplored. This gap is particularly important given code's structured syntax and distinct similarity criteria compared to natural language. To address this, we conduct a comprehensive empirical study of seven state-of-the-art TDD methods on source code data, evaluating their performance across eight CodeLLMs. To support this evaluation, we introduce CodeSnitch, a function-level benchmark dataset comprising 9,000 code samples in three programming languages, each explicitly labeled as either included or excluded from CodeLLM training. Beyond evaluation on the original CodeSnitch, we design targeted mutation strategies to test the robustness of TDD methods under three distinct settings. These mutation strategies are grounded in the well-established Type-1 to Type-4 code clone detection taxonomy. Our study provides a systematic assessment of current TDD techniques for code and offers insights to guide the development of more effective and robust detection methods in the future.",
      "authors": [
        "Tianlin Li",
        "Yunxiang Wei",
        "Zhiming Li",
        "Aishan Liu",
        "Qing Guo",
        "Xianglong Liu",
        "Dongning Sun",
        "Yang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:34:22+00:00",
          "link": "https://arxiv.org/abs/2507.17389v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "Investigating Training Data Detection in AI Coders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17389",
        "HTML": "https://arxiv.org/html/2507.17389v1",
        "PDF": "https://arxiv.org/pdf/2507.17389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper's main focus is on training data detection (TDD) for code large language models. While it includes a discussion on data-related issues, such as potential non-compliant use and the creation of a dataset (CodeSnitch), the emphasis is on evaluating TDD methods rather than explicitly on improving or processing training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17391",
      "abstract": "We introduce a variant of the classic prophet inequality, called \\emph{residual prophet inequality} (RPI). In the RPI problem, we consider a finite sequence of $n$ nonnegative independent random values with known distributions, and a known integer $0\\leq k\\leq n-1$. Before the gambler observes the sequence, the top $k$ values are removed, whereas the remaining $n-k$ values are streamed sequentially to the gambler. For example, one can assume that the top $k$ values have already been allocated to a higher-priority agent. Upon observing a value, the gambler must decide irrevocably whether to accept or reject it, without the possibility of revisiting past values.\n  We study two variants of RPI, according to whether the gambler learns online of the identity of the variable that he sees (FI model) or not (NI model). Our main result is a randomized algorithm in the FI model with \\emph{competitive ratio} of at least $1/(k+2)$, which we show is tight. Our algorithm is data-driven and requires access only to the $k+1$ largest values of a single sample from the $n$ input distributions. In the NI model, we provide a similar algorithm that guarantees a competitive ratio of $1/(2k+2)$. We further analyze independent and identically distributed instances when $k=1$. We build a single-threshold algorithm with a competitive ratio of at least 0.4901, and show that no single-threshold strategy can get a competitive ratio greater than 0.5464.",
      "authors": [
        "Jose Correa",
        "Sebastian Perez-Salazar",
        "Dana Pizarro and Bruno Ziliotto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:36:11+00:00",
          "link": "https://arxiv.org/abs/2507.17391v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Residual Prophet Inequalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17391",
        "HTML": "https://arxiv.org/html/2507.17391v1",
        "PDF": "https://arxiv.org/pdf/2507.17391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a variant of the classic prophet inequality and its application in competitive analysis. It does not make any contribution to LLM training data processing, as it is centered around algorithmic and theoretical aspects of decision making."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17394",
      "abstract": "Video Anomaly Detection (VAD) aims to identify and locate deviations from normal patterns in video sequences. Traditional methods often struggle with substantial computational demands and a reliance on extensive labeled datasets, thereby restricting their practical applicability. To address these constraints, we propose HiProbe-VAD, a novel framework that leverages pre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring fine-tuning. In this paper, we discover that the intermediate hidden states of MLLMs contain information-rich representations, exhibiting higher sensitivity and linear separability for anomalies compared to the output layer. To capitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP) mechanism that intelligently identifies and extracts the most informative hidden states from the optimal intermediate layer during the MLLMs reasoning. Then a lightweight anomaly scorer and temporal localization module efficiently detects anomalies using these extracted hidden states and finally generate explanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate that HiProbe-VAD outperforms existing training-free and most traditional approaches. Furthermore, our framework exhibits remarkable cross-model generalization capabilities in different MLLMs without any tuning, unlocking the potential of pre-trained MLLMs for video anomaly detection and paving the way for more practical and scalable solutions.",
      "authors": [
        "Zhaolin Cai",
        "Fan Li",
        "Ziwei Zheng",
        "Yanjun Qin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.17394v1",
          "size": "934kb",
          "version": "v1"
        }
      ],
      "title": "HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17394",
        "HTML": "https://arxiv.org/html/2507.17394v1",
        "PDF": "https://arxiv.org/pdf/2507.17394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with video anomaly detection using pre-trained Multimodal Large Language Models without fine-tuning. The focus is on the methodology for anomaly detection in video data, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17399",
      "abstract": "Recent studies have explored graph-based approaches to retrieval-augmented generation, leveraging structured or semi-structured information -- such as entities and their relations extracted from documents -- to enhance retrieval. However, these methods are typically designed to address specific tasks, such as multi-hop question answering and query-focused summarisation, and therefore, there is limited evidence of their general applicability across broader datasets. In this paper, we aim to adapt a state-of-the-art graph-based RAG solution: $\\text{GeAR}$ and explore its performance and limitations on the SIGIR 2025 LiveRAG Challenge.",
      "authors": [
        "Zhili Shen",
        "Chenxin Diao",
        "Pascual Merita",
        "Pavlos Vougiouklis",
        "Jeff Z. Pan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:54:24+00:00",
          "link": "https://arxiv.org/abs/2507.17399v1",
          "size": "3170kb",
          "version": "v1"
        }
      ],
      "title": "Millions of $\\text{GeAR}$-s: Extending GraphRAG to Millions of Documents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17399",
        "PDF": "https://arxiv.org/pdf/2507.17399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores graph-based approaches to retrieval-augmented generation but does not address LLM training data processing. Its primary focus is on exploring enhancements to retrieval techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17401",
      "abstract": "Affordances - i.e. possibilities for action that an environment or objects in it provide - are important for robots operating in human environments to perceive. Existing approaches train such capabilities on annotated static images or shapes. This work presents a novel dataset for affordance learning of common household tasks. Unlike previous approaches, our dataset consists of video sequences demonstrating the tasks from first- and third-person perspectives, along with metadata about the affordances that are manifested in the task, and is aimed towards training perception systems to recognize affordance manifestations. The demonstrations were collected from several participants and in total record about seven hours of human activity. The variety of task performances also allows studying preparatory maneuvers that people may perform for a task, such as how they arrange their task space, which is also relevant for collaborative service robots.",
      "authors": [
        "Rachel Ringe",
        "Mihai Pomarlan",
        "Nikolaos Tsiogkas",
        "Stefano De Giorgis",
        "Maria Hedblom",
        "Rainer Malaka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.17401v1",
          "size": "664kb",
          "version": "v1"
        }
      ],
      "title": "The Wilhelm Tell Dataset of Affordance Demonstrations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17401",
        "HTML": "https://arxiv.org/html/2507.17401v1",
        "PDF": "https://arxiv.org/pdf/2507.17401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a dataset for affordance learning in robotics, focusing on video sequences for human-robot interaction tasks. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17402",
      "abstract": "Partially Relevant Video Retrieval (PRVR) addresses the critical challenge of matching untrimmed videos with text queries describing only partial content. Existing methods suffer from geometric distortion in Euclidean space that sometimes misrepresents the intrinsic hierarchical structure of videos and overlooks certain hierarchical semantics, ultimately leading to suboptimal temporal modeling. To address this issue, we propose the first hyperbolic modeling framework for PRVR, namely HLFormer, which leverages hyperbolic space learning to compensate for the suboptimal hierarchical modeling capabilities of Euclidean space. Specifically, HLFormer integrates the Lorentz Attention Block and Euclidean Attention Block to encode video embeddings in hybrid spaces, using the Mean-Guided Adaptive Interaction Module to dynamically fuse features. Additionally, we introduce a Partial Order Preservation Loss to enforce \"text < video\" hierarchy through Lorentzian cone constraints. This approach further enhances cross-modal matching by reinforcing partial relevance between video content and text queries. Extensive experiments show that HLFormer outperforms state-of-the-art methods. Code is released at https://github.com/lijun2005/ICCV25-HLFormer.",
      "authors": [
        "Li Jun",
        "Wang Jinpeng",
        "Tan Chaolei",
        "Lian Niu",
        "Chen Long",
        "Zhang Min",
        "Wang Yaowei",
        "Xia Shu-Tao",
        "Chen Bin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:59:46+00:00",
          "link": "https://arxiv.org/abs/2507.17402v1",
          "size": "578kb",
          "version": "v1"
        }
      ],
      "title": "HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17402",
        "HTML": "https://arxiv.org/html/2507.17402v1",
        "PDF": "https://arxiv.org/pdf/2507.17402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for partially relevant video retrieval using hyperbolic learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17403",
      "abstract": "As space missions increase, there is a growing need to replace point-to-point communication with an efficient and reliable network-centric communication approach. Disruption/Delay Tolerant Networking (DTN) with the Bundle Protocol (BP) has been selected as an interoperable network protocol in the LunaNet Interoperability Specification. It is also considered for future Earth Observation and Mars communication scenarios. In a DTN, the \"bundle\" -- the fundamental data unit of BP -- requires dedicated mechanisms to ensure reliability due to the challenges posed by intermittent connectivity and long delays. The previous version of BP, BPv6, contained a mechanism for reliable transfer between \"custodial nodes\" called \"custody transfer\". However, this approach has been removed from the core protocol specification for BPv7, which requires a corresponding BP reliability extension to be defined separately. This paper introduces a new custody transfer process for BPv7 (expected to be published by CCSDS as an experimental specification in 2025). The core features of this new custody transfer method for BPv7 are: (1) A strategy to efficiently identify sets of bundles by sequence numbering (2) A new Custody Transfer Extension Block and a corresponding administrative record, Compressed Custody Signal, to efficiently report on the acceptance or rejection of custody using sequence numbering (3) A new Compressed Reporting Extension Block requesting reporting on bundle processing steps using a corresponding administrative record with sequence numbering for efficiency. The paper will describe those concepts and their design, specification, and implementation in detail. These mechanisms have been prototyped in the ESA BP implementation and tested in Earth Observation and Lunar communication simulation scenarios. The results will be presented, as will an outlook on future work in the DTN reliable transfer domain.",
      "authors": [
        "Alice Le Bihan",
        "Felix Flentge",
        "Juan A. Fraire"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.17403v1",
          "size": "358kb",
          "version": "v1"
        }
      ],
      "title": "Custody Transfer and Compressed Status Reporting for Bundle Protocol Version 7",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17403",
        "HTML": "https://arxiv.org/html/2507.17403v1",
        "PDF": "https://arxiv.org/pdf/2507.17403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses network protocols for space communication, specifically bundle protocols in DTN. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17404",
      "abstract": "The concepts of amenable and compatible functions have been introduced in a recent work, in order to state precise mathematical theorems that guarantee that a backward stable algorithm is also forward stable, and that the composition of two stable algorithms results in an stable algorithm. In this work, we elaborate in this theory for univariate real analytic functions, providing simple tests for both concepts and producing tables for a number of elementary functions which are or fail to be amenable.",
      "authors": [
        "Carlos Beltr\\'an"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:00:03+00:00",
          "link": "https://arxiv.org/abs/2507.17404v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Univariate amenable functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17404",
        "HTML": "https://arxiv.org/html/2507.17404v1",
        "PDF": "https://arxiv.org/pdf/2507.17404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on mathematical properties of amenable functions relevant to algorithm stability, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17406",
      "abstract": "Most monocular and physics-based human pose tracking methods, while achieving state-of-the-art results, suffer from artifacts when the scene does not have a strictly flat ground plane or when the camera is moving. Moreover, these methods are often evaluated on in-the-wild real world videos without ground-truth data or on synthetic datasets, which fail to model the real world light transport, camera motion, and pose-induced appearance and geometry changes. To tackle these two problems, we introduce MoviCam, the first non-synthetic dataset containing ground-truth camera trajectories of a dynamically moving monocular RGB camera, scene geometry, and 3D human motion with human-scene contact labels. Additionally, we propose PhysDynPose, a physics-based method that incorporates scene geometry and physical constraints for more accurate human motion tracking in case of camera motion and non-flat scenes. More precisely, we use a state-of-the-art kinematics estimator to obtain the human pose and a robust SLAM method to capture the dynamic camera trajectory, enabling the recovery of the human pose in the world frame. We then refine the kinematic pose estimate using our scene-aware physics optimizer. From our new benchmark, we found that even state-of-the-art methods struggle with this inherently challenging setting, i.e. a moving camera and non-planar environments, while our method robustly estimates both human and camera poses in world coordinates.",
      "authors": [
        "Ayce Idil Aytekin",
        "Chuqiao Li",
        "Diogo Luvizon",
        "Rishabh Dabral",
        "Martin Oswald",
        "Marc Habermann",
        "Christian Theobalt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:04:30+00:00",
          "link": "https://arxiv.org/abs/2507.17406v1",
          "size": "7113kb",
          "version": "v1"
        }
      ],
      "title": "Physics-based Human Pose Estimation from a Single Moving RGB Camera",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17406",
        "HTML": "https://arxiv.org/html/2507.17406v1",
        "PDF": "https://arxiv.org/pdf/2507.17406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset and method for human pose estimation using a moving RGB camera, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17409",
      "abstract": "In assessing argument strength, the notions of what makes a good argument are manifold. With the broader trend towards treating subjectivity as an asset and not a problem in NLP, new dimensions of argument quality are studied. Although studies on individual subjective features like personal stories exist, there is a lack of large-scale analyses of the relation between these features and argument strength. To address this gap, we conduct regression analysis to quantify the impact of subjective factors $-$ emotions, storytelling, and hedging $-$ on two standard datasets annotated for objective argument quality and subjective persuasion. As such, our contribution is twofold: at the level of contributed resources, as there are no datasets annotated with all studied dimensions, this work compares and evaluates automated annotation methods for each subjective feature. At the level of novel insights, our regression analysis uncovers different patterns of impact of subjective features on the two facets of argument strength encoded in the datasets. Our results show that storytelling and hedging have contrasting effects on objective and subjective argument quality, while the influence of emotions depends on their rhetoric utilization rather than the domain.",
      "authors": [
        "Carlotta Quensel and Neele Falk and Gabriella Lapesa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:09:52+00:00",
          "link": "https://arxiv.org/abs/2507.17409v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "Investigating Subjective Factors of Argument Strength: Storytelling, Emotions, and Hedging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17409",
        "HTML": "https://arxiv.org/html/2507.17409v1",
        "PDF": "https://arxiv.org/pdf/2507.17409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates subjective factors affecting argument strength, such as storytelling, emotions, and hedging, without addressing innovations or contributions in the domain of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17411",
      "abstract": "We study the problem of scheduling a general computational DAG on multiple processors in a 2-level memory hierarchy. This setting is a natural generalization of several prominent models in the literature, and it simultaneously captures workload balancing, communication, and data movement due to cache size limitations. We first analyze the fundamental properties of this problem from a theoretical perspective, such as its computational complexity. We also prove that optimizing parallelization and memory management separately, as done in many applications, can result in a solution that is a linear factor away from the optimum.\n  On the algorithmic side, we discuss a natural technique to represent and solve the problem as an Integer Linear Program (ILP). We develop a holistic scheduling algorithm based on this approach, and we experimentally study its performance and properties on a small benchmark of computational tasks. Our results confirm that the ILP-based method can indeed find considerably better solutions than a baseline which combines classical scheduling algorithms and memory management policies.",
      "authors": [
        "P\\'al Andr\\'as Papp",
        "Toni B\\\"ohnlein",
        "A. N. Yzelman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:12:08+00:00",
          "link": "https://arxiv.org/abs/2507.17411v1",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "title": "Multiprocessor Scheduling with Memory Constraints: Fundamental Properties and Finding Optimal Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17411",
        "HTML": "https://arxiv.org/html/2507.17411v1",
        "PDF": "https://arxiv.org/pdf/2507.17411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on multiprocessor scheduling with memory constraints, discussing theoretical properties and algorithmic solutions. It does not involve LLM training data processing operations or contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17412",
      "abstract": "The increasing volume of medical images poses challenges for radiologists in retrieving relevant cases. Content-based image retrieval (CBIR) systems offer potential for efficient access to similar cases, yet lack standardized evaluation and comprehensive studies. Building on prior studies for tumor characterization via CBIR, this study advances CBIR research for volumetric medical images through three key contributions: (1) a framework eliminating reliance on pre-segmented data and organ-specific datasets, aligning with large and unstructured image archiving systems, i.e. PACS in clinical practice; (2) introduction of C-MIR, a novel volumetric re-ranking method adapting ColBERT's contextualized late interaction mechanism for 3D medical imaging; (3) comprehensive evaluation across four tumor sites using three feature extractors and three database configurations. Our evaluations highlight the significant advantages of C-MIR. We demonstrate the successful adaptation of the late interaction principle to volumetric medical images, enabling effective context-aware re-ranking. A key finding is C-MIR's ability to effectively localize the region of interest, eliminating the need for pre-segmentation of datasets and offering a computationally efficient alternative to systems relying on expensive data enrichment steps. C-MIR demonstrates promising improvements in tumor flagging, achieving improved performance, particularly for colon and lung tumors (p<0.05). C-MIR also shows potential for improving tumor staging, warranting further exploration of its capabilities. Ultimately, our work seeks to bridge the gap between advanced retrieval techniques and their practical applications in healthcare, paving the way for improved diagnostic processes.",
      "authors": [
        "Farnaz Khun Jush",
        "Steffen Vogler",
        "Matthias Lenga"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:12:52+00:00",
          "link": "https://arxiv.org/abs/2507.17412v1",
          "size": "617kb",
          "version": "v1"
        }
      ],
      "title": "Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17412",
        "HTML": "https://arxiv.org/html/2507.17412v1",
        "PDF": "https://arxiv.org/pdf/2507.17412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered around content-based 3D image retrieval for tumor flagging, without addressing or contributing to LLM training data processing aspects like collection, filtering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17417",
      "abstract": "For large language models (LLMs), post-training quantization (PTQ) can significantly reduce memory footprint and computational overhead. Model quantization is a rapidly evolving research field. Though many papers have reported breakthrough performance, they may not conduct experiments on the same ground since one quantization method usually contains multiple components. In addition, analyzing the theoretical connections among existing methods is crucial for in-depth understanding. To bridge these gaps, we conduct an extensive review of state-of-the-art methods and perform comprehensive evaluations on the same ground to ensure fair comparisons. To our knowledge, this fair and extensive investigation remains critically important yet underexplored. To better understand the theoretical connections, we decouple the published quantization methods into two steps: pre-quantization transformation and quantization error mitigation. We define the former as a preprocessing step applied before quantization to reduce the impact of outliers, making the data distribution flatter and more suitable for quantization. Quantization error mitigation involves techniques that offset the errors introduced during quantization, thereby enhancing model performance. We evaluate and analyze the impact of different components of quantization methods. Additionally, we analyze and evaluate the latest MXFP4 data format and its performance. Our experimental results demonstrate that optimized rotation and scaling yield the best performance for pre-quantization transformation, and combining low-rank compensation with GPTQ occasionally outperforms using GPTQ alone for quantization error mitigation. Furthermore, we explore the potential of the latest MXFP4 quantization and reveal that the optimal pre-quantization transformation strategy for INT4 does not generalize well to MXFP4, inspiring further investigation.",
      "authors": [
        "Yutong Liu",
        "Cairong Zhao",
        "Guosheng Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:21:21+00:00",
          "link": "https://arxiv.org/abs/2507.17417v1",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Evaluation on Quantization Techniques for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17417",
        "HTML": "https://arxiv.org/html/2507.17417v1",
        "PDF": "https://arxiv.org/pdf/2507.17417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines quantization techniques for LLMs, focusing on post-training quantization and model efficiency. It does not discuss training data processing operations or dataset creation relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17418",
      "abstract": "Precise modeling of microscopic vehicle trajectories is critical for traffic behavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a context-aware trajectory generation framework that synthesizes realistic urban driving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses nonlinear interdependencies and training instability inherent in microscopic settings. By explicitly conditioning on surrounding vehicles and road geometry, Ctx2TrajGen generates interaction-aware trajectories aligned with real-world context. Experiments on the drone-captured DRIFT dataset demonstrate superior performance over existing methods in terms of realism, behavioral diversity, and contextual fidelity, offering a robust solution to data scarcity and domain shift without simulation.",
      "authors": [
        "Joobin Jin",
        "Seokjun Hong",
        "Gyeongseon Baek",
        "Yeeun Kim",
        "Byeongjoon Noh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:21:27+00:00",
          "link": "https://arxiv.org/abs/2507.17418v1",
          "size": "4718kb",
          "version": "v1"
        }
      ],
      "title": "Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17418",
        "HTML": "https://arxiv.org/html/2507.17418v1",
        "PDF": "https://arxiv.org/pdf/2507.17418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Ctx2TrajGen models microscopic vehicle trajectories using generative adversarial imitation learning, focusing on traffic behavior analysis rather than any aspect of LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17420",
      "abstract": "In computed tomography (CT), achieving high image quality while minimizing radiation exposure remains a key clinical challenge. This paper presents CAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and Predictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT integrates image data with acquisition metadata (such as tube voltage, tube current, and contrast agent types) to model the underlying causal relationships that influence image quality. An ensemble of Variational Autoencoders (VAEs) is employed to extract meaningful features and generate causal representations from observational data, including CT images and associated imaging parameters. These input features are fused to predict the Signal-to-Noise Ratio (SNR) and support counterfactual inference, enabling what-if simulations, such as changes in contrast agents (types and concentrations) or scan parameters. CAPRI-CT is trained and validated using an ensemble learning approach, achieving strong predictive performance. By facilitating both prediction and interpretability, CAPRI-CT provides actionable insights that could help radiologists and technicians design more efficient CT protocols without repeated physical scans. The source code and dataset are publicly available at https://github.com/SnehaGeorge22/capri-ct.",
      "authors": [
        "Sneha George Gnanakalavathy",
        "Hairil Abdul Razak",
        "Robert Meertens",
        "Jonathan E. Fieldsend",
        "Xujiong Ye",
        "Mohammed M. Abdelsamea"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:23:02+00:00",
          "link": "https://arxiv.org/abs/2507.17420v1",
          "size": "622kb",
          "version": "v1"
        }
      ],
      "title": "CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17420",
        "HTML": "https://arxiv.org/html/2507.17420v1",
        "PDF": "https://arxiv.org/pdf/2507.17420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a deep learning framework for optimizing image quality in computed tomography, focusing on causal analysis and predictive reasoning. It does not concern LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17422",
      "abstract": "The mixed-model assembly line (MMAL) is a production system used in the automobile industry to manufacture different car models on the same conveyor, offering a high degree of product customization and flexibility. However, the MMAL also poses challenges, such as finding optimal sequences of models satisfying multiple constraints and objectives related to production performance, quality, and delivery -- including minimizing the number of color changeovers in the Paint Shop, balancing the workload and setup times on the assembly line, and meeting customer demand and delivery deadlines. We propose a multi-objective algorithm to solve the MMAL resequencing problem under consideration of all these aspects simultaneously. We also present empirical results obtained from recorded event data of the production process over $4$ weeks following the deployment of our algorithm in the Saarlouis plant of Ford-Werke GmbH. We achieved an improvement of the average batch size of about $30\\%$ over the old control software translating to a $23\\%$ reduction of color changeovers. Moreover, we reduced the spread of cars planned for a specific date by $10\\%$, reducing the risk of delays in delivery. We discuss effectiveness and robustness of our algorithm in improving production performance and quality as well as trade-offs and limitations.",
      "authors": [
        "Andreas Karrenbauer",
        "Bernd Kuhn",
        "Kurt Mehlhorn",
        "Paolo Luigi Rinaldi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:29:44+00:00",
          "link": "https://arxiv.org/abs/2507.17422v1",
          "size": "698kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Car Resequencing on Mixed-Model Assembly Lines: Algorithm Development and Deployment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17422",
        "HTML": "https://arxiv.org/html/2507.17422v1",
        "PDF": "https://arxiv.org/pdf/2507.17422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses optimization algorithms for car resequencing in mixed-model assembly lines. It focuses on production performance and does not involve LLM training data processing or data engineering operations relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17423",
      "abstract": "We present a novel approach to define the filter and relax steps in the evolve-filter-relax (EFR) framework for simulating turbulent flows. The EFR main advantages are its ease of implementation and computational efficiency. However, as it only contains two parameters (one for the filter step and one for the relax step) its flexibility is rather limited. In this work, we propose a data-driven approach in which the optimal filter is found based on DNS data in the frequency domain. The optimization step is computationally efficient and only involves one-dimensional least-squares problems for each wavenumber. Across both decaying turbulence and Kolmogorov flow, our learned filter decisively outperforms the standard differential filter and the Smagorinsky model, yielding significantly improved accuracy in energy spectra and in the temporal evolution of both energy and enstrophy. In addition, the relax parameter is determined by requiring energy and/or enstrophy conservation, which enforces stability of the method and reduces the appearance of numerical wiggles, especially when the filter is built in scarce data regimes. Applying the learned filter is also more computationally efficient compared to traditional differential filters, as it circumvents solving a linear system.",
      "authors": [
        "Anna Ivagnes",
        "Toby van Gastelen",
        "Syver D{\\o}ving Agdestein",
        "Benjamin Sanderse",
        "Giovanni Stabile",
        "Gianluigi Rozza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:30:44+00:00",
          "link": "https://arxiv.org/abs/2507.17423v1",
          "size": "16489kb",
          "version": "v1"
        }
      ],
      "title": "A new data-driven energy-stable Evolve-Filter-Relax model for turbulent flow simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17423",
        "HTML": "https://arxiv.org/html/2507.17423v1",
        "PDF": "https://arxiv.org/pdf/2507.17423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a data-driven model for turbulent flow simulation, focusing on improved filtering techniques. It does not contribute to LLM training data processing or involve relevant data techniques for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17426",
      "abstract": "This paper addresses decentralized stochastic gradient descent (D-SGD) over resource-constrained networks by introducing node-based and link-based scheduling strategies to enhance communication efficiency. In each iteration of the D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly activated, subject to a given communication cost constraint. We propose a novel importance metric based on information entropy to determine node and link scheduling probabilities. We validate the effectiveness of our approach through extensive simulations, comparing it against state-of-the-art methods, including betweenness centrality (BC) for node scheduling and \\textit{MATCHA} for link scheduling. The results show that our method consistently outperforms the BC-based method in the node scheduling case, achieving faster convergence with up to 60\\% lower communication budgets. At higher communication budgets (above 60\\%), our method maintains comparable or superior performance. In the link scheduling case, our method delivers results that are superior to or on par with those of \\textit{MATCHA}.",
      "authors": [
        "Jaiprakash Nagar",
        "Zheng Chen",
        "Marios Kountouris",
        "Photios A. Stavrou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:33:35+00:00",
          "link": "https://arxiv.org/abs/2507.17426v1",
          "size": "827kb",
          "version": "v1"
        }
      ],
      "title": "Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17426",
        "HTML": "https://arxiv.org/html/2507.17426v1",
        "PDF": "https://arxiv.org/pdf/2507.17426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents scheduling strategies to enhance communication efficiency in decentralized learning using stochastic gradient descent. It does not relate to LLM training data processing or data techniques for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17427",
      "abstract": "Dirty paper coding (DPC) is a classical problem in information theory that considers communication in the presence of channel state known only at the transmitter. While the theoretical impact of DPC has been substantial, practical realizations of DPC, such as Tomlinson-Harashima precoding (THP) or lattice-based schemes, often rely on specific modeling assumptions about the input, state and channel. In this work, we explore whether modern learning-based approaches can offer a complementary path forward by revisiting the DPC problem. We propose a data-driven solution in which both the encoder and decoder are parameterized by neural networks. Our proposed model operates without prior knowledge of the state (also referred to as \"interference\"), channel or input statistics, and recovers nonlinear mappings that yield effective interference pre-cancellation. To the best of our knowledge, this is the first interpretable proof-of-concept demonstrating that learning-based DPC schemes can recover characteristic features of well-established solutions, such as THP and lattice-based precoding, and outperform them in several regimes.",
      "authors": [
        "Ezgi Ozyilkan",
        "O\\u{g}uzhan Kubilay \\\"Ulger",
        "Elza Erkip"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:36:43+00:00",
          "link": "https://arxiv.org/abs/2507.17427v1",
          "size": "243kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Write on Dirty Paper",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17427",
        "HTML": "https://arxiv.org/html/2507.17427v1",
        "PDF": "https://arxiv.org/pdf/2507.17427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores learning-based approaches to dirty paper coding in communication systems. It does not address LLM training data processing or contribute relevant data engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17430",
      "abstract": "Integrating technology with the distinctive characteristics of craftsmanship has become a key issue in the field of digital craftsmanship. This paper introduces Layered Interactions, a design approach that seamlessly merges Human-Computer Interaction (HCI) technologies with traditional lacquerware craftsmanship. By leveraging the multi-layer structure and material properties of lacquerware, we embed interactive circuits and integrate programmable hardware within the layers, creating tangible interfaces that support diverse interactions. This method enhances the adaptability and practicality of traditional crafts in modern digital contexts. Through the development of a lacquerware toolkit, along with user experiments and semi-structured interviews, we demonstrate that this approach not only makes technology more accessible to traditional artisans but also enhances the materiality and emotional qualities of interactive interfaces. Additionally, it fosters mutual learning and collaboration between artisans and technologists. Our research introduces a cross-disciplinary perspective to the HCI community, broadening the material and design possibilities for interactive interfaces.",
      "authors": [
        "Yan Dong",
        "Hanjie Yu",
        "Yanran Chen",
        "Zipeng Zhang",
        "Qiong Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:41:43+00:00",
          "link": "https://arxiv.org/abs/2507.17430v1",
          "size": "25336kb",
          "version": "v1"
        }
      ],
      "title": "Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17430",
        "HTML": "https://arxiv.org/html/2507.17430v1",
        "PDF": "https://arxiv.org/pdf/2507.17430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating technology with craftsmanship using Human-Computer Interaction (HCI) technologies and traditional lacquerware craftsmanship. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17432",
      "abstract": "In the Wyner-Ziv source coding problem, a source $X$ has to be encoded while the decoder has access to side information $Y$. This paper investigates the indirect setup, in which a latent source $S$, unobserved by both the encoder and the decoder, must also be reconstructed at the decoder. This scenario is increasingly relevant in the context of goal-oriented communications, where $S$ can represent semantic information obtained from $X$. This paper derives the indirect Wyner-Ziv rate-distortion function in asymptotic regime and provides an achievable region in finite block-length. Furthermore, a Blahut-Arimoto algorithm tailored for the indirect Wyner-Ziv setup, is proposed. This algorithm is then used to give a numerical evaluation of the achievable indirect rate-distortion region when $S$ is treated as a classification label.",
      "authors": [
        "Jiahui Wei",
        "Philippe Mary",
        "Elsa Dupraz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:42:58+00:00",
          "link": "https://arxiv.org/abs/2507.17432v1",
          "size": "186kb",
          "version": "v1"
        }
      ],
      "title": "Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17432",
        "HTML": "https://arxiv.org/html/2507.17432v1",
        "PDF": "https://arxiv.org/pdf/2507.17432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the Wyner-Ziv source coding problem, focusing on indirect setups and achievable rate-distortion regions. It does not relate to LLM training data processing or any related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17433",
      "abstract": "Participatory budgeting is a method of collectively understanding and addressing spending priorities where citizens vote on how a budget is spent, it is regularly run to improve the fairness of the distribution of public funds. Participatory budgeting requires voters to make decisions on projects which can lead to ``choice overload\". A multi-agent reinforcement learning approach to decision support can make decision making easier for voters by identifying voting strategies that increase the winning proportion of their vote. This novel approach can also support policymakers by highlighting aspects of election design that enable fair compromise on projects. This paper presents a novel, ethically aligned approach to decision support using multi-agent deep reinforcement learning modelling. This paper introduces a novel use of a branching neural network architecture to overcome scalability challenges of multi-agent reinforcement learning in a decentralized way. Fair compromises are found through optimising voter actions towards greater representation of voter preferences in the winning set. Experimental evaluation with real-world participatory budgeting data reveals a pattern in fair compromise: that it is achievable through projects with smaller cost.",
      "authors": [
        "Hugh Adams",
        "Srijoni Majumdar",
        "Evangelos Pournaras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:46:13+00:00",
          "link": "https://arxiv.org/abs/2507.17433v1",
          "size": "1622kb",
          "version": "v1"
        }
      ],
      "title": "Fair Compromises in Participatory Budgeting: a Multi-Agent Deep Reinforcement Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17433",
        "HTML": "https://arxiv.org/html/2507.17433v1",
        "PDF": "https://arxiv.org/pdf/2507.17433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research explores participatory budgeting through a multi-agent deep reinforcement learning approach, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17436",
      "abstract": "The Mixture of Experts (MoE) architecture has excelled in Large Vision-Language Models (LVLMs), yet its potential in real-time open-vocabulary object detectors, which also leverage large-scale vision-language datasets but smaller models, remains unexplored. This work investigates this domain, revealing intriguing insights. In the shallow layers, experts tend to cooperate with diverse peers to expand the search space. While in the deeper layers, fixed collaborative structures emerge, where each expert maintains 2-3 fixed partners and distinct expert combinations are specialized in processing specific patterns. Concretely, we propose Dynamic-DINO, which extends Grounding DINO 1.5 Edge from a dense model to a dynamic inference framework via an efficient MoE-Tuning strategy. Additionally, we design a granularity decomposition mechanism to decompose the Feed-Forward Network (FFN) of base model into multiple smaller expert networks, expanding the subnet search space. To prevent performance degradation at the start of fine-tuning, we further propose a pre-trained weight allocation strategy for the experts, coupled with a specific router initialization. During inference, only the input-relevant experts are activated to form a compact subnet. Experiments show that, pretrained with merely 1.56M open-source data, Dynamic-DINO outperforms Grounding DINO 1.5 Edge, pretrained on the private Grounding20M dataset.",
      "authors": [
        "Yehao Lu",
        "Minghe Weng",
        "Zekang Xiao",
        "Rui Jiang",
        "Wei Su",
        "Guangcong Zheng",
        "Ping Lu",
        "Xi Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.17436v1",
          "size": "20529kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17436",
        "HTML": "https://arxiv.org/html/2507.17436v1",
        "PDF": "https://arxiv.org/pdf/2507.17436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes Dynamic-DINO for real-time open-vocabulary object detection using MoE architecture, leveraging smaller vision-language datasets. It briefly touches on fine-tuning but focuses mainly on model architecture rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17440",
      "abstract": "Real-time rendering imposes strict limitations on the sampling budget for light transport simulation, often resulting in noisy images. However, denoisers have demonstrated that it is possible to produce noise-free images through filtering. We enhance image quality by removing noise before material shading, rather than filtering already shaded noisy images. This approach allows for material-agnostic denoising (MAD) and leverages machine learning by approximating the light transport integral operator with a neural network, effectively performing parametric integration with neural operators. Our method operates in real-time, requires data from only a single frame, seamlessly integrates with existing denoisers and temporal anti-aliasing techniques, and is efficient to train. Additionally, it is straightforward to incorporate with physically based rendering algorithms.",
      "authors": [
        "Christoph Schied and Alexander Keller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:02:01+00:00",
          "link": "https://arxiv.org/abs/2507.17440v1",
          "size": "21986kb",
          "version": "v1"
        }
      ],
      "title": "Parametric Integration with Neural Integral Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17440",
        "HTML": "https://arxiv.org/html/2507.17440v1",
        "PDF": "https://arxiv.org/pdf/2507.17440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on real-time rendering and denoising in computer graphics, specifically using neural integral operators for image quality enhancement. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17442",
      "abstract": "Recently, as Large Language Models (LLMs) have fundamentally impacted various fields, the methods for incorporating up-to-date information into LLMs or adding external knowledge to construct domain-specific models have garnered wide attention. Retrieval-Augmented Generation (RAG), serving as an inference-time scaling method, is notable for its low cost and minimal effort for parameter tuning. However, due to heterogeneous training data and model architecture, the variant embedding models used in RAG exhibit different benefits across various areas, often leading to different similarity calculation results and, consequently, varying response quality from LLMs. To address this problem, we propose and examine two approaches to enhance RAG by combining the benefits of multiple embedding models, named Mixture-Embedding RAG and Confident RAG. Mixture-Embedding RAG simply sorts and selects retrievals from multiple embedding models based on standardized similarity; however, it does not outperform vanilla RAG. In contrast, Confident RAG generates responses multiple times using different embedding models and then selects the responses with the highest confidence level, demonstrating average improvements of approximately 10% and 5% over vanilla LLMs and RAG, respectively. The consistent results across different LLMs and embedding models indicate that Confident RAG is an efficient plug-and-play approach for various domains. We will release our code upon publication.",
      "authors": [
        "Shiting Chen",
        "Zijian Zhao",
        "Jinsong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:03:54+00:00",
          "link": "https://arxiv.org/abs/2507.17442v1",
          "size": "1632kb",
          "version": "v1"
        }
      ],
      "title": "Each to Their Own: Exploring the Optimal Embedding in RAG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17442",
        "HTML": "https://arxiv.org/html/2507.17442v1",
        "PDF": "https://arxiv.org/pdf/2507.17442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing Retrieval-Augmented Generation (RAG) which involves embeddings and retrieval techniques. While it speaks to embedding optimization, it primarily focuses on inference enhancements rather than dataset processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17445",
      "abstract": "Detecting diverse objects within complex indoor 3D point clouds presents significant challenges for robotic perception, particularly with varied object shapes, clutter, and the co-existence of static and dynamic elements where traditional bounding box methods falter. To address these limitations, we propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor mobile robots.\n  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles naturally occlusions and provides a consistent top-down view aiding to distinguish static obstacles from dynamic agents. The obtained 2D BEV results is directly usable to downstream robotic tasks like navigation, motion prediction, and planning. Our architecture utilizes an axis compact encoder and a window-based backbone to extract rich spatial features from this BEV map. A query-based decoder head then employs learned object queries to concurrently predict object classes and instance masks in the BEV space. This mask-centric formulation effectively captures the footprint of both static and dynamic objects regardless of their shape, offering a robust alternative to bounding box regression. We demonstrate the effectiveness of IndoorBEV on a custom indoor dataset featuring diverse object classes including static objects\n  and dynamic elements like robots and miscellaneous items, showcasing its potential for robust indoor scene understanding.",
      "authors": [
        "Haichuan Li",
        "Changda Tian",
        "Panos Trahanias",
        "Tomi Westerlund"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:07:21+00:00",
          "link": "https://arxiv.org/abs/2507.17445v1",
          "size": "9401kb",
          "version": "v1"
        }
      ],
      "title": "IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17445",
        "HTML": "https://arxiv.org/html/2507.17445v1",
        "PDF": "https://arxiv.org/pdf/2507.17445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "IndoorBEV pertains to object detection and footprint completion in 3D point clouds for robotics, focusing on mask-based predictions and Bird's-Eye View perception. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17448",
      "abstract": "Retrosynthesis planning, essential in organic synthesis and drug discovery, has greatly benefited from recent AI-driven advancements. Nevertheless, existing methods frequently face limitations in both applicability and explainability. Traditional graph-based and sequence-to-sequence models often lack generalized chemical knowledge, leading to predictions that are neither consistently accurate nor easily explainable. To address these challenges, we introduce RetroDFM-R, a reasoning-based large language model (LLM) designed specifically for chemical retrosynthesis. Leveraging large-scale reinforcement learning guided by chemically verifiable rewards, RetroDFM-R significantly enhances prediction accuracy and explainability. Comprehensive evaluations demonstrate that RetroDFM-R significantly outperforms state-of-the-art methods, achieving a top-1 accuracy of 65.0% on the USPTO-50K benchmark. Double-blind human assessments further validate the chemical plausibility and practical utility of RetroDFM-R's predictions. RetroDFM-R also accurately predicts multistep retrosynthetic routes reported in the literature for both real-world drug molecules and perovskite materials. Crucially, the model's explicit reasoning process provides human-interpretable insights, thereby enhancing trust and practical value in real-world retrosynthesis applications.",
      "authors": [
        "Situo Zhang",
        "Hanqi Li",
        "Lu Chen",
        "Zihan Zhao",
        "Xuanze Lin",
        "Zichen Zhu",
        "Bo Chen",
        "Xin Chen",
        "Kai Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:13:06+00:00",
          "link": "https://arxiv.org/abs/2507.17448v1",
          "size": "1457kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning-Driven Retrosynthesis Prediction with Large Language Models via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17448",
        "HTML": "https://arxiv.org/html/2507.17448v1",
        "PDF": "https://arxiv.org/pdf/2507.17448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a reasoning-driven LLM for retrosynthesis prediction in chemistry, enhanced by reinforcement learning. It does not address the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17450",
      "abstract": "We present a topological pipeline for automated multiclass emotion recognition from eye-tracking data. Delay embeddings of gaze trajectories are analyzed using persistent homology. From the resulting persistence diagrams, we extract shape-based features such as mean persistence, maximum persistence, and entropy. A random forest classifier trained on these features achieves up to $75.6\\%$ accuracy on four emotion classes, which are the quadrants the Circumplex Model of Affect. The results demonstrate that persistence diagram geometry effectively encodes discriminative gaze dynamics, suggesting a promising topological approach for affective computing and human behavior analysis.",
      "authors": [
        "Arsha Niksa",
        "Hooman Zare",
        "Ali Shahrabi",
        "Hanieh Hatami",
        "Mohammadreza Razvan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:14:17+00:00",
          "link": "https://arxiv.org/abs/2507.17450v1",
          "size": "422kb",
          "version": "v1"
        }
      ],
      "title": "Persistent Patterns in Eye Movements: A Topological Approach to Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17450",
        "HTML": "https://arxiv.org/html/2507.17450v1",
        "PDF": "https://arxiv.org/pdf/2507.17450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a topological approach for emotion recognition using eye-tracking data and persistent homology. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17453",
      "abstract": "The vulnerability of neural networks to adversarial perturbations has necessitated formal verification techniques that can rigorously certify the quality of neural networks. As the state-of-the-art, branch and bound (BaB) is a \"divide-and-conquer\" strategy that applies off-the-shelf verifiers to sub-problems for which they perform better. While BaB can identify the sub-problems that are necessary to be split, it explores the space of these sub-problems in a naive \"first-come-first-serve\" manner, thereby suffering from an issue of inefficiency to reach a verification conclusion. To bridge this gap, we introduce an order over different sub-problems produced by BaB, concerning with their different likelihoods of containing counterexamples. Based on this order, we propose a novel verification framework Oliva that explores the sub-problem space by prioritizing those sub-problems that are more likely to find counterexamples, in order to efficiently reach the conclusion of the verification. Even if no counterexample can be found in any sub-problem, it only changes the order of visiting different sub-problem and so will not lead to a performance degradation. Specifically, Oliva has two variants, including $Oliva^{GR}$, a greedy strategy that always prioritizes the sub-problems that are more likely to find counterexamples, and $Oliva^{SA}$, a balanced strategy inspired by simulated annealing that gradually shifts from exploration to exploitation to locate the globally optimal sub-problems. We experimentally evaluate the performance of Oliva on 690 verification problems spanning over 5 models with datasets MNIST and CIFAR10. Compared to the state-of-the-art approaches, we demonstrate the speedup of Oliva for up to 25X in MNIST, and up to 80X in CIFAR10.",
      "authors": [
        "Guanqin Zhang",
        "Kota Fukuda",
        "Zhenya Zhang",
        "H.M.N. Dilum Bandara",
        "Shiping Chen",
        "Jianjun Zhao",
        "Yulei Sui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:20:20+00:00",
          "link": "https://arxiv.org/abs/2507.17453v1",
          "size": "2084kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Neural Network Verification via Order Leading Exploration of Branch-and-Bound Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17453",
        "HTML": "https://arxiv.org/html/2507.17453v1",
        "PDF": "https://arxiv.org/pdf/2507.17453"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on neural network verification techniques, specifically the exploration of sub-problems in branch-and-bound trees, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17454",
      "abstract": "Multivariate time series forecasting has drawn increasing attention due to its practical importance. Existing approaches typically adopt either channel-mixing (CM) or channel-independence (CI) strategies. CM strategy can capture inter-variable dependencies but fails to discern variable-specific temporal patterns. CI strategy improves this aspect but fails to fully exploit cross-variable dependencies like CM. Hybrid strategies based on feature fusion offer limited generalization and interpretability. To address these issues, we propose C3RL, a novel representation learning framework that jointly models both CM and CI strategies. Motivated by contrastive learning in computer vision, C3RL treats the inputs of the two strategies as transposed views and builds a siamese network architecture: one strategy serves as the backbone, while the other complements it. By jointly optimizing contrastive and prediction losses with adaptive weighting, C3RL balances representation and forecasting performance. Extensive experiments on seven models show that C3RL boosts the best-case performance rate to 81.4\\% for models based on CI strategy and to 76.3\\% for models based on CM strategy, demonstrating strong generalization and effectiveness. The code will be available once the paper is accepted.",
      "authors": [
        "Shusen Ma",
        "Yun-Bo Zhao and Yu Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:21:26+00:00",
          "link": "https://arxiv.org/abs/2507.17454v1",
          "size": "3130kb",
          "version": "v1"
        }
      ],
      "title": "C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17454",
        "HTML": "https://arxiv.org/html/2507.17454v1",
        "PDF": "https://arxiv.org/pdf/2507.17454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multivariate time series forecasting and representation learning strategies, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17455",
      "abstract": "Geo-localization from a single image at planet scale (essentially an advanced or extreme version of the kidnapped robot problem) is a fundamental and challenging task in applications such as navigation, autonomous driving and disaster response due to the vast diversity of locations, environmental conditions, and scene variations. Traditional retrieval-based methods for geo-localization struggle with scalability and perceptual aliasing, while classification-based approaches lack generalization and require extensive training data. Recent advances in vision-language models (VLMs) offer a promising alternative by leveraging contextual understanding and reasoning. However, while VLMs achieve high accuracy, they are often prone to hallucinations and lack interpretability, making them unreliable as standalone solutions. In this work, we propose a novel hybrid geo-localization framework that combines the strengths of VLMs with retrieval-based visual place recognition (VPR) methods. Our approach first leverages a VLM to generate a prior, effectively guiding and constraining the retrieval search space. We then employ a retrieval step, followed by a re-ranking mechanism that selects the most geographically plausible matches based on feature similarity and proximity to the initially estimated coordinates. We evaluate our approach on multiple geo-localization benchmarks and show that it consistently outperforms prior state-of-the-art methods, particularly at street (up to 4.51%) and city level (up to 13.52%). Our results demonstrate that VLM-generated geographic priors in combination with VPR lead to scalable, robust, and accurate geo-localization systems.",
      "authors": [
        "Sania Waheed",
        "Na Min An",
        "Michael Milford",
        "Sarvapali D. Ramchurn",
        "Shoaib Ehsan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:23:03+00:00",
          "link": "https://arxiv.org/abs/2507.17455v1",
          "size": "4397kb",
          "version": "v1"
        }
      ],
      "title": "VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17455",
        "HTML": "https://arxiv.org/html/2507.17455v1",
        "PDF": "https://arxiv.org/pdf/2507.17455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses geo-localization using vision-language models, focusing on improving retrieval mechanisms rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17456",
      "abstract": "Human-Object Interaction (HOI) detection aims to identify humans and objects within images and interpret their interactions. Existing HOI methods rely heavily on large datasets with manual annotations to learn interactions from visual cues. These annotations are labor-intensive to create, prone to inconsistency, and limit scalability to new domains and rare interactions. We argue that recent advances in Vision-Language Models (VLMs) offer untapped potential, particularly in enhancing interaction representation. While prior work has injected such potential and even proposed training-free methods, there remain key gaps. Consequently, we propose a novel training-free HOI detection framework for Dynamic Scoring with enhanced semantics (DYSCO) that effectively utilizes textual and visual interaction representations within a multimodal registry, enabling robust and nuanced interaction understanding. This registry incorporates a small set of visual cues and uses innovative interaction signatures to improve the semantic alignment of verbs, facilitating effective generalization to rare interactions. Additionally, we propose a unique multi-head attention mechanism that adaptively weights the contributions of the visual and textual features. Experimental results demonstrate that our DYSCO surpasses training-free state-of-the-art models and is competitive with training-based approaches, particularly excelling in rare interactions. Code is available at https://github.com/francescotonini/dysco.",
      "authors": [
        "Francesco Tonini",
        "Lorenzo Vaquero",
        "Alessandro Conti",
        "Cigdem Beyan",
        "Elisa Ricci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:30:19+00:00",
          "link": "https://arxiv.org/abs/2507.17456v1",
          "size": "11925kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17456",
        "PDF": "https://arxiv.org/pdf/2507.17456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with Human-Object Interaction detection and proposes a training-free framework based on VLMs, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17458",
      "abstract": "In this paper we present \\textsc{DUDDSketch}, a distributed version of the \\textsc{UDDSketch} algorithm for accurate tracking of quantiles. The algorithm is a fully decentralized, gossip-based distributed protocol working in the context of unstructured P2P networks. We discuss the algorithm's design and formally prove its correctness. We also show, through extensive experimental results, that the algorithm converges to the results provided by the sequential algorithm, which is a fundamental and highly desirable property.",
      "authors": [
        "Marco Pulimeno",
        "Italo Epicoco and Massimo Cafaro"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:37:45+00:00",
          "link": "https://arxiv.org/abs/2507.17458v1",
          "size": "2954kb",
          "version": "v1"
        }
      ],
      "title": "Distributed P2P quantile tracking with relative value error",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17458",
        "HTML": "https://arxiv.org/html/2507.17458v1",
        "PDF": "https://arxiv.org/pdf/2507.17458"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a decentralized algorithm for quantile tracking in distributed networks, unrelated to any stage of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17462",
      "abstract": "Robot imitation learning relies on 4D multi-view sequential images. However, the high cost of data collection and the scarcity of high-quality data severely constrain the generalization and application of embodied intelligence policies like Vision-Language-Action (VLA) models. Data augmentation is a powerful strategy to overcome data scarcity, but methods for editing 4D multi-view sequential images for manipulation tasks are currently lacking. Thus, we propose ERMV (Editing Robotic Multi-View 4D data), a novel data augmentation framework that efficiently edits an entire multi-view sequence based on single-frame editing and robot state conditions. This task presents three core challenges: (1) maintaining geometric and appearance consistency across dynamic views and long time horizons; (2) expanding the working window with low computational costs; and (3) ensuring the semantic integrity of critical objects like the robot arm. ERMV addresses these challenges through a series of innovations. First, to ensure spatio-temporal consistency in motion blur, we introduce a novel Epipolar Motion-Aware Attention (EMA-Attn) mechanism that learns pixel shift caused by movement before applying geometric constraints. Second, to maximize the editing working window, ERMV pioneers a Sparse Spatio-Temporal (STT) module, which decouples the temporal and spatial views and remodels a single-frame multi-view problem through sparse sampling of the views to reduce computational demands. Third, to alleviate error accumulation, we incorporate a feedback intervention Mechanism, which uses a Multimodal Large Language Model (MLLM) to check editing inconsistencies and request targeted expert guidance only when necessary. Extensive experiments demonstrate that ERMV-augmented data significantly boosts the robustness and generalization of VLA models in both simulated and real-world environments.",
      "authors": [
        "Chang Nie",
        "Guangming Wang",
        "Zhe Lie",
        "Hesheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:41:11+00:00",
          "link": "https://arxiv.org/abs/2507.17462v1",
          "size": "5837kb",
          "version": "v1"
        }
      ],
      "title": "ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17462",
        "HTML": "https://arxiv.org/html/2507.17462v1",
        "PDF": "https://arxiv.org/pdf/2507.17462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on data augmentation for robotic imitation learning using 4D images, which is not related to LLM training data processing. It does not make a contribution to LLM pretraining or fine-tuning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17467",
      "abstract": "This study investigates the extent to which the Visual Entailment (VE) task serves as a reliable probe of vision-language understanding in multimodal language models, using the LLaMA 3.2 11B Vision model as a test case. Beyond reporting performance metrics, we aim to interpret what these results reveal about the underlying possibilities and limitations of the VE task. We conduct a series of experiments across zero-shot, few-shot, and fine-tuning settings, exploring how factors such as prompt design, the number and order of in-context examples and access to visual information might affect VE performance. To further probe the reasoning processes of the model, we used explanation-based evaluations. Results indicate that three-shot inference outperforms the zero-shot baselines. However, additional examples introduce more noise than they provide benefits. Additionally, the order of the labels in the prompt is a critical factor that influences the predictions. In the absence of visual information, the model has a strong tendency to hallucinate and imagine content, raising questions about the model's over-reliance on linguistic priors. Fine-tuning yields strong results, achieving an accuracy of 83.3% on the e-SNLI-VE dataset and outperforming the state-of-the-art OFA-X model. Additionally, the explanation evaluation demonstrates that the fine-tuned model provides semantically meaningful explanations similar to those of humans, with a BERTScore F1-score of 89.2%. We do, however, find comparable BERTScore results in experiments with limited vision, questioning the visual grounding of this task. Overall, our results highlight both the utility and limitations of VE as a diagnostic task for vision-language understanding and point to directions for refining multimodal evaluation methods.",
      "authors": [
        "Elena Pitta and Tom Kouwenhoven and Tessa Verhoef"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:46:51+00:00",
          "link": "https://arxiv.org/abs/2507.17467v1",
          "size": "827kb",
          "version": "v1"
        }
      ],
      "title": "Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17467",
        "HTML": "https://arxiv.org/html/2507.17467v1",
        "PDF": "https://arxiv.org/pdf/2507.17467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper examines fine-tuning in the context of a vision-language task but focuses on the evaluation and understanding of model performance rather than the creation or processing of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17472",
      "abstract": "Human decision-making in high-stakes domains often relies on expertise and heuristics, but is vulnerable to hard-to-detect cognitive biases that threaten fairness and long-term outcomes. This work presents a novel approach to enhancing complex decision-making workflows through the integration of hierarchical learning alongside various enhancements. Focusing on university admissions as a representative high-stakes domain, we propose BGM-HAN, an enhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network, designed to effectively model semi-structured applicant data. BGM-HAN captures multi-level representations that are crucial for nuanced assessment, improving both interpretability and predictive performance. Experimental results on real admissions data demonstrate that our proposed model significantly outperforms both state-of-the-art baselines from traditional machine learning to large language models, offering a promising framework for augmenting decision-making in domains where structure, context, and fairness matter. Source code is available at: https://github.com/junhua/bgm-han.",
      "authors": [
        "Junhua Liu",
        "Roy Ka-Wei Lee and Kwan Hui Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:52:38+00:00",
          "link": "https://arxiv.org/abs/2507.17472v1",
          "size": "521kb",
          "version": "v1"
        }
      ],
      "title": "BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17472",
        "HTML": "https://arxiv.org/html/2507.17472v1",
        "PDF": "https://arxiv.org/pdf/2507.17472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a hierarchical attention network for decision-making on semi-structured profiles, which is not associated with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17475",
      "abstract": "This paper presents a technique for designing output feedback controllers for constrained linear parameter-varying systems that are subject to persistent disturbances. Specifically, we develop an incremental parameter-varying output feedback control law to address control rate constraints, as well as state and control amplitude constraints. The proposal is based on the concept of robust positively invariant sets and applies the extended Farkas' lemma to derive a set of algebraic conditions that define both the control gains and a robust positively invariant polyhedron that satisfies the control and state constraints. These algebraic conditions are formulated into a bilinear optimization problem aimed at determining the output feedback gains and the associated polyedral robust positively invariant region. The obtained controller ensures that any closed-loop trajectory originating from the polyhedron converges to another smaller inner polyhedral set around the origin in finite time, where the trajectory remains ultimately bounded regardless of the persistent disturbances and variations in system parameters. Furthermore, by including the sizes of the two polyhedral sets inside the objective function, the proposed optimization can also jointly enlarge the outer set while minimizing the inner one. Numerical examples are presented to demonstrate the effectiveness of our proposal in managing the specified constraints, disturbances, and parameter variations.",
      "authors": [
        "Jackson G. Ernesto",
        "Eugenio B. Castelan",
        "Walter Lucia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:56:18+00:00",
          "link": "https://arxiv.org/abs/2507.17475v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "Output Feedback Design for Parameter Varying Systems subject to Persistent Disturbances and Control Rate Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17475",
        "HTML": "https://arxiv.org/html/2507.17475v1",
        "PDF": "https://arxiv.org/pdf/2507.17475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves control systems and feedback design for parameter-varying systems, a topic not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17476",
      "abstract": "Although recent Large Language Models (LLMs) have shown rapid improvement on reasoning benchmarks in English, the evaluation of such LLMs' multilingual reasoning capability across diverse languages and cultural contexts remains limited. Existing multilingual reasoning benchmarks are typically constructed by translating existing English reasoning benchmarks, biasing these benchmarks towards reasoning problems with context in English language/cultures. In this work, we introduce the Multilingual Native Reasoning Challenge (MultiNRC), a benchmark designed to assess LLMs on more than 1,000 native, linguistic and culturally grounded reasoning questions written by native speakers in French, Spanish, and Chinese. MultiNRC covers four core reasoning categories: language-specific linguistic reasoning, wordplay & riddles, cultural/tradition reasoning, and math reasoning with cultural relevance. For cultural/tradition reasoning and math reasoning with cultural relevance, we also provide English equivalent translations of the multilingual questions by manual translation from native speakers fluent in English. This set of English equivalents can provide a direct comparison of LLM reasoning capacity in other languages vs. English on the same reasoning questions. We systematically evaluate current 14 leading LLMs covering most LLM families on MultiNRC and its English equivalent set. The results show that (1) current LLMs are still not good at native multilingual reasoning, with none scoring above 50% on MultiNRC; (2) LLMs exhibit distinct strengths and weaknesses in handling linguistic, cultural, and logical reasoning tasks; (3) Most models perform substantially better in math reasoning in English compared to in original languages (+10%), indicating persistent challenges with culturally grounded knowledge.",
      "authors": [
        "Alexander R. Fabbri",
        "Diego Mares",
        "Jorge Flores",
        "Meher Mankikar",
        "Ernesto Hernandez",
        "Dean Lee",
        "Bing Liu",
        "Chen Xing"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:56:31+00:00",
          "link": "https://arxiv.org/abs/2507.17476v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "MultiNRC: A Challenging and Native Multilingual Reasoning Evaluation Benchmark for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17476",
        "HTML": "https://arxiv.org/html/2507.17476v1",
        "PDF": "https://arxiv.org/pdf/2507.17476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with evaluating multilingual reasoning capabilities of LLMs using the MultiNRC benchmark, which is focused on evaluation rather than training data processing. It does not discuss data processing for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17477",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in instruction following and general-purpose reasoning. However, achieving high-quality alignment with human intent and safety norms without human annotations remains a fundamental challenge. In this work, we propose an Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to improve LLM alignment in a fully automated manner. UDASA first generates multiple responses for each input and quantifies output uncertainty across three dimensions: semantics, factuality, and value alignment. Based on these uncertainty scores, the framework constructs preference pairs and categorizes training samples into three stages, conservative, moderate, and exploratory, according to their uncertainty difference. The model is then optimized progressively across these stages. In addition, we conduct a series of preliminary studies to validate the core design assumptions and provide strong empirical motivation for the proposed framework. Experimental results show that UDASA outperforms existing alignment methods across multiple tasks, including harmlessness, helpfulness, truthfulness, and controlled sentiment generation, significantly improving model performance.",
      "authors": [
        "Haoran Sun",
        "Zekun Zhang",
        "Shaoning Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:00:00+00:00",
          "link": "https://arxiv.org/abs/2507.17477v1",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "title": "An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17477",
        "HTML": "https://arxiv.org/html/2507.17477v1",
        "PDF": "https://arxiv.org/pdf/2507.17477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a framework for improving LLM alignment using an automated approach, focusing on response generation and uncertainty quantification. It does not primarily address training data processing, though it touches on alignment fine-tuning indirectly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17479",
      "abstract": "Upsampling LiDAR point clouds in autonomous driving scenarios remains a significant challenge due to the inherent sparsity and complex 3D structures of the data. Recent studies have attempted to address this problem by converting the complex 3D spatial scenes into 2D image super-resolution tasks. However, due to the sparse and blurry feature representation of range images, accurately reconstructing detailed and complex spatial topologies remains a major difficulty. To tackle this, we propose a novel sparse point cloud upsampling method named SRMambaV2, which enhances the upsampling accuracy in long-range sparse regions while preserving the overall geometric reconstruction quality. Specifically, inspired by human driver visual perception, we design a biomimetic 2D selective scanning self-attention (2DSSA) mechanism to model the feature distribution in distant sparse areas. Meanwhile, we introduce a dual-branch network architecture to enhance the representation of sparse features. In addition, we introduce a progressive adaptive loss (PAL) function to further refine the reconstruction of fine-grained details during the upsampling process. Experimental results demonstrate that SRMambaV2 achieves superior performance in both qualitative and quantitative evaluations, highlighting its effectiveness and practical value in automotive sparse point cloud upsampling tasks.",
      "authors": [
        "Chuang Chen and Xiaolin Qin and Jing Hu and Wenyi Ge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:01:19+00:00",
          "link": "https://arxiv.org/abs/2507.17479v1",
          "size": "40117kb",
          "version": "v1"
        }
      ],
      "title": "SRMambaV2: Biomimetic Attention for Sparse Point Cloud Upsampling in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17479",
        "HTML": "https://arxiv.org/html/2507.17479v1",
        "PDF": "https://arxiv.org/pdf/2507.17479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on techniques for upsampling sparse point clouds in autonomous driving, not related to LLM training data processing. Its focus is outside the domain of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17481",
      "abstract": "Artificial intelligence has deeply permeated numerous fields, especially the design area which relies on technology as a tool for innovation. This change naturally extends to the field of design education, which is closest to design practice. This has led to further exploration of the impact of AI on college-level education in the design discipline. This study aims to examine how current design educators perceive the role of AI in college-level design education, their perspectives on integrating AI into teaching and research, and their concerns regarding its potential challenges in design education and research. Through qualitative, semi-structured, in-depth interviews with seven faculties in U.S. design colleges, the findings reveal that AI, as a tool and source of information, has become an integral part of design education. AI- derived functionalities are increasingly utilized in design software, and educators are actively incorporating AI as a theoretical framework in their teaching. Educators can guide students in using AI tools, but only if they first acquire a strong foundation in basic design principles and skills. This study also indicates the importance of promoting a cooperative relationship between design educators and AI. At the same time, educators express anticipation for advancements in ethical standards, authenticity, and the resolution of copyright issues related to AI.",
      "authors": [
        "Lizhu Zhang and Cecilia X. Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:02:37+00:00",
          "link": "https://arxiv.org/abs/2507.17481v1",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "title": "AI in Design Education at College Level-Educators' Perspectives and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17481",
        "PDF": "https://arxiv.org/pdf/2507.17481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the impact of AI on design education, focusing on educators' perspectives and challenges. It does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17482",
      "abstract": "Neuro-symbolic artificial intelligence aims to combine neural architectures with symbolic approaches that can represent knowledge in a human-interpretable formalism. Continual learning concerns with agents that expand their knowledge over time, improving their skills while avoiding to forget previously learned concepts. Most of the existing approaches for neuro-symbolic artificial intelligence are applied to static scenarios only, and the challenging setting where reasoning along the temporal dimension is necessary has been seldom explored. In this work we introduce LTLZinc, a benchmarking framework that can be used to generate datasets covering a variety of different problems, against which neuro-symbolic and continual learning methods can be evaluated along the temporal and constraint-driven dimensions. Our framework generates expressive temporal reasoning and continual learning tasks from a linear temporal logic specification over MiniZinc constraints, and arbitrary image classification datasets. Fine-grained annotations allow multiple neural and neuro-symbolic training settings on the same generated datasets. Experiments on six neuro-symbolic sequence classification and four class-continual learning tasks generated by LTLZinc, demonstrate the challenging nature of temporal learning and reasoning, and highlight limitations of current state-of-the-art methods. We release the LTLZinc generator and ten ready-to-use tasks to the neuro-symbolic and continual learning communities, in the hope of fostering research towards unified temporal learning and reasoning frameworks.",
      "authors": [
        "Luca Salvatore Lorello",
        "Nikolaos Manginas",
        "Marco Lippi",
        "Stefano Melacci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:04:13+00:00",
          "link": "https://arxiv.org/abs/2507.17482v1",
          "size": "787kb",
          "version": "v1"
        }
      ],
      "title": "LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17482",
        "PDF": "https://arxiv.org/pdf/2507.17482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces LTLZinc, a framework for generating datasets for continual learning and neuro-symbolic reasoning. While it involves dataset creation, it is not directly aimed at LLM training data processing but rather at neuro-symbolic and temporal reasoning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17486",
      "abstract": "Unsupervised anomaly detection (UAD) plays a crucial role in neuroimaging for identifying deviations from healthy subject data and thus facilitating the diagnosis of neurological disorders. In this work, we focus on Bayesian flow networks (BFNs), a novel class of generative models, which have not yet been applied to medical imaging or anomaly detection. BFNs combine the strength of diffusion frameworks and Bayesian inference. We introduce AnoBFN, an extension of BFNs for UAD, designed to: i) perform conditional image generation under high levels of spatially correlated noise, and ii) preserve subject specificity by incorporating a recursive feedback from the input image throughout the generative process. We evaluate AnoBFN on the challenging task of Alzheimer's disease-related anomaly detection in FDG PET images. Our approach outperforms other state-of-the-art methods based on VAEs (beta-VAE), GANs (f-AnoGAN), and diffusion models (AnoDDPM), demonstrating its effectiveness at detecting anomalies while reducing false positive rates.",
      "authors": [
        "Hugues Roy",
        "Reuben Dorent",
        "Ninon Burgos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:09:57+00:00",
          "link": "https://arxiv.org/abs/2507.17486v1",
          "size": "396kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised anomaly detection using Bayesian flow networks: application to brain FDG PET in the context of Alzheimer's disease",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17486",
        "HTML": "https://arxiv.org/html/2507.17486v1",
        "PDF": "https://arxiv.org/pdf/2507.17486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on unsupervised anomaly detection in neuroimaging data using Bayesian flow networks, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17487",
      "abstract": "We investigate Controlled Query Evaluation (CQE) over ontologies, where information disclosure is regulated by epistemic dependencies (EDs), a family of logical rules recently proposed for the CQE framework. In particular, we combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground atoms that are entailed by the ontology and can be safely revealed. We focus on answering Boolean unions of conjunctive queries (BUCQs) with respect to the intersection of all optimal GA censors - an approach that has been shown in other contexts to ensure strong security guarantees with favorable computational behavior. First, we characterize the security of this intersection-based approach and identify a class of EDs (namely, full EDs) for which it remains safe. Then, for a subclass of EDs and for DL-Lite_R ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0 in data complexity by presenting a suitable, detailed first-order rewriting algorithm. Finally, we report on experiments conducted in two different evaluation scenarios, showing the practical feasibility of our rewriting function.",
      "authors": [
        "Lorenzo Marconi",
        "Flavia Ricci",
        "Riccardo Rosati"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:10:33+00:00",
          "link": "https://arxiv.org/abs/2507.17487v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17487",
        "HTML": "https://arxiv.org/html/2507.17487v1",
        "PDF": "https://arxiv.org/pdf/2507.17487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with controlled query evaluation over ontologies with epistemic dependencies, focusing on logical rules and security, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17489",
      "abstract": "Strong light sources in nighttime photography frequently produce flares in images, significantly degrading visual quality and impacting the performance of downstream tasks. While some progress has been made, existing methods continue to struggle with removing large-scale flare artifacts and repairing structural damage in regions near the light source. We observe that these challenging flare artifacts exhibit more significant discrepancies from the reference images in the frequency domain compared to the spatial domain. Therefore, this paper presents a novel dynamic frequency-guided deflare network (DFDNet) that decouples content information from flare artifacts in the frequency domain, effectively removing large-scale flare artifacts. Specifically, DFDNet consists mainly of a global dynamic frequency-domain guidance (GDFG) module and a local detail guidance module (LDGM). The GDFG module guides the network to perceive the frequency characteristics of flare artifacts by dynamically optimizing global frequency domain features, effectively separating flare information from content information. Additionally, we design an LDGM via a contrastive learning strategy that aligns the local features of the light source with the reference image, reduces local detail damage from flare removal, and improves fine-grained image restoration. The experimental results demonstrate that the proposed method outperforms existing state-of-the-art methods in terms of performance. The code is available at \\href{https://github.com/AXNing/DFDNet}{https://github.com/AXNing/DFDNet}.",
      "authors": [
        "Minglong Xue",
        "Aoxiang Ning",
        "Shivakumara Palaiahnakote",
        "Mingliang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:14:59+00:00",
          "link": "https://arxiv.org/abs/2507.17489v1",
          "size": "4898kb",
          "version": "v1"
        }
      ],
      "title": "DFDNet: Dynamic Frequency-Guided De-Flare Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17489",
        "HTML": "https://arxiv.org/html/2507.17489v1",
        "PDF": "https://arxiv.org/pdf/2507.17489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for removing flare artifacts in images using a dynamic frequency-guided de-flare network, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17491",
      "abstract": "As 5G networks expand into critical infrastructure, secure and efficient user authentication is more important than ever. The 5G-AKA protocol, standardized by 3GPP in TS 33.501, is central to authentication in current 5G deployments. It provides mutual authentication, user privacy, and key secrecy. However, despite its adoption, 5G-AKA has known limitations in both security and performance. While it focuses on protecting privacy against passive attackers, recent studies show its vulnerabilities to active attacks. It also relies on a sequence number mechanism to prevent replay attacks, requiring perfect synchronization between the device and the core network. This stateful design adds complexity, causes desynchronization, and incurs extra communication overhead. More critically, 5G-AKA lacks Perfect Forward Secrecy (PFS), exposing past communications if long-term keys are compromised-an increasing concern amid sophisticated threats. This paper proposes an enhanced authentication protocol that builds on 5G-AKA's design while addressing its shortcomings. First, we introduce a stateless version that removes sequence number reliance, reducing complexity while staying compatible with existing SIM cards and infrastructure. We then extend this design to add PFS with minimal cryptographic overhead. Both protocols are rigorously analyzed using ProVerif, confirming their compliance with all major security requirements, including resistance to passive and active attacks, as well as those defined by 3GPP and academic studies. We also prototype both protocols and evaluate their performance against 5G-AKA and 5G-AKA' (USENIX'21). Our results show the proposed protocols offer stronger security with only minor computational overhead, making them practical, future-ready solutions for 5G and beyond.",
      "authors": [
        "Nazatul H. Sultan",
        "Xinlong Guan",
        "Josef Pieprzyk",
        "Wei Ni",
        "Sharif Abuadbba",
        "and Hajime Suzuki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:18:44+00:00",
          "link": "https://arxiv.org/abs/2507.17491v1",
          "size": "435kb",
          "version": "v1"
        }
      ],
      "title": "Active Attack Resilience in 5G: A New Take on Authentication and Key Agreement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17491",
        "HTML": "https://arxiv.org/html/2507.17491v1",
        "PDF": "https://arxiv.org/pdf/2507.17491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes enhancements to the 5G authentication protocol, focusing on security and efficiency in network communications, without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17493",
      "abstract": "The grounding bottleneck poses one of the key challenges that hinders the widespread adoption of Answer Set Programming in industry. Hybrid Grounding is a step in alleviating the bottleneck by combining the strength of standard bottom-up grounding with recently proposed techniques where rule bodies are decoupled during grounding. However, it has remained unclear when hybrid grounding shall use body-decoupled grounding and when to use standard bottom-up grounding. In this paper, we address this issue by developing automated hybrid grounding: we introduce a splitting algorithm based on data-structural heuristics that detects when to use body-decoupled grounding and when standard grounding is beneficial. We base our heuristics on the structure of rules and an estimation procedure that incorporates the data of the instance. The experiments conducted on our prototypical implementation demonstrate promising results, which show an improvement on hard-to-ground scenarios, whereas on hard-to-solve instances we approach state-of-the-art performance.",
      "authors": [
        "Alexander Beiser",
        "Markus Hecher",
        "Stefan Woltran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:19:02+00:00",
          "link": "https://arxiv.org/abs/2507.17493v1",
          "size": "565kb",
          "version": "v1"
        }
      ],
      "title": "Automated Hybrid Grounding Using Structural and Data-Driven Heuristics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17493",
        "HTML": "https://arxiv.org/html/2507.17493v1",
        "PDF": "https://arxiv.org/pdf/2507.17493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses grounding challenges in Answer Set Programming through hybrid grounding strategies, unrelated to LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17501",
      "abstract": "Transformers have become the de facto backbone of modern deep learning, yet their training typically demands an advanced optimizer with adaptive learning rate like AdamW, rather than a momentum SGDW (mSGDW). Previous works show that it is mainly due to a heavy-tailed distribution of the gradients. In this paper, we introduce a Deeply Normalized Transformer (DNT), which is meticulously engineered to overcome this limitation enabling seamless training with vanilla mSGDW while yielding comparable performance to the Transformers trained via AdamW. To be specific, in DNT, we strategically integrate normalization techniques at proper positions in the Transformers to effectively modulate the Jacobian matrices of each layer, balance the influence of weights, activations, and their interactions, and thus enable the distributions of gradients concentrated. We provide both theoretical justifications of the normalization technique used in our DNT and extensive empirical evaluation on two popular Transformer architectures to validate that: a) DNT outperforms its counterparts (\\ie, ViT and GPT), and b) DNT can be effectively trained with vanilla mSGDW.",
      "authors": [
        "Xianbiao Qi",
        "Marco Chen",
        "Wenjie Xiao",
        "Jiaquan Ye",
        "Yelin He",
        "Chun-Guang Li",
        "Zhouchen Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:37:23+00:00",
          "link": "https://arxiv.org/abs/2507.17501v1",
          "size": "548kb",
          "version": "v1"
        }
      ],
      "title": "DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17501",
        "HTML": "https://arxiv.org/html/2507.17501v1",
        "PDF": "https://arxiv.org/pdf/2507.17501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a Deeply Normalized Transformer to enable training with Momentum SGD, focusing on model architecture and training optimization, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17507",
      "abstract": "Data quality describes the degree to which data meet specific requirements and are fit for use by humans and/or downstream tasks (e.g., artificial intelligence). Data quality can be assessed across multiple high-level concepts called dimensions, such as accuracy, completeness, consistency, or timeliness. While extensive research and several attempts for standardization (e.g., ISO/IEC 25012) exist for data quality dimensions, their practical application often remains unclear. In parallel to research endeavors, a large number of tools have been developed that implement functionalities for the detection and mitigation of specific data quality issues, such as missing values or outliers. With this paper, we aim to bridge this gap between data quality theory and practice by systematically connecting low-level functionalities offered by data quality tools with high-level dimensions, revealing their many-to-many relationships. Through an examination of seven open-source data quality tools, we provide a comprehensive mapping between their functionalities and the data quality dimensions, demonstrating how individual functionalities and their variants partially contribute to the assessment of single dimensions. This systematic survey provides both practitioners and researchers with a unified view on the fragmented landscape of data quality checks, offering actionable insights for quality assessment across multiple dimensions.",
      "authors": [
        "Vasileios Papastergios",
        "Lisa Ehrlinger",
        "Anastasios Gounaris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:46:03+00:00",
          "link": "https://arxiv.org/abs/2507.17507v1",
          "size": "134kb",
          "version": "v1"
        }
      ],
      "title": "Unfolding Data Quality Dimensions in Practice: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17507",
        "HTML": "https://arxiv.org/html/2507.17507v1",
        "PDF": "https://arxiv.org/pdf/2507.17507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys data quality dimensions in general data processing contexts but does not specifically address LLM training data, nor does it propose specific methods or frameworks applicable to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17508",
      "abstract": "Automated X-ray inspection is crucial for efficient and unobtrusive security screening in various public settings. However, challenges such as object occlusion, variations in the physical properties of items, diversity in X-ray scanning devices, and limited training data hinder accurate and reliable detection of illicit items. Despite the large body of research in the field, reported experimental evaluations are often incomplete, with frequently conflicting outcomes. To shed light on the research landscape and facilitate further research, a systematic, detailed, and thorough comparative evaluation of recent Deep Learning (DL)-based methods for X-ray object detection is conducted. For this, a comprehensive evaluation framework is developed, composed of: a) Six recent, large-scale, and widely used public datasets for X-ray illicit item detection (OPIXray, CLCXray, SIXray, EDS, HiXray, and PIDray), b) Ten different state-of-the-art object detection schemes covering all main categories in the literature, including generic Convolutional Neural Network (CNN), custom CNN, generic transformer, and hybrid CNN-transformer architectures, and c) Various detection (mAP50 and mAP50:95) and time/computational-complexity (inference time (ms), parameter size (M), and computational load (GFLOPS)) metrics. A thorough analysis of the results leads to critical observations and insights, emphasizing key aspects such as: a) Overall behavior of the object detection schemes, b) Object-level detection performance, c) Dataset-specific observations, and d) Time efficiency and computational complexity analysis. To support reproducibility of the reported experimental results, the evaluation code and model weights are made publicly available at https://github.com/jgenc/xray-comparative-evaluation.",
      "authors": [
        "Jorgen Cani",
        "Christos Diou",
        "Spyridon Evangelatos",
        "Vasileios Argyriou",
        "Panagiotis Radoglou-Grammatikis",
        "Panagiotis Sarigiannidis",
        "Iraklis Varlamis and Georgios Th. Papadopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:47:33+00:00",
          "link": "https://arxiv.org/abs/2507.17508v1",
          "size": "936kb",
          "version": "v1"
        }
      ],
      "title": "Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17508",
        "HTML": "https://arxiv.org/html/2507.17508v1",
        "PDF": "https://arxiv.org/pdf/2507.17508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on illicit object detection in X-ray imaging using deep learning techniques. It does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17511",
      "abstract": "Diffusion models produce realistic images and videos but require substantial computational resources, necessitating multi-accelerator parallelism for real-time deployment. However, parallel inference introduces significant communication overhead from exchanging large activations between devices, limiting efficiency and scalability. We present CompactFusion, a compression framework that significantly reduces communication while preserving generation quality. Our key observation is that diffusion activations exhibit strong temporal redundancy-adjacent steps produce highly similar activations, saturating bandwidth with near-duplicate data carrying little new information. To address this inefficiency, we seek a more compact representation that encodes only the essential information. CompactFusion achieves this via Residual Compression that transmits only compressed residuals (step-wise activation differences). Based on empirical analysis and theoretical justification, we show that it effectively removes redundant data, enabling substantial data reduction while maintaining high fidelity. We also integrate lightweight error feedback to prevent error accumulation. CompactFusion establishes a new paradigm for parallel diffusion inference, delivering lower latency and significantly higher generation quality than prior methods. On 4xL20, it achieves 3.0x speedup while greatly improving fidelity. It also uniquely supports communication-heavy strategies like sequence parallelism on slow networks, achieving 6.7x speedup over prior overlap-based method. CompactFusion applies broadly across diffusion models and parallel settings, and integrates easily without requiring pipeline rework. Portable implementation demonstrated on xDiT is publicly available at https://github.com/Cobalt-27/CompactFusion",
      "authors": [
        "Jiajun Luo",
        "Yicheng Xiao",
        "Jianru Xu",
        "Yangxiu You",
        "Rongwei Lu",
        "Chen Tang",
        "Jingyan Jiang",
        "Zhi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:49:25+00:00",
          "link": "https://arxiv.org/abs/2507.17511v1",
          "size": "25876kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating Parallel Diffusion Model Serving with Residual Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17511",
        "HTML": "https://arxiv.org/html/2507.17511v1",
        "PDF": "https://arxiv.org/pdf/2507.17511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a compression framework for parallel diffusion model serving, focusing on computational efficiency, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17512",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing research has predominantly concentrated on isolated reasoning domains such as mathematical problem-solving, coding tasks, or logical reasoning. However, real world reasoning scenarios inherently demand an integrated application of multiple cognitive skills. Despite this, the interplay among these reasoning skills under reinforcement learning remains poorly understood. To bridge this gap, we present a systematic investigation of multi-domain reasoning within the RLVR framework, explicitly focusing on three primary domains: mathematical reasoning, code generation, and logical puzzle solving. We conduct a comprehensive study comprising four key components: (1) Leveraging the GRPO algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the models' in-domain improvements and cross-domain generalization capabilities when trained on single-domain datasets. (2) Additionally, we examine the intricate interactions including mutual enhancements and conflicts that emerge during combined cross-domain training. (3) To further understand the influence of SFT on RL, we also analyze and compare performance differences between base and instruct models under identical RL configurations. (4) Furthermore, we delve into critical RL training details, systematically exploring the impacts of curriculum learning strategies, variations in reward design, and language-specific factors. Through extensive experiments, our results offer significant insights into the dynamics governing domain interactions, revealing key factors influencing both specialized and generalizable reasoning performance. These findings provide valuable guidance for optimizing RL methodologies to foster comprehensive, multi-domain reasoning capabilities in LLMs.",
      "authors": [
        "Yu Li",
        "Zhuoshi Pan",
        "Honglin Lin",
        "Mengyuan Sun",
        "Conghui He",
        "Lijun Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:51:04+00:00",
          "link": "https://arxiv.org/abs/2507.17512v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17512",
        "HTML": "https://arxiv.org/html/2507.17512v1",
        "PDF": "https://arxiv.org/pdf/2507.17512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates multi-domain reasoning capabilities in LLMs with reinforcement learning, which may involve some aspect of data processing for training but primarily focuses on model evaluation and interaction rather than dedicated LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17513",
      "abstract": "Optimal transport (OT) has become a natural framework for guiding the probability flows. Yet, the majority of recent generative models assume trivial geometry (e.g., Euclidean) and rely on strong density-estimation assumptions, yielding trajectories that do not respect the true principles of optimality in the underlying manifold. We present Hamiltonian Optimal Transport Advection (HOTA), a Hamilton-Jacobi-Bellman based method that tackles the dual dynamical OT problem explicitly through Kantorovich potentials, enabling efficient and scalable trajectory optimization. Our approach effectively evades the need for explicit density modeling, performing even when the cost functionals are non-smooth. Empirically, HOTA outperforms all baselines in standard benchmarks, as well as in custom datasets with non-differentiable costs, both in terms of feasibility and optimality.",
      "authors": [
        "Nazar Buzun",
        "Daniil Shlenskii",
        "Maxim Bobrin",
        "Dmitry V. Dylov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.17513v1",
          "size": "4701kb",
          "version": "v1"
        }
      ],
      "title": "HOTA: Hamiltonian framework for Optimal Transport Advection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17513",
        "HTML": "https://arxiv.org/html/2507.17513v1",
        "PDF": "https://arxiv.org/pdf/2507.17513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimal transport advection using a Hamiltonian framework. It does not relate to any aspect of LLM training data processing, such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17514",
      "abstract": "This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool with minimalistic input. The current version of the tool supports the legal TAI assessment, with a particular emphasis on facilitating compliance with the AI Act. It involves a two-step approach with a pre-screening and an assessment phase. The assessment output of the system includes insight regarding the risk-level of the AI system according to the AI Act, while at the same time retrieving relevant articles to aid with compliance and notify on their obligations. Our qualitative evaluation using use-case scenarios yields promising results, correctly predicting risk levels while retrieving relevant articles across three distinct semantic groups. Furthermore, interpretation of results shows that the tool's reasoning relies on comparison with the setting of high-risk systems, a behaviour attributed to their deployment requiring careful consideration, and therefore frequently presented within the AI Act.",
      "authors": [
        "Athanasios Davvetas",
        "Xenia Ziouvelou",
        "Ypatia Dami",
        "Alexis Kaponis",
        "Konstantina Giouvanopoulou",
        "Michael Papademas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:51:23+00:00",
          "link": "https://arxiv.org/abs/2507.17514v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17514",
        "HTML": "https://arxiv.org/html/2507.17514v1",
        "PDF": "https://arxiv.org/pdf/2507.17514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a self-assessment tool for AI compliance with legal standards, focusing on trustworthy AI assessment, which does not relate to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17515",
      "abstract": "Large-scale alignment pipelines typically pair a policy model with a separately trained reward model whose parameters remain frozen during reinforcement learning (RL). This separation creates a complex, resource-intensive pipeline and suffers from a performance ceiling due to a static reward signal. We propose a novel framework, Unified Reward & Policy Optimization (URPO), that unifies instruction-following (\"player\") and reward modeling (\"referee\") within a single model and a single training phase. Our method recasts all alignment data-including preference pairs, verifiable reasoning, and open-ended instructions-into a unified generative format optimized by a single Group-Relative Policy Optimization (GRPO) loop. This enables the model to learn from ground-truth preferences and verifiable logic while simultaneously generating its own rewards for open-ended tasks. Experiments on the Qwen2.5-7B model demonstrate URPO's superiority. Our unified model significantly outperforms a strong baseline using a separate generative reward model, boosting the instruction-following score on AlpacaEval from 42.24 to 44.84 and the composite reasoning average from 32.66 to 35.66. Furthermore, URPO cultivates a superior internal evaluator as a byproduct of training, achieving a RewardBench score of 85.15 and surpassing the dedicated reward model it replaces (83.55). By eliminating the need for a separate reward model and fostering a co-evolutionary dynamic between generation and evaluation, URPO presents a simpler, more efficient, and more effective path towards robustly aligned language models.",
      "authors": [
        "Songshuo Lu",
        "Hua Wang",
        "Zhi Chen",
        "Yaohua Tang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:52:27+00:00",
          "link": "https://arxiv.org/abs/2507.17515v1",
          "size": "603kb",
          "version": "v1"
        }
      ],
      "title": "URPO: A Unified Reward & Policy Optimization Framework for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17515",
        "PDF": "https://arxiv.org/pdf/2507.17515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mainly focuses on unifying reward and policy optimization in LLMs, it involves aligning instruction-following and reward modeling, which touches on aspects of data processing for SFT, but the core contribution is model-related rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17516",
      "abstract": "Large-scale data collection, from national censuses to IoT-enabled smart homes, routinely gathers dozens of attributes per individual. These multi-attribute datasets are vital for analytics but pose significant privacy risks. Local Differential Privacy (LDP) is a powerful tool to protect user data privacy by allowing users to locally perturb their records before releasing to an untrusted data aggregator. However, existing LDP mechanisms either split the privacy budget across all attributes or treat each attribute independently, ignoring natural inter-attribute correlations. This leads to excessive noise or fragmented budgets, resulting in significant utility loss, particularly in high-dimensional settings.\n  To overcome these limitations, we propose Correlated Randomized Response (Corr-RR), a novel LDP mechanism that leverages correlations among attributes to substantially improve utility while maintaining rigorous LDP guarantees. Corr-RR allocates the full privacy budget to perturb a single, randomly selected attribute and reconstructs the remaining attributes using estimated interattribute dependencies, without incurring additional privacy cost. To enable this, Corr-RR operates in two phases: (1) a subset of users apply standard LDP mechanisms to estimate correlations, and (2) each remaining user perturbs one attribute and infers the others using the learned correlations. We theoretically prove that Corr-RR satisfies $\\epsilon$-LDP, and extensive experiments on synthetic and real-world datasets demonstrate that Corr-RR consistently outperforms state-of-the-art LDP mechanisms, particularly in scenarios with many attributes and strong inter-attribute correlations.",
      "authors": [
        "Shafizur Rahman Seeam",
        "Ye Zheng and Yidan Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:52:45+00:00",
          "link": "https://arxiv.org/abs/2507.17516v1",
          "size": "1319kb",
          "version": "v1"
        }
      ],
      "title": "Frequency Estimation of Correlated Multi-attribute Data under Local Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17516",
        "HTML": "https://arxiv.org/html/2507.17516v1",
        "PDF": "https://arxiv.org/pdf/2507.17516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study deals with frequency estimation under local differential privacy for multi-attribute datasets, focusing on data privacy rather than processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17518",
      "abstract": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability to replicate complex IT (Information Technology), OT (Operational Technology), and IoT (Internet of Things) infrastructures, allowing for real time monitoring, threat analysis, and system simulation. This study investigates how integrating DTs with penetration testing tools and Large Language Models (LLMs) can enhance cybersecurity education and operational readiness. By simulating realistic cyber environments, this approach offers a practical, interactive framework for exploring vulnerabilities and defensive strategies. At the core of this research is the Red Team Knife (RTK), a custom penetration testing toolkit aligned with the Cyber Kill Chain model. RTK is designed to guide learners through key phases of cyberattacks, including reconnaissance, exploitation, and response within a DT powered ecosystem. The incorporation of Large Language Models (LLMs) further enriches the experience by providing intelligent, real-time feedback, natural language threat explanations, and adaptive learning support during training exercises. This combined DT LLM framework is currently being piloted in academic settings to develop hands on skills in vulnerability assessment, threat detection, and security operations. Initial findings suggest that the integration significantly improves the effectiveness and relevance of cybersecurity training, bridging the gap between theoretical knowledge and real-world application. Ultimately, the research demonstrates how DTs and LLMs together can transform cybersecurity education to meet evolving industry demands.",
      "authors": [
        "Vita Santa Barletta",
        "Vito Bavaro",
        "Miriana Calvano",
        "Antonio Curci",
        "Antonio Piccinno",
        "Davide Pio Posa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:55:35+00:00",
          "link": "https://arxiv.org/abs/2507.17518v1",
          "size": "1300kb",
          "version": "v1"
        }
      ],
      "title": "Enabling Cyber Security Education through Digital Twins and Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17518",
        "HTML": "https://arxiv.org/html/2507.17518v1",
        "PDF": "https://arxiv.org/pdf/2507.17518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of digital twins and LLMs for cybersecurity education rather than addressing any LLM training data processing operations like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17519",
      "abstract": "Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial software typically treat a Region of Interest (RoI) only as a 2D plane, ignoring important3D structure characteristics. This leads to incomplete 3Dreconstructions, especially around occluded or vertical surfaces. In this paper, we propose a modular algorithm that can extend commercial two-dimensional path planners to facilitate terrain-aware planning by adjusting altitude and camera orientations. To demonstrate it, we extend the well-known DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm and produce DARP-3D. We present simulation results in multiple 3D environments and a real-world flight test using DJI hardware. Compared to baseline, our approach consistently captures improved 3D reconstructions, particularly in areas with significant vertical features. An open-source implementation of the algorithm is available here:https://github.com/konskara/TerraPlan",
      "authors": [
        "Kostas Karakontis (1)",
        "Thanos Petsanis (1 and 2)",
        "Athanasios Ch. Kapoutsis (2)",
        "Pavlos Ch. Kapoutsis (2)",
        "Elias B. Kosmatopoulos (1 and 2) ((1) Department of Electrical and Computer Engineering",
        "Democritus University of Thrace",
        "Xanthi",
        "Greece",
        "(2) Information Technologies Institute",
        "The Centre for Research and Technology",
        "Thessaloniki",
        "Greece)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.17519v1",
          "size": "3134kb",
          "version": "v1"
        }
      ],
      "title": "Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17519",
        "HTML": "https://arxiv.org/html/2507.17519v1",
        "PDF": "https://arxiv.org/pdf/2507.17519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-UAV coverage path planning and enhancing 3D reconstructions. It does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17520",
      "abstract": "To operate effectively in the real world, robots must integrate multimodal reasoning with precise action generation. However, existing vision-language-action (VLA) models often sacrifice one for the other, narrow their abilities to task-specific manipulation data, and suffer catastrophic forgetting of pre-trained vision-language capabilities. To bridge this gap, we introduce InstructVLA, an end-to-end VLA model that preserves the flexible reasoning of large vision-language models (VLMs) while delivering leading manipulation performance. InstructVLA introduces a novel training paradigm, Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal training with mixture-of-experts adaptation to jointly optimize textual reasoning and action generation on both standard VLM corpora and a curated 650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves 30.5% improvement over SpatialVLA. To evaluate generalization, we introduce SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and high-level instruction understanding, where it outperforms a fine-tuned OpenVLA by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling by leveraging textual reasoning to boost manipulation performance in both simulated and real-world settings. These results demonstrate InstructVLA's potential for bridging intuitive and steerable human-robot interaction with efficient policy learning.",
      "authors": [
        "Shuai Yang",
        "Hao Li",
        "Yilun Chen",
        "Bin Wang",
        "Yang Tian",
        "Tai Wang",
        "Hanqing Wang",
        "Feng Zhao",
        "Yiyi Liao",
        "Jiangmiao Pang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:57:06+00:00",
          "link": "https://arxiv.org/abs/2507.17520v1",
          "size": "15045kb",
          "version": "v1"
        }
      ],
      "title": "InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17520",
        "HTML": "https://arxiv.org/html/2507.17520v1",
        "PDF": "https://arxiv.org/pdf/2507.17520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a curated 650K-sample VLA-IT dataset for training the InstructVLA model, which touches on training data processing. However, the main focus is on vision-language-action models rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17522",
      "abstract": "Very few studies have addressed quality enhancement for compressed dynamic point clouds. In particular, the effective exploitation of spatial-temporal correlations between point cloud frames remains largely unexplored. Addressing this gap, we propose a spatial-temporal attribute quality enhancement (STQE) network that exploits both spatial and temporal correlations to improve the visual quality of G-PCC compressed dynamic point clouds. Our contributions include a recoloring-based motion compensation module that remaps reference attribute information to the current frame geometry to achieve precise inter-frame geometric alignment, a channel-aware temporal attention module that dynamically highlights relevant regions across bidirectional reference frames, a Gaussian-guided neighborhood feature aggregation module that efficiently captures spatial dependencies between geometry and color attributes, and a joint loss function based on the Pearson correlation coefficient, designed to alleviate over-smoothing effects typical of point-wise mean squared error optimization. When applied to the latest G-PCC test model, STQE achieved improvements of 0.855 dB, 0.682 dB, and 0.828 dB in delta PSNR, with Bj{\\o}ntegaard Delta rate (BD-rate) reductions of -25.2%, -31.6%, and -32.5% for the Luma, Cb, and Cr components, respectively.",
      "authors": [
        "Tian Guo",
        "Hui Yuan",
        "Xiaolong Mao",
        "Shiqi Jiang",
        "Raouf Hamzaoui",
        "and Sam Kwong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:03:54+00:00",
          "link": "https://arxiv.org/abs/2507.17522v1",
          "size": "14504kb",
          "version": "v1"
        }
      ],
      "title": "STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17522",
        "HTML": "https://arxiv.org/html/2507.17522v1",
        "PDF": "https://arxiv.org/pdf/2507.17522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on quality enhancement for compressed dynamic point clouds, specifically improving visual quality through spatial-temporal correlations, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17524",
      "abstract": "Electroencephalography(EEG) based emotion recognition holds great promise for affective brain-computer interfaces (aBCIs), yet practical deployment remains challenging due to substantial inter-subject variability and the lack of labeled data in target domains. To overcome these limitations, we present a novel unsupervised Semantic-Dynamic Consistency domain adaptation network for fully label-free cross-subject EEG emotion recognition. First, we introduce a Same-Subject Same-Trial Mixup strategy that generates augmented samples via intra-trial interpolation, enhancing data diversity while explicitly preserving individual identity to mitigate label ambiguity. Second, we construct a dynamic distribution alignment module in reproducing kernel Hilbert space (RKHS), jointly aligning marginal and conditional distributions through multi-objective kernel mean embedding, and leveraging a confidence-aware pseudo-labeling strategy to ensure stable adaptation. Third, we propose a dual-domain similarity consistency learning mechanism that enforces cross-domain structural constraints based on latent pairwise similarities, enabling semantic boundary learning without relying on temporal synchronization or label priors. To validate the effectiveness and robustness of the proposed SDC-Net, extensive experiments are conducted on three widely used EEG benchmark datasets: SEED, SEED-IV, and Faced. Comparative results against existing unsupervised domain adaptation methods demonstrate that SDC-Net achieves state-of-the-art performance in emotion recognition under both cross-subject and cross-session conditions. This advancement significantly improves the accuracy and generalization capability of emotion decoding, and lays a solid foundation for real-world applications of personalized affective brain-computer interfaces (aBCIs). The source code will be released at https://github.com/XuanSuTrum/SDC-Net.",
      "authors": [
        "Jiahao Tang and Youjun Li and Xiangting Fan and Yangxuan Zheng and Siyuan Lu and Xueping Li and Peng Fang and Chenxi Li and Zi-Gang Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:04:43+00:00",
          "link": "https://arxiv.org/abs/2507.17524v1",
          "size": "9653kb",
          "version": "v1"
        }
      ],
      "title": "SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17524",
        "HTML": "https://arxiv.org/html/2507.17524v1",
        "PDF": "https://arxiv.org/pdf/2507.17524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about improving EEG emotion recognition using unsupervised domain adaptation, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17526",
      "abstract": "Building energy modeling is a key tool for optimizing the performance of building energy systems. Historically, a wide spectrum of methods has been explored -- ranging from conventional physics-based models to purely data-driven techniques. Recently, hybrid approaches that combine the strengths of both paradigms have gained attention. These include strategies such as learning surrogates for physics-based models, modeling residuals between simulated and observed data, fine-tuning surrogates with real-world measurements, using physics-based outputs as additional inputs for data-driven models, and integrating the physics-based output into the loss function the data-driven model. Despite this progress, two significant research gaps remain. First, most hybrid methods focus on deterministic modeling, often neglecting the inherent uncertainties caused by factors like weather fluctuations and occupant behavior. Second, there has been little systematic comparison within a probabilistic modeling framework. This study addresses these gaps by evaluating five representative hybrid approaches for probabilistic building energy modeling, focusing on quantile predictions of building thermodynamics in a real-world case study. Our results highlight two main findings. First, the performance of hybrid approaches varies across different building room types, but residual learning with a Feedforward Neural Network performs best on average. Notably, the residual approach is the only model that produces physically intuitive predictions when applied to out-of-distribution test data. Second, Quantile Conformal Prediction is an effective procedure for calibrating quantile predictions in case of indoor temperature modeling.",
      "authors": [
        "Leandro Von Krannichfeldt",
        "Kristina Orehounig and Olga Fink"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:07:33+00:00",
          "link": "https://arxiv.org/abs/2507.17526v1",
          "size": "3418kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17526",
        "HTML": "https://arxiv.org/html/2507.17526v1",
        "PDF": "https://arxiv.org/pdf/2507.17526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores probabilistic building energy modeling using hybrid approaches, focusing on quantile predictions of building thermodynamics, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17527",
      "abstract": "Simultaneous Interpretation (SI) represents one of the most daunting frontiers in the translation industry, with product-level automatic systems long plagued by intractable challenges: subpar transcription and translation quality, lack of real-time speech generation, multi-speaker confusion, and translated speech inflation, especially in long-form discourses. In this study, we introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers high-fidelity, ultra-low-latency speech-to-speech generation with voice cloning capabilities. As a fully operational product-level solution, Seed-LiveInterpret 2.0 tackles these challenges head-on through our novel duplex speech-to-speech understanding-generating framework. Experimental results demonstrate that through large-scale pretraining and reinforcement learning, the model achieves a significantly better balance between translation accuracy and latency, validated by human interpreters to exceed 70% correctness in complex scenarios. Notably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by significant margins in translation quality, while slashing the average latency of cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is around a near 70% reduction that drastically enhances practical usability.",
      "authors": [
        "Shanbo Cheng",
        "Yu Bao",
        "Zhichao Huang",
        "Yu Lu",
        "Ningxin Peng",
        "Lu Xu",
        "Runsheng Yu",
        "Rong Cao",
        "Ting Han",
        "Zeyang Li",
        "Sitong Liu",
        "Shengtao Ma",
        "Shiguang Pan",
        "Jiongchen Xiao",
        "Nuo Xu",
        "Meng Yang",
        "Rong Ye",
        "Yiming Yu",
        "Ruofei Zhang",
        "Wanyi Zhang",
        "Wenhao Zhu",
        "Liehao Zou",
        "Lu Lu",
        "Yuxuan Wang",
        "Yonghui Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:07:41+00:00",
          "link": "https://arxiv.org/abs/2507.17527v1",
          "size": "1600kb",
          "version": "v1"
        }
      ],
      "title": "Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17527",
        "HTML": "https://arxiv.org/html/2507.17527v1",
        "PDF": "https://arxiv.org/pdf/2507.17527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on simultaneous speech-to-speech translation with improved real-time capabilities and voice cloning, which does not involve contributions to LLM training data processing, such as data collection or quality improvement in training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17528",
      "abstract": "The matrix contextual bandit (CB), as an extension of the well-known multi-armed bandit, is a powerful framework that has been widely applied in sequential decision-making scenarios involving low-rank structure. In many real-world scenarios, such as online advertising and recommender systems, additional graph information often exists beyond the low-rank structure, that is, the similar relationships among users/items can be naturally captured through the connectivity among nodes in the corresponding graphs. However, existing matrix CB methods fail to explore such graph information, and thereby making them difficult to generate effective decision-making policies. To fill in this void, we propose in this paper a novel matrix CB algorithmic framework that builds upon the classical upper confidence bound (UCB) framework. This new framework can effectively integrate both the low-rank structure and graph information in a unified manner. Specifically, it involves first solving a joint nuclear norm and matrix Laplacian regularization problem, followed by the implementation of a graph-based generalized linear version of the UCB algorithm. Rigorous theoretical analysis demonstrates that our procedure outperforms several popular alternatives in terms of cumulative regret bound, owing to the effective utilization of graph information. A series of synthetic and real-world data experiments are conducted to further illustrate the merits of our procedure.",
      "authors": [
        "Yao Wang",
        "Jiannan Li",
        "Yue Kang",
        "Shanxing Gao",
        "Zhenxin Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:07:47+00:00",
          "link": "https://arxiv.org/abs/2507.17528v1",
          "size": "7864kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Low-Rank Matrix Contextual Bandits with Graph Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17528",
        "HTML": "https://arxiv.org/html/2507.17528v1",
        "PDF": "https://arxiv.org/pdf/2507.17528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for matrix contextual bandits with graph information for decision-making scenarios, which is unrelated to training data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17530",
      "abstract": "Generalized Advantage Estimation (GAE) has been used to mitigate the computational complexity of reinforcement learning (RL) by employing an exponentially weighted estimation of the advantage function to reduce the variance in policy gradient estimates. Despite its effectiveness, GAE is not designed to handle value distributions integral to distributional RL, which can capture the inherent stochasticity in systems and is hence more robust to system noises. To address this gap, we propose a novel approach that utilizes the optimal transport theory to introduce a Wasserstein-like directional metric, which measures both the distance and the directional discrepancies between probability distributions. Using the exponentially weighted estimation, we leverage this Wasserstein-like directional metric to derive distributional GAE (DGAE). Similar to traditional GAE, our proposed DGAE provides a low-variance advantage estimate with controlled bias, making it well-suited for policy gradient algorithms that rely on advantage estimation for policy updates. We integrated DGAE into three different policy gradient methods. Algorithms were evaluated across various OpenAI Gym environments and compared with the baselines with traditional GAE to assess the performance.",
      "authors": [
        "Shahil Shaik",
        "Jonathon M. Smereka",
        "and Yue Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:07:56+00:00",
          "link": "https://arxiv.org/abs/2507.17530v1",
          "size": "5023kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Advantage Estimation for Distributional Policy Gradients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17530",
        "HTML": "https://arxiv.org/html/2507.17530v1",
        "PDF": "https://arxiv.org/pdf/2507.17530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an approach for generalized advantage estimation in reinforcement learning, which does not address training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17531",
      "abstract": "Robust relocalization in dynamic outdoor environments remains a key challenge for autonomous systems relying on 3D lidar. While long-term localization has been widely studied, short-term environmental changes, occurring over days or weeks, remain underexplored despite their practical significance. To address this gap, we present a highresolution, short-term multi-temporal dataset collected weekly from February to April 2025 across natural and semi-urban settings. Each session includes high-density point cloud maps, 360 deg panoramic images, and trajectory data. Projected lidar scans, derived from the point cloud maps and modeled with sensor-accurate occlusions, are used to evaluate alignment accuracy against the ground truth using two Iterative Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show that Point-to-Plane offers significantly more stable and accurate registration, particularly in areas with sparse features or dense vegetation. This study provides a structured dataset for evaluating short-term localization robustness, a reproducible framework for analyzing scan-to-map alignment under noise, and a comparative evaluation of ICP performance in evolving outdoor environments. Our analysis underscores how local geometry and environmental variability affect localization success, offering insights for designing more resilient robotic systems.",
      "authors": [
        "Abdel-Raouf Dannaoui",
        "Johann Laconte",
        "Christophe Debain",
        "Francois Pomerleau and Paul Checchin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:10:48+00:00",
          "link": "https://arxiv.org/abs/2507.17531v1",
          "size": "11983kb",
          "version": "v1"
        }
      ],
      "title": "When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17531",
        "HTML": "https://arxiv.org/html/2507.17531v1",
        "PDF": "https://arxiv.org/pdf/2507.17531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on localization challenges and datasets related to 3D lidar in evolving environments, not on LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17533",
      "abstract": "Recent advances in multi-modal pre-training methods have shown promising effectiveness in learning 3D representations by aligning multi-modal features between 3D shapes and their corresponding 2D counterparts. However, existing multi-modal pre-training frameworks primarily rely on a single pre-training task to gather multi-modal data in 3D applications. This limitation prevents the models from obtaining the abundant information provided by other relevant tasks, which can hinder their performance in downstream tasks, particularly in complex and diverse domains. In order to tackle this issue, we propose MMPT, a Multi-modal Multi-task Pre-training framework designed to enhance point cloud understanding. Specifically, three pre-training tasks are devised: (i) Token-level reconstruction (TLR) aims to recover masked point tokens, endowing the model with representative learning abilities. (ii) Point-level reconstruction (PLR) is integrated to predict the masked point positions directly, and the reconstructed point cloud can be considered as a transformed point cloud used in the subsequent task. (iii) Multi-modal contrastive learning (MCL) combines feature correspondences within and across modalities, thus assembling a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised manner. Moreover, this framework operates without requiring any 3D annotations, making it scalable for use with large datasets. The trained encoder can be effectively transferred to various downstream tasks. To demonstrate its effectiveness, we evaluated its performance compared to state-of-the-art methods in various discriminant and generative applications under widely-used benchmarks.",
      "authors": [
        "Liwen Liu",
        "Weidong Yang",
        "Lipeng Ma",
        "Ben Fei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:13:14+00:00",
          "link": "https://arxiv.org/abs/2507.17533v1",
          "size": "8407kb",
          "version": "v1"
        }
      ],
      "title": "Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17533",
        "HTML": "https://arxiv.org/html/2507.17533v1",
        "PDF": "https://arxiv.org/pdf/2507.17533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study discusses a multi-modal pre-training framework for point cloud understanding and related applications, with no relevant contributions to the data processing aspects of large language models specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17534",
      "abstract": "This paper proposes a unified approach for designing stochastic optimization algorithms that robustly scale to the federated learning setting. Our work studies a class of Majorize-Minimization (MM) problems, which possesses a linearly parameterized family of majorizing surrogate functions. This framework encompasses (proximal) gradient-based algorithms for (regularized) smooth objectives, the Expectation Maximization algorithm, and many problems seen as variational surrogate MM. We show that our framework motivates a unifying algorithm called Stochastic Approximation Stochastic Surrogate MM (\\SSMM), which includes previous stochastic MM procedures as special instances. We then extend \\SSMM\\ to the federated setting, while taking into consideration common bottlenecks such as data heterogeneity, partial participation, and communication constraints; this yields \\QSMM. The originality of \\QSMM\\ is to learn locally and then aggregate information characterizing the \\textit{surrogate majorizing function}, contrary to classical algorithms which learn and aggregate the \\textit{original parameter}. Finally, to showcase the flexibility of this methodology beyond our theoretical setting, we use it to design an algorithm for computing optimal transport maps in the federated setting.",
      "authors": [
        "Aymeric Dieuleveut",
        "Gersende Fort",
        "Mahmoud Hegazy",
        "Hoi-To Wai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:13:19+00:00",
          "link": "https://arxiv.org/abs/2507.17534v1",
          "size": "2043kb",
          "version": "v1"
        }
      ],
      "title": "Federated Majorize-Minimization: Beyond Parameter Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17534",
        "HTML": "https://arxiv.org/html/2507.17534v1",
        "PDF": "https://arxiv.org/pdf/2507.17534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and stochastic optimization, dealing with majorize-minimization. It does not involve LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17539",
      "abstract": "Multimodal large language models (MLLMs) demonstrate significant potential in the field of medical diagnosis. However, they face critical challenges in specialized domains such as ophthalmology, particularly the fragmentation of annotation granularity and inconsistencies in clinical reasoning logic, which hinder precise cross-modal understanding. This paper introduces FundusExpert, an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning capabilities, along with FundusGen, a dataset constructed through the intelligent Fundus-Engine system. Fundus-Engine automates localization and leverages MLLM-based semantic expansion to integrate global disease classification, local object detection, and fine-grained feature analysis within a single fundus image. Additionally, by constructing a clinically aligned cognitive chain, it guides the model to generate interpretable reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen, achieves the best performance in ophthalmic question-answering tasks, surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in zero-shot report generation tasks, achieving a clinical consistency of 77.0%, significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling law between data quality and model capability ($L \\propto N^{0.068}$), demonstrating that the cognitive alignment annotations in FundusGen enhance data utilization efficiency. By integrating region-level localization with diagnostic reasoning chains, our work develops a scalable, clinically-aligned MLLM and explores a pathway toward bridging the visual-language gap in specific MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.",
      "authors": [
        "Xinyao Liu",
        "Diping Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:19:30+00:00",
          "link": "https://arxiv.org/abs/2507.17539v1",
          "size": "1539kb",
          "version": "v1"
        }
      ],
      "title": "Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17539",
        "HTML": "https://arxiv.org/html/2507.17539v1",
        "PDF": "https://arxiv.org/pdf/2507.17539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces FundusGen, a dataset specifically created for ophthalmic MLLMs, which involves data generation and annotation for training LLMs in a specialized medical domain, making a direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17542",
      "abstract": "Bug reproduction is critical in the software debugging and repair process, yet the majority of bugs in open-source and industrial settings lack executable tests to reproduce them at the time they are reported, making diagnosis and resolution more difficult and time-consuming. To address this challenge, we introduce AssertFlip, a novel technique for automatically generating Bug Reproducible Tests (BRTs) using large language models (LLMs). Unlike existing methods that attempt direct generation of failing tests, AssertFlip first generates passing tests on the buggy behaviour and then inverts these tests to fail when the bug is present. We hypothesize that LLMs are better at writing passing tests than ones that crash or fail on purpose. Our results show that AssertFlip outperforms all known techniques in the leaderboard of SWT-Bench, a benchmark curated for BRTs. Specifically, AssertFlip achieves a fail-to-pass success rate of 43.6% on the SWT-Bench-Verified subset.",
      "authors": [
        "Lara Khatib",
        "Noble Saji Mathews",
        "Meiyappan Nagappan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:19:55+00:00",
          "link": "https://arxiv.org/abs/2507.17542v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "AssertFlip: Reproducing Bugs via Inversion of LLM-Generated Passing Tests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17542",
        "HTML": "https://arxiv.org/html/2507.17542v1",
        "PDF": "https://arxiv.org/pdf/2507.17542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a novel technique, AssertFlip, for generating Bug Reproducible Tests using LLMs, which involves data generation but is not directly focused on LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17543",
      "abstract": "The rapid growth of messaging scams creates an escalating challenge for user security and financial safety. In this paper, we present the Anticipate, Simulate, Reason (ASR) framework, a generative AI method that enables users to proactively identify and comprehend scams within instant messaging platforms. Using large language models, ASR predicts scammer responses, creates realistic scam conversations, and delivers real-time, interpretable support to end-users. We develop ScamGPT-J, a domain-specific language model fine-tuned on a new, high-quality dataset of scam conversations covering multiple scam types. Thorough experimental evaluation shows that the ASR framework substantially enhances scam detection, particularly in challenging contexts such as job scams, and uncovers important demographic patterns in user vulnerability and perceptions of AI-generated assistance. Our findings reveal a contradiction where those most at risk are often least receptive to AI support, emphasizing the importance of user-centered design in AI-driven fraud prevention. This work advances both the practical and theoretical foundations for interpretable, human-centered AI systems in combating evolving digital threats.",
      "authors": [
        "Xue Wen Tan",
        "Kenneth See",
        "Stanley Kok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:20:09+00:00",
          "link": "https://arxiv.org/abs/2507.17543v1",
          "size": "39165kb",
          "version": "v1"
        }
      ],
      "title": "Anticipate, Simulate, Reason (ASR): A Comprehensive Generative AI Framework for Combating Messaging Scams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17543",
        "HTML": "https://arxiv.org/html/2507.17543v1",
        "PDF": "https://arxiv.org/pdf/2507.17543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ScamGPT-J, a domain-specific language model fine-tuned on a dataset of scam conversations. While it involves the creation of a new dataset for fine-tuning, the focus is more on combating messaging scams and the framework rather than a primary contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17548",
      "abstract": "Code reasoning is a fundamental capability for large language models (LLMs) in the code domain. It involves understanding and predicting a program's execution behavior, such as determining the output for a given input or whether a specific statement will be executed. This capability is essential for downstream tasks like debugging, code generation, and program repair. Prior approaches mainly rely on supervised fine-tuning to improve performance in code reasoning tasks. However, they often show limited gains and fail to generalize across diverse scenarios. We argue this is due to two core issues: the low quality of training data and the limitations of supervised fine-tuning, which struggles to teach general reasoning skills. To address these challenges, we propose CodeReasoner, a framework that spans both dataset construction and a two-stage training process. First, we introduce a method to construct datasets that focus on the core execution logic of Python programs. Next, we apply instruction tuning to inject execution-specific knowledge distilled from a powerful teacher model. We then enhance reasoning and generalization through GRPO reinforcement learning on top of the fine-tuned model. Experiments on three widely-used code reasoning benchmarks show that CodeReasoner improves performance by 27.1% to 40.2% over prior methods using a 7B model. Notably, the 7B model matches GPT-4o on key tasks like input/output and coverage prediction. When scaled to 14B, CodeReasoner outperforms GPT-4o across all benchmarks. Ablation studies confirm the effectiveness of each training stage and highlight the importance of reasoning chains.",
      "authors": [
        "Lingxiao Tang",
        "He Ye",
        "Zhongxin Liu",
        "Xiaoxue Ren",
        "Lingfeng Bao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:26:58+00:00",
          "link": "https://arxiv.org/abs/2507.17548v1",
          "size": "1123kb",
          "version": "v1"
        }
      ],
      "title": "CodeReasoner: Enhancing the Code Reasoning Ability with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17548",
        "HTML": "https://arxiv.org/html/2507.17548v1",
        "PDF": "https://arxiv.org/pdf/2507.17548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "CodeReasoner introduces a method for constructing datasets focused on Python program execution logic and applies instruction tuning, contributing directly to the improvement of training data for LLM fine-tuning and enhancing reasoning abilities in code contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17552",
      "abstract": "Increasing penetration of renewable energy sources (RES) and electrification of energy systems necessitates the engagement of demand-side management (DSM) to help alleviate congestion in electricity grid. Heat pump and thermal energy storage (HPTES) systems, being energy efficient solutions, are becoming popular in modern buildings and are promising to contribute to demand-side management (DSM) due to their significant share in household electricity consumption. For typical HPTES systems, this paper presents a systematic design framework covering a control-oriented modeling process and energy-flexible model predictive control (MPC) design. The proposed MPC-based DSM strategy offers an innovative solution for efficient DSM by following a two-step DSM framework. In the first step, flexibility assessment is performed to quantitatively evaluate the flexibility potential of the HPTES system by solving a mixed-integer economic MPC problem. In the second step, flexibility exploitation is achieved through reacting to feasible demand response (DR) requests while respecting system constraints. Both numerical simulations and real-world experiments are performed based on a real HPTES installation to showcase the viability and effectiveness of the proposed design.",
      "authors": [
        "Weihong Tang",
        "Yun Li",
        "Shalika Walker",
        "Tamas Keviczky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:40:35+00:00",
          "link": "https://arxiv.org/abs/2507.17552v1",
          "size": "5549kb",
          "version": "v1"
        }
      ],
      "title": "Model Predictive Control for Unlocking Energy Flexibility of Heat Pump and Thermal Energy Storage Systems: Experimental Results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17552",
        "HTML": "https://arxiv.org/html/2507.17552v1",
        "PDF": "https://arxiv.org/pdf/2507.17552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with model predictive control for energy systems, not related to any operations or methodologies for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17554",
      "abstract": "The versatility of diffusion models in generating customized images from few samples raises significant privacy concerns, particularly regarding unauthorized modifications of private content. This concerning issue has renewed the efforts in developing protection mechanisms based on adversarial attacks, which generate effective perturbations to poison diffusion models. Our work is motivated by the observation that these models exhibit a high degree of abstraction within their semantic latent space (`h-space'), which encodes critical high-level features for generating coherent and meaningful content. In this paper, we propose a novel anti-customization approach, called HAAD (h-space based Adversarial Attack for Diffusion models), that leverages adversarial attacks to craft perturbations based on the h-space that can efficiently degrade the image generation process. Building upon HAAD, we further introduce a more efficient variant, HAAD-KV, that constructs perturbations solely based on the KV parameters of the h-space. This strategy offers a stronger protection, that is computationally less expensive. Despite their simplicity, our methods outperform state-of-the-art adversarial attacks, highlighting their effectiveness.",
      "authors": [
        "Xide Xu",
        "Sandesh Kamath",
        "Muhammad Atif Butt",
        "Bogdan Raducanu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:43:22+00:00",
          "link": "https://arxiv.org/abs/2507.17554v1",
          "size": "36995kb",
          "version": "v1"
        }
      ],
      "title": "An h-space Based Adversarial Attack for Protection Against Few-shot Personalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17554",
        "HTML": "https://arxiv.org/html/2507.17554v1",
        "PDF": "https://arxiv.org/pdf/2507.17554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial attacks against diffusion models' image generation, primarily related to privacy and security of customized image generation, rather than training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17561",
      "abstract": "Neurorehabilitation conventionally relies on the interaction between a patient and a physical therapist. Robotic systems can improve and enrich the physical feedback provided to patients after neurological injury, but they under-utilize the adaptability and clinical expertise of trained therapists. In this position paper, we advocate for a novel approach that integrates the therapist's clinical expertise and nuanced decision-making with the strength, accuracy, and repeatability of robotics: Robot-mediated physical Human-Human Interaction. This framework, which enables two individuals to physically interact through robotic devices, has been studied across diverse research groups and has recently emerged as a promising link between conventional manual therapy and rehabilitation robotics, harmonizing the strengths of both approaches. This paper presents the rationale of a multidisciplinary team-including engineers, doctors, and physical therapists-for conducting research that utilizes: a unified taxonomy to describe robot-mediated rehabilitation, a framework of interaction based on social psychology, and a technological approach that makes robotic systems seamless facilitators of natural human-human interaction.",
      "authors": [
        "Lorenzo Vianello",
        "Matthew Short",
        "Julia Manczurowsky",
        "Emek Bar{\\i}\\c{s} K\\\"u\\c{c}\\\"uktabak",
        "Francesco Di Tommaso",
        "Alessia Noccaro",
        "Laura Bandini",
        "Shoshana Clark",
        "Alaina Fiorenza",
        "Francesca Lunardini",
        "Alberto Canton",
        "Marta Gandolla",
        "Alessandra L. G. Pedrocchi",
        "Emilia Ambrosini",
        "Manuel Murie-Fernandez",
        "Carmen B. Roman",
        "Jesus Tornero",
        "Natacha Leon",
        "Andrew Sawers",
        "Jim Patton",
        "Domenico Formica",
        "Nevio Luigi Tagliamonte",
        "Georg Rauter",
        "Kilian Baur",
        "Fabian Just",
        "Christopher J. Hasson",
        "Vesna D. Novak",
        "Jose L. Pons"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:51:55+00:00",
          "link": "https://arxiv.org/abs/2507.17561v1",
          "size": "4560kb",
          "version": "v1"
        }
      ],
      "title": "Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17561",
        "HTML": "https://arxiv.org/html/2507.17561v1",
        "PDF": "https://arxiv.org/pdf/2507.17561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses robot-mediated physical human-human interaction in neurorehabilitation, which does not touch upon any aspects pertaining to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17563",
      "abstract": "Human communication involves more than explicit semantics, with implicit signals and contextual cues playing a critical role in shaping meaning. However, modern speech technologies, such as Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) often fail to capture these beyond-semantic dimensions. To better characterize and benchmark the progression of speech intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5), a hierarchical framework illustrated the evolution of spoken dialogue systems from basic command recognition to human-like social interaction. To support these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which refers to the set of information in speech communication that encompasses but transcends explicit semantics. It conveys emotions, contexts, and modifies or extends meanings through multidimensional features such as affective cues, contextual dynamics, and implicit semantics, thereby enhancing the understanding of communicative intentions and scenarios. We present a formalized framework for BoSS, leveraging cognitive relevance theories and machine learning models to analyze temporal and contextual speech dynamics. We evaluate BoSS-related attributes across five different dimensions, reveals that current spoken language models (SLMs) are hard to fully interpret beyond-semantic signals. These findings highlight the need for advancing BoSS research to enable richer, more context-aware human-machine communication.",
      "authors": [
        "Qing Wang",
        "Zehan Li",
        "Hang Lv",
        "Hongjie Chen",
        "Yaodong Song",
        "Jian Kang",
        "Jie Lian",
        "Jie Li",
        "Yongxiang Li",
        "Zhongjiang He",
        "Xuelong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:53:50+00:00",
          "link": "https://arxiv.org/abs/2507.17563v1",
          "size": "2345kb",
          "version": "v1"
        }
      ],
      "title": "BoSS: Beyond-Semantic Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17563",
        "HTML": "https://arxiv.org/html/2507.17563v1",
        "PDF": "https://arxiv.org/pdf/2507.17563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the beyond-semantic aspects of speech in communication and developing spoken interaction system capabilities, rather than on data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17569",
      "abstract": "We introduce novel a posteriori error indicators for a nonlinear least-squares solver for smooth solutions of the Monge--Amp\\`ere equation on convex polygonal domains in $\\mathbb{R}^2$. At each iteration, our iterative scheme decouples the problem into (i) a pointwise nonlinear minimization problem and (ii) a linear biharmonic variational problem. For the latter, we derive an equivalence to a biharmonic problem with Navier boundary conditions and solve it via mixed piecewise-linear finite elements. Reformulating this as a coupled second-order system, we derive a priori and a posteriori $\\mathbb{P}^1$ finite element error estimators and we design a robust adaptive mesh refinement strategy. Numerical tests confirm that errors in different norms scale appropriately. Finally, we demonstrate the effectiveness of our a posteriori indicators in guiding mesh refinement.",
      "authors": [
        "Alexandre Caboussat",
        "Anna Peruso",
        "Marco Picasso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:59:20+00:00",
          "link": "https://arxiv.org/abs/2507.17569v1",
          "size": "11901kb",
          "version": "v1"
        }
      ],
      "title": "Error estimates and adaptivity for a least-squares method applied to the Monge-Amp\\`ere equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17569",
        "HTML": "https://arxiv.org/html/2507.17569v1",
        "PDF": "https://arxiv.org/pdf/2507.17569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with numerical methods and error estimation for solving a class of mathematical equations (Monge-Amp\u00e8re), unrelated to the topic of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17571",
      "abstract": "We study skew polycyclic codes over a finite field $\\mathbb{F}_q$, associated with a skew polynomial $f(x) \\in \\mathbb{F}_q[x;\\sigma]$, where $\\sigma$ is an automorphism of $\\mathbb{F}_q$. We start by proving the Roos-like bound for both the Hamming and the rank metric for this class of codes. Next, we focus on the Hamming and rank equivalence between two classes of polycyclic codes by introducing an equivalence relation and describing its equivalence classes. Finally, we present examples that illustrate applications of the theory developed in this paper.",
      "authors": [
        "Hassan Ou-azzou",
        "Anna-Lena Horlemann",
        "Nuh Aydin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:03:24+00:00",
          "link": "https://arxiv.org/abs/2507.17571v1",
          "size": "54kb",
          "version": "v1"
        }
      ],
      "title": "Bounds and Equivalence of Skew Polycyclic Codes over Finite Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17571",
        "HTML": "https://arxiv.org/html/2507.17571v1",
        "PDF": "https://arxiv.org/pdf/2507.17571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is on skew polycyclic codes over finite fields, primarily concerning algebra and coding theory, which does not pertain to LLM training data processing operations or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17572",
      "abstract": "Global optimization has gained attraction over the past decades, thanks to the development of both theoretical foundations and efficient numerical routines to cope with optimization problems of various complexities. Among recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful framework, leveraging the potential of sum of squares methods from the polynomial optimization community with the expressivity of kernel methods widely used in machine learning. This paper applies the kernel sum of squares framework for solving control and estimation problems, which exhibit poor local minima. We demonstrate that KernelSOS performs well on a selection of problems from both domains. In particular, we show that KernelSOS is competitive with other sum of squares approaches on estimation problems, while being applicable to non-polynomial and non-parametric formulations. The sample-based nature of KernelSOS allows us to apply it to trajectory optimization problems with an integrated simulator treated as a black box, both as a standalone method and as a powerful initialization method for local solvers, facilitating the discovery of better solutions.",
      "authors": [
        "Antoine Groudiev",
        "Fabian Schramm",
        "\\'Elo\\\"ise Berthier",
        "Justin Carpentier",
        "Frederike D\\\"umbgen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:03:40+00:00",
          "link": "https://arxiv.org/abs/2507.17572v1",
          "size": "4263kb",
          "version": "v1"
        }
      ],
      "title": "KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17572",
        "HTML": "https://arxiv.org/html/2507.17572v1",
        "PDF": "https://arxiv.org/pdf/2507.17572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on Kernel Sum of Squares methods for optimization in control and estimation problems, which are not related to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17577",
      "abstract": "One of the most practical and challenging types of black-box adversarial attacks is the hard-label attack, where only the top-1 predicted label is available. One effective approach is to search for the optimal ray direction from the benign image that minimizes the $\\ell_p$-norm distance to the adversarial region. The unique advantage of this approach is that it transforms the hard-label attack into a continuous optimization problem. The objective function value is the ray's radius, which can be obtained via binary search at a high query cost. Existing methods use a \"sign trick\" in gradient estimation to reduce the number of queries. In this paper, we theoretically analyze the quality of this gradient estimation and propose a novel prior-guided approach to improve ray search efficiency both theoretically and empirically. Specifically, we utilize the transfer-based priors from surrogate models, and our gradient estimators appropriately integrate them by approximating the projection of the true gradient onto the subspace spanned by these priors and random directions, in a query-efficient manner. We theoretically derive the expected cosine similarities between the obtained gradient estimators and the true gradient, and demonstrate the improvement achieved by incorporating priors. Extensive experiments on the ImageNet and CIFAR-10 datasets show that our approach significantly outperforms 11 state-of-the-art methods in terms of query efficiency.",
      "authors": [
        "Chen Ma",
        "Xinjie Xu",
        "Shuyu Cheng",
        "Qi Xuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:11:25+00:00",
          "link": "https://arxiv.org/abs/2507.17577v1",
          "size": "23671kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17577",
        "PDF": "https://arxiv.org/pdf/2507.17577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses black-box adversarial attacks and prior-guided gradient estimation, which do not pertain to data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17578",
      "abstract": "Speech technology remains out of reach for most of the over 2300 languages in Africa. We present the first systematic assessment of large-scale synthetic voice corpora for African ASR. We apply a three-step process: LLM-driven text creation, TTS voice synthesis, and ASR fine-tuning. Eight out of ten languages for which we create synthetic text achieved readability scores above 5 out of 7. We evaluated ASR improvement for three (Hausa, Dholuo, Chichewa) and created more than 2,500 hours of synthetic voice data at below 1% of the cost of real data. Fine-tuned Wav2Vec-BERT-2.0 models trained on 250h real and 250h synthetic Hausa matched a 500h real-data-only baseline, while 579h real and 450h to 993h synthetic data created the best performance. We also present gender-disaggregated ASR performance evaluation. For very low-resource languages, gains varied: Chichewa WER improved about 6.5% relative with a 1:2 real-to-synthetic ratio; a 1:1 ratio for Dholuo showed similar improvements on some evaluation data, but not on others. Investigating intercoder reliability, ASR errors and evaluation datasets revealed the need for more robust reviewer protocols and more accurate evaluation data. All data and models are publicly released to invite further work to improve synthetic data for African languages.",
      "authors": [
        "Brian DeRenzi",
        "Anna Dixon",
        "Mohamed Aymane Farhi and Christian Resch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:13:32+00:00",
          "link": "https://arxiv.org/abs/2507.17578v1",
          "size": "733kb",
          "version": "v1"
        }
      ],
      "title": "Synthetic Voice Data for Automatic Speech Recognition in African Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17578",
        "HTML": "https://arxiv.org/html/2507.17578v1",
        "PDF": "https://arxiv.org/pdf/2507.17578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper discusses the creation of synthetic voice data and the use of LLM for generating text to improve ASR in African languages, directly involving dataset generation and fine-tuning, which is a core aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17580",
      "abstract": "Federated Learning (FL) has become increasingly popular across different sectors, offering a way for clients to work together to train a global model without sharing sensitive data. It involves multiple rounds of communication between the global model and participating clients, which introduces several challenges like high communication costs, heterogeneous client data, prolonged processing times, and increased vulnerability to privacy threats. In recent years, the convergence of federated learning and parameterized quantum circuits has sparked significant research interest, with promising implications for fields such as healthcare and finance. By enabling decentralized training of quantum models, it allows clients or institutions to collaboratively enhance model performance and outcomes while preserving data privacy. Recognizing that Fisher information can quantify the amount of information that a quantum state carries under parameter changes, thereby providing insight into its geometric and statistical properties. We intend to leverage this property to address the aforementioned challenges. In this work, we propose a Quantum Federated Learning (QFL) algorithm that makes use of the Fisher information computed on local client models, with data distributed across heterogeneous partitions. This approach identifies the critical parameters that significantly influence the quantum model's performance, ensuring they are preserved during the aggregation process. Our research assessed the effectiveness and feasibility of QFL by comparing its performance against other variants, and exploring the benefits of incorporating Fisher information in QFL settings. Experimental results on ADNI and MNIST datasets demonstrate the effectiveness of our approach in achieving better performance and robustness against the quantum federated averaging method.",
      "authors": [
        "Amandeep Singh Bhatia",
        "Sabre Kais"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:14:53+00:00",
          "link": "https://arxiv.org/abs/2507.17580v1",
          "size": "3046kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Quantum Federated Learning with Fisher Information-Based Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17580",
        "HTML": "https://arxiv.org/html/2507.17580v1",
        "PDF": "https://arxiv.org/pdf/2507.17580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a Quantum Federated Learning algorithm using Fisher information, focusing on improving federated learning without any emphasis on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17585",
      "abstract": "Real-world 3D scene-level scans offer realism and can enable better real-world generalizability for downstream applications. However, challenges such as data volume, diverse annotation formats, and tool compatibility limit their use. This paper demonstrates a methodology to effectively leverage these scans and their annotations. We propose a unified annotation integration using USD, with application-specific USD flavors. We identify challenges in utilizing holistic real-world scan datasets and present mitigation strategies. The efficacy of our approach is demonstrated through two downstream applications: LLM-based scene editing, enabling effective LLM understanding and adaptation of the data (80% success), and robotic simulation, achieving an 87% success rate in policy learning.",
      "authors": [
        "Anna-Maria Halacheva",
        "Jan-Nico Zaech",
        "Sombit Dey",
        "Luc Van Gool",
        "Danda Pani Paudel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:20:31+00:00",
          "link": "https://arxiv.org/abs/2507.17585v1",
          "size": "10613kb",
          "version": "v1"
        }
      ],
      "title": "From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17585",
        "HTML": "https://arxiv.org/html/2507.17585v1",
        "PDF": "https://arxiv.org/pdf/2507.17585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper briefly mentions LLM-based scene editing, its primary focus is on integrating 3D scans and annotations, not specifically on data processing techniques directly applicable to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17587",
      "abstract": "The widespread adoption of electric vehicles (EVs) has significantly increased demand on both transportation and power systems, posing challenges to their stable operation. To support the growing need for EV charging, both fixed charging stations (FCSs) and mobile charging stations (MCSs) have been introduced, serving as key interfaces between the power grid and traffic network. Recognizing the importance of collaborative planning across these sectors, this paper presents a two-stage joint planning model for FCSs and MCSs, utilizing an improved alternating direction method of multipliers (ADMM) algorithm. The primary goal of the proposed model is to transform the potential negative impacts of large-scale EV integration into positive outcomes, thereby enhancing social welfare through collaboration among multiple stakeholders. In the first stage, we develop a framework for evaluating FCS locations, incorporating assessments of EV hosting capacity and voltage stability. The second stage introduces a joint planning model for FCSs and MCSs, aiming to minimize the overall social costs of the EV charging system while maintaining a reliable power supply. To solve the planning problem, we employ a combination of mixed-integer linear programming, queueing theory, and sequential quadratic programming. The improved ADMM algorithm couples the siting and sizing decisions consistently by introducing coupling constraints, and supports a distributed optimization framework that coordinates the interests of EV users, MCS operators, and distribution system operators. Additionally, a flexible capacity planning strategy that accounts for the multi-period development potential of EVCS is proposed to reduce both the complexity and the investment required for FCS construction. Finally, a case study with comparative experiments demonstrates the effectiveness of the proposed models and solution methods.",
      "authors": [
        "Zhe Yu",
        "Xue Hu",
        "Qin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:22:04+00:00",
          "link": "https://arxiv.org/abs/2507.17587v1",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "title": "A Joint Planning Model for Fixed and Mobile Electric Vehicle Charging Stations Considering Flexible Capacity Strategy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17587",
        "HTML": "https://arxiv.org/html/2507.17587v1",
        "PDF": "https://arxiv.org/pdf/2507.17587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on joint planning models for electric vehicle charging stations, using optimization algorithms for system design, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17588",
      "abstract": "Multimodal Machine Translation (MMT) typically enhances text-only translation by incorporating aligned visual features. Despite the remarkable progress, state-of-the-art MMT approaches often rely on paired image-text inputs at inference and are sensitive to irrelevant visual noise, which limits their robustness and practical applicability. To address these issues, we propose D2P-MMT, a diffusion-based dual-branch prompting framework for robust vision-guided translation. Specifically, D2P-MMT requires only the source text and a reconstructed image generated by a pre-trained diffusion model, which naturally filters out distracting visual details while preserving semantic cues. During training, the model jointly learns from both authentic and reconstructed images using a dual-branch prompting strategy, encouraging rich cross-modal interactions. To bridge the modality gap and mitigate training-inference discrepancies, we introduce a distributional alignment loss that enforces consistency between the output distributions of the two branches. Extensive experiments on the Multi30K dataset demonstrate that D2P-MMT achieves superior translation performance compared to existing state-of-the-art approaches.",
      "authors": [
        "Jie Wang",
        "Zhendong Yang",
        "Liansong Zong",
        "Xiaobo Zhang",
        "Dexian Wang",
        "Ji Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:22:51+00:00",
          "link": "https://arxiv.org/abs/2507.17588v1",
          "size": "4222kb",
          "version": "v1"
        }
      ],
      "title": "Dual-branch Prompting for Multimodal Machine Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17588",
        "HTML": "https://arxiv.org/html/2507.17588v1",
        "PDF": "https://arxiv.org/pdf/2507.17588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a multimodal machine translation framework involving dual-branch prompting and a pre-trained diffusion model, but its main focus is on translation performance, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17594",
      "abstract": "The introduction of the neural implicit representation has notably propelled the advancement of online dense reconstruction techniques. Compared to traditional explicit representations, such as TSDF, it improves the mapping completeness and memory efficiency. However, the lack of reconstruction details and the time-consuming learning of neural representations hinder the widespread application of neural-based methods to large-scale online reconstruction. We introduce RemixFusion, a novel residual-based mixed representation for scene reconstruction and camera pose estimation dedicated to high-quality and large-scale online RGB-D reconstruction. In particular, we propose a residual-based map representation comprised of an explicit coarse TSDF grid and an implicit neural module that produces residuals representing fine-grained details to be added to the coarse grid. Such mixed representation allows for detail-rich reconstruction with bounded time and memory budget, contrasting with the overly-smoothed results by the purely implicit representations, thus paving the way for high-quality camera tracking. Furthermore, we extend the residual-based representation to handle multi-frame joint pose optimization via bundle adjustment (BA). In contrast to the existing methods, which optimize poses directly, we opt to optimize pose changes. Combined with a novel technique for adaptive gradient amplification, our method attains better optimization convergence and global optimality. Furthermore, we adopt a local moving volume to factorize the mixed scene representation with a divide-and-conquer design to facilitate efficient online learning in our residual-based framework. Extensive experiments demonstrate that our method surpasses all state-of-the-art ones, including those based either on explicit or implicit representations, in terms of the accuracy of both mapping and tracking on large-scale scenes.",
      "authors": [
        "Yuqing Lan",
        "Chenyang Zhu",
        "Shuaifeng Zhi",
        "Jiazhao Zhang",
        "Zhoufeng Wang",
        "Renjiao Yi",
        "Yijie Wang",
        "Kai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:27:09+00:00",
          "link": "https://arxiv.org/abs/2507.17594v1",
          "size": "25426kb",
          "version": "v1"
        }
      ],
      "title": "RemixFusion: Residual-based Mixed Representation for Large-scale Online RGB-D Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17594",
        "HTML": "https://arxiv.org/html/2507.17594v1",
        "PDF": "https://arxiv.org/pdf/2507.17594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces RemixFusion for RGB-D reconstruction and camera pose estimation, focusing on neural implicit representations for scene reconstruction, which does not relate to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17596",
      "abstract": "While end-to-end autonomous driving models show promising results, their practical deployment is often hindered by large model sizes, a reliance on expensive LiDAR sensors and computationally intensive BEV feature representations. This limits their scalability, especially for mass-market vehicles equipped only with cameras. To address these challenges, we propose PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving architecture operates using only camera data, without explicit BEV representation and forgoing the need for LiDAR. PRIX leverages a visual feature extractor coupled with a generative planning head to predict safe trajectories from raw pixel inputs directly. A core component of our architecture is the Context-aware Recalibration Transformer (CaRT), a novel module designed to effectively enhance multi-level visual features for more robust planning. We demonstrate through comprehensive experiments that PRIX achieves state-of-the-art performance on the NavSim and nuScenes benchmarks, matching the capabilities of larger, multimodal diffusion planners while being significantly more efficient in terms of inference speed and model size, making it a practical solution for real-world deployment. Our work is open-source and the code will be at https://maxiuw.github.io/prix.",
      "authors": [
        "Maciej K. Wozniak",
        "Lianhang Liu",
        "Yixi Cai",
        "Patric Jensfelt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:28:23+00:00",
          "link": "https://arxiv.org/abs/2507.17596v1",
          "size": "8181kb",
          "version": "v1"
        }
      ],
      "title": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17596",
        "HTML": "https://arxiv.org/html/2507.17596v1",
        "PDF": "https://arxiv.org/pdf/2507.17596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The PRIX model focuses on autonomous driving using raw pixel data for efficient trajectory planning with vision features, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17597",
      "abstract": "As surgery embraces digital transformation--integrating sophisticated imaging, advanced algorithms, and robotics to support and automate complex sub-tasks--human judgment of system correctness remains a vital safeguard for patient safety. This shift introduces new \"operator-type\" roles tasked with verifying complex algorithmic outputs, particularly at critical junctures of the procedure, such as the intermediary check before drilling or implant placement. A prime example is 2D/3D registration, a key enabler of image-based surgical navigation that aligns intraoperative 2D images with preoperative 3D data. Although registration algorithms have advanced significantly, they occasionally yield inaccurate results. Because even small misalignments can lead to revision surgery or irreversible surgical errors, there is a critical need for robust quality assurance. Current visualization-based strategies alone have been found insufficient to enable humans to reliably detect 2D/3D registration misalignments. In response, we propose the first artificial intelligence (AI) framework trained specifically for 2D/3D registration quality verification, augmented by explainability features that clarify the model's decision-making. Our explainable AI (XAI) approach aims to enhance informed decision-making for human operators by providing a second opinion together with a rationale behind it. Through algorithm-centric and human-centered evaluations, we systematically compare four conditions: AI-only, human-only, human-AI, and human-XAI. Our findings reveal that while explainability features modestly improve user trust and willingness to override AI errors, they do not exceed the standalone AI in aggregate performance. Nevertheless, future work extending both the algorithmic design and the human-XAI collaboration elements holds promise for more robust quality assurance of 2D/3D registration.",
      "authors": [
        "Sue Min Cho",
        "Alexander Do",
        "Russell H. Taylor",
        "Mathias Unberath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:28:57+00:00",
          "link": "https://arxiv.org/abs/2507.17597v1",
          "size": "727kb",
          "version": "v1"
        }
      ],
      "title": "Explainable AI for Collaborative Assessment of 2D/3D Registration Quality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17597",
        "HTML": "https://arxiv.org/html/2507.17597v1",
        "PDF": "https://arxiv.org/pdf/2507.17597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an AI framework for verifying the quality of 2D/3D registration in surgical navigation, focusing on explainability features to enhance human decision-making. It does not involve LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17603",
      "abstract": "Recent advances in citation recommendation have improved accuracy by leveraging multi-view representation learning to integrate the various modalities present in scholarly documents. However, effectively combining multiple data views requires fusion techniques that can capture complementary information while preserving the unique characteristics of each modality. We propose a novel citation recommendation algorithm that improves upon linear Canonical Correlation Analysis (CCA) methods by applying Deep CCA (DCCA), a neural network extension capable of capturing complex, non-linear relationships between distributed textual and graph-based representations of scientific articles. Experiments on the large-scale DBLP (Digital Bibliography & Library Project) citation network dataset demonstrate that our approach outperforms state-of-the-art CCA-based methods, achieving relative improvements of over 11% in Mean Average Precision@10, 5% in Precision@10, and 7% in Recall@10. These gains reflect more relevant citation recommendations and enhanced ranking quality, suggesting that DCCA's non-linear transformations yield more expressive latent representations than CCA's linear projections.",
      "authors": [
        "Conor McNamara",
        "Effirul Ramlan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:34:07+00:00",
          "link": "https://arxiv.org/abs/2507.17603v1",
          "size": "677kb",
          "version": "v1"
        }
      ],
      "title": "Citation Recommendation using Deep Canonical Correlation Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17603",
        "HTML": "https://arxiv.org/html/2507.17603v1",
        "PDF": "https://arxiv.org/pdf/2507.17603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses citation recommendation algorithms using Deep Canonical Correlation Analysis. It does not involve any aspect of LLM training data processing or relevant data engineering operations for LLM pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17610",
      "abstract": "Data-driven predictive control approaches, in general, and Data-enabled Predictive Control (DeePC), in particular, exploit matrices of raw input/output trajectories for control design. These data are typically gathered only from the system to be controlled. Nonetheless, the increasing connectivity and inherent similarity of (mass-produced) systems have the potential to generate a considerable amount of information that can be exploited to undertake a control task. In light of this, we propose a preliminary federated extension of DeePC that leverages a combination of input/output trajectories from multiple similar systems for predictive control. Supported by a suite of numerical examples, our analysis unveils the potential benefits of exploiting information from similar systems and its possible downsides.",
      "authors": [
        "Gert Vankan and Valentina Breschi and Simone Formentin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:41:32+00:00",
          "link": "https://arxiv.org/abs/2507.17610v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "Toward Federated DeePC: borrowing data from similar systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17610",
        "HTML": "https://arxiv.org/html/2507.17610v1",
        "PDF": "https://arxiv.org/pdf/2507.17610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a federated extension of DeePC using input/output trajectories from multiple systems for predictive control, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17613",
      "abstract": "We present InvRGB+L, a novel inverse rendering model that reconstructs large, relightable, and dynamic scenes from a single RGB+LiDAR sequence. Conventional inverse graphics methods rely primarily on RGB observations and use LiDAR mainly for geometric information, often resulting in suboptimal material estimates due to visible light interference. We find that LiDAR's intensity values-captured with active illumination in a different spectral range-offer complementary cues for robust material estimation under variable lighting. Inspired by this, InvRGB+L leverages LiDAR intensity cues to overcome challenges inherent in RGB-centric inverse graphics through two key innovations: (1) a novel physics-based LiDAR shading model and (2) RGB-LiDAR material consistency losses. The model produces novel-view RGB and LiDAR renderings of urban and indoor scenes and supports relighting, night simulations, and dynamic object insertions, achieving results that surpass current state-of-the-art methods in both scene-level urban inverse rendering and LiDAR simulation.",
      "authors": [
        "Xiaoxue Chen",
        "Bhargav Chandaka",
        "Chih-Hao Lin",
        "Ya-Qin Zhang",
        "David Forsyth",
        "Hao Zhao",
        "Shenlong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:46:09+00:00",
          "link": "https://arxiv.org/abs/2507.17613v1",
          "size": "17041kb",
          "version": "v1"
        }
      ],
      "title": "InvRGB+L: Inverse Rendering of Complex Scenes with Unified Color and LiDAR Reflectance Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17613",
        "HTML": "https://arxiv.org/html/2507.17613v1",
        "PDF": "https://arxiv.org/pdf/2507.17613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an inverse rendering model, InvRGB+L, using RGB and LiDAR data for scene reconstruction, unrelated to LLM training data processing or relevant operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17616",
      "abstract": "Visual attention mechanisms play a crucial role in human perception and aesthetic evaluation. Recent advances in Vision Transformers (ViTs) have demonstrated remarkable capabilities in computer vision tasks, yet their alignment with human visual attention patterns remains underexplored, particularly in aesthetic contexts. This study investigates the correlation between human visual attention and ViT attention mechanisms when evaluating handcrafted objects. We conducted an eye-tracking experiment with 30 participants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal objects comprising basketry bags and ginger jars. Using a Pupil Labs eye-tracker, we recorded gaze patterns and generated heat maps representing human visual attention. Simultaneously, we analyzed the same objects using a pre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting attention maps from each of the 12 attention heads. We compared human and ViT attention distributions using Kullback-Leibler divergence across varying Gaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal correlation at sigma=2.4 +-0.03, with attention head #12 showing the strongest alignment with human visual patterns. Significant differences were found between attention heads, with heads #7 and #9 demonstrating the greatest divergence from human attention (p< 0.05, Tukey HSD test). Results indicate that while ViTs exhibit more global attention patterns compared to human focal attention, certain attention heads can approximate human visual behavior, particularly for specific object features like buckles in basketry items. These findings suggest potential applications of ViT attention mechanisms in product design and aesthetic evaluation, while highlighting fundamental differences in attention strategies between human perception and current AI models.",
      "authors": [
        "Miguel Carrasco",
        "C\\'esar Gonz\\'alez-Mart\\'in",
        "Jos\\'e Aranda",
        "Luis Oliveros"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:47:34+00:00",
          "link": "https://arxiv.org/abs/2507.17616v1",
          "size": "15004kb",
          "version": "v1"
        }
      ],
      "title": "Vision Transformer attention alignment with human visual perception in aesthetic object evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17616",
        "HTML": "https://arxiv.org/html/2507.17616v1",
        "PDF": "https://arxiv.org/pdf/2507.17616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores visual attention mechanisms in Vision Transformers and their alignment with human perception. It does not address LLM training data processing, as it is primarily concerned with computer vision and aesthetic object evaluation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17617",
      "abstract": "Understanding lane toplogy relationships accurately is critical for safe autonomous driving. However, existing two-stage methods suffer from inefficiencies due to error propagations and increased computational overheads. To address these challenges, we propose a one-stage architecture that simultaneously predicts traffic elements, lane centerlines and topology relationship, improving both the accuracy and inference speed of lane topology understanding for autonomous driving. Our key innovation lies in reusing intermediate attention resources within distinct transformer decoders. This approach effectively leverages the inherent relational knowledge within the element detection module to enable the modeling of topology relationships among traffic elements and lanes without requiring additional computationally expensive graph networks. Furthermore, we are the first to demonstrate that knowledge can be distilled from models that utilize standard definition (SD) maps to those operates without using SD maps, enabling superior performance even in the absence of SD maps. Extensive experiments on the OpenLane-V2 dataset show that our approach outperforms baseline methods in both accuracy and efficiency, achieving superior results in lane detection, traffic element identification, and topology reasoning. Our code is available at https://github.com/Yang-Li-2000/one-stage.git.",
      "authors": [
        "Yang Li",
        "Zongzheng Zhang",
        "Xuchong Qiu",
        "Xinrun Li",
        "Ziming Liu",
        "Leichen Wang",
        "Ruikai Li",
        "Zhenxin Zhu",
        "Huan-ang Gao",
        "Xiaojian Lin",
        "Zhiyong Cui",
        "Hang Zhao",
        "Hao Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:48:16+00:00",
          "link": "https://arxiv.org/abs/2507.17617v1",
          "size": "4537kb",
          "version": "v1"
        }
      ],
      "title": "Reusing Attention for One-stage Lane Topology Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17617",
        "HTML": "https://arxiv.org/html/2507.17617v1",
        "PDF": "https://arxiv.org/pdf/2507.17617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for lane topology understanding in autonomous driving. It discusses architecture improvements and efficiency enhancements in the context of vision systems, not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17618",
      "abstract": "Large language models are computationally expensive due to their deep structures. Prior research has shown that intermediate layers contain sufficient information to generate accurate answers, leading to the development of early-exit algorithms that reduce inference costs by terminating computation at earlier layers. However, these methods often suffer from poor performance due to misalignment between intermediate and output layer representations that lead to decoding inaccuracy. To address these challenges, we propose SPADE (SPace Alignment DEcoding), a novel decoding method that aligns intermediate layer representations with the output layer by propagating a minimally reduced sequence consisting of only the start token and the answer token. We further optimize the early-exit decision-making process by training a linear approximation of SPADE that computes entropy-based confidence metrics. Putting them together, we create a hybrid early-exit algorithm that monitors confidence levels and stops inference at intermediate layers while using SPADE to generate high-quality outputs. This approach significantly reduces inference costs without compromising accuracy, offering a scalable and efficient solution for deploying large language models in real-world applications.",
      "authors": [
        "Bowen Zheng",
        "Ming Ma",
        "Zhongqiao Lin",
        "Tianming Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:49:03+00:00",
          "link": "https://arxiv.org/abs/2507.17618v1",
          "size": "6125kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid Early-Exit Algorithm for Large Language Models Based on Space Alignment Decoding (SPADE)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17618",
        "HTML": "https://arxiv.org/html/2507.17618v1",
        "PDF": "https://arxiv.org/pdf/2507.17618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on reducing inference costs for large language models through a hybrid early-exit algorithm and SPADE decoding. It does not contribute to the processing of training data for LLMs, focusing instead on model efficiency."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17626",
      "abstract": "We introduce Quotegraph, a novel large-scale social network derived from speaker-attributed quotations in English news articles published between 2008 and 2020. Quotegraph consists of 528 thousand unique nodes and 8.63 million directed edges, pointing from speakers to persons they mention. The nodes are linked to their corresponding items in Wikidata, thereby endowing the dataset with detailed biographic entity information, including nationality, gender, and political affiliation. Being derived from Quotebank, a massive corpus of quotations, relations in Quotegraph are additionally enriched with the information about the context in which they are featured. Each part of the network construction pipeline is language agnostic, enabling the construction of similar datasets based on non-English news corpora. We believe Quotegraph is a compelling resource for computational social scientists, complementary to online social networks, with the potential to yield novel insights into the behavior of public figures and how it is captured in the news.",
      "authors": [
        "Marko \\v{C}uljak",
        "Robert West",
        "Andreas Spitz",
        "Akhil Arora"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:53:32+00:00",
          "link": "https://arxiv.org/abs/2507.17626v1",
          "size": "732kb",
          "version": "v1"
        }
      ],
      "title": "Quotegraph: A Social Network Extracted from Millions of News Quotations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17626",
        "HTML": "https://arxiv.org/html/2507.17626v1",
        "PDF": "https://arxiv.org/pdf/2507.17626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Quotegraph is a social network dataset derived from news quotations. Although it involves data extraction and processing, it is intended for social network analysis, not related specifically to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17628",
      "abstract": "The valuation of Cyber Threat Intelligence (CTI) remains a persistent challenge due to the problem of negative evidence: successful threat prevention results in non-events that generate minimal observable financial impact, making CTI expenditures difficult to justify within traditional cost-benefit frameworks. This study introduces a data-driven methodology for quantifying the return on investment (ROI) of CTI, thereby reframing it as a measurable contributor to risk mitigation. The proposed framework extends established models in security economics, including the Gordon-Loeb and FAIR models, to account for CTI's complex influence on both the probability of security breaches and the severity of associated losses. The framework is operationalized through empirically grounded performance indicators, such as reductions in mean time to detect (MTTD), mean time to respond (MTTR), and adversary dwell time, supported by three sector-specific case studies in finance, healthcare, and retail. To address limitations in conventional linear assessment methodologies, the Threat Intelligence Effectiveness Index (TIEI) is introduced as a composite metric based on a weighted geometric mean. TIEI penalizes underperformance across critical dimensions: quality, enrichment, integration, and operational impact; thereby capturing bottleneck effect where the least effective component limits overall performance. By integrating financial quantification, adversarial coverage, and qualitative assessments of business enablement, the proposed hybrid model converts negative evidence into a justifiable ROI explanation. This approach offers a replicable means of repositioning CTI from an expense to a strategic investment, enabling informed decision-making and continuous optimization across diverse organizational contexts.",
      "authors": [
        "Matteo Strada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:54:56+00:00",
          "link": "https://arxiv.org/abs/2507.17628v1",
          "size": "140kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying the ROI of Cyber Threat Intelligence: A Data-Driven Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17628",
        "HTML": "https://arxiv.org/html/2507.17628v1",
        "PDF": "https://arxiv.org/pdf/2507.17628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantifying the return on investment of Cyber Threat Intelligence and does not relate to LLM training data processing or contribute any dataset or data processing insights for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17634",
      "abstract": "Recent advances in learning rate (LR) scheduling have demonstrated the effectiveness of decay-free approaches that eliminate the traditional decay phase while maintaining competitive performance. Model merging techniques have emerged as particularly promising solutions in this domain. We present Warmup-Stable and Merge (WSM), a general framework that establishes a formal connection between learning rate decay and model merging. WSM provides a unified theoretical foundation for emulating various decay strategies-including cosine decay, linear decay and inverse square root decay-as principled model averaging schemes, while remaining fully compatible with diverse optimization methods. Through extensive experiments, we identify merge duration-the training window for checkpoint aggregation-as the most critical factor influencing model performance, surpassing the importance of both checkpoint interval and merge quantity. Our framework consistently outperforms the widely-adopted Warmup-Stable-Decay (WSD) approach across multiple benchmarks, achieving significant improvements of +3.5% on MATH, +2.9% on HumanEval, and +5.5% on MMLU-Pro. The performance advantages extend to supervised fine-tuning scenarios, highlighting WSM's potential for long-term model refinement.",
      "authors": [
        "Changxin Tian",
        "Jiapeng Wang",
        "Qian Zhao",
        "Kunlong Chen",
        "Jia Liu",
        "Ziqi Liu",
        "Jiaxin Mao",
        "Wayne Xin Zhao",
        "Zhiqiang Zhang",
        "Jun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:02:06+00:00",
          "link": "https://arxiv.org/abs/2507.17634v1",
          "size": "1325kb",
          "version": "v1"
        }
      ],
      "title": "WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM Pre-training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17634",
        "HTML": "https://arxiv.org/html/2507.17634v1",
        "PDF": "https://arxiv.org/pdf/2507.17634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The main focus of the paper is on learning rate scheduling and model merging techniques during LLM pretraining. While it may impact the training process, it does not present any novel methods or techniques specifically for data processing in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17636",
      "abstract": "Negative campaigning is a central feature of political competition, yet empirical research has been limited by the high cost and limited scalability of existing classification methods. This study makes two key contributions. First, it introduces zero-shot Large Language Models (LLMs) as a novel approach for cross-lingual classification of negative campaigning. Using benchmark datasets in ten languages, we demonstrate that LLMs achieve performance on par with native-speaking human coders and outperform conventional supervised machine learning approaches. Second, we leverage this novel method to conduct the largest cross-national study of negative campaigning to date, analyzing 18 million tweets posted by parliamentarians in 19 European countries between 2017 and 2022. The results reveal consistent cross-national patterns: governing parties are less likely to use negative messaging, while ideologically extreme and populist parties -- particularly those on the radical right -- engage in significantly higher levels of negativity. These findings advance our understanding of how party-level characteristics shape strategic communication in multiparty systems. More broadly, the study demonstrates the potential of LLMs to enable scalable, transparent, and replicable research in political communication across linguistic and cultural contexts.",
      "authors": [
        "Victor Hartman",
        "Petter T\\\"ornberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:02:52+00:00",
          "link": "https://arxiv.org/abs/2507.17636v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17636",
        "HTML": "https://arxiv.org/html/2507.17636v1",
        "PDF": "https://arxiv.org/pdf/2507.17636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper applies existing LLMs for cross-lingual classification in political communication rather than addressing data processing for LLMs or contributing new datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17638",
      "abstract": "We study the problem of learning clusters of partially observed linear dynamical systems from multiple input-output trajectories. This setting is particularly relevant when there are limited observations (e.g., short trajectories) from individual data sources, making direct estimation challenging. In such cases, incorporating data from multiple related sources can improve learning. We propose an estimation algorithm that leverages different data requirements for the tasks of clustering and system identification. First, short impulse responses are estimated from individual trajectories and clustered. Then, refined models for each cluster are jointly estimated using multiple trajectories. We establish end-to-end finite sample guarantees for estimating Markov parameters and state space realizations and highlight trade-offs among the number of observed systems, the trajectory lengths, and the complexity of the underlying models.",
      "authors": [
        "Maryann Rui",
        "Munther A. Dahleh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:03:19+00:00",
          "link": "https://arxiv.org/abs/2507.17638v1",
          "size": "171kb",
          "version": "v1"
        }
      ],
      "title": "Learning clusters of partially observed linear dynamical systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17638",
        "HTML": "https://arxiv.org/html/2507.17638v1",
        "PDF": "https://arxiv.org/pdf/2507.17638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the clustering of linear dynamical systems using input-output trajectories and does not relate to LLM training data processing or development of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17640",
      "abstract": "Person identification in unconstrained viewing environments presents significant challenges due to variations in distance, viewpoint, imaging conditions, and clothing. We introduce $\\textbf{E}$va $\\textbf{C}$lothes-Change from $\\textbf{H}$idden $\\textbf{O}$bjects - $\\textbf{B}$ody $\\textbf{ID}$entification (ECHO-BID), a class of long-term re-id models built on object-pretrained EVA-02 Large backbones. We compare ECHO-BID to 9 other models that vary systematically in backbone architecture, model size, scale of object classification pretraining, and transfer learning protocol. Models were evaluated on benchmark datasets across constrained, unconstrained, and occluded settings. ECHO-BID, with transfer learning on the most challenging clothes-change data, achieved state-of-the-art results on long-term re-id -- substantially outperforming other methods. ECHO-BID also surpassed other methods by a wide margin in occluded viewing scenarios. A combination of increased model size and Masked Image Modeling during pretraining underlie ECHO-BID's strong performance on long-term re-id. Notably, a smaller, but more challenging transfer learning dataset, generalized better across datasets than a larger, less challenging one. However, the larger dataset with an additional fine-tuning step proved best on the most difficult data. Selecting the correct pretrained backbone architecture and transfer learning protocols can drive substantial gains in long-term re-id performance.",
      "authors": [
        "Thomas M. Metz",
        "Matthew Q. Hill",
        "Alice J. O'Toole"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:04:45+00:00",
          "link": "https://arxiv.org/abs/2507.17640v1",
          "size": "374kb",
          "version": "v1"
        }
      ],
      "title": "The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17640",
        "HTML": "https://arxiv.org/html/2507.17640v1",
        "PDF": "https://arxiv.org/pdf/2507.17640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores person identification models pre-trained on object classification tasks, focusing on model architecture and transfer learning, not on LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17647",
      "abstract": "Approximate nearest neighbor (ANN) search is a fundamental problem in computer science for which in-memory graph-based methods, such as Hierarchical Navigable Small World (HNSW), perform exceptionally well. To scale beyond billions of high-dimensional vectors, the index must be distributed. The disaggregated memory architecture physically separates compute and memory into two distinct hardware units and has become popular in modern data centers. Both units are connected via RDMA networks that allow compute nodes to directly access remote memory and perform all the computations, posing unique challenges for disaggregated indexes.\n  In this work, we propose a scalable HNSW index for ANN search in disaggregated memory. In contrast to existing distributed approaches, which partition the graph at the cost of accuracy, our method builds a graph-preserving index that reaches the same accuracy as a single-machine HNSW. Continuously fetching high-dimensional vector data from remote memory leads to severe network bandwidth limitations, which we overcome by employing an efficient caching mechanism. Since answering a single query involves processing numerous unique graph nodes, caching alone is not sufficient to achieve high scalability. We logically combine the caches of the compute nodes to increase the overall cache effectiveness and confirm the efficiency and scalability of our method in our evaluation.",
      "authors": [
        "Manuel Widmoser",
        "Daniel Kocher",
        "Nikolaus Augsten"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:09:10+00:00",
          "link": "https://arxiv.org/abs/2507.17647v1",
          "size": "2015kb",
          "version": "v1"
        }
      ],
      "title": "SHINE: A Scalable HNSW Index in Disaggregated Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17647",
        "HTML": "https://arxiv.org/html/2507.17647v1",
        "PDF": "https://arxiv.org/pdf/2507.17647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scalable HNSW index for ANN search in disaggregated memory, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17649",
      "abstract": "Accurate event detection is key to the successful design of semi-passive and powered prosthetics. Kinematically, the natural knee is complex, with translation and rotation components that have a substantial impact on gait characteristics. When simplified to a pin joint, some of this behaviour is lost. This study investigates the role of cruciate ligament stretch in event detection. A bicondylar knee design was used, constrained by analogues of the anterior and posterior cruciate ligaments. This offers the ability to characterize knee kinematics by the stretch of the ligaments. The ligament stretch was recorded using LVDTs parallel to the ligaments of the Russell knee on a bent knee crutch. Which was used to capture data on a treadmill at 3 speeds. This study finds speed dependence within the stretch of the cruciate ligaments, prominently around 5\\% and 80\\% of the gait cycle for the posterior and anterior. The cycle profile remains consistent with speed; therefore, other static events such as the turning point feature at around 90\\% and 95\\% of the cycle, for the posterior and anterior, respectively, could be used as a predictive precursor for initial contact. Likewise at 90\\% and 95\\%, another pair of turning points that in this case could be used to predict foot flat. This concludes that the use of a bicondylar knee design could improve the detection of events during the gait cycle, and therefore could increase the accuracy of subsequent controllers for powered prosthetics.",
      "authors": [
        "J. D. Clark",
        "P. Ellison"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:14:08+00:00",
          "link": "https://arxiv.org/abs/2507.17649v1",
          "size": "2905kb",
          "version": "v1"
        }
      ],
      "title": "Event Detection for Active Lower Limb Prosthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17649",
        "HTML": "https://arxiv.org/html/2507.17649v1",
        "PDF": "https://arxiv.org/pdf/2507.17649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on event detection in prosthesis design, with no relation to LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17650",
      "abstract": "Ensemble Machine Learning (EML) techniques, especially stacking, have been shown to improve predictive performance by combining multiple base models. However, they are often criticized for their lack of interpretability. In this paper, we introduce XStacking, an effective and inherently explainable framework that addresses this limitation by integrating dynamic feature transformation with model-agnostic Shapley additive explanations. This enables stacked models to retain their predictive accuracy while becoming inherently explainable. We demonstrate the effectiveness of the framework on 29 datasets, achieving improvements in both the predictive effectiveness of the learning space and the interpretability of the resulting models. XStacking offers a practical and scalable solution for responsible ML.",
      "authors": [
        "Moncef Garouani",
        "Ayah Barhrhouj",
        "Olivier Teste"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:14:48+00:00",
          "link": "https://arxiv.org/abs/2507.17650v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "XStacking: Explanation-Guided Stacked Ensemble Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17650",
        "HTML": "https://arxiv.org/html/2507.17650v1",
        "PDF": "https://arxiv.org/pdf/2507.17650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presents XStacking for ensemble learning explainability and performance improvement, not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17651",
      "abstract": "An important challenge when using computer vision models in the real world is to evaluate their performance in potential out-of-distribution (OOD) scenarios. While simple synthetic corruptions are commonly applied to test OOD robustness, they often fail to capture nuisance shifts that occur in the real world. Recently, diffusion models have been applied to generate realistic images for benchmarking, but they are restricted to binary nuisance shifts. In this work, we introduce CNS-Bench, a Continuous Nuisance Shift Benchmark to quantify OOD robustness of image classifiers for continuous and realistic generative nuisance shifts. CNS-Bench allows generating a wide range of individual nuisance shifts in continuous severities by applying LoRA adapters to diffusion models. To address failure cases, we propose a filtering mechanism that outperforms previous methods, thereby enabling reliable benchmarking with generative models. With the proposed benchmark, we perform a large-scale study to evaluate the robustness of more than 40 classifiers under various nuisance shifts. Through carefully designed comparisons and analyses, we find that model rankings can change for varying shifts and shift scales, which cannot be captured when applying common binary shifts. Additionally, we show that evaluating the model performance on a continuous scale allows the identification of model failure points, providing a more nuanced understanding of model robustness. Project page including code and data: https://genintel.github.io/CNS.",
      "authors": [
        "Olaf D\\\"unkel",
        "Artur Jesslen",
        "Jiahao Xie",
        "Christian Theobalt",
        "Christian Rupprecht",
        "Adam Kortylewski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:15:48+00:00",
          "link": "https://arxiv.org/abs/2507.17651v1",
          "size": "22916kb",
          "version": "v1"
        }
      ],
      "title": "CNS-Bench: Benchmarking Image Classifier Robustness Under Continuous Nuisance Shifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17651",
        "HTML": "https://arxiv.org/html/2507.17651v1",
        "PDF": "https://arxiv.org/pdf/2507.17651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "CNS-Bench develops a benchmark for image classifier robustness under OOD conditions, without focus on LLM or language model data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17653",
      "abstract": "Multi-annotator learning traditionally aggregates diverse annotations to approximate a single ground truth, treating disagreements as noise. However, this paradigm faces fundamental challenges: subjective tasks often lack absolute ground truth, and sparse annotation coverage makes aggregation statistically unreliable. We introduce a paradigm shift from sample-wise aggregation to annotator-wise behavior modeling. By treating annotator disagreements as valuable information rather than noise, modeling annotator-specific behavior patterns can reconstruct unlabeled data to reduce annotation cost, enhance aggregation reliability, and explain annotator decision behavior. To this end, we propose QuMATL (Query-based Multi-Annotator Behavior Pattern Learning), which uses light-weight queries to model individual annotators while capturing inter-annotator correlations as implicit regularization, preventing overfitting to sparse individual data while maintaining individualization and improving generalization, with a visualization of annotator focus regions offering an explainable analysis of behavior understanding. We contribute two large-scale datasets with dense per-annotator labels: STREET (4,300 labels/annotator) and AMER (average 3,118 labels/annotator), the first multimodal multi-annotator dataset.",
      "authors": [
        "Liyun Zhang",
        "Zheng Lian",
        "Hong Liu",
        "Takanori Takebe",
        "Yuta Nakashima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:17:43+00:00",
          "link": "https://arxiv.org/abs/2507.17653v1",
          "size": "3318kb",
          "version": "v1"
        }
      ],
      "title": "QuMAB: Query-based Multi-annotator Behavior Pattern Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17653",
        "HTML": "https://arxiv.org/html/2507.17653v1",
        "PDF": "https://arxiv.org/pdf/2507.17653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper tackles multi-annotator behavior modelling in data annotation and not related to LLM training data processing, fine-tuning, or dataset development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17654",
      "abstract": "Function-correcting codes are a coding framework designed to minimize redundancy while ensuring that specific functions or computations of encoded data can be reliably recovered, even in the presence of errors. The choice of metric is crucial in designing such codes, as it determines which computations must be protected and how errors are measured and corrected. Previous work by Liu and Liu [6] studied function-correcting codes over $\\mathbb{Z}_{2^l},\\ l\\geq 2$ using the homogeneous metric, which coincides with the Lee metric over $\\mathbb{Z}_4$. In this paper, we extend the study to codes over $\\mathbb{Z}_m,$ for any positive integer $m\\geq 2$ under the Lee metric and aim to determine their optimal redundancy. To achieve this, we introduce irregular Lee distance codes and derive upper and lower bounds on the optimal redundancy by characterizing the shortest possible length of such codes. These general bounds are then simplified and applied to specific classes of functions, including Lee-local functions, Lee weight functions, and Lee weight distribution functions, leading to improved some bounds compared to those of Liu and Liu [6] over $\\mathbb{Z}_4$ and generalize the other bounds over $\\mathbb{Z}_m$ in the Lee metric.",
      "authors": [
        "Gyanendra K. Verma and Abhay Kumar Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Discrete Mathematics (cs.DM)",
        "Information Retrieval (cs.IR)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:17:46+00:00",
          "link": "https://arxiv.org/abs/2507.17654v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "On Function-Correcting Codes in the Lee Metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17654",
        "HTML": "https://arxiv.org/html/2507.17654v1",
        "PDF": "https://arxiv.org/pdf/2507.17654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on function-correcting codes in the Lee metric, dealing with mathematical coding frameworks and redundancy minimization, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17655",
      "abstract": "As organizations rapidly migrate to the cloud, the security of cryptographic key management has become a growing concern. Hardware Security Modules (HSMs) and Trusted Platform Modules (TPMs), traditionally seen as the gold standard for securing encryption keys and digital trust, are increasingly challenged by cloud-native threats. Real-world breaches have exposed weaknesses in cloud deployments, including misconfigurations, API abuse, and privilege escalations, allowing attackers to access sensitive key material and bypass protections. These incidents reveal that while the hardware remains secure, the surrounding cloud ecosystem introduces systemic vulnerabilities. This paper analyzes notable security failures involving HSMs and TPMs, identifies common attack vectors, and questions longstanding assumptions about their effectiveness in distributed environments. We explore alternative approaches such as confidential computing, post-quantum cryptography, and decentralized key management. Our findings highlight that while HSMs and TPMs still play a role, modern cloud security requires more adaptive, layered architectures. By evaluating both current weaknesses and emerging models, this research equips cloud architects and security engineers with strategies to reinforce cryptographic trust in the evolving threat landscape.",
      "authors": [
        "Shams Shaikh and Trima P. Fernandes e Fizardo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:18:16+00:00",
          "link": "https://arxiv.org/abs/2507.17655v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17655",
        "HTML": "https://arxiv.org/html/2507.17655v1",
        "PDF": "https://arxiv.org/pdf/2507.17655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses security challenges associated with Hardware Security Modules (HSMs) and Trusted Platform Modules (TPMs) in cloud environments, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17657",
      "abstract": "We introduce a new interpretation of the attention matrix as a discrete-time Markov chain. Our interpretation sheds light on common operations involving attention scores such as selection, summation, and averaging in a unified framework. It further extends them by considering indirect attention, propagated through the Markov chain, as opposed to previous studies that only model immediate effects. Our main observation is that tokens corresponding to semantically similar regions form a set of metastable states, where the attention clusters, while noisy attention scores tend to disperse. Metastable states and their prevalence can be easily computed through simple matrix multiplication and eigenanalysis, respectively. Using these lightweight tools, we demonstrate state-of-the-art zero-shot segmentation. Lastly, we define TokenRank -- the steady state vector of the Markov chain, which measures global token importance. We demonstrate that using it brings improvements in unconditional image generation. We believe our framework offers a fresh view of how tokens are being attended in modern visual transformers.",
      "authors": [
        "Yotam Erel",
        "Olaf D\\\"unkel",
        "Rishabh Dabral",
        "Vladislav Golyanik",
        "Christian Theobalt",
        "Amit H. Bermano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:20:47+00:00",
          "link": "https://arxiv.org/abs/2507.17657v1",
          "size": "19250kb",
          "version": "v1"
        }
      ],
      "title": "Attention (as Discrete-Time Markov) Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17657",
        "HTML": "https://arxiv.org/html/2507.17657v1",
        "PDF": "https://arxiv.org/pdf/2507.17657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a novel interpretation of the attention mechanism as a Markov chain within the context of visual transformers. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17659",
      "abstract": "Multimodal Large Language Models (MLLMs) have pushed the frontiers of Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is fundamentally bottlenecked by a reliance on uni-dimensional evidence. This \"seeing only the trees, but not the forest\" approach prevents robust, multi-faceted understanding. Inspired by the principle of seeing both the forest and trees, we propose Synergos-VQA, a novel synergistic reasoning framework. At its core, Synergos-VQA concurrently generates and fuses three complementary evidence streams at inference time: (1) Holistic Evidence to perceive the entire scene (the \"forest\"), (2) Structural Evidence from a prototype-driven module to identify key objects (the \"trees\"), and (3) Causal Evidence from a counterfactual probe to ensure the reasoning is robustly grounded. By synergistically fusing this multi-faceted evidence, our framework achieves a more comprehensive and reliable reasoning process. Extensive experiments show that Synergos-VQA decisively establishes a new state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA. Furthermore, our approach demonstrates strong plug-and-play capabilities, significantly boosting various open-source MLLMs and proving that superior methodological design can outperform sheer model scale.",
      "authors": [
        "Junjie Wang",
        "Yunhan Tang",
        "Yijie Wang",
        "Zhihao Yuan",
        "Huan Wang",
        "Yangfan He",
        "Bin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.17659v1",
          "size": "1576kb",
          "version": "v1"
        }
      ],
      "title": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17659",
        "HTML": "https://arxiv.org/html/2507.17659v1",
        "PDF": "https://arxiv.org/pdf/2507.17659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a synergistic reasoning framework for knowledge-based visual question answering, concentrating on reasoning processes rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17661",
      "abstract": "Monocular Semantic Scene Completion (MSSC) aims to predict the voxel-wise occupancy and semantic category from a single-view RGB image. Existing methods adopt a single-stage framework that aims to simultaneously achieve visible region segmentation and occluded region hallucination, while also being affected by inaccurate depth estimation. Such methods often achieve suboptimal performance, especially in complex scenes. We propose a novel two-stage framework that decomposes MSSC into coarse MSSC followed by the Masked Recurrent Network. Specifically, we propose the Masked Sparse Gated Recurrent Unit (MS-GRU) which concentrates on the occupied regions by the proposed mask updating mechanism, and a sparse GRU design is proposed to reduce the computation cost. Additionally, we propose the distance attention projection to reduce projection errors by assigning different attention scores according to the distance to the observed surface. Experimental results demonstrate that our proposed unified framework, MonoMRN, effectively supports both indoor and outdoor scenes and achieves state-of-the-art performance on the NYUv2 and SemanticKITTI datasets. Furthermore, we conduct robustness analysis under various disturbances, highlighting the role of the Masked Recurrent Network in enhancing the model's resilience to such challenges. The source code is publicly available.",
      "authors": [
        "Xuzhi Wang",
        "Xinran Wu",
        "Song Wang",
        "Lingdong Kong",
        "Ziping Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.17661v1",
          "size": "5040kb",
          "version": "v1"
        }
      ],
      "title": "Monocular Semantic Scene Completion via Masked Recurrent Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17661",
        "PDF": "https://arxiv.org/pdf/2507.17661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research pertains to semantic scene completion using novel network techniques, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17664",
      "abstract": "Event cameras offer microsecond-level latency and robustness to motion blur, making them ideal for understanding dynamic environments. Yet, connecting these asynchronous streams to human language remains an open challenge. We introduce Talk2Event, the first large-scale benchmark for language-driven object grounding in event-based perception. Built from real-world driving data, we provide over 30,000 validated referring expressions, each enriched with four grounding attributes -- appearance, status, relation to viewer, and relation to other objects -- bridging spatial, temporal, and relational reasoning. To fully exploit these cues, we propose EventRefer, an attribute-aware grounding framework that dynamically fuses multi-attribute representations through a Mixture of Event-Attribute Experts (MoEE). Our method adapts to different modalities and scene dynamics, achieving consistent gains over state-of-the-art baselines in event-only, frame-only, and event-frame fusion settings. We hope our dataset and approach will establish a foundation for advancing multimodal, temporally-aware, and language-driven perception in real-world robotics and autonomy.",
      "authors": [
        "Lingdong Kong",
        "Dongyue Lu",
        "Ao Liang",
        "Rong Li",
        "Yuhao Dong",
        "Tianshuai Hu",
        "Lai Xing Ng",
        "Wei Tsang Ooi",
        "Benoit R. Cottereau"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:29:52+00:00",
          "link": "https://arxiv.org/abs/2507.17664v1",
          "size": "19016kb",
          "version": "v1"
        }
      ],
      "title": "Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17664",
        "PDF": "https://arxiv.org/pdf/2507.17664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark and framework for event-based perception in robotics, focusing on language-driven object grounding. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17665",
      "abstract": "With the rise of robotics, LiDAR-based 3D object detection has garnered significant attention in both academia and industry. However, existing datasets and methods predominantly focus on vehicle-mounted platforms, leaving other autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET, the first benchmark featuring LiDAR data and 3D bounding box annotations collected from multiple platforms: vehicle, quadruped, and drone, thereby facilitating research in 3D object detection for non-vehicle platforms as well as cross-platform 3D detection. Based on Pi3DET, we propose a novel cross-platform adaptation framework that transfers knowledge from the well-studied vehicle platform to other platforms. This framework achieves perspective-invariant 3D detection through robust alignment at both geometric and feature levels. Additionally, we establish a benchmark to evaluate the resilience and robustness of current 3D detectors in cross-platform scenarios, providing valuable insights for developing adaptive 3D perception systems. Extensive experiments validate the effectiveness of our approach on challenging cross-platform tasks, demonstrating substantial gains over existing adaptation methods. We hope this work paves the way for generalizable and unified 3D perception systems across diverse and complex environments. Our Pi3DET dataset, cross-platform benchmark suite, and annotation toolkit have been made publicly available.",
      "authors": [
        "Ao Liang",
        "Lingdong Kong",
        "Dongyue Lu",
        "Youquan Liu",
        "Jian Fang",
        "Huaici Zhao",
        "Wei Tsang Ooi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:29:57+00:00",
          "link": "https://arxiv.org/abs/2507.17665v1",
          "size": "19159kb",
          "version": "v1"
        }
      ],
      "title": "Perspective-Invariant 3D Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17665",
        "PDF": "https://arxiv.org/pdf/2507.17665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a benchmark and framework for perspective-invariant 3D object detection across different platforms. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17668",
      "abstract": "The process of meta-learning algorithms from data, instead of relying on manual design, is growing in popularity as a paradigm for improving the performance of machine learning systems. Meta-learning shows particular promise for reinforcement learning (RL), where algorithms are often adapted from supervised or unsupervised learning despite their suboptimality for RL. However, until now there has been a severe lack of comparison between different meta-learning algorithms, such as using evolution to optimise over black-box functions or LLMs to propose code. In this paper, we carry out this empirical comparison of the different approaches when applied to a range of meta-learned algorithms which target different parts of the RL pipeline. In addition to meta-train and meta-test performance, we also investigate factors including the interpretability, sample cost and train time for each meta-learning algorithm. Based on these findings, we propose several guidelines for meta-learning new RL algorithms which will help ensure that future learned algorithms are as performant as possible.",
      "authors": [
        "Alexander David Goldie",
        "Zilin Wang",
        "Jakob Nicolaus Foerster",
        "Shimon Whiteson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:31:38+00:00",
          "link": "https://arxiv.org/abs/2507.17668v1",
          "size": "929kb",
          "version": "v1"
        }
      ],
      "title": "How Should We Meta-Learn Reinforcement Learning Algorithms?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17668",
        "HTML": "https://arxiv.org/html/2507.17668v1",
        "PDF": "https://arxiv.org/pdf/2507.17668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates meta-learning approaches in the context of reinforcement learning but does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17673",
      "abstract": "Iterative solvers for large-scale linear systems such as Krylov subspace methods can diverge when the linear system is ill-conditioned, thus significantly reducing the applicability of these iterative methods in practice for high-performance computing solutions of such large-scale linear systems. To address this fundamental problem, we propose general algorithmic frameworks to modify Krylov subspace iterative solution methods which ensure that the algorithms are stable and do not diverge. We then apply our general frameworks to current implementations of the corresponding iterative methods in SciPy and demonstrate the efficacy of our stable iterative approach with respect to numerical experiments across a wide range of synthetic and real-world ill-conditioned linear systems.",
      "authors": [
        "Vasileios Kalantzis",
        "Mark S. Squillante",
        "Chai Wah Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Data Structures and Algorithms (cs.DS)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:35:04+00:00",
          "link": "https://arxiv.org/abs/2507.17673v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "Stable Iterative Solvers for Ill-conditioned Linear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17673",
        "HTML": "https://arxiv.org/html/2507.17673v1",
        "PDF": "https://arxiv.org/pdf/2507.17673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses iterative solvers for ill-conditioned linear systems in high-performance computing, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17679",
      "abstract": "Autonomous drones have gained considerable attention for applications in real-world scenarios, such as search and rescue, inspection, and delivery. As their use becomes ever more pervasive in civilian applications, failure to ensure safe operation can lead to physical damage to the system, environmental pollution, and even loss of human life. Recent work has demonstrated that motion planning techniques effectively generate a collision-free trajectory during navigation. However, these methods, while creating the motion plans, do not inherently consider the safe operational region of the system, leading to potential safety constraints violation during deployment. In this paper, we propose a method that leverages run time safety assurance in a kinodynamic motion planning scheme to satisfy the system's operational constraints. First, we use a sampling-based geometric planner to determine a high-level collision-free path within a user-defined space. Second, we design a low-level safety assurance filter to provide safety guarantees to the control input of a Linear Quadratic Regulator (LQR) designed with the purpose of trajectory tracking. We demonstrate our proposed approach in a restricted 3D simulation environment using a model of the Crazyflie 2.0 drone.",
      "authors": [
        "Theodoros Tavoulareas",
        "Marzia Cescon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:42:12+00:00",
          "link": "https://arxiv.org/abs/2507.17679v1",
          "size": "1756kb",
          "version": "v1"
        }
      ],
      "title": "Safety Assurance for Quadrotor Kinodynamic Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17679",
        "HTML": "https://arxiv.org/html/2507.17679v1",
        "PDF": "https://arxiv.org/pdf/2507.17679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with safety assurance for quadrotor motion planning and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17680",
      "abstract": "Understanding socio-ecological systems requires insights from diverse stakeholder perspectives, which are often hard to access. To enable alternative, simulation-based exploration of different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) to represent various stakeholders; users can step into the agent roles to experience perspectival differences. A simulation protocol serves as a \"scaffold\" to streamline multiple perspective-taking simulations, supporting users in reflecting on, transitioning between, and integrating across perspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional dynamics and land use change, enabling both narrative-driven and numerical experiments. In an illustrative experiment, a user successively adopts the perspectives of a system observer and a researcher - a role that analyses data from the embedded land use model to inform evidence-based decision-making for other LLM agents representing various institutions. Despite the user's effort to recommend technically sound policies, discrepancies persist between the policy recommendation and implementation due to stakeholders' competing advocacies, mirroring real-world misalignment between researcher and policymaker perspectives. The user's reflection highlights the subjective feelings of frustration and disappointment as a researcher, especially due to the challenge of maintaining political neutrality while attempting to gain political influence. Despite this, the user exhibits high motivation to experiment with alternative narrative framing strategies, suggesting the system's potential in exploring different perspectives. Further system and protocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-ecological simulations.",
      "authors": [
        "Yongchao Zeng",
        "Calum Brown",
        "Ioannis Kyriakou",
        "Ronja Hotz",
        "Mark Rounsevell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:42:51+00:00",
          "link": "https://arxiv.org/abs/2507.17680v1",
          "size": "2877kb",
          "version": "v1"
        }
      ],
      "title": "Simulating multiple human perspectives in socio-ecological systems using large language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17680",
        "PDF": "https://arxiv.org/pdf/2507.17680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper leverages LLMs to simulate stakeholder perspectives in socio-ecological systems, but its main focus is on simulation and perspective-taking rather than on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17682",
      "abstract": "Accurate classification of articulatory-phonological features plays a vital role in understanding human speech production and developing robust speech technologies, particularly in clinical contexts where targeted phonemic analysis and therapy can improve disease diagnosis accuracy and personalized rehabilitation. In this work, we propose a multimodal deep learning framework that combines real-time magnetic resonance imaging (rtMRI) and speech signals to classify three key articulatory dimensions: manner of articulation, place of articulation, and voicing. We perform classification on 15 phonological classes derived from the aforementioned articulatory dimensions and evaluate the system with four audio/vision configurations: unimodal rtMRI, unimodal audio signals, multimodal middle fusion, and contrastive learning-based audio-vision fusion. Experimental results on the USC-TIMIT dataset show that our contrastive learning-based approach achieves state-of-the-art performance, with an average F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal baseline. The results confirm the effectiveness of contrastive representation learning for multimodal articulatory analysis. Our code and processed dataset will be made publicly available at https://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.",
      "authors": [
        "Daiqi Liu",
        "Tom\\'as Arias-Vergara",
        "Jana Hutter",
        "Andreas Maier and Paula Andrea P\\'erez-Toro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:44:22+00:00",
          "link": "https://arxiv.org/abs/2507.17682v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Audio-Vision Contrastive Learning for Phonological Class Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17682",
        "HTML": "https://arxiv.org/html/2507.17682v1",
        "PDF": "https://arxiv.org/pdf/2507.17682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores audio-vision contrastive learning for phonological class recognition, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17684",
      "abstract": "Dual discriminator generative adversarial networks (D2 GANs) were introduced to mitigate the problem of mode collapse in generative adversarial networks. In D2 GANs, two discriminators are employed alongside a generator: one discriminator rewards high scores for samples from the true data distribution, while the other favors samples from the generator. In this work, we first introduce dual discriminator $\\alpha$-GANs (D2 $\\alpha$-GANs), which combines the strengths of dual discriminators with the flexibility of a tunable loss function, $\\alpha$-loss. We further generalize this approach to arbitrary functions defined on positive reals, leading to a broader class of models we refer to as generalized dual discriminator generative adversarial networks. For each of these proposed models, we provide theoretical analysis and show that the associated min-max optimization reduces to the minimization of a linear combination of an $f$-divergence and a reverse $f$-divergence. This generalizes the known simplification for D2-GANs, where the objective reduces to a linear combination of the KL-divergence and the reverse KL-divergence. Finally, we perform experiments on 2D synthetic data and use multiple performance metrics to capture various advantages of our GANs.",
      "authors": [
        "Penukonda Naga Chandana",
        "Tejas Srivastava",
        "Gowtham R. Kurri",
        "V. Lalitha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:46:03+00:00",
          "link": "https://arxiv.org/abs/2507.17684v1",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Dual Discriminator GANs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17684",
        "HTML": "https://arxiv.org/html/2507.17684v1",
        "PDF": "https://arxiv.org/pdf/2507.17684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces variations of GANs to address mode collapse, focusing on model architecture and optimization rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17685",
      "abstract": "We present a particle filtering algorithm for stochastic models on infinite dimensional state space, making use of Girsanov perturbations to nudge the ensemble of particles into regions of higher likelihood. We argue that the optimal control problem needs to couple control variables for all of the particles to maintain an ensemble with good effective sample size (ESS). We provide an optimisation formulation that separates the problem into three stages, separating the nonlinearity in the ESS term in the functional with the nonlinearity due to the forward problem, and allowing independent parallel computation for each particle when calculations are performed over control variable space. The particle filter is applied to the stochastic Kuramoto-Sivashinsky equation, and compared with the temper-jitter particle filter approach. We observe that whilst the nudging filter is over spread compared to the temper-jitter filter, it responds to extreme events in the assimilated data more quickly and robustly.",
      "authors": [
        "Maneesh Kumar Singh",
        "Joshua Hope-Collins",
        "Colin J. Cotter and Dan Crisan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:49:30+00:00",
          "link": "https://arxiv.org/abs/2507.17685v1",
          "size": "767kb",
          "version": "v1"
        }
      ],
      "title": "Data assimilation using a global Girsanov nudged particle filter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17685",
        "HTML": "https://arxiv.org/html/2507.17685v1",
        "PDF": "https://arxiv.org/pdf/2507.17685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a particle filtering algorithm for stochastic models and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17687",
      "abstract": "Graph class-incremental learning (GCIL) allows graph neural networks (GNNs) to adapt to evolving graph analytical tasks by incrementally learning new class knowledge while retaining knowledge of old classes. Existing GCIL methods primarily focus on a closed-set assumption, where all test samples are presumed to belong to previously known classes. Such an assumption restricts their applicability in real-world scenarios, where unknown classes naturally emerge during inference, and are absent during training. In this paper, we explore a more challenging open-set graph class-incremental learning scenario with two intertwined challenges: catastrophic forgetting of old classes, which impairs the detection of unknown classes, and inadequate open-set recognition, which destabilizes the retention of learned knowledge. To address the above problems, a novel OGCIL framework is proposed, which utilizes pseudo-sample embedding generation to effectively mitigate catastrophic forgetting and enable robust detection of unknown classes. To be specific, a prototypical conditional variational autoencoder is designed to synthesize node embeddings for old classes, enabling knowledge replay without storing raw graph data. To handle unknown classes, we employ a mixing-based strategy to generate out-of-distribution (OOD) samples from pseudo in-distribution and current node embeddings. A novel prototypical hypersphere classification loss is further proposed, which anchors in-distribution embeddings to their respective class prototypes, while repelling OOD embeddings away. Instead of assigning all unknown samples into one cluster, our proposed objective function explicitly models them as outliers through prototype-aware rejection regions, ensuring a robust open-set recognition. Extensive experiments on five benchmarks demonstrate the effectiveness of OGCIL over existing GCIL and open-set GNN methods.",
      "authors": [
        "Jiazhen Chen",
        "Zheng Ma",
        "Sichao Fu",
        "Mingbin Feng",
        "Tony S. Wirjanto",
        "Weihua Ou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:51:23+00:00",
          "link": "https://arxiv.org/abs/2507.17687v1",
          "size": "634kb",
          "version": "v1"
        }
      ],
      "title": "Towards Effective Open-set Graph Class-incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17687",
        "HTML": "https://arxiv.org/html/2507.17687v1",
        "PDF": "https://arxiv.org/pdf/2507.17687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores open-set graph class-incremental learning and addresses catastrophic forgetting in GNNs, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17688",
      "abstract": "Mindfulness training is widely recognized for its benefits in reducing depression, anxiety, and loneliness. With the rise of smartphone-based mindfulness apps, digital meditation has become more accessible, but sustaining long-term user engagement remains a challenge. This paper explores whether respiration biosignal feedback and mindfulness skill estimation enhance system usability and skill development. We develop a smartphone's accelerometer-based respiration tracking algorithm, eliminating the need for additional wearables. Unlike existing methods, our approach accurately captures slow breathing patterns typical of mindfulness meditation. Additionally, we introduce the first quantitative framework to estimate mindfulness skills-concentration, sensory clarity, and equanimity-based on accelerometer-derived respiration data. We develop and test our algorithms on 261 mindfulness sessions in both controlled and real-world settings. A user study comparing an experimental group receiving biosignal feedback with a control group using a standard app shows that respiration feedback enhances system usability. Our respiration tracking model achieves a mean absolute error (MAE) of 1.6 breaths per minute, closely aligning with ground truth data, while our mindfulness skill estimation attains F1 scores of 80-84% in tracking skill progression. By integrating respiration tracking and mindfulness estimation into a commercial app, we demonstrate the potential of smartphone sensors to enhance digital mindfulness training.",
      "authors": [
        "Mohammad Nur Hossain Khan",
        "David creswell",
        "Jordan Albert",
        "Patrick O'Connell",
        "Shawn Fallon",
        "Mathew Polowitz",
        "Xuhai \"orson\" Xu",
        "and Bashima islam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:52:42+00:00",
          "link": "https://arxiv.org/abs/2507.17688v1",
          "size": "2216kb",
          "version": "v1"
        }
      ],
      "title": "Mindfulness Meditation and Respiration: Accelerometer-Based Respiration Rate and Mindfulness Progress Estimation to Enhance App Engagement and Mindfulness Skills",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17688",
        "PDF": "https://arxiv.org/pdf/2507.17688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the development of respiration tracking algorithms for mindfulness meditation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17690",
      "abstract": "A commit message describes the main code changes in a commit and plays a crucial role in software maintenance. Existing commit message generation (CMG) approaches typically frame it as a direct mapping which inputs a code diff and produces a brief descriptive sentence as output. However, we argue that relying solely on the code diff is insufficient, as raw code diff fails to capture the full context needed for generating high-quality and informative commit messages. In this paper, we propose a contextual code retrieval-based method called C3Gen to enhance CMG by retrieving commit-relevant code snippets from the repository and incorporating them into the model input to provide richer contextual information at the repository scope. In the experiments, we evaluated the effectiveness of C3Gen across various models using four objective and three subjective metrics. Meanwhile, we design and conduct a human evaluation to investigate how C3Gen-generated commit messages are perceived by human developers. The results show that by incorporating contextual code into the input, C3Gen enables models to effectively leverage additional information to generate more comprehensive and informative commit messages with greater practical value in real-world development scenarios. Further analysis underscores concerns about the reliability of similaritybased metrics and provides empirical insights for CMG.",
      "authors": [
        "Bo Xiong",
        "Linghao Zhang",
        "Chong Wang",
        "Peng Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.17690v1",
          "size": "300kb",
          "version": "v1"
        }
      ],
      "title": "Contextual Code Retrieval for Commit Message Generation: A Preliminary Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17690",
        "HTML": "https://arxiv.org/html/2507.17690v1",
        "PDF": "https://arxiv.org/pdf/2507.17690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for improving commit message generation by retrieving contextual code. It does not relate to LLM training data processing in any stage or operation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17691",
      "abstract": "Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.",
      "authors": [
        "Shan Jiang",
        "Pranoy Kovuri",
        "David Tao",
        "Zhixun Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:57:32+00:00",
          "link": "https://arxiv.org/abs/2507.17691v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "CASCADE: LLM-Powered JavaScript Deobfuscator at Google",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17691",
        "HTML": "https://arxiv.org/html/2507.17691v1",
        "PDF": "https://arxiv.org/pdf/2507.17691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a system called CASCADE for JavaScript deobfuscation using LLMs for enhanced software testing and analysis. It does not address LLM training data processing, pretraining, or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17692",
      "abstract": "Learning with noisy labels is a crucial task for training accurate deep neural networks. To mitigate label noise, prior studies have proposed various robust loss functions, particularly symmetric losses. Nevertheless, symmetric losses usually suffer from the underfitting issue due to the overly strict constraint. To address this problem, the Active Passive Loss (APL) jointly optimizes an active and a passive loss to mutually enhance the overall fitting ability. Within APL, symmetric losses have been successfully extended, yielding advanced robust loss functions. Despite these advancements, emerging theoretical analyses indicate that asymmetric losses, a new class of robust loss functions, possess superior properties compared to symmetric losses. However, existing asymmetric losses are not compatible with advanced optimization frameworks such as APL, limiting their potential and applicability. Motivated by this theoretical gap and the prospect of asymmetric losses, we extend the asymmetric loss to the more complex passive loss scenario and propose the Asymetric Mean Square Error (AMSE), a novel asymmetric loss. We rigorously establish the necessary and sufficient condition under which AMSE satisfies the asymmetric condition. By substituting the traditional symmetric passive loss in APL with our proposed AMSE, we introduce a novel robust loss framework termed Joint Asymmetric Loss (JAL). Extensive experiments demonstrate the effectiveness of our method in mitigating label noise. Code available at: https://github.com/cswjl/joint-asymmetric-loss",
      "authors": [
        "Jialiang Wang",
        "Xianming Liu",
        "Xiong Zhou",
        "Gangfeng Hu",
        "Deming Zhai",
        "Junjun Jiang",
        "Xiangyang Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:57:43+00:00",
          "link": "https://arxiv.org/abs/2507.17692v1",
          "size": "3569kb",
          "version": "v1"
        }
      ],
      "title": "Joint Asymmetric Loss for Learning with Noisy Labels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17692",
        "HTML": "https://arxiv.org/html/2507.17692v1",
        "PDF": "https://arxiv.org/pdf/2507.17692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study develops a new loss function, Joint Asymmetric Loss, for learning with noisy labels, which is unrelated to LLM training data processing. It focuses on model optimization rather than data operations or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17695",
      "abstract": "Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLM's input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.",
      "authors": [
        "Ilias Chatzistefanidis",
        "Navid Nikaein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:01:23+00:00",
          "link": "https://arxiv.org/abs/2507.17695v1",
          "size": "10133kb",
          "version": "v1"
        }
      ],
      "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17695",
        "HTML": "https://arxiv.org/html/2507.17695v1",
        "PDF": "https://arxiv.org/pdf/2507.17695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a paradigm for LLM-based agents in AGI networks, focusing on decision-making and optimization in 5G networks rather than LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17699",
      "abstract": "Large Reasoning Models (LRMs) have become a central focus in today's large language model (LLM) research, where models are designed to output a step-by-step thinking process before arriving at a final answer to handle complex reasoning tasks. Despite their promise, recent empirical studies (e.g., [Shojaee et al., 2025] from Apple) suggest that this thinking process may not actually enhance reasoning ability, where LLMs without explicit reasoning actually outperform LRMs on tasks with low or high complexity. In this work, we revisit these findings and investigate whether the limitations of LRMs persist when tool augmentations are introduced. We incorporate two types of tools, Python interpreters and scratchpads, and evaluate three representative LLMs and their LRM counterparts on Apple's benchmark reasoning puzzles. Our results show that, with proper tool use, LRMs consistently outperform their non-reasoning counterparts across all levels of task complexity. These findings challenge the recent narrative that reasoning is an illusion and highlight the potential of tool-augmented LRMs for solving complex problems.",
      "authors": [
        "Zhao Song",
        "Song Yue",
        "Jiahao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:04:20+00:00",
          "link": "https://arxiv.org/abs/2507.17699v1",
          "size": "437kb",
          "version": "v1"
        }
      ],
      "title": "Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17699",
        "HTML": "https://arxiv.org/html/2507.17699v1",
        "PDF": "https://arxiv.org/pdf/2507.17699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores Large Reasoning Models using tool augmentations to enhance reasoning tasks, focusing on model capabilities and evaluation rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17702",
      "abstract": "Mixture-of-Experts (MoE) has become a dominant architecture for scaling Large Language Models (LLMs) efficiently by decoupling total parameters from computational cost. However, this decoupling creates a critical challenge: predicting the model capacity of a given MoE configurations (e.g., expert activation ratio and granularity) remains an unresolved problem. To address this gap, we introduce Efficiency Leverage (EL), a metric quantifying the computational advantage of an MoE model over a dense equivalent. We conduct a large-scale empirical study, training over 300 models up to 28B parameters, to systematically investigate the relationship between MoE architectural configurations and EL. Our findings reveal that EL is primarily driven by the expert activation ratio and the total compute budget, both following predictable power laws, while expert granularity acts as a non-linear modulator with a clear optimal range. We integrate these discoveries into a unified scaling law that accurately predicts the EL of an MoE architecture based on its configuration. To validate our derived scaling laws, we designed and trained Ling-mini-beta, a pilot model for Ling-2.0 series with only 0.85B active parameters, alongside a 6.1B dense model for comparison. When trained on an identical 1T high-quality token dataset, Ling-mini-beta matched the performance of the 6.1B dense model while consuming over 7x fewer computational resources, thereby confirming the accuracy of our scaling laws. This work provides a principled and empirically-grounded foundation for the scaling of efficient MoE models.",
      "authors": [
        "Changxin Tian",
        "Kunlong Chen",
        "Jia Liu",
        "Ziqi Liu",
        "Zhiqiang Zhang",
        "Jun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:10:23+00:00",
          "link": "https://arxiv.org/abs/2507.17702v1",
          "size": "7017kb",
          "version": "v1"
        }
      ],
      "title": "Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17702",
        "HTML": "https://arxiv.org/html/2507.17702v1",
        "PDF": "https://arxiv.org/pdf/2507.17702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the study mainly investigates the scaling of Mixture-of-Experts models, it mentions training these models on a 1T high-quality token dataset. However, the focus is more on model architecture than on data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17703",
      "abstract": "This paper presents a method for the simultaneous synthesis of a barrier certificate and a safe controller for discrete-time nonlinear stochastic systems. Our approach, based on piecewise stochastic control barrier functions, reduces the synthesis problem to a minimax optimization, which we solve exactly using a dual linear program with zero gap. This enables the joint optimization of the barrier certificate and safe controller within a single formulation. The method accommodates stochastic dynamics with additive noise and a bounded continuous control set. The synthesized controllers and barrier certificates provide a formally guaranteed lower bound on probabilistic safety. Case studies on linear and nonlinear stochastic systems validate the effectiveness of our approach.",
      "authors": [
        "Rayan Mazouz",
        "Luca Laurenti",
        "Morteza Lahijanian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:10:54+00:00",
          "link": "https://arxiv.org/abs/2507.17703v1",
          "size": "1630kb",
          "version": "v1"
        }
      ],
      "title": "Piecewise Control Barrier Functions for Stochastic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17703",
        "HTML": "https://arxiv.org/html/2507.17703v1",
        "PDF": "https://arxiv.org/pdf/2507.17703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on barrier certificates and safe controllers for stochastic systems, which lacks any mention of LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17706",
      "abstract": "Large language models (LLMs) often leverage adapters, such as low-rank-based adapters, to achieve strong performance on downstream tasks. However, storing a separate adapter for each task significantly increases memory requirements, posing a challenge for resource-constrained environments such as mobile devices. Although model merging techniques can reduce storage costs, they typically result in substantial performance degradation. In this work, we introduce HydraOpt, a new model merging technique that capitalizes on the inherent similarities between the matrices of low-rank adapters. Unlike existing methods that produce a fixed trade-off between storage size and performance, HydraOpt allows us to navigate this spectrum of efficiency and performance. Our experiments show that HydraOpt significantly reduces storage size (48% reduction) compared to storing all adapters, while achieving competitive performance (0.2-1.8% drop). Furthermore, it outperforms existing merging techniques in terms of performance at the same or slightly worse storage efficiency.",
      "authors": [
        "Taha Ceritli",
        "Ondrej Bohdal",
        "Mete Ozay",
        "Jijoong Moon",
        "Kyeng-Hun Lee",
        "Hyeonmok Ko",
        "Umberto Michieli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:12:19+00:00",
          "link": "https://arxiv.org/abs/2507.17706v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "HydraOpt: Navigating the Efficiency-Performance Trade-off of Adapter Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17706",
        "HTML": "https://arxiv.org/html/2507.17706v1",
        "PDF": "https://arxiv.org/pdf/2507.17706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses HydraOpt, a technique to optimize storage and performance of adapters used in LLMs, it primarily deals with model optimization techniques rather than data processing for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17709",
      "abstract": "We present TyDi QA-WANA, a question-answering dataset consisting of 28K examples divided among 10 language varieties of western Asia and northern Africa. The data collection process was designed to elicit information-seeking questions, where the asker is genuinely curious to know the answer. Each question in paired with an entire article that may or may not contain the answer; the relatively large size of the articles results in a task suitable for evaluating models' abilities to utilize large text contexts in answering questions. Furthermore, the data was collected directly in each language variety, without the use of translation, in order to avoid issues of cultural relevance. We present performance of two baseline models, and release our code and data to facilitate further improvement by the research community.",
      "authors": [
        "Parker Riley",
        "Siamak Shakeri",
        "Waleed Ammar",
        "Jonathan H. Clark"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:20:28+00:00",
          "link": "https://arxiv.org/abs/2507.17709v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "TyDi QA-WANA: A Benchmark for Information-Seeking Question Answering in Languages of West Asia and North Africa",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17709",
        "HTML": "https://arxiv.org/html/2507.17709v1",
        "PDF": "https://arxiv.org/pdf/2507.17709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the TyDi QA-WANA, a new dataset for QA in multiple languages, contributing to training data processing by creating a new, linguistically diverse dataset for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17711",
      "abstract": "Rare events in Stochastic Vector Addition System (VAS) are of significant interest because, while extremely unlikely, they may represent undesirable behavior that can have adverse effects. Their low probabilities and potentially extremely large state spaces challenge existing probabilistic model checking and stochastic rare-event simulation techniques. In particular, in Chemical Reaction Networks (CRNs), a chemical kinetic language often represented as VAS, rare event effects may be pathological. We present two novel heuristics for priority-first partial state space expansion and trace generation tuned to the transient analysis of rare-event probability in VAS: Iterative Subspace Reduction (ISR) and Single Distance Priority (SDP). Both methods construct a closed vector space containing all solution states. SDP then simply prioritizes shorter distances to this ``solution space'', while ISR constructs a set of nested subspaces, where short and highly-probable satisfying traces are likely to pass through in sequence. The resulting partial state graph from each method contains likely traces to rare-event states, allowing efficient probabilistic model checking to compute a lower-bound probability of a rare event of interest. These methods are deterministic, fast, and demonstrate marked performance on challenging CRN models.",
      "authors": [
        "Joshua Jeppson",
        "Landon Taylor",
        "Bingqing Hu",
        "Zhen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:21:59+00:00",
          "link": "https://arxiv.org/abs/2507.17711v1",
          "size": "85kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning about Rare-Event Reachability in Stochastic Vector Addition Systems via Affine Vector Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17711",
        "PDF": "https://arxiv.org/pdf/2507.17711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus on rare-event reachability in stochastic vector addition systems is unrelated to LLM training data processing or the development of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17717",
      "abstract": "AI-generated clinical notes are increasingly used in healthcare, but evaluating their quality remains a challenge due to high subjectivity and limited scalability of expert review. Existing automated metrics often fail to align with real-world physician preferences. To address this, we propose a pipeline that systematically distills real user feedback into structured checklists for note evaluation. These checklists are designed to be interpretable, grounded in human feedback, and enforceable by LLM-based evaluators. Using deidentified data from over 21,000 clinical encounters, prepared in accordance with the HIPAA safe harbor standard, from a deployed AI medical scribe system, we show that our feedback-derived checklist outperforms baseline approaches in our offline evaluations in coverage, diversity, and predictive power for human ratings. Extensive experiments confirm the checklist's robustness to quality-degrading perturbations, significant alignment with clinician preferences, and practical value as an evaluation methodology. In offline research settings, the checklist can help identify notes likely to fall below our chosen quality thresholds.",
      "authors": [
        "Karen Zhou",
        "John Giorgi",
        "Pranav Mani",
        "Peng Xu",
        "Davis Liang",
        "Chenhao Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:28:31+00:00",
          "link": "https://arxiv.org/abs/2507.17717v1",
          "size": "2258kb",
          "version": "v1"
        }
      ],
      "title": "From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17717",
        "HTML": "https://arxiv.org/html/2507.17717v1",
        "PDF": "https://arxiv.org/pdf/2507.17717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While focusing on the evaluation of AI-generated clinical notes through a feedback-derived checklist, it relates to LLMs indirectly. The paper's contribution lies in note evaluation rather than the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17718",
      "abstract": "With the rise of voice-enabled artificial intelligence (AI) systems, quantitative survey researchers have access to a new data-collection mode: AI telephone surveying. By using AI to conduct phone interviews, researchers can scale quantitative studies while balancing the dual goals of human-like interactivity and methodological rigor. Unlike earlier efforts that used interactive voice response (IVR) technology to automate these surveys, voice AI enables a more natural and adaptive respondent experience as it is more robust to interruptions, corrections, and other idiosyncrasies of human speech.\n  We built and tested an AI system to conduct quantitative surveys based on large language models (LLM), automatic speech recognition (ASR), and speech synthesis technologies. The system was specifically designed for quantitative research, and strictly adhered to research best practices like question order randomization, answer order randomization, and exact wording.\n  To validate the system's effectiveness, we deployed it to conduct two pilot surveys with the SSRS Opinion Panel and followed-up with a separate human-administered survey to assess respondent experiences. We measured three key metrics: the survey completion rates, break-off rates, and respondent satisfaction scores. Our results suggest that shorter instruments and more responsive AI interviewers may contribute to improvements across all three metrics studied.",
      "authors": [
        "Danny D. Leybzon",
        "Shreyas Tirumala",
        "Nishant Jain",
        "Summer Gillen",
        "Michael Jackson",
        "Cameron McPhee",
        "Jennifer Schmidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:30:14+00:00",
          "link": "https://arxiv.org/abs/2507.17718v1",
          "size": "2753kb",
          "version": "v1"
        }
      ],
      "title": "AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17718",
        "HTML": "https://arxiv.org/html/2507.17718v1",
        "PDF": "https://arxiv.org/pdf/2507.17718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces an AI-based system for conducting telephone surveys utilizing LLMs, ASR, and speech synthesis, but primarily focuses on data collection methodologies rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17722",
      "abstract": "Large language models (LLMs) are growingly extended to process multimodal data such as text and video simultaneously. Their remarkable performance in understanding what is shown in images is surpassing specialized neural networks (NNs) such as Yolo that is supporting only a well-formed but very limited vocabulary, ie., objects that they are able to detect. When being non-restricted, LLMs and in particular state-of-the-art vision language models (VLMs) show impressive performance to describe even complex traffic situations. This is making them potentially suitable components for automotive perception systems to support the understanding of complex traffic situations or edge case situation. However, LLMs and VLMs are prone to hallucination, which mean to either potentially not seeing traffic agents such as vulnerable road users who are present in a situation, or to seeing traffic agents who are not there in reality. While the latter is unwanted making an ADAS or autonomous driving systems (ADS) to unnecessarily slow down, the former could lead to disastrous decisions from an ADS. In our work, we are systematically assessing the performance of 3 state-of-the-art VLMs on a diverse subset of traffic situations sampled from the Waymo Open Dataset to support safety guardrails for capturing such hallucinations in VLM-supported perception systems. We observe that both, proprietary and open VLMs exhibit remarkable image understanding capabilities even paying thorough attention to fine details sometimes difficult to spot for us humans. However, they are also still prone to making up elements in their descriptions to date requiring hallucination detection strategies such as BetterCheck that we propose in our work.",
      "authors": [
        "Malsha Ashani Mahawatta Dona",
        "Beatriz Cabrero-Daniel",
        "Yinan Yu",
        "Christian Berger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:32:17+00:00",
          "link": "https://arxiv.org/abs/2507.17722v1",
          "size": "10506kb",
          "version": "v1"
        }
      ],
      "title": "BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17722",
        "HTML": "https://arxiv.org/html/2507.17722v1",
        "PDF": "https://arxiv.org/pdf/2507.17722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on assessing the performance of vision-language models in automotive perception systems and addressing hallucinations, not on training data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17723",
      "abstract": "Eliminating warpage in injection molded polymeric parts is one of the most important problems in the injection molding industry today. This situation is critical in geometries that are particularly susceptible to warping due to their geometric features, and this occurs with topologies of great length and slenderness with high changes in thickness. These features are, in these special geometries, impossible to manufacture with traditional technologies to meet the dimensional and sustainable requirements of the industry. This paper presents an innovative green conformal cooling system that is specifically designed for parts with slender geometric shapes that are highly susceptible to warping. Additionally, the work presented by the authors investigates the importance of using highly conductive inserts made of steel alloys in combination with the use of additively manufactured conformal channels for reducing influential parameters, such as warpage, cooling time, and residual stresses in the complex manufacturing of long and slender parts. The results of this real industrial case study indicated that the use of conformal cooling layouts decreased the cycle time by 175.1 s 66% below the current cooling time; the temperature gradient by 78.5% specifically, 18.16 C; the residual stress by 39.78 MPa or 81.88%; and the warpage by 6.9 mm or 90.5%. In this way, it was possible to achieve a final warping in the complex geometry studied of 0.72 mm, which was under the maximum value required at the industrial level of 1 mm. The resulting values obtained by the researchers present a turning point from which the manufacturing and sustainability in the injection molding of said plastic geometries is possible, and they take into account that the geometric manufacturing features analyzed will present a great demand in the coming years in the auto parts manufacturing industry.",
      "authors": [
        "Abelardo Torres Alba",
        "Jorge Manuel Mercado Colmenero",
        "Juan de Dios Caballero Garcia and Cristina Martin Donate"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:32:20+00:00",
          "link": "https://arxiv.org/abs/2507.17723v1",
          "size": "861kb",
          "version": "v1"
        }
      ],
      "title": "Application of new conformal cooling layouts to the green injection molding of complex slender polymeric parts with high dimensional specifications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17723",
        "PDF": "https://arxiv.org/pdf/2507.17723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about improving manufacturing processes in injection molding through the use of conformal cooling layouts, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17725",
      "abstract": "Modern neural networks are expected to simultaneously satisfy a host of desirable properties: accurate fitting to training data, generalization to unseen inputs, parameter and computational efficiency, and robustness to adversarial perturbations. While compressibility and robustness have each been studied extensively, a unified understanding of their interaction still remains elusive. In this work, we develop a principled framework to analyze how different forms of compressibility - such as neuron-level sparsity and spectral compressibility - affect adversarial robustness. We show that these forms of compression can induce a small number of highly sensitive directions in the representation space, which adversaries can exploit to construct effective perturbations. Our analysis yields a simple yet instructive robustness bound, revealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$ robustness via their effects on the learned representations. Crucially, the vulnerabilities we identify arise irrespective of how compression is achieved - whether via regularization, architectural bias, or implicit learning dynamics. Through empirical evaluations across synthetic and realistic tasks, we confirm our theoretical predictions, and further demonstrate that these vulnerabilities persist under adversarial training and transfer learning, and contribute to the emergence of universal adversarial perturbations. Our findings show a fundamental tension between structured compressibility and robustness, and suggest new pathways for designing models that are both efficient and secure.",
      "authors": [
        "Melih Barsbey and Ant\\^onio H. Ribeiro and Umut \\c{S}im\\c{s}ekli and Tolga Birdal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:35:48+00:00",
          "link": "https://arxiv.org/abs/2507.17725v1",
          "size": "522kb",
          "version": "v1"
        }
      ],
      "title": "On the Interaction of Compressibility and Adversarial Robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17725",
        "PDF": "https://arxiv.org/pdf/2507.17725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the interaction between compressibility and adversarial robustness in neural networks, without any mention of LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17727",
      "abstract": "State-of-the-art visual under-canopy navigation methods are designed with deep learning-based perception models to distinguish traversable space from crop rows. While these models have demonstrated successful performance, they require large amounts of training data to ensure reliability in real-world field deployment. However, data collection is costly, demanding significant human resources for in-field sampling and annotation. To address this challenge, various data augmentation techniques are commonly employed during model training, such as color jittering, Gaussian blur, and horizontal flip, to diversify training data and enhance model robustness. In this paper, we hypothesize that utilizing only these augmentation techniques may lead to suboptimal performance, particularly in complex under-canopy environments with frequent occlusions, debris, and non-uniform spacing of crops. Instead, we propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut) which masks random regions out in input images that are spatially distributed around crop rows on the sides to encourage trained models to capture high-level contextual features even when fine-grained information is obstructed. Our extensive experiments with a public cornfield dataset demonstrate that masking-based augmentations are effective for simulating occlusions and significantly improving robustness in semantic keypoint predictions for visual navigation. In particular, we show that biasing the mask distribution toward crop rows in CA-Cut is critical for enhancing both prediction accuracy and generalizability across diverse environments achieving up to a 36.9% reduction in prediction error. In addition, we conduct ablation studies to determine the number of masks, the size of each mask, and the spatial distribution of masks to maximize overall performance.",
      "authors": [
        "Robel Mamo",
        "Taeyeong Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:41:55+00:00",
          "link": "https://arxiv.org/abs/2507.17727v1",
          "size": "3258kb",
          "version": "v1"
        }
      ],
      "title": "CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17727",
        "HTML": "https://arxiv.org/html/2507.17727v1",
        "PDF": "https://arxiv.org/pdf/2507.17727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses CA-Cut, a data augmentation method designed to improve navigation models' robustness. While it involves data processing, its focus on augmentation for navigation models doesn't directly contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17728",
      "abstract": "We present Megrez2, a novel lightweight and high-performance language model architecture optimized for device native deployment. Megrez2 introduces a novel cross-layer expert sharing mechanism, which significantly reduces total parameter count by reusing expert modules across adjacent transformer layers while maintaining most of the model's capacity. It also incorporates pre-gated routing, enabling memory-efficient expert loading and faster inference. As the first instantiation of the Megrez2 architecture, we introduce the Megrez2-Preview model, which is pre-trained on a 5-trillion-token corpus and further enhanced through supervised fine-tuning and reinforcement learning with verifiable rewards. With only 3B activated and 7.5B stored parameters, Megrez2-Preview demonstrates competitive or superior performance compared to larger models on a wide range of tasks, including language understanding, instruction following, mathematical reasoning, and code generation. These results highlight the effectiveness of the Megrez2 architecture to achieve a balance between accuracy, efficiency, and deployability, making it a strong candidate for real-world, resource-constrained applications.",
      "authors": [
        "Boxun Li",
        "Yadong Li",
        "Zhiyuan Li",
        "Congyi Liu",
        "Weilin Liu",
        "Guowei Niu",
        "Zheyue Tan",
        "Haiyang Xu",
        "Zhuyu Yao",
        "Tao Yuan",
        "Dong Zhou",
        "Yueqing Zhuang",
        "Bo Zhao",
        "Guohao Dai",
        "Yu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:43:07+00:00",
          "link": "https://arxiv.org/abs/2507.17728v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "Megrez2 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17728",
        "HTML": "https://arxiv.org/html/2507.17728v1",
        "PDF": "https://arxiv.org/pdf/2507.17728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The Megrez2 paper's main focus is on introducing a novel language model architecture and optimization techniques, including pre-training on a large corpus. However, it does not explore innovative methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17729",
      "abstract": "Facial filters are now commonplace for social media users around the world. Previous work has demonstrated that facial filters can negatively impact automated face recognition performance. However, these studies focus on small numbers of hand-picked filters in particular styles. In order to more effectively incorporate the wide ranges of filters present on various social media applications, we introduce a framework that allows for larger-scale study of the impact of facial filters on automated recognition. This framework includes a controlled dataset of face images, a principled filter selection process that selects a representative range of filters for experimentation, and a set of experiments to evaluate the filters' impact on recognition. We demonstrate our framework with a case study of filters from the American applications Instagram and Snapchat and the Chinese applications Meitu and Pitu to uncover cross-cultural differences. Finally, we show how the filtering effect in a face embedding space can easily be detected and restored to improve face recognition performance.",
      "authors": [
        "Kagan Ozturk",
        "Louisa Conwill",
        "Jacob Gutierrez",
        "Kevin Bowyer",
        "Walter J. Scheirer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:43:35+00:00",
          "link": "https://arxiv.org/abs/2507.17729v1",
          "size": "3945kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Evaluation Framework for the Study of the Effects of Facial Filters on Face Recognition Accuracy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17729",
        "HTML": "https://arxiv.org/html/2507.17729v1",
        "PDF": "https://arxiv.org/pdf/2507.17729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for evaluating facial filters' effects on face recognition accuracy, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17730",
      "abstract": "Research communities have developed benchmark datasets across domains to compare the performance of algorithms and techniques However, tracking the progress in these research areas is not easy, as publications appear in different venues at the same time, and many of them claim to represent the state-of-the-art. To address this, research communities often organise periodic competitions to evaluate the performance of various algorithms and techniques, thereby tracking advancements in the field. However, these competitions pose a significant operational burden. The organisers must manage and evaluate a large volume of submissions. Furthermore, participants typically develop their solutions in diverse environments, leading to compatibility issues during the evaluation of their submissions. This paper presents an online competition system that automates the submission and evaluation process for a competition. The competition system allows organisers to manage large numbers of submissions efficiently, utilising isolated environments to evaluate submissions. This system has already been used successfully for several competitions, including the Grid-Based Pathfinding Competition and the League of Robot Runners competition.",
      "authors": [
        "Zhe Chen",
        "Daniel Harabor",
        "Ryan Hechnenberger",
        "Nathan R. Sturtevant"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:44:10+00:00",
          "link": "https://arxiv.org/abs/2507.17730v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "Online Submission and Evaluation System Design for Competition Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17730",
        "HTML": "https://arxiv.org/html/2507.17730v1",
        "PDF": "https://arxiv.org/pdf/2507.17730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on designing an online system for managing submissions and evaluations in competitions. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17731",
      "abstract": "Over the past decade, advances in generative modeling, such as generative adversarial networks, masked autoencoders, and diffusion models, have significantly transformed biological research and discovery, enabling breakthroughs in molecule design, protein generation, drug discovery, and beyond. At the same time, biological applications have served as valuable testbeds for evaluating the capabilities of generative models. Recently, flow matching has emerged as a powerful and efficient alternative to diffusion-based generative modeling, with growing interest in its application to problems in biology and life sciences. This paper presents the first comprehensive survey of recent developments in flow matching and its applications in biological domains. We begin by systematically reviewing the foundations and variants of flow matching, and then categorize its applications into three major areas: biological sequence modeling, molecule generation and design, and peptide and protein generation. For each, we provide an in-depth review of recent progress. We also summarize commonly used datasets and software tools, and conclude with a discussion of potential future directions. The corresponding curated resources are available at https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.",
      "authors": [
        "Zihao Li",
        "Zhichen Zeng",
        "Xiao Lin",
        "Feihao Fang",
        "Yanru Qu",
        "Zhe Xu",
        "Zhining Liu",
        "Xuying Ning",
        "Tianxin Wei",
        "Ge Liu",
        "Hanghang Tong",
        "Jingrui He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:44:29+00:00",
          "link": "https://arxiv.org/abs/2507.17731v1",
          "size": "1814kb",
          "version": "v1"
        }
      ],
      "title": "Flow Matching Meets Biology and Life Science: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17731",
        "HTML": "https://arxiv.org/html/2507.17731v1",
        "PDF": "https://arxiv.org/pdf/2507.17731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on flow matching in biological research and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17734",
      "abstract": "Creating aesthetically pleasing data visualizations remains challenging for users without design expertise or familiarity with visualization tools. To address this gap, we present DataWink, a system that enables users to create custom visualizations by adapting high-quality examples. Our approach combines large multimodal models (LMMs) to extract data encoding from existing SVG-based visualization examples, featuring an intermediate representation of visualizations that bridges primitive SVG and visualization programs. Users may express adaptation goals to a conversational agent and control the visual appearance through widgets generated on demand. With an interactive interface, users can modify both data mappings and visual design elements while maintaining the original visualization's aesthetic quality. To evaluate DataWink, we conduct a user study (N=12) with replication and free-form exploration tasks. As a result, DataWink is recognized for its learnability and effectiveness in personalized authoring tasks. Our results demonstrate the potential of example-driven approaches for democratizing visualization creation.",
      "authors": [
        "Liwenhan Xie",
        "Yanna Lin",
        "Can Liu",
        "Huamin Qu",
        "Xinhuan Shu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:50:34+00:00",
          "link": "https://arxiv.org/abs/2507.17734v1",
          "size": "8276kb",
          "version": "v1"
        }
      ],
      "title": "DataWink: Reusing and Adapting SVG-based Visualization Examples with Large Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17734",
        "HTML": "https://arxiv.org/html/2507.17734v1",
        "PDF": "https://arxiv.org/pdf/2507.17734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "DataWink is a tool for creating visualizations using large multimodal models and does not involve processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17736",
      "abstract": "We introduce the problem of symmetric private information retrieval (SPIR) on replicated databases modeled by a simple graph. In this model, each vertex corresponds to a server, and a message is replicated on two servers if and only if there is an edge between them. We consider the setting where the server-side common randomness necessary to accomplish SPIR is also replicated at the servers according to the graph, and we call this as message-specific common randomness. In this setting, we establish a lower bound on the SPIR capacity, i.e., the maximum download rate, for general graphs, by proposing an achievable SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the minimum size of message-specific randomness should be equal to the size of a message. Finally, by providing matching upper bounds, we derive the exact SPIR capacity for the class of path and regular graphs.",
      "authors": [
        "Shreya Meel and Sennur Ulukus"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:51:08+00:00",
          "link": "https://arxiv.org/abs/2507.17736v1",
          "size": "295kb",
          "version": "v1"
        }
      ],
      "title": "Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17736",
        "HTML": "https://arxiv.org/html/2507.17736v1",
        "PDF": "https://arxiv.org/pdf/2507.17736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on symmetric private information retrieval in graph-based systems, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17743",
      "abstract": "Object-Oriented programming is frequently challenging for undergraduate Computer Science students, particularly in understanding abstract concepts such as encapsulation, inheritance, and polymorphism. Although the literature outlines various methods to identify potential design and coding issues in object-oriented programming through source code analysis, such as code smells and SOLID principles, few studies explore how these code-level issues relate to learning difficulties in Object-Oriented Programming. In this study, we explore the relationship of the code issue indicators with common challenges encountered during the learning of object-oriented programming. Using qualitative analysis, we identified the main categories of learning difficulties and, through a literature review, established connections between these difficulties, code smells, and violations of the SOLID principles. As a result, we developed a conceptual map that links code-related issues to specific learning challenges in Object-Oriented Programming. The model was then evaluated by an expert who applied it in the analysis of the student code to assess its relevance and applicability in educational contexts.",
      "authors": [
        "Andre Menolli and Bruno Strik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:56:16+00:00",
          "link": "https://arxiv.org/abs/2507.17743v1",
          "size": "878kb",
          "version": "v1"
        }
      ],
      "title": "Educational Insights from Code: Mapping Learning Challenges in Object-Oriented Programming through Code-Based Evidence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17743",
        "HTML": "https://arxiv.org/html/2507.17743v1",
        "PDF": "https://arxiv.org/pdf/2507.17743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on educational insights and learning challenges in Object-Oriented Programming through code analysis, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17744",
      "abstract": "Yume aims to use images, text, or videos to create an interactive, realistic, and dynamic world, which allows exploration and control using peripheral devices or neural signals. In this report, we present a preview version of \\method, which creates a dynamic world from an input image and allows exploration of the world using keyboard actions. To achieve this high-fidelity and interactive video world generation, we introduce a well-designed framework, which consists of four main components, including camera motion quantization, video generation architecture, advanced sampler, and model acceleration. First, we quantize camera motions for stable training and user-friendly interaction using keyboard inputs. Then, we introduce the Masked Video Diffusion Transformer~(MVDT) with a memory module for infinite video generation in an autoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM) and Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE) are introduced to the sampler for better visual quality and more precise control. Moreover, we investigate model acceleration by synergistic optimization of adversarial distillation and caching mechanisms. We use the high-quality world exploration dataset \\sekai to train \\method, and it achieves remarkable results in diverse scenes and applications. All data, codebase, and model weights are available on https://github.com/stdstu12/YUME. Yume will update monthly to achieve its original goal. Project page: https://stdstu12.github.io/YUME-Project/.",
      "authors": [
        "Xiaofeng Mao",
        "Shaoheng Lin",
        "Zhen Li",
        "Chuanhao Li",
        "Wenshuo Peng",
        "Tong He",
        "Jiangmiao Pang",
        "Mingmin Chi",
        "Yu Qiao",
        "Kaipeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.17744v1",
          "size": "2986kb",
          "version": "v1"
        }
      ],
      "title": "Yume: An Interactive World Generation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17744",
        "HTML": "https://arxiv.org/html/2507.17744v1",
        "PDF": "https://arxiv.org/pdf/2507.17744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a model for interactive world generation using audiovisual inputs. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17745",
      "abstract": "Recent advances in sparse voxel representations have significantly improved the quality of 3D content generation, enabling high-resolution modeling with fine-grained geometry. However, existing frameworks suffer from severe computational inefficiencies due to the quadratic complexity of attention mechanisms in their two-stage diffusion pipelines. In this work, we propose Ultra3D, an efficient 3D generation framework that significantly accelerates sparse voxel modeling without compromising quality. Our method leverages the compact VecSet representation to efficiently generate a coarse object layout in the first stage, reducing token count and accelerating voxel coordinate prediction. To refine per-voxel latent features in the second stage, we introduce Part Attention, a geometry-aware localized attention mechanism that restricts attention computation within semantically consistent part regions. This design preserves structural continuity while avoiding unnecessary global attention, achieving up to 6.7x speed-up in latent generation. To support this mechanism, we construct a scalable part annotation pipeline that converts raw meshes into part-labeled sparse voxels. Extensive experiments demonstrate that Ultra3D supports high-resolution 3D generation at 1024 resolution and achieves state-of-the-art performance in both visual fidelity and user preference.",
      "authors": [
        "Yiwen Chen",
        "Zhihao Li",
        "Yikai Wang",
        "Hu Zhang",
        "Qin Li",
        "Chi Zhang",
        "Guosheng Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:57:16+00:00",
          "link": "https://arxiv.org/abs/2507.17745v1",
          "size": "29399kb",
          "version": "v1"
        }
      ],
      "title": "Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17745",
        "HTML": "https://arxiv.org/html/2507.17745v1",
        "PDF": "https://arxiv.org/pdf/2507.17745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work involves the efficient generation of 3D content using a voxel representation with part attention. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17746",
      "abstract": "Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world tasks often requires balancing objective and subjective evaluation criteria. However, many such tasks lack a single, unambiguous ground truth-making it difficult to define reliable reward signals for post-training language models. While traditional preference-based methods offer a workaround, they rely on opaque reward functions that are difficult to interpret and prone to spurious correlations. We introduce $\\textbf{Rubrics as Rewards}$ (RaR), a framework that uses structured, checklist-style rubrics as interpretable reward signals for on-policy training with GRPO. Our best RaR method yields up to a $28\\%$ relative improvement on HealthBench-1k compared to simple Likert-based approaches, while matching or surpassing the performance of reward signals derived from expert-written references. By treating rubrics as structured reward signals, we show that RaR enables smaller-scale judge models to better align with human preferences and sustain robust performance across model scales.",
      "authors": [
        "Anisha Gunjal",
        "Anthony Wang",
        "Elaine Lau",
        "Vaskar Nath",
        "Bing Liu",
        "Sean Hendryx"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:57:55+00:00",
          "link": "https://arxiv.org/abs/2507.17746v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17746",
        "HTML": "https://arxiv.org/html/2507.17746v1",
        "PDF": "https://arxiv.org/pdf/2507.17746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses using rubrics as interpretable reward signals in reinforcement learning, it briefly touches on post-training evaluation aspects, which could be tangentially related to fine-tuning data evaluation methods but not core to the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17747",
      "abstract": "As frontier language models increasingly saturate standard QA benchmarks, concerns about data contamination, memorization, and escalating dataset creation costs persist. We propose a debate-driven evaluation paradigm that transforms any existing QA dataset into structured adversarial debates--where one model is given the official answer to defend, and another constructs and defends an alternative answer--adjudicated by a judge model blind to the correct solution. By forcing multi-round argumentation, this approach substantially increases difficulty while penalizing shallow memorization, yet reuses QA items to reduce curation overhead. We make two main contributions: (1) an evaluation pipeline to systematically convert QA tasks into debate-based assessments, and (2) a public benchmark that demonstrates our paradigm's effectiveness on a subset of MMLU-Pro questions, complete with standardized protocols and reference models. Empirical results validate the robustness of the method and its effectiveness against data contamination--a Llama 3.1 model fine-tuned on test questions showed dramatic accuracy improvements (50% -> 82%) but performed worse in debates. Results also show that even weaker judges can reliably differentiate stronger debaters, highlighting how debate-based evaluation can scale to future, more capable systems while maintaining a fraction of the cost of creating new benchmarks. Overall, our framework underscores that \"pretraining on the test set is no longer all you need,\" offering a sustainable path for measuring the genuine reasoning ability of advanced language models.",
      "authors": [
        "Linbo Cao",
        "Jinman Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:58:14+00:00",
          "link": "https://arxiv.org/abs/2507.17747v1",
          "size": "581kb",
          "version": "v1"
        }
      ],
      "title": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17747",
        "HTML": "https://arxiv.org/html/2507.17747v1",
        "PDF": "https://arxiv.org/pdf/2507.17747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a debate-driven evaluation paradigm for QA benchmarks, addressing issues like data contamination and memorization. While it suggests a method to reuse existing datasets, the main focus is on evaluation rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17748",
      "abstract": "Robustness and resource-efficiency are two highly desirable properties for modern machine learning models. However, achieving them jointly remains a challenge. In this paper, we position high learning rates as a facilitator for simultaneously achieving robustness to spurious correlations and network compressibility. We demonstrate that large learning rates also produce desirable representation properties such as invariant feature utilization, class separation, and activation sparsity. Importantly, our findings indicate that large learning rates compare favorably to other hyperparameters and regularization methods, in consistently satisfying these properties in tandem. In addition to demonstrating the positive effect of large learning rates across diverse spurious correlation datasets, models, and optimizers, we also present strong evidence that the previously documented success of large learning rates in standard classification tasks is likely due to its effect on addressing hidden/rare spurious correlations in the training dataset.",
      "authors": [
        "Melih Barsbey and Lucas Prieto and Stefanos Zafeiriou and Tolga Birdal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.17748v1",
          "size": "5653kb",
          "version": "v1"
        }
      ],
      "title": "Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17748",
        "HTML": "https://arxiv.org/html/2507.17748v1",
        "PDF": "https://arxiv.org/pdf/2507.17748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the role of large learning rates in achieving robustness and compressibility, focusing on representation properties in machine learning models. It does not address LLM training data processing aspects like data collection, filtering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17749",
      "abstract": "Cross-domain recommendation (CDR) methods predominantly leverage overlapping users to transfer knowledge from a source domain to a target domain. However, through empirical studies, we uncover a critical bias inherent in these approaches: while overlapping users experience significant enhancements in recommendation quality, non-overlapping users benefit minimally and even face performance degradation. This unfairness may erode user trust, and, consequently, negatively impact business engagement and revenue. To address this issue, we propose a novel solution that generates virtual source-domain users for non-overlapping target-domain users. Our method utilizes a dual attention mechanism to discern similarities between overlapping and non-overlapping users, thereby synthesizing realistic virtual user embeddings. We further introduce a limiter component that ensures the generated virtual users align with real-data distributions while preserving each user's unique characteristics. Notably, our method is model-agnostic and can be seamlessly integrated into any CDR model. Comprehensive experiments conducted on three public datasets with five CDR baselines demonstrate that our method effectively mitigates the CDR non-overlapping user bias, without loss of overall accuracy. Our code is publicly available at https://github.com/WeixinChen98/VUG.",
      "authors": [
        "Weixin Chen and Yuhan Zhao and Li Chen and Weike Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:59:08+00:00",
          "link": "https://arxiv.org/abs/2507.17749v1",
          "size": "267kb",
          "version": "v1"
        }
      ],
      "title": "Leave No One Behind: Fairness-Aware Cross-Domain Recommender Systems for Non-Overlapping Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17749",
        "HTML": "https://arxiv.org/html/2507.17749v1",
        "PDF": "https://arxiv.org/pdf/2507.17749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on fairness-aware cross-domain recommender systems and introduces a method to generate virtual users to mitigate user bias. It does not involve any LLM training data processing operations such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.04711",
      "abstract": "The objective of this Philosophiae Doctor (Ph.D) thesis is to propose an efficient approach for optimizing a multidisciplinary black-box model when the optimization problem is constrained and involves a large number of mixed integer design variables (typically 100 variables). The targeted optimization approach, called EGO, is based on a sequential enrichment of an adaptive surrogate model and, in this context, GP surrogate models are one of the most widely used in engineering problems to approximate time-consuming high fidelity models. EGO is a heuristic BO method that performs well in terms of solution quality. However, like any other global optimization method, EGO suffers from the curse of dimensionality, meaning that its performance is satisfactory on lower dimensional problems, but deteriorates as the dimensionality of the optimization search space increases. For realistic aircraft design problems, the typical size of the design variables can even exceed 100 and, thus, trying to solve directly the problems using EGO is ruled out. The latter is especially true when the problems involve both continuous and categorical variables increasing even more the size of the search space. In this Ph.D thesis, effective parameterization tools are investigated, including techniques like partial least squares regression, to significantly reduce the number of design variables. Additionally, Bayesian optimization is adapted to handle discrete variables and high-dimensional spaces in order to reduce the number of evaluations when optimizing innovative aircraft concepts such as the \"DRAGON\" hybrid airplane to reduce their climate impact.",
      "authors": [
        "Paul Saves"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Mathematical Software (cs.MS)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T09:58:52+00:00",
          "link": "https://arxiv.org/abs/2402.04711v1",
          "size": "19757kb",
          "version": "v1"
        },
        {
          "date": "2024-02-10T11:34:42+00:00",
          "link": "https://arxiv.org/abs/2402.04711v2",
          "size": "19757kb",
          "version": "v2"
        },
        {
          "date": "2024-05-26T20:02:59+00:00",
          "link": "https://arxiv.org/abs/2402.04711v3",
          "size": "29268kb",
          "version": "v3"
        }
      ],
      "title": "High-dimensional multidisciplinary design optimization for aircraft eco-design / Optimisation multi-disciplinaire en grande dimension pour l'\\'eco-conception avion en avant-projet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04711",
        "PDF": "https://arxiv.org/pdf/2402.04711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on high-dimensional optimization techniques for aircraft design, specifically using EGO and Bayesian optimization, and does not relate to LLM training data processing or any data operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14982",
      "abstract": "Consider a downlink integrated sensing and communications (ISAC) system in which a base station employs linear beamforming to communicate to $K$ users, while simultaneously uses sensing beams to perform a sensing task of estimating $L$ real parameters. How many beamformers are needed to achieve the best performance for both sensing and communications? This paper establishes bounds on the minimum number of downlink beamformers, in which sensing performance is measured in terms of the Cram\\'{e}r-Rao bound for parameter estimation and communications performance is measured in terms of the signal-to-interference-and-noise ratios. We show that an ISAC system requires at most $K + \\sqrt{\\frac{L(L+1)}{2}}$ beamformers if the remote users have the ability to cancel the interference caused by the sensing beams. If cancelling interference due to the sensing beams is not possible, the bound becomes $\\sqrt{K^2 + \\frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound on the number of beamformers is less than the sum of the bounds for each task individually. These results can be extended to sensing tasks for which the performance is measured as a function of $d$ quadratic terms in the beamformers. In this case, the bound becomes $K + \\sqrt{d}$ and $\\sqrt{K^2 + d}$, respectively. Specifically, for estimating complex path losses and angles-of-arrival of $N_\\text{tr}$ targets while communicating to $K$ users, the bound on the minimum number of beamformers scales linearly in $K$ and in $N_\\text{tr}$, assuming interference from sensing can be cancelled. When interference cancellation is not possible, the following exact characterization for the case of $N_\\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two beamformers should be used; when $K \\ge 2$, exactly $K$ beamformers should be used, i.e., communication beamformers alone are already sufficient.",
      "authors": [
        "Kareem M. Attiah",
        "and Wei Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:37:01+00:00",
          "link": "https://arxiv.org/abs/2507.14982v1",
          "size": "154kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T11:53:01+00:00",
          "link": "https://arxiv.org/abs/2507.14982v2",
          "size": "154kb",
          "version": "v2"
        }
      ],
      "title": "How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14982",
        "HTML": "https://arxiv.org/html/2507.14982v2",
        "PDF": "https://arxiv.org/pdf/2507.14982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on integrated sensing and communications systems and establishes bounds on beamformers, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16832",
      "abstract": "Using speech samples as a biomarker is a promising avenue for detecting and monitoring the progression of Parkinson's disease (PD), but there is considerable disagreement in the literature about how best to collect and analyze such data. Early research in detecting PD from speech used a sustained vowel phonation (SVP) task, while some recent research has explored recordings of more cognitively demanding tasks. To assess the role of language in PD detection, we tested pretrained models with varying data types and pretraining objectives and found that (1) text-only models match the performance of vocal-feature models, (2) multilingual Whisper outperforms self-supervised models whereas monolingual Whisper does worse, and (3) AudioSet pretraining improves performance on SVP but not spontaneous speech. These findings together highlight the critical role of language for the early detection of Parkinson's disease.",
      "authors": [
        "Peter Plantinga",
        "Briac Cordelle",
        "Dominique Lou\\\"er",
        "Mirco Ravanelli",
        "Denise Klein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:23:09+00:00",
          "link": "https://arxiv.org/abs/2507.16832v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Does Language Matter for Early Detection of Parkinson's Disease from Speech?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16832",
        "HTML": "https://arxiv.org/html/2507.16832v1",
        "PDF": "https://arxiv.org/pdf/2507.16832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses the use of speech samples for detecting Parkinson's disease with pretrained models, focusing on performance comparisons rather than LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16834",
      "abstract": "Although Jamaican Patois is a widely spoken language, current speech recognition systems perform poorly on Patois music, producing inaccurate captions that limit accessibility and hinder downstream applications. In this work, we take a data-centric approach to this problem by curating more than 40 hours of manually transcribed Patois music. We use this dataset to fine-tune state-of-the-art automatic speech recognition (ASR) models, and use the results to develop scaling laws for the performance of Whisper models on Jamaican Patois audio. We hope that this work will have a positive impact on the accessibility of Jamaican Patois music and the future of Jamaican Patois language modeling.",
      "authors": [
        "Jordan Madden",
        "Matthew Stone",
        "Dimitri Johnson",
        "Daniel Geddez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:42:05+00:00",
          "link": "https://arxiv.org/abs/2507.16834v1",
          "size": "472kb",
          "version": "v1"
        }
      ],
      "title": "Towards Robust Speech Recognition for Jamaican Patois Music Transcription",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16834",
        "HTML": "https://arxiv.org/html/2507.16834v1",
        "PDF": "https://arxiv.org/pdf/2507.16834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper curates a dataset of manually transcribed Jamaican Patois music for fine-tuning ASR models, but the focus is on speech recognition rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16835",
      "abstract": "Voice-based conversational AI systems increasingly rely on cascaded architectures combining speech-to-text (STT), large language models (LLMs), and text-to-speech (TTS) components. However, systematic evaluation of different component combinations in production settings remains understudied. We present a large-scale empirical comparison of STT x LLM x TTS stacks using data from over 300,000 AI-conducted job interviews. We develop an automated evaluation framework using LLM-as-a-Judge to assess conversational quality, technical accuracy, and skill assessment capabilities. Our analysis of four production configurations reveals that Google STT paired with GPT-4.1 significantly outperforms alternatives in both conversational and technical quality metrics. Surprisingly, we find that objective quality metrics correlate weakly with user satisfaction scores, suggesting that user experience in voice-based AI systems depends on factors beyond technical performance. Our findings provide practical guidance for selecting components in multimodal conversational AI systems and contribute a validated evaluation methodology for voice-based interactions.",
      "authors": [
        "Nima Yazdani",
        "Ali Ansari",
        "Aruj Mahajan",
        "Amirhossein Afsharrad",
        "Seyed Shahabeddin Mousavi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:30:55+00:00",
          "link": "https://arxiv.org/abs/2507.16835v1",
          "size": "414kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16835",
        "HTML": "https://arxiv.org/html/2507.16835v1",
        "PDF": "https://arxiv.org/pdf/2507.16835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates the performance of AI systems combining speech-to-text and text-to-speech with LLMs in job interviews, focusing on system evaluation rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16836",
      "abstract": "Speech holds promise as a cost-effective and non-invasive biomarker for neurological conditions such as Parkinson's disease (PD). While deep learning systems trained on raw audio can find subtle signals not available from hand-crafted features, their black-box nature hinders clinical adoption. To address this, we apply sparse autoencoders (SAEs) to uncover interpretable internal representations from a speech-based PD detection system. We introduce a novel mask-based activation for adapting SAEs to small biomedical datasets, creating sparse disentangled dictionary representations. These dictionary entries are found to have strong associations with characteristic articulatory deficits in PD speech, such as reduced spectral flux and increased spectral flatness in the low-energy regions highlighted by the model attention. We further show that the spectral flux is related to volumetric measurements of the putamen from MRI scans, demonstrating the potential of SAEs to reveal clinically relevant biomarkers for disease monitoring and diagnosis.",
      "authors": [
        "Peter Plantinga",
        "Jen-Kai Chen",
        "Roozbeh Sattari",
        "Mirco Ravanelli",
        "Denise Klein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:22:02+00:00",
          "link": "https://arxiv.org/abs/2507.16836v1",
          "size": "609kb",
          "version": "v1"
        }
      ],
      "title": "From Black Box to Biomarker: Sparse Autoencoders for Interpreting Speech Models of Parkinson's Disease",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16836",
        "HTML": "https://arxiv.org/html/2507.16836v1",
        "PDF": "https://arxiv.org/pdf/2507.16836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the application of sparse autoencoders for interpreting models related to Parkinson's disease, with a focus on clinical applications and speech biomarker discovery, not LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16838",
      "abstract": "Mispronunciation detection and diagnosis (MDD) is a significant part in modern computer aided language learning (CALL) systems. Within MDD, phoneme-level pronunciation assessment is key to helping L2 learners improve their pronunciation. However, most systems are based on a form of goodness of pronunciation (GOP) which requires pre-segmentation of speech into phonetic units. This limits the accuracy of these methods and the possibility to use modern CTC-based acoustic models for their evaluation. In this study, we first propose self-alignment GOP (GOP-SA) that enables the use of CTC-trained ASR models for MDD. Next, we define a more general alignment-free method that takes all possible alignments of the target phoneme into account (GOP-AF). We give a theoretical account of our definition of GOP-AF, an implementation that solves potential numerical issues as well as a proper normalization which makes the method applicable with acoustic models with different peakiness over time. We provide extensive experimental results on the CMU Kids and Speechocean762 datasets comparing the different definitions of our methods, estimating the dependency of GOP-AF on the peakiness of the acoustic models and on the amount of context around the target phoneme. Finally, we compare our methods with recent studies over the Speechocean762 data showing that the feature vectors derived from the proposed method achieve state-of-the-art results on phoneme-level pronunciation assessment.",
      "authors": [
        "Xinwei Cao",
        "Zijian Fan",
        "Torbj{\\o}rn Svendsen",
        "Giampiero Salvi"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T04:00:58+00:00",
          "link": "https://arxiv.org/abs/2507.16838v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "Segmentation-free Goodness of Pronunciation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16838",
        "HTML": "https://arxiv.org/html/2507.16838v1",
        "PDF": "https://arxiv.org/pdf/2507.16838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study develops methods for mispronunciation detection in language learning, focusing on phoneme-level pronunciation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16845",
      "abstract": "Lung diseases, including lung cancer and COPD, are significant health concerns globally. Traditional diagnostic methods can be costly, time-consuming, and invasive. This study investigates the use of semi supervised learning methods for lung sound signal detection using a model combination of MFCC+CNN. By introducing semi supervised learning modules such as Mix Match, Co-Refinement, and Co Refurbishing, we aim to enhance the detection performance while reducing dependence on manual annotations. With the add-on semi-supervised modules, the accuracy rate of the MFCC+CNN model is 92.9%, an increase of 3.8% to the baseline model. The research contributes to the field of lung disease sound detection by addressing challenges such as individual differences, feature insufficient labeled data.",
      "authors": [
        "Xiaoran Xua",
        "In-Ho Rab",
        "and Ravi Sankarc"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:10:24+00:00",
          "link": "https://arxiv.org/abs/2507.16845v1",
          "size": "1732kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Lung Disease Diagnosis via Semi-Supervised Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16845",
        "PDF": "https://arxiv.org/pdf/2507.16845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on semi-supervised learning for lung disease diagnosis and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16855",
      "abstract": "The tumor immune microenvironment (TIME) in non-small cell lung cancer (NSCLC) histopathology contains morphological and molecular characteristics predictive of immunotherapy response. Computational quantification of TIME characteristics, such as cell detection and tissue segmentation, can support biomarker development. However, currently available digital pathology datasets of NSCLC for the development of cell detection or tissue segmentation algorithms are limited in scope, lack annotations of clinically prevalent metastatic sites, and forgo molecular information such as PD-L1 immunohistochemistry (IHC). To fill this gap, we introduce the IGNITE data toolkit, a multi-stain, multi-centric, and multi-scanner dataset of annotated NSCLC whole-slide images. We publicly release 887 fully annotated regions of interest from 155 unique patients across three complementary tasks: (i) multi-class semantic segmentation of tissue compartments in H&E-stained slides, with 16 classes spanning primary and metastatic NSCLC, (ii) nuclei detection, and (iii) PD-L1 positive tumor cell detection in PD-L1 IHC slides. To the best of our knowledge, this is the first public NSCLC dataset with manual annotations of H&E in metastatic sites and PD-L1 IHC.",
      "authors": [
        "Joey Spronck",
        "Leander van Eekelen",
        "Dominique van Midden",
        "Joep Bogaerts",
        "Leslie Tessier",
        "Valerie Dechering",
        "Muradije Demirel-Andishmand",
        "Gabriel Silva de Souza",
        "Roland Nemeth",
        "Enrico Munari",
        "Giuseppe Bogina",
        "Ilaria Girolami",
        "Albino Eccher",
        "Balazs Acs",
        "Ceren Boyaci",
        "Natalie Klubickova",
        "Monika Looijen-Salamon",
        "Shoko Vos",
        "Francesco Ciompi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:16:22+00:00",
          "link": "https://arxiv.org/abs/2507.16855v1",
          "size": "5425kb",
          "version": "v1"
        }
      ],
      "title": "A tissue and cell-level annotated H&E and PD-L1 histopathology image dataset in non-small cell lung cancer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16855",
        "HTML": "https://arxiv.org/html/2507.16855v1",
        "PDF": "https://arxiv.org/pdf/2507.16855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a histopathology image dataset for non-small cell lung cancer, focusing on tasks related to tissue segmentation and cell detection. It has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16875",
      "abstract": "High-quality speech generation for low-resource languages, such as many Indian languages, remains a significant challenge due to limited data and diverse linguistic structures. Duration prediction is a critical component in many speech generation pipelines, playing a key role in modeling prosody and speech rhythm. While some recent generative approaches choose to omit explicit duration modeling, often at the cost of longer training times. We retain and explore this module to better understand its impact in the linguistically rich and data-scarce landscape of India. We train a non-autoregressive Continuous Normalizing Flow (CNF) based speech model using publicly available Indian language data and evaluate multiple duration prediction strategies for zero-shot, speaker-specific generation. Our comparative analysis on speech-infilling tasks reveals nuanced trade-offs: infilling based predictors improve intelligibility in some languages, while speaker-prompted predictors better preserve speaker characteristics in others. These findings inform the design and selection of duration strategies tailored to specific languages and tasks, underscoring the continued value of interpretable components like duration prediction in adapting advanced generative architectures to low-resource, multilingual settings.",
      "authors": [
        "Isha Pandey",
        "Pranav Gaikwad",
        "Amruta Parulekar",
        "Ganesh Ramakrishnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T09:38:30+00:00",
          "link": "https://arxiv.org/abs/2507.16875v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Technical report: Impact of Duration Prediction on Speaker-specific TTS for Indian Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16875",
        "HTML": "https://arxiv.org/html/2507.16875v1",
        "PDF": "https://arxiv.org/pdf/2507.16875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on duration prediction in text-to-speech systems for Indian languages, a task unrelated to LLM training data processing. It discusses speech generation not language model training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16876",
      "abstract": "Multimodal machine learning integrating histopathology and molecular data shows promise for cancer prognostication. We systematically reviewed studies combining whole slide images (WSIs) and high-throughput omics to predict overall survival. Searches of EMBASE, PubMed, and Cochrane CENTRAL (12/08/2024), plus citation screening, identified eligible studies. Data extraction used CHARMS; bias was assessed with PROBAST+AI; synthesis followed SWiM and PRISMA 2020. Protocol: PROSPERO (CRD42024594745).\n  Forty-eight studies (all since 2017) across 19 cancer types met criteria; all used The Cancer Genome Atlas. Approaches included regularised Cox regression (n=4), classical ML (n=13), and deep learning (n=31). Reported c-indices ranged 0.550-0.857; multimodal models typically outperformed unimodal ones. However, all studies showed unclear/high bias, limited external validation, and little focus on clinical utility.\n  Multimodal WSI-omics survival prediction is a fast-growing field with promising results but needs improved methodological rigor, broader datasets, and clinical evaluation.\n  Funded by NPIC, Leeds Teaching Hospitals NHS Trust, UK (Project 104687), supported by UKRI Industrial Strategy Challenge Fund.",
      "authors": [
        "Charlotte Jennings (1",
        "2)",
        "Andrew Broad (1)",
        "Lucy Godson (1)",
        "Emily Clarke (1",
        "2)",
        "David Westhead (2) and Darren Treanor (1",
        "2",
        "3) ((1) National Pathology Imaging Cooperative",
        "Leeds Teaching Hospitals NHS Trust",
        "Leeds",
        "UK (2) University of Leeds",
        "Leeds",
        "UK (3) Link\\\"oping University",
        "Link\\\"oping",
        "Sweden)"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T11:02:51+00:00",
          "link": "https://arxiv.org/abs/2507.16876v1",
          "size": "2991kb",
          "version": "v1"
        }
      ],
      "title": "Machine learning-based multimodal prognostic models integrating pathology images and high-throughput omic data for overall survival prediction in cancer: a systematic review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16876",
        "PDF": "https://arxiv.org/pdf/2507.16876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews multimodal prognostic models for cancer prediction, integrating pathology images and omics data. This application of machine learning has no direct relevance to LLM data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16915",
      "abstract": "Koopman operator theory enables linear analysis of nonlinear dynamical systems by lifting their evolution to infinite-dimensional function spaces. However, finite-dimensional approximations of Koopman and transfer (Frobenius--Perron) operators are prone to spectral pollution, introducing spurious eigenvalues that can compromise spectral computations. While recent advances have yielded provably convergent methods for Koopman operators, analogous tools for general transfer operators remain limited. In this paper, we present algorithms for computing spectral properties of transfer operators without spectral pollution, including extensions to the Hardy-Hilbert space. Case studies--ranging from families of Blaschke maps with known spectrum to a molecular dynamics model of protein folding--demonstrate the accuracy and flexibility of our approach. Notably, we demonstrate that spectral features can arise even when the corresponding eigenfunctions lie outside the chosen space, highlighting the functional-analytic subtleties in defining the \"true\" Koopman spectrum. Our methods offer robust tools for spectral estimation across a broad range of applications.",
      "authors": [
        "April Herwig",
        "Matthew J. Colbrook",
        "Oliver Junge",
        "P\\'eter Koltai",
        "Julia Slipantschuk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Spectral Theory (math.SP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:01:05+00:00",
          "link": "https://arxiv.org/abs/2507.16915v1",
          "size": "3140kb",
          "version": "v1"
        }
      ],
      "title": "Avoiding spectral pollution for transfer operators using residuals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16915",
        "HTML": "https://arxiv.org/html/2507.16915v1",
        "PDF": "https://arxiv.org/pdf/2507.16915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with spectral pollution in transfer operators and does not relate to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16953",
      "abstract": "Estimating high-dimensional covariance matrices is a key task across many fields. This paper explores the theoretical limits of distributed covariance estimation in a feature-split setting, where communication between agents is constrained. Specifically, we study a scenario in which multiple agents each observe different components of i.i.d. samples drawn from a sub-Gaussian random vector. A central server seeks to estimate the complete covariance matrix using a limited number of bits communicated by each agent. We obtain a nearly tight minimax lower bound for covariance matrix estimation under operator norm and Frobenius norm. Our main technical tool is a novel generalization of the strong data processing inequality (SDPI), termed the Conditional Strong Data Processing Inequality (C-SDPI) coefficient, introduced in this work. The C-SDPI coefficient shares key properties such as tensorization with the conventional SDPI. Crucially, it quantifies the average contraction in a state-dependent channel and can be significantly lower than the worst-case SDPI coefficient over the state input.\n  Utilizing the doubling trick of Geng-Nair and an operator Jensen inequality, we compute this coefficient for Gaussian mixture channels. We then employ it to establish minimax lower bounds on estimation error, capturing the trade-offs among sample size, communication cost, and data dimensionality. Building on this, we present a nearly optimal estimation protocol whose sample and communication requirements match the lower bounds up to logarithmic factors. Unlike much of the existing literature, our framework does not assume infinite samples or Gaussian distributions, making it broadly applicable. Finally, we extend our analysis to interactive protocols, showing interaction can significantly reduce communication requirements compared to non-interactive schemes.",
      "authors": [
        "Mohammad Reza Rahmani",
        "Mohammad Hossein Yassaee",
        "Mohammad Reza Aref"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:50:02+00:00",
          "link": "https://arxiv.org/abs/2507.16953v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "Fundamental limits of distributed covariance matrix estimation via a conditional strong data processing inequality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16953",
        "PDF": "https://arxiv.org/pdf/2507.16953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores theoretical limits in distributed covariance matrix estimation, focusing on mathematical frameworks and estimations, rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16955",
      "abstract": "Early and accurate interpretation of screening mammograms is essential for effective breast cancer detection, yet it remains a complex challenge due to subtle imaging findings and diagnostic ambiguity. Many existing AI approaches fall short by focusing on single view inputs or single-task outputs, limiting their clinical utility. To address these limitations, we propose a novel multi-view, multitask hybrid deep learning framework that processes all four standard mammography views and jointly predicts diagnostic labels and BI-RADS scores for each breast. Our architecture integrates a hybrid CNN VSSM backbone, combining convolutional encoders for rich local feature extraction with Visual State Space Models (VSSMs) to capture global contextual dependencies. To improve robustness and interpretability, we incorporate a gated attention-based fusion module that dynamically weights information across views, effectively handling cases with missing data. We conduct extensive experiments across diagnostic tasks of varying complexity, benchmarking our proposed hybrid models against baseline CNN architectures and VSSM models in both single task and multi task learning settings. Across all tasks, the hybrid models consistently outperform the baselines. In the binary BI-RADS 1 vs. 5 classification task, the shared hybrid model achieves an AUC of 0.9967 and an F1 score of 0.9830. For the more challenging ternary classification, it attains an F1 score of 0.7790, while in the five-class BI-RADS task, the best F1 score reaches 0.4904. These results highlight the effectiveness of the proposed hybrid framework and underscore both the potential and limitations of multitask learning for improving diagnostic performance and enabling clinically meaningful mammography analysis.",
      "authors": [
        "Yalda Zafari",
        "Roaa Elalfy",
        "Mohamed Mabrok",
        "Somaya Al-Maadeed",
        "Tamer Khattab",
        "and Essam A. Rashed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T18:52:18+00:00",
          "link": "https://arxiv.org/abs/2507.16955v1",
          "size": "1631kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid CNN-VSSM model for Multi-View, Multi-Task Mammography Analysis: Robust Diagnosis with Attention-Based Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16955",
        "HTML": "https://arxiv.org/html/2507.16955v1",
        "PDF": "https://arxiv.org/pdf/2507.16955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a multi-view, multi-task deep learning framework for mammography analysis, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16962",
      "abstract": "Modern medical imaging technologies have greatly advanced neuroscience research and clinical diagnostics. However, imaging data collected across different scanners, acquisition protocols, or imaging sites often exhibit substantial heterogeneity, known as \"batch effects\" or \"site effects\". These non-biological sources of variability can obscure true biological signals, reduce reproducibility and statistical power, and severely impair the generalizability of learning-based models across datasets. Image harmonization aims to eliminate or mitigate such site-related biases while preserving meaningful biological information, thereby improving data comparability and consistency. This review provides a comprehensive overview of key concepts, methodological advances, publicly available datasets, current challenges, and future directions in the field of medical image harmonization, with a focus on magnetic resonance imaging (MRI). We systematically cover the full imaging pipeline, and categorize harmonization approaches into prospective acquisition and reconstruction strategies, retrospective image-level and feature-level methods, and traveling-subject-based techniques. Rather than providing an exhaustive survey, we focus on representative methods, with particular emphasis on deep learning-based approaches. Finally, we summarize the major challenges that remain and outline promising avenues for future research.",
      "authors": [
        "Qinqin Yang",
        "Firoozeh Shomal-Zadeh",
        "Ali Gholipour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:06:02+00:00",
          "link": "https://arxiv.org/abs/2507.16962v1",
          "size": "6095kb",
          "version": "v1"
        }
      ],
      "title": "Harmonization in Magnetic Resonance Imaging: A Survey of Acquisition, Image-level, and Feature-level Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16962",
        "HTML": "https://arxiv.org/html/2507.16962v1",
        "PDF": "https://arxiv.org/pdf/2507.16962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys methods for harmonization in MRI, focusing on medical image consistency rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16978",
      "abstract": "The exponential growth of DNA sequencing data has outpaced traditional heuristic-based methods, which struggle to scale effectively. Efficient computational approaches are urgently needed to support large-scale similarity search, a foundational task in bioinformatics for detecting homology, functional similarity, and novelty among genomic and proteomic sequences. Although tools like BLAST have been widely used and remain effective in many scenarios, they suffer from limitations such as high computational cost and poor performance on divergent sequences.\n  In this work, we explore embedding-based similarity search methods that learn latent representations capturing deeper structural and functional patterns beyond raw sequence alignment. We systematically evaluate two state-of-the-art vector search libraries, FAISS and ScaNN, on biologically meaningful gene embeddings. Unlike prior studies, our analysis focuses on bioinformatics-specific embeddings and benchmarks their utility for detecting novel sequences, including those from uncharacterized taxa or genes lacking known homologs. Our results highlight both computational advantages (in memory and runtime efficiency) and improved retrieval quality, offering a promising alternative to traditional alignment-heavy tools.",
      "authors": [
        "Mohammad Saleh Refahi",
        "Gavin Hearne",
        "Harrison Muller",
        "Kieran Lynch",
        "Bahrad A. Sokhansanj",
        "James R. Brown",
        "Gail Rosen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T19:28:54+00:00",
          "link": "https://arxiv.org/abs/2507.16978v1",
          "size": "2246kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Scalable Gene Embedding Search: A Comparative Study of FAISS and ScaNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16978",
        "HTML": "https://arxiv.org/html/2507.16978v1",
        "PDF": "https://arxiv.org/pdf/2507.16978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses bioinformatics similarity searches using embedding-based methods and evaluates vector search libraries, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16995",
      "abstract": "As quantum hardware rapidly advances toward the early fault-tolerant era, a key challenge is to develop quantum algorithms that are not only theoretically sound but also hardware-friendly on near-term devices. In this work, we propose a quantum algorithm for solving linear ordinary differential equations (ODEs) with a provable runtime guarantee. Our algorithm uses only a single ancilla qubit, and is locality preserving, i.e., when the coefficient matrix of the ODE is $k$-local, the algorithm only needs to implement the time evolution of $(k+1)$-local Hamiltonians. We also discuss the connection between our proposed algorithm and Lindbladian simulation as well as its application to the interacting Hatano-Nelson model, a widely studied non-Hermitian model with rich phenomenology.",
      "authors": [
        "Di Fang and David Lloyd George and Yu Tong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:08:34+00:00",
          "link": "https://arxiv.org/abs/2507.16995v1",
          "size": "479kb",
          "version": "v1"
        }
      ],
      "title": "Qubit-Efficient Quantum Algorithm for Linear Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16995",
        "HTML": "https://arxiv.org/html/2507.16995v1",
        "PDF": "https://arxiv.org/pdf/2507.16995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a quantum algorithm for solving differential equations, which is not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16999",
      "abstract": "We present a novel approach to help decision-makers efficiently identify preferred solutions from the Pareto set of a multi-objective optimization problem. Our method uses a Bayesian model to estimate the decision-maker's utility function based on pairwise comparisons. Aided by this model, a principled elicitation strategy selects queries interactively to balance exploration and exploitation, guiding the discovery of high-utility solutions. The approach is flexible: it can be used interactively or a posteriori after estimating the Pareto front through standard multi-objective optimization techniques. Additionally, at the end of the elicitation phase, it generates a reduced menu of high-quality solutions, simplifying the decision-making process. Through experiments on test problems with up to nine objectives, our method demonstrates superior performance in finding high-utility solutions with a small number of queries. We also provide an open-source implementation of our method to support its adoption by the broader community.",
      "authors": [
        "Felix Huber",
        "Sebastian Rojas Gonzalez and Raul Astudillo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.16999v1",
          "size": "8266kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian preference elicitation for decision support in multiobjective optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16999",
        "HTML": "https://arxiv.org/html/2507.16999v1",
        "PDF": "https://arxiv.org/pdf/2507.16999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with multi-objective optimization and decision support using Bayesian models, which are unrelated to LLM training data processing or any associated data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17006",
      "abstract": "Compiling Bell games under cryptographic assumptions replaces the need for physical separation, allowing nonlocality to be probed with a single untrusted device. While Kalai et al. (STOC'23) showed that this compilation preserves quantum advantages, its quantitative quantum soundness has remained an open problem. We address this gap with two primary contributions. First, we establish the first quantitative quantum soundness bounds for every bipartite compiled Bell game whose optimal quantum strategy is finite-dimensional: any polynomial-time prover's score in the compiled game is negligibly close to the game's ideal quantum value. More generally, for all bipartite games we show that the compiled score cannot significantly exceed the bounds given by a newly formalized sequential Navascu\\'es-Pironio-Ac\\'in (NPA) hierarchy. Second, we provide a full characterization of this sequential NPA hierarchy, establishing it as a robust numerical tool that is of independent interest. Finally, for games without finite-dimensional optimal strategies, we explore the necessity of NPA approximation error for quantitatively bounding their compiled scores, linking these considerations to the complexity conjecture $\\mathrm{MIP}^{\\mathrm{co}}=\\mathrm{coRE}$ and open challenges such as quantum homomorphic encryption correctness for \"weakly commuting\" quantum registers.",
      "authors": [
        "Igor Klep",
        "Connor Paddock",
        "Marc-Olivier Renou",
        "Simon Schmidt",
        "Lucas Tendick",
        "Xiangling Xu",
        "Yuming Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T20:31:41+00:00",
          "link": "https://arxiv.org/abs/2507.17006v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Quantitative Quantum Soundness for Bipartite Compiled Bell Games via the Sequential NPA Hierarchy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17006",
        "HTML": "https://arxiv.org/html/2507.17006v1",
        "PDF": "https://arxiv.org/pdf/2507.17006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on quantum soundness in compiled Bell games, an area outside of natural language processing and data handling for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17026",
      "abstract": "Neural Posterior Estimation (NPE) has emerged as a powerful approach for amortized Bayesian inference when the true posterior $p(\\theta \\mid y)$ is intractable or difficult to sample. But evaluating the accuracy of neural posterior estimates remains challenging, with existing methods suffering from major limitations. One appealing and widely used method is the classifier two-sample test (C2ST), where a classifier is trained to distinguish samples from the true posterior $p(\\theta \\mid y)$ versus the learned NPE approximation $q(\\theta \\mid y)$. Yet despite the appealing simplicity of the C2ST, its theoretical and practical reliability depend upon having access to a near-Bayes-optimal classifier -- a requirement that is rarely met and, at best, difficult to verify. Thus a major open question is: can a weak classifier still be useful for neural posterior validation? We show that the answer is yes. Building on the work of Hu and Lei, we present several key results for a conformal variant of the C2ST, which converts any trained classifier's scores -- even those of weak or over-fitted models -- into exact finite-sample p-values. We establish two key theoretical properties of the conformal C2ST: (i) finite-sample Type-I error control, and (ii) non-trivial power that degrades gently in tandem with the error of the trained classifier. The upshot is that even weak, biased, or overfit classifiers can still yield powerful and reliable tests. Empirically, the Conformal C2ST outperforms classical discriminative tests across a wide range of benchmarks. These results reveal the under appreciated strength of weak classifiers for validating neural posterior estimates, establishing the conformal C2ST as a practical, theoretically grounded diagnostic for modern simulation-based inference.",
      "authors": [
        "Vansh Bansal",
        "Tianyu Chen",
        "James G. Scott"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:30:06+00:00",
          "link": "https://arxiv.org/abs/2507.17026v1",
          "size": "18433kb",
          "version": "v1"
        }
      ],
      "title": "The surprising strength of weak classifiers for validating neural posterior estimates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17026",
        "HTML": "https://arxiv.org/html/2507.17026v1",
        "PDF": "https://arxiv.org/pdf/2507.17026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using weak classifiers for validating neural posterior estimates, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17030",
      "abstract": "We consider the problem of validating whether a neural posterior estimate \\( q(\\theta \\mid x) \\) is an accurate approximation to the true, unknown true posterior \\( p(\\theta \\mid x) \\). Existing methods for evaluating the quality of an NPE estimate are largely derived from classifier-based tests or divergence measures, but these suffer from several practical drawbacks. As an alternative, we introduce the \\emph{Conditional Localization Test} (CoLT), a principled method designed to detect discrepancies between \\( p(\\theta \\mid x) \\) and \\( q(\\theta \\mid x) \\) across the full range of conditioning inputs. Rather than relying on exhaustive comparisons or density estimation at every \\( x \\), CoLT learns a localization function that adaptively selects points $\\theta_l(x)$ where the neural posterior $q$ deviates most strongly from the true posterior $p$ for that $x$. This approach is particularly advantageous in typical simulation-based inference settings, where only a single draw \\( \\theta \\sim p(\\theta \\mid x) \\) from the true posterior is observed for each conditioning input, but where the neural posterior \\( q(\\theta \\mid x) \\) can be sampled an arbitrary number of times. Our theoretical results establish necessary and sufficient conditions for assessing distributional equality across all \\( x \\), offering both rigorous guarantees and practical scalability. Empirically, we demonstrate that CoLT not only performs better than existing methods at comparing $p$ and $q$, but also pinpoints regions of significant divergence, providing actionable insights for model refinement. These properties position CoLT as a state-of-the-art solution for validating neural posterior estimates.",
      "authors": [
        "Tianyu Chen",
        "Vansh Bansal",
        "James G. Scott"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T21:38:59+00:00",
          "link": "https://arxiv.org/abs/2507.17030v1",
          "size": "12075kb",
          "version": "v1"
        }
      ],
      "title": "CoLT: The conditional localization test for assessing the accuracy of neural posterior estimates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17030",
        "HTML": "https://arxiv.org/html/2507.17030v1",
        "PDF": "https://arxiv.org/pdf/2507.17030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the Conditional Localization Test (CoLT) for validating neural posterior estimates, focusing on accuracy assessment rather than on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17043",
      "abstract": "Quantum computing has significantly advanced in recent years, boasting devices with hundreds of quantum bits (qubits), hinting at its potential quantum advantage over classical computing. Yet, noise in quantum devices poses significant barriers to realizing this supremacy. Understanding noise's impact is crucial for reproducibility and application reuse; moreover, the next-generation quantum-centric supercomputing essentially requires efficient and accurate noise characterization to support system management (e.g., job scheduling), where ensuring correct functional performance (i.e., fidelity) of jobs on available quantum devices can even be higher-priority than traditional objectives. However, noise fluctuates over time, even on the same quantum device, which makes predicting the computational bounds for on-the-fly noise is vital. Noisy quantum simulation can offer insights but faces efficiency and scalability issues. In this work, we propose a data-driven workflow, namely QuBound, to predict computational performance bounds. It decomposes historical performance traces to isolate noise sources and devises a novel encoder to embed circuit and noise information processed by a Long Short-Term Memory (LSTM) network. For evaluation, we compare QuBound with a state-of-the-art learning-based predictor, which only generates a single performance value instead of a bound. Experimental results show that the result of the existing approach falls outside of performance bounds, while all predictions from our QuBound with the assistance of performance decomposition better fit the bounds. Moreover, QuBound can efficiently produce practical bounds for various circuits with over 106 speedup over simulation; in addition, the range from QuBound is over 10x narrower than the state-of-the-art analytical approach.",
      "authors": [
        "Jinyang Li",
        "Samudra Dasgupta",
        "Yuhong Song",
        "Lei Yang",
        "Travis Humble",
        "Weiwen Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T22:00:09+00:00",
          "link": "https://arxiv.org/abs/2507.17043v1",
          "size": "18069kb",
          "version": "v1"
        }
      ],
      "title": "Computational Performance Bounds Prediction in Quantum Computing with Unstable Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17043",
        "HTML": "https://arxiv.org/html/2507.17043v1",
        "PDF": "https://arxiv.org/pdf/2507.17043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focused on quantum computing and noise prediction using data-driven approaches, this paper does not address any aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17069",
      "abstract": "When given a generalized matrix separation problem, which aims to recover a low rank matrix $L_0$ and a sparse matrix $S_0$ from $M_0=L_0+HS_0$, the work \\cite{CW25} proposes a novel convex optimization problem whose objective function is the sum of the $\\ell_1$-norm and nuclear norm. In this paper we detail the iterative algorithms and its associated computations for solving this convex optimization problem. We present various efficient implementation strategies, with attention to practical cases where $H$ is circulant, separable, or block structured. Notably, we propose a preconditioning technique that drastically improved the performance of our algorithms in terms of efficiency, accuracy, and robustness. While this paper serves as an illustrative algorithm implementation manual, we also provide theoretical guarantee for our preconditioning strategy. Numerical results illustrate the effectiveness of the proposed approach.",
      "authors": [
        "Xuemei Chen and Owen Deen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T23:09:44+00:00",
          "link": "https://arxiv.org/abs/2507.17069v1",
          "size": "600kb",
          "version": "v1"
        }
      ],
      "title": "The Generalized Matrix Separation Problem: Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17069",
        "HTML": "https://arxiv.org/html/2507.17069v1",
        "PDF": "https://arxiv.org/pdf/2507.17069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about solving a generalized matrix separation problem using convex optimization and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17099",
      "abstract": "While recent research demonstrates that AI route-optimization systems improve taxi driver productivity by 14\\%, this study reveals that such findings capture only a fraction of AI's potential in transportation. We examine comprehensive weather-aware AI systems that integrate deep learning meteorological prediction with machine learning positioning optimization, comparing their performance against traditional operations and route-only AI approaches. Using simulation data from 10,000 taxi operations across varied weather conditions, we find that weather-aware AI systems increase driver revenue by 107.3\\%, compared to 14\\% improvements from route-optimization alone. Weather prediction contributes the largest individual productivity gain, with strong correlations between meteorological conditions and demand ($r=0.575$). Economic analysis reveals annual earnings increases of 13.8 million yen per driver, with rapid payback periods and superior return on investment. These findings suggest that current AI literature significantly underestimates AI's transformative potential by focusing narrowly on routing algorithms, while weather intelligence represents an untapped \\$8.9 billion market opportunity. Our results indicate that future AI implementations should adopt comprehensive approaches that address multiple operational challenges simultaneously rather than optimizing isolated functions.",
      "authors": [
        "Tatsuru Kikuchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Artificial Intelligence (cs.AI)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T00:30:09+00:00",
          "link": "https://arxiv.org/abs/2507.17099v1",
          "size": "2872kb",
          "version": "v1"
        }
      ],
      "title": "Weather-Aware AI Systems versus Route-Optimization AI: A Comprehensive Analysis of AI Applications in Transportation Productivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17099",
        "HTML": "https://arxiv.org/html/2507.17099v1",
        "PDF": "https://arxiv.org/pdf/2507.17099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores AI applications in transportation, focusing on weather-aware systems rather than any aspect of data processing or management relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17115",
      "abstract": "This paper introduces a methodology for identifying and simulating financial and economic systems using stochastically structured reservoir computers (SSRCs). The proposed framework leverages structure-preserving embeddings and graph-informed coupling matrices to model inter-agent dynamics with enhanced interpretability. A constrained optimization scheme ensures that the learned models satisfy both stochastic and structural constraints. Two empirical case studies, a dynamic behavioral model of resource competition among agents, and regional inflation network dynamics, illustrate the effectiveness of the approach in capturing and anticipating complex nonlinear patterns and enabling interpretable predictive analysis under uncertainty.",
      "authors": [
        "Lendy Banegas",
        "Fredy Vides"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Theoretical Economics (econ.TH)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T01:35:33+00:00",
          "link": "https://arxiv.org/abs/2507.17115v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "Stochastically Structured Reservoir Computers for Financial and Economic System Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17115",
        "HTML": "https://arxiv.org/html/2507.17115v1",
        "PDF": "https://arxiv.org/pdf/2507.17115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores financial and economic systems identification using stochastically structured reservoir computers, not concerning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17126",
      "abstract": "The Okada model is a widely used analytical solution for displacements and strains caused by a point or rectangular dislocation source in a 3D elastic half-space. We present OkadaTorch, a PyTorch implementation of the Okada model, where the entire code is differentiable; gradients with respect to input can be easily computed using automatic differentiation (AD). Our work consists of two components: a direct translation of the original Okada model into PyTorch, and a convenient wrapper interface for efficiently computing gradients and Hessians with respect to either observation station coordinates or fault parameters. This differentiable framework is well suited for fault parameter inversion, including gradient-based optimization, Bayesian inference, and integration with scientific machine learning (SciML) models. Our code is available here: https://github.com/msomeya1/OkadaTorch",
      "authors": [
        "Masayoshi Someya",
        "Taisuke Yamada and Tomohisa Okazaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:02:39+00:00",
          "link": "https://arxiv.org/abs/2507.17126v1",
          "size": "1517kb",
          "version": "v1"
        }
      ],
      "title": "OkadaTorch: A Differentiable Programming of Okada Model to Calculate Displacements and Strains from Fault Parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17126",
        "HTML": "https://arxiv.org/html/2507.17126v1",
        "PDF": "https://arxiv.org/pdf/2507.17126"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents OkadaTorch, a PyTorch implementation for calculating displacements and strains using the Okada model, focusing on scientific computing rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17154",
      "abstract": "The aim of this project is to develop a new wireless powered wearable ECG monitoring device. The main goal of the project is to provide a wireless, small-sized ECG monitoring device that can be worn for a long period of time by the monitored person. Electrocardiogram ECG reflects physiological and pathological information about heart activity and is commonly used to diagnose heart disease. Existing wearable smart ECG solutions suffer from high power consumption in both ECG diagnosis and transmission for high accuracy. Monitoring of ECG devices is mainly done by data extraction and acquisition, pre-processing, feature extraction, processing and analysis, visualisation and auxiliary procedures. During the pre-processing of the information, different kinds of noise generated during the signal collection need to be taken into account. The quality of the signal-to-noise ratio can usually be improved by optimising algorithms and reducing the noise power. The choice of electrodes usually has a direct impact on the signal-to-noise ratio and the user experience, and conventional Ag/AgCl gel electrodes are not suitable for long-term and dynamic monitoring as they are prone to skin irritation, inflammation and allergic reactions. Therefore, a completely new way of combining electrodes and wires will be used in the report. The electrodes and wires are cut in one piece from a silver-plated fabric. The wire portion is cut into a curved structure close to an S shape to ensure that it has good ductility for comfort and signal integrity during daily movement of the garment.",
      "authors": [
        "Ruihua Wang",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T02:42:36+00:00",
          "link": "https://arxiv.org/abs/2507.17154v1",
          "size": "1682kb",
          "version": "v1"
        }
      ],
      "title": "Design of a Noval Wearable ECG Monitoring Device",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17154",
        "HTML": "https://arxiv.org/html/2507.17154v1",
        "PDF": "https://arxiv.org/pdf/2507.17154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the development of a wearable ECG monitoring device. It is not related to language model training data processing or any data engineering tasks relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17193",
      "abstract": "As artificial intelligence (AI) advances into diverse applications, ensuring reliability of AI models is increasingly critical. Conventional neural networks offer strong predictive capabilities but produce deterministic outputs without inherent uncertainty estimation, limiting their reliability in safety-critical domains. Probabilistic neural networks (PNNs), which introduce randomness, have emerged as a powerful approach for enabling intrinsic uncertainty quantification. However, traditional CMOS architectures are inherently designed for deterministic operation and actively suppress intrinsic randomness. This poses a fundamental challenge for implementing PNNs, as probabilistic processing introduces significant computational overhead. To address this challenge, we introduce a Magnetic Probabilistic Computing (MPC) platform-an energy-efficient, scalable hardware accelerator that leverages intrinsic magnetic stochasticity for uncertainty-aware computing. This physics-driven strategy utilizes spintronic systems based on magnetic domain walls (DWs) and their dynamics to establish a new paradigm of physical probabilistic computing for AI. The MPC platform integrates three key mechanisms: thermally induced DW stochasticity, voltage controlled magnetic anisotropy (VCMA), and tunneling magnetoresistance (TMR), enabling fully electrical and tunable probabilistic functionality at the device level. As a representative demonstration, we implement a Bayesian Neural Network (BNN) inference structure and validate its functionality on CIFAR-10 classification tasks. Compared to standard 28nm CMOS implementations, our approach achieves a seven orders of magnitude improvement in the overall figure of merit, with substantial gains in area efficiency, energy consumption, and speed. These results underscore the MPC platform's potential to enable reliable and trustworthy physical AI systems.",
      "authors": [
        "Tianyi Wang",
        "Bingqian Dai",
        "Kin Wong",
        "Yaochen Li",
        "Yang Cheng",
        "Qingyuan Shu",
        "Haoran He",
        "Puyang Huang",
        "Hanshen Huang",
        "and Kang L. Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T04:39:04+00:00",
          "link": "https://arxiv.org/abs/2507.17193v1",
          "size": "11092kb",
          "version": "v1"
        }
      ],
      "title": "Spintronic Bayesian Hardware Driven by Stochastic Magnetic Domain Wall Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17193",
        "PDF": "https://arxiv.org/pdf/2507.17193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on spintronic hardware for uncertainty-aware computing and Bayesian Neural Networks, lacking any discussion related to LLM training data processing or dataset handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17224",
      "abstract": "Extracellular recordings are brief voltage fluctuations recorded near neurons, widely used in neuroscience as the basis for decoding brain activity at single-neuron resolution. Spike sorting, which assigns each spike to its source neuron, is a critical step in brain sensing pipelines. However, it remains challenging under low signal-to-noise ratio (SNR), electrode drift, and cross-session variability. In this paper, we propose HuiduRep, a robust self-supervised representation learning framework that extracts discriminative and generalizable features from extracellular spike waveforms. By combining contrastive learning with a denoising autoencoder, HuiduRep learns latent representations that are robust to noise and drift. Built on HuiduRep, we develop a spike sorting pipeline that clusters spike representations without supervision. Experiments on hybrid and real-world datasets demonstrate that HuiduRep achieves strong robustness and the pipeline matches or outperforms state-of-the-art tools such as KiloSort4 and MountainSort5. These findings demonstrate the potential of self-supervised spike representation learning as a foundational tool for robust and generalizable processing of extracellular recordings.",
      "authors": [
        "Feng Cao",
        "Zishuo Feng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T05:45:38+00:00",
          "link": "https://arxiv.org/abs/2507.17224v1",
          "size": "12328kb",
          "version": "v1"
        }
      ],
      "title": "HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17224",
        "HTML": "https://arxiv.org/html/2507.17224v1",
        "PDF": "https://arxiv.org/pdf/2507.17224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on self-supervised learning for neural representations from extracellular spikes, primarily involving spike sorting without supervision in neuroscience, rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17269",
      "abstract": "Early diagnosis and accurate identification of lesion location and progression in prostate cancer (PCa) are critical for assisting clinicians in formulating effective treatment strategies. However, due to the high semantic homogeneity between lesion and non-lesion areas, existing medical image segmentation methods often struggle to accurately comprehend lesion semantics, resulting in the problem of semantic confusion. To address this challenge, we propose a novel Pixel Anchor Module, which guides the model to discover a sparse set of feature anchors that serve to capture and interpret global contextual information. This mechanism enhances the model's nonlinear representation capacity and improves segmentation accuracy within lesion regions. Moreover, we design a self-attention-based Top_k selection strategy to further refine the identification of these feature anchors, and incorporate a focal loss function to mitigate class imbalance, thereby facilitating more precise semantic interpretation across diverse regions. Our method achieves state-of-the-art performance on the PI-CAI dataset, demonstrating 69.73% IoU and 74.32% Dice scores, and significantly improving prostate cancer lesion detection.",
      "authors": [
        "Zhengcheng Lin (1)",
        "Zuobin Ying (2)",
        "Zhenyu Li (3)",
        "Zhenyu Liu (4)",
        "Jian Lu (5)",
        "Weiping Ding (6) ((1)",
        "(2) City University of Macau",
        "(3) Shandong University",
        "(4) Chinese Academy of Sciences",
        "(5) Peking University",
        "(6) Nantong University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T07:10:07+00:00",
          "link": "https://arxiv.org/abs/2507.17269v1",
          "size": "402kb",
          "version": "v1"
        }
      ],
      "title": "MyGO: Make your Goals Obvious, Avoiding Semantic Confusion in Prostate Cancer Lesion Region Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17269",
        "HTML": "https://arxiv.org/html/2507.17269v1",
        "PDF": "https://arxiv.org/pdf/2507.17269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses semantic confusion in medical image segmentation for prostate cancer, focusing on enhancing model representation capacity and segmentation accuracy. It does not relate to LLM training data processing or involve any data processing operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17303",
      "abstract": "Multimodal large language models (MLLMs) have emerged as powerful tools for computational pathology, offering unprecedented opportunities to integrate pathological images with language context for comprehensive diagnostic analysis. These models hold particular promise for automating complex tasks that traditionally require expert interpretation of pathologists. However, current MLLM approaches in pathology demonstrate significantly constrained reasoning capabilities, primarily due to their reliance on expensive chain-of-thought annotations. Additionally, existing methods remain limited to simplex application of visual question answering (VQA) at region-of-interest (ROI) level, failing to address the full spectrum of diagnostic needs such as ROI classification, detection, segmentation, whole-slide-image (WSI) classification and VQA in clinical practice. In this study, we present SmartPath-R1, a versatile MLLM capable of simultaneously addressing both ROI-level and WSI-level tasks while demonstrating robust pathological reasoning capability. Our framework combines scale-dependent supervised fine-tuning and task-aware reinforcement fine-tuning, which circumvents the requirement for chain-of-thought supervision by leveraging the intrinsic knowledge within MLLM. Furthermore, SmartPath-R1 integrates multiscale and multitask analysis through a mixture-of-experts mechanism, enabling dynamic processing for diverse tasks. We curate a large-scale dataset comprising 2.3M ROI samples and 188K WSI samples for training and evaluation. Extensive experiments across 72 tasks validate the effectiveness and superiority of the proposed approach. This work represents a significant step toward developing versatile, reasoning-enhanced AI systems for precision pathology.",
      "authors": [
        "Zhe Xu",
        "Ziyi Liu",
        "Junlin Hou",
        "Jiabo Ma",
        "Cheng Jin",
        "Yihui Wang",
        "Zhixuan Chen",
        "Zhengyu Zhang",
        "Zhengrui Guo",
        "Fengtao Zhou",
        "Yingxue Xu",
        "Xi Wang",
        "Ronald Cheong Kin Chan",
        "Li Liang",
        "Hao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:09:42+00:00",
          "link": "https://arxiv.org/abs/2507.17303v1",
          "size": "8504kb",
          "version": "v1"
        }
      ],
      "title": "A Versatile Pathology Co-pilot via Reasoning Enhanced Multimodal Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17303",
        "HTML": "https://arxiv.org/html/2507.17303v1",
        "PDF": "https://arxiv.org/pdf/2507.17303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SmartPath-R1, which involves curating a large-scale dataset of ROI and WSI samples for training and evaluation of a multimodal LLM. This contributes to dataset creation for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17316",
      "abstract": "We consider the problem of estimating a discrete distribution $p$ with support of size $K$ and provide both upper and lower bounds with high probability in KL divergence. We prove that in the worst case, for any estimator $\\widehat{p}$, with probability at least $\\delta$, $\\text{KL}(p \\| \\widehat{p}) \\geq C\\max\\{K,\\ln(K)\\ln(1/\\delta) \\}/n $, where $n$ is the sample size and $C > 0$ is a constant. We introduce a computationally efficient estimator $p^{\\text{OTB}}$, based on Online to Batch conversion and suffix averaging, and show that with probability at least $1 - \\delta$ $\\text{KL}(p \\| \\widehat{p}) \\leq C(K\\log(\\log(K)) + \\ln(K)\\ln(1/\\delta)) /n$.\n  Furthermore, we also show that with sufficiently many observations relative to $\\log(1/\\delta)$, the maximum likelihood estimator $\\bar{p}$ guarantees that with probability at least $1-\\delta$ $$\n  1/6 \\chi^2(\\bar{p}\\|p) \\leq 1/4 \\chi^2(p\\|\\bar{p}) \\leq \\text{KL}(p|\\bar{p}) \\leq C(K + \\log(1/\\delta))/n\\,, $$ where $\\chi^2$ denotes the $\\chi^2$-divergence.",
      "authors": [
        "Dirk van der Hoeven",
        "Julia Olkhovskaia",
        "Tim van Erven"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T08:30:37+00:00",
          "link": "https://arxiv.org/abs/2507.17316v1",
          "size": "47kb",
          "version": "v1"
        }
      ],
      "title": "Nearly Minimax Discrete Distribution Estimation in Kullback-Leibler Divergence with High Probability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17316",
        "PDF": "https://arxiv.org/pdf/2507.17316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses statistical issues in discrete distribution estimation, aiming to minimize KL divergence. It is not related to processing data for LLM training or any pertinent data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17364",
      "abstract": "In quantum secret sharing, a quantum secret state is mapped to multiple shares such that shares from qualified sets can recover the secret state and shares from other forbidden sets reveal nothing about the secret state; we study the setting where there are both classical shares and quantum shares. We show that the quantum secret sharing problem with both classical and quantum shares is feasible if and only if any two qualified sets have some quantum share in common. Next, for threshold quantum secret sharing where there are $N_1$ classical shares, $N_2$ quantum shares and qualified sets consist of any $K_1$ (or more) classical shares and any $K_2 > N_2/2$ (or more) quantum shares, we show that to share $1$ qubit secret, each classical share needs to be at least $2$ bits and each quantum share needs to be at least $1$ qubit. Finally, we characterize the minimum share sizes for quantum secret sharing with at most $2$ classical shares and at most $2$ quantum shares. The converse proofs rely on quantum information inequalities and the achievable schemes use classical secret sharing, (encrypted) quantum secret sharing with only quantum shares, superdense coding, treating quantum digits as classical digits, and their various combinations.",
      "authors": [
        "Hua Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T09:55:33+00:00",
          "link": "https://arxiv.org/abs/2507.17364v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Secret Sharing with Classical and Quantum Shares",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17364",
        "HTML": "https://arxiv.org/html/2507.17364v1",
        "PDF": "https://arxiv.org/pdf/2507.17364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum secret sharing, which is unrelated to LLM training data processing. The focus is on quantum information theory, addressing issues in quantum and classical shares."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17396",
      "abstract": "This paper proposes a neural framework for power and timing prediction of multi-stage data path, distinguishing itself from traditional lib-based analytical methods dependent on driver characterization and load simplifications. To the best of our knowledge, this is the first language-based, netlist-aware neural network designed explicitly for standard cells. Our approach employs two pre-trained neural models of waveform prediction and delay estimation that directly infer transient waveforms and propagation delays from SPICE netlists, conditioned on critical physical parameters such as load capacitance, input slew, and gate size. This method accurately captures both intrinsic and coupling-induced delay effects without requiring simplification or interpolation. For multi-stage timing prediction, we implement a recursive propagation strategy where predicted waveforms from each stage feed into subsequent stages, cumulatively capturing delays across the logic chain. This approach ensures precise timing alignment and complete waveform visibility throughout complex signal pathways. The waveform prediction utilizes a hybrid CNN-Transformer architecture with netlist-aware node-level encoding, addressing traditional Transformers' fixed input dimensionality constraints. Additionally, specialized subnetworks separately handle primary delay estimation and crosstalk correction. Experimental results demonstrate SPICE-level accuracy, consistently achieving RMSE below 0.0098 across diverse industrial circuits. The proposed framework provides a scalable, structurally adaptable neural alternative to conventional power and timing engines, demonstrating high fidelity to physical circuit behaviors.",
      "authors": [
        "Junlang Huang",
        "Hao Chen",
        "Zhong Guan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T10:46:25+00:00",
          "link": "https://arxiv.org/abs/2507.17396v1",
          "size": "1318kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Scratch: Structurally-masked Transformer for Next Generation Lib-free Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17396",
        "HTML": "https://arxiv.org/html/2507.17396v1",
        "PDF": "https://arxiv.org/pdf/2507.17396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for power and timing prediction in circuits using neural networks. It does not involve LLM training data processing, as it is primarily focused on circuit design and simulation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17439",
      "abstract": "Outliers can severely distort causal effect estimation in observational studies, yet this issue has received limited attention in the literature. Their influence is especially pronounced in small sample sizes, where detecting and removing outliers becomes increasingly difficult. Therefore, it is essential to estimate treatment effects robustly without excluding these influential data points. To address this, we propose a doubly robust point estimator for the average treatment effect under a contaminated model that includes outliers. Robustness in outcome regression is achieved through a robust estimating equation, while covariate balancing propensity scores (CBPS) ensure resilience in propensity score modeling.\n  To prevent model overfitting due to the inclusion of numerous parameters, we incorporate variable selection. All these components are unified under a penalized empirical likelihood framework. For confidence interval estimation, most existing approaches rely on asymptotic properties, which may be unreliable in finite samples. We derive an optimal finite-sample confidence interval for the average treatment effect using our proposed estimating equation, ensuring that the interval bounds remain unaffected by outliers. Through simulations and a real-world application involving hypertension data with outliers, we demonstrate that our method consistently outperforms existing approaches in both accuracy and robustness.",
      "authors": [
        "Joonsung Kang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T11:58:54+00:00",
          "link": "https://arxiv.org/abs/2507.17439v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Doubly robust outlier resistant inference on causal treatment effect",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17439",
        "HTML": "https://arxiv.org/html/2507.17439v1",
        "PDF": "https://arxiv.org/pdf/2507.17439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with causal effect estimation and outlier resistance in observational studies, which is not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17470",
      "abstract": "The ongoing development of quantum processors is driving breakthroughs in scientific discovery. Despite this progress, the formidable cost of fabricating large-scale quantum processors means they will remain rare for the foreseeable future, limiting their widespread application. To address this bottleneck, we introduce the concept of predictive surrogates, which are classical learning models designed to emulate the mean-value behavior of a given quantum processor with provably computational efficiency. In particular, we propose two predictive surrogates that can substantially reduce the need for quantum processor access in diverse practical scenarios. To demonstrate their potential in advancing digital quantum simulation, we use these surrogates to emulate a quantum processor with up to 20 programmable superconducting qubits, enabling efficient pre-training of variational quantum eigensolvers for families of transverse-field Ising models and identification of non-equilibrium Floquet symmetry-protected topological phases. Experimental results reveal that the predictive surrogates not only reduce measurement overhead by orders of magnitude, but can also surpass the performance of conventional, quantum-resource-intensive approaches. Collectively, these findings establish predictive surrogates as a practical pathway to broadening the impact of advanced quantum processors.",
      "authors": [
        "Wei-You Liao",
        "Yuxuan Du",
        "Xinbiao Wang",
        "Tian-Ci Tian",
        "Yong Luo",
        "Bo Du",
        "Dacheng Tao",
        "He-Liang Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T12:51:03+00:00",
          "link": "https://arxiv.org/abs/2507.17470v1",
          "size": "10986kb",
          "version": "v1"
        }
      ],
      "title": "Demonstration of Efficient Predictive Surrogates for Large-scale Quantum Processors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17470",
        "PDF": "https://arxiv.org/pdf/2507.17470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses predictive surrogates for quantum processors, focusing on reducing the need for quantum processor access, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17494",
      "abstract": "In next-generation communications and networks, machine learning (ML) models are expected to deliver not only accurate predictions but also well-calibrated confidence scores that reflect the true likelihood of correct decisions. This paper studies the calibration performance of an ML-based outage predictor within a single-user, multi-resource allocation framework. We first establish key theoretical properties of this system's outage probability (OP) under perfect calibration. Importantly, we show that as the number of resources grows, the OP of a perfectly calibrated predictor approaches the expected output conditioned on it being below the classification threshold. In contrast, when only one resource is available, the system's OP equals the model's overall expected output. We then derive the OP conditions for a perfectly calibrated predictor. These findings guide the choice of the classification threshold to achieve a desired OP, helping system designers meet specific reliability requirements. We also demonstrate that post-processing calibration cannot improve the system's minimum achievable OP, as it does not introduce new information about future channel states. Additionally, we show that well-calibrated models are part of a broader class of predictors that necessarily improve OP. In particular, we establish a monotonicity condition that the accuracy-confidence function must satisfy for such improvement to occur. To demonstrate these theoretical properties, we conduct a rigorous simulation-based analysis using post-processing calibration techniques: Platt scaling and isotonic regression. As part of this framework, the predictor is trained using an outage loss function specifically designed for this system. Furthermore, this analysis is performed on Rayleigh fading channels with temporal correlation captured by Clarke's 2D model, which accounts for receiver mobility.",
      "authors": [
        "Rashika Raina",
        "Nidhi Simmons",
        "David E. Simmons",
        "Michel Daoud Yacoub",
        "Trung Q. Duong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:23:43+00:00",
          "link": "https://arxiv.org/abs/2507.17494v1",
          "size": "14321kb",
          "version": "v1"
        }
      ],
      "title": "To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17494",
        "HTML": "https://arxiv.org/html/2507.17494v1",
        "PDF": "https://arxiv.org/pdf/2507.17494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on calibration in ML-based resource allocation for wireless networks, specifically addressing outage prediction and calibration performance, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17495",
      "abstract": "The rise of quantum networks has revolutionized domains such as communication, sensing, and cybersecurity. Despite this progress, current quantum network systems remain limited in scale, are highly application-specific (e.g., for quantum key distribution), and lack a clear road map for global expansion. These limitations are largely driven by a shortage of skilled professionals, limited accessibility to quantum infrastructure, and the high complexity and cost associated with building and operating quantum hardware. To address these challenges, this paper proposes an open-access software-based quantum network virtualization platform designed to facilitate scalable and remote interaction with quantum hardware. The system is built around a cloud application that virtualizes the core hardware components of a lab-scale quantum network testbed, including the time tagger and optical switch, enabling users to perform coincidence counts of the photon entanglements while ensuring fair resource allocation. The fairness is ensured by employing the Hungarian Algorithm to allocate nearly equal effective entanglement rates among users. We provide implementation details and performance analysis from the perspectives of hardware, software, and cloud platform, which demonstrates the functionality and efficiency of the developed prototype.",
      "authors": [
        "Raj Kamleshkumar Madhu",
        "Visuttha Manthamkarn",
        "Zheshen Zhang",
        "Jianqing Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:24:34+00:00",
          "link": "https://arxiv.org/abs/2507.17495v1",
          "size": "2414kb",
          "version": "v1"
        }
      ],
      "title": "A Virtual Quantum Network Prototype for Open Access",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17495",
        "HTML": "https://arxiv.org/html/2507.17495v1",
        "PDF": "https://arxiv.org/pdf/2507.17495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a virtual quantum network prototype to facilitate access to quantum hardware, which is unrelated to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17505",
      "abstract": "We investigate whether equipping fluid-antenna (FA) receivers with multiple ($L>1$) radiofrequency (RF) chains can improve the performance of the slow fluid-antenna multiple access (FAMA) technique, which enables open-loop connectivity with channel state information (CSI) available only at the receiver side. We analyze the case of slow-FAMA users equipped with multiport receivers, so that $L$ ports of the FA are selected and combined to reduce interference. We show that a joint design of the port selection matrix and the combining vector at each receiver yields significant performance gains over reference schemes, demonstrating the potential of multiport reception in FA systems with a limited number of RF chains.",
      "authors": [
        "Jos\\'e P. Gonz\\'alez-Coma and F. Javier L\\'opez-Mart\\'inez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:42:00+00:00",
          "link": "https://arxiv.org/abs/2507.17505v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Slow Fluid Antenna Multiple Access with Multiport Receivers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17505",
        "HTML": "https://arxiv.org/html/2507.17505v1",
        "PDF": "https://arxiv.org/pdf/2507.17505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses performance improvements in fluid-antenna systems with multiport receivers, concentrating on radiofrequency chain design, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17506",
      "abstract": "This correspondence presents a power-aware cognitive radar framework for joint detection and tracking of multiple targets in a massive multiple-input multiple-output (MIMO) radar environment. Building on a previous single-target algorithm based on Partially Observable Monte Carlo Planning (POMCP), we extend it to the multi-target case by assigning each target an independent POMCP tree, enabling scalable and efficient planning.\n  Departing from uniform power allocation-which is often suboptimal with varying signal-to-noise ratios (SNRs)-our approach predicts each target's future angular position and expected received power, based on its estimated range and radar cross-section (RCS). These predictions guide adaptive waveform design via a constrained optimization problem that allocates transmit energy to enhance the detectability of weaker or distant targets, while ensuring sufficient power for high-SNR targets. The reward function in the underlying partially observable Markov decision process (POMDP) is also modified to prioritize accurate spatial and power estimation.\n  Simulations involving multiple targets with different SNRs confirm the effectiveness of our method. The proposed framework for the cognitive radar improves detection probability for low-SNR targets and achieves more accurate tracking compared to approaches using uniform or orthogonal waveforms. These results demonstrate the potential of the POMCP-based framework for adaptive, efficient multi-target radar systems.",
      "authors": [
        "Imad Bouhou",
        "Stefano Fortunati",
        "Leila Gharsalli",
        "Alexandre Renaux"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:43:29+00:00",
          "link": "https://arxiv.org/abs/2507.17506v1",
          "size": "452kb",
          "version": "v1"
        }
      ],
      "title": "Joint Multi-Target Detection-Tracking in Cognitive Massive MIMO Radar via POMCP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17506",
        "HTML": "https://arxiv.org/html/2507.17506v1",
        "PDF": "https://arxiv.org/pdf/2507.17506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This correspondence presents a power-aware cognitive radar framework and does not involve LLM training data processing, focusing instead on radar detection and tracking algorithms."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17509",
      "abstract": "We present a graph-based deep learning framework for predicting the magnetic properties of quasi-one-dimensional Ising spin systems. The lattice geometry is encoded as a graph and processed by a graph neural network (GNN) followed by fully connected layers. The model is trained on Monte Carlo simulation data and accurately reproduces key features of the magnetization curve, including plateaus, critical transition points, and the effects of geometric frustration. It captures both local motifs and global symmetries, demonstrating that GNNs can infer magnetic behavior directly from structural connectivity. The proposed approach enables efficient prediction of magnetization without the need for additional Monte Carlo simulations.",
      "authors": [
        "V. Slavin",
        "O. Kryvchikov",
        "D. Laptev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T13:47:38+00:00",
          "link": "https://arxiv.org/abs/2507.17509v1",
          "size": "211kb",
          "version": "v1"
        }
      ],
      "title": "Graph Neural Network Approach to Predicting Magnetization in Quasi-One-Dimensional Ising Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17509",
        "HTML": "https://arxiv.org/html/2507.17509v1",
        "PDF": "https://arxiv.org/pdf/2507.17509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a graph neural network approach for predicting magnetization in Ising systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17540",
      "abstract": "In speaker verification, contrastive learning is gaining popularity as an alternative to the traditionally used classification-based approaches. Contrastive methods can benefit from an effective use of hard negative pairs, which are different-class samples particularly challenging for a verification model due to their similarity. In this paper, we propose CHNS - a clustering-based hard negative sampling method, dedicated for supervised contrastive speaker representation learning. Our approach clusters embeddings of similar speakers, and adjusts batch composition to obtain an optimal ratio of hard and easy negatives during contrastive loss calculation. Experimental evaluation shows that CHNS outperforms a baseline supervised contrastive approach with and without loss-based hard negative sampling, as well as a state-of-the-art classification-based approach to speaker verification by as much as 18 % relative EER and minDCF on the VoxCeleb dataset using two lightweight model architectures.",
      "authors": [
        "Piotr Masztalski",
        "Micha{\\l} Romaniuk",
        "Jakub \\.Zak",
        "Mateusz Matuszewski",
        "Konrad Kowalczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:19:33+00:00",
          "link": "https://arxiv.org/abs/2507.17540v1",
          "size": "91kb",
          "version": "v1"
        }
      ],
      "title": "Clustering-based hard negative sampling for supervised contrastive speaker verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17540",
        "HTML": "https://arxiv.org/html/2507.17540v1",
        "PDF": "https://arxiv.org/pdf/2507.17540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a clustering-based hard negative sampling method for speaker verification, which is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17541",
      "abstract": "Modularity is a very widely used measure of the level of clustering or community structure in networks. Here we consider a recent generalisation of the definition of modularity to temporal graphs, whose edge-sets change over discrete timesteps; such graphs offer a more realistic model of many real-world networks in which connections between entities (for example, between individuals in a social network) evolve over time. Computing modularity is notoriously difficult: it is NP-hard even to approximate in general, and only admits efficient exact algorithms in very restricted special cases. Our main result is that a multiplicative approximation to temporal modularity can be computed efficiently when the underlying graph has small treewidth. This generalises a similar approximation algorithm for the static case, but requires some substantially new ideas to overcome technical challenges associated with the temporal nature of the problem.",
      "authors": [
        "Vilhelm Agdur",
        "Jessica Enright",
        "Laura Larios-Jones",
        "Kitty Meeks",
        "Fiona Skerman and Ella Yates"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:19:44+00:00",
          "link": "https://arxiv.org/abs/2507.17541v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Approximating temporal modularity on graphs of small underlying treewidth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17541",
        "HTML": "https://arxiv.org/html/2507.17541v1",
        "PDF": "https://arxiv.org/pdf/2507.17541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on approximating temporal modularity on graphs with a small treewidth and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17544",
      "abstract": "Differential privacy has become a cornerstone in the development of privacy-preserving learning algorithms. This work addresses optimizing differentially private kernel learning within the empirical risk minimization (ERM) framework. We propose a novel differentially private kernel ERM algorithm based on random projection in the reproducing kernel Hilbert space using Gaussian processes. Our method achieves minimax-optimal excess risk for both the squared loss and Lipschitz-smooth convex loss functions under a local strong convexity condition. We further show that existing approaches based on alternative dimension reduction techniques, such as random Fourier feature mappings or $\\ell_2$ regularization, yield suboptimal generalization performance. Our key theoretical contribution also includes the derivation of dimension-free generalization bounds for objective perturbation-based private linear ERM -- marking the first such result that does not rely on noisy gradient-based mechanisms. Additionally, we obtain sharper generalization bounds for existing differentially private kernel ERM algorithms. Empirical evaluations support our theoretical claims, demonstrating that random projection enables statistically efficient and optimally private kernel learning. These findings provide new insights into the design of differentially private algorithms and highlight the central role of dimension reduction in balancing privacy and utility.",
      "authors": [
        "Bonwoo Lee",
        "Cheolwoo Park",
        "Jeongyoun Ahn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:20:46+00:00",
          "link": "https://arxiv.org/abs/2507.17544v1",
          "size": "350kb",
          "version": "v1"
        }
      ],
      "title": "Optimal differentially private kernel learning with random projection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17544",
        "PDF": "https://arxiv.org/pdf/2507.17544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses differentially private kernel learning and does not address any aspect of LLM training data processing, focusing instead on privacy-preserving learning algorithms within the empirical risk minimization framework."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17545",
      "abstract": "We consider the problem of minimizing a difference of (smooth) convex functions over a compact convex feasible region $P$, i.e., $\\min_{x \\in P} f(x) - g(x)$, with smooth $f$ and Lipschitz continuous $g$. This computational study builds upon and complements the framework of Maskan et al. [2025] by integrating advanced Frank-Wolfe variants to reduce computational overhead. We empirically show that constrained DC problems can be efficiently solved using a combination of the Blended Pairwise Conditional Gradients (BPCG) algorithm [Tsuji et al., 2022] with warm-starting and the adaptive error bound from Maskan et al. [2025]. The result is a highly efficient and scalable projection-free algorithm for constrained DC optimization.",
      "authors": [
        "Sebastian Pokutta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T14:22:42+00:00",
          "link": "https://arxiv.org/abs/2507.17545v1",
          "size": "1396kb",
          "version": "v1"
        }
      ],
      "title": "Scalable DC Optimization via Adaptive Frank-Wolfe Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17545",
        "HTML": "https://arxiv.org/html/2507.17545v1",
        "PDF": "https://arxiv.org/pdf/2507.17545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on scalable optimization techniques for solving constrained DC (difference of convex) problems, without any relation to LLM training data processing or the generation of datasets for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17589",
      "abstract": "With the rapid advancement of quantum computing, quantum compilation has become a crucial layer connecting high-level algorithms with physical hardware. In quantum cloud computing, compilation is performed on the cloud side, which exposes user circuits to potential risks such as structural leakage and output predictability. To address these issues, we propose the encrypted-state quantum compilation scheme based on quantum circuit obfuscation (ECQCO), the first secure compilation framework tailored for the co-location of compilers and quantum hardware. It applies quantum homomorphic encryption to conceal output states and instantiates a structure obfuscation mechanism based on quantum indistinguishability obfuscation, effectively protecting both functionality and topology of the circuit. Additionally, an adaptive decoupling obfuscation algorithm is designed to suppress potential idle errors while inserting pulse operations. The proposed scheme achieves information-theoretic security and guarantees computational indistinguishability under the quantum random oracle model. Experimental results on benchmark datasets show that ECQCO achieves a TVD of up to 0.7 and a normalized GED of 0.88, enhancing compilation-stage security. Moreover, it introduces only a slight increase in circuit depth, while keeping the average fidelity change within 1%, thus achieving a practical balance between security and efficiency.",
      "authors": [
        "Chenyi Zhang",
        "Tao Shang",
        "Xueyi Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:23:18+00:00",
          "link": "https://arxiv.org/abs/2507.17589v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "Encrypted-State Quantum Compilation Scheme Based on Quantum Circuit Obfuscation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17589",
        "HTML": "https://arxiv.org/html/2507.17589v1",
        "PDF": "https://arxiv.org/pdf/2507.17589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a secure quantum compilation framework, focusing on quantum circuit obfuscation and encryption, which is not related to the field of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17606",
      "abstract": "In this research, we explore neural network-based methods for pricing multidimensional American put options under the BlackScholes and Heston model, extending up to five dimensions. We focus on two approaches: the Time Deep Gradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the TDGF method to handle the free-boundary partial differential equation inherent in American options. We carefully design the sampling strategy during training to enhance performance. Both TDGF and DGM achieve high accuracy while outperforming conventional Monte Carlo methods in terms of computational speed. In particular, TDGF tends to be faster during training than DGM.",
      "authors": [
        "Jasper Rou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Mathematical Finance (q-fin.MF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:39:39+00:00",
          "link": "https://arxiv.org/abs/2507.17606v1",
          "size": "416kb",
          "version": "v1"
        }
      ],
      "title": "Time Deep Gradient Flow Method for pricing American options",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17606",
        "HTML": "https://arxiv.org/html/2507.17606v1",
        "PDF": "https://arxiv.org/pdf/2507.17606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on neural network-based methods for pricing American options, with an emphasis on computational techniques rather than LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17614",
      "abstract": "Variational quantum algorithms are of special importance in the research on quantum computing applications because of their applicability to current Noisy Intermediate-Scale Quantum (NISQ) devices. The main building blocks of these algorithms (among them, the definition of the Hamiltonian and of the ansatz, the optimizer) define a relatively large parameter space, making the comparison of results and performance between different approaches and software simulators cumbersome and prone to errors. In this paper, we employ a generic description of the problem, in terms of both Hamiltonian and ansatz, to port a problem definition consistently among different simulators. Three use cases of relevance for current quantum hardware (ground state calculation for the Hydrogen molecule, MaxCut, Travelling Salesman Problem) have been run on a set of HPC systems and software simulators to study the dependence of performance on the runtime environment, the scalability of the simulation codes and the mutual agreement of the physical results, respectively. The results show that our toolchain can successfully translate a problem definition between different simulators. On the other hand, variational algorithms are limited in their scaling by the long runtimes with respect to their memory footprint, so they expose limited parallelism to computation. This shortcoming is partially mitigated by using techniques like job arrays. The potential of the parser tool for exploring HPC performance and comparisons of results of variational algorithm simulations is highlighted.",
      "authors": [
        "Marco De Pascale",
        "Tobias Valentin Bauer",
        "Yaknan John Gambo",
        "Mario Hern\\'andez Vera",
        "Stefan Huber",
        "Burak Mete",
        "Amit Jamadagni",
        "Amine Bentellis",
        "Marita Oliv",
        "Luigi Iapichino",
        "Jeanette Miriam Lorenz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T15:46:54+00:00",
          "link": "https://arxiv.org/abs/2507.17614v1",
          "size": "827kb",
          "version": "v1"
        }
      ],
      "title": "Comparing performance of variational quantum algorithm simulations on HPC systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17614",
        "HTML": "https://arxiv.org/html/2507.17614v1",
        "PDF": "https://arxiv.org/pdf/2507.17614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on variational quantum algorithm simulations and does not address any aspect of LLM training data processing. It is concerned with quantum computing applications and performance analysis on HPC systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17662",
      "abstract": "Breast cancer (BC) remains one of the leading causes of cancer-related mortality among women, despite recent advances in Computer-Aided Diagnosis (CAD) systems. Accurate and efficient interpretation of multi-view mammograms is essential for early detection, driving a surge of interest in Artificial Intelligence (AI)-powered CAD models. While state-of-the-art multi-view mammogram classification models are largely based on Transformer architectures, their computational complexity scales quadratically with the number of image patches, highlighting the need for more efficient alternatives. To address this challenge, we propose Mammo-Mamba, a novel framework that integrates Selective State-Space Models (SSMs), transformer-based attention, and expert-driven feature refinement into a unified architecture. Mammo-Mamba extends the MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE) mechanism through its customized SecMamba block. The SecMamba is a modified MambaVision block that enhances representation learning in high-resolution mammographic images by enabling content-adaptive feature refinement. These blocks are integrated into the deeper stages of MambaVision, allowing the model to progressively adjust feature emphasis through dynamic expert gating, effectively mitigating the limitations of traditional Transformer models. Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior classification performance across all key metrics while maintaining computational efficiency.",
      "authors": [
        "Farnoush Bayatmakou",
        "Reza Taleei",
        "Nicole Simone",
        "Arash Mohammadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:29:46+00:00",
          "link": "https://arxiv.org/abs/2507.17662v1",
          "size": "890kb",
          "version": "v1"
        }
      ],
      "title": "Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17662",
        "HTML": "https://arxiv.org/html/2507.17662v1",
        "PDF": "https://arxiv.org/pdf/2507.17662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel architecture called Mammo-Mamba for mammography image processing and does not involve LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17678",
      "abstract": "Myocardial motion tracking is important for assessing cardiac function and diagnosing cardiovascular diseases, for which cine cardiac magnetic resonance (CMR) has been established as the gold standard imaging modality. Many existing methods learn motion from single image pairs consisting of a reference frame and a randomly selected target frame from the cardiac cycle. However, these methods overlook the continuous nature of cardiac motion and often yield inconsistent and non-smooth motion estimations. In this work, we propose a novel Mamba-based cardiac motion tracking network (MCM) that explicitly incorporates target image sequence from the cardiac cycle to achieve smooth and temporally consistent motion tracking. By developing a bi-directional Mamba block equipped with a bi-directional scanning mechanism, our method facilitates the estimation of plausible deformation fields. With our proposed motion decoder that integrates motion information from frames adjacent to the target frame, our method further enhances temporal coherence. Moreover, by taking advantage of Mamba's structured state-space formulation, the proposed method learns the continuous dynamics of the myocardium from sequential images without increasing computational complexity. We evaluate the proposed method on two public datasets. The experimental results demonstrate that the proposed method quantitatively and qualitatively outperforms both conventional and state-of-the-art learning-based cardiac motion tracking methods. The code is available at https://github.com/yjh-0104/MCM.",
      "authors": [
        "Jiahui Yin",
        "Xinxing Cheng",
        "Jinming Duan",
        "Yan Pang",
        "Declan O'Regan",
        "Hadrien Reynaud",
        "Qingjie Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:40:43+00:00",
          "link": "https://arxiv.org/abs/2507.17678v1",
          "size": "2753kb",
          "version": "v1"
        }
      ],
      "title": "MCM: Mamba-based Cardiac Motion Tracking using Sequential Images in MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17678",
        "HTML": "https://arxiv.org/html/2507.17678v1",
        "PDF": "https://arxiv.org/pdf/2507.17678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cardiac motion tracking using MRI, with no mention of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17686",
      "abstract": "Previous studies have shown that hazard ratios between treatment groups estimated with the Cox model are uninterpretable because the indefinite baseline hazard of the model fails to identify temporal change in the risk set composition due to treatment assignment and unobserved factors among multiple, contradictory scenarios. To alleviate this problem, especially in studies based on observational data with uncontrolled dynamic treatment and real-time measurement of many covariates, we propose abandoning the baseline hazard and using machine learning to explicitly model the change in the risk set with or without latent variables. For this framework, we clarify the context in which hazard ratios can be causally interpreted, and then develop a method based on Neyman orthogonality to compute debiased maximum-likelihood estimators of hazard ratios. Computing the constructed estimators is more efficient than computing those based on weighted regression with marginal structural Cox models. Numerical simulations confirm that the proposed method identifies the ground truth with minimal bias. These results lay the foundation for developing a useful, alternative method for causal inference with uncontrolled, observational data in modern epidemiology.",
      "authors": [
        "Takashi Hayakawa and Satoshi Asai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T16:51:09+00:00",
          "link": "https://arxiv.org/abs/2507.17686v1",
          "size": "3111kb",
          "version": "v1"
        }
      ],
      "title": "Debiased maximum-likelihood estimators for hazard ratios under machine-learning adjustment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17686",
        "HTML": "https://arxiv.org/html/2507.17686v1",
        "PDF": "https://arxiv.org/pdf/2507.17686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses statistical methods for computing debiased maximum-likelihood estimators and is concerned with causal inference in epidemiology, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17712",
      "abstract": "The number of qubits in quantum computers keeps growing, but most quantum programs remain relatively small because of the noisy nature of the underlying quantum hardware. This might lead quantum cloud providers to explore increased hardware utilization, and thus profitability through means such as multi-programming, which would allow the execution of multiple programs in parallel. The adoption of such technology would bring entirely new challenges to the field of quantum software security. This article explores and reports the key challenges identified in quantum software security within shared quantum computing environments.",
      "authors": [
        "Samuel Ovaskainen",
        "Majid Haghparast",
        "Tommi Mikkonen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:23:34+00:00",
          "link": "https://arxiv.org/abs/2507.17712v1",
          "size": "89kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Software Security Challenges within Shared Quantum Computing Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17712",
        "HTML": "https://arxiv.org/html/2507.17712v1",
        "PDF": "https://arxiv.org/pdf/2507.17712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses quantum software security challenges, which does not pertain to any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17713",
      "abstract": "Inverse problems governed by partial differential equations (PDEs) play a crucial role in various fields, including computational science, image processing, and engineering. Particularly, Darcy flow equation is a fundamental equation in fluid mechanics, which plays a crucial role in understanding fluid flow through porous media. Bayesian methods provide an effective approach for solving PDEs inverse problems, while their numerical implementation requires numerous evaluations of computationally expensive forward solvers. Therefore, the adoption of surrogate models with lower computational costs is essential. However, constructing a globally accurate surrogate model for high-dimensional complex problems demands high model capacity and large amounts of data. To address this challenge, this study proposes an efficient locally accurate surrogate that focuses on the high-probability regions of the true likelihood in inverse problems, with relatively low model complexity and few training data requirements. Additionally, we introduce a sequential Bayesian design strategy to acquire the proposed surrogate since the high-probability region of the likelihood is unknown. The strategy treats the posterior evolution process of sequential Bayesian design as a Gaussian process, enabling algorithmic acceleration through one-step ahead prior. The complete algorithmic framework is referred to as Sequential Bayesian design for locally accurate surrogate (SBD-LAS). Finally, three experiments based the Darcy flow equation demonstrate the advantages of the proposed method in terms of both inversion accuracy and computational speed.",
      "authors": [
        "Hongji Wang",
        "Hongqiao Wang",
        "Jinyong Ying",
        "Qingping Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:25:14+00:00",
          "link": "https://arxiv.org/abs/2507.17713v1",
          "size": "22749kb",
          "version": "v1"
        }
      ],
      "title": "Sequential Bayesian Design for Efficient Surrogate Construction in the Inversion of Darcy Flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17713",
        "HTML": "https://arxiv.org/html/2507.17713v1",
        "PDF": "https://arxiv.org/pdf/2507.17713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on constructing surrogate models for the inversion of Darcy flows using Bayesian design, addressing computational efficiency in inverse PDE problems, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17726",
      "abstract": "Increasingly large datasets of microscopic images with atomic resolution facilitate the development of machine learning methods to identify and analyze subtle physical phenomena embedded within the images. In this work, microscopic images of honeycomb lattice spin-ice samples serve as datasets from which we automate the calculation of net magnetic moments and directional orientations of spin-ice configurations. In the first stage of our workflow, machine learning models are trained to accurately predict magnetic moments and directions within spin-ice structures. Variational Autoencoders (VAEs), an emergent unsupervised deep learning technique, are employed to generate high-quality synthetic magnetic force microscopy (MFM) images and extract latent feature representations, thereby reducing experimental and segmentation errors. The second stage of proposed methodology enables precise identification and prediction of frustrated vertices and nanomagnetic segments, effectively correlating structural and functional aspects of microscopic images. This facilitates the design of optimized spin-ice configurations with controlled frustration patterns, enabling potential on-demand synthesis.",
      "authors": [
        "Arnab Neogi",
        "Suryakant Mishra",
        "Prasad P Iyer",
        "Tzu-Ming Lu",
        "Ezra Bussmann",
        "Sergei Tretiak",
        "Andrew Crandall Jones",
        "Jian-Xin Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:40:39+00:00",
          "link": "https://arxiv.org/abs/2507.17726v1",
          "size": "16611kb",
          "version": "v1"
        }
      ],
      "title": "Deep Generative Learning of Magnetic Frustration in Artificial Spin Ice from Magnetic Force Microscopy Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17726",
        "HTML": "https://arxiv.org/html/2507.17726v1",
        "PDF": "https://arxiv.org/pdf/2507.17726"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work concentrates on using machine learning methods to analyze magnetic spin-ice configurations from microscopic images, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.17735",
      "abstract": "Accent normalization converts foreign-accented speech into native-like speech while preserving speaker identity. We propose a novel pipeline using self-supervised discrete tokens and non-parallel training data. The system extracts tokens from source speech, converts them through a dedicated model, and synthesizes the output using flow matching. Our method demonstrates superior performance over a frame-to-frame baseline in naturalness, accentedness reduction, and timbre preservation across multiple English accents. Through token-level phonetic analysis, we validate the effectiveness of our token-based approach. We also develop two duration preservation methods, suitable for applications such as dubbing.",
      "authors": [
        "Qibing Bai",
        "Sho Inoue",
        "Shuai Wang",
        "Zhongjie Jiang",
        "Yannan Wang",
        "Haizhou Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-23T17:51:03+00:00",
          "link": "https://arxiv.org/abs/2507.17735v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Accent Normalization Using Self-Supervised Discrete Tokens with Non-Parallel Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.17735",
        "HTML": "https://arxiv.org/html/2507.17735v1",
        "PDF": "https://arxiv.org/pdf/2507.17735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses accent normalization in speech processing using discrete tokens and non-parallel training data, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2108.03776",
      "abstract": "This paper presents and analyzes an immersed finite element (IFE) method for solving Stokes interface problems with a piecewise constant viscosity coefficient that has a jump across the interface. In the method, the triangulation does not need to fit the interface and the IFE spaces are constructed from the traditional $CR$-$P_0$ element with modifications near the interface according to the interface jump conditions. We prove that the IFE basis functions are unisolvent on arbitrary interface elements and the IFE spaces have the optimal approximation capabilities, although the proof is challenging due to the coupling of the velocity and the pressure. The stability and the optimal error estimates of the proposed IFE method are also derived rigorously. The constants in the error estimates are shown to be independent of the interface location relative to the triangulation. Numerical examples are provided to verify the theoretical results.",
      "authors": [
        "Haifeng Ji",
        "Feng Wang",
        "Jinru Chen",
        "Zhilin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2021-08-09T01:51:34+00:00",
          "link": "https://arxiv.org/abs/2108.03776v1",
          "size": "34kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:10:09+00:00",
          "link": "https://arxiv.org/abs/2108.03776v2",
          "size": "38kb",
          "version": "v2"
        }
      ],
      "title": "An immersed $CR$-$P_0$ element for Stokes interface problems and the optimal convergence analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2108.03776",
        "HTML": "https://arxiv.org/html/2108.03776v2",
        "PDF": "https://arxiv.org/pdf/2108.03776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on an immersed finite element method for Stokes interface problems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2206.05437",
      "abstract": "Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The dynamics of the system is a reaction-diffusion process which can separate particles without blowing up. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the particle system solution constitutes the message passing propagation. ACMP which has a simple implementation with a neural ODE solver can propel the network depth up to one hundred of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs circumventing the common GNN problem of oversmoothing. GNNs with ACMP achieve state of the art performance for real-world node classification tasks on both homophilic and heterophilic datasets. Codes are available at https://github.com/ykiiiiii/ACMP.",
      "authors": [
        "Yuelin Wang",
        "Kai Yi",
        "Xinliang Liu",
        "Yu Guang Wang",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-11T06:26:12+00:00",
          "link": "https://arxiv.org/abs/2206.05437v1",
          "size": "2005kb",
          "version": "v1"
        },
        {
          "date": "2022-10-30T08:11:58+00:00",
          "link": "https://arxiv.org/abs/2206.05437v2",
          "size": "2540kb",
          "version": "v2"
        },
        {
          "date": "2023-04-24T01:52:14+00:00",
          "link": "https://arxiv.org/abs/2206.05437v3",
          "size": "2546kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T11:10:40+00:00",
          "link": "https://arxiv.org/abs/2206.05437v4",
          "size": "2089kb",
          "version": "v4"
        }
      ],
      "title": "ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.05437",
        "HTML": "https://arxiv.org/html/2206.05437v4",
        "PDF": "https://arxiv.org/pdf/2206.05437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a message passing framework for graph neural networks, concentrating on model architecture and performance in node classification tasks, with no mention of LLM training data processing."
      },
      "tasks": [
        "Node Classification"
      ],
      "repo_urls": [
        "https://github.com/ykiiiiii/acmp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2301.12309",
      "abstract": "Existing bounds on the generalization error of deep networks assume some form of smooth or bounded dependence on the input variable, falling short of investigating the mechanisms controlling such factors in practice. In this work, we present an extensive experimental study of the empirical Lipschitz constant of deep networks undergoing double descent, and highlight non-monotonic trends strongly correlating with the test error. Building a connection between parameter-space and input-space gradients for SGD around a critical point, we isolate two important factors -- namely loss landscape curvature and distance of parameters from initialization -- respectively controlling optimization dynamics around a critical point and bounding model function complexity, even beyond the training data. Our study presents novels insights on implicit regularization via overparameterization, and effective model complexity for networks trained in practice.",
      "authors": [
        "Matteo Gamba",
        "Hossein Azizpour",
        "M{\\aa}rten Bj\\\"orkman"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-28T23:22:49+00:00",
          "link": "https://arxiv.org/abs/2301.12309v1",
          "size": "1811kb",
          "version": "v1"
        },
        {
          "date": "2023-02-16T03:32:37+00:00",
          "link": "https://arxiv.org/abs/2301.12309v2",
          "size": "1905kb",
          "version": "v2"
        },
        {
          "date": "2023-04-27T13:39:51+00:00",
          "link": "https://arxiv.org/abs/2301.12309v3",
          "size": "31837kb",
          "version": "v3"
        },
        {
          "date": "2023-11-14T15:48:48+00:00",
          "link": "https://arxiv.org/abs/2301.12309v4",
          "size": "33124kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T16:41:45+00:00",
          "link": "https://arxiv.org/abs/2301.12309v5",
          "size": "33138kb",
          "version": "v5"
        }
      ],
      "title": "On the Lipschitz Constant of Deep Networks and Double Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12309",
        "PDF": "https://arxiv.org/pdf/2301.12309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the generalization error and Lipschitz constant of deep networks, with no mention of data processing for LLM training. It deals with model dynamics and complexity rather than dataset operations or improvements."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/magamba/overparameterization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.05103",
      "abstract": "Algorithms wield increasing power over our lives. They can and often do wield that power unfairly, and much has been said about algorithmic fairness. In contrast, algorithmic neutrality has been largely neglected. I investigate algorithmic neutrality, asking: What is it? Is it possible? And what is its normative significance?",
      "authors": [
        "Milo Phillips-Brown"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-09T08:23:56+00:00",
          "link": "https://arxiv.org/abs/2303.05103v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2023-07-13T18:52:59+00:00",
          "link": "https://arxiv.org/abs/2303.05103v2",
          "size": "237kb",
          "version": "v2"
        },
        {
          "date": "2024-06-09T12:14:12+00:00",
          "link": "https://arxiv.org/abs/2303.05103v3",
          "size": "45kb",
          "version": "v3"
        },
        {
          "date": "2025-07-22T19:35:58+00:00",
          "link": "https://arxiv.org/abs/2303.05103v4",
          "size": "51kb",
          "version": "v4"
        }
      ],
      "title": "Algorithmic neutrality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.05103",
        "HTML": "https://arxiv.org/html/2303.05103v4",
        "PDF": "https://arxiv.org/pdf/2303.05103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the concept of algorithmic neutrality, which is unrelated to the processing of LLM training data, instead focusing on the ethics and fairness of algorithms."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2305.08175",
      "abstract": "Noisy marginals are a common form of confidentiality protecting data release and are useful for many downstream tasks such as contingency table analysis, construction of Bayesian networks, and even synthetic data generation. Privacy mechanisms that provide unbiased noisy answers to linear queries (such as marginals) are known as matrix mechanisms.\n  We propose ResidualPlanner and ResidualPlanner+, two highly scalable matrix mechanisms. ResidualPlanner is both optimal and scalable for answering marginal queries with Gaussian noise, while ResidualPlanner+ provides support for more general workloads, such as combinations of marginals and range queries or prefix-sum queries. ResidualPlanner can optimize for many loss functions that can be written as a convex function of marginal variances (prior work was restricted to just one predefined objective function). ResidualPlanner can optimize the accuracy of marginals in large scale settings in seconds, even when the previous state of the art (HDMM) runs out of memory. It even runs on datasets with 100 attributes in a couple of minutes. Furthermore, ResidualPlanner can efficiently compute variance/covariance values for each marginal (prior methods quickly run out of memory, even for relatively small datasets).\n  ResidualPlanner+ provides support for more complex workloads that combine marginal and range/prefix-sum queries (e.g., a marginal on race, a range query on age, and a combined race/age tabulation that answers age range queries for each race). It even supports custom user-defined workloads on different attributes. With this added flexibility, ResidualPlanner+ is not necessarily optimal, however it is still extremely scalable and outperforms the prior state-of-the-art (HDMM) on prefix-sum queries both in terms of accuracy and speed.",
      "authors": [
        "Yingtai Xiao",
        "Guanlin He",
        "Levent Toksoz",
        "Zeyu Ding",
        "Danfeng Zhang",
        "Daniel Kifer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-14T14:55:58+00:00",
          "link": "https://arxiv.org/abs/2305.08175v1",
          "size": "83kb",
          "version": "v1"
        },
        {
          "date": "2023-10-25T20:09:49+00:00",
          "link": "https://arxiv.org/abs/2305.08175v2",
          "size": "84kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T18:43:11+00:00",
          "link": "https://arxiv.org/abs/2305.08175v3",
          "size": "2024kb",
          "version": "v3"
        }
      ],
      "title": "ResidualPlanner+: a scalable matrix mechanism for marginals and beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.08175",
        "PDF": "https://arxiv.org/pdf/2305.08175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ResidualPlanner+, a scalable matrix mechanism for handling marginal queries, with an emphasis on privacy and accuracy of queries. It does not focus on LLM training data processing."
      },
      "conference_url_abs": "https://openreview.net/forum?id=QKSejqE8Vp",
      "tasks": [
        "Synthetic Data Generation"
      ],
      "repo_urls": [
        "https://github.com/dkifer/residualplanner"
      ],
      "source": "arXiv"
    },
    {
      "id": "2305.13613",
      "abstract": "This article presents a Galerkin projection-based reduced-order modelling (ROM) approach for segregated fluid-structure interaction (FSI) problems, formulated within an Arbitrary Lagrangian Eulerian (ALE) framework at low Reynolds numbers using the Finite Volume Method (FVM). The ROM is constructed using Proper Orthogonal Decomposition (POD) and incorporates a data-driven technique that combines classical Galerkin projection with radial basis function (RBF) networks. The results demonstrate the numerical stability and accuracy of the proposed method relative to the high-fidelity model. The ROM successfully captures transient flow fields and, importantly, the forces acting on the moving structure without exhibiting unphysical growth or divergence over time. This is further supported by the bounded evolution of error metrics and physical observables, which remain consistent with the full-order simulations throughout the prediction horizon. The method's effectiveness is validated through a benchmark vortex-induced vibration (VIV) case involving a circular cylinder at Reynolds number Re=200. The hybrid ROM approach yields an accurate and efficient tool for solving FSI problems involving mesh motion.",
      "authors": [
        "Valentin Nkana Ngan and Giovanni Stabile and Andrea Mola and Gianluigi Rozza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-23T02:22:41+00:00",
          "link": "https://arxiv.org/abs/2305.13613v1",
          "size": "1948kb",
          "version": "v1"
        },
        {
          "date": "2024-10-17T21:47:47+00:00",
          "link": "https://arxiv.org/abs/2305.13613v2",
          "size": "11851kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T10:11:29+00:00",
          "link": "https://arxiv.org/abs/2305.13613v3",
          "size": "14327kb",
          "version": "v3"
        }
      ],
      "title": "A reduced-order model for segregated fluid-structure interaction solvers based on an ALE approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.13613",
        "HTML": "https://arxiv.org/html/2305.13613v3",
        "PDF": "https://arxiv.org/pdf/2305.13613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a reduced-order modeling approach for fluid-structure interaction problems using an ALE framework and is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.02862",
      "abstract": "We consider an extension of the classical Total Store Order (TSO) semantics by expanding it to turn-based 2-player safety games. During her turn, a player can select any of the communicating processes and perform its next transition. We consider different formulations of the safety game problem depending on whether one player or both of them transfer messages from the process buffers to the shared memory. We give the complete decidability picture for all the possible alternatives.",
      "authors": [
        "Stephan Spengler and Sanchari Sil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-06T09:42:31+00:00",
          "link": "https://arxiv.org/abs/2309.02862v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2023-09-07T10:37:04+00:00",
          "link": "https://arxiv.org/abs/2309.02862v2",
          "size": "552kb",
          "version": "v2"
        },
        {
          "date": "2024-03-12T15:20:20+00:00",
          "link": "https://arxiv.org/abs/2309.02862v3",
          "size": "70kb",
          "version": "v3"
        },
        {
          "date": "2025-01-30T15:53:19+00:00",
          "link": "https://arxiv.org/abs/2309.02862v4",
          "size": "79kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T11:29:23+00:00",
          "link": "https://arxiv.org/abs/2309.02862v5",
          "size": "64kb",
          "version": "v5"
        }
      ],
      "title": "TSO Games -- On the decidability of safety games under the total store order semantics (extended LMCS version with appendix)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.02862",
        "HTML": "https://arxiv.org/html/2309.02862v5",
        "PDF": "https://arxiv.org/pdf/2309.02862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on the decidability of safety games under total store order semantics, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.12451",
      "abstract": "Exceptionally elegant formulae exist for the fractional Laplacian operator applied to weighted classical orthogonal polynomials. We utilize these results to construct a solver, based on frame properties, for equations involving the fractional Laplacian of any power, $s \\in (0,1)$, on an unbounded domain in one or two dimensions. The numerical method represents solutions in an expansion of weighted classical orthogonal polynomials as well as their unweighted counterparts with a specific extension to $\\mathbb{R}^d$, $d \\in \\{1,2\\}$. We examine the frame properties of this family of functions for the solution expansion and, under standard frame conditions, derive an a priori estimate for the stationary equation. Moreover, we prove one achieves the expected order of convergence when considering an implicit Euler discretization in time for the fractional heat equation. We apply our solver to numerous examples including the fractional heat equation (utilizing up to a $6^\\text{th}$-order Runge--Kutta time discretization), a fractional heat equation with a time-dependent exponent $s(t)$, and a two-dimensional problem, observing spectral convergence in the spatial dimension for sufficiently smooth data.",
      "authors": [
        "Ioannis P. A. Papadopoulos",
        "Timon S. Gutleb",
        "Jos\\'e A. Carrillo and Sheehan Olver"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-21T09:04:53+00:00",
          "link": "https://arxiv.org/abs/2311.12451v1",
          "size": "514kb",
          "version": "v1"
        },
        {
          "date": "2024-02-29T10:38:25+00:00",
          "link": "https://arxiv.org/abs/2311.12451v2",
          "size": "514kb",
          "version": "v2"
        },
        {
          "date": "2025-02-06T11:10:50+00:00",
          "link": "https://arxiv.org/abs/2311.12451v3",
          "size": "238kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T07:16:01+00:00",
          "link": "https://arxiv.org/abs/2311.12451v4",
          "size": "250kb",
          "version": "v4"
        }
      ],
      "title": "A frame approach for equations involving the fractional Laplacian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.12451",
        "HTML": "https://arxiv.org/html/2311.12451v4",
        "PDF": "https://arxiv.org/pdf/2311.12451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a numerical method for solving equations involving the fractional Laplacian using frame properties. It does not focus on any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/ioannispapapadopoulos/fractionalframes.jl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.03584",
      "abstract": "We propose Context Diffusion, a diffusion-based framework that enables image generation models to learn from visual examples presented in context. Recent work tackles such in-context learning for image generation, where a query image is provided alongside context examples and text prompts. However, the quality and context fidelity of the generated images deteriorate when the prompt is not present, demonstrating that these models cannot truly learn from the visual context. To address this, we propose a novel framework that separates the encoding of the visual context and the preservation of the desired image layout. This results in the ability to learn from the visual context and prompts, but also from either of them. Furthermore, we enable our model to handle few-shot settings, to effectively address diverse in-context learning scenarios. Our experiments and human evaluation demonstrate that Context Diffusion excels in both in-domain and out-of-domain tasks, resulting in an overall enhancement in image quality and context fidelity compared to counterpart models.",
      "authors": [
        "Ivona Najdenkoska",
        "Animesh Sinha",
        "Abhimanyu Dubey",
        "Dhruv Mahajan",
        "Vignesh Ramanathan",
        "Filip Radenovic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-06T16:19:51+00:00",
          "link": "https://arxiv.org/abs/2312.03584v1",
          "size": "44763kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:47:48+00:00",
          "link": "https://arxiv.org/abs/2312.03584v2",
          "size": "8644kb",
          "version": "v2"
        }
      ],
      "title": "Context Diffusion: In-Context Aware Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.03584",
        "HTML": "https://arxiv.org/html/2312.03584v2",
        "PDF": "https://arxiv.org/pdf/2312.03584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for image generation and context learning, which does not pertain to LLM training data processing in any capacity."
      },
      "tasks": [
        "Image Generation",
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.03885",
      "abstract": "When training large models, such as neural networks, the full derivatives of order 2 and beyond are usually inaccessible, due to their computational cost. Therefore, among the second-order optimization methods, it is common to bypass the computation of the Hessian by using first-order information, such as the gradient of the parameters (e.g., quasi-Newton methods) or the activations (e.g., K-FAC). In this paper, we focus on the exact and explicit computation of projections of the Hessian and higher-order derivatives on well-chosen subspaces relevant for optimization. Namely, for a given partition of the set of parameters, we compute tensors that can be seen as \"higher-order derivatives according to the partition\", at a reasonable cost as long as the number of subsets of the partition remains small. Then, we give some examples of how these tensors can be used. First, we show how to compute a learning rate per subset of parameters, which can be used for hyperparameter tuning. Second, we show how to use these tensors at order 2 to construct an optimization method that uses information contained in the Hessian. Third, we show how to use these tensors at order 3 (information contained in the third derivative of the loss) to regularize this optimization method. The resulting training step has several interesting properties, including: it takes into account long-range interactions between the layers of the trained neural network, which is usually not the case in similar methods (e.g., K-FAC); the trajectory of the optimization is invariant under affine layer-wise reparameterization.",
      "authors": [
        "Pierre Wolinski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-06T20:24:05+00:00",
          "link": "https://arxiv.org/abs/2312.03885v1",
          "size": "532kb",
          "version": "v1"
        },
        {
          "date": "2024-02-03T09:00:08+00:00",
          "link": "https://arxiv.org/abs/2312.03885v2",
          "size": "146kb",
          "version": "v2"
        },
        {
          "date": "2025-01-23T11:18:13+00:00",
          "link": "https://arxiv.org/abs/2312.03885v3",
          "size": "1442kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T11:50:49+00:00",
          "link": "https://arxiv.org/abs/2312.03885v4",
          "size": "358kb",
          "version": "v4"
        }
      ],
      "title": "Gathering and Exploiting Higher-Order Information when Training Large Structured Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.03885",
        "HTML": "https://arxiv.org/html/2312.03885v4",
        "PDF": "https://arxiv.org/pdf/2312.03885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper delves into optimization methods for training large structured models and does not touch upon any processes related to LLM training data processing."
      },
      "tasks": [
        "Second-order methods"
      ],
      "repo_urls": [
        "https://github.com/p-wol/GroupedNewton"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.11053",
      "abstract": "Temporal facts, which are used to describe events that occur during specific time periods, have become a topic of increased interest in the field of knowledge graph (KG) research. In terms of quality management, the introduction of time restrictions brings new challenges to maintaining the temporal consistency of KGs. Previous studies rely on manually enumerated temporal constraints to detect conflicts, which are labor-intensive and may have granularity issues. To address this problem, we start from the common pattern of temporal facts and propose a pattern-based temporal constraint mining method, PaTeCon. Unlike previous studies, PaTeCon uses graph patterns and statistical information relevant to the given KG to automatically generate temporal constraints, without the need for human experts. In this paper, we illustrate how this method can be optimized to achieve significant speed improvement. We also annotate Wikidata and Freebase to build two new benchmarks for conflict detection. Extensive experiments demonstrate that our pattern-based automatic constraint mining approach is highly effective in generating valuable temporal constraints.",
      "authors": [
        "Jianhao Chen",
        "Junyang Ren",
        "Wentao Ding",
        "Haoyuan Ouyang",
        "Wei Hu",
        "Yuzhong Qu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-18T09:35:43+00:00",
          "link": "https://arxiv.org/abs/2312.11053v1",
          "size": "778kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:36:26+00:00",
          "link": "https://arxiv.org/abs/2312.11053v2",
          "size": "655kb",
          "version": "v2"
        }
      ],
      "title": "Conflict Detection for Temporal Knowledge Graphs:A Fast Constraint Mining Algorithm and New Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.11053",
        "PDF": "https://arxiv.org/pdf/2312.11053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on conflict detection in temporal knowledge graphs through constraint mining, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Management"
      ],
      "repo_urls": [
        "https://github.com/jianhaochen-nju/patecon"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.15234",
      "abstract": "In the rapidly evolving landscape of artificial intelligence (AI), generative large language models (LLMs) stand at the forefront, revolutionizing how we interact with our data. However, the computational intensity and memory consumption of deploying these models present substantial challenges in terms of serving efficiency, particularly in scenarios demanding low latency and high throughput. This survey addresses the imperative need for efficient LLM serving methodologies from a machine learning system (MLSys) research perspective, standing at the crux of advanced AI innovations and practical system optimizations. We provide in-depth analysis, covering a spectrum of solutions, ranging from cutting-edge algorithmic modifications to groundbreaking changes in system designs. The survey aims to provide a comprehensive understanding of the current state and future directions in efficient LLM serving, offering valuable insights for researchers and practitioners in overcoming the barriers of effective LLM deployment, thereby reshaping the future of AI.",
      "authors": [
        "Xupeng Miao",
        "Gabriele Oliaro",
        "Zhihao Zhang",
        "Xinhao Cheng",
        "Hongyi Jin",
        "Tianqi Chen",
        "Zhihao Jia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-23T11:57:53+00:00",
          "link": "https://arxiv.org/abs/2312.15234v1",
          "size": "335kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:11:55+00:00",
          "link": "https://arxiv.org/abs/2312.15234v2",
          "size": "858kb",
          "version": "v2"
        }
      ],
      "title": "Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.15234",
        "HTML": "https://arxiv.org/html/2312.15234v2",
        "PDF": "https://arxiv.org/pdf/2312.15234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey discusses efficiency in serving generative LLMs but does not cover topics related to training data processing, collection, or improvement."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.01100",
      "abstract": "As a pivotal branch of machine learning, manifold learning uncovers the intrinsic low-dimensional structure within complex nonlinear manifolds in high-dimensional space for visualization, classification, clustering, and gaining key insights. Although existing techniques have achieved remarkable successes, they suffer from extensive distortions of cluster structure, which hinders the understanding of underlying patterns. Scalability issues also limit their applicability for handling large-scale data. We hence propose a sampling-based Scalable manifold learning technique that enables Uniform and Discriminative Embedding, namely SUDE, for large-scale and high-dimensional data. It starts by seeking a set of landmarks to construct the low-dimensional skeleton of the entire data, and then incorporates the non-landmarks into the learned space based on the constrained locally linear embedding (CLLE). We empirically validated the effectiveness of SUDE on synthetic datasets and real-world benchmarks, and applied it to analyze single-cell data and detect anomalies in electrocardiogram (ECG) signals. SUDE exhibits distinct advantage in scalability with respect to data size and embedding dimension, and has promising performance in cluster separation, integrity, and global structure preservation. The experiments also demonstrate notable robustness in embedding quality as the sampling rate decreases.",
      "authors": [
        "Dehua Peng",
        "Zhipeng Gui",
        "Wenzhang Wei",
        "Fa Li",
        "Jie Gui",
        "Huayi Wu",
        "Jianya Gong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-02T08:43:06+00:00",
          "link": "https://arxiv.org/abs/2401.01100v1",
          "size": "5599kb",
          "version": "v1"
        },
        {
          "date": "2024-01-05T08:09:14+00:00",
          "link": "https://arxiv.org/abs/2401.01100v2",
          "size": "5605kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T14:08:03+00:00",
          "link": "https://arxiv.org/abs/2401.01100v3",
          "size": "19618kb",
          "version": "v3"
        }
      ],
      "title": "Sampling-enabled scalable manifold learning unveils discriminative cluster structure of high-dimensional data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01100",
        "PDF": "https://arxiv.org/pdf/2401.01100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on scalable manifold learning technique for clustering high-dimensional data, which pertains to visualization and classification rather than LLM training data processing."
      },
      "tasks": [
        "Dimensionality Reduction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.01799",
      "abstract": "Lattices with minimal normalized second moments are designed using a new numerical optimization algorithm. Starting from a random lower-triangular generator matrix and applying stochastic gradient descent, all elements are updated towards the negative gradient, which makes it the most efficient algorithm proposed so far for this purpose. A graphical illustration of the theta series, called theta image, is introduced and shown to be a powerful tool for converting numerical lattice representations into their underlying exact forms. As a proof of concept, optimized lattices are designed in dimensions up to 16. In all dimensions, the algorithm converges to either the previously best known lattice or a better one. The dual of the 15-dimensional laminated lattice is conjectured to be optimal in its dimension and its exact normalized second moment is computed.",
      "authors": [
        "Erik Agrell",
        "Daniel Pook-Kolb",
        "and Bruce Allen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Metric Geometry (math.MG)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-03T15:56:37+00:00",
          "link": "https://arxiv.org/abs/2401.01799v1",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "2024-06-23T10:42:28+00:00",
          "link": "https://arxiv.org/abs/2401.01799v2",
          "size": "83kb",
          "version": "v2"
        },
        {
          "date": "2025-04-25T19:25:00+00:00",
          "link": "https://arxiv.org/abs/2401.01799v3",
          "size": "50kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T11:58:29+00:00",
          "link": "https://arxiv.org/abs/2401.01799v4",
          "size": "51kb",
          "version": "v4"
        }
      ],
      "title": "Optimization and Identification of Lattice Quantizers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01799",
        "PDF": "https://arxiv.org/pdf/2401.01799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on the optimization of lattice quantizers using a numerical algorithm, which is unrelated to LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.03812",
      "abstract": "In the digital age, data has emerged as one of the most valuable assets across various sectors, including academia, industry, and healthcare. Effective data preservation involves the management of data to ensure its long-term accessibility and usability. Given the importance and sensitivity of data, the need for effective management is a crucial necessity. One of the big recent proposed approaches for data management is the FAIR Digital Objects (FDOs) which has emerged to revolutionize the field of data management and preservation. Central to this revolution is the alignment of FDOs with the FAIR principles (Findable, Accessible, Interoperable, Reusable), particularly emphasizing machine-actionability and interoperability across diverse data ecosystems. This paper presents \"FDO Manager\" a Minimum Viable Implementation of FDOs, tailored specifically for the use case and field of research artefacts such as datasets, publications, and code. The paper discusses the core ideas behind the FDO Manager, its architecture, usage and implementation details, as well as its potential impact, demonstrating a simple and abstract implementation of FDOs in the research realm.",
      "authors": [
        "Oussama Zoubia and Nagaraj Bahubali Asundi and Adamantios Koumpis and Christoph Lange and Sezin Dogan and Oya Beyan and Zeyd Boukhers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-06T08:57:12+00:00",
          "link": "https://arxiv.org/abs/2402.03812v1",
          "size": "518kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:27:48+00:00",
          "link": "https://arxiv.org/abs/2402.03812v2",
          "size": "165kb",
          "version": "v2"
        }
      ],
      "title": "FDO Manager: Minimum Viable FAIR Digital Object Implementation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.03812",
        "HTML": "https://arxiv.org/html/2402.03812v2",
        "PDF": "https://arxiv.org/pdf/2402.03812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the FDO Manager, an implementation for managing digital objects following FAIR principles, not specifically addressing LLM training data processing or dataset manipulation."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.13574",
      "abstract": "Nowadays, reading or writing comments on captivating videos has emerged as a critical part of the viewing experience on online video platforms. However, existing recommender systems primarily focus on users' interaction behaviors with videos, neglecting comment content and interaction in user preference modeling. In this paper, we propose a novel recommendation approach called LSVCR that utilizes user interaction histories with both videos and comments to jointly perform personalized video and comment recommendation. Specifically, our approach comprises two key components: sequential recommendation (SR) model and supplemental large language model (LLM) recommender. The SR model functions as the primary recommendation backbone (retained in deployment) of our method for efficient user preference modeling. Concurrently, we employ a LLM as the supplemental recommender (discarded in deployment) to better capture underlying user preferences derived from heterogeneous interaction behaviors. In order to integrate the strengths of the SR model and the supplemental LLM recommender, we introduce a two-stage training paradigm. The first stage, personalized preference alignment, aims to align the preference representations from both components, thereby enhancing the semantics of the SR model. The second stage, recommendation-oriented fine-tuning, involves fine-tuning the alignment-enhanced SR model according to specific objectives. Extensive experiments in both video and comment recommendation tasks demonstrate the effectiveness of LSVCR. Moreover, online A/B testing on KuaiShou platform verifies the practical benefits of our approach. In particular, we attain a cumulative gain of 4.13% in comment watch time.",
      "authors": [
        "Bowen Zheng",
        "Zihan Lin",
        "Enze Liu",
        "Chen Yang",
        "Enyang Bai",
        "Cheng Ling",
        "Wayne Xin Zhao",
        "Ji-Rong Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-20T13:14:29+00:00",
          "link": "https://arxiv.org/abs/2403.13574v1",
          "size": "504kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:55:50+00:00",
          "link": "https://arxiv.org/abs/2403.13574v2",
          "size": "497kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Sequential Recommender with Large Language Models for Joint Video and Comment Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13574",
        "HTML": "https://arxiv.org/html/2403.13574v2",
        "PDF": "https://arxiv.org/pdf/2403.13574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a recommendation system using a large language model (LLM) for fine-tuning user interaction preferences. It involves fine-tuning and integration but does not specifically focus on data processing techniques related to LLM training data."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Recommendation Systems",
        "Sequential Recommendation"
      ],
      "repo_urls": [
        "https://github.com/rucaibox/lsvcr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.14459",
      "abstract": "Despite the increasing use of large language models (LLMs) for context-grounded tasks like summarization and question-answering, understanding what makes an LLM produce a certain response is challenging. We propose Multi-Level Explanations for Generative Language Models (MExGen), a technique to provide explanations for context-grounded text generation. MExGen assigns scores to parts of the context to quantify their influence on the model's output. It extends attribution methods like LIME and SHAP to LLMs used in context-grounded tasks where (1) inference cost is high, (2) input text is long, and (3) the output is text. We conduct a systematic evaluation, both automated and human, of perturbation-based attribution methods for summarization and question answering. The results show that our framework can provide more faithful explanations of generated output than available alternatives, including LLM self-explanations. We open-source code for MExGen as part of the ICX360 toolkit: https://github$.$com/IBM/ICX360.",
      "authors": [
        "Lucas Monteiro Paes",
        "Dennis Wei",
        "Hyo Jin Do",
        "Hendrik Strobelt",
        "Ronny Luss",
        "Amit Dhurandhar",
        "Manish Nagireddy",
        "Karthikeyan Natesan Ramamurthy",
        "Prasanna Sattigeri",
        "Werner Geyer",
        "Soumya Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-21T15:06:14+00:00",
          "link": "https://arxiv.org/abs/2403.14459v1",
          "size": "3545kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:48:23+00:00",
          "link": "https://arxiv.org/abs/2403.14459v2",
          "size": "2003kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Level Explanations for Generative Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.14459",
        "HTML": "https://arxiv.org/html/2403.14459v2",
        "PDF": "https://arxiv.org/pdf/2403.14459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for providing explanations for outputs of generative LLMs focused on context-grounded tasks, unrelated to LLM training data processing."
      },
      "tasks": [
        "Question Answering",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.11944",
      "abstract": "Multi-view learning methods often focus on improving decision accuracy while neglecting the decision uncertainty, which significantly restricts their applications in safety-critical scenarios. To address this, trusted multi-view learning methods estimate prediction uncertainties by learning class distributions from each instance. However, these methods heavily rely on high quality ground-truth labels. This motivates us to delve into a new problem: how to develop a reliable multi-view learning model under the guidance of noisy labels? We propose the Trusted Multi view Noise Refining (TMNR) method to address this challenge by modeling label noise arising from low-quality data features and easily-confused classes. TMNR employs evidential deep neural networks to construct view-specific opinions that capture both beliefs and uncertainty. These opinions are then transformed through noise correlation matrices to align with the noisy supervision, where matrix elements are constrained by sample uncertainty to reflect label reliability. Furthermore, considering the challenge of jointly optimizing the evidence network and noise correlation matrices under noisy supervision, we further propose Trusted Multi-view Noise Re-Refining (TMNR^2 ), which disentangles this complex co-training problem by establishing different training objectives for distinct modules. TMNR^2 identifies potentially mislabeled samples through evidence-label consistency and generates pseudo-labels from neighboring information. By assigning clean samples to optimize evidential networks and noisy samples to guide noise correlation matrices, respectively, TMNR^2 reduces mapping interference and achieves stabilizes training. Experimental results demonstrate that TMNR^2 significantly outperforms baseline methods, with average accuracy improvements of 7% on datasets with 50% label noise.",
      "authors": [
        "Yilin Zhang",
        "Cai Xu",
        "Han Jiang",
        "Ziyu Guan",
        "Wei Zhao",
        "Xiaofei He",
        "and Murat Sensoy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-18T06:47:30+00:00",
          "link": "https://arxiv.org/abs/2404.11944v1",
          "size": "3818kb",
          "version": "v1"
        },
        {
          "date": "2024-05-10T06:20:22+00:00",
          "link": "https://arxiv.org/abs/2404.11944v2",
          "size": "3823kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:34:21+00:00",
          "link": "https://arxiv.org/abs/2404.11944v3",
          "size": "7588kb",
          "version": "v3"
        }
      ],
      "title": "Trusted Multi-view Learning under Noisy Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.11944",
        "HTML": "https://arxiv.org/html/2404.11944v3",
        "PDF": "https://arxiv.org/pdf/2404.11944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces methods to improve prediction uncertainty estimation in multi-view learning under noisy supervision, which includes handling low-quality data features, but it does not primarily focus on LLM training data processing."
      },
      "tasks": [
        "MULTI-VIEW LEARNING"
      ],
      "repo_urls": [
        "https://github.com/YilinZhang107/TMNR"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.19664",
      "abstract": "Scaling deep learning to massive and diverse internet data has driven remarkable breakthroughs in domains such as video generation and natural language processing. Robot learning, however, has thus far failed to replicate this success and remains constrained by a scarcity of available data. Learning from videos (LfV) methods aim to address this data bottleneck by augmenting traditional robot data with large-scale internet video. This video data provides foundational information regarding physical dynamics, behaviours, and tasks, and can be highly informative for general-purpose robots.\n  This survey systematically examines the emerging field of LfV. We first outline essential concepts, including detailing fundamental LfV challenges such as distribution shift and missing action labels in video data. Next, we comprehensively review current methods for extracting knowledge from large-scale internet video, overcoming LfV challenges, and improving robot learning through video-informed training. The survey concludes with a critical discussion of future opportunities. Here, we emphasize the need for scalable foundation model approaches that can leverage the full range of available internet video and enhance the learning of robot policies and dynamics models. Overall, the survey aims to inform and catalyse future LfV research, driving progress towards general-purpose robots.",
      "authors": [
        "Robert McCarthy",
        "Daniel C.H. Tan",
        "Dominik Schmidt",
        "Fernando Acero",
        "Nathan Herr",
        "Yilun Du",
        "Thomas G. Thuruthel",
        "Zhibin Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-30T15:57:41+00:00",
          "link": "https://arxiv.org/abs/2404.19664v1",
          "size": "3888kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T09:25:42+00:00",
          "link": "https://arxiv.org/abs/2404.19664v2",
          "size": "913kb",
          "version": "v2"
        },
        {
          "date": "2024-10-14T17:41:06+00:00",
          "link": "https://arxiv.org/abs/2404.19664v3",
          "size": "1636kb",
          "version": "v3"
        },
        {
          "date": "2024-11-12T12:43:42+00:00",
          "link": "https://arxiv.org/abs/2404.19664v4",
          "size": "1644kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T17:31:03+00:00",
          "link": "https://arxiv.org/abs/2404.19664v5",
          "size": "1183kb",
          "version": "v5"
        }
      ],
      "title": "Towards Generalist Robot Learning from Internet Video: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.19664",
        "HTML": "https://arxiv.org/html/2404.19664v5",
        "PDF": "https://arxiv.org/pdf/2404.19664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey focuses on learning from videos to improve robot learning, which is unrelated to data processing for LLM training."
      },
      "tasks": [
        "Natural Language Understanding",
        "Reinforcement Learning (RL)",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.08427",
      "abstract": "Stickers are increasingly used in social media to express sentiment and intent. Despite their significant impact on sentiment analysis and intent recognition, little research has been conducted in this area. To address this gap, we propose a new task: \\textbf{M}ultimodal chat \\textbf{S}entiment \\textbf{A}nalysis and \\textbf{I}ntent \\textbf{R}ecognition involving \\textbf{S}tickers (MSAIRS). Additionally, we introduce a novel multimodal dataset containing Chinese chat records and stickers excerpted from several mainstream social media platforms. Our dataset includes paired data with the same text but different stickers, the same sticker but different contexts, and various stickers consisting of the same images with different texts, allowing us to better understand the impact of stickers on chat sentiment and intent. We also propose an effective multimodal joint model, MMSAIR, featuring differential vector construction and cascaded attention mechanisms for enhanced multimodal fusion. Our experiments demonstrate the necessity and effectiveness of jointly modeling sentiment and intent, as they mutually reinforce each other's recognition accuracy. MMSAIR significantly outperforms traditional models and advanced MLLMs, demonstrating the challenge and uniqueness of sticker interpretation in social media. Our dataset and code are available on https://github.com/FakerBoom/MSAIRS-Dataset.",
      "authors": [
        "Yuanchen Shi",
        "Biao Ma",
        "Longyin Zhang",
        "and Fang Kong"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-14T08:42:49+00:00",
          "link": "https://arxiv.org/abs/2405.08427v1",
          "size": "7238kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:35:12+00:00",
          "link": "https://arxiv.org/abs/2405.08427v2",
          "size": "6376kb",
          "version": "v2"
        }
      ],
      "title": "Impact of Stickers on Multimodal Sentiment and Intent in Social Media: A New Task, Dataset and Baseline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.08427",
        "HTML": "https://arxiv.org/html/2405.08427v2",
        "PDF": "https://arxiv.org/pdf/2405.08427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on sentiment and intent recognition involving stickers in social media, introducing a new task and dataset for this purpose. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Intent Recognition",
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.15632",
      "abstract": "Federated Learning (FL), a privacy-aware approach in distributed deep learning environments, enables many clients to collaboratively train a model without sharing sensitive data, thereby reducing privacy risks. However, enabling human trust and control over FL systems requires understanding the evolving behaviour of clients, whether beneficial or detrimental for the training, which still represents a key challenge in the current literature. To address this challenge, we introduce Federated Behavioural Planes (FBPs), a novel method to analyse, visualise, and explain the dynamics of FL systems, showing how clients behave under two different lenses: predictive performance (error behavioural space) and decision-making processes (counterfactual behavioural space). Our experiments demonstrate that FBPs provide informative trajectories describing the evolving states of clients and their contributions to the global model, thereby enabling the identification of clusters of clients with similar behaviours. Leveraging the patterns identified by FBPs, we propose a robust aggregation technique named Federated Behavioural Shields to detect malicious or noisy client models, thereby enhancing security and surpassing the efficacy of existing state-of-the-art FL defense mechanisms. Our code is publicly available on GitHub.",
      "authors": [
        "Dario Fenoglio",
        "Gabriele Dominici",
        "Pietro Barbiero",
        "Alberto Tonda",
        "Martin Gjoreski",
        "Marc Langheinrich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-24T15:17:51+00:00",
          "link": "https://arxiv.org/abs/2405.15632v1",
          "size": "3584kb",
          "version": "v1"
        },
        {
          "date": "2024-10-13T16:40:29+00:00",
          "link": "https://arxiv.org/abs/2405.15632v2",
          "size": "4036kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T14:57:55+00:00",
          "link": "https://arxiv.org/abs/2405.15632v3",
          "size": "4042kb",
          "version": "v3"
        }
      ],
      "title": "Federated Behavioural Planes: Explaining the Evolution of Client Behaviour in Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15632",
        "HTML": "https://arxiv.org/html/2405.15632v3",
        "PDF": "https://arxiv.org/pdf/2405.15632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Federated Behavioural Planes for understanding client behavior in Federated Learning, focusing on enhancing FL system security. It does not relate to LLM training data processing."
      },
      "tasks": [
        "counterfactual",
        "Decision Making",
        "Federated Learning"
      ],
      "repo_urls": [
        "https://github.com/dariofenoglio98/cf_fl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.07661",
      "abstract": "Perceiving and autonomously navigating through work zones is a challenging and underexplored problem. Open datasets for this long-tailed scenario are scarce. We propose the ROADWork dataset to learn to recognize, observe, analyze, and drive through work zones. State-of-the-art foundation models fail when applied to work zones. Fine-tuning models on our dataset significantly improves perception and navigation in work zones. With ROADWork dataset, we discover new work zone images with higher precision (+32.5%) at a much higher rate (12.8$\\times$) around the world. Open-vocabulary methods fail too, whereas fine-tuned detectors improve performance (+32.2 AP). Vision-Language Models (VLMs) struggle to describe work zones, but fine-tuning substantially improves performance (+36.7 SPICE).\n  Beyond fine-tuning, we show the value of simple techniques. Video label propagation provides additional gains (+2.6 AP) for instance segmentation. While reading work zone signs, composing a detector and text spotter via crop-scaling improves performance +14.2% 1-NED). Composing work zone detections to provide context further reduces hallucinations (+3.9 SPICE) in VLMs. We predict navigational goals and compute drivable paths from work zone videos. Incorporating road work semantics ensures 53.6% goals have angular error (AE) < 0.5 (+9.9 %) and 75.3% pathways have AE < 0.5 (+8.1 %).",
      "authors": [
        "Anurag Ghosh",
        "Shen Zheng",
        "Robert Tamburo",
        "Khiem Vuong",
        "Juan Alvarez-Padilla",
        "Hailiang Zhu",
        "Michael Cardei",
        "Nicholas Dunn",
        "Christoph Mertz",
        "Srinivasa G. Narasimhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-11T19:06:41+00:00",
          "link": "https://arxiv.org/abs/2406.07661v1",
          "size": "47870kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T23:55:25+00:00",
          "link": "https://arxiv.org/abs/2406.07661v2",
          "size": "43985kb",
          "version": "v2"
        }
      ],
      "title": "ROADWork Dataset: Learning to Recognize, Observe, Analyze and Drive Through Work Zones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.07661",
        "HTML": "https://arxiv.org/html/2406.07661v2",
        "PDF": "https://arxiv.org/pdf/2406.07661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The ROADWork dataset is introduced for improving perception and navigation in work zones, with techniques that include fine-tuning for task performance improvement. While it involves dataset creation and fine-tuning, the primary focus is not on LLM training data processes."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2406.10447",
      "abstract": "Human children far exceed modern machine learning algorithms in their sample efficiency, achieving high performance in key domains with much less data than current models. This ''data gap'' is a key challenge both for building intelligent artificial systems and for understanding human development. Egocentric video capturing children's experience--their ''training data''--is a key ingredient for comparison of humans and models and for the development of algorithmic innovations to bridge this gap. Yet there are few such datasets available, and extant data are low-resolution, have limited metadata, and importantly, represent only a small set of children's experiences. Here, we provide the first release of a large developmental egocentric video dataset--the BabyView dataset--recorded using a high-resolution camera with a large vertical field-of-view and gyroscope/accelerometer data. This 868 hour dataset includes egocentric videos from children spanning 6 months to 3 years of age in longitudinal, at-home contexts. We provide gold-standard annotations for the evaluation of speech transcription, speaker diarization, and human pose estimation, and evaluate models in each of these domains. We train self-supervised language and vision models and evaluate their transfer to out-of-distribution tasks, including syntactic structure learning, object recognition, depth estimation, and image segmentation. Although performance in each domain scales with dataset size, overall performance is relatively lower than when models are trained on curated datasets, especially in the visual domain. Our dataset stands as an open challenge for robust, human-like AI systems: how can such systems achieve human-levels of success on the same scale and distribution of training data as humans?",
      "authors": [
        "Bria Long",
        "Robert Z. Sparks",
        "Violet Xiang",
        "Stefan Stojanov",
        "Zi Yin",
        "Grace E. Keene",
        "Alvin W. M. Tan",
        "Steven Y. Feng",
        "Chengxu Zhuang",
        "Virginia A. Marchman",
        "Daniel L. K. Yamins",
        "and Michael C. Frank"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-14T23:52:27+00:00",
          "link": "https://arxiv.org/abs/2406.10447v1",
          "size": "17742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T22:34:57+00:00",
          "link": "https://arxiv.org/abs/2406.10447v2",
          "size": "30654kb",
          "version": "v2"
        }
      ],
      "title": "The BabyView dataset: High-resolution egocentric videos of infants' and young children's everyday experiences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10447",
        "HTML": "https://arxiv.org/html/2406.10447v2",
        "PDF": "https://arxiv.org/pdf/2406.10447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the BabyView dataset, which is a large-scale developmental egocentric video dataset. While the dataset is used to train models in domains such as language and vision, its main focus is human AI comparison and development, not directly on LLM training data processing."
      },
      "tasks": [
        "Depth Estimation",
        "Image Segmentation",
        "Object Recognition",
        "Pose Estimation",
        "Semantic Segmentation",
        "speaker-diarization",
        "Speaker Diarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.13166",
      "abstract": "The increasing scale and complexity of global supply chains have led to new challenges spanning various fields, such as supply chain disruptions due to long waiting lines at the ports, material shortages, and inflation. Coupled with the size of supply chains and the availability of vast amounts of data, efforts towards tackling such challenges have led to an increasing interest in applying machine learning methods in many aspects of supply chains. Unlike other solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and Neural Networks, make predictions and approximate optimal solutions faster. This paper presents an automated ML framework to enhance supply chain security by detecting fraudulent activities, predicting maintenance needs, and forecasting material backorders. Using datasets of varying sizes, results show that fraud detection achieves an 88% accuracy rate using sampling methods, machine failure prediction reaches 93.4% accuracy, and material backorder prediction achieves 89.3% accuracy. Hyperparameter tuning significantly improved the performance of these models, with certain supervised techniques like XGBoost and LightGBM reaching up to 100% precision. This research contributes to supply chain security by streamlining data preprocessing, feature selection, model optimization, and inference deployment, addressing critical challenges and boosting operational efficiency.",
      "authors": [
        "Haibo Wang",
        "Lutfu S.Sua",
        "and Bahram Alidaee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "General Economics (econ.GN)",
        "Optimization and Control (math.OC)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-19T02:45:32+00:00",
          "link": "https://arxiv.org/abs/2406.13166v1",
          "size": "1183kb",
          "version": "v1"
        },
        {
          "date": "2024-12-01T22:34:05+00:00",
          "link": "https://arxiv.org/abs/2406.13166v2",
          "size": "1680kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T18:22:57+00:00",
          "link": "https://arxiv.org/abs/2406.13166v3",
          "size": "2100kb",
          "version": "v3"
        }
      ],
      "title": "Enhancing supply chain security with automated machine learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.13166",
        "PDF": "https://arxiv.org/pdf/2406.13166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with enhancing supply chain security through automated machine learning, focusing on fraud detection and prediction tasks. There is no mention of LLMs or processes relevant to LLM training data processing."
      },
      "tasks": [
        "feature selection",
        "Fraud Detection",
        "Hyperparameter Optimization",
        "Model Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.04626",
      "abstract": "Computational problems concerning the orbit of a point under the action of a matrix group occur throughout computer science, including in program analysis, complexity theory, quantum computation, and automata theory. In many cases the focus extends beyond orbits proper to orbit closures under a suitable topology. Typically one starts from a group and a set of points and asks questions about the orbit closure of the set under the action of the group, e.g., whether two given orbit closures intersect.\n  In this paper we consider a collection of what we call determination problems concerning matrix groups and orbit closures. These problems begin with a given variety and seek to understand whether and how it arises either as an algebraic matrix group or as an orbit closure. The how question asks whether the underlying group is $s$-generated, meaning it is topologically generated by $s$ matrices for a given number $s$. Among other applications, problems of this type have recently been studied in the context of synthesising loops subject to certain specified invariants on program variables.\n  Our main result is a polynomial-space procedure that inputs a variety and a number $s$ and determines whether the given variety arises as an orbit closure of a point under an $s$-generated commutative algebraic matrix group. The main tools in our approach are structural properties of commutative algebraic matrix groups and module theory. We leave open the question of determining whether a variety is an orbit closure of a point under an $s$-generated algebraic matrix group (without the requirement of commutativity).",
      "authors": [
        "Rida Ait El Manssour",
        "George Kenison",
        "Mahsa Shirmohammadi",
        "Anton Varonka",
        "James Worrell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-05T16:34:09+00:00",
          "link": "https://arxiv.org/abs/2407.04626v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T21:38:38+00:00",
          "link": "https://arxiv.org/abs/2407.04626v2",
          "size": "74kb",
          "version": "v2"
        }
      ],
      "title": "Determination Problems for Orbit Closures and Matrix Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.04626",
        "HTML": "https://arxiv.org/html/2407.04626v2",
        "PDF": "https://arxiv.org/pdf/2407.04626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines computational problems with matrix groups and orbit closures, which does not relate to LLM training data processing or any relevant dataset engineering or data quality improvements for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.05593",
      "abstract": "Despite much work on advanced deep learning and generative modeling techniques for tabular data generation and imputation, traditional methods have continued to win on imputation benchmarks. We herein present UnmaskingTrees, a simple method for tabular imputation (and generation) employing gradient-boosted decision trees which are used to incrementally unmask individual features. On a benchmark for out-of-the-box performance on 27 small tabular datasets, UnmaskingTrees offers leading performance on imputation; state-of-the-art performance on generation given data with missingness; and competitive performance on vanilla generation given data without missingness. To solve the conditional generation subproblem, we propose a tabular probabilistic prediction method, BaltoBot, which fits a balanced tree of boosted tree classifiers. Unlike older methods, it requires no parametric assumption on the conditional distribution, accommodating features with multimodal distributions; unlike newer diffusion methods, it offers fast sampling, closed-form density estimation, and flexible handling of discrete variables. We finally consider our two approaches as meta-algorithms, demonstrating in-context learning-based generative modeling with TabPFN.",
      "authors": [
        "Calvin McCarter"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T04:15:43+00:00",
          "link": "https://arxiv.org/abs/2407.05593v1",
          "size": "190kb",
          "version": "v1"
        },
        {
          "date": "2024-09-21T03:15:54+00:00",
          "link": "https://arxiv.org/abs/2407.05593v2",
          "size": "1741kb",
          "version": "v2"
        },
        {
          "date": "2024-09-29T22:03:26+00:00",
          "link": "https://arxiv.org/abs/2407.05593v3",
          "size": "1763kb",
          "version": "v3"
        },
        {
          "date": "2024-12-01T04:36:57+00:00",
          "link": "https://arxiv.org/abs/2407.05593v4",
          "size": "2073kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T03:16:46+00:00",
          "link": "https://arxiv.org/abs/2407.05593v5",
          "size": "1912kb",
          "version": "v5"
        }
      ],
      "title": "Unmasking Trees for Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05593",
        "HTML": "https://arxiv.org/html/2407.05593v5",
        "PDF": "https://arxiv.org/pdf/2407.05593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "UnmaskingTrees is focused on tabular data imputation and generation using decision trees, which does not contribute to LLM training data processing for language models in terms of pretraining or fine-tuning datasets."
      },
      "tasks": [
        "Density Estimation",
        "Imputation",
        "In-Context Learning",
        "Tabular Data Generation"
      ],
      "repo_urls": [
        "https://github.com/calvinmccarter/unmasking-trees"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.18661",
      "abstract": "In this paper, we address the development of a robotic rehabilitation system for the upper limbs based on collaborative end-effector solutions. The use of commercial collaborative robots offers significant advantages for this task, as they are optimized from an engineering perspective and ensure safe physical interaction with humans. However, they also come with noticeable drawbacks, such as the limited range of sizes available on the market and the standard control modes, which are primarily oriented towards industrial or service applications. To address these limitations, we propose an optimization-based design method to fully exploit the capability of the cobot in performing rehabilitation tasks. Additionally, we introduce a novel control architecture based on an admittance-type Virtual Fixture method, which constrains the motion of the robot along a prescribed path. This approach allows for an intuitive definition of the task to be performed via Programming by Demonstration and enables the system to operate both passively and actively. In passive mode, the system supports the patient during task execution with additional force, while in active mode, it opposes the motion with a braking force. Experimental results demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Dario Onfiani",
        "Marco Caramaschi",
        "Luigi Biagiotti",
        "Fabio Pini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-26T10:53:57+00:00",
          "link": "https://arxiv.org/abs/2407.18661v1",
          "size": "12297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:33:38+00:00",
          "link": "https://arxiv.org/abs/2407.18661v2",
          "size": "31383kb",
          "version": "v2"
        }
      ],
      "title": "Optimizing Design and Control Methods for Using Collaborative Robots in Upper-Limb Rehabilitation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.18661",
        "HTML": "https://arxiv.org/html/2407.18661v2",
        "PDF": "https://arxiv.org/pdf/2407.18661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robotic rehabilitation systems, optimizing design, and control methods for collaborative robots, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.03108",
      "abstract": "In this paper, new representations of the Green's function for an acoustic d-dimensional half-space problem with impedance boundary conditions are presented. The main features of the new representation are: a) in addition to additive terms that appear also in the case of Dirichlet or Neumann boundary conditions, the remaining part of the Green's function is factored into an oscillatory complex exponential function (with the product of the wavenumber and the eikonal as argument) and a remaining function which is slowly varying and hence allows for efficient polynomial approximation; b) the representation is given uniformly for all parameters by a single formula which consists of the product of two analytic functions.",
      "authors": [
        "C. Lin",
        "J.M. Melenk",
        "S. Sauter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-06T11:32:41+00:00",
          "link": "https://arxiv.org/abs/2408.03108v1",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:53:32+00:00",
          "link": "https://arxiv.org/abs/2408.03108v2",
          "size": "10kb",
          "version": "v2"
        }
      ],
      "title": "An explicit factorization of the Green's function for an acoustic half-space problem with impedance boundary conditions into an oscillatory exponential and a slowly varying function",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.03108",
        "HTML": "https://arxiv.org/html/2408.03108v2",
        "PDF": "https://arxiv.org/pdf/2408.03108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concerns the factorization of the Green's function for an acoustic half-space problem, a topic in mathematical physics, not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.08068",
      "abstract": "Informal Knowledge Sharing (KS) is vital for end-user programmers to gain expertise. To better understand how personal (self-efficacy), social (reputational gains, trust between colleagues), and software-related (codification effort) variables influence spreadsheet KS intention, we conducted a multiple regressions analysis based on survey data from spreadsheet users (n=100) in administrative and finance roles. We found that high levels of spreadsheet self-efficacy and a perception that sharing would result in reputational gains predicted higher KS intention, but individuals who found knowledge codification effortful showed lower KS intention. We also observed that regardless of occupation, users tended to report a lower sense of self-efficacy in their general spreadsheet proficiency, despite also reporting high self-efficacy in spreadsheet use for job-related contexts. Our findings suggest that acknowledging and designing for these social and personal variables can help avoid situations where experienced individuals refrain unnecessarily from sharing, with implications for spreadsheet design.",
      "authors": [
        "Qing (Nancy) Xia",
        "Advait Sarkar",
        "Duncan P. Brumby",
        "Anna Cox"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-15T10:31:46+00:00",
          "link": "https://arxiv.org/abs/2408.08068v1",
          "size": "143kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:12:15+00:00",
          "link": "https://arxiv.org/abs/2408.08068v2",
          "size": "143kb",
          "version": "v2"
        }
      ],
      "title": "The Paradox of Spreadsheet Self-Efficacy: Social Incentives for Informal Knowledge Sharing in End-User Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.08068",
        "HTML": "https://arxiv.org/html/2408.08068v2",
        "PDF": "https://arxiv.org/pdf/2408.08068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on informal knowledge sharing and spreadsheet self-efficacy, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.12240",
      "abstract": "Timed automata (TAs) are an extension of finite automata that can measure and react to the passage of time, providing the ability to handle real-time constraints using clocks. In 2009, Franck Cassez showed that the timed opacity problem, where an attacker can observe some actions with their timestamps and attempts to deduce information, is undecidable for TAs. Moreover, he showed that the undecidability holds even for subclasses such as event-recording automata. In this article, we consider the same definition of opacity, by restricting either the system or the attacker. Our first contribution is to prove the inter-reducibility of two variants of opacity: full opacity (for which the observations should be the same regardless of the visit of a private location) and weak opacity (for which it suffices that the attacker cannot deduce whether the private location was visited, but for which it is harmless to deduce that it was not visited); we also prove further results including a connection with timed language inclusion. Our second contribution is to study opacity for several subclasses of TAs: with restrictions on the number of clocks, the number of actions, the nature of time, or a new subclass called observable event-recording automata. We show that opacity is mostly decidable in these cases, except for one-action TAs and for one-clock TAs with $\\epsilon$-transitions, for which undecidability remains. Our third (and arguably main) contribution is to propose a new definition of opacity in which the number of observations made by the attacker is limited to the first $N$ observations, or to a set of $N$ timestamps after which the attacker observes the first action that follows immediately. This set can be defined either a priori or at runtime; all three versions yield decidability for the whole TA class.",
      "authors": [
        "\\'Etienne Andr\\'e",
        "Sarah D\\'epernet and Engel Lefaucheux"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Cryptography and Security (cs.CR)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T09:17:59+00:00",
          "link": "https://arxiv.org/abs/2408.12240v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2024-09-19T12:21:39+00:00",
          "link": "https://arxiv.org/abs/2408.12240v2",
          "size": "58kb",
          "version": "v2"
        },
        {
          "date": "2024-09-27T14:00:11+00:00",
          "link": "https://arxiv.org/abs/2408.12240v3",
          "size": "58kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T13:51:01+00:00",
          "link": "https://arxiv.org/abs/2408.12240v4",
          "size": "69kb",
          "version": "v4"
        }
      ],
      "title": "The Bright Side of Timed Opacity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12240",
        "PDF": "https://arxiv.org/pdf/2408.12240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses timed automata and opacity problems, which do not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.14672",
      "abstract": "State-of-the-art semantic segmentation models are typically optimized in a data-driven fashion, minimizing solely per-pixel or per-segment classification objectives on their training data. This purely data-driven paradigm often leads to absurd segmentations, especially when the domain of input images is shifted from the one encountered during training. For instance, state-of-the-art models may assign the label \"road\" to a segment that is included by another segment that is respectively labeled as \"sky\". However, the ground truth of the existing dataset at hand dictates that such inclusion is not feasible. Our method, Infeasible Semantic Inclusions (InSeIn), first extracts explicit inclusion constraints that govern spatial class relations from the semantic segmentation training set at hand in an offline, data-driven fashion, and then enforces a morphological yet differentiable loss that penalizes violations of these constraints during training to promote prediction feasibility. InSeIn is a light-weight plug-and-play method, constitutes a novel step towards minimizing infeasible semantic inclusions in the predictions of learned segmentation models, and yields consistent and significant performance improvements over diverse state-of-the-art networks across the ADE20K, Cityscapes, and ACDC datasets. https://github.com/SHAMIK-97/InSeIn/tree/main",
      "authors": [
        "Shamik Basu",
        "Luc Van Gool",
        "Christos Sakaridis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-26T22:39:08+00:00",
          "link": "https://arxiv.org/abs/2408.14672v1",
          "size": "29444kb",
          "version": "v1"
        },
        {
          "date": "2024-09-11T17:26:06+00:00",
          "link": "https://arxiv.org/abs/2408.14672v2",
          "size": "29444kb",
          "version": "v2"
        },
        {
          "date": "2025-01-19T19:03:04+00:00",
          "link": "https://arxiv.org/abs/2408.14672v3",
          "size": "23123kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T17:16:41+00:00",
          "link": "https://arxiv.org/abs/2408.14672v4",
          "size": "22096kb",
          "version": "v4"
        }
      ],
      "title": "Optimizing against Infeasible Inclusions from Data for Semantic Segmentation through Morphology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14672",
        "HTML": "https://arxiv.org/html/2408.14672v4",
        "PDF": "https://arxiv.org/pdf/2408.14672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on semantic segmentation models and optimizing against infeasible inclusions using morphological methods, without mention of LLM training data processing."
      },
      "tasks": [
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/shamik-97/valeo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.16446",
      "abstract": "This study examines the impact of historical text normalization on the classification of medieval charters, specifically focusing on document dating and locating. Using a data set of Middle High German charters from a digital archive, we evaluate various classifiers, including traditional and transformer-based models, with and without normalization. Our results indicate that the given normalization minimally improves locating tasks but reduces accuracy for dating, implying that original texts contain crucial features that normalization may obscure. We find that support vector machines and gradient boosting outperform other models, questioning the efficiency of transformers for this use case. Results suggest a selective approach to historical text normalization, emphasizing the significance of preserving some textual characteristics that are critical for classification tasks in document analysis.",
      "authors": [
        "Florian Atzenhofer-Baumgartner",
        "Tam\\'as Kov\\'acs"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-29T11:19:57+00:00",
          "link": "https://arxiv.org/abs/2408.16446v1",
          "size": "35kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:57:59+00:00",
          "link": "https://arxiv.org/abs/2408.16446v2",
          "size": "36kb",
          "version": "v2"
        }
      ],
      "title": "Is text normalization relevant for classifying medieval charters?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16446",
        "HTML": "https://arxiv.org/html/2408.16446v2",
        "PDF": "https://arxiv.org/pdf/2408.16446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study relates to historical text normalization and classification of medieval charters, which does not align with LLM training data processing."
      },
      "tasks": [
        "Document Dating",
        "Text Normalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01475",
      "abstract": "Not every directed acyclic graph (DAG) whose underlying undirected graph is planar admits an upward planar drawing. We are interested in pushing the notion of upward drawings beyond planarity by considering upward $k$-planar drawings of DAGs in which the edges are monotonically increasing in a common direction and every edge is crossed at most $k$ times for some integer $k \\ge 1$. We show that the number of crossings per edge in a monotone drawing is in general unbounded for the class of bipartite outerplanar, cubic, or bounded pathwidth DAGs. However, it is at most two for outerpaths and it is at most quadratic in the bandwidth in general. From the computational point of view, we prove that testing upward-$k$-planarity is NP-complete already for $k=1$ and even for restricted instances for which upward planarity testing is polynomial. On the positive side, we can decide in linear time whether a single-source DAG admits an upward 1-planar drawing in which all vertices are incident to the outer face.",
      "authors": [
        "Patrizio Angelini",
        "Therese Biedl",
        "Markus Chimani",
        "Sabine Cornelsen",
        "Giordano Da Lozzo",
        "Seok-Hee Hong",
        "Giuseppe Liotta",
        "Maurizio Patrignani",
        "Sergey Pupyrev",
        "Ignaz Rutter",
        "Alexander Wolff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T21:55:00+00:00",
          "link": "https://arxiv.org/abs/2409.01475v1",
          "size": "1076kb",
          "version": "v1"
        },
        {
          "date": "2025-02-09T13:56:00+00:00",
          "link": "https://arxiv.org/abs/2409.01475v2",
          "size": "646kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:13:47+00:00",
          "link": "https://arxiv.org/abs/2409.01475v3",
          "size": "753kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T16:00:31+00:00",
          "link": "https://arxiv.org/abs/2409.01475v4",
          "size": "676kb",
          "version": "v4"
        }
      ],
      "title": "The Price of Upwardness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01475",
        "HTML": "https://arxiv.org/html/2409.01475v4",
        "PDF": "https://arxiv.org/pdf/2409.01475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The topic is on upward planar drawings in directed acyclic graphs, rather than LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.01534",
      "abstract": "In this study, we propose Cross-domain Multi-step Thinking (CdMT) to improve zero-shot fine-grained traffic sign recognition (TSR) performance in the wild. Zero-shot fine-grained TSR in the wild is challenging due to the cross-domain problem between clean template traffic signs and real-world counterparts, and existing approaches particularly struggle with cross-country TSR scenarios, where traffic signs typically differ between countries. The proposed CdMT framework tackles these challenges by leveraging the multi-step reasoning capabilities of large multimodal models (LMMs). We introduce context, characteristic, and differential descriptions to design multiple thinking processes for LMMs. Context descriptions, which are enhanced by center coordinate prompt optimization, enable the precise localization of target traffic signs in complex road images and filter irrelevant responses via novel prior traffic sign hypotheses. Characteristic descriptions, which are derived from in-context learning with template traffic signs, bridge cross-domain gaps and enhance fine-grained TSR. Differential descriptions refine the multimodal reasoning ability of LMMs by distinguishing subtle differences among similar signs. CdMT is independent of training data and requires only simple and uniform instructions, enabling it to achieve cross-country TSR. We conducted extensive experiments on three benchmark datasets and two real-world datasets from different countries. The proposed CdMT framework achieved superior performance compared with other state-of-the-art methods on all five datasets, with recognition accuracies of 0.93, 0.89, 0.97, 0.89, and 0.85 on the GTSRB, BTSD, TT-100K, Sapporo, and Yokohama datasets, respectively.",
      "authors": [
        "Yaozong Gan",
        "Guang Li",
        "Ren Togo",
        "Keisuke Maeda",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T02:08:47+00:00",
          "link": "https://arxiv.org/abs/2409.01534v1",
          "size": "5720kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:14:06+00:00",
          "link": "https://arxiv.org/abs/2409.01534v2",
          "size": "5405kb",
          "version": "v2"
        }
      ],
      "title": "Cross-domain Multi-step Thinking: Zero-shot Fine-grained Traffic Sign Recognition in the Wild",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01534",
        "HTML": "https://arxiv.org/html/2409.01534v2",
        "PDF": "https://arxiv.org/pdf/2409.01534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving traffic sign recognition using a new method, CdMT, that leverages multimodal models without involving any aspect of LLM training data processing."
      },
      "tasks": [
        "In-Context Learning",
        "Traffic Sign Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.02595",
      "abstract": "We try to clarify the relationship between computation and concurrency. Base on the so-called truly concurrent automata, we introduce communication and more operators, and establish the algebras modulo language equivalence and bisimilarity.",
      "authors": [
        "Yong Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T10:23:15+00:00",
          "link": "https://arxiv.org/abs/2409.02595v1",
          "size": "2363kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:47:57+00:00",
          "link": "https://arxiv.org/abs/2409.02595v2",
          "size": "91kb",
          "version": "v2"
        }
      ],
      "title": "Computation and Concurrency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02595",
        "PDF": "https://arxiv.org/pdf/2409.02595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the theoretical relationship between computation and concurrency, introducing algebras and operators. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.12967",
      "abstract": "Providing consistent summative assessment to students is important, as the grades they are awarded affect their progression through university and future career prospects. While small cohorts are typically assessed by a single assessor, such as the module/class leader, larger cohorts are often assessed by multiple assessors, typically teaching assistants, which increases the risk of inconsistent grading.\n  To investigate the consistency of human grading of programming assignments, we asked 28 participants to each grade 40 CS1 introductory Java assignments, providing grades and feedback for correctness, code elegance, readability and documentation; the 40 assignments were split into two batches of 20. The 28 participants were divided into seven groups of four (where each group graded the same 40 assignments) to allow us to investigate the consistency of a group of assessors. In the second batch of 20, we duplicated one assignment from the first to analyse the internal consistency of individual assessors.\n  Our results show that human graders in our study can not agree on the grade to give a piece of student work and are often individually inconsistent, suggesting that the idea of a ``gold standard'' of human grading might be flawed. This highlights that a shared rubric alone is not enough to ensure consistency, and other aspects such as assessor training and alternative grading practices should be explored to improve the consistency of human grading further when grading programming assignments.",
      "authors": [
        "Marcus Messer",
        "Neil C. C. Brown",
        "Michael K\\\"olling",
        "Miaojing Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T13:30:53+00:00",
          "link": "https://arxiv.org/abs/2409.12967v1",
          "size": "2543kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T19:45:45+00:00",
          "link": "https://arxiv.org/abs/2409.12967v2",
          "size": "2592kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T09:24:31+00:00",
          "link": "https://arxiv.org/abs/2409.12967v3",
          "size": "2438kb",
          "version": "v3"
        }
      ],
      "title": "How Consistent Are Humans When Grading Programming Assignments?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12967",
        "HTML": "https://arxiv.org/html/2409.12967v3",
        "PDF": "https://arxiv.org/pdf/2409.12967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates the consistency of human grading for programming assignments, without addressing topics related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.13684",
      "abstract": "Feature-based methods are commonly used to explain model predictions, but these methods often implicitly assume that interpretable features are readily available. However, this is often not the case for high-dimensional data, and it can be hard even for domain experts to mathematically specify which features are important. Can we instead automatically extract collections or groups of features that are aligned with expert knowledge? To address this gap, we present FIX (Features Interpretable to eXperts), a benchmark for measuring how well a collection of features aligns with expert knowledge. In collaboration with domain experts, we propose FIXScore, a unified expert alignment measure applicable to diverse real-world settings across cosmology, psychology, and medicine domains in vision, language, and time series data modalities. With FIXScore, we find that popular feature-based explanation methods have poor alignment with expert-specified knowledge, highlighting the need for new methods that can better identify features interpretable to experts.",
      "authors": [
        "Helen Jin",
        "Shreya Havaldar",
        "Chaehyeon Kim",
        "Anton Xue",
        "Weiqiu You",
        "Helen Qu",
        "Marco Gatti",
        "Daniel A Hashimoto",
        "Bhuvnesh Jain",
        "Amin Madani",
        "Masao Sako",
        "Lyle Ungar",
        "Eric Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-20T17:53:03+00:00",
          "link": "https://arxiv.org/abs/2409.13684v1",
          "size": "5226kb",
          "version": "v1"
        },
        {
          "date": "2024-10-09T17:47:01+00:00",
          "link": "https://arxiv.org/abs/2409.13684v2",
          "size": "5290kb",
          "version": "v2"
        },
        {
          "date": "2024-12-23T19:39:18+00:00",
          "link": "https://arxiv.org/abs/2409.13684v3",
          "size": "5290kb",
          "version": "v3"
        },
        {
          "date": "2025-07-22T23:03:48+00:00",
          "link": "https://arxiv.org/abs/2409.13684v4",
          "size": "3687kb",
          "version": "v4"
        }
      ],
      "title": "The FIX Benchmark: Extracting Features Interpretable to eXperts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13684",
        "HTML": "https://arxiv.org/html/2409.13684v4",
        "PDF": "https://arxiv.org/pdf/2409.13684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses feature interpretability for experts through the FIX benchmark, which is unrelated to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "BrachioLab/supernova-timeseries",
          "downloads": "16",
          "likes": "0",
          "link": "https://huggingface.co/datasets/BrachioLab/supernova-timeseries"
        },
        {
          "dataset_name": "BrachioLab/massmaps-cosmogrid-100k",
          "downloads": "37",
          "likes": "0",
          "link": "https://huggingface.co/datasets/BrachioLab/massmaps-cosmogrid-100k"
        },
        {
          "dataset_name": "BrachioLab/cholec",
          "downloads": "141",
          "likes": "0",
          "link": "https://huggingface.co/datasets/BrachioLab/cholec"
        }
      ],
      "tasks": [
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/BrachioLab/exlib"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.14659",
      "abstract": "Visual content on social media plays a key role in entertainment and information sharing, yet some images gain more engagement than others. We propose that image memorability - the ability to be remembered - may predict viral potential. Using 1,247 Reddit image posts across three timepoints, we assessed memorability with neural network ResMem and correlated the predicted memorability scores with virality metrics. Memorable images are consistently associated with more comments, even after controlling for image categories with ResNet-152. Semantic analysis revealed that memorable images relate to more neutral-affect comments, suggesting a distinct pathway to virality from emotional contents. Additionally, visual consistency analysis showed that memorable posts inspired diverse, externally-associated comments. By analyzing ResMem's layers, we found that semantic distinctiveness was key to both memorability and virality even after accounting for image category effects. This study highlights memorability as a unique correlate of social media virality, offering insights into how visual features and human cognitive behavioral interactions are associated with online engagement.",
      "authors": [
        "Shikang Peng",
        "Wilma A. Bainbridge"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T02:00:34+00:00",
          "link": "https://arxiv.org/abs/2409.14659v1",
          "size": "1801kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T22:35:07+00:00",
          "link": "https://arxiv.org/abs/2409.14659v2",
          "size": "1934kb",
          "version": "v2"
        }
      ],
      "title": "Image memorability predicts social media virality and externally-associated commenting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14659",
        "PDF": "https://arxiv.org/pdf/2409.14659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research examines the memorability of images and their correlation with social media virality, which does not involve LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/shikangpeng/memoMedia"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.19638",
      "abstract": "Precise future human motion prediction over sub-second horizons from past observations is crucial for various safety-critical applications. To date, only a few studies have examined the vulnerability of skeleton-based neural networks to evasion and backdoor attacks. In this paper, we propose BadHMP, a novel backdoor attack that targets specifically human motion prediction tasks. Our approach involves generating poisoned training samples by embedding a localized backdoor trigger in one limb of the skeleton, causing selected joints to follow predefined motion in historical time steps. Subsequently, the future sequences are globally modified that all the joints move following the target trajectories. Our carefully designed backdoor triggers and targets guarantee the smoothness and naturalness of the poisoned samples, making them stealthy enough to evade detection by the model trainer while keeping the poisoned model unobtrusive in terms of prediction fidelity to untainted sequences. The target sequences can be successfully activated by the designed input sequences even with a low poisoned sample injection ratio. Experimental results on two datasets (Human3.6M and CMU-Mocap) and two network architectures (LTD and HRI) demonstrate the high-fidelity, effectiveness, and stealthiness of BadHMP. Robustness of our attack against fine-tuning defense is also verified.",
      "authors": [
        "Chaohui Xu",
        "Si Wang and Chip-Hong Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-29T09:55:31+00:00",
          "link": "https://arxiv.org/abs/2409.19638v1",
          "size": "1284kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:48:33+00:00",
          "link": "https://arxiv.org/abs/2409.19638v2",
          "size": "913kb",
          "version": "v2"
        }
      ],
      "title": "BadHMP: Backdoor Attack against Human Motion Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.19638",
        "HTML": "https://arxiv.org/html/2409.19638v2",
        "PDF": "https://arxiv.org/pdf/2409.19638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a backdoor attack method specifically targeting human motion prediction tasks rather than contributing to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Backdoor Attack",
        "Human motion prediction",
        "motion prediction",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.04571",
      "abstract": "With Large Language Models (LLMs) rapidly approaching and potentially surpassing human-level performance, it has become imperative to develop approaches capable of effectively supervising and enhancing these powerful models using smaller, human-level models exposed to only human-level data. We address this critical weak-to-strong (W2S) generalization challenge by proposing a novel method aimed at improving weak experts, by training on the same limited human-level data, enabling them to generalize to complex, super-human-level tasks. Our approach, called **EnsemW2S**, employs a token-level ensemble strategy that iteratively combines multiple weak experts, systematically addressing the shortcomings identified in preceding iterations. By continuously refining these weak models, we significantly enhance their collective ability to supervise stronger student models. We extensively evaluate the generalization performance of both the ensemble of weak experts and the subsequent strong student model across in-distribution (ID) and out-of-distribution (OOD) datasets. For OOD, we specifically introduce question difficulty as an additional dimension for defining distributional shifts. Our empirical results demonstrate notable improvements, achieving 4%, and 3.2% improvements on ID datasets and, upto 6% and 2.28% on OOD datasets for experts and student models respectively, underscoring the effectiveness of our proposed method in advancing W2S generalization.",
      "authors": [
        "Aakriti Agrawal",
        "Mucong Ding",
        "Zora Che",
        "Chenghao Deng",
        "Anirudh Satheesh",
        "Bang An",
        "Bayan Bruss",
        "John Langford",
        "Furong Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-06T18:06:42+00:00",
          "link": "https://arxiv.org/abs/2410.04571v1",
          "size": "2478kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T22:40:11+00:00",
          "link": "https://arxiv.org/abs/2410.04571v2",
          "size": "3749kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T01:08:36+00:00",
          "link": "https://arxiv.org/abs/2410.04571v3",
          "size": "3749kb",
          "version": "v3"
        }
      ],
      "title": "EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04571",
        "HTML": "https://arxiv.org/html/2410.04571v3",
        "PDF": "https://arxiv.org/pdf/2410.04571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper touches upon training data use by enhancing generalization from limited human-level data but primarily focuses on model techniques, specifically ensemble methods, rather than on data processing operations."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08385",
      "abstract": "Language models are extensively evaluated, but correctly interpreting evaluation results requires knowledge of train-test overlap which refers to the extent to which the language model is trained on the very data it is being tested on. The public currently lacks adequate information about train-test overlap: most models have no public train-test overlap statistics, and third parties cannot directly measure train-test overlap since they do not have access to the training data. To make this clear, we document the practices of 30 model developers, finding that just 9 developers report train-test overlap: 4 developers release training data under open-source licenses, enabling the community to directly measure train-test overlap, and 5 developers publish their train-test overlap methodology and statistics. By engaging with language model developers, we provide novel information about train-test overlap for three additional developers. Overall, we take the position that language model developers should publish train-test overlap statistics and/or training data whenever they report evaluation results on public test sets. We hope our work increases transparency into train-test overlap to increase the community-wide trust in model evaluations.",
      "authors": [
        "Andy K Zhang",
        "Kevin Klyman",
        "Yifan Mai",
        "Yoav Levine",
        "Yian Zhang",
        "Rishi Bommasani",
        "Percy Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T21:44:56+00:00",
          "link": "https://arxiv.org/abs/2410.08385v1",
          "size": "8143kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T23:36:25+00:00",
          "link": "https://arxiv.org/abs/2410.08385v2",
          "size": "8298kb",
          "version": "v2"
        }
      ],
      "title": "Language model developers should report train-test overlap",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08385",
        "HTML": "https://arxiv.org/html/2410.08385v2",
        "PDF": "https://arxiv.org/pdf/2410.08385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper emphasizes the importance of reporting train-test overlap for language models, which relates to training data transparency, but it does not directly discuss data processing operations or dataset creation."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17491",
      "abstract": "General-purpose navigation in challenging environments remains a significant problem in robotics, with current state-of-the-art approaches facing myriad limitations. Classical approaches struggle with cluttered settings and require extensive tuning, while learning-based methods face difficulties generalizing to out-of-distribution environments. This paper introduces X-Mobility, an end-to-end generalizable navigation model that overcomes existing challenges by leveraging three key ideas. First, X-Mobility employs an auto-regressive world modeling architecture with a latent state space to capture world dynamics. Second, a diverse set of multi-head decoders enables the model to learn a rich state representation that correlates strongly with effective navigation skills. Third, by decoupling world modeling from action policy, our architecture can train effectively on a variety of data sources, both with and without expert policies: off-policy data allows the model to learn world dynamics, while on-policy data with supervisory control enables optimal action policy learning. Through extensive experiments, we demonstrate that X-Mobility not only generalizes effectively but also surpasses current state-of-the-art navigation approaches. Additionally, X-Mobility also achieves zero-shot Sim2Real transferability and shows strong potential for cross-embodiment generalization.",
      "authors": [
        "Wei Liu",
        "Huihua Zhao",
        "Chenran Li",
        "Joydeep Biswas",
        "Billy Okal",
        "Pulkit Goyal",
        "Yan Chang",
        "Soha Pouya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T01:11:29+00:00",
          "link": "https://arxiv.org/abs/2410.17491v1",
          "size": "27428kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T22:22:54+00:00",
          "link": "https://arxiv.org/abs/2410.17491v2",
          "size": "27428kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T20:45:12+00:00",
          "link": "https://arxiv.org/abs/2410.17491v3",
          "size": "24192kb",
          "version": "v3"
        }
      ],
      "title": "X-MOBILITY: End-To-End Generalizable Navigation via World Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17491",
        "HTML": "https://arxiv.org/html/2410.17491v3",
        "PDF": "https://arxiv.org/pdf/2410.17491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a navigation model in robotics using world modeling. It does not address LLM training data processing methods or related operations."
      },
      "models": [
        {
          "model_path": "nvidia/X-Mobility",
          "downloads": "0",
          "likes": "10",
          "trending_score": "1.0",
          "link": "https://huggingface.co/nvidia/X-Mobility"
        }
      ],
      "repo_urls": [
        "https://github.com/NVlabs/X-MOBILITY"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.18489",
      "abstract": "Leveraging Large Language Models (LLM) like GPT4 in the auto generation of code represents a significant advancement, yet it is not without its challenges. The ambiguity inherent in natural language descriptions of software poses substantial obstacles to generating deployable, structured artifacts. This research champions Model Driven Development (MDD) as a viable strategy to overcome these challenges, proposing an Agile Model Driven Development (AMDD) approach that employs GPT4 as a code generator. This approach enhances the flexibility and scalability of the code auto generation process and offers agility that allows seamless adaptation to changes in models or deployment environments. We illustrate this by modeling a multi agent Unmanned Vehicle Fleet (UVF) system using the Unified Modeling Language (UML), significantly reducing model ambiguity by integrating the Object Constraint Language (OCL) for code structure meta modeling, and the FIPA ontology language for communication semantics meta modeling. Applying GPT4 auto generation capabilities yields Java and Python code that is compatible with the JADE and PADE frameworks, respectively. Our thorough evaluation of the auto generated code verifies its alignment with expected behaviors and identifies enhancements in agent interactions. Structurally, we assessed the complexity of code derived from a model constrained solely by OCL meta models, against that influenced by both OCL and FIPA ontology meta models. The results indicate that the ontology constrained meta model produces inherently more complex code, yet its cyclomatic complexity remains within manageable levels, suggesting that additional meta model constraints can be incorporated without exceeding the high risk threshold for complexity.",
      "authors": [
        "Ahmed R. Sadik",
        "Sebastian Brulin",
        "Markus Olhofer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Robotics (cs.RO)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T07:24:11+00:00",
          "link": "https://arxiv.org/abs/2410.18489v1",
          "size": "1482kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T18:02:57+00:00",
          "link": "https://arxiv.org/abs/2410.18489v2",
          "size": "1482kb",
          "version": "v2"
        }
      ],
      "title": "LLM as a code generator in Agile Model Driven Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18489",
        "HTML": "https://arxiv.org/html/2410.18489v2",
        "PDF": "https://arxiv.org/pdf/2410.18489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs like GPT4 for auto-generating code as part of a Model Driven Development approach but does not directly contribute to LLM training data processing, focusing more on model-driven development methodologies."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.19384",
      "abstract": "Designing two-sided matching mechanisms is challenging when practical demands for matching outcomes are difficult to formalize and the designed mechanism must satisfy theoretical conditions. To address this, prior work has proposed a framework that learns a matching mechanism from examples, using a parameterized family that satisfies properties such as stability. However, despite its usefulness, this framework does not guarantee strategy-proofness (SP), and cannot handle varying numbers of agents or incorporate publicly available contextual information about agents, both of which are crucial in real-world applications. In this paper, we propose a new parametrized family of matching mechanisms that always satisfy strategy-proofness, are applicable for an arbitrary number of agents, and deal with public contextual information of agents, based on the serial dictatorship (SD). This family is represented by NeuralSD, a novel neural network architecture based on SD, where agent rankings in SD are treated as learnable parameters computed from agents' contexts using an attention-based sub-network. To enable learning, we introduce tensor serial dictatorship (TSD), a differentiable relaxation of SD using tensor operations. This allows NeuralSD to be trained end-to-end from example matchings while satisfying SP. We conducted experiments to learn a matching mechanism from matching examples while satisfying SP. We demonstrated that our method outperformed baselines in predicting matchings and on several metrics for goodness of matching outcomes.",
      "authors": [
        "Ryota Maruo",
        "Koh Takeuchi",
        "Hisashi Kashima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T08:34:25+00:00",
          "link": "https://arxiv.org/abs/2410.19384v1",
          "size": "1099kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T01:17:48+00:00",
          "link": "https://arxiv.org/abs/2410.19384v2",
          "size": "891kb",
          "version": "v2"
        }
      ],
      "title": "Learning Neural Strategy-Proof Matching Mechanism from Examples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19384",
        "HTML": "https://arxiv.org/html/2410.19384v2",
        "PDF": "https://arxiv.org/pdf/2410.19384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing strategy-proof matching mechanisms through neural networks. It does not discuss any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.20519",
      "abstract": "The digital art market faces unprecedented challenges in authenticity verification and copyright protection. This study introduces an integrated framework to address these issues by combining neural style transfer, fractal analysis, and blockchain technology. We generate abstract artworks inspired by Jackson Pollock, using their inherent mathematical complexity to create robust, imperceptible watermarks. Our method embeds these watermarks, derived from fractal and turbulence features, directly into the artwork's structure. This approach is then secured by linking the watermark to NFT metadata, ensuring immutable proof of ownership. Rigorous testing shows our feature-based watermarking achieves a 76.2% average detection rate against common attacks, significantly outperforming traditional methods (27.8-44.0%). This work offers a practical solution for digital artists and collectors, enhancing security and trust in the digital art ecosystem.",
      "authors": [
        "Yiquan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-27T17:02:11+00:00",
          "link": "https://arxiv.org/abs/2410.20519v1",
          "size": "4551kb",
          "version": "v1"
        },
        {
          "date": "2024-10-29T15:18:47+00:00",
          "link": "https://arxiv.org/abs/2410.20519v2",
          "size": "4552kb",
          "version": "v2"
        },
        {
          "date": "2024-11-03T16:35:27+00:00",
          "link": "https://arxiv.org/abs/2410.20519v3",
          "size": "4552kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T07:23:31+00:00",
          "link": "https://arxiv.org/abs/2410.20519v4",
          "size": "3068kb",
          "version": "v4"
        }
      ],
      "title": "Fractal Signatures: Securing AI-Generated Pollock-Style Art via Intrinsic Watermarking and Blockchain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20519",
        "HTML": "https://arxiv.org/html/2410.20519v4",
        "PDF": "https://arxiv.org/pdf/2410.20519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about securing digital art via watermarking and blockchain technology and does not address LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/pollock_vgg19"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.20682",
      "abstract": "Shared memories between two individuals strengthen their bond and are crucial for facilitating their ongoing conversations. This study aims to make long-term dialogue more engaging by leveraging these shared memories. To this end, we introduce a new long-term dialogue dataset named SHARE, constructed from movie scripts, which are a rich source of shared memories among various relationships. Our dialogue dataset contains the summaries of persona information and events of two individuals, as explicitly revealed in their conversation, along with implicitly extractable shared memories. We also introduce EPISODE, a long-term dialogue framework based on SHARE that utilizes shared experiences between individuals. Through experiments using SHARE, we demonstrate that shared memories between two individuals make long-term dialogues more engaging and sustainable, and that EPISODE effectively manages shared memories during dialogue. Our dataset and code are available at https://github.com/e1kim/SHARE.",
      "authors": [
        "Eunwon Kim",
        "Chanho Park",
        "Buru Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T02:41:33+00:00",
          "link": "https://arxiv.org/abs/2410.20682v1",
          "size": "2669kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T05:26:04+00:00",
          "link": "https://arxiv.org/abs/2410.20682v2",
          "size": "640kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T02:46:52+00:00",
          "link": "https://arxiv.org/abs/2410.20682v3",
          "size": "640kb",
          "version": "v3"
        }
      ],
      "title": "SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20682",
        "HTML": "https://arxiv.org/html/2410.20682v3",
        "PDF": "https://arxiv.org/pdf/2410.20682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new long-term dialogue dataset called SHARE, constructed from movie scripts. This involves data collection and dataset creation, which is a direct contribution to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "PJMixers-Dev/SHARE-2410.20682",
          "downloads": "18",
          "likes": "0",
          "link": "https://huggingface.co/datasets/PJMixers-Dev/SHARE-2410.20682"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.00107",
      "abstract": "Combining data-driven models that adapt online and model predictive control (MPC) has enabled effective control of nonlinear systems. However, when deployed on unstable systems, online adaptation may not be fast enough to ensure reliable simultaneous learning and control. For example, a controller on a vehicle executing highly dynamic maneuvers--such as drifting to avoid an obstacle--may push the vehicle's tires to their friction limits, destabilizing the vehicle and allowing modeling errors to quickly compound and cause a loss of control. To address this challenge, we present an active information gathering framework for identifying vehicle dynamics as quickly as possible. We propose an expressive vehicle dynamics model that leverages Bayesian last-layer meta-learning to enable rapid online adaptation. The model's uncertainty estimates are used to guide informative data collection and quickly improve the model prior to deployment. Dynamic drifting experiments on a Toyota Supra show that (i) the framework enables reliable control of a vehicle at the edge of stability, (ii) online adaptation alone may not suffice for zero-shot control and can lead to undesirable transient errors or spin-outs, and (iii) active data collection helps achieve reliable performance.",
      "authors": [
        "Alexander Davydov and Franck Djeumou and Marcus Greiff and Makoto Suminaka and Michael Thompson and John Subosits and Thomas Lew"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T18:02:30+00:00",
          "link": "https://arxiv.org/abs/2411.00107v1",
          "size": "10274kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:24:16+00:00",
          "link": "https://arxiv.org/abs/2411.00107v2",
          "size": "10276kb",
          "version": "v2"
        }
      ],
      "title": "First, Learn What You Don't Know: Active Information Gathering for Driving at the Limits of Handling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00107",
        "HTML": "https://arxiv.org/html/2411.00107v2",
        "PDF": "https://arxiv.org/pdf/2411.00107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses active information gathering and control for vehicle dynamics, focusing on adaptive control strategies rather than LLM training data processing."
      },
      "tasks": [
        "Friction",
        "Meta-Learning",
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.01579",
      "abstract": "Deploying Convolutional Neural Networks (CNNs) on resource-constrained devices necessitates efficient management of computational resources, often via distributed environments susceptible to latency from straggler nodes. This paper introduces the Flexible Coded Distributed Convolution Computing (FCDCC) framework to enhance straggler resilience and numerical stability in distributed CNNs. We extend Coded Distributed Computing (CDC) with Circulant and Rotation Matrix Embedding (CRME) which was originally proposed for matrix multiplication to high-dimensional tensor convolution. For the proposed scheme, referred to as the Numerically Stable Coded Tensor Convolution (NSCTC) scheme, we also propose two new coded partitioning schemes: Adaptive-Padding Coded Partitioning (APCP) for the input tensor and Kernel-Channel Coded Partitioning (KCCP) for the filter tensor. These strategies enable linear decomposition of tensor convolutions and encoding them into CDC subtasks, combining model parallelism with coded redundancy for robust and efficient execution. Theoretical analysis identifies an optimal trade-off between communication and storage costs. Empirical results validate the framework's effectiveness in computational efficiency, straggler resilience, and scalability across various CNN architectures.",
      "authors": [
        "Shuo Tan",
        "Rui Liu",
        "Xuesong Han",
        "XianLei Long",
        "Kai Wan",
        "Linqi Song and Yong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-03T14:05:29+00:00",
          "link": "https://arxiv.org/abs/2411.01579v1",
          "size": "4425kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T02:45:38+00:00",
          "link": "https://arxiv.org/abs/2411.01579v2",
          "size": "4116kb",
          "version": "v2"
        }
      ],
      "title": "Flexible Coded Distributed Convolution Computing for Enhanced Straggler Resilience and Numerical Stability in Distributed CNNs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01579",
        "HTML": "https://arxiv.org/html/2411.01579v2",
        "PDF": "https://arxiv.org/pdf/2411.01579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving straggler resilience and numerical stability in distributed CNNs using a new computational framework. It does not address LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Distributed Computing",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.04030",
      "abstract": "Authenticated Key Exchange (AKE) between any two entities is one of the most important security protocols available for securing our digital networks and infrastructures. In PQCrypto 2023, Bruckner, Ramacher and Striecks proposed a novel hybrid AKE (HAKE) protocol, dubbed Muckle+, that is particularly useful in large quantum-safe networks consisting of a large number of nodes. Their protocol is hybrid in the sense that it allows key material from conventional and post-quantum primitives, as well as from quantum key distribution, to be incorporated into a single end-to-end shared key.\n  To achieve the desired authentication properties, Muckle+ utilizes post-quantum digital signatures. However, available instantiations of such signatures schemes are not yet efficient enough compared to their post-quantum key-encapsulation mechanism (KEM) counterparts, particularly in large networks with potentially several connections in a short period of time.\n  To mitigate this gap, we propose Muckle# that pushes the efficiency boundaries of currently known HAKE constructions. Muckle# uses post-quantum key-encapsulating mechanisms for implicit authentication inspired by recent works done in the area of Transport Layer Security (TLS) protocols, particularly, in KEMTLS (CCS'20).\n  We port those ideas to the HAKE framework and develop novel proof techniques on the way. Due to our novel KEM-based approach, the resulting protocol has a slightly different message flow compared to prior work that we carefully align with the HAKE framework and which makes our changes to the Muckle+ non-trivial.",
      "authors": [
        "Christopher Battarbee",
        "Christoph Striecks",
        "Ludovic Perret",
        "Sebastian Ramacher",
        "Kevin Verhaeghe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T16:28:17+00:00",
          "link": "https://arxiv.org/abs/2411.04030v1",
          "size": "6027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:41:48+00:00",
          "link": "https://arxiv.org/abs/2411.04030v2",
          "size": "5995kb",
          "version": "v2"
        }
      ],
      "title": "Quantum-Safe Hybrid Key Exchanges with KEM-Based Authentication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04030",
        "PDF": "https://arxiv.org/pdf/2411.04030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with key exchange protocols for security in quantum-safe networks, focusing on KEM-based authentication. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10371",
      "abstract": "Event Causality Identification (ECI) has emerged as a pivotal task in natural language processing (NLP), aimed at automatically detecting causal relationships between events in text. In this comprehensive survey, we systematically elucidate the foundational principles and technical frameworks of ECI, proposing a novel classification framework to categorize and clarify existing methods. {We discuss associated challenges, provide quantitative evaluations, and outline future directions for this dynamic and rapidly evolving field. We first delineate key definitions, problem formalization, and evaluation protocols of ECI. Our classification framework organizes ECI methods based on two primary tasks: Sentence-level Event Causality Identification (SECI) and Document-level Event Causality Identification (DECI). For SECI, we review methods including feature pattern-based matching, machine learning-based classification, deep semantic encoding, prompt-based fine-tuning, and causal knowledge pre-training, alongside common data augmentation strategies. For DECI, we focus on techniques such as deep semantic encoding, event graph reasoning, and prompt-based fine-tuning. We dedicate specific discussions to advancements in multi-lingual and cross-lingual ECI as well as zero-shot ECI leveraging Large Language Models (LLMs). Furthermore, we analyze the strengths, limitations, and unresolved challenges of each method. Extensive quantitative evaluations are conducted on four benchmark datasets to assess various ECI methods. Finally, we explore future research directions.",
      "authors": [
        "Qing Cheng",
        "Zefan Zeng",
        "Xingchen Hu",
        "Yuehang Si",
        "Zhong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T17:19:42+00:00",
          "link": "https://arxiv.org/abs/2411.10371v1",
          "size": "5111kb",
          "version": "v1"
        },
        {
          "date": "2024-11-25T16:55:09+00:00",
          "link": "https://arxiv.org/abs/2411.10371v2",
          "size": "5159kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T07:35:00+00:00",
          "link": "https://arxiv.org/abs/2411.10371v3",
          "size": "9959kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T02:03:22+00:00",
          "link": "https://arxiv.org/abs/2411.10371v4",
          "size": "1123kb",
          "version": "v4"
        }
      ],
      "title": "A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10371",
        "HTML": "https://arxiv.org/html/2411.10371v4",
        "PDF": "https://arxiv.org/pdf/2411.10371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the primary focus of this paper is event causality identification in NLP, it mentions ECI techniques related to prompt-based fine-tuning and causal knowledge pre-training using LLMs. However, the main focus is not specifically on LLM training data processing."
      },
      "tasks": [
        "Causal Inference",
        "Event Causality Identification",
        "Sentence"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16619",
      "abstract": "AI-driven video generation techniques have made significant progress in recent years. However, AI-generated videos (AGVs) involving human activities often exhibit substantial visual and semantic distortions, hindering the practical application of video generation technologies in real-world scenarios. To address this challenge, we conduct a pioneering study on human activity AGV quality assessment, focusing on visual quality evaluation and the identification of semantic distortions. First, we construct the AI-Generated Human activity Video Quality Assessment (Human-AGVQA) dataset, consisting of 6,000 AGVs derived from 15 popular text-to-video (T2V) models using 400 text prompts that describe diverse human activities. We conduct a subjective study to evaluate the human appearance quality, action continuity quality, and overall video quality of AGVs, and identify semantic issues of human body parts. Based on Human-AGVQA, we benchmark the performance of T2V models and analyze their strengths and weaknesses in generating different categories of human activities. Second, we develop an objective evaluation metric, named AI-Generated Human activity Video Quality metric (GHVQ), to automatically analyze the quality of human activity AGVs. GHVQ systematically extracts human-focused quality features, AI-generated content-aware quality features, and temporal continuity features, making it a comprehensive and explainable quality metric for human activity AGVs. The extensive experimental results show that GHVQ outperforms existing quality metrics on the Human-AGVQA dataset by a large margin, demonstrating its efficacy in assessing the quality of human activity AGVs. The Human-AGVQA dataset and GHVQ metric will be released at https://github.com/zczhang-sjtu/GHVQ.git.",
      "authors": [
        "Zhichao Zhang",
        "Wei Sun",
        "Xinyue Li",
        "Yunhao Li",
        "Qihang Ge",
        "Jun Jia",
        "Zicheng Zhang",
        "Zhongpeng Ji",
        "Fengyu Sun",
        "Shangling Jui",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T17:58:43+00:00",
          "link": "https://arxiv.org/abs/2411.16619v1",
          "size": "4741kb",
          "version": "v1"
        },
        {
          "date": "2025-04-17T07:28:43+00:00",
          "link": "https://arxiv.org/abs/2411.16619v2",
          "size": "9032kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T08:05:06+00:00",
          "link": "https://arxiv.org/abs/2411.16619v3",
          "size": "4849kb",
          "version": "v3"
        }
      ],
      "title": "Human-Activity AGV Quality Assessment: A Benchmark Dataset and an Objective Evaluation Metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16619",
        "HTML": "https://arxiv.org/html/2411.16619v3",
        "PDF": "https://arxiv.org/pdf/2411.16619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI-generated video quality assessment, specifically related to human activity, which does not involve training data processing for large language models."
      },
      "tasks": [
        "Video Generation",
        "Video Quality Assessment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.02198",
      "abstract": "Aging presents a significant challenge in face recognition, as changes in skin texture and tone can alter facial features over time, making it particularly difficult to compare images of the same individual taken years apart, such as in long-term identification scenarios. Transformer networks have the strength to preserve sequential spatial relationships caused by aging effect. This paper presents a technique for loss evaluation that uses a transformer network as an additive loss in the face recognition domain. The standard metric loss function typically takes the final embedding of the main CNN backbone as its input. Here, we employ a transformer-metric loss, a combined approach that integrates both transformer-loss and metric-loss. This research intends to analyze the transformer behavior on the convolution output when the CNN outcome is arranged in a sequential vector. These sequential vectors have the potential to overcome the texture or regional structure referred to as wrinkles or sagging skin affected by aging. The transformer encoder takes input from the contextual vectors obtained from the final convolution layer of the network. The learned features can be more age-invariant, complementing the discriminative power of the standard metric loss embedding. With this technique, we use transformer loss with various base metric-loss functions to evaluate the effect of the combined loss functions. We observe that such a configuration allows the network to achieve SoTA results in LFW and age-variant datasets (CA-LFW and AgeDB). This research expands the role of transformers in the machine vision domain and opens new possibilities for exploring transformers as a loss function.",
      "authors": [
        "Pritesh Prakash",
        "S Umamaheswaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T06:23:35+00:00",
          "link": "https://arxiv.org/abs/2412.02198v1",
          "size": "926kb",
          "version": "v1"
        },
        {
          "date": "2025-01-29T10:59:30+00:00",
          "link": "https://arxiv.org/abs/2412.02198v2",
          "size": "1213kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T05:03:04+00:00",
          "link": "https://arxiv.org/abs/2412.02198v3",
          "size": "422kb",
          "version": "v3"
        }
      ],
      "title": "Transformer-Based Auxiliary Loss for Face Recognition Across Age Variations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02198",
        "HTML": "https://arxiv.org/html/2412.02198v3",
        "PDF": "https://arxiv.org/pdf/2412.02198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores a transformer-based auxiliary loss for face recognition across age variations, which does not pertain to LLM training data processing or data engineering."
      },
      "tasks": [
        "Face Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.02808",
      "abstract": "Understanding video content is pivotal for advancing real-world applications like activity recognition, autonomous systems, and human-computer interaction. While scene graphs are adept at capturing spatial relationships between objects in individual frames, extending these representations to capture dynamic interactions across video sequences remains a significant challenge. To address this, we present TCDSG, Temporally Consistent Dynamic Scene Graphs, an innovative end-to-end framework that detects, tracks, and links subject-object relationships across time, generating action tracklets, temporally consistent sequences of entities and their interactions. Our approach leverages a novel bipartite matching mechanism, enhanced by adaptive decoder queries and feedback loops, ensuring temporal coherence and robust tracking over extended sequences. This method not only establishes a new benchmark by achieving over 60% improvement in temporal recall@k on the Action Genome, OpenPVSG, and MEVA datasets but also pioneers the augmentation of MEVA with persistent object ID annotations for comprehensive tracklet generation. By seamlessly integrating spatial and temporal dynamics, our work sets a new standard in multi-frame video analysis, opening new avenues for high-impact applications in surveillance, autonomous navigation, and beyond.",
      "authors": [
        "Raphael Ruschel",
        "Md Awsafur Rahman",
        "Hardik Prajapati",
        "Suya You",
        "B. S. Manjuanth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T20:19:20+00:00",
          "link": "https://arxiv.org/abs/2412.02808v1",
          "size": "4294kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T19:23:25+00:00",
          "link": "https://arxiv.org/abs/2412.02808v2",
          "size": "1000kb",
          "version": "v2"
        }
      ],
      "title": "Temporally Consistent Dynamic Scene Graphs: An End-to-End Approach for Action Tracklet Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02808",
        "HTML": "https://arxiv.org/html/2412.02808v2",
        "PDF": "https://arxiv.org/pdf/2412.02808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with dynamic scene graphs for action tracklet generation in videos, without contributing to training data processing for language models."
      },
      "tasks": [
        "Activity Recognition",
        "Autonomous Navigation",
        "Decoder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.07493",
      "abstract": "Performing complex manipulation tasks in dynamic environments requires efficient Task and Motion Planning (TAMP) approaches that combine high-level symbolic plans with low-level motion control. Advances in Large Language Models (LLMs), such as GPT-4, are transforming task planning by offering natural language as an intuitive and flexible way to describe tasks, generate symbolic plans, and reason. However, the effectiveness of LLM-based TAMP approaches is limited due to static and template-based prompting, which limits adaptability to dynamic environments and complex task contexts. To address these limitations, this work proposes a novel Onto-LLM-TAMP framework that employs knowledge-based reasoning to refine and expand user prompts with task-contextual reasoning and knowledge-based environment state descriptions. Integrating domain-specific knowledge into the prompt ensures semantically accurate and context-aware task plans. The proposed framework demonstrates its effectiveness by resolving semantic errors in symbolic plan generation, such as maintaining logical temporal goal ordering in scenarios involving hierarchical object placement. The proposed framework is validated through both simulation and real-world scenarios, demonstrating significant improvements over the baseline approach in terms of adaptability to dynamic environments and the generation of semantically correct task plans.",
      "authors": [
        "Muhayy Ud Din and Jan Rosell and Waseem Akram and Isiah Zaplana and Maximo A Roa and Irfan Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-10T13:18:45+00:00",
          "link": "https://arxiv.org/abs/2412.07493v1",
          "size": "31941kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:31:07+00:00",
          "link": "https://arxiv.org/abs/2412.07493v2",
          "size": "22165kb",
          "version": "v2"
        }
      ],
      "title": "Onto-LLM-TAMP: Knowledge-oriented Task and Motion Planning using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.07493",
        "HTML": "https://arxiv.org/html/2412.07493v2",
        "PDF": "https://arxiv.org/pdf/2412.07493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses using LLMs for task and motion planning, it briefly touches upon prompt-based data input but does not focus on LLM training data processing or improving data quality."
      },
      "tasks": [
        "Motion Planning",
        "Task and Motion Planning",
        "Task Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10595",
      "abstract": "Traditional recommender systems based on revealed preferences often fail to capture the fundamental duality in user behavior, where consumption choices are driven by both inherent value (enrichment) and instant appeal (temptation). Consequently, these systems may generate recommendations that prioritize short-term engagement over long-lasting user satisfaction. We propose a novel recommender design that explicitly models the tension between enrichment and temptation. We introduce a behavioral model that accounts for how both enrichment and temptation influence user choices, while incorporating the reality of off-platform alternatives. Building on this model, we formulate a novel recommendation objective aligned with maximizing consumed enrichment and prove the optimality of a locally greedy recommendation strategy. Finally, we present an estimation framework that leverages the distinction between explicit user feedback and implicit choice data while making minimal assumptions about off-platform options. Through comprehensive evaluation using both synthetic simulations and real-world data from the MovieLens dataset, we demonstrate that our approach consistently outperforms competitive baselines that ignore temptation dynamics either by assuming revealed preferences or recommending solely based on enrichment. Our work represents a paradigm shift toward more nuanced and user-centric recommender design, with significant implications for developing responsible AI systems that genuinely serve users' long-term interests rather than merely maximizing engagement.",
      "authors": [
        "Md Sanzeed Anwar",
        "Paramveer S. Dhillon",
        "Grant Schoenebeck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computers and Society (cs.CY)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T22:44:22+00:00",
          "link": "https://arxiv.org/abs/2412.10595v1",
          "size": "87kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:15:21+00:00",
          "link": "https://arxiv.org/abs/2412.10595v2",
          "size": "102kb",
          "version": "v2"
        }
      ],
      "title": "Recommendation and Temptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10595",
        "HTML": "https://arxiv.org/html/2412.10595v2",
        "PDF": "https://arxiv.org/pdf/2412.10595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new approach for recommender systems by modeling user behavior; it does not address any aspects of LLM training data processing."
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.12749",
      "abstract": "Flexibility provision from active distribution grids requires efficient and robust methods of optimization and control suitable to online operation. In this paper we introduce conditions for the safe operation of feedback optimization based controllers. We use the feasible operating region of a controlled system as bounds for safe system states and evaluate the trajectories of the controller based on the projection of the full system state onto the two-dimensional PQ-plane. We demonstrate the defined conditions for an exemplary sub-transmission system. We show that the proposed method is suitable to evaluate controller performance and robustness for systems subject to disturbances.",
      "authors": [
        "Florian Klein-Helmkamp",
        "Tina M\\\"ollemann",
        "Irina Zettl",
        "Steffen Kortmann",
        "Andreas Ulbig"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T10:13:22+00:00",
          "link": "https://arxiv.org/abs/2412.12749v1",
          "size": "3225kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:23:00+00:00",
          "link": "https://arxiv.org/abs/2412.12749v2",
          "size": "2126kb",
          "version": "v2"
        }
      ],
      "title": "Safe Trajectory Sets for Online Operation of Power Systems under Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12749",
        "HTML": "https://arxiv.org/html/2412.12749v2",
        "PDF": "https://arxiv.org/pdf/2412.12749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on feedback optimization and controller performance for power systems, which is outside the scope of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.14382",
      "abstract": "Mixed-integer programming (MIP) is a powerful paradigm for modeling and solving various important combinatorial optimization problems. Recently, learning-based approaches have shown a potential to speed up MIP solving via offline training that then guides important design decisions during the search. However, a significant drawback of these methods is their heavy reliance on offline training, which requires collecting training datasets and computationally costly training epochs yet offering only limited generalization to unseen (larger) instances. In this paper, we propose Balans, an adaptive meta-solver for MIPs with online learning capability that does not require any supervision or apriori training. At its core, Balans is based on adaptive large-neighborhood search, operating on top of an MIP solver by successive applications of destroy and repair neighborhood operators. During the search, the selection among different neighborhood definitions is guided on the fly for the instance at hand via multi-armed bandit algorithms. Our extensive experiments on hard optimization instances show that Balans offers significant performance gains over the default MIP solver, is better than committing to any single best neighborhood, and improves over the state-of-the-art large-neighborhood search for MIPs. Finally, we release Balans as a highly configurable, MIP solver agnostic, open-source software.",
      "authors": [
        "Junyang Cai",
        "Serdar Kadioglu",
        "Bistra Dilkina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T22:32:13+00:00",
          "link": "https://arxiv.org/abs/2412.14382v1",
          "size": "1456kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T21:25:17+00:00",
          "link": "https://arxiv.org/abs/2412.14382v2",
          "size": "1531kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T17:09:55+00:00",
          "link": "https://arxiv.org/abs/2412.14382v3",
          "size": "1531kb",
          "version": "v3"
        }
      ],
      "title": "Balans: Multi-Armed Bandits-based Adaptive Large Neighborhood Search for Mixed-Integer Programming Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14382",
        "HTML": "https://arxiv.org/html/2412.14382v3",
        "PDF": "https://arxiv.org/pdf/2412.14382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about improving mixed-integer programming via adaptive search methods and does not relate to any aspect of training data processing for LLMs."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Multi-Armed Bandits"
      ],
      "repo_urls": [
        "https://github.com/skadio/balans"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16209",
      "abstract": "Imbalanced binary classification problems arise in many fields of study. When using machine learning models for these problems, it is common to subsample the majority class (i.e., undersampling) to create a (more) balanced dataset for model training. This biases the model's predictions because the model learns from a dataset that does not follow the same data generating process as new data. One way of accounting for this bias is to analytically map the resulting predictions to new values based on the sampling rate for the majority class, which was used to create the training dataset. While this approach may work well for some machine learning models, we show that calibrating a random forest this way has unintended negative consequences, including prevalence estimates that can be upwardly biased. These prevalence estimates depend on both i) the number of predictors considered at each split in the random forest; and ii) the sampling rate used. We explain the former using known properties of random forests and analytical calibration. However, in investigating the latter issue, we made a surprising discovery - contrary to the widespread belief that decision trees are biased towards the majority class, they actually can be biased towards the minority class.",
      "authors": [
        "Nathan Phelps",
        "Daniel J. Lizotte",
        "and Douglas G. Woolford"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T19:38:29+00:00",
          "link": "https://arxiv.org/abs/2412.16209v1",
          "size": "823kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:32:05+00:00",
          "link": "https://arxiv.org/abs/2412.16209v2",
          "size": "1000kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T17:25:41+00:00",
          "link": "https://arxiv.org/abs/2412.16209v3",
          "size": "1000kb",
          "version": "v3"
        }
      ],
      "title": "Challenges learning from imbalanced data using tree-based models: Prevalence estimates systematically depend on hyperparameters and can be upwardly biased",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16209",
        "PDF": "https://arxiv.org/pdf/2412.16209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses challenges in imbalanced data classification using tree-based models, focusing on sampling bias and prevalence estimates, rather than LLM training data processing operations."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17252",
      "abstract": "We introduce a multi-modal autonomous delivery optimization framework as a coalition game for a fleet of UAVs and ADRs operating in two overlaying networks to address last-mile delivery in urban environments, including high-density areas and time-critical applications. The problem is defined as multiple depot pickup and delivery with time windows constrained over operational restrictions, such as vehicle battery limitation, precedence time window, and building obstruction. Utilizing the coalition game theory, we investigate cooperation structures among the modes to capture how strategic collaboration can improve overall routing efficiency. To do so, a generalized reinforcement learning model is designed to evaluate the cost-sharing and allocation to different modes to learn the cooperative behaviour with respect to various realistic scenarios. Our methodology leverages an end-to-end deep multi-agent policy gradient method augmented by a novel spatio-temporal adjacency neighbourhood graph attention network using a heterogeneous edge-enhanced attention model and transformer architecture. Several numerical experiments on last-mile delivery applications have been conducted, showing the results from the case study in the city of Mississauga, which shows that despite the incorporation of an extensive network in the graph for two modes and a complex training structure, the model addresses realistic operational constraints and achieves high-quality solutions compared with the existing transformer-based and classical methods. It can perform well on non-homogeneous data distribution, generalizes well on different scales and configurations, and demonstrates a robust cooperative performance under stochastic scenarios across various tasks, which is effectively reflected by coalition analysis and cost allocation to signify the advantage of cooperation.",
      "authors": [
        "Farzan Moosavi and Bilal Farooq"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T03:50:29+00:00",
          "link": "https://arxiv.org/abs/2412.17252v1",
          "size": "12467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T22:52:59+00:00",
          "link": "https://arxiv.org/abs/2412.17252v2",
          "size": "6611kb",
          "version": "v2"
        }
      ],
      "title": "A Coalition Game for On-demand Multi-modal 3D Automated Delivery System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17252",
        "HTML": "https://arxiv.org/html/2412.17252v2",
        "PDF": "https://arxiv.org/pdf/2412.17252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on delivery optimization using coalition game theory and learning models, with no mention of LLM training data processing or related operations."
      },
      "tasks": [
        "Graph Attention"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.20936",
      "abstract": "Influence maximization in temporal social networks presents unique challenges due to the dynamic interactions that evolve over time. Traditional diffusion models often fall short in capturing the real-world complexities of active-inactive transitions among nodes, obscuring the true behavior of influence spread. In dynamic networks, nodes do not simply transition to an active state once; rather, they can oscillate between active and inactive states, with the potential for reactivation and reinforcement over time. This reactivation allows previously influenced nodes to regain influence potency, enhancing their ability to spread influence to others and amplifying the overall diffusion process. Ignoring these transitions can thus conceal the cumulative impact of influence, making it essential to account for them in any effective diffusion model. To address these challenges, we introduce the Continuous Persistent Susceptible-Infected Model with Reinforcement and Re-activation (cpSI-R), which explicitly incorporates active-inactive transitions, capturing the progressive reinforcement that makes nodes more potent spreaders upon reactivation. This model naturally leads to a submodular and monotone objective function, which supports efficient optimization for seed selection in influence maximization tasks. Alongside cpSI-R, we propose an efficient temporal snapshot sampling method, simplifying the analysis of evolving networks. We then adapt the prior algorithms of seed selection to our model and sampling strategy, resulting in reduced computational costs and enhanced seed selection efficiency. Experimental evaluations on diverse datasets demonstrate substantial improvements in performance over baseline methods, underscoring the effectiveness of cpSI-R for real-world temporal networks",
      "authors": [
        "Aaqib Zahoor",
        "Iqra Altaf Gillani",
        "and Janib ul Bashir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T13:27:00+00:00",
          "link": "https://arxiv.org/abs/2412.20936v1",
          "size": "233kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T18:51:41+00:00",
          "link": "https://arxiv.org/abs/2412.20936v2",
          "size": "725kb",
          "version": "v2"
        }
      ],
      "title": "Influence Maximization in Temporal Networks with Persistent and Reactive Behaviors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20936",
        "HTML": "https://arxiv.org/html/2412.20936v2",
        "PDF": "https://arxiv.org/pdf/2412.20936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on influence maximization in temporal networks using a specific diffusion model and does not cover any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.02851",
      "abstract": "We study community detection in multiple networks with jointly correlated node attributes and edges. This setting arises naturally in applications such as social platforms, where a shared set of users may exhibit both correlated friendship patterns and correlated attributes across different platforms. Extending the classical Stochastic Block Model (SBM) and its contextual counterpart (Contextual SBM or CSBM), we introduce the correlated CSBM, which incorporates structural and attribute correlations across graphs. To build intuition, we first analyze correlated Gaussian Mixture Models, wherein only correlated node attributes are available without edges, and identify the conditions under which an estimator minimizing the distance between attributes achieves exact matching of nodes across the two databases. For the correlated CSBMs, we develop a two-step procedure that first applies $k$-core matching to most nodes using edge information, then refines the matching for the remaining unmatched nodes by leveraging their attributes with a distance-based estimator. We identify the conditions under which the algorithm recovers the exact node correspondence, enabling us to merge the correlated edges and average the correlated attributes for enhanced community detection. Crucially, by aligning and combining graphs, we identify regimes in which community detection is impossible in a single graph but becomes feasible when side information from correlated graphs is incorporated. Our results illustrate how the interplay between graph matching and community recovery can boost performance, broadening the scope of multi-graph, attribute-based community detection.",
      "authors": [
        "Joonhyuk Yang and Hye Won Chung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T08:57:44+00:00",
          "link": "https://arxiv.org/abs/2501.02851v1",
          "size": "177kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:45:33+00:00",
          "link": "https://arxiv.org/abs/2501.02851v2",
          "size": "238kb",
          "version": "v2"
        }
      ],
      "title": "Exact Matching in Correlated Networks with Node Attributes for Improved Community Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02851",
        "HTML": "https://arxiv.org/html/2501.02851v2",
        "PDF": "https://arxiv.org/pdf/2501.02851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with community detection and exact matching in networks, focusing on correlated node attributes and edges, which is not related to LLM training data processing."
      },
      "tasks": [
        "Attribute",
        "Community Detection",
        "Graph Matching",
        "Stochastic Block Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06158",
      "abstract": "Drug discovery is a complex process that involves multiple stages and tasks. However, existing molecular generative models can only tackle some of these tasks. We present Generalist Molecular generative model (GenMol), a versatile framework that uses only a single discrete diffusion model to handle diverse drug discovery scenarios. GenMol generates Sequential Attachment-based Fragment Embedding (SAFE) sequences through non-autoregressive bidirectional parallel decoding, thereby allowing the utilization of a molecular context that does not rely on the specific token ordering while having better sampling efficiency. GenMol uses fragments as basic building blocks for molecules and introduces fragment remasking, a strategy that optimizes molecules by regenerating masked fragments, enabling effective exploration of chemical space. We further propose molecular context guidance (MCG), a guidance method tailored for masked discrete diffusion of GenMol. GenMol significantly outperforms the previous GPT-based model in de novo generation and fragment-constrained generation, and achieves state-of-the-art performance in goal-directed hit generation and lead optimization. These results demonstrate that GenMol can tackle a wide range of drug discovery tasks, providing a unified and versatile approach for molecular design. Our code is available at https://github.com/NVIDIA-Digital-Bio/genmol.",
      "authors": [
        "Seul Lee",
        "Karsten Kreis",
        "Srimukh Prasad Veccham",
        "Meng Liu",
        "Danny Reidenbach",
        "Yuxing Peng",
        "Saee Paliwal",
        "Weili Nie",
        "Arash Vahdat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T18:30:05+00:00",
          "link": "https://arxiv.org/abs/2501.06158v1",
          "size": "1398kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T23:51:15+00:00",
          "link": "https://arxiv.org/abs/2501.06158v2",
          "size": "2268kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T22:03:34+00:00",
          "link": "https://arxiv.org/abs/2501.06158v3",
          "size": "1502kb",
          "version": "v3"
        }
      ],
      "title": "GenMol: A Drug Discovery Generalist with Discrete Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06158",
        "HTML": "https://arxiv.org/html/2501.06158v3",
        "PDF": "https://arxiv.org/pdf/2501.06158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces GenMol, a molecular generative model for drug discovery tasks. It does not relate to LLM training data processing as it focuses on molecular generation and optimization."
      },
      "datasets": [
        {
          "dataset_name": "Derify/pubchem_10m_genmol_similarity",
          "downloads": "42",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Derify/pubchem_10m_genmol_similarity"
        }
      ],
      "tasks": [
        "Computational Efficiency",
        "Drug Discovery",
        "molecular representation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06348",
      "abstract": "Understanding the motivations underlying the human inclination to automate tasks is vital to developing truly helpful robots integrated into daily life. Accordingly, we ask: are individuals more inclined to automate chores based on the time they consume or the feelings experienced while performing them? This study explores these preferences and whether they vary across different social groups (i.e., gender category and income level). Leveraging data from the BEHAVIOR-1K dataset, the American Time-Use Survey, and the American Time-Use Survey Well-Being Module, we investigate the relationship between the desire for automation, time spent on daily activities, and their associated feelings - Happiness, Meaningfulness, Sadness, Painfulness, Stressfulness, or Tiredness. Our key findings show that, despite common assumptions, time spent does not strongly relate to the desire for automation for the general population. For the feelings analyzed, only happiness and pain are key indicators. Significant differences by gender and economic level also emerged: Women prefer to automate stressful activities, whereas men prefer to automate those that make them unhappy; mid-income individuals prioritize automating less enjoyable and meaningful activities, while low and high-income show no significant correlations. We hope our research helps motivate technologies to develop robots that match the priorities of potential users, moving domestic robotics toward more socially relevant solutions. We open-source all the data, including an online tool that enables the community to replicate our analysis and explore additional trends at https://robin-lab.cs.utexas.edu/why-automate-this/.",
      "authors": [
        "Ruchira Ray",
        "Leona Pang",
        "Sanjana Srivastava",
        "Li Fei-Fei",
        "Samantha Shorey",
        "Roberto Mart\\'in-Mart\\'in"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T21:20:11+00:00",
          "link": "https://arxiv.org/abs/2501.06348v1",
          "size": "2403kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T16:18:12+00:00",
          "link": "https://arxiv.org/abs/2501.06348v2",
          "size": "1860kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T17:44:37+00:00",
          "link": "https://arxiv.org/abs/2501.06348v3",
          "size": "1860kb",
          "version": "v3"
        }
      ],
      "title": "Why Automate This? Exploring Correlations between Desire for Robotic Automation, Invested Time and Well-Being",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06348",
        "PDF": "https://arxiv.org/pdf/2501.06348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates human preferences for robotic automation based on time and emotional factors, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06438",
      "abstract": "This paper presents Qffusion, a dual-frame-guided framework for portrait video editing. Specifically, we consider a design principle of ``animation for editing'', and train Qffusion as a general animation framework from two still reference images while we can use it for portrait video editing easily by applying modified start and end frames as references during inference. Leveraging the powerful generative power of Stable Diffusion, we propose a Quadrant-grid Arrangement (QGA) scheme for latent re-arrangement, which arranges the latent codes of two reference images and that of four facial conditions into a four-grid fashion, separately. Then, we fuse features of these two modalities and use self-attention for both appearance and temporal learning, where representations at different times are jointly modeled under QGA. Our Qffusion can achieve stable video editing without additional networks or complex training stages, where only the input format of Stable Diffusion is modified. Further, we propose a Quadrant-grid Propagation (QGP) inference strategy, which enjoys a unique advantage on stable arbitrary-length video generation by processing reference and condition frames recursively. Through extensive experiments, Qffusion consistently outperforms state-of-the-art techniques on portrait video editing. Project page: https://qffusion.github.io/page/.",
      "authors": [
        "Maomao Li",
        "Lijian Lin",
        "Yunfei Liu",
        "Ye Zhu",
        "Yu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-11T04:56:07+00:00",
          "link": "https://arxiv.org/abs/2501.06438v1",
          "size": "15409kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:18:50+00:00",
          "link": "https://arxiv.org/abs/2501.06438v2",
          "size": "8860kb",
          "version": "v2"
        }
      ],
      "title": "Qffusion: Controllable Portrait Video Editing via Quadrant-Grid Attention Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06438",
        "HTML": "https://arxiv.org/html/2501.06438v2",
        "PDF": "https://arxiv.org/pdf/2501.06438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for portrait video editing and leverages techniques like latent re-arrangement and attention learning, but it does not involve any aspects of LLM training data processing."
      },
      "tasks": [
        "Video Editing",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06488",
      "abstract": "Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting, effectively creates photorealistic scenes from sparse viewpoints, typically evaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However, these full-reference methods, which compare synthesized views to reference views, may not fully capture the perceptual quality of neurally synthesized scenes (NSS), particularly due to the limited availability of dense reference views. Furthermore, the challenges in acquiring human perceptual labels hinder the creation of extensive labeled datasets, risking model overfitting and reduced generalizability. To address these issues, we propose NVS-SQA, a NSS quality assessment method to learn no-reference quality representations through self-supervision without reliance on human labels. Traditional self-supervised learning predominantly relies on the \"same instance, similar representation\" assumption and extensive datasets. However, given that these conditions do not apply in NSS quality assessment, we employ heuristic cues and quality scores as learning objectives, along with a specialized contrastive pair preparation process to improve the effectiveness and efficiency of learning. The results show that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e., on average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second best) and even exceeds 16 full-reference methods across all evaluation metrics (i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best).",
      "authors": [
        "Qiang Qu",
        "Yiran Shen",
        "Xiaoming Chen",
        "Yuk Ying Chung",
        "Weidong Cai",
        "Tongliang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-11T09:12:43+00:00",
          "link": "https://arxiv.org/abs/2501.06488v1",
          "size": "33342kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T02:32:10+00:00",
          "link": "https://arxiv.org/abs/2501.06488v2",
          "size": "33453kb",
          "version": "v2"
        }
      ],
      "title": "NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06488",
        "HTML": "https://arxiv.org/html/2501.06488v2",
        "PDF": "https://arxiv.org/pdf/2501.06488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for quality assessment in Neural View Synthesis (NVS), which does not pertain to data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [
        "NeRF",
        "Representation Learning",
        "Self-Supervised Learning",
        "SSIM"
      ],
      "repo_urls": [
        "https://github.com/vincentqqu/nvs-sqa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08518",
      "abstract": "Seasickness poses a widespread problem that adversely impacts both passenger comfort and the operational efficiency of maritime crews. Although attention shift has been proposed as a potential method to alleviate symptoms of motion sickness, its efficacy remains to be rigorously validated, especially in maritime environments. In this study, we develop an AI-driven brain-computer interface (BCI) to realize sustained and practical attention shift by incorporating tasks such as breath counting. Forty-three participants completed a real-world nautical experiment consisting of a real-feedback session, a resting session, and a pseudo-feedback session. Notably, 81.39\\% of the participants reported that the BCI intervention was effective. EEG analysis revealed that the proposed system can effectively regulate motion sickness EEG signatures, such as an decrease in total band power, along with an increase in theta relative power and a decrease in beta relative power. Furthermore, an indicator of attentional focus, the theta/beta ratio, exhibited a significant reduction during the real-feedback session, providing further evidence to support the effectiveness of the BCI in shifting attention. Collectively, this study presents a novel nonpharmacological, portable, and effective approach for seasickness intervention, which has the potential to open up a brand-new application domain for BCIs.",
      "authors": [
        "Xiaoyu Bao and Kailin Xu and Jiawei Zhu and Haiyun Huang and Kangning Li and Qiyun Huang and Yuanqing Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T02:06:29+00:00",
          "link": "https://arxiv.org/abs/2501.08518v1",
          "size": "14355kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:01:28+00:00",
          "link": "https://arxiv.org/abs/2501.08518v2",
          "size": "2744kb",
          "version": "v2"
        }
      ],
      "title": "Alleviating Seasickness through Brain-Computer Interface-based Attention Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08518",
        "HTML": "https://arxiv.org/html/2501.08518v2",
        "PDF": "https://arxiv.org/pdf/2501.08518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a brain-computer interface approach for alleviating seasickness, unrelated to LLM training data processing."
      },
      "tasks": [
        "Brain Computer Interface",
        "EEG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.10601",
      "abstract": "Background: Harnessing advanced computing for scientific discovery and technological innovation demands scientists and engineers well-versed in both domain science and computational science and engineering (CSE). However, few universities provide access to both integrated domain science/CSE cross-training and Top-500 High-Performance Computing (HPC) facilities. National laboratories offer internship opportunities capable of developing these skills. Purpose: This student presents an evaluation of federally-funded postgraduate internship outcomes at a national laboratory. This study seeks to answer three questions: 1) What computational skills, research skills, and professional skills do students improve through internships at the selected national laboratory. 2) Do students gain knowledge in domain science topics through their internships. 3) Do students' career interests change after these internships? Design/Method: We developed a survey and collected responses from past participants of five federally-funded internship programs and compare participant ratings of their prior experience to their internship experience. Findings: Our results indicate that participants improve CSE skills and domain science knowledge, and are more interested in working at national labs. Participants go on to degree programs and positions in relevant domain science topics after their internships. Conclusions: We show that national laboratory internships are an opportunity for students to build CSE skills that may not be available at all institutions. We also show a growth in domain science skills during their internships through direct exposure to research topics. The survey instrument and approach used may be adapted to other studies to measure the impact of postgraduate internships in multiple disciplines and internship settings.",
      "authors": [
        "Morgan M. Fong",
        "Hilary Egan",
        "Marc Day",
        "Kristin Potter",
        "and Michael J. Martin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T23:31:57+00:00",
          "link": "https://arxiv.org/abs/2501.10601v1",
          "size": "845kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T17:37:41+00:00",
          "link": "https://arxiv.org/abs/2501.10601v2",
          "size": "828kb",
          "version": "v2"
        }
      ],
      "title": "Understanding Computational Science and Engineering (CSE) and Domain Science Skills Development in National Laboratory Postgraduate Internships",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10601",
        "PDF": "https://arxiv.org/pdf/2501.10601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates computational skill development in postgraduate internships, focusing on domain sciences and CSE, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.12296",
      "abstract": "In the pursuit of robust autonomous driving systems, models trained on real-world datasets often struggle to adapt to new environments, particularly when confronted with corner cases such as extreme weather conditions. Collecting these corner cases in the real world is non-trivial, which necessitates the use of simulators for validation. However,the high computational cost and the domain gap in data distribution have hindered the seamless transition between real and simulated driving scenarios. To tackle this challenge, we propose Retrieval-Augmented Learning for Autonomous Driving (RALAD), a novel framework designed to bridge the real-to-sim gap at a low cost. RALAD features three primary designs, including (1) domain adaptation via an enhanced Optimal Transport (OT) method that accounts for both individual and grouped image distances, (2) a simple and unified framework that can be applied to various models, and (3) efficient fine-tuning techniques that freeze the computationally expensive layers while maintaining robustness. Experimental results demonstrate that RALAD compensates for the performance degradation in simulated environments while maintaining accuracy in real-world scenarios across three different models. Taking Cross View as an example, the mIOU and mAP metrics in real-world scenarios remain stable before and after RALAD fine-tuning, while in simulated environments,the mIOU and mAP metrics are improved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of our approach is reduced by approximately 88.1%. Our code is available at https://github.com/JiachengZuo/RALAD.git.",
      "authors": [
        "Jiacheng Zuo",
        "Haibo Hu",
        "Zikang Zhou",
        "Yufei Cui",
        "Ziquan Liu",
        "Jianping Wang",
        "Nan Guan",
        "Jin Wang",
        "Chun Jason Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T17:03:06+00:00",
          "link": "https://arxiv.org/abs/2501.12296v1",
          "size": "3011kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T06:45:12+00:00",
          "link": "https://arxiv.org/abs/2501.12296v2",
          "size": "6695kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T13:04:12+00:00",
          "link": "https://arxiv.org/abs/2501.12296v3",
          "size": "10530kb",
          "version": "v3"
        }
      ],
      "title": "RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12296",
        "HTML": "https://arxiv.org/html/2501.12296v3",
        "PDF": "https://arxiv.org/pdf/2501.12296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving performance in autonomous driving scenarios through domain adaptation and efficient fine-tuning techniques. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Domain Adaptation"
      ],
      "repo_urls": [
        "https://github.com/jiachengzuo/ralad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12971",
      "abstract": "We study universal decoding over unknown discrete additive channels determined by a finite-state (unifilar) random process. Aiming at low-complexity decoders, we study variants of noise-guessing decoders that use estimators for the probability of a noise sequence when the actual channel law is unknown. A deterministic version produces noise sequences in a fixed order, and a new randomised version draws them at random, until finding a sequence that, subtracted from the received sequence, results in a valid codeword. We show that both strategies are random-coding universal (i.e. have the same random-coding error exponent as the optimal maximum likelihood decoding), and derive upper bounds for their complexity. Numerical examples in additive Markov channels illustrate the proposed methods' performance, showing that they consistently outperform a more usual training-based strategy.",
      "authors": [
        "Henrique K. Miyamoto",
        "Sheng Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T15:57:21+00:00",
          "link": "https://arxiv.org/abs/2501.12971v1",
          "size": "407kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:43:44+00:00",
          "link": "https://arxiv.org/abs/2501.12971v2",
          "size": "1299kb",
          "version": "v2"
        }
      ],
      "title": "Universal Decoding over Finite-State Additive Channels via Noise Guessing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12971",
        "HTML": "https://arxiv.org/html/2501.12971v2",
        "PDF": "https://arxiv.org/pdf/2501.12971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about universal decoding in finite-state channels and deals with noise-guessing decoders, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13686",
      "abstract": "We extend the formalism of Conjectural Variations games to Stackelberg games involving multiple leaders and a single follower. To solve these nonconvex games, a common assumption is that the leaders compute their strategies having perfect knowledge of the follower's best response. However, in practice, the leaders may have little to no knowledge about the other players' reactions. To deal with this lack of knowledge, we assume that each leader can form conjectures about the other players' best responses, and update its strategy relying on these conjectures. Our contributions are twofold: (i) On the theoretical side, we introduce the concept of Conjectural Stackelberg Equilibrium -- keeping our formalism conjecture agnostic -- with Stackelberg Equilibrium being a refinement of it. (ii) On the algorithmic side, we introduce a two-stage algorithm with guarantees of convergence, which allows the leaders to first learn conjectures on a training data set, and then update their strategies. Theoretical results are illustrated numerically.",
      "authors": [
        "Francesco Morri",
        "H\\'el\\`ene Le Cadre",
        "Luce Brotcorne"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T14:13:26+00:00",
          "link": "https://arxiv.org/abs/2501.13686v1",
          "size": "120kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T07:15:57+00:00",
          "link": "https://arxiv.org/abs/2501.13686v2",
          "size": "132kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T12:56:40+00:00",
          "link": "https://arxiv.org/abs/2501.13686v3",
          "size": "119kb",
          "version": "v3"
        }
      ],
      "title": "Learning in Conjectural Stackelberg Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13686",
        "HTML": "https://arxiv.org/html/2501.13686v3",
        "PDF": "https://arxiv.org/pdf/2501.13686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses game theory in the context of Stackelberg games, focusing on strategy formation and equilibrium concepts, without addressing LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/francescomorri/costal"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.13926",
      "abstract": "Chain-of-Thought (CoT) reasoning has been extensively explored in large models to tackle complex understanding tasks. However, it still remains an open question whether such strategies can be applied to verifying and reinforcing image generation scenarios. In this paper, we provide the first comprehensive investigation of the potential of CoT reasoning to enhance autoregressive image generation. We focus on three techniques: scaling test-time computation for verification, aligning model preferences with Direct Preference Optimization (DPO), and integrating these techniques for complementary effects. Our results demonstrate that these approaches can be effectively adapted and combined to significantly improve image generation performance. Furthermore, given the pivotal role of reward models in our findings, we propose the Potential Assessment Reward Model (PARM) and PARM++, specialized for autoregressive image generation. PARM adaptively assesses each generation step through a potential assessment approach, merging the strengths of existing reward models, and PARM++ further introduces a reflection mechanism to self-correct the generated unsatisfactory image, which is the first to incorporate reflection in autoregressive image generation. Using our investigated reasoning strategies, we enhance a baseline model, Show-o, to achieve superior results, with a significant +24% improvement on the GenEval benchmark, surpassing Stable Diffusion 3 by +15%. We hope our study provides unique insights and paves a new path for integrating CoT reasoning with autoregressive image generation. Code and models are released at https://github.com/ZiyuGuo99/Image-Generation-CoT",
      "authors": [
        "Ziyu Guo",
        "Renrui Zhang",
        "Chengzhuo Tong",
        "Zhizheng Zhao",
        "Rui Huang",
        "Haoquan Zhang",
        "Manyuan Zhang",
        "Jiaming Liu",
        "Shanghang Zhang",
        "Peng Gao",
        "Hongsheng Li",
        "Pheng-Ann Heng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T18:59:43+00:00",
          "link": "https://arxiv.org/abs/2501.13926v1",
          "size": "9261kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T16:09:10+00:00",
          "link": "https://arxiv.org/abs/2501.13926v2",
          "size": "5685kb",
          "version": "v2"
        }
      ],
      "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13926",
        "HTML": "https://arxiv.org/html/2501.13926v2",
        "PDF": "https://arxiv.org/pdf/2501.13926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates Chain-of-Thought reasoning for improving image generation tasks, which does not relate to any aspect of LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "Text-to-Image Generation"
      ],
      "repo_urls": [
        "https://github.com/ziyuguo99/image-generation-cot",
        "https://github.com/caraj7/t2i-r1"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14644",
      "abstract": "Decentralized learning enables distributed agents to collaboratively train a shared machine learning model without a central server, through local computation and peer-to-peer communication. Although each agent retains its dataset locally, sharing local models can still expose private information about the local training datasets to adversaries. To mitigate privacy attacks, a common strategy is to inject random artificial noise at each agent before exchanging local models between neighbors. However, this often leads to utility degradation due to the negative effects of cumulated artificial noise on the learning algorithm. In this work, we introduce CorN-DSGD, a novel covariance-based framework for generating correlated privacy noise across agents, which unifies several state-of-the-art methods as special cases. By leveraging network topology and mixing weights, CorN-DSGD optimizes the noise covariance to achieve network-wide noise cancellation. Experimental results show that CorN-DSGD cancels more noise than existing pairwise correlation schemes, improving model performance under formal privacy guarantees.",
      "authors": [
        "Angelo Rodio",
        "Zheng Chen",
        "Erik G. Larsson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T17:05:00+00:00",
          "link": "https://arxiv.org/abs/2501.14644v1",
          "size": "77kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:55:02+00:00",
          "link": "https://arxiv.org/abs/2501.14644v2",
          "size": "189kb",
          "version": "v2"
        }
      ],
      "title": "Optimizing Privacy-Utility Trade-off in Decentralized Learning with Generalized Correlated Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14644",
        "HTML": "https://arxiv.org/html/2501.14644v2",
        "PDF": "https://arxiv.org/pdf/2501.14644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores privacy-utility trade-offs in decentralized learning, focusing on privacy through correlated noise, without involvement in LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/arodio/whisperdsgd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18965",
      "abstract": "We show that learning-rate schedules for large model training behave surprisingly similar to a performance bound from non-smooth convex optimization theory. We provide a bound for the constant schedule with linear cooldown; in particular, the practical benefit of cooldown is reflected in the bound due to the absence of logarithmic terms. Further, we show that this surprisingly close match between optimization theory and practice can be exploited for learning-rate tuning: we achieve noticeable improvements for training 124M and 210M Llama-type models by (i) extending the schedule for continued training with optimal learning-rate, and (ii) transferring the optimal learning-rate across schedules.",
      "authors": [
        "Fabian Schaipp",
        "Alexander H\\\"agele",
        "Adrien Taylor",
        "Umut Simsekli",
        "Francis Bach"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T08:55:56+00:00",
          "link": "https://arxiv.org/abs/2501.18965v1",
          "size": "7533kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:03:41+00:00",
          "link": "https://arxiv.org/abs/2501.18965v2",
          "size": "9208kb",
          "version": "v2"
        }
      ],
      "title": "The Surprising Agreement Between Convex Optimization Theory and Learning-Rate Scheduling for Large Model Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18965",
        "HTML": "https://arxiv.org/html/2501.18965v2",
        "PDF": "https://arxiv.org/pdf/2501.18965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on learning-rate schedules for large model training, which relates to optimization and training dynamics rather than training data processing."
      },
      "tasks": [
        "Scheduling"
      ],
      "repo_urls": [
        "https://github.com/fabian-sp/lr-scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01670",
      "abstract": "The rapid growth in computing demands, particularly driven by artificial intelligence applications, has begun to exceed the capabilities of traditional electronic hardware. Optical computing offers a promising alternative due to its parallelism, high computational speed, and low power consumption. However, existing photonic integrated circuits are constrained by large footprints, costly electro-optical interfaces, and complex control mechanisms, limiting the practical scalability of optical neural networks (ONNs). To address these limitations, we introduce a block-circulant photonic tensor core for a structure-compressed optical neural network (StrC-ONN) architecture. The structured compression technique substantially reduces both model complexity and hardware resources without sacrificing the versatility of neural networks, and achieves accuracy comparable to uncompressed models. Additionally, we propose a hardware-aware training framework to compensate for on-chip nonidealities to improve model robustness and accuracy. Experimental validation through image processing and classification tasks demonstrates that our StrC-ONN achieves a reduction in trainable parameters of up to 74.91%,while still maintaining competitive accuracy levels. Performance analyses further indicate that this hardware-software co-design approach is expected to yield a 3.56 times improvement in power efficiency. By reducing both hardware requirements and control complexity across multiple dimensions, this work explores a new pathway toward practical and scalable ONNs, highlighting a promising route to address future computational efficiency challenges.",
      "authors": [
        "Shupeng Ning",
        "Hanqing Zhu",
        "Chenghao Feng",
        "Jiaqi Gu",
        "David Z. Pan",
        "and Ray T. Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T17:03:45+00:00",
          "link": "https://arxiv.org/abs/2502.01670v1",
          "size": "13254kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:39:55+00:00",
          "link": "https://arxiv.org/abs/2502.01670v2",
          "size": "2783kb",
          "version": "v2"
        }
      ],
      "title": "Hardware-Efficient Photonic Tensor Core: Accelerating Deep Neural Networks with Structured Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01670",
        "PDF": "https://arxiv.org/pdf/2502.01670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hardware efficiency and structured compression in optical neural networks, which is not related to training data processing for large language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.02170",
      "abstract": "Mobility performance has been a key focus in cellular networks up to 5G. To enhance handover (HO) performance, 3GPP introduced Conditional Handover (CHO) and Layer 1/Layer 2 Triggered Mobility (LTM) mechanisms in 5G. While these reactive HO strategies address the trade-off between HO failures (HOF) and ping-pong effects, they often result in inefficient radio resource utilization due to additional HO preparations. To overcome these challenges, this article proposes a proactive HO framework for mobility management in O-RAN, leveraging user-cell link predictions to identify the optimal target cell for HO. We explore various categories of Graph Neural Networks (GNNs) for link prediction and analyze the complexity of applying them to the mobility management domain. Two GNN models are compared using a real-world dataset, with experimental results demonstrating their ability to capture the dynamic and graph-structured nature of cellular networks. Finally, we present key insights from our study and outline future steps to enable the integration of GNN-based link prediction for mobility management in O-RAN networks.",
      "authors": [
        "Ana Gonzalez Bermudez",
        "Miquel Farreras",
        "Milan Groshev",
        "Jos\\'e Antonio Trujillo",
        "Isabel de la Bandera and Raquel Barco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T09:44:41+00:00",
          "link": "https://arxiv.org/abs/2502.02170v1",
          "size": "777kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:48:02+00:00",
          "link": "https://arxiv.org/abs/2502.02170v2",
          "size": "310kb",
          "version": "v2"
        }
      ],
      "title": "Graph Neural Networks for O-RAN Mobility Management: A Link Prediction Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02170",
        "HTML": "https://arxiv.org/html/2502.02170v2",
        "PDF": "https://arxiv.org/pdf/2502.02170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses mobility management in cellular networks using graph neural networks rather than focusing on LLM training data processing."
      },
      "tasks": [
        "Link Prediction",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03829",
      "abstract": "In deep-sea exploration and surgical robotics scenarios, environmental lighting and device resolution limitations often cause high-frequency feature attenuation. Addressing the differences in frequency band sensitivity between CNNs and the human visual system (mid-frequency sensitivity with low-frequency sensitivity surpassing high-frequency), we experimentally quantified the CNN contrast sensitivity function and proposed a wavelet adaptive spectrum fusion (WASF) method inspired by biological vision mechanisms to balance cross-frequency image features. Furthermore, we designed a perception frequency block (PFB) that integrates WASF to enhance frequency-domain feature extraction. Based on this, we developed the FE-UNet model, which employs a SAM2 backbone network and incorporates fine-tuned Hiera-Large modules to ensure segmentation accuracy while improving generalization capability. Experiments demonstrate that FE-UNet achieves state-of-the-art performance in cross-domain tasks such as marine organism segmentation and polyp segmentation, showcasing robust adaptability and significant application potential.",
      "authors": [
        "Guohao Huo",
        "Ruiting Dai",
        "Ling Shao",
        "Jinliang Liu",
        "Hao Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T07:24:34+00:00",
          "link": "https://arxiv.org/abs/2502.03829v1",
          "size": "1381kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:04:31+00:00",
          "link": "https://arxiv.org/abs/2502.03829v2",
          "size": "1238kb",
          "version": "v2"
        }
      ],
      "title": "FE-UNet: Frequency Domain Enhanced U-Net for Low-Frequency Information-Rich Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03829",
        "PDF": "https://arxiv.org/pdf/2502.03829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an improved image segmentation approach with FE-UNet, focusing on convolutional network sensitivity and segmentation, not on processing LLM training data."
      },
      "tasks": [
        "Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05236",
      "abstract": "While autoregressive speech token generation models produce speech with remarkable variety and naturalness, their inherent lack of controllability often results in issues such as hallucinations and undesired vocalizations that do not conform to conditioning inputs. We introduce Koel-TTS, a suite of enhanced encoder-decoder Transformer TTS models that address these challenges by incorporating preference alignment techniques guided by automatic speech recognition and speaker verification models. Additionally, we incorporate classifier-free guidance to further improve synthesis adherence to the transcript and reference speaker audio. Our experiments demonstrate that these optimizations significantly enhance target speaker similarity, intelligibility, and naturalness of synthesized speech. Notably, Koel-TTS directly maps text and context audio to acoustic tokens, and on the aforementioned metrics, outperforms state-of-the-art TTS models, despite being trained on a significantly smaller dataset. Audio samples and demos are available on our website.",
      "authors": [
        "Shehzeen Hussain",
        "Paarth Neekhara",
        "Xuesong Yang",
        "Edresson Casanova",
        "Subhankar Ghosh",
        "Mikyas T. Desta",
        "Roy Fejgin",
        "Rafael Valle",
        "Jason Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T06:47:11+00:00",
          "link": "https://arxiv.org/abs/2502.05236v1",
          "size": "2366kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T21:32:13+00:00",
          "link": "https://arxiv.org/abs/2502.05236v2",
          "size": "1553kb",
          "version": "v2"
        }
      ],
      "title": "Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05236",
        "HTML": "https://arxiv.org/html/2502.05236v2",
        "PDF": "https://arxiv.org/pdf/2502.05236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing speech generation models with preference alignment and classifier-free guidance, primarily addressing issues in TTS systems rather than LLM training data processing."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Decoder",
        "Speaker Verification",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06269",
      "abstract": "With the rise of generative paradigms, generative recommendation has garnered increasing attention. The core component is the item code, generally derived by quantizing collaborative or semantic representations to serve as candidate items identifiers in the context. However, existing methods typically construct separate codes for each modality, leading to higher computational and storage costs and hindering the integration of their complementary strengths. Considering this limitation, we seek to integrate two different modalities into a unified code, fully unleashing the potential of complementary nature among modalities. Nevertheless, the integration remains challenging: the integrated embedding obtained by the common concatenation method would lead to underutilization of collaborative knowledge, thereby resulting in limited effectiveness. To address this, we propose a novel method, named UNGER, which integrates semantic and collaborative knowledge into a unified code for generative recommendation. Specifically, we propose to adaptively learn an integrated embedding through the joint optimization of cross-modality knowledge alignment and next item prediction tasks. Subsequently, to mitigate the information loss caused by the quantization process, we introduce an intra-modality knowledge distillation task, using the integrated embeddings as supervised signals to compensate. Extensive experiments on three widely used benchmarks demonstrate the superiority of our approach compared to existing methods.",
      "authors": [
        "Longtao Xiao",
        "Haozhao Wang",
        "Cheng Wang",
        "Linfei Ji",
        "Yifan Wang",
        "Jieming Zhu",
        "Zhenhua Dong",
        "Rui Zhang",
        "Ruixuan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T09:08:37+00:00",
          "link": "https://arxiv.org/abs/2502.06269v1",
          "size": "2639kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:15:44+00:00",
          "link": "https://arxiv.org/abs/2502.06269v2",
          "size": "848kb",
          "version": "v2"
        }
      ],
      "title": "UNGER: Generative Recommendation with A Unified Code via Semantic and Collaborative Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06269",
        "HTML": "https://arxiv.org/html/2502.06269v2",
        "PDF": "https://arxiv.org/pdf/2502.06269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a recommendation system named UNGER that integrates semantic and collaborative knowledge, focusing on generative recommendation rather than any aspect of LLM training data processing."
      },
      "tasks": [
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08791",
      "abstract": "Vision-language navigation (VLN) has emerged as a promising paradigm, enabling mobile robots to perform zero-shot inference and execute tasks without specific pre-programming. However, current systems often separate map exploration and path planning, with exploration relying on inefficient algorithms due to limited (partially observed) environmental information. In this paper, we present a novel navigation pipeline named \"VL-Explore\" for simultaneous exploration and target discovery in unknown environments, leveraging the capabilities of a vision-language model named CLIP. Our approach requires only monocular vision and operates without any prior map or knowledge about the target. For comprehensive evaluations, we designed a functional prototype of a UGV (unmanned ground vehicle) system named \"Open Rover\", a customized platform for general-purpose VLN tasks. We integrated and deployed the VL-Explore pipeline on Open Rover to evaluate its throughput, obstacle avoidance capability, and trajectory performance across various real-world scenarios. Experimental results demonstrate that VL-Explore consistently outperforms traditional map-traversal algorithms and achieves performance comparable to path-planning methods that depend on prior map and target knowledge. Notably, VL-Explore offers real-time active navigation without requiring pre-captured candidate images or pre-built node graphs, addressing key limitations of existing VLN pipelines.",
      "authors": [
        "Yuxuan Zhang",
        "Adnan Abdullah",
        "Sanjeev J. Koppal",
        "and Md Jahidul Islam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T21:07:10+00:00",
          "link": "https://arxiv.org/abs/2502.08791v1",
          "size": "26048kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T21:17:17+00:00",
          "link": "https://arxiv.org/abs/2502.08791v2",
          "size": "28079kb",
          "version": "v2"
        }
      ],
      "title": "VL-Explore: Zero-shot Vision-Language Exploration and Target Discovery by Mobile Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08791",
        "HTML": "https://arxiv.org/html/2502.08791v2",
        "PDF": "https://arxiv.org/pdf/2502.08791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a vision-language navigation pipeline for mobile robots, focusing on navigation and exploration tasks using vision-language models, and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.11046",
      "abstract": "Transaction processing systems are the crux for modern data-center applications, yet current multi-node systems are slow due to network overheads. This paper advocates for Compute Express Link (CXL) as a network alternative, which enables low-latency and cache-coherent shared memory accesses. However, directly adopting standard CXL primitives leads to performance degradation due to the high cost of maintaining cross-node cache coherence. To address the CXL challenges, this paper introduces CtXnL, a software-hardware co-designed system that implements a novel hybrid coherence primitive tailored to the loosely coherent nature of transactional data. The core innovation of CtXnL is empowering transaction system developers with the ability to selectively achieve data coherence. Our evaluations on OLTP workloads demonstrate that CtXnL enhances performance, outperforming current network-based systems and achieves with up to 2.08x greater throughput than vanilla CXL memory sharing architectures across universal transaction processing policies.",
      "authors": [
        "Zhao Wang",
        "Yiqi Chen",
        "Cong Li",
        "Dimin Niu",
        "Tianchan Guan",
        "Zhaoyang Du",
        "Xingda Wei",
        "Guangyu Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-16T09:08:36+00:00",
          "link": "https://arxiv.org/abs/2502.11046v1",
          "size": "6810kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T01:42:19+00:00",
          "link": "https://arxiv.org/abs/2502.11046v2",
          "size": "4160kb",
          "version": "v2"
        }
      ],
      "title": "Enabling Efficient Transaction Processing on CXL-Based Memory Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11046",
        "HTML": "https://arxiv.org/html/2502.11046v2",
        "PDF": "https://arxiv.org/pdf/2502.11046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with transaction processing systems using CXL-based memory sharing, focusing on system performance rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12988",
      "abstract": "Previous approaches to persona simulation large language models (LLMs) have typically relied on learning basic biographical information, or using limited role-play dialogue datasets to capture a character's responses. However, a holistic representation of an individual goes beyond surface-level facts or conversations to deeper thoughts and thinking. In this work, we introduce CharacterBot, a model designed to replicate both the linguistic patterns and distinctive thought processes of a character. Using Lu Xun, a renowned Chinese writer, as a case study, we propose four training tasks derived from his 17 essay collections. These include a pre-training task focused on mastering external linguistic structures and knowledge, as well as three fine-tuning tasks: multiple-choice question answering, generative question answering, and style transfer, each aligning the LLM with Lu Xun's internal ideation and writing style. To optimize learning across these tasks, we introduce a CharLoRA parameter updating mechanism, where a general linguistic style expert collaborates with other task-specific experts to better study both the language style and the understanding of deeper thoughts. We evaluate CharacterBot on three tasks for linguistic accuracy and opinion comprehension, demonstrating that it significantly outperforms the baselines on our adapted metrics. We hope that this work inspires future research on deep character persona simulation LLM.",
      "authors": [
        "Zixiao Wang",
        "Duzhen Zhang",
        "Ishita Agrawal",
        "Shen Gao",
        "Le Song",
        "Xiuying Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T16:11:54+00:00",
          "link": "https://arxiv.org/abs/2502.12988v1",
          "size": "432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:00:49+00:00",
          "link": "https://arxiv.org/abs/2502.12988v2",
          "size": "299kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12988",
        "HTML": "https://arxiv.org/html/2502.12988v2",
        "PDF": "https://arxiv.org/pdf/2502.12988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on character persona simulation in LLMs by proposing new training tasks and a parameter updating mechanism. It briefly touches upon fine-tuning techniques but does not make a significant contribution to training data processing."
      },
      "tasks": [
        "Generative Question Answering",
        "Multiple-choice",
        "Question Answering",
        "Style Transfer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13294",
      "abstract": "The implementation of responsible AI in an organization is inherently complex due to the involvement of multiple stakeholders, each with their unique set of goals and responsibilities across the entire AI lifecycle. These responsibilities are often ambiguously defined and assigned, leading to confusion, miscommunication, and inefficiencies. Even when responsibilities are clearly defined and assigned to specific roles, the corresponding AI actors lack effective tools to support their execution.\n  Toward closing these gaps, we present a systematic review and comprehensive meta-analysis of the current state of responsible AI tools, focusing on their alignment with specific stakeholder roles and their responsibilities in various AI lifecycle stages. We categorize over 220 tools according to AI actors and stages they address. Our findings reveal significant imbalances across the stakeholder roles and lifecycle stages addressed. The vast majority of available tools have been created to support AI designers and developers specifically during data-centric and statistical modeling stages while neglecting other roles such as institutional leadership, deployers, end-users, and impacted communities, and stages such as value proposition and deployment. The uneven distribution we describe here highlights critical gaps that currently exist in responsible AI governance research and practice. Our analysis reveals that despite the myriad of frameworks and tools for responsible AI, it remains unclear \\emph{who} within an organization and \\emph{when} in the AI lifecycle a tool applies. Furthermore, existing tools are rarely validated, leaving critical gaps in their usability and effectiveness. These gaps provide a starting point for researchers and practitioners to create more effective and holistic approaches to responsible AI development and governance.",
      "authors": [
        "Blaine Kuehnert",
        "Rachel M. Kim",
        "Jodi Forlizzi",
        "Hoda Heidari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T21:31:31+00:00",
          "link": "https://arxiv.org/abs/2502.13294v1",
          "size": "1547kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:52:43+00:00",
          "link": "https://arxiv.org/abs/2502.13294v2",
          "size": "197kb",
          "version": "v2"
        }
      ],
      "title": "The \"Who\", \"What\", and \"How\" of Responsible AI Governance: A Systematic Review and Meta-Analysis of (Actor, Stage)-Specific Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13294",
        "HTML": "https://arxiv.org/html/2502.13294v2",
        "PDF": "https://arxiv.org/pdf/2502.13294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with responsible AI governance tools and their lifecycle, focusing on stakeholder roles rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15910",
      "abstract": "Generative models such as Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) trained on massive datasets can lead them to memorize and inadvertently reveal sensitive information, raising ethical and privacy concerns. While some prior works have explored this issue in the context of LLMs, it presents a unique challenge for MLLMs due to the entangled nature of knowledge across modalities, making comprehensive unlearning more difficult. To address this challenge, we propose Modality Aware Neuron Unlearning (MANU), a novel unlearning framework for MLLMs designed to selectively clip neurons based on their relative importance to the targeted forget data, curated for different modalities. Specifically, MANU consists of two stages: important neuron selection and selective pruning. The first stage identifies and collects the most influential neurons across modalities relative to the targeted forget knowledge, while the second stage is dedicated to pruning those selected neurons. MANU effectively isolates and removes the neurons that contribute most to the forget data within each modality, while preserving the integrity of retained knowledge. Our experiments conducted across various MLLM architectures illustrate that MANU can achieve a more balanced and comprehensive unlearning in each modality without largely affecting the overall model utility.",
      "authors": [
        "Zheyuan Liu",
        "Guangyao Dou",
        "Xiangchi Yuan",
        "Chunhui Zhang",
        "Zhaoxuan Tan",
        "Meng Jiang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T19:54:46+00:00",
          "link": "https://arxiv.org/abs/2502.15910v1",
          "size": "3258kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T06:29:03+00:00",
          "link": "https://arxiv.org/abs/2502.15910v2",
          "size": "3263kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T06:18:53+00:00",
          "link": "https://arxiv.org/abs/2502.15910v3",
          "size": "3263kb",
          "version": "v3"
        }
      ],
      "title": "Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15910",
        "HTML": "https://arxiv.org/html/2502.15910v3",
        "PDF": "https://arxiv.org/pdf/2502.15910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses unlearning in multimodal LLMs using a method for neuron pruning. It does not contribute to LLM training data processing operations like dataset creation or enhancement."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/franciscoliu/MANU"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17289",
      "abstract": "In this article, we propose a novel approach for plant hierarchical taxonomy classification by posing the problem as an open class problem. It is observed that existing methods for medicinal plant classification often fail to perform hierarchical classification and accurately identifying unknown species, limiting their effectiveness in comprehensive plant taxonomy classification. Thus we address the problem of unknown species classification by assigning it best hierarchical labels. We propose a novel method, which integrates DenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for hierarchical classification. The approach systematically categorizes medicinal plants at multiple taxonomic levels, from phylum to species, ensuring detailed and precise classification. Using multi scale space attention, the model captures both local and global contextual information from the images, improving the distinction between similar species and the identification of new ones. It uses attention scores to focus on important features across multiple scales. The proposed method provides a solution for hierarchical classification, showcasing superior performance in identifying both known and unknown species. The model was tested on two state-of-art datasets with and without background artifacts and so that it can be deployed to tackle real word application. We used unknown species for testing our model. For unknown species the model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for predicting correct phylum, class, order and family respectively. Our proposed model size is almost four times less than the existing state of the art methods making it easily deploy able in real world application.",
      "authors": [
        "Soumen Sinha",
        "Tanisha Rana",
        "Rahul Roy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T16:20:25+00:00",
          "link": "https://arxiv.org/abs/2502.17289v1",
          "size": "2954kb",
          "version": "v1"
        },
        {
          "date": "2025-05-04T14:50:45+00:00",
          "link": "https://arxiv.org/abs/2502.17289v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T21:32:15+00:00",
          "link": "https://arxiv.org/abs/2502.17289v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "A novel approach to navigate the taxonomic hierarchy to address the Open-World Scenarios in Medicinal Plant Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17289",
        "PDF": "https://arxiv.org/pdf/2502.17289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is related to medicinal plant classification using hierarchical taxonomy, which does not involve LLM training data processing."
      },
      "tasks": [
        "Classification",
        "Navigate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20650",
      "abstract": "In recent years, Diffusion Models (DMs) have demonstrated significant advances in the field of image generation. However, according to current research, DMs are vulnerable to backdoor attacks, which allow attackers to control the model's output by inputting data containing covert triggers, such as a specific visual patch or phrase. Existing defense strategies are well equipped to thwart such attacks through backdoor detection and trigger inversion because previous attack methods are constrained by limited input spaces and low-dimensional triggers. For example, visual triggers are easily observed by defenders, text-based or attention-based triggers are more susceptible to neural network detection. To explore more possibilities of backdoor attack in DMs, we propose Gungnir, a novel method that enables attackers to activate the backdoor in DMs through style triggers within input images. Our approach proposes using stylistic features as triggers for the first time and implements backdoor attacks successfully in image-to-image tasks by introducing Reconstructing-Adversarial Noise (RAN) and Short-Term Timesteps-Retention (STTR). Our technique generates trigger-embedded images that are perceptually indistinguishable from clean images, thus bypassing both manual inspection and automated detection neural networks. Experiments demonstrate that Gungnir can easily bypass existing defense methods. Among existing DM defense frameworks, our approach achieves a 0 backdoor detection rate (BDR). Our codes are available at https://github.com/paoche11/Gungnir.",
      "authors": [
        "Yu Pan",
        "Jiahao Chen",
        "Bingrong Dai",
        "Lin Wang",
        "Yi Du",
        "Jiao Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T02:08:26+00:00",
          "link": "https://arxiv.org/abs/2502.20650v1",
          "size": "1380kb",
          "version": "v1"
        },
        {
          "date": "2025-04-22T03:07:08+00:00",
          "link": "https://arxiv.org/abs/2502.20650v2",
          "size": "40276kb",
          "version": "v2"
        },
        {
          "date": "2025-06-09T03:23:33+00:00",
          "link": "https://arxiv.org/abs/2502.20650v3",
          "size": "40276kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T02:38:02+00:00",
          "link": "https://arxiv.org/abs/2502.20650v4",
          "size": "40274kb",
          "version": "v4"
        }
      ],
      "title": "Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20650",
        "HTML": "https://arxiv.org/html/2502.20650v4",
        "PDF": "https://arxiv.org/pdf/2502.20650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses backdoor attacks on diffusion models in image generation, unrelated to LLM training data processing."
      },
      "tasks": [
        "Backdoor Attack",
        "backdoor defense",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/paoche11/gungnir"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00227",
      "abstract": "This work introduces a unified framework for a more detailed exploration of games. In existing literature, strategies of players are typically assigned scalar values, and the concept of Nash equilibrium is used to identify compatible strategies. However, this approach lacks the internal structure of a player, thereby failing to accurately model observed behaviors.\n  To address this limitation, we propose an abstract definition of a player. This allows for a more nuanced understanding of players and brings the focus to the challenge of learning that players face. Unlike Markov decision processes, which formalize control problems but not agent design, our framework subsumes standard reinforcement learning structures. It thus offers a language that enables a deeper connection between games and learning. To illustrate the need for such generality, we study a simple two-player game and show that even in the most basic settings, a sophisticated player may adopt dynamic strategies that cannot be captured by simpler designs or compatibility analysis alone.\n  In the discrete setting, we consider a player whose structure incorporates standard estimates from the literature. We explore connections to correlated equilibrium and highlight that dynamic programming naturally applies to all estimates. In the mean-field setting, we exploit symmetry to construct explicit examples of equilibria. Finally, we examine connections to reinforcement learning and bandit problems, demonstrating the broad applicability of the framework.",
      "authors": [
        "Melih \\.I\\c{s}eri",
        "Erhan Bayraktar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Theoretical Economics (econ.TH)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T22:24:52+00:00",
          "link": "https://arxiv.org/abs/2503.00227v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T20:20:15+00:00",
          "link": "https://arxiv.org/abs/2503.00227v2",
          "size": "136kb",
          "version": "v2"
        }
      ],
      "title": "The Learning Approach to Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00227",
        "HTML": "https://arxiv.org/html/2503.00227v2",
        "PDF": "https://arxiv.org/pdf/2503.00227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on game theory and learning in games, exploring the abstract definition of players and connections to reinforcement learning, without any focus on LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/melihiseri/twoplayergame",
        "https://github.com/melihiseri/cartpole_toymodel"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01424",
      "abstract": "Research is a fundamental process driving the advancement of human civilization, yet it demands substantial time and effort from researchers. In recent years, the rapid development of artificial intelligence (AI) technologies has inspired researchers to explore how AI can accelerate and enhance research. To monitor relevant advancements, this paper presents a systematic review of the progress in this domain. Specifically, we organize the relevant studies into three main categories: hypothesis formulation, hypothesis validation, and manuscript publication. Hypothesis formulation involves knowledge synthesis and hypothesis generation. Hypothesis validation includes the verification of scientific claims, theorem proving, and experiment validation. Manuscript publication encompasses manuscript writing and the peer review process. Furthermore, we identify and discuss the current challenges faced in these areas, as well as potential future directions for research. Finally, we also offer a comprehensive overview of existing benchmarks and tools across various domains that support the integration of AI into the research process. We hope this paper serves as an introduction for beginners and fosters future research. Resources have been made publicly available at https://github.com/zkzhou126/AI-for-Research.",
      "authors": [
        "Zekun Zhou",
        "Xiaocheng Feng",
        "Lei Huang",
        "Xiachong Feng",
        "Ziyun Song",
        "Ruihan Chen",
        "Liang Zhao",
        "Weitao Ma",
        "Yuxuan Gu",
        "Baoxin Wang",
        "Dayong Wu",
        "Guoping Hu",
        "Ting Liu",
        "Bing Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T11:27:13+00:00",
          "link": "https://arxiv.org/abs/2503.01424v1",
          "size": "2506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:06:25+00:00",
          "link": "https://arxiv.org/abs/2503.01424v2",
          "size": "1286kb",
          "version": "v2"
        }
      ],
      "title": "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01424",
        "HTML": "https://arxiv.org/html/2503.01424v2",
        "PDF": "https://arxiv.org/pdf/2503.01424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews AI-driven research support systems across different stages of research but does not directly address or contribute to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.01627",
      "abstract": "The Model Constructing Satisfiability (MCSat) approach to the SMT problem extends the ideas of CDCL from the SAT level to the theory level. Like SAT, its search is driven by incrementally constructing a model by assigning concrete values to theory variables and performing theory-level reasoning to learn lemmas when conflicts arise. Therefore, the selection of values can significantly impact the search process and the solver's performance. In this work, we propose guiding the MCSat search by utilizing assignment values discovered through local search. First, we present a theory-agnostic framework to seamlessly integrate local search techniques within the MCSat framework. Then, we highlight how to use the framework to design a search procedure for (quantifier-free) Nonlinear Integer Arithmetic (NIA), utilizing accelerated hill-climbing and a new operation called feasible-sets jumping. We implement the proposed approach in the MCSat engine of the Yices2 solver, and empirically evaluate its performance over the N IA benchmarks of SMT-LIB.",
      "authors": [
        "Enrico Lipparini",
        "Thomas Hader",
        "Ahmed Irfan",
        "and St\\'ephane Graham-Lengrand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T15:02:49+00:00",
          "link": "https://arxiv.org/abs/2503.01627v1",
          "size": "1365kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T16:50:53+00:00",
          "link": "https://arxiv.org/abs/2503.01627v2",
          "size": "1525kb",
          "version": "v2"
        }
      ],
      "title": "Boosting MCSat Modulo Nonlinear Integer Arithmetic via Local Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01627",
        "HTML": "https://arxiv.org/html/2503.01627v2",
        "PDF": "https://arxiv.org/pdf/2503.01627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an enhancement to MCSat search for solving nonlinear integer arithmetic, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02382",
      "abstract": "Enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) is of great scientific and practical significance. Researchers typically employ process-supervised reward models (PRMs) to guide the reasoning process, effectively improving the models' reasoning abilities. However, existing methods for constructing process supervision training data, such as manual annotation and per-step Monte Carlo estimation, are often costly or suffer from poor quality. To address these challenges, this paper introduces a framework called EpicPRM, which annotates each intermediate reasoning step based on its quantified contribution and uses an adaptive binary search algorithm to enhance both annotation precision and efficiency. Using this approach, we efficiently construct a high-quality process supervision training dataset named Epic50k, consisting of 50k annotated intermediate steps. Compared to other publicly available datasets, the PRM trained on Epic50k demonstrates significantly superior performance. Getting Epic50k at https://github.com/xiaolizh1/EpicPRM.",
      "authors": [
        "Wei Sun",
        "Qianlong Du",
        "Fuwei Cui",
        "Jiajun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T08:18:46+00:00",
          "link": "https://arxiv.org/abs/2503.02382v1",
          "size": "421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:19:41+00:00",
          "link": "https://arxiv.org/abs/2503.02382v2",
          "size": "289kb",
          "version": "v2"
        }
      ],
      "title": "An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02382",
        "HTML": "https://arxiv.org/html/2503.02382v2",
        "PDF": "https://arxiv.org/pdf/2503.02382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces EpicPRM, a framework for efficiently constructing a high-quality process supervision training dataset named Epic50k. It specifically improves the data quality for training process-supervised reward models, making a significant contribution to LLM training data processing."
      },
      "tasks": [
        "Mathematical Reasoning"
      ],
      "repo_urls": [
        "https://github.com/xiaolizh1/epicprm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02832",
      "abstract": "In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.",
      "authors": [
        "Songming Zhang",
        "Xue Zhang",
        "Tong Zhang",
        "Bojie Hu",
        "Yufeng Chen",
        "Jinan Xu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T17:57:09+00:00",
          "link": "https://arxiv.org/abs/2503.02832v1",
          "size": "9147kb",
          "version": "v1"
        },
        {
          "date": "2025-06-19T13:29:42+00:00",
          "link": "https://arxiv.org/abs/2503.02832v2",
          "size": "1079kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T04:59:45+00:00",
          "link": "https://arxiv.org/abs/2503.02832v3",
          "size": "1080kb",
          "version": "v3"
        }
      ],
      "title": "AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02832",
        "HTML": "https://arxiv.org/html/2503.02832v3",
        "PDF": "https://arxiv.org/pdf/2503.02832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces AlignDistil, focusing on token-level alignment in LLMs, the primary contribution relates to improving model optimization and convergence rather than directly contributing to the processing of training data for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03460",
      "abstract": "Fine-tuning Large Language Models (LLMs) with first-order methods like back-propagation is computationally intensive. Zeroth-Order (ZO) optimisation uses function evaluations instead of gradients, reducing memory usage, but suffers from slow convergence in high-dimensional models. As a result, ZO research in LLMs has mostly focused on classification, overlooking more complex generative tasks. In this paper, we introduce ZOPrO, a novel ZO algorithm designed for Preference Optimisation in LLMs. We begin by analysing the interplay between policy and reward models during traditional (first-order) Preference Optimisation, uncovering patterns in their relative updates. Guided by these insights, we adapt Simultaneous Perturbation Stochastic Approximation (SPSA) with a targeted sampling strategy to accelerate convergence. Through experiments on summarisation, machine translation, and conversational assistants, we demonstrate that our method consistently enhances reward signals while achieving convergence times comparable to first-order methods. While it falls short of some state-of-the-art methods, our work is the first to apply Zeroth-Order methods to Preference Optimisation in LLMs, going beyond classification tasks and paving the way for a largely unexplored research direction. Code and visualisations are available at https://github.com/alessioGalatolo/VisZOPrO",
      "authors": [
        "Alessio Galatolo",
        "Zhenbang Dai",
        "Katie Winkle",
        "Meriem Beloucif"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T12:49:48+00:00",
          "link": "https://arxiv.org/abs/2503.03460v1",
          "size": "9951kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:18:26+00:00",
          "link": "https://arxiv.org/abs/2503.03460v2",
          "size": "9838kb",
          "version": "v2"
        }
      ],
      "title": "Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference Optimisation of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03460",
        "HTML": "https://arxiv.org/html/2503.03460v2",
        "PDF": "https://arxiv.org/pdf/2503.03460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a novel Zeroth-Order algorithm for preference optimization in LLMs, which may indirectly relate to data processing through its impact on model training outcomes, but it primarily focuses on optimization methods rather than data processing techniques."
      },
      "tasks": [
        "Machine Translation"
      ],
      "repo_urls": [
        "https://github.com/alessiogalatolo/viszopro"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04498",
      "abstract": "We study the equivalence of families of polycyclic codes associated with polynomials of the form $x^n - a_{n-1}x^{n-1} - \\ldots - a_1x - a_0$ over a finite field. We begin with the specific case of polycyclic codes associated with a trinomial $x^n - a_{\\ell} x^{\\ell} - a_0$ (for some $0< \\ell <n$), which we refer to as \\textit{$\\ell$-trinomial codes}, after which we generalize our results to general polycyclic codes. We introduce an equivalence relation called \\textit{$n$-equivalence}, which extends the known notion of $n$-equivalence for constacyclic codes \\cite{Chen2014}. We compute the number of $n$-equivalence classes %, $ N_{(n,\\ell)}$, for this relation and provide conditions under which two families of polycyclic (or $\\ell$-trinomial) codes are equivalent. In particular, we prove that when $\\gcd(n, n-\\ell) = 1$, any $\\ell$-trinomial code family is equivalent to a trinomial code family associated with the polynomial $x^n - x^{\\ell} - 1$. Finally, we focus on $p^{\\ell}$-trinomial codes of length $p^{\\ell+r}$, where $p$ is the characteristic of $\\mathbb{F}_q$ and $r$ an integer, and provide some examples as an application of the theory developed in this paper.",
      "authors": [
        "Hassan Ou-azzou",
        "Anna-Lena Horlemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T14:48:00+00:00",
          "link": "https://arxiv.org/abs/2503.04498v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:24:51+00:00",
          "link": "https://arxiv.org/abs/2503.04498v2",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "title": "Equivalence of Families of Polycyclic Codes over Finite Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04498",
        "HTML": "https://arxiv.org/html/2503.04498v2",
        "PDF": "https://arxiv.org/pdf/2503.04498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with the equivalence of polycyclic codes over finite fields, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05200",
      "abstract": "Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative to develop specialized foundational LLMs tailored for O-RAN. Built on 18 models spanning five open-source LLM frameworks -- Mistral, Qwen, Llama, Phi, and Gemma -- ORANSight-2.0 fine-tunes models ranging from 1B to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance in O-RAN-specific tasks. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG)-based instruction-tuning framework that employs two LLM agents -- a Mistral-based Question Generator and a Qwen-based Answer Generator -- to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack.",
      "authors": [
        "Pranshav Gajjar",
        "Vijay K. Shah"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T07:44:31+00:00",
          "link": "https://arxiv.org/abs/2503.05200v1",
          "size": "854kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T20:40:41+00:00",
          "link": "https://arxiv.org/abs/2503.05200v2",
          "size": "593kb",
          "version": "v2"
        }
      ],
      "title": "ORANSight-2.0: Foundational LLMs for O-RAN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05200",
        "PDF": "https://arxiv.org/pdf/2503.05200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces ORANSight-2.0, which creates high-quality instruction-tuning datasets for O-RAN, involving data processing through its data generation and fine-tuning approach, making a significant contribution to LLM training data processing."
      },
      "tasks": [
        "Code Generation",
        "Marketing",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06506",
      "abstract": "Text-to-image generative models have made significant advancements in recent years; however, accurately capturing intricate details in textual prompts-such as entity missing, attribute binding errors, and incorrect relationships remains a formidable challenge. In response, we present an innovative, training-free method that directly addresses these challenges by incorporating tailored objectives to account for textual constraints. Unlike layout-based approaches that enforce rigid structures and limit diversity, our proposed approach offers a more flexible arrangement of the scene by imposing just the extracted constraints from the text, without any unnecessary additions. These constraints are formulated as losses-entity missing, entity mixing, attribute binding, and spatial relationships-integrated into a unified loss that is applied in the first generation stage. Furthermore, we introduce a feedback-driven system for fine-grained initial noise refinement. This system integrates a verifier that evaluates the generated image, identifies inconsistencies, and provides corrective feedback. Leveraging this feedback, our refinement method first targets the unmet constraints by refining the faulty attention maps caused by initial noise, through the optimization of selective losses associated with these constraints. Subsequently, our unified loss function is reapplied to proceed the second generation phase. Experimental results demonstrate that our method, relying solely on our proposed objective functions, significantly enhances compositionality, achieving a 24% improvement in human evaluation and a 25% gain in spatial relationships. Furthermore, our fine-grained noise refinement proves effective, boosting performance by up to 5%. Code is available at \\href{https://github.com/hadi-hosseini/noise-refinement}{https://github.com/hadi-hosseini/noise-refinement}.",
      "authors": [
        "Amir Mohammad Izadi",
        "Seyed Mohammad Hadi Hosseini",
        "Soroush Vafaie Tabar",
        "Ali Abdollahi",
        "Armin Saghafian",
        "and Mahdieh Soleymani Baghshah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T08:18:43+00:00",
          "link": "https://arxiv.org/abs/2503.06506v1",
          "size": "12857kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T20:17:37+00:00",
          "link": "https://arxiv.org/abs/2503.06506v2",
          "size": "15178kb",
          "version": "v2"
        }
      ],
      "title": "Fine-Grained Alignment and Noise Refinement for Compositional Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06506",
        "HTML": "https://arxiv.org/html/2503.06506v2",
        "PDF": "https://arxiv.org/pdf/2503.06506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on text-to-image generation methods, specifically noise refinement and compositionality in image generation, and does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Attribute",
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "repo_urls": [
        "https://github.com/hadi-hosseini/noise-refinement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06882",
      "abstract": "Maximum Inner Product Search (MIPS) for high-dimensional vectors is pivotal across databases, information retrieval, and artificial intelligence. Existing methods either reduce MIPS to Nearest Neighbor Search (NNS) while suffering from harmful vector space transformations, or attempt to tackle MIPS directly but struggle to mitigate redundant computations due to the absence of the triangle inequality. This paper presents a novel theoretical framework that equates MIPS with NNS without requiring space transformation, thereby allowing us to leverage advanced graph-based indices for NNS and efficient edge pruning strategies, significantly reducing unnecessary computations. Despite a strong baseline set by our theoretical analysis, we identify and address two persistent challenges to further refine our method: the introduction of the Proximity Graph with Spherical Pathway (PSP), designed to mitigate the issue of MIPS solutions clustering around large-norm vectors, and the implementation of Adaptive Early Termination (AET), which efficiently curtails the excessive exploration once an accuracy bottleneck is reached. Extensive experiments reveal the superiority of our method over existing state-of-the-art techniques in search efficiency, scalability, and practical applicability. Compared with state-of-the-art graph based methods, it achieves an average 35% speed-up in query processing and a 3x reduction in index size. Notably, our approach has been validated and deployed in the search engines of Shopee, a well-known online shopping platform. Our code and an industrial-scale dataset for offline evaluation will also be released to address the absence of e-commerce data in public benchmarks.",
      "authors": [
        "Tingyang Chen",
        "Cong Fu",
        "Kun Wang",
        "Xiangyu Ke",
        "Yunjun Gao",
        "Wenchao Zhou",
        "Yabo Ni",
        "Anxiang Zeng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T03:17:13+00:00",
          "link": "https://arxiv.org/abs/2503.06882v1",
          "size": "3437kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:28:24+00:00",
          "link": "https://arxiv.org/abs/2503.06882v2",
          "size": "3636kb",
          "version": "v2"
        }
      ],
      "title": "Maximum Inner Product is Query-Scaled Nearest Neighbor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06882",
        "HTML": "https://arxiv.org/html/2503.06882v2",
        "PDF": "https://arxiv.org/pdf/2503.06882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on a new framework for Maximum Inner Product Search (MIPS) and its applications, not addressing any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06894",
      "abstract": "In Recent Years, Digital Technologies Have Made Significant Strides In Augmenting-Human-Health, Cognition, And Perception, Particularly Within The Field Of Computational-Pathology. This Paper Presents A Novel Approach To Enhancing The Analysis Of Histopathology Images By Leveraging A Mult-modal-Model That Combines Vision Transformers (Vit) With Gpt-2 For Image Captioning. The Model Is Fine-Tuned On The Specialized Arch-Dataset, Which Includes Dense Image Captions Derived From Clinical And Academic Resources, To Capture The Complexities Of Pathology Images Such As Tissue Morphologies, Staining Variations, And Pathological Conditions. By Generating Accurate, Contextually Captions, The Model Augments The Cognitive Capabilities Of Healthcare Professionals, Enabling More Efficient Disease Classification, Segmentation, And Detection. The Model Enhances The Perception Of Subtle Pathological Features In Images That Might Otherwise Go Unnoticed, Thereby Improving Diagnostic Accuracy. Our Approach Demonstrates The Potential For Digital Technologies To Augment Human Cognitive Abilities In Medical Image Analysis, Providing Steps Toward More Personalized And Accurate Healthcare Outcomes.",
      "authors": [
        "Xiaoqian Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T03:50:25+00:00",
          "link": "https://arxiv.org/abs/2503.06894v1",
          "size": "2725kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T08:18:22+00:00",
          "link": "https://arxiv.org/abs/2503.06894v2",
          "size": "5794kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T12:27:38+00:00",
          "link": "https://arxiv.org/abs/2503.06894v3",
          "size": "5711kb",
          "version": "v3"
        }
      ],
      "title": "A Deep Learning Approach for Augmenting Perceptional Understanding of Histopathology Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06894",
        "HTML": "https://arxiv.org/html/2503.06894v3",
        "PDF": "https://arxiv.org/pdf/2503.06894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses enhancing histopathology image analysis using a multi-modal model, concentrating on image captioning and not on training data processing for LLMs."
      },
      "tasks": [
        "Diagnostic",
        "Image Captioning",
        "Medical Image Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11937",
      "abstract": "Text-to-Image (T2I) Diffusion Models have achieved remarkable performance in generating high quality images. However, enabling precise control of continuous attributes, especially multiple attributes simultaneously, in a new domain (e.g., numeric values like eye openness or car width) with text-only guidance remains a significant challenge. To address this, we introduce the Attribute (Att) Adapter, a novel plug-and-play module designed to enable fine-grained, multi-attributes control in pretrained diffusion models. Our approach learns a single control adapter from a set of sample images that can be unpaired and contain multiple visual attributes. The Att-Adapter leverages the decoupled cross attention module to naturally harmonize the multiple domain attributes with text conditioning. We further introduce Conditional Variational Autoencoder (CVAE) to the Att-Adapter to mitigate overfitting, matching the diverse nature of the visual world. Evaluations on two public datasets show that Att-Adapter outperforms all LoRA-based baselines in controlling continuous attributes. Additionally, our method enables a broader control range and also improves disentanglement across multiple attributes, surpassing StyleGAN-based techniques. Notably, Att-Adapter is flexible, requiring no paired synthetic data for training, and is easily scalable to multiple attributes within a single model.",
      "authors": [
        "Wonwoong Cho",
        "Yan-Ying Chen",
        "Matthew Klenk",
        "David I. Inouye",
        "Yanxia Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T01:06:34+00:00",
          "link": "https://arxiv.org/abs/2503.11937v1",
          "size": "15532kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T13:42:51+00:00",
          "link": "https://arxiv.org/abs/2503.11937v2",
          "size": "15532kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:56:25+00:00",
          "link": "https://arxiv.org/abs/2503.11937v3",
          "size": "16033kb",
          "version": "v3"
        }
      ],
      "title": "Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11937",
        "HTML": "https://arxiv.org/html/2503.11937v3",
        "PDF": "https://arxiv.org/pdf/2503.11937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for multi-attribute control in text-to-image diffusion models and does not pertain to LLM training data processing."
      },
      "models": [
        {
          "model_path": "WonwoongCho/Att-Adapter",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WonwoongCho/Att-Adapter"
        }
      ],
      "tasks": [
        "Attribute",
        "Disentanglement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12122",
      "abstract": "Recent advances in Large Language Models (LLMs) have permitted the development of language-guided multi-robot systems, which allow robots to execute tasks based on natural language instructions. However, achieving effective coordination in distributed multi-agent environments remains challenging due to (1) misalignment between instructions and task requirements and (2) inconsistency in robot behaviors when they independently interpret ambiguous instructions. To address these challenges, we propose Instruction-Conditioned Coordinator (ICCO), a Multi-Agent Reinforcement Learning (MARL) framework designed to enhance coordination in language-guided multi-robot systems. ICCO consists of a Coordinator agent and multiple Local Agents, where the Coordinator generates Task-Aligned and Consistent Instructions (TACI) by integrating language instructions with environmental states, ensuring task alignment and behavioral consistency. The Coordinator and Local Agents are jointly trained to optimize a reward function that balances task efficiency and instruction following. A Consistency Enhancement Term is added to the learning objective to maximize mutual information between instructions and robot behaviors, further improving coordination. Simulation and real-world experiments validate the effectiveness of ICCO in achieving language-guided task-aligned multi-robot control. The demonstration can be found at https://yanoyoshiki.github.io/ICCO/.",
      "authors": [
        "Yoshiki Yano",
        "Kazuki Shibata",
        "Maarten Kokshoorn and Takamitsu Matsubara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T13:03:20+00:00",
          "link": "https://arxiv.org/abs/2503.12122v1",
          "size": "3133kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T04:56:04+00:00",
          "link": "https://arxiv.org/abs/2503.12122v2",
          "size": "3199kb",
          "version": "v2"
        }
      ],
      "title": "ICCO: Learning an Instruction-conditioned Coordinator for Language-guided Task-aligned Multi-robot Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12122",
        "HTML": "https://arxiv.org/html/2503.12122v2",
        "PDF": "https://arxiv.org/pdf/2503.12122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multi-agent reinforcement learning framework for enhancing coordination in language-guided multi-robot systems. It does not address LLM training data processing."
      },
      "tasks": [
        "Instruction Following",
        "Multi-agent Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12192",
      "abstract": "Software supply chain frameworks, such as the US NIST Secure Software Development Framework (SSDF), detail what tasks software development organizations are recommended or mandated to adopt to reduce security risk. However, to further reduce the risk of similar attacks occurring, software organizations benefit from knowing what tasks mitigate attack techniques the attackers are currently using to address specific threats, prioritize tasks, and close mitigation gaps. The goal of this study is to aid software organizations in reducing the risk of software supply chain attacks by systematically synthesizing how framework tasks mitigate the attack techniques used in the SolarWinds, Log4j, and XZ Utils attacks. We qualitatively analyzed 106 Cyber Threat Intelligence (CTI) reports of the 3 attacks to gather the attack techniques. We then systematically constructed a mapping between attack techniques and the 73 tasks enumerated in 10 software supply chain frameworks. Afterward, we established and ranked priority tasks that mitigate attack techniques. The three mitigation tasks with the highest scores are role-based access control, system monitoring, and boundary protection. Additionally, three mitigation tasks were missing from all ten frameworks, including sustainable open-source software and environmental scanning tools. Thus, software products would still be vulnerable to software supply chain attacks even if organizations adopted all recommended tasks.",
      "authors": [
        "Sivana Hamer",
        "Jacob Bowen",
        "Md Nazmul Haque",
        "Robert Hines",
        "Chris Madden",
        "Laurie Williams"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T16:22:09+00:00",
          "link": "https://arxiv.org/abs/2503.12192v1",
          "size": "1220kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T16:13:13+00:00",
          "link": "https://arxiv.org/abs/2503.12192v2",
          "size": "1785kb",
          "version": "v2"
        }
      ],
      "title": "Closing the Chain: How to reduce your risk of being SolarWinds, Log4j, or XZ Utils",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12192",
        "HTML": "https://arxiv.org/html/2503.12192v2",
        "PDF": "https://arxiv.org/pdf/2503.12192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses software supply chain security and risk mitigation strategies, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.13844",
      "abstract": "Political advertising plays a pivotal role in shaping public opinion and influencing electoral outcomes, often through subtle persuasive techniques embedded in broader propaganda strategies. Detecting these persuasive elements is crucial for enhancing voter awareness and ensuring transparency in democratic processes. This paper presents an integrated approach that bridges model development and real-world application through two interconnected studies. First, we introduce a lightweight model for persuasive text detection that achieves state-of-the-art performance in Subtask 3 of SemEval 2023 Task 3 while requiring significantly fewer computational resources and training data than existing methods. Second, we demonstrate the model's practical utility by collecting the Australian Federal Election 2022 Facebook Ads (APA22) dataset, partially annotating a subset for persuasion, and fine-tuning the model to adapt from mainstream news to social media content. We then apply the fine-tuned model to label the remainder of the APA22 dataset, revealing distinct patterns in how political campaigns leverage persuasion through different funding strategies, word choices, demographic targeting, and temporal shifts in persuasion intensity as election day approaches. Our findings not only underscore the necessity of domain-specific modeling for analyzing persuasion on social media but also show how uncovering these strategies can enhance transparency, inform voters, and promote accountability in digital campaigns.",
      "authors": [
        "Elyas Meguellati",
        "Stefano Civelli",
        "Pietro Bernardelle",
        "Shazia Sadiq",
        "Irwin King",
        "Gianluca Demartini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T02:33:38+00:00",
          "link": "https://arxiv.org/abs/2503.13844v1",
          "size": "10419kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:38:14+00:00",
          "link": "https://arxiv.org/abs/2503.13844v2",
          "size": "915kb",
          "version": "v2"
        }
      ],
      "title": "Towards Detecting Persuasion on Social Media: From Model Development to Insights on Persuasion Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13844",
        "HTML": "https://arxiv.org/html/2503.13844v2",
        "PDF": "https://arxiv.org/pdf/2503.13844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus is on persuasion detection model development, there is mention of creating a dataset (APA22) and annotating it for persuasion analysis, which is somewhat related to training data processing."
      },
      "tasks": [
        "Text Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15986",
      "abstract": "Spiking Neural Networks (SNNs) based on Transformers have garnered significant attention due to their superior performance and high energy efficiency. However, the spiking attention modules of most existing Transformer-based SNNs are adapted from those of analog Transformers, failing to fully address the issue of over-allocating attention to irrelevant contexts. To fix this fundamental yet overlooked issue, we propose a Lateral Inhibition-inspired Spiking Transformer (SpiLiFormer). It emulates the brain's lateral inhibition mechanism, guiding the model to enhance attention to relevant tokens while suppressing attention to irrelevant ones. Our model achieves state-of-the-art (SOTA) performance across multiple datasets, including CIFAR-10 (+0.45%), CIFAR-100 (+0.48%), CIFAR10-DVS (+2.70%), N-Caltech101 (+1.94%), and ImageNet-1K (+1.6%). Notably, on the ImageNet-1K dataset, SpiLiFormer (69.9M parameters, 4 time steps, 384 resolution) outperforms E-SpikeFormer (173.0M parameters, 8 time steps, 384 resolution), a SOTA spiking Transformer, by 0.46% using only 39% of the parameters and half the time steps. The code and model checkpoints are publicly available at https://github.com/KirinZheng/SpiLiFormer.",
      "authors": [
        "Zeqi Zheng",
        "Yanchen Huang",
        "Yingchao Yu",
        "Zizheng Zhu",
        "Junfeng Tang",
        "Zhaofei Yu",
        "Yaochu Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T09:36:31+00:00",
          "link": "https://arxiv.org/abs/2503.15986v1",
          "size": "1597kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:42:32+00:00",
          "link": "https://arxiv.org/abs/2503.15986v2",
          "size": "2010kb",
          "version": "v2"
        }
      ],
      "title": "SpiLiFormer: Enhancing Spiking Transformers with Lateral Inhibition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15986",
        "HTML": "https://arxiv.org/html/2503.15986v2",
        "PDF": "https://arxiv.org/pdf/2503.15986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper improves Spiking Transformers using lateral inhibition but does not contribute to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.17032",
      "abstract": "Realistic 3D full-body talking avatars hold great potential in AR, with applications ranging from e-commerce live streaming to holographic communication. Despite advances in 3D Gaussian Splatting (3DGS) for lifelike avatar creation, existing methods struggle with fine-grained control of facial expressions and body movements in full-body talking tasks. Additionally, they often lack sufficient details and cannot run in real-time on mobile devices. We present TaoAvatar, a high-fidelity, lightweight, 3DGS-based full-body talking avatar driven by various signals. Our approach starts by creating a personalized clothed human parametric template that binds Gaussians to represent appearances. We then pre-train a StyleUnet-based network to handle complex pose-dependent non-rigid deformation, which can capture high-frequency appearance details but is too resource-intensive for mobile devices. To overcome this, we \"bake\" the non-rigid deformations into a lightweight MLP-based network using a distillation technique and develop blend shapes to compensate for details. Extensive experiments show that TaoAvatar achieves state-of-the-art rendering quality while running in real-time across various devices, maintaining 90 FPS on high-definition stereo devices such as the Apple Vision Pro.",
      "authors": [
        "Jianchuan Chen",
        "Jingchuan Hu",
        "Gaige Wang",
        "Zhonghua Jiang",
        "Tiansong Zhou",
        "Zhiwen Chen",
        "Chengfei Lv"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T10:40:37+00:00",
          "link": "https://arxiv.org/abs/2503.17032v1",
          "size": "12762kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T11:42:41+00:00",
          "link": "https://arxiv.org/abs/2503.17032v2",
          "size": "55020kb",
          "version": "v2"
        }
      ],
      "title": "TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17032",
        "HTML": "https://arxiv.org/html/2503.17032v2",
        "PDF": "https://arxiv.org/pdf/2503.17032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating lifelike 3D full-body talking avatars for augmented reality, emphasizing techniques for rendering and real-time performance. It does not contribute to LLM training data processing."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Chen_TaoAvatar_Real-Time_Lifelike_Full-Body_Talking_Avatars_for_Augmented_Reality_via_CVPR_2025_paper.html",
      "tasks": [
        "3DGS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17141",
      "abstract": "Speech Enhancement techniques have become core technologies in mobile devices and voice software. Still, modern deep learning solutions often require high amount of computational resources what makes their usage on low-resource devices challenging. We present HiFi-Stream, an optimized version of recently published HiFi++ model. Our experiments demonstrate that HiFi-Stream saves most of the qualities of the original model despite its size and computational complexity improved in comparison to the original HiFi++ making it one of the smallest and fastest models available. The model is evaluated in streaming setting where it demonstrates its superior performance in comparison to modern baselines.",
      "authors": [
        "Ekaterina Dmitrieva and Maksim Kaledin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T13:44:12+00:00",
          "link": "https://arxiv.org/abs/2503.17141v1",
          "size": "467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:11:04+00:00",
          "link": "https://arxiv.org/abs/2503.17141v2",
          "size": "343kb",
          "version": "v2"
        }
      ],
      "title": "HiFi-Stream: Streaming Speech Enhancement with Generative Adversarial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17141",
        "HTML": "https://arxiv.org/html/2503.17141v2",
        "PDF": "https://arxiv.org/pdf/2503.17141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses speech enhancement using a generative adversarial network, aiming to optimize computational efficiency. It does not address training data processing for language models."
      },
      "tasks": [
        "Speech Enhancement"
      ],
      "repo_urls": [
        "https://github.com/KVDmitrieva/source_sep_hifi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17352",
      "abstract": "We introduce OpenVLThinker, one of the first open-source large vision-language models (LVLMs) to exhibit sophisticated chain-of-thought reasoning, achieving notable performance gains on challenging visual reasoning tasks. While text-based reasoning models (e.g., Deepseek R1) show promising results in text-only tasks, distilling their reasoning into LVLMs via supervised fine-tuning (SFT) often results in performance degradation due to imprecise visual grounding. Conversely, purely reinforcement learning (RL)-based methods face a large search space, hindering the emergence of reflective behaviors in smaller models (e.g., 7B LVLMs). Surprisingly, alternating between SFT and RL ultimately results in significant performance improvements after a few iterations. Our analysis reveals that the base model rarely exhibits reasoning behaviors initially, but SFT effectively surfaces these latent actions and narrows the RL search space, accelerating the development of reasoning capabilities. Each subsequent RL stage further refines the model's reasoning skills, producing higher-quality SFT data for continued self-improvement. OpenVLThinker-7B consistently advances performance across six benchmarks demanding mathematical and general reasoning, notably improving MathVista by 3.8%, EMMA by 2.4%, and HallusionBench by 1.6%. Beyond demonstrating the synergy between SFT and RL for complex reasoning tasks, our findings provide early evidence towards achieving R1-style reasoning in multimodal contexts. The code, model and data are held at https://github.com/yihedeng9/OpenVLThinker.",
      "authors": [
        "Yihe Deng",
        "Hritik Bansal",
        "Fan Yin",
        "Nanyun Peng",
        "Wei Wang",
        "Kai-Wei Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T17:52:43+00:00",
          "link": "https://arxiv.org/abs/2503.17352v1",
          "size": "1586kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T21:04:21+00:00",
          "link": "https://arxiv.org/abs/2503.17352v2",
          "size": "2403kb",
          "version": "v2"
        }
      ],
      "title": "OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL Cycles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17352",
        "HTML": "https://arxiv.org/html/2503.17352v2",
        "PDF": "https://arxiv.org/pdf/2503.17352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a vision-language model that incorporates supervised fine-tuning (SFT) and reinforcement learning (RL) cycles for reasoning tasks. While SFT is involved, the main focus is on model performance improvements, not data processing."
      },
      "models": [
        {
          "model_path": "ydeng9/OpenVLThinker-7B-v1.2",
          "downloads": "41",
          "likes": "2",
          "trending_score": "1.0",
          "link": "https://huggingface.co/ydeng9/OpenVLThinker-7B-v1.2"
        },
        {
          "model_path": "ydeng9/OpenVLThinker-7B",
          "downloads": "1173",
          "likes": "17",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ydeng9/OpenVLThinker-7B"
        }
      ],
      "tasks": [
        "Multimodal Reasoning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/yihedeng9/openvlthinker"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22913",
      "abstract": "Recent shifts in the space of large language model (LLM) research have shown an increasing focus on novel architectures to compete with prototypical Transformer-based models that have long dominated this space. Linear recurrent models have proven to be a viable competitor due to their computational efficiency. However, such models still demonstrate a sizable gap compared to Transformers in terms of in-context learning among other tasks that require recalling information from a context. In this work, we introduce Resona, a simple and scalable framework for augmenting linear recurrent models with retrieval. Resona augments models with the ability to integrate retrieved information from the provided input context, enabling tailored behavior to diverse task requirements. Experiments on a variety of linear recurrent models demonstrate that Resona-augmented models observe significant performance gains on a variety of synthetic as well as real-world natural language tasks, highlighting its ability to act as a general purpose method to improve the in-context learning and language modeling abilities of linear recurrent LLMs.",
      "authors": [
        "Xinyu Wang",
        "Linrui Ma",
        "Jerry Huang",
        "Peng Lu",
        "Prasanna Parthasarathi",
        "Xiao-Wen Chang",
        "Boxing Chen",
        "Yufei Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T23:43:33+00:00",
          "link": "https://arxiv.org/abs/2503.22913v1",
          "size": "412kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:54:34+00:00",
          "link": "https://arxiv.org/abs/2503.22913v2",
          "size": "381kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T02:06:03+00:00",
          "link": "https://arxiv.org/abs/2503.22913v3",
          "size": "263kb",
          "version": "v3"
        }
      ],
      "title": "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22913",
        "HTML": "https://arxiv.org/html/2503.22913v3",
        "PDF": "https://arxiv.org/pdf/2503.22913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The research outlines enhancements to linear recurrent models through retrieval for context integration. It discusses language modeling but does not emphasize training data processing techniques or dataset creation."
      },
      "tasks": [
        "Computational Efficiency",
        "In-Context Learning",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23956",
      "abstract": "Recent advancements in Large Visual Language Models (LVLMs) have gained significant attention due to their remarkable reasoning capabilities and proficiency in generalization. However, processing a large number of visual tokens and generating long-context outputs impose substantial computational overhead, leading to excessive demands for key-value (KV) cache. To address this critical bottleneck, we propose AirCache, a novel KV cache compression method aimed at accelerating LVLMs inference. This work systematically investigates the correlations between visual and textual tokens within the attention mechanisms of LVLMs. Our empirical analysis reveals considerable redundancy in cached visual tokens, wherein strategically eliminating these tokens preserves model performance while significantly accelerating context generation. Inspired by these findings, we introduce an elite observation window for assessing the importance of visual components in the KV cache, focusing on stable inter-modal relevancy modeling with enhanced multi-perspective consistency. Additionally, we develop an adaptive layer-wise budget allocation strategy that capitalizes on the strength and skewness of token importance distribution, showcasing superior efficiency compared to uniform allocation. Comprehensive evaluations across multiple LVLMs and benchmarks demonstrate that our method achieves comparable performance to the full cache while retaining only 10% of visual KV cache, thereby reducing decoding latency by 29% to 66% across various batch size and prompt length of inputs. Notably, as cache retention rates decrease, our method exhibits increasing performance advantages over existing approaches.",
      "authors": [
        "Kai Huang",
        "Hao Zou",
        "Bochen Wang",
        "Ye Xi",
        "Zhen Xie",
        "Hao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T11:13:18+00:00",
          "link": "https://arxiv.org/abs/2503.23956v1",
          "size": "10958kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T01:30:43+00:00",
          "link": "https://arxiv.org/abs/2503.23956v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T11:42:03+00:00",
          "link": "https://arxiv.org/abs/2503.23956v3",
          "size": "3140kb",
          "version": "v3"
        }
      ],
      "title": "AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23956",
        "HTML": "https://arxiv.org/html/2503.23956v3",
        "PDF": "https://arxiv.org/pdf/2503.23956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with KV cache compression to optimize the inference of large vision-language models, focusing on computational efficiency rather than training data processing for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.01677",
      "abstract": "There is an increasing need for effective control of systems with complex dynamics, particularly through data-driven approaches. System Level Synthesis (SLS) has emerged as a powerful framework that facilitates the control of large-scale systems while accounting for model uncertainties. SLS approaches are currently limited to linear systems and time-varying linear control policies, thus limiting the class of achievable control strategies. We introduce a novel closed-loop parameterization for time-varying affine control policies, extending the SLS framework to a broader class of systems and policies. We show that the closed-loop behavior under affine policies can be equivalently characterized using past system trajectories, enabling a fully data-driven formulation. This parameterization seamlessly integrates affine policies into optimal control problems, allowing for a closed-loop formulation of general Model Predictive Control (MPC) problems. To the best of our knowledge, this is the first work to extend SLS to affine policies in both model-based and data-driven settings, enabling an equivalent formulation of MPC problems using closed-loop maps. We validate our approach through numerical experiments, demonstrating that our model-based and data-driven affine SLS formulations achieve performance on par with traditional model-based MPC.",
      "authors": [
        "Lukas Sch\\\"uepp",
        "Giulia De Pasquale",
        "Florian D\\\"orfler",
        "Carmen Amo Alonso"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T12:26:20+00:00",
          "link": "https://arxiv.org/abs/2504.01677v1",
          "size": "105kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:35:54+00:00",
          "link": "https://arxiv.org/abs/2504.01677v2",
          "size": "105kb",
          "version": "v2"
        }
      ],
      "title": "System Level Synthesis for Affine Control Policies: Model Based and Data-Driven Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01677",
        "HTML": "https://arxiv.org/html/2504.01677v2",
        "PDF": "https://arxiv.org/pdf/2504.01677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on System Level Synthesis for control policies, particularly extending to affine control in data-driven settings. It does not address LLM training data processing."
      },
      "tasks": [
        "Model Predictive Control"
      ],
      "repo_urls": [
        "https://github.com/lukaschu/SLS-for-Affine-Policies"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02193",
      "abstract": "Aligning large language models (LLMs) with human values is an increasingly critical step in post-training. Direct Preference Optimization (DPO) has emerged as a simple, yet effective alternative to reinforcement learning from human feedback (RLHF). Synthetic preference data with its low cost and high quality enable effective alignment through single- or multi-model generated preference data. Our study reveals a striking, safety-specific phenomenon associated with DPO alignment: Although multi-model generated data enhances performance on general tasks (ARC, Hellaswag, MMLU, TruthfulQA, Winogrande) by providing diverse responses, it also tends to facilitate reward hacking during training. This can lead to a high attack success rate (ASR) when models encounter jailbreaking prompts. The issue is particularly pronounced when employing stronger models like GPT-4o or larger models in the same family to generate chosen responses paired with target model self-generated rejected responses, resulting in dramatically poorer safety outcomes. Furthermore, with respect to safety, using solely self-generated responses (single-model generation) for both chosen and rejected pairs significantly outperforms configurations that incorporate responses from stronger models, whether used directly as chosen data or as part of a multi-model response pool. We demonstrate that multi-model preference data exhibits high linear separability between chosen and rejected responses, which allows models to exploit superficial cues rather than internalizing robust safety constraints. Our experiments, conducted on models from the Llama, Mistral, and Qwen families, consistently validate these findings.",
      "authors": [
        "Yifan Wang",
        "Runjin Chen",
        "Bolian Li",
        "David Cho",
        "Yihe Deng",
        "Ruqi Zhang",
        "Tianlong Chen",
        "Zhangyang Wang",
        "Ananth Grama",
        "Junyuan Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T00:36:40+00:00",
          "link": "https://arxiv.org/abs/2504.02193v1",
          "size": "6314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T18:06:23+00:00",
          "link": "https://arxiv.org/abs/2504.02193v2",
          "size": "2974kb",
          "version": "v2"
        }
      ],
      "title": "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02193",
        "HTML": "https://arxiv.org/html/2504.02193v2",
        "PDF": "https://arxiv.org/pdf/2504.02193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses synthetic preference data for Direct Preference Optimization in LLM safety alignment. However, its primary focus is on alignment and safety rather than data processing techniques."
      },
      "tasks": [
        "ARC",
        "HellaSwag",
        "MMLU",
        "Safety Alignment",
        "TruthfulQA",
        "Winogrande"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03038",
      "abstract": "In this paper, we present a novel theoretical framework for online adaptation of Control Barrier Function (CBF) parameters, i.e., of the class K functions included in the CBF condition, under input constraints. We introduce the concept of locally validated CBF parameters, which are adapted online to guarantee finite-horizon safety, based on conditions derived from Nagumo's theorem and tangent cone analysis. To identify these parameters online, we integrate a learning-based approach with an uncertainty-aware verification process that account for both epistemic and aleatoric uncertainties inherent in neural network predictions. Our method is demonstrated on a VTOL quadplane model during challenging transition and landing maneuvers, showcasing enhanced performance while maintaining safety.",
      "authors": [
        "Taekyung Kim",
        "Randal W. Beard",
        "Dimitra Panagou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T21:32:32+00:00",
          "link": "https://arxiv.org/abs/2504.03038v1",
          "size": "1151kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T05:03:36+00:00",
          "link": "https://arxiv.org/abs/2504.03038v2",
          "size": "1150kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T16:02:07+00:00",
          "link": "https://arxiv.org/abs/2504.03038v3",
          "size": "1191kb",
          "version": "v3"
        }
      ],
      "title": "How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03038",
        "HTML": "https://arxiv.org/html/2504.03038v3",
        "PDF": "https://arxiv.org/pdf/2504.03038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a learning-based approach for adapting Control Barrier Functions, specifically for safety in control systems. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03173",
      "abstract": "Privacy-Preserving Federated Learning (PPFL) allows multiple clients to collaboratively train a deep learning model by submitting hidden model updates. Nonetheless, PPFL is vulnerable to data poisoning attacks due to the distributed training nature of clients. Existing solutions have struggled to improve the performance of cross-silo PPFL in poisoned Non-IID data. To address the issues, this paper proposes a privacy-preserving federated prototype learning framework, named PPFPL, which enhances the cross-silo FL performance in poisoned Non-IID data while effectively resisting data poisoning attacks. Specifically, we adopt prototypes as client-submitted model updates to eliminate the impact of tampered data distribution on federated learning. Moreover, we utilize two servers to achieve Byzantine-robust aggregation by secure aggregation protocol, which greatly reduces the impact of malicious clients. Theoretical analyses confirm the convergence of PPFPL, and experimental results on publicly available datasets show that PPFPL is effective for resisting data poisoning attacks with Non-IID conditions.",
      "authors": [
        "Hongliang Zhang",
        "Jiguo Yu",
        "Fenghua Xu",
        "Chunqiang Hu",
        "Yongzhao Zhang",
        "Xiaofen Wang",
        "Zhongyuan Yu",
        "Xiaosong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T05:05:24+00:00",
          "link": "https://arxiv.org/abs/2504.03173v1",
          "size": "1488kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T04:29:57+00:00",
          "link": "https://arxiv.org/abs/2504.03173v2",
          "size": "1425kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T07:02:51+00:00",
          "link": "https://arxiv.org/abs/2504.03173v3",
          "size": "456kb",
          "version": "v3"
        }
      ],
      "title": "PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03173",
        "HTML": "https://arxiv.org/html/2504.03173v3",
        "PDF": "https://arxiv.org/pdf/2504.03173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a privacy-preserving federated learning framework to combat data poisoning attacks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05018",
      "abstract": "Reinforcement learning (RL) holds significant promise for adaptive traffic signal control. While existing RL-based methods demonstrate effectiveness in reducing vehicular congestion, their predominant focus on vehicle-centric optimization leaves pedestrian mobility needs and safety challenges unaddressed. In this paper, we present a deep RL framework for adaptive control of eight traffic signals along a real-world urban corridor, jointly optimizing both pedestrian and vehicular efficiency. Our single-agent policy is trained using real-world pedestrian and vehicle demand data derived from Wi-Fi logs and video analysis. The results demonstrate significant performance improvements over traditional fixed-time signals, reducing average wait times per pedestrian and per vehicle by up to 67% and 52% respectively, while simultaneously decreasing total wait times for both groups by up to 67% and 53%. Additionally, our results demonstrate generalization capabilities across varying traffic demands, including conditions entirely unseen during training, validating RL's potential for developing transportation systems that serve all road users.",
      "authors": [
        "Bibek Poudel",
        "Xuan Wang",
        "Weizi Li",
        "Lei Zhu",
        "and Kevin Heaslip"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T12:41:58+00:00",
          "link": "https://arxiv.org/abs/2504.05018v1",
          "size": "6062kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T00:13:12+00:00",
          "link": "https://arxiv.org/abs/2504.05018v2",
          "size": "3592kb",
          "version": "v2"
        }
      ],
      "title": "Joint Pedestrian and Vehicle Traffic Optimization in Urban Environments using Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05018",
        "HTML": "https://arxiv.org/html/2504.05018v2",
        "PDF": "https://arxiv.org/pdf/2504.05018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses reinforcement learning for traffic optimization using real-world pedestrian and vehicle data. It does not involve LLM training data processing or operations related to language model datasets."
      },
      "tasks": [
        "Reinforcement Learning (RL)",
        "Traffic Signal Control"
      ],
      "repo_urls": [
        "https://github.com/poudel-bibek/Urban-Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05172",
      "abstract": "Fault diagnosis in multimode processes plays a critical role in ensuring the safe operation of industrial systems across multiple modes. It faces a great challenge yet to be addressed - that is, the significant distributional differences among monitoring data from multiple modes make it difficult for the models to extract shared feature representations related to system health conditions. In response to this problem, this paper introduces a novel method called attention-based multiscale temporal fusion network. The multiscale depthwise convolution and gated recurrent unit are employed to extract multiscale contextual local features and long-short-term features. Instance normalization is applied to suppress mode-specific information. Furthermore, a temporal attention mechanism is designed to focus on critical time points with higher cross-mode shared information, thereby enhancing the accuracy of fault diagnosis. The proposed model is applied to Tennessee Eastman process dataset and three-phase flow facility dataset. The experiments demonstrate that the proposed model achieves superior diagnostic performance and maintains a small model size. The source code will be available on GitHub at https://github.com/GuangqiangLi/AMTFNet.",
      "authors": [
        "Guangqiang Li",
        "M. Amine Atoui and Xiangshun Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T15:16:22+00:00",
          "link": "https://arxiv.org/abs/2504.05172v1",
          "size": "8426kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T08:47:52+00:00",
          "link": "https://arxiv.org/abs/2504.05172v2",
          "size": "8547kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T03:13:44+00:00",
          "link": "https://arxiv.org/abs/2504.05172v3",
          "size": "10272kb",
          "version": "v3"
        }
      ],
      "title": "Attention-Based Multiscale Temporal Fusion Network for Uncertain-Mode Fault Diagnosis in Multimode Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05172",
        "HTML": "https://arxiv.org/html/2504.05172v3",
        "PDF": "https://arxiv.org/pdf/2504.05172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on fault diagnosis in industrial systems through a novel attention-based multiscale network. It does not contribute to LLM training data processing or any operations related to language datasets."
      },
      "tasks": [
        "Diagnostic",
        "Fault Diagnosis"
      ],
      "repo_urls": [
        "https://github.com/guangqiangli/amtfnet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05815",
      "abstract": "Recently, the diffusion model has gained significant attention as one of the most successful image generation models, which can generate high-quality images by iteratively sampling noise. However, recent studies have shown that diffusion models are vulnerable to backdoor attacks, allowing attackers to enter input data containing triggers to activate the backdoor and generate their desired output. Existing backdoor attack methods primarily focused on target noise-to-image and text-to-image tasks, with limited work on backdoor attacks in image-to-image tasks. Furthermore, traditional backdoor attacks often rely on a single, conspicuous trigger to generate a fixed target image, lacking concealability and flexibility. To address these limitations, we propose a novel backdoor attack method called \"Parasite\" for image-to-image tasks in diffusion models, which not only is the first to leverage steganography for triggers hiding, but also allows attackers to embed the target content as a backdoor trigger to achieve a more flexible attack. \"Parasite\" as a novel attack method effectively bypasses existing detection frameworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved a 0 percent backdoor detection rate against the mainstream defense frameworks. In addition, in the ablation study, we discuss the influence of different hiding coefficients on the attack results. You can find our code at https://anonymous.4open.science/r/Parasite-1715/.",
      "authors": [
        "Jiahao Chen",
        "Yu Pan",
        "Yi Du",
        "Chunkai Wu",
        "Lin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T08:53:47+00:00",
          "link": "https://arxiv.org/abs/2504.05815v1",
          "size": "21692kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T02:43:00+00:00",
          "link": "https://arxiv.org/abs/2504.05815v2",
          "size": "21692kb",
          "version": "v2"
        }
      ],
      "title": "Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05815",
        "HTML": "https://arxiv.org/html/2504.05815v2",
        "PDF": "https://arxiv.org/pdf/2504.05815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a backdoor attack framework for diffusion models in the image domain, which is unrelated to data processing for large language models or LLM datasets."
      },
      "tasks": [
        "Backdoor Attack",
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.09751",
      "abstract": "Ray tracing (RT) simulation is a widely used approach to enable modeling wireless channels in applications such as network digital twins. However, the computational cost to execute ray tracing (RT) is proportional to factors such as the level of detail used in the adopted 3D scenario. This work proposes RT pre-processing algorithms that aim at simplifying the 3D scene without distorting the channel, by reducing the scenario area and/or simplifying object shapes in the scenario. It also proposes a post-processing method that augments a set of RT results to achieve an improved time resolution. These methods enable using RT in applications that use a detailed and photorealistic 3D scenario while generating consistent wireless channels over time. Our simulation results with different urban scenarios scales, in terms of area and object details, demonstrate that it is possible to reduce the simulation time by more than 50% without compromising the accuracy of the multipath RT parameters, such as angles of arrival and departure, delay, phase, and path gain.",
      "authors": [
        "Cl\\'audio Modesto",
        "Lucas Mozart",
        "Pedro Batista",
        "Andr\\'e Cavalcante and Aldebaro Klautau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-13T23:02:36+00:00",
          "link": "https://arxiv.org/abs/2504.09751v1",
          "size": "3507kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:44:30+00:00",
          "link": "https://arxiv.org/abs/2504.09751v2",
          "size": "3291kb",
          "version": "v2"
        }
      ],
      "title": "Accelerating Ray Tracing-Based Wireless Channels Generation for Real-Time Network Digital Twins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09751",
        "HTML": "https://arxiv.org/html/2504.09751v2",
        "PDF": "https://arxiv.org/pdf/2504.09751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses ray tracing simulations for wireless channels in digital twins, focusing on pre-processing and post-processing algorithms for 3D scenes. It does not discuss training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.10166",
      "abstract": "We propose CRAVE (Cluster-based Retrieval Augmented Verification with Explanation); a novel framework that integrates retrieval-augmented Large Language Models (LLMs) with clustering techniques to address fact-checking challenges on social media. CRAVE automatically retrieves multimodal evidence from diverse, often contradictory, sources. Evidence is clustered into coherent narratives, and evaluated via an LLM-based judge to deliver fact-checking verdicts explained by evidence summaries. By synthesizing evidence from both text and image modalities and incorporating agent-based refinement, CRAVE ensures consistency and diversity in evidence representation. Comprehensive experiments demonstrate CRAVE's efficacy in retrieval precision, clustering quality, and judgment accuracy, showcasing its potential as a robust decision-support tool for fact-checkers.",
      "authors": [
        "Arka Ujjal Dey",
        "Muhammad Junaid Awan",
        "Georgia Channing",
        "Christian Schroeder de Witt",
        "John Collomosse"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T12:21:27+00:00",
          "link": "https://arxiv.org/abs/2504.10166v1",
          "size": "28166kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T22:07:56+00:00",
          "link": "https://arxiv.org/abs/2504.10166v2",
          "size": "31586kb",
          "version": "v2"
        }
      ],
      "title": "Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented LLMs for Social Media Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10166",
        "HTML": "https://arxiv.org/html/2504.10166v2",
        "PDF": "https://arxiv.org/pdf/2504.10166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes CRAVE, which leverages LLMs for retrieving and processing data in social media fact-checking, its focus is primarily on fact-checking methodologies rather than LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.14861",
      "abstract": "Maximum Inner Product Search (MIPS) is a fundamental challenge in machine learning and information retrieval, particularly in high-dimensional data applications. Existing approaches to MIPS either rely solely on Inner Product (IP) similarity, which faces issues with local optima and redundant computations, or reduce the MIPS problem to the Nearest Neighbor Search under the Euclidean metric via space projection, leading to topology destruction and information loss. Despite the divergence of the two paradigms, we argue that there is no inherent binary opposition between IP and Euclidean metrics. By stitching IP and Euclidean in the design of indexing and search algorithms, we can significantly enhance MIPS performance. Specifically, this paper explores the theoretical and empirical connections between these two metrics from the MIPS perspective. Our investigation, grounded in graph-based search, reveals that different indexing and search strategies offer distinct advantages for MIPS, depending on the underlying data topology. Building on these insights, we introduce a novel graph-based index called Metric-Amphibious Graph (MAG) and a corresponding search algorithm, Adaptive Navigation with Metric Switch (ANMS). To facilitate parameter tuning for optimal performance, we identify three statistical indicators that capture essential data topology properties and correlate strongly with parameter tuning. Extensive experiments on 12 real-world datasets demonstrate that MAG outperforms existing state-of-the-art methods, achieving up to 4x search speedup while maintaining adaptability and scalability.",
      "authors": [
        "Tingyang Chen",
        "Cong Fu",
        "Xiangyu Ke",
        "Yunjun Gao",
        "Yabo Ni",
        "Anxiang Zeng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T05:01:58+00:00",
          "link": "https://arxiv.org/abs/2504.14861v1",
          "size": "2150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:37:06+00:00",
          "link": "https://arxiv.org/abs/2504.14861v2",
          "size": "2137kb",
          "version": "v2"
        }
      ],
      "title": "Stitching Inner Product and Euclidean Metrics for Topology-aware Maximum Inner Product Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14861",
        "HTML": "https://arxiv.org/html/2504.14861v2",
        "PDF": "https://arxiv.org/pdf/2504.14861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores maximum inner product search in high-dimensional data using a combined metric approach. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.15181",
      "abstract": "This report provides a detailed comparison between the Safety and Security measures proposed in the EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and the current commitments and practices voluntarily adopted by leading AI companies. As the EU moves toward enforcing binding obligations for GPAI model providers, the Code of Practice will be key for bridging legal requirements with concrete technical commitments. Our analysis focuses on the draft's Safety and Security section (Commitments II.1-II.16), documenting excerpts from current public-facing documents that are relevant to each individual measure.\n  We systematically reviewed different document types, such as companies' frontier safety frameworks and model cards, from over a dozen companies, including OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and others. This report is not meant to be an indication of legal compliance, nor does it take any prescriptive viewpoint about the Code of Practice or companies' policies. Instead, it aims to inform the ongoing dialogue between regulators and General-Purpose AI model providers by surfacing evidence of industry precedent for various measures. Nonetheless, we were able to find relevant quotes from at least 5 companies' documents for the majority of the measures in Commitments II.1-II.16.",
      "authors": [
        "Lily Stelling",
        "Mick Yang",
        "Rokas Gipi\\v{s}kis",
        "Leon Staufer",
        "Ze Shen Chin",
        "Sim\\'eon Campos",
        "Ariel Gil",
        "and Michael Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T15:44:01+00:00",
          "link": "https://arxiv.org/abs/2504.15181v1",
          "size": "2716kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T19:27:15+00:00",
          "link": "https://arxiv.org/abs/2504.15181v2",
          "size": "3999kb",
          "version": "v2"
        }
      ],
      "title": "Mapping Industry Practices to the EU AI Act's GPAI Code of Practice Safety and Security Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15181",
        "PDF": "https://arxiv.org/pdf/2504.15181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The report compares industry practices with the EU AI Act's safety measures, focusing on policy and legal aspects. It does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.18046",
      "abstract": "Ophthalmic diseases pose a significant global health challenge, yet traditional diagnosis methods and existing single-eye deep learning approaches often fail to account for binocular pathological correlations. To address this, we propose DMS-Net, a dual-modal multi-scale Siamese network for binocular fundus image classification. Our framework leverages weight-shared Siamese ResNet-152 backbones to extract deep semantic features from paired fundus images. To tackle challenges such as lesion boundary ambiguity and scattered pathological distributions, we introduce a Multi-Scale Context-Aware Module (MSCAM) that integrates adaptive pooling and attention mechanisms for multi-resolution feature aggregation. Additionally, a Dual-Modal Feature Fusion (DMFF) module enhances cross-modal interaction through spatial-semantic recalibration and bidirectional attention, effectively combining global context and local edge features. Evaluated on the ODIR-5K dataset, DMS-Net achieves state-of-the-art performance with 82.9% accuracy, 84.5% recall, and 83.2% Cohen's kappa, demonstrating superior capability in detecting symmetric pathologies and advancing clinical decision-making for ocular diseases.",
      "authors": [
        "Guohao Huo",
        "Zibo Lin",
        "Zitong Wang",
        "Ruiting Dai",
        "Hao Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T03:27:28+00:00",
          "link": "https://arxiv.org/abs/2504.18046v1",
          "size": "5630kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:21:52+00:00",
          "link": "https://arxiv.org/abs/2504.18046v2",
          "size": "6859kb",
          "version": "v2"
        }
      ],
      "title": "DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18046",
        "HTML": "https://arxiv.org/html/2504.18046v2",
        "PDF": "https://arxiv.org/pdf/2504.18046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a dual-modal multi-scale Siamese network for binocular fundus image classification. It is centered around medical imaging and deep learning architectures, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19991",
      "abstract": "Effective weed management is crucial for improving agricultural productivity, as weeds compete with crops for vital resources like nutrients and water. Accurate maps of weed management methods are essential for policymakers to assess farmer practices, evaluate impacts on vegetation health, biodiversity, and climate, as well as ensure compliance with policies and subsidies. However, monitoring weed management methods is challenging as they commonly rely on ground-based field surveys, which are often costly, time-consuming and subject to delays. In order to tackle this problem, we leverage earth observation data and Machine Learning (ML). Specifically, we developed separate ML models using Sentinel-2 and PlanetScope satellite time series data, respectively, to classify four distinct weed management methods (Mowing, Tillage, Chemical-spraying, and No practice) in orchards. The findings demonstrate the potential of ML-driven remote sensing to enhance the efficiency and accuracy of weed management mapping in orchards.",
      "authors": [
        "Ioannis Kontogiorgakis",
        "Iason Tsardanidis",
        "Dimitrios Bormpoudakis",
        "Ilias Tsoumas",
        "Dimitra A. Loka",
        "Christos Noulas",
        "Alexandros Tsitouras and Charalampos Kontoes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T17:09:10+00:00",
          "link": "https://arxiv.org/abs/2504.19991v1",
          "size": "4572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T12:31:13+00:00",
          "link": "https://arxiv.org/abs/2504.19991v2",
          "size": "3887kb",
          "version": "v2"
        }
      ],
      "title": "Mapping of Weed Management Methods in Orchards using Sentinel-2 and PlanetScope Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19991",
        "HTML": "https://arxiv.org/html/2504.19991v2",
        "PDF": "https://arxiv.org/pdf/2504.19991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with machine learning models for mapping weed management using satellite data, showing no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19996",
      "abstract": "The widespread use of Exogenous Organic Matter in agriculture necessitates monitoring to assess its effects on soil and crop health. This study evaluates optical Sentinel-2 satellite imagery for detecting digestate application, a practice that enhances soil fertility but poses environmental risks like microplastic contamination and nitrogen losses. In the first instance, Sentinel-2 satellite image time series (SITS) analysis of specific indices (EOMI, NDVI, EVI) was used to characterize EOM's spectral behavior after application on the soils of four different crop types in Thessaly, Greece. Furthermore, Machine Learning (ML) models (namely Random Forest, k-NN, Gradient Boosting and a Feed-Forward Neural Network), were used to investigate digestate presence detection, achieving F1-scores up to 0.85. The findings highlight the potential of combining remote sensing and ML for scalable and cost-effective monitoring of EOM applications, supporting precision agriculture and sustainability.",
      "authors": [
        "Andreas Kalogeras",
        "Dimitrios Bormpoudakis",
        "Iason Tsardanidis",
        "Dimitra A. Loka and Charalampos Kontoes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T17:16:40+00:00",
          "link": "https://arxiv.org/abs/2504.19996v1",
          "size": "1124kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:50:45+00:00",
          "link": "https://arxiv.org/abs/2504.19996v2",
          "size": "1138kb",
          "version": "v2"
        }
      ],
      "title": "Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19996",
        "HTML": "https://arxiv.org/html/2504.19996v2",
        "PDF": "https://arxiv.org/pdf/2504.19996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates the use of satellite imagery and machine learning to monitor digestate application in agriculture. It's not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.01709",
      "abstract": "Operating robots in open-ended scenarios with diverse tasks is a crucial research and application direction in robotics. While recent progress in natural language processing and large multimodal models has enhanced robots' ability to understand complex instructions, robot manipulation still faces the procedural skill dilemma and the declarative skill dilemma in open environments. Existing methods often compromise cognitive and executive capabilities. To address these challenges, in this paper, we propose RoBridge, a hierarchical intelligent architecture for general robotic manipulation. It consists of a high-level cognitive planner (HCP) based on a large-scale pre-trained vision-language model (VLM), an invariant operable representation (IOR) serving as a symbolic bridge, and a generalist embodied agent (GEA). RoBridge maintains the declarative skill of VLM and unleashes the procedural skill of reinforcement learning, effectively bridging the gap between cognition and execution. RoBridge demonstrates significant performance improvements over existing baselines, achieving a 75% success rate on new tasks and an 83% average success rate in sim-to-real generalization using only five real-world data samples per task. This work represents a significant step towards integrating cognitive reasoning with physical execution in robotic systems, offering a new paradigm for general robotic manipulation.",
      "authors": [
        "Kaidong Zhang",
        "Rongtao Xu",
        "Pengzhen Ren",
        "Junfan Lin",
        "Hefeng Wu",
        "Liang Lin",
        "Xiaodan Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-03T06:17:18+00:00",
          "link": "https://arxiv.org/abs/2505.01709v1",
          "size": "5345kb",
          "version": "v1"
        },
        {
          "date": "2025-05-07T08:37:17+00:00",
          "link": "https://arxiv.org/abs/2505.01709v2",
          "size": "5348kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T07:22:26+00:00",
          "link": "https://arxiv.org/abs/2505.01709v3",
          "size": "5710kb",
          "version": "v3"
        }
      ],
      "title": "RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01709",
        "HTML": "https://arxiv.org/html/2505.01709v3",
        "PDF": "https://arxiv.org/pdf/2505.01709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a hierarchical architecture for robotic manipulation and does not pertain to LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Robot Manipulation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02586",
      "abstract": "This work introduces RGBX-DiffusionDet, an object detection framework extending the DiffusionDet model to fuse the heterogeneous 2D data (X) with RGB imagery via an adaptive multimodal encoder. To enable cross-modal interaction, we design the dynamic channel reduction within a convolutional block attention module (DCR-CBAM), which facilitates cross-talk between subnetworks by dynamically highlighting salient channel features. Furthermore, the dynamic multi-level aggregation block (DMLAB) is proposed to refine spatial feature representations through adaptive multiscale fusion. Finally, novel regularization losses that enforce channel saliency and spatial selectivity are introduced, leading to compact and discriminative feature embeddings. Extensive experiments using RGB-Depth (KITTI), a novel annotated RGB-Polarimetric dataset, and RGB-Infrared (M$^3$FD) benchmark dataset were conducted. We demonstrate consistent superiority of the proposed approach over the baseline RGB-only DiffusionDet. The modular architecture maintains the original decoding complexity, ensuring efficiency. These results establish the proposed RGBX-DiffusionDet as a flexible multimodal object detection approach, providing new insights into integrating diverse 2D sensing modalities into diffusion-based detection pipelines.",
      "authors": [
        "Eliraz Orfaig",
        "Inna Stainvas",
        "Igal Bilik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T11:39:51+00:00",
          "link": "https://arxiv.org/abs/2505.02586v1",
          "size": "39913kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T08:03:05+00:00",
          "link": "https://arxiv.org/abs/2505.02586v2",
          "size": "39914kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T13:55:47+00:00",
          "link": "https://arxiv.org/abs/2505.02586v3",
          "size": "39914kb",
          "version": "v3"
        }
      ],
      "title": "RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02586",
        "HTML": "https://arxiv.org/html/2505.02586v3",
        "PDF": "https://arxiv.org/pdf/2505.02586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on an object detection framework using multimodal data, with no contribution to LLM training data processing or data engineering operations specific to language models."
      },
      "tasks": [
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04457",
      "abstract": "Training data cleaning is a new application for generative model-based speech restoration (SR). This paper introduces Miipher-2, an SR model designed for million-hour scale data, for training data cleaning for large-scale generative models like large language models. Key challenges addressed include generalization to unseen languages, operation without explicit conditioning (e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a frozen, pre-trained Universal Speech Model (USM), supporting over 300 languages, as a robust, conditioning-free feature extractor. To optimize efficiency and minimize memory, Miipher-2 incorporates parallel adapters for predicting clean USM features from noisy inputs and employs the WaveFit neural vocoder for waveform synthesis. These components were trained on 3,000 hours of multi-lingual, studio-quality recordings with augmented degradations, while USM parameters remained fixed. Experimental results demonstrate Miipher-2's superior or comparable performance to conventional SR models in word-error-rate, speaker similarity, and both objective and subjective sound quality scores across all tested languages. Miipher-2 operates efficiently on consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling the processing of a million-hour speech dataset in approximately three days using only 100 such accelerators.",
      "authors": [
        "Shigeki Karita",
        "Yuma Koizumi",
        "Heiga Zen",
        "Haruko Ishikawa",
        "Robin Scheibler",
        "Michiel Bacchiani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T14:27:46+00:00",
          "link": "https://arxiv.org/abs/2505.04457v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T23:59:00+00:00",
          "link": "https://arxiv.org/abs/2505.04457v2",
          "size": "195kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T01:08:39+00:00",
          "link": "https://arxiv.org/abs/2505.04457v3",
          "size": "196kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T12:16:28+00:00",
          "link": "https://arxiv.org/abs/2505.04457v4",
          "size": "196kb",
          "version": "v4"
        }
      ],
      "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04457",
        "HTML": "https://arxiv.org/html/2505.04457v4",
        "PDF": "https://arxiv.org/pdf/2505.04457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses Miipher-2 for generative model-based speech restoration and data cleaning, which might relate to data processing concepts, it is primarily about speech data cleaning rather than LLM-specific data processing."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/yukara-ikemiya/wavefit-pytorch"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.07773",
      "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation. While Reinforcement Learning (RL) from outcome-based rewards enhances text-based reasoning, understanding how agents autonomously learn to leverage external tools like code execution remains crucial. We investigate RL from outcome-based rewards for Tool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously generate and execute Python code for mathematical problems without supervised tool-use examples. Our central contribution is we demonstrate that as RL training progresses, key metrics scale predictably. Specifically, we observe strong positive correlations where increased training steps lead to increases in the spontaneous code execution frequency, the average response length, and, critically, the final task accuracy. This suggests a quantifiable relationship between computational effort invested in training and the emergence of effective, tool-augmented reasoning strategies. We implement a robust framework featuring a decoupled code execution environment and validate our findings across standard RL algorithms and frameworks. Experiments show ZeroTIR significantly surpasses non-tool ZeroRL baselines on challenging math benchmarks. Our findings provide a foundational understanding of how autonomous tool use is acquired and scales within Agent RL, offering a reproducible benchmark for future studies. Code is released at \\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.",
      "authors": [
        "Xinji Mai",
        "Haotian Xu",
        "Xing W",
        "Weinong Wang",
        "Jian Hu",
        "Yingying Zhang",
        "Wenqiang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T17:23:34+00:00",
          "link": "https://arxiv.org/abs/2505.07773v1",
          "size": "424kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T04:15:06+00:00",
          "link": "https://arxiv.org/abs/2505.07773v2",
          "size": "424kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T14:15:28+00:00",
          "link": "https://arxiv.org/abs/2505.07773v3",
          "size": "596kb",
          "version": "v3"
        }
      ],
      "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07773",
        "HTML": "https://arxiv.org/html/2505.07773v3",
        "PDF": "https://arxiv.org/pdf/2505.07773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reinforcement learning for tool integration in mathematical problem solving, especially through code execution. It does not address training data processing related to LLM pretraining or fine-tuning stages."
      },
      "tasks": [
        "Math",
        "Mathematical Problem-Solving",
        "Mathematical Reasoning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/anonymize-author/agentrl",
        "https://github.com/yyht/openrlhf_async_pipline"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.07983",
      "abstract": "This paper addresses the feasibility of virtual holonomic constraints (VHCs) in the context of motion planning for underactuated mechanical systems with a single degree of underactuation. While existing literature has established a widely accepted definition of VHC, we argue that this definition is overly restrictive and excludes a broad class of admissible trajectories from consideration. To illustrate this point, we analyze a periodic motion of the Planar Vertical Take-Off and Landing (PVTOL) aircraft that satisfies all standard motion planning requirements, including orbital stabilizability. However, for this solution -- as well as for a broad class of similar ones -- there exists no VHC that satisfies the conventional definition. We further provide a formal proof demonstrating that the conditions imposed by this definition necessarily fail for a broad class of trajectories of mechanical systems. These findings call for a reconsideration of the current definition of VHCs, with the potential to significantly broaden their applicability in motion planning.",
      "authors": [
        "Maksim Surov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T18:29:35+00:00",
          "link": "https://arxiv.org/abs/2505.07983v1",
          "size": "206kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:42:48+00:00",
          "link": "https://arxiv.org/abs/2505.07983v2",
          "size": "484kb",
          "version": "v2"
        }
      ],
      "title": "Virtual Holonomic Constraints in Motion Planning: Revisiting Feasibility and Limitations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07983",
        "HTML": "https://arxiv.org/html/2505.07983v2",
        "PDF": "https://arxiv.org/pdf/2505.07983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses motion planning for underactuated mechanical systems and virtual holonomic constraints. It does not involve LLM training data processing or any operations related to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.10016",
      "abstract": "Autonomous driving technology is progressively transforming traditional car driving methods, marking a significant milestone in modern transportation. Object detection serves as a cornerstone of autonomous systems, playing a vital role in enhancing driving safety, enabling autonomous functionality, improving traffic efficiency, and facilitating effective emergency responses. However, current technologies such as radar for environmental perception, cameras for road perception, and vehicle sensor networks face notable challenges, including high costs, vulnerability to weather and lighting conditions, and limited resolution.To address these limitations, this paper presents an improved autonomous target detection network based on YOLOv8. By integrating structural reparameterization technology, a bidirectional pyramid structure network model, and a novel detection pipeline into the YOLOv8 framework, the proposed approach achieves highly efficient and precise detection of multi-scale, small, and remote objects. Experimental results demonstrate that the enhanced model can effectively detect both large and small objects with a detection accuracy of 65%, showcasing significant advancements over traditional methods.This improved model holds substantial potential for real-world applications and is well-suited for autonomous driving competitions, such as the Formula Student Autonomous China (FSAC), particularly excelling in scenarios involving single-target and small-object detection.",
      "authors": [
        "Shijie Lyu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T06:58:45+00:00",
          "link": "https://arxiv.org/abs/2505.10016v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:01:56+00:00",
          "link": "https://arxiv.org/abs/2505.10016v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Application of YOLOv8 in monocular downward multiple Car Target detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10016",
        "PDF": "https://arxiv.org/pdf/2505.10016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research involves improving object detection using YOLOv8 for autonomous driving. It does not pertain to LLM training data processing in any relevant aspect."
      },
      "tasks": [
        "Autonomous Driving",
        "object-detection",
        "Object Detection",
        "Small Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10027",
      "abstract": "With the rapid advancement of remote sensing technology, super-resolution image reconstruction is of great research and practical significance. Existing deep learning methods have made progress but still face limitations in handling complex scenes and preserving image details. This paper proposes a reinforcement learning-based latent diffusion model (LDM) fine-tuning method for remote sensing image super-resolution. The method constructs a reinforcement learning environment with states, actions, and rewards, optimizing decision objectives through proximal policy optimization (PPO) during the reverse denoising process of the LDM model. Experiments on the RESISC45 dataset show significant improvements over the baseline model in PSNR, SSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11, and LPIPS reducing by 0.06-0.10, particularly in structured and complex natural scenes. The results demonstrate the method's effectiveness in enhancing super-resolution quality and adaptability across scenes.",
      "authors": [
        "Shijie Lyu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T07:17:03+00:00",
          "link": "https://arxiv.org/abs/2505.10027v1",
          "size": "404kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:01:44+00:00",
          "link": "https://arxiv.org/abs/2505.10027v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10027",
        "PDF": "https://arxiv.org/pdf/2505.10027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses super-resolution reconstruction for remote sensing images using reinforcement learning and does not relate to LLM training data processing or techniques to improve LLM datasets."
      },
      "tasks": [
        "Denoising",
        "Image Reconstruction",
        "Image Super-Resolution",
        "reinforcement-learning",
        "Reinforcement Learning",
        "SSIM",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10764",
      "abstract": "Innovations in digital intelligence are transforming robotic surgery with more informed decision-making. Real-time awareness of surgical instrument presence and actions (e.g., cutting tissue) is essential for such systems. Yet, despite decades of research, most machine learning models for this task are trained on small datasets and still struggle to generalize. Recently, vision-Language Models (VLMs) have brought transformative advances in reasoning across visual and textual modalities. Their unprecedented generalization capabilities suggest great potential for advancing intelligent robotic surgery. However, surgical VLMs remain under-explored, and existing models show limited performance, highlighting the need for benchmark studies to assess their capabilities and limitations and to inform future development. To this end, we benchmark the zero-shot performance of several advanced VLMs on two public robotic-assisted laparoscopic datasets for instrument and action classification. Beyond standard evaluation, we integrate explainable AI to visualize VLM attention and uncover causal explanations behind their predictions. This provides a previously underexplored perspective in this field for evaluating the reliability of model predictions. We also propose several explainability analysis-based metrics to complement standard evaluations. Our analysis reveals that surgical VLMs, despite domain-specific training, often rely on weak contextual cues rather than clinically relevant visual evidence, highlighting the need for stronger visual and reasoning supervision in surgical applications.",
      "authors": [
        "Jiajun Cheng",
        "Xianwu Zhao",
        "Sainan Liu",
        "Xiaofan Yu",
        "Ravi Prakash",
        "Patrick J. Codd",
        "Jonathan Elliott Katz",
        "Shan Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T00:42:18+00:00",
          "link": "https://arxiv.org/abs/2505.10764v1",
          "size": "9859kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T23:19:43+00:00",
          "link": "https://arxiv.org/abs/2505.10764v2",
          "size": "13291kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T04:04:22+00:00",
          "link": "https://arxiv.org/abs/2505.10764v3",
          "size": "32714kb",
          "version": "v3"
        }
      ],
      "title": "SurgXBench: Explainable Vision-Language Model Benchmark for Surgery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10764",
        "HTML": "https://arxiv.org/html/2505.10764v3",
        "PDF": "https://arxiv.org/pdf/2505.10764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on benchmarking vision-language models for robotic surgery, which does not contribute to the area of LLM training data processing, dataset creation, or improvement."
      },
      "tasks": [
        "Benchmarking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17764",
      "abstract": "The role of high-degree nodes, or hubs, in shaping graph dynamics and structure is well-recognized in network science, yet their influence remains underexplored in the context of dynamic graph embedding. Recent advances in representation learning for graphs have shown that random walk-based methods can capture both structural and temporal patterns, but often overlook the impact of hubs on walk trajectories and embedding stability. In this paper, we introduce DeepHub, a method for dynamic graph embedding that explicitly integrates hub sensitivity into random walk sampling strategies. Focusing on dynnode2vec as a representative dynamic embedding method, we systematically analyze the effect of hub-biased walks across nine real-world temporal networks. Our findings reveal that standard random walks tend to overrepresent hub nodes, leading to embeddings that underfit the evolving local context of less-connected nodes. By contrast, hub-aware walks can balance exploration, resulting in embeddings that better preserve temporal neighborhood structure and improve downstream task performance. These results suggest that hub-awareness is an important yet overlooked factor in dynamic graph embedding, and our work provides a foundation for more robust, structure-sensitive representation learning in evolving networks.",
      "authors": [
        "Aleksandar Tom\\v{c}i\\'c",
        "Milo\\v{s} Savi\\'c",
        "Du\\v{s}an Simi\\'c",
        "Milo\\v{s} Radovanovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T11:35:24+00:00",
          "link": "https://arxiv.org/abs/2505.17764v1",
          "size": "145kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:37:00+00:00",
          "link": "https://arxiv.org/abs/2505.17764v2",
          "size": "138kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic Graph Embedding Through Hub-aware Random Walks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17764",
        "HTML": "https://arxiv.org/html/2505.17764v2",
        "PDF": "https://arxiv.org/pdf/2505.17764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces DeepHub, a method for dynamic graph embedding focused on random walks and hub nodes, with no mention of LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18079",
      "abstract": "Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery agent to leverage an agentic search strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools, formulates appropriate parameters for actions, and iteratively refines its internal reasoning in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates the advantage of the entire system design. Our DVD agent achieves SOTA performance, significantly surpassing prior works by a large margin on the challenging LVBench dataset. Comprehensive ablation studies and in-depth tool analyses are also provided, yielding insights to further advance intelligent agents tailored for long-form video understanding tasks. The code has been released in https://github.com/microsoft/DeepVideoDiscovery.",
      "authors": [
        "Xiaoyi Zhang",
        "Zhaoyang Jia",
        "Zongyu Guo",
        "Jiahao Li",
        "Bin Li",
        "Houqiang Li",
        "Yan Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T16:37:36+00:00",
          "link": "https://arxiv.org/abs/2505.18079v1",
          "size": "455kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T08:30:39+00:00",
          "link": "https://arxiv.org/abs/2505.18079v2",
          "size": "456kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T17:26:05+00:00",
          "link": "https://arxiv.org/abs/2505.18079v3",
          "size": "456kb",
          "version": "v3"
        }
      ],
      "title": "Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18079",
        "HTML": "https://arxiv.org/html/2505.18079v3",
        "PDF": "https://arxiv.org/pdf/2505.18079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the Deep Video Discovery agent for video understanding, which implicates LLMs in video processing, but it does not involve data processing operations related to LLM training data."
      },
      "tasks": [
        "Form",
        "Question Answering",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19166",
      "abstract": "We introduce JEDI, a test-time adaptation method that enhances subject separation and compositional alignment in diffusion models without requiring retraining or external supervision. JEDI operates by minimizing semantic entanglement in attention maps using a novel Jensen-Shannon divergence based objective. To improve efficiency, we leverage adversarial optimization, reducing the number of updating steps required. JEDI is model-agnostic and applicable to architectures such as Stable Diffusion 1.5 and 3.5, consistently improving prompt alignment and disentanglement in complex scenes. Additionally, JEDI provides a lightweight, CLIP-free disentanglement score derived from internal attention distributions, offering a principled benchmark for compositional alignment under test-time conditions. Code and results are available at https://ericbill21.github.io/JEDI/.",
      "authors": [
        "Eric Tillmann Bill",
        "Enis Simsar and Thomas Hofmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T14:32:24+00:00",
          "link": "https://arxiv.org/abs/2505.19166v1",
          "size": "33642kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T12:14:57+00:00",
          "link": "https://arxiv.org/abs/2505.19166v2",
          "size": "15759kb",
          "version": "v2"
        }
      ],
      "title": "JEDI: The Force of Jensen-Shannon Divergence in Disentangling Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19166",
        "HTML": "https://arxiv.org/html/2505.19166v2",
        "PDF": "https://arxiv.org/pdf/2505.19166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "JEDI, the test-time adaptation method developed by the paper, enhances attention mechanisms in diffusion models; it does not relate to LLM training data processing."
      },
      "tasks": [
        "Disentanglement",
        "Test-time Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19550",
      "abstract": "With the rise of artificial intelligence (A.I.) and large language models like ChatGPT, a new race for achieving artificial general intelligence (A.G.I) has started. While many speculate how and when A.I. will achieve A.G.I., there is no clear agreement on how A.G.I. can be detected in A.I. models, even when popular tools like the Turing test (and its modern variations) are used to measure their intelligence. In this work, we discuss why traditional methods like the Turing test do not suffice for measuring or detecting A.G.I. and provide a new, practical method that can be used to decide if a system (computer or any other) has reached or surpassed A.G.I. To achieve this, we make two new contributions. First, we present a clear definition for general intelligence (G.I.) and set a G.I. Threshold (G.I.T.) that can be used to distinguish between systems that achieve A.G.I. and systems that do not. Second, we present a new framework on how to construct tests that can detect if a system has achieved G.I. in a simple, comprehensive, and clear-cut fail/pass way. We call this novel framework the Turing test 2.0. We then demonstrate real-life examples of applying tests that follow our Turing test 2.0 framework on modern A.I. models.",
      "authors": [
        "Georgios Mappouras"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T06:13:15+00:00",
          "link": "https://arxiv.org/abs/2505.19550v1",
          "size": "999kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T06:53:17+00:00",
          "link": "https://arxiv.org/abs/2505.19550v2",
          "size": "1001kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T01:55:54+00:00",
          "link": "https://arxiv.org/abs/2505.19550v3",
          "size": "1135kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T15:09:33+00:00",
          "link": "https://arxiv.org/abs/2505.19550v4",
          "size": "1136kb",
          "version": "v4"
        }
      ],
      "title": "Turing Test 2.0: The General Intelligence Threshold",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19550",
        "PDF": "https://arxiv.org/pdf/2505.19550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on defining and detecting artificial general intelligence (AGI) and introducing a new framework for the Turing test. It does not address any aspects of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.20424",
      "abstract": "Operating home appliances, among the most common tools in every household, is a critical capability for assistive home robots. This paper presents ApBot, a robot system that operates novel household appliances by \"reading\" their user manuals. ApBot faces multiple challenges: (i) infer goal-conditioned partial policies from their unstructured, textual descriptions in a user manual document, (ii) ground the policies to the appliance in the physical world, and (iii) execute the policies reliably over potentially many steps, despite compounding errors. To tackle these challenges, ApBot constructs a structured, symbolic model of an appliance from its manual, with the help of a large vision-language model (VLM). It grounds the symbolic actions visually to control panel elements. Finally, ApBot closes the loop by updating the model based on visual feedback. Our experiments show that across a wide range of simulated and real-world appliances, ApBot achieves consistent and statistically significant improvements in task success rate, compared with state-of-the-art large VLMs used directly as control policies. These results suggest that a structured internal representations plays an important role in robust robot operation of home appliances, especially, complex ones.",
      "authors": [
        "Jian Zhang",
        "Hanbo Zhang",
        "Anxing Xiao",
        "David Hsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T18:17:07+00:00",
          "link": "https://arxiv.org/abs/2505.20424v1",
          "size": "17716kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T17:39:54+00:00",
          "link": "https://arxiv.org/abs/2505.20424v2",
          "size": "8465kb",
          "version": "v2"
        }
      ],
      "title": "Robot Operation of Home Appliances by Reading User Manuals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20424",
        "PDF": "https://arxiv.org/pdf/2505.20424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a robot system for operating home appliances by interpreting user manuals, with the aid of a vision-language model. It is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.22334",
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated impressive chain-of-thought reasoning capabilities, with reinforcement learning (RL) playing a crucial role in this progress. While \"aha moment\" patterns--where models exhibit self-correction through reflection--are often attributed to emergent properties from RL, we first demonstrate that these patterns exist in multimodal LLMs (MLLMs) prior to RL training but may not necessarily correlate with improved reasoning performance. Building on these insights, we present a comprehensive study on enhancing multimodal reasoning through a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start with structured chain-of-thought reasoning patterns, followed by (2) reinforcement learning via GRPO to further refine these capabilities. Our extensive experiments show that this combined approach consistently outperforms both SFT-only and RL-only methods across challenging multimodal reasoning benchmarks. The resulting models achieve state-of-the-art performance among open-source MLLMs at both 3B and 7B scales, with our 7B model showing substantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on MathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving performance competitive with several 7B models. Overall, this work provides practical guidance for building advanced multimodal reasoning models. Our code is available at https://github.com/waltonfuture/RL-with-Cold-Start.",
      "authors": [
        "Lai Wei",
        "Yuting Li",
        "Kaipeng Zheng",
        "Chen Wang",
        "Yue Wang",
        "Linghe Kong",
        "Lichao Sun",
        "Weiran Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T13:21:38+00:00",
          "link": "https://arxiv.org/abs/2505.22334v1",
          "size": "451kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:37:08+00:00",
          "link": "https://arxiv.org/abs/2505.22334v2",
          "size": "451kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22334",
        "PDF": "https://arxiv.org/pdf/2505.22334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses training multimodal LLMs using a combination of supervised fine-tuning and reinforcement learning, but the focus is on reasoning capabilities rather than on training data processing techniques."
      },
      "models": [
        {
          "model_path": "WaltonFuture/Qwen2.5VL-7b-RLCS",
          "downloads": "27",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WaltonFuture/Qwen2.5VL-7b-RLCS"
        },
        {
          "model_path": "WaltonFuture/Qwen2.5VL-3b-RLCS",
          "downloads": "9781",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WaltonFuture/Qwen2.5VL-3b-RLCS"
        }
      ],
      "datasets": [
        {
          "dataset_name": "WaltonFuture/Multimodal-RL-Data",
          "downloads": "302",
          "likes": "4",
          "link": "https://huggingface.co/datasets/WaltonFuture/Multimodal-RL-Data"
        },
        {
          "dataset_name": "WaltonFuture/Multimodal-Cold-Start",
          "downloads": "78",
          "likes": "2",
          "link": "https://huggingface.co/datasets/WaltonFuture/Multimodal-Cold-Start"
        }
      ],
      "tasks": [
        "Math",
        "Multimodal Reasoning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/hiyouga/easyr1",
        "https://github.com/waltonfuture/rl-with-cold-start"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22404",
      "abstract": "Autonomous robots require efficient on-device learning to adapt to new environments without cloud dependency. For this edge training, Microscaling (MX) data types offer a promising solution by combining integer and floating-point representations with shared exponents, reducing energy consumption while maintaining accuracy. However, the state-of-the-art continuous learning processor, namely Dacapo, faces limitations with its MXINT-only support and inefficient vector-based grouping during backpropagation. In this paper, we present, to the best of our knowledge, the first work that addresses these limitations with two key innovations: (1) a precision-scalable arithmetic unit that supports all six MX data types by exploiting sub-word parallelism and unified integer and floating-point processing; and (2) support for square shared exponent groups to enable efficient weight handling during backpropagation, removing storage redundancy and quantization overhead. We evaluate our design against Dacapo under iso-peak-throughput on four robotics workloads in TSMC 16nm FinFET technology at 400MHz, reaching a 51% lower memory footprint, and 4x higher effective training throughput, while achieving comparable energy efficiency, enabling efficient robotics continual learning at the edge.",
      "authors": [
        "Stef Cuyckens",
        "Xiaoling Yi",
        "Nitish Satya Murthy",
        "Chao Fang",
        "Marian Verhelst"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T14:34:32+00:00",
          "link": "https://arxiv.org/abs/2505.22404v1",
          "size": "1392kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:07:16+00:00",
          "link": "https://arxiv.org/abs/2505.22404v2",
          "size": "1477kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22404",
        "HTML": "https://arxiv.org/html/2505.22404v2",
        "PDF": "https://arxiv.org/pdf/2505.22404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hardware for robotics learning, specifically improving MX data processing and not LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.23404",
      "abstract": "Recent advancements in adversarial jailbreak attacks have exposed critical vulnerabilities in Large Language Models (LLMs), enabling the circumvention of alignment safeguards through increasingly sophisticated prompt manipulations. Based on our experiments, we found that the effectiveness of jailbreak strategies is influenced by the comprehension ability of the attacked LLM. Building on this insight, we propose a capability-aware Multi-Encryption Framework (MEF) for evaluating vulnerabilities in black-box LLMs. Specifically, MEF first categorizes the comprehension ability level of the LLM, then applies different strategies accordingly: For models with limited comprehension ability, MEF adopts the Fu+En1 strategy, which integrates layered semantic mutations with an encryption technique, more effectively contributing to evasion of the LLM's defenses at the input and inference stages. For models with strong comprehension ability, MEF uses a more complex Fu+En1+En2 strategy, in which additional dual-ended encryption techniques are applied to the LLM's responses, further contributing to evasion of the LLM's defenses at the output stage. Experimental results demonstrate the effectiveness of our approach, achieving attack success rates of 98.9% on GPT-4o (29 May 2025 release) and 99.8% on GPT-4.1 (8 July 2025 release). Our work contributes to a deeper understanding of the vulnerabilities in current LLM alignment mechanisms.",
      "authors": [
        "Mingyu Yu",
        "Wei Wang",
        "Yanjie Wei",
        "Sujuan Qin",
        "Fei Gao",
        "Wenmin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T12:50:57+00:00",
          "link": "https://arxiv.org/abs/2505.23404v1",
          "size": "2337kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T12:24:01+00:00",
          "link": "https://arxiv.org/abs/2505.23404v2",
          "size": "1878kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T03:36:46+00:00",
          "link": "https://arxiv.org/abs/2505.23404v3",
          "size": "230kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T12:06:53+00:00",
          "link": "https://arxiv.org/abs/2505.23404v4",
          "size": "230kb",
          "version": "v4"
        }
      ],
      "title": "MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23404",
        "PDF": "https://arxiv.org/pdf/2505.23404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates vulnerabilities in LLMs through adversarial attacks using a multi-encryption framework. It does not address training data processing or dataset enhancement."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.23822",
      "abstract": "Speech is a noninvasive digital phenotype that can offer valuable insights into mental health conditions, but it is often treated as a single modality. In contrast, we propose the treatment of patient speech data as a trimodal multimedia data source for depression detection. This study explores the potential of large language model-based architectures for speech-based depression prediction in a multimodal regime that integrates speech-derived text, acoustic landmarks, and vocal biomarkers. Adolescent depression presents a significant challenge and is often comorbid with multiple disorders, such as suicidal ideation and sleep disturbances. This presents an additional opportunity to integrate multi-task learning (MTL) into our study by simultaneously predicting depression, suicidal ideation, and sleep disturbances using the multimodal formulation. We also propose a longitudinal analysis strategy that models temporal changes across multiple clinical interactions, allowing for a comprehensive understanding of the conditions' progression. Our proposed approach, featuring trimodal, longitudinal MTL is evaluated on the Depression Early Warning dataset. It achieves a balanced accuracy of 70.8%, which is higher than each of the unimodal, single-task, and non-longitudinal methods.",
      "authors": [
        "Mai Ali",
        "Christopher Lucasius",
        "Tanmay P. Patel",
        "Madison Aitken",
        "Jacob Vorstman",
        "Peter Szatmari",
        "Marco Battaglia",
        "Deepa Kundur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T04:07:17+00:00",
          "link": "https://arxiv.org/abs/2505.23822v1",
          "size": "426kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T15:46:53+00:00",
          "link": "https://arxiv.org/abs/2505.23822v2",
          "size": "426kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T14:16:49+00:00",
          "link": "https://arxiv.org/abs/2505.23822v3",
          "size": "426kb",
          "version": "v3"
        }
      ],
      "title": "Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23822",
        "HTML": "https://arxiv.org/html/2505.23822v3",
        "PDF": "https://arxiv.org/pdf/2505.23822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores multimodal LLM-based approaches for mental health prediction from speech data. It involves processing diverse data types but does not focus primarily on LLM training data processing."
      },
      "tasks": [
        "Depression Detection",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Multi-Task Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00178",
      "abstract": "Prompt engineering represents a critical bottleneck to harness the full potential of Large Language Models (LLMs) for solving complex tasks, as it requires specialized expertise, significant trial-and-error, and manual intervention. This challenge is particularly pronounced for tasks involving subjective quality assessment, where defining explicit optimization objectives becomes fundamentally problematic. Existing automated prompt optimization methods falter in these scenarios, as they typically require well-defined task-specific numerical fitness functions or rely on generic templates that cannot capture the nuanced requirements of complex use cases. We introduce DEEVO (DEbate-driven EVOlutionary prompt optimization), a novel framework that guides prompt evolution through a debate-driven evaluation with an Elo-based selection. Contrary to prior work, DEEVOs approach enables exploration of the discrete prompt space while preserving semantic coherence through intelligent crossover and strategic mutation operations that incorporate debate-based feedback, combining elements from both successful and unsuccessful prompts based on identified strengths rather than arbitrary splicing. Using Elo ratings as a fitness proxy, DEEVO simultaneously drives improvement and preserves valuable diversity in the prompt population. Experimental results demonstrate that DEEVO significantly outperforms both manual prompt engineering and alternative state-of-the-art optimization approaches on open-ended tasks and close-ended tasks despite using no ground truth feedback. By connecting LLMs reasoning capabilities with adaptive optimization, DEEVO represents a significant advancement in prompt optimization research by eliminating the need of predetermined metrics to continuously improve AI systems.",
      "authors": [
        "Anirudh Nair",
        "Adi Banerjee",
        "Laurent Mombaerts",
        "Matthew Hagen",
        "Tarik Borogovac"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T19:33:41+00:00",
          "link": "https://arxiv.org/abs/2506.00178v1",
          "size": "817kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T18:01:11+00:00",
          "link": "https://arxiv.org/abs/2506.00178v2",
          "size": "817kb",
          "version": "v2"
        }
      ],
      "title": "Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00178",
        "HTML": "https://arxiv.org/html/2506.00178v2",
        "PDF": "https://arxiv.org/pdf/2506.00178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with prompt optimization using debate-driven techniques. It does not discuss pretraining, fine-tuning, or any training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01966",
      "abstract": "Deep neural networks employ specialized architectures for vision, sequential and language tasks, yet this proliferation obscures their underlying commonalities. We introduce a unified matrix-order framework that casts convolutional, recurrent and self-attention operations as sparse matrix multiplications. Convolution is realized via an upper-triangular weight matrix performing first-order transformations; recurrence emerges from a lower-triangular matrix encoding stepwise updates; attention arises naturally as a third-order tensor factorization. We prove algebraic isomorphism with standard CNN, RNN and Transformer layers under mild assumptions. Empirical evaluations on image classification (MNIST, CIFAR-10/100, Tiny ImageNet), time-series forecasting (ETTh1, Electricity Load Diagrams) and language modeling/classification (AG News, WikiText-2, Penn Treebank) confirm that sparse-matrix formulations match or exceed native model performance while converging in comparable or fewer epochs. By reducing architecture design to sparse pattern selection, our matrix perspective aligns with GPU parallelism and leverages mature algebraic optimization tools. This work establishes a mathematically rigorous substrate for diverse neural architectures and opens avenues for principled, hardware-aware network design.",
      "authors": [
        "Yuzhou Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-11T06:26:34+00:00",
          "link": "https://arxiv.org/abs/2506.01966v1",
          "size": "86kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:48:16+00:00",
          "link": "https://arxiv.org/abs/2506.01966v2",
          "size": "86kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T20:07:02+00:00",
          "link": "https://arxiv.org/abs/2506.01966v3",
          "size": "86kb",
          "version": "v3"
        }
      ],
      "title": "Unified Sparse-Matrix Representations for Diverse Neural Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01966",
        "HTML": "https://arxiv.org/html/2506.01966v3",
        "PDF": "https://arxiv.org/pdf/2506.01966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a unified sparse-matrix representation for neural architectures, focusing on computational frameworks rather than any aspect of LLM training data processing."
      },
      "tasks": [
        "All",
        "image-classification",
        "Image Classification",
        "Language Modeling",
        "Language Modelling",
        "Time Series Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02634",
      "abstract": "Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV\\$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV\\$ caching, where system design decisions like cache eviction policies are highly workload-dependent. In this paper, we present the first systematic characterization of the KV\\$ workload patterns from one of the leading LLM service providers. We draw observations that were not covered by previous studies focusing on synthetic workloads, including: KV\\$ reuses are skewed across requests, where reuses between single-turn requests are equally important as multi-turn requests; the reuse time and probability are diverse considering all requests, but for a specific request category, the pattern tends to be predictable; and the overall cache size required for an ideal cache hit ratio is moderate. Based on the characterization, we further propose a workload-aware cache eviction policy that improves the serving performance under real-world traces, especially with limited cache capacity.",
      "authors": [
        "Jiahao Wang",
        "Jinbo Han",
        "Xingda Wei",
        "Sijie Shen",
        "Dingyan Zhang",
        "Chenguang Fang",
        "Rong Chen",
        "Wenyuan Yu",
        "Haibo Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T08:51:38+00:00",
          "link": "https://arxiv.org/abs/2506.02634v1",
          "size": "26463kb",
          "version": "v1"
        },
        {
          "date": "2025-06-14T04:39:21+00:00",
          "link": "https://arxiv.org/abs/2506.02634v2",
          "size": "26038kb",
          "version": "v2"
        },
        {
          "date": "2025-06-19T02:18:16+00:00",
          "link": "https://arxiv.org/abs/2506.02634v3",
          "size": "26033kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T08:07:19+00:00",
          "link": "https://arxiv.org/abs/2506.02634v4",
          "size": "26033kb",
          "version": "v4"
        }
      ],
      "title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02634",
        "HTML": "https://arxiv.org/html/2506.02634v4",
        "PDF": "https://arxiv.org/pdf/2506.02634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing cache systems for LLM serving at cloud providers, specifically examining KV$ caching. It does not contribute to training data processing for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/alibaba-edu/qwen-bailian-usagetraces-anon"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02951",
      "abstract": "Large Language Model (LLM) based multi-agent systems have shown remarkable performance in various tasks, especially when enhanced through collaborative communication. However, current methods often rely on a fixed number of agents and static communication structures, limiting their ability to adapt to varying task complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a novel task-adaptive multi-agent collaboration framework that jointly optimizes agent quantity (hard-pruning) and communication topology (soft-pruning). Specifically, our method employs a two-stage training strategy: firstly, independently training soft-pruning networks for different agent quantities to determine optimal agent-quantity-specific complete graphs and positional masks across specific tasks; and then jointly optimizing hard-pruning and soft-pruning within a maximum complete graph to dynamically configure the number of agents and their communication topologies per task. Extensive experiments demonstrate that our approach is: (1) High-performing, achieving state-of-the-art results across six benchmarks and consistently generalizes across multiple mainstream LLM architectures, with a increase in performance of $2.58\\%\\sim 9.84\\%$; (2) Task-adaptive, dynamically constructing optimized communication topologies tailored to specific tasks, with an extremely high performance in all three task categories (general reasoning, mathematical reasoning, and code generation); (3) Token-economical, having fewer training steps and token consumption at the same time, with a decrease in token consumption of $90\\%+$; and (4) Training-efficient, achieving high performance with very few training steps compared with other methods. The performance will surpass the existing baselines after about ten steps of training under six benchmarks.",
      "authors": [
        "Boyi Li",
        "Zhonghan Zhao",
        "Der-Horng Lee",
        "Gaoang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T14:46:00+00:00",
          "link": "https://arxiv.org/abs/2506.02951v1",
          "size": "5515kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T03:10:04+00:00",
          "link": "https://arxiv.org/abs/2506.02951v2",
          "size": "5516kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T03:40:09+00:00",
          "link": "https://arxiv.org/abs/2506.02951v3",
          "size": "5516kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive Graph Pruning for Multi-Agent Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02951",
        "HTML": "https://arxiv.org/html/2506.02951v3",
        "PDF": "https://arxiv.org/pdf/2506.02951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a multi-agent collaboration framework for LLMs, focusing on communication structures and agent optimization, rather than on training data processing."
      },
      "tasks": [
        "Code Generation",
        "Large Language Model",
        "Mathematical Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04134",
      "abstract": "Cued Speech (CS) enhances lipreading through hand coding, providing precise speech perception support for the hearing-impaired. CS Video-to-Speech generation (CSV2S) task aims to convert the CS visual expressions (CS videos) of hearing-impaired individuals into comprehensible speech signals. Direct generation of speech from CS video (called single CSV2S) yields poor performance due to insufficient CS data. Current research mostly focuses on CS Recognition (CSR), which convert video content into linguistic text. Based on this, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech system. This combined architecture relies on text as an intermediate medium for stepwise cross-modal alignment, which may lead to error propagation and temporal misalignment between speech and video dynamics. To address these challenges, we propose a novel approach that directly generates speech from CS videos without relying on intermediate text. Building upon this, we propose UniCUE, the first unified framework for CSV2S, whose core innovation lies in the integration of the CSR task that provides fine-grained visual-semantic information to facilitate speech generation from CS videos. More precisely, (1) a novel fine-grained semantic alignment pool to ensure precise mapping between visual features and speech contents; (2) a VisioPhonetic adapter to bridge cross-task representations, ensuring seamless compatibility between two distinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is introduced to enhance fine-grained spatiotemporal correlations between lip and hand movements in CS video. Experiments on our new established Chinese CS dataset show that our UniCUE achieves state-of-the-art performance across various metrics.",
      "authors": [
        "Jinting Wang",
        "Shan Yang",
        "Li Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T16:26:49+00:00",
          "link": "https://arxiv.org/abs/2506.04134v1",
          "size": "3371kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:56:36+00:00",
          "link": "https://arxiv.org/abs/2506.04134v2",
          "size": "2511kb",
          "version": "v2"
        }
      ],
      "title": "UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04134",
        "HTML": "https://arxiv.org/html/2506.04134v2",
        "PDF": "https://arxiv.org/pdf/2506.04134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents a framework for direct speech generation from CS videos, focusing on multimodal alignment and speech generation, without involving LLM training data processing."
      },
      "tasks": [
        "cross-modal alignment",
        "Lipreading",
        "text-to-speech",
        "Text to Speech"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04260",
      "abstract": "Practitioners building online services and tools often turn to online forums such as Reddit, Law Stack Exchange, and Stack Overflow for legal guidance to ensure compliance with the GDPR. The legal information presented in these forums directly impacts present-day industry practitioner's decisions. Online forums can serve as gateways that, depending on the accuracy and quality of the answers provided, may either support or undermine the protection of privacy and data protection fundamental rights. However, there is a need for deeper investigation into practitioners' decision-making processes and their understanding of legal compliance when seeking for legal information online.\n  Using GDPR's ``legitimate interests'' legal ground for processing personal data as a case study, we investigate how practitioners use online forums to identify common areas of confusion in applying legitimate interests in practice, and evaluate how legally sound online forum responses are.\n  Our analysis found that applying the legal basis of legitimate interest is complex for practitioners, with important implications for how the GDPR is implemented in practice. The legal analysis showed that crowdsourced legal information tends to be legally sound, though sometimes incomplete. We outline recommendations to improve the quality of online forums by ensuring that responses are more legally sound and comprehensive, enabling practitioners to apply legitimate interests effectively in practice and uphold the GDPR.",
      "authors": [
        "Lin Kyi",
        "Cristiana Santos",
        "Sushil Ammanaghatta Shivakumar",
        "Franziska Roesner and Asia Biega"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T20:16:01+00:00",
          "link": "https://arxiv.org/abs/2506.04260v1",
          "size": "125kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:21:00+00:00",
          "link": "https://arxiv.org/abs/2506.04260v2",
          "size": "128kb",
          "version": "v2"
        }
      ],
      "title": "Turning to Online Forums for Legal Information: A Case Study of GDPR's Legitimate Interests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04260",
        "HTML": "https://arxiv.org/html/2506.04260v2",
        "PDF": "https://arxiv.org/pdf/2506.04260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates how online forums provide legal compliance information, focusing on GDPR guidance rather than techniques related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.05367",
      "abstract": "In this paper, we propose a novel diffusion-based approach to generate stereo images given a text prompt. Since stereo image datasets with large baselines are scarce, training a diffusion model from scratch is not feasible. Therefore, we propose leveraging the strong priors learned by Stable Diffusion and fine-tuning it on stereo image datasets to adapt it to the task of stereo generation. To improve stereo consistency and text-to-image alignment, we further tune the model using prompt alignment and our proposed stereo consistency reward functions. Comprehensive experiments demonstrate the superiority of our approach in generating high-quality stereo images across diverse scenarios, outperforming existing methods.",
      "authors": [
        "Aakash Garg",
        "Libing Zeng",
        "Andrii Tsarov",
        "Nima Khademi Kalantari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T22:40:35+00:00",
          "link": "https://arxiv.org/abs/2506.05367v1",
          "size": "14431kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:25:59+00:00",
          "link": "https://arxiv.org/abs/2506.05367v2",
          "size": "14431kb",
          "version": "v2"
        }
      ],
      "title": "Text2Stereo: Repurposing Stable Diffusion for Stereo Generation with Consistency Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05367",
        "HTML": "https://arxiv.org/html/2506.05367v2",
        "PDF": "https://arxiv.org/pdf/2506.05367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper extends Stable Diffusion to generate stereo images by fine-tuning it with stereo datasets and introducing consistency rewards. While it involves fine-tuning and dataset use, its core focus is on image generation, not LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07584",
      "abstract": "A unified foundation model for medical time series -- pretrained on open access and ethics board-approved medical corpora -- offers the potential to reduce annotation burdens, minimize model customization, and enable robust transfer across clinical institutions, modalities, and tasks, particularly in data-scarce or privacy-constrained environments. However, existing generalist time series foundation models struggle to handle medical time series data due to their inherent challenges, including irregular intervals, heterogeneous sampling rates, and frequent missing values. To address these challenges, we introduce MIRA, a unified foundation model specifically designed for medical time series forecasting. MIRA incorporates a Continuous-Time Rotary Positional Encoding that enables fine-grained modeling of variable time intervals, a frequency-specific mixture-of-experts layer that routes computation across latent frequency regimes to further promote temporal specialization, and a Continuous Dynamics Extrapolation Block based on Neural ODE that models the continuous trajectory of latent states, enabling accurate forecasting at arbitrary target timestamps. Pretrained on a large-scale and diverse medical corpus comprising over 454 billion time points collect from publicly available datasets, MIRA achieves reductions in forecasting errors by an average of 10% and 7% in out-of-distribution and in-distribution scenarios, respectively, when compared to other zero-shot and fine-tuned baselines. We also introduce a comprehensive benchmark spanning multiple downstream clinical tasks, establishing a foundation for future research in medical time series modeling.",
      "authors": [
        "Hao Li",
        "Bowen Deng",
        "Chang Xu",
        "Zhiyuan Feng",
        "Viktor Schlegel",
        "Yu-Hao Huang",
        "Yizheng Sun",
        "Jingyuan Sun",
        "Kailai Yang",
        "Yiyao Yu",
        "Jiang Bian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T09:27:17+00:00",
          "link": "https://arxiv.org/abs/2506.07584v1",
          "size": "385kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T08:03:59+00:00",
          "link": "https://arxiv.org/abs/2506.07584v2",
          "size": "385kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T12:45:18+00:00",
          "link": "https://arxiv.org/abs/2506.07584v3",
          "size": "385kb",
          "version": "v3"
        }
      ],
      "title": "MIRA: Medical Time Series Foundation Model for Real-World Health Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07584",
        "HTML": "https://arxiv.org/html/2506.07584v3",
        "PDF": "https://arxiv.org/pdf/2506.07584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on medical time series forecasting using a model specifically designed for this purpose. It does not discuss data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [
        "Ethics",
        "Missing Values",
        "Mixture-of-Experts",
        "Time Series",
        "Time Series Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07986",
      "abstract": "Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress in text-driven visual generation. However, even state-of-the-art MM-DiT models like FLUX struggle with achieving precise alignment between text prompts and generated content. We identify two key issues in the attention mechanism of MM-DiT, namely 1) the suppression of cross-modal attention due to token imbalance between visual and textual modalities and 2) the lack of timestep-aware attention weighting, which hinder the alignment. To address these issues, we propose \\textbf{Temperature-Adjusted Cross-modal Attention (TACA)}, a parameter-efficient method that dynamically rebalances multimodal interactions through temperature scaling and timestep-dependent adjustment. When combined with LoRA fine-tuning, TACA significantly enhances text-image alignment on the T2I-CompBench benchmark with minimal computational overhead. We tested TACA on state-of-the-art models like FLUX and SD3.5, demonstrating its ability to improve image-text alignment in terms of object appearance, attribute binding, and spatial relationships. Our findings highlight the importance of balancing cross-modal attention in improving semantic fidelity in text-to-image diffusion models. Our codes are publicly available at \\href{https://github.com/Vchitect/TACA}",
      "authors": [
        "Zhengyao Lv",
        "Tianlin Pan",
        "Chenyang Si",
        "Zhaoxi Chen",
        "Wangmeng Zuo",
        "Ziwei Liu",
        "Kwan-Yee K. Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:54:04+00:00",
          "link": "https://arxiv.org/abs/2506.07986v1",
          "size": "30023kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T04:30:58+00:00",
          "link": "https://arxiv.org/abs/2506.07986v2",
          "size": "30023kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T03:45:11+00:00",
          "link": "https://arxiv.org/abs/2506.07986v3",
          "size": "30024kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07986",
        "HTML": "https://arxiv.org/html/2506.07986v3",
        "PDF": "https://arxiv.org/pdf/2506.07986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores improvements in multimodal diffusion transformers for text-driven visual generation, emphasizing attention mechanisms. It does not focus on LLM training data processing."
      },
      "models": [
        {
          "model_path": "ldiex/TACA",
          "downloads": "138",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ldiex/TACA"
        }
      ],
      "tasks": [
        "Attribute"
      ],
      "repo_urls": [
        "https://github.com/vchitect/taca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08274",
      "abstract": "This research addresses the critical lack of comprehensive studies on feature scaling by systematically evaluating 12 scaling techniques - including several less common transformations - across 14 different Machine Learning algorithms and 16 datasets for classification and regression tasks. We meticulously analyzed impacts on predictive performance (using metrics such as accuracy, MAE, MSE, and $R^2$) and computational costs (training time, inference time, and memory usage). Key findings reveal that while ensemble methods (such as Random Forest and gradient boosting models like XGBoost, CatBoost and LightGBM) demonstrate robust performance largely independent of scaling, other widely used models such as Logistic Regression, SVMs, TabNet, and MLPs show significant performance variations highly dependent on the chosen scaler. This extensive empirical analysis, with all source code, experimental results, and model parameters made publicly available to ensure complete transparency and reproducibility, offers model-specific crucial guidance to practitioners on the need for an optimal selection of feature scaling techniques.",
      "authors": [
        "Jo\\~ao Manoel Herrera Pinheiro",
        "Suzana Vilas Boas de Oliveira",
        "Thiago Henrique Segreto Silva",
        "Pedro Antonio Rabelo Saraiva",
        "Enzo Ferreira de Souza",
        "Ricardo V. Godoy",
        "Leonardo Andr\\'e Ambrosio and Marcelo Becker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T22:32:51+00:00",
          "link": "https://arxiv.org/abs/2506.08274v1",
          "size": "8936kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T22:44:11+00:00",
          "link": "https://arxiv.org/abs/2506.08274v2",
          "size": "8665kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T17:23:04+00:00",
          "link": "https://arxiv.org/abs/2506.08274v3",
          "size": "11898kb",
          "version": "v3"
        }
      ],
      "title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08274",
        "HTML": "https://arxiv.org/html/2506.08274v3",
        "PDF": "https://arxiv.org/pdf/2506.08274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies the impact of feature scaling on various machine learning tasks. It does not contribute to any aspect of LLM training data processing."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08735",
      "abstract": "Within the family of convolutional neural networks, InceptionNeXt has shown excellent competitiveness in image classification and a number of downstream tasks. Built on parallel one-dimensional strip convolutions, however, it suffers from limited ability of capturing spatial dependencies along different dimensions and fails to fully explore spatial modeling in local neighborhood. Besides, inherent locality constraints of convolution operations are detrimental to effective global context modeling. To overcome these limitations, we propose a novel backbone architecture termed InceptionMamba in this study. More specifically, the traditional one-dimensional strip convolutions are replaced by orthogonal band convolutions in our InceptionMamba to achieve cohesive spatial modeling. Furthermore, global contextual modeling can be achieved via a bottleneck Mamba module, facilitating enhanced cross-channel information fusion and enlarged receptive field. Extensive evaluations on classification and various downstream tasks demonstrate that the proposed InceptionMamba achieves state-of-the-art performance with superior parameter and computational efficiency. The source code will be available at https://github.com/Wake1021/InceptionMamba.",
      "authors": [
        "Yuhang Wang",
        "Jun Li",
        "Zhijian Wu",
        "Jifeng Shen",
        "Jianhua Xu",
        "Wankou Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T12:31:05+00:00",
          "link": "https://arxiv.org/abs/2506.08735v1",
          "size": "1005kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T07:35:07+00:00",
          "link": "https://arxiv.org/abs/2506.08735v2",
          "size": "1005kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T10:31:35+00:00",
          "link": "https://arxiv.org/abs/2506.08735v3",
          "size": "2246kb",
          "version": "v3"
        }
      ],
      "title": "InceptionMamba: An Efficient Hybrid Network with Large Band Convolution and Bottleneck Mamba",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08735",
        "HTML": "https://arxiv.org/html/2506.08735v3",
        "PDF": "https://arxiv.org/pdf/2506.08735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a new convolutional neural network architecture called InceptionMamba for image classification. It does not involve LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "image-classification",
        "Image Classification",
        "Mamba"
      ],
      "repo_urls": [
        "https://github.com/wake1021/inceptionmamba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08979",
      "abstract": "LiDAR segmentation has emerged as an important task to enrich scene perception and understanding. Range-view-based methods have gained popularity due to their high computational efficiency and compatibility with real-time deployment. However, their generalized performance under adverse weather conditions remains underexplored, limiting their reliability in real-world environments. In this work, we identify and analyze the unique challenges that affect the generalization of range-view LiDAR segmentation in severe weather. To address these challenges, we propose a modular and lightweight framework that enhances robustness without altering the core architecture of existing models. Our method reformulates the initial stem block of standard range-view networks into two branches to process geometric attributes and reflectance intensity separately. Specifically, a Geometric Abnormality Suppression (GAS) module reduces the influence of weather-induced spatial noise, and a Reflectance Distortion Calibration (RDC) module corrects reflectance distortions through memory-guided adaptive instance normalization. The processed features are then fused and passed to the original segmentation pipeline. Extensive experiments on different benchmarks and baseline models demonstrate that our approach significantly improves generalization to adverse weather with minimal inference overhead, offering a practical and effective solution for real-world LiDAR segmentation.",
      "authors": [
        "Longyu Yang",
        "Lu Zhang",
        "Jun Liu",
        "Yap-Peng Tan",
        "Heng Tao Shen",
        "Xiaofeng Zhu",
        "Ping Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T16:48:27+00:00",
          "link": "https://arxiv.org/abs/2506.08979v1",
          "size": "4564kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:32:38+00:00",
          "link": "https://arxiv.org/abs/2506.08979v2",
          "size": "1390kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Range-View LiDAR Segmentation in Adverse Weather",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08979",
        "HTML": "https://arxiv.org/html/2506.08979v2",
        "PDF": "https://arxiv.org/pdf/2506.08979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on LiDAR segmentation in adverse weather, proposing a framework for enhancing robustness. It does not address LLM training data processing or related tasks like dataset creation or data quality improvement for language models."
      },
      "tasks": [
        "Computational Efficiency",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09859",
      "abstract": "In this paper, we propose a novel hierarchical framework for robot navigation in dynamic environments with heterogeneous constraints. Our approach leverages a graph neural network trained via reinforcement learning (RL) to efficiently estimate the robot's cost-to-go, formulated as local goal recommendations. A spatio-temporal path-searching module, which accounts for kinematic constraints, is then employed to generate a reference trajectory to facilitate solving the non-convex optimization problem used for explicit constraint enforcement. More importantly, we introduce an incremental action-masking mechanism and a privileged learning strategy, enabling end-to-end training of the proposed planner. Both simulation and real-world experiments demonstrate that the proposed method effectively addresses local planning in complex dynamic environments, achieving state-of-the-art (SOTA) performance. Compared with existing learning-optimization hybrid methods, our approach eliminates the dependency on high-fidelity simulation environments, offering significant advantages in computational efficiency and training scalability. The code will be released as open-source upon acceptance of the paper.",
      "authors": [
        "Huajian Liu",
        "Yixuan Feng",
        "Wei Dong",
        "Kunpeng Fan",
        "Chao Wang and Yongzhuo Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T15:31:25+00:00",
          "link": "https://arxiv.org/abs/2506.09859v1",
          "size": "4827kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:56:08+00:00",
          "link": "https://arxiv.org/abs/2506.09859v2",
          "size": "6186kb",
          "version": "v2"
        }
      ],
      "title": "Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09859",
        "HTML": "https://arxiv.org/html/2506.09859v2",
        "PDF": "https://arxiv.org/pdf/2506.09859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a hierarchical framework for robot navigation, emphasizing a learning-enhanced approach to enhance efficiency and planning in dynamic environments. It is not related to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/TIB-K330/HALO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10533",
      "abstract": "The flow of incompressible fluid in highly permeable porous media in vorticity - velocity - Bernoulli pressure form leads to a double saddle-point problem in the Navier--Stokes--Brinkman--Forchheimer equations. The paper establishes, for small sources, the existence of solutions on the continuous and discrete level of lowest-order piecewise divergence-free Crouzeix--Raviart finite elements. The vorticity employs a vector version of the pressure space with normal and tangential velocity jump penalisation terms. A simple Raviart--Thomas interpolant leads to pressure-robust a priori error estimates. An explicit residual-based a posteriori error estimate allows for efficient and reliable a posteriori error control. The efficiency for the Forchheimer nonlinearity requires a novel discrete inequality of independent interest. The implementation is based upon a light-weight forest-of-trees data structure handled by a highly parallel set of adaptive mesh refining algorithms. Numerical simulations reveal robustness of the a posteriori error estimates and improved convergence rates by adaptive mesh-refining.",
      "authors": [
        "Santiago Badia and Carsten Carstensen and Alberto F. Martin and Ricardo Ruiz-Baier and Segundo Villa-Fuentes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T10:00:38+00:00",
          "link": "https://arxiv.org/abs/2506.10533v1",
          "size": "1423kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:28:24+00:00",
          "link": "https://arxiv.org/abs/2506.10533v2",
          "size": "1423kb",
          "version": "v2"
        }
      ],
      "title": "A velocity-vorticity-pressure formulation for the steady Navier--Stokes--Brinkman--Forchheimer problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10533",
        "HTML": "https://arxiv.org/html/2506.10533v2",
        "PDF": "https://arxiv.org/pdf/2506.10533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with numerical simulations and formulations of the Navier--Stokes--Brinkman--Forchheimer problem, focusing on fluid flow in porous media. It does not involve LLM data processing or dataset development for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12404",
      "abstract": "Deep learning has significantly propelled the performance of ECG arrhythmia classification, yet its clinical adoption remains hindered by challenges in interpretability and deployment on resource-constrained edge devices. To bridge this gap, we propose EXGnet, a novel and reliable ECG arrhythmia classification network tailored for single-lead signals, specifically designed to balance high accuracy, explainability, and edge compatibility. EXGnet integrates XAI supervision during training via a normalized cross-correlation based loss, directing the model's attention to clinically relevant ECG regions, similar to a cardiologist's focus. This supervision is driven by automatically generated ground truth, derived through an innovative heart rate variability-based approach, without the need for manual annotation. To enhance classification accuracy without compromising deployment simplicity, we incorporate quantitative ECG features during training. These enrich the model with multi-domain knowledge but are excluded during inference, keeping the model lightweight for edge deployment. Additionally, we introduce an innovative multiresolution block to efficiently capture both short and long-term signal features while maintaining computational efficiency. Rigorous evaluation on the Chapman and Ningbo benchmark datasets validates the supremacy of EXGnet, which achieves average five-fold accuracies of 98.762% and 96.932%, and F1-scores of 97.910% and 95.527%, respectively. Comprehensive ablation studies and both quantitative and qualitative interpretability assessment confirm that the XAI guidance is pivotal, demonstrably enhancing the model's focus and trustworthiness. Overall, EXGnet sets a new benchmark by combining high-performance arrhythmia classification with interpretability, paving the way for more trustworthy and accessible portable ECG based health monitoring systems.",
      "authors": [
        "Tushar Talukder Showrav",
        "Soyabul Islam Lincoln",
        "Md. Kamrul Hasan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T08:48:44+00:00",
          "link": "https://arxiv.org/abs/2506.12404v1",
          "size": "1670kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:58:51+00:00",
          "link": "https://arxiv.org/abs/2506.12404v2",
          "size": "7783kb",
          "version": "v2"
        }
      ],
      "title": "EXGnet: a single-lead explainable-AI guided multiresolution network with train-only quantitative features for trustworthy ECG arrhythmia classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12404",
        "HTML": "https://arxiv.org/html/2506.12404v2",
        "PDF": "https://arxiv.org/pdf/2506.12404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The EXGnet paper focuses on ECG arrhythmia classification with a new network designed for single-lead ECG signals, emphasizing explainable AI and edge compatibility. It is unrelated to data processing for LLMs or related data improvement methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13343",
      "abstract": "User-level stance detection (UserSD) remains challenging due to the lack of high-quality benchmarks that jointly capture linguistic and social structure. In this paper, we introduce TwiUSD, the first large-scale, manually annotated UserSD benchmark with explicit followee relationships, containing 16,211 users and 47,757 tweets. TwiUSD enables rigorous evaluation of stance models by integrating tweet content and social links, with superior scale and annotation quality. Building on this resource, we propose MRFG: a structure-aware framework that uses LLM-based relevance filtering and feature routing to address noise and context heterogeneity. MRFG employs multi-scale filtering and adaptively routes features through graph neural networks or multi-layer perceptrons based on topological informativeness. Experiments show MRFG consistently outperforms strong baselines (including PLMs, graph-based models, and LLM prompting) in both in-target and cross-target evaluation.",
      "authors": [
        "Fuqiang Niu",
        "Zini Chen",
        "Zhiyu Xie",
        "Hu Huang",
        "Genan Dai and Bowen Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T10:33:47+00:00",
          "link": "https://arxiv.org/abs/2506.13343v1",
          "size": "1552kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:36:06+00:00",
          "link": "https://arxiv.org/abs/2506.13343v2",
          "size": "1552kb",
          "version": "v2"
        }
      ],
      "title": "TwiUSD: A Benchmark Dataset and Structure-Aware LLM Framework for User Stance Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13343",
        "HTML": "https://arxiv.org/html/2506.13343v2",
        "PDF": "https://arxiv.org/pdf/2506.13343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces TwiUSD, a dataset for user stance detection, and proposes a structure-aware framework using LLMs for relevance filtering. While it involves some data processing for stance detection, its primary focus is on model framework and evaluation, not on LLM training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15239",
      "abstract": "In this paper, we evaluate the capacity of current language technologies to understand Basque and Spanish language varieties. We use Natural Language Inference (NLI) as a pivot task and introduce a novel, manually-curated parallel dataset in Basque and Spanish, along with their respective variants. Our empirical analysis of crosslingual and in-context learning experiments using encoder-only and decoder-based Large Language Models (LLMs) shows a performance drop when handling linguistic variation, especially in Basque. Error analysis suggests that this decline is not due to lexical overlap, but rather to the linguistic variation itself. Further ablation experiments indicate that encoder-only models particularly struggle with Western Basque, which aligns with linguistic theory that identifies peripheral dialects (e.g., Western) as more distant from the standard. All data and code are publicly available.",
      "authors": [
        "Jaione Bengoetxea",
        "Itziar Gonzalez-Dios",
        "Rodrigo Agerri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T08:20:19+00:00",
          "link": "https://arxiv.org/abs/2506.15239v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:37:11+00:00",
          "link": "https://arxiv.org/abs/2506.15239v2",
          "size": "193kb",
          "version": "v2"
        }
      ],
      "title": "Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15239",
        "HTML": "https://arxiv.org/html/2506.15239v2",
        "PDF": "https://arxiv.org/pdf/2506.15239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a parallel dataset in Basque and Spanish for evaluating linguistic variation in NLI tasks, but it mainly focuses on evaluating language model performance. The dataset aspect is relevant, but the study's primary focus is not on improving LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "HiTZ/XNLIvar",
          "downloads": "52",
          "likes": "0",
          "link": "https://huggingface.co/datasets/HiTZ/XNLIvar"
        }
      ],
      "tasks": [
        "Decoder",
        "In-Context Learning",
        "Natural Language Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15606",
      "abstract": "Large Language Models (LLMs) have become indispensable in real-world applications. However, their widespread adoption raises significant safety concerns, particularly in responding to socially harmful questions. Despite substantial efforts to improve model safety through alignment, aligned models can still have their safety protections undermined by subsequent fine-tuning - even when the additional training data appears benign. In this paper, we empirically demonstrate that this vulnerability stems from the sensitivity of safety-critical low-rank subspaces in LLM parameters to fine-tuning. Building on this insight, we propose a novel training-free method, termed Low-Rank Extrapolation (LoX), to enhance safety robustness by extrapolating the safety subspace of an aligned LLM. Our experimental results confirm the effectiveness of LoX, demonstrating significant improvements in robustness against both benign and malicious fine-tuning attacks while preserving the model's adaptability to new tasks. For instance, LoX leads to 11% to 54% absolute reductions in attack success rates (ASR) facing benign or malicious fine-tuning attacks. By investigating the ASR landscape of parameters, we attribute the success of LoX to that the extrapolation moves LLM parameters to a flatter zone, thereby less sensitive to perturbations. The code is available at github.com/VITA-Group/LoX.",
      "authors": [
        "Gabriel J. Perin",
        "Runjin Chen",
        "Xuxi Chen",
        "Nina S. T. Hirata",
        "Zhangyang Wang",
        "Junyuan Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T16:30:02+00:00",
          "link": "https://arxiv.org/abs/2506.15606v1",
          "size": "745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T16:48:01+00:00",
          "link": "https://arxiv.org/abs/2506.15606v2",
          "size": "746kb",
          "version": "v2"
        }
      ],
      "title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15606",
        "HTML": "https://arxiv.org/html/2506.15606v2",
        "PDF": "https://arxiv.org/pdf/2506.15606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing the safety robustness of LLMs using a training-free method called Low-Rank Extrapolation. It addresses safety concerns related to fine-tuning but does not contribute to LLM training data processing techniques."
      },
      "tasks": [
        "Attribute"
      ],
      "repo_urls": [
        "https://github.com/vita-group/lox"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15610",
      "abstract": "Open-vocabulary 3D object detection has gained significant interest due to its critical applications in autonomous driving and embodied AI. Existing detection methods, whether offline or online, typically rely on dense point cloud reconstruction, which imposes substantial computational overhead and memory constraints, hindering real-time deployment in downstream tasks. To address this, we propose a novel reconstruction-free online framework tailored for memory-efficient and real-time 3D detection. Specifically, given streaming posed RGB-D video input, we leverage Cubify Anything as a pre-trained visual foundation model (VFM) for single-view 3D object detection by bounding boxes, coupled with CLIP to capture open-vocabulary semantics of detected objects. To fuse all detected bounding boxes across different views into a unified one, we employ an association module for correspondences of multi-views and an optimization module to fuse the 3D bounding boxes of the same instance predicted in multi-views. The association module utilizes 3D Non-Maximum Suppression (NMS) and a box correspondence matching module, while the optimization module uses an IoU-guided efficient random optimization technique based on particle filtering to enforce multi-view consistency of the 3D bounding boxes while minimizing computational complexity. Extensive experiments on ScanNetV2 and CA-1M datasets demonstrate that our method achieves state-of-the-art performance among online methods. Benefiting from this novel reconstruction-free paradigm for 3D object detection, our method exhibits great generalization abilities in various scenarios, enabling real-time perception even in environments exceeding 1000 square meters.",
      "authors": [
        "Yuqing Lan",
        "Chenyang Zhu",
        "Zhirui Gao",
        "Jiazhao Zhang",
        "Yihan Cao",
        "Renjiao Yi",
        "Yijie Wang",
        "Kai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T16:40:05+00:00",
          "link": "https://arxiv.org/abs/2506.15610v1",
          "size": "11185kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:38:09+00:00",
          "link": "https://arxiv.org/abs/2506.15610v2",
          "size": "11181kb",
          "version": "v2"
        }
      ],
      "title": "BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15610",
        "HTML": "https://arxiv.org/html/2506.15610v2",
        "PDF": "https://arxiv.org/pdf/2506.15610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for 3D object detection using RGB-D videos, focusing on reducing computational overhead in detection tasks. It does not address any aspects of LLM training data processing."
      },
      "tasks": [
        "3D Object Detection",
        "Autonomous Driving",
        "object-detection",
        "Object Detection",
        "Point cloud reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16383",
      "abstract": "Argument Mining (AM), a critical subfield of Natural Language Processing (NLP), focuses on extracting argumentative structures from text. The advent of Large Language Models (LLMs) has profoundly transformed AM, enabling advanced in-context learning, prompt-based generation, and robust cross-domain adaptability. This survey systematically synthesizes recent advancements in LLM-driven AM. We provide a concise review of foundational theories and annotation frameworks, alongside a meticulously curated catalog of datasets. A key contribution is our comprehensive taxonomy of AM subtasks, elucidating how contemporary LLM techniques -- such as prompting, chain-of-thought reasoning, and retrieval augmentation -- have reconfigured their execution. We further detail current LLM architectures and methodologies, critically assess evaluation practices, and delineate pivotal challenges including long-context reasoning, interpretability, and annotation bottlenecks. Conclusively, we highlight emerging trends and propose a forward-looking research agenda for LLM-based computational argumentation, aiming to strategically guide researchers in this rapidly evolving domain.",
      "authors": [
        "Hao Li",
        "Viktor Schlegel",
        "Yizheng Sun",
        "Riza Batista-Navarro",
        "Goran Nenadic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T15:12:58+00:00",
          "link": "https://arxiv.org/abs/2506.16383v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:25:12+00:00",
          "link": "https://arxiv.org/abs/2506.16383v2",
          "size": "249kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:45:07+00:00",
          "link": "https://arxiv.org/abs/2506.16383v3",
          "size": "386kb",
          "version": "v3"
        }
      ],
      "title": "Large Language Models in Argument Mining: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16383",
        "HTML": "https://arxiv.org/html/2506.16383v3",
        "PDF": "https://arxiv.org/pdf/2506.16383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys advancements in Argument Mining facilitated by LLMs, with an emphasis on datasets and techniques that have impacted argument mining. While datasets are discussed, the focus is primarily on LLM methodologies and their application in argument mining rather than on data processing specifically for LLM training."
      },
      "tasks": [
        "Argument Mining",
        "In-Context Learning",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16596",
      "abstract": "The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.",
      "authors": [
        "Vinay K Chaudhri",
        "Chaitan Baru",
        "Brandon Bennett",
        "Mehul Bhatt",
        "Darion Cassel",
        "Anthony G Cohn",
        "Rina Dechter",
        "Esra Erdem",
        "Dave Ferrucci",
        "Ken Forbus",
        "Gregory Gelfond",
        "Michael Genesereth",
        "Andrew S. Gordon",
        "Benjamin Grosof",
        "Gopal Gupta",
        "Jim Hendler",
        "Sharat Israni",
        "Tyler R. Josephson",
        "Patrick Kyllonen",
        "Yuliya Lierler",
        "Vladimir Lifschitz",
        "Clifton McFate",
        "Hande K. McGinty",
        "Leora Morgenstern",
        "Alessandro Oltramari",
        "Praveen Paritosh",
        "Dan Roth",
        "Blake Shepard",
        "Cogan Shimzu",
        "Denny Vrande\\v{c}i\\'c",
        "Mark Whiting",
        "Michael Witbrock"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T20:51:28+00:00",
          "link": "https://arxiv.org/abs/2506.16596v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T23:03:41+00:00",
          "link": "https://arxiv.org/abs/2506.16596v2",
          "size": "30kb",
          "version": "v2"
        }
      ],
      "title": "A Community-driven vision for a new Knowledge Resource for AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16596",
        "HTML": "https://arxiv.org/html/2506.16596v2",
        "PDF": "https://arxiv.org/pdf/2506.16596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a vision for a new knowledge resource infrastructure for AI, focusing on knowledge representation, reasoning, and social structures. It does not address LLM training data processing or operations related to improving or creating new datasets specifically for LLMs."
      },
      "tasks": [
        "Knowledge Graphs",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16622",
      "abstract": "Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
      "authors": [
        "Jiaxin Pei",
        "Dustin Wright",
        "Isabelle Augenstein and David Jurgens"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T21:49:28+00:00",
          "link": "https://arxiv.org/abs/2506.16622v1",
          "size": "461kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T18:13:52+00:00",
          "link": "https://arxiv.org/abs/2506.16622v2",
          "size": "461kb",
          "version": "v2"
        }
      ],
      "title": "Modeling Public Perceptions of Science in Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16622",
        "HTML": "https://arxiv.org/html/2506.16622v2",
        "PDF": "https://arxiv.org/pdf/2506.16622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset for modeling public perceptions of science in media, which includes annotations for NLP model prediction. Although it contributes a dataset, its focus is on public perception modeling rather than directly on LLM training data processing techniques."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.17286",
      "abstract": "Attention mechanisms underpin the success of large language models (LLMs), yet their substantial computational and memory overhead poses challenges for optimizing efficiency and performance. A critical bottleneck arises as KV cache and attention computations scale rapidly with text length, challenging deployment on hardware with limited computational and memory resources. We observe that attention mechanisms exhibit substantial redundancy, since the KV cache can be significantly compressed and attention maps across heads display high similarity, revealing that much of the computation and storage is unnecessary. Leveraging these insights, we propose \\textbf{G}rouped-Head Laten\\textbf{T} \\textbf{A}ttention (GTA), a novel attention mechanism that reduces memory usage and computational complexity while maintaining performance. GTA comprises two components: (1) a shared attention map mechanism that reuses attention scores across multiple heads, decreasing the key cache size; and (2) a nonlinear value decoder with learned projections that compresses the value cache into a latent space, further cutting memory needs. GTA cuts attention computation FLOPs by up to \\emph{62.5\\%} versus Grouped-Query Attention and shrink the KV cache by up to \\emph{70\\%}, all while avoiding the extra overhead of Multi-Head Latent Attention to improve LLM deployment efficiency. Consequently, GTA models achieve a \\emph{2x} increase in end-to-end inference speed, with prefill benefiting from reduced computational cost and decoding benefiting from the smaller cache footprint.",
      "authors": [
        "Luoyang Sun",
        "Cheng Deng",
        "Jiwen Jiang",
        "Xinjian Wu",
        "Haifeng Zhang",
        "Lei Chen",
        "Lionel Ni",
        "Jun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T07:19:33+00:00",
          "link": "https://arxiv.org/abs/2506.17286v1",
          "size": "7832kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:57:32+00:00",
          "link": "https://arxiv.org/abs/2506.17286v2",
          "size": "7832kb",
          "version": "v2"
        }
      ],
      "title": "GTA: Grouped-head latenT Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17286",
        "HTML": "https://arxiv.org/html/2506.17286v2",
        "PDF": "https://arxiv.org/pdf/2506.17286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel attention mechanism (GTA) to improve computational efficiency in LLMs but does not address data processing or dataset creation specifically for LLM training. The focus is on model architecture optimization rather than training data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21427",
      "abstract": "Generative models such as diffusion and flow-matching offer expressive policies for offline reinforcement learning (RL) by capturing rich, multimodal action distributions, but their iterative sampling introduces high inference costs and training instability due to gradient propagation across sampling steps. We propose the \\textit{Single-Step Completion Policy} (SSCP), a generative policy trained with an augmented flow-matching objective to predict direct completion vectors from intermediate flow samples, enabling accurate, one-shot action generation. In an off-policy actor-critic framework, SSCP combines the expressiveness of generative models with the training and inference efficiency of unimodal policies, without requiring long backpropagation chains. Our method scales effectively to offline, offline-to-online, and online RL settings, offering substantial gains in speed and adaptability over diffusion-based baselines. We further extend SSCP to goal-conditioned RL, enabling flat policies to exploit subgoal structures without explicit hierarchical inference. SSCP achieves strong results across standard offline RL and behavior cloning benchmarks, positioning it as a versatile, expressive, and efficient framework for deep RL and sequential decision-making.",
      "authors": [
        "Prajwal Koirala",
        "Cody Fleming"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:09:53+00:00",
          "link": "https://arxiv.org/abs/2506.21427v1",
          "size": "5229kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T17:30:42+00:00",
          "link": "https://arxiv.org/abs/2506.21427v2",
          "size": "5229kb",
          "version": "v2"
        }
      ],
      "title": "Flow-Based Single-Step Completion for Efficient and Expressive Policy Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21427",
        "HTML": "https://arxiv.org/html/2506.21427v2",
        "PDF": "https://arxiv.org/pdf/2506.21427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generative models for reinforcement learning and proposes a single-step completion policy for efficiency in policy learning. It does not address LLM training data processing or involve creating or enhancing datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00358",
      "abstract": "We study reinforcement learning (RL) for the same class of continuous-time stochastic linear--quadratic (LQ) control problems as in \\cite{huang2024sublinear}, where volatilities depend on both states and controls while states are scalar-valued and running control rewards are absent. We propose a model-free, data-driven exploration mechanism that adaptively adjusts entropy regularization by the critic and policy variance by the actor. Unlike the constant or deterministic exploration schedules employed in \\cite{huang2024sublinear}, which require extensive tuning for implementations and ignore learning progresses during iterations, our adaptive exploratory approach boosts learning efficiency with minimal tuning. Despite its flexibility, our method achieves a sublinear regret bound that matches the best-known model-free results for this class of LQ problems, which were previously derived only with fixed exploration schedules. Numerical experiments demonstrate that adaptive explorations accelerate convergence and improve regret performance compared to the non-adaptive model-free and model-based counterparts.",
      "authors": [
        "Yilie Huang and Xun Yu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T01:09:06+00:00",
          "link": "https://arxiv.org/abs/2507.00358v1",
          "size": "4632kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:00:39+00:00",
          "link": "https://arxiv.org/abs/2507.00358v2",
          "size": "2181kb",
          "version": "v2"
        }
      ],
      "title": "Data-Driven Exploration for a Class of Continuous-Time Indefinite Linear--Quadratic Reinforcement Learning Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00358",
        "HTML": "https://arxiv.org/html/2507.00358v2",
        "PDF": "https://arxiv.org/pdf/2507.00358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on reinforcement learning for stochastic linear-quadratic control problems and proposes a model-free exploration mechanism. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00748",
      "abstract": "Recently, Multimodal Large Language Models (MLLMs) excel at visual grounding in single-image scenarios with textual references. However, their performance degrades when handling real-world applications that involve complex multi-image compositions and multi-modal instructions, revealing limitations in cross-image reasoning and generalization. To address these challenges, we adopt a Reinforcement Learning (RL) based post-training strategy to improve the reasoning of MLLMs in multi-image grounding tasks. Our approach begins with synthesizing high-quality chain-of-thought (CoT) data for cold-start initialization, followed by supervised fine-tuning (SFT) using low-rank adaptation (LoRA). The cold-start training stage enables the model to identify correct solutions. Subsequently, we perform rejection sampling using the merged SFT model to curate high-quality RL data and leverage rule-based RL to guide the model toward optimal reasoning paths. Extensive experimental results demonstrate the effectiveness of our approach, yielding improvements of +9.04% on MIG-Bench, +6.37% on MC-Bench, and +4.98% on several out-of-domain reasoning grounding benchmarks compared to the SFT baseline. Furthermore, our method exhibits strong generalization in multi-image perception, with gains of +3.1% and +2.4% over the base model on BLINK and MMIU benchmarks, respectively.",
      "authors": [
        "Bob Zhang",
        "Haoran Li",
        "Tao Zhang",
        "Cilin Yan",
        "Jiayin Cai",
        "Yanbin Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T13:48:57+00:00",
          "link": "https://arxiv.org/abs/2507.00748v1",
          "size": "431kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:23:35+00:00",
          "link": "https://arxiv.org/abs/2507.00748v2",
          "size": "828kb",
          "version": "v2"
        }
      ],
      "title": "Improving the Reasoning of Multi-Image Grounding in MLLMs via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00748",
        "HTML": "https://arxiv.org/html/2507.00748v2",
        "PDF": "https://arxiv.org/pdf/2507.00748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper applies reinforcement learning and synthesis of chain-of-thought data for post-training MLLMs in multi-image grounding tasks. It briefly uses data synthesis for model improvement but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00782",
      "abstract": "In this paper, we study a functional programming approach to natural language semantics, allowing us to increase the expressiveness of a more traditional denotation style. We will formalize a category based type and effect system to represent the semantic difference between syntactically equivalent expressions. We then construct a diagrammatic calculus to model parsing and handling of effects, providing a method to efficiently compute the denotations for sentences.",
      "authors": [
        "Matthieu Pierre Boyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T14:21:20+00:00",
          "link": "https://arxiv.org/abs/2507.00782v1",
          "size": "586kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T12:07:49+00:00",
          "link": "https://arxiv.org/abs/2507.00782v2",
          "size": "396kb",
          "version": "v2"
        }
      ],
      "title": "A Diagrammatic Calculus for a Functional Model of Natural Language Semantics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00782",
        "PDF": "https://arxiv.org/pdf/2507.00782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a functional programming approach to natural language semantics, with a focus on modeling and calculating denotations for sentences. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01630",
      "abstract": "The task of Human-Object conTact (HOT) detection involves identifying the specific areas of the human body that are touching objects. Nevertheless, current models are restricted to just one type of image, often leading to too much segmentation in areas with little interaction, and struggling to maintain category consistency within specific regions. To tackle this issue, a HOT framework, termed \\textbf{P3HOT}, is proposed, which blends \\textbf{P}rompt guidance and human \\textbf{P}roximal \\textbf{P}erception. To begin with, we utilize a semantic-driven prompt mechanism to direct the network's attention towards the relevant regions based on the correlation between image and text. Then a human proximal perception mechanism is employed to dynamically perceive key depth range around the human, using learnable parameters to effectively eliminate regions where interactions are not expected. Calculating depth resolves the uncertainty of the overlap between humans and objects in a 2D perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss (RJLoss) has been created as a new loss to inhibit abnormal categories in the same area. A new evaluation metric called ``AD-Acc.'' is introduced to address the shortcomings of existing methods in addressing negative samples. Comprehensive experimental results demonstrate that our approach achieves state-of-the-art performance in four metrics across two benchmark datasets. Specifically, our model achieves an improvement of \\textbf{0.7}$\\uparrow$, \\textbf{2.0}$\\uparrow$, \\textbf{1.6}$\\uparrow$, and \\textbf{11.0}$\\uparrow$ in SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated dataset. The sources code are available at https://github.com/YuxiaoWang-AI/P3HOT.",
      "authors": [
        "Yuxiao Wang",
        "Yu Lei",
        "Zhenao Wei",
        "Weiying Xue",
        "Xinyu Jiang",
        "Nan Zhuang",
        "Qi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T11:59:32+00:00",
          "link": "https://arxiv.org/abs/2507.01630v1",
          "size": "5458kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:22:32+00:00",
          "link": "https://arxiv.org/abs/2507.01630v2",
          "size": "5459kb",
          "version": "v2"
        }
      ],
      "title": "Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01630",
        "HTML": "https://arxiv.org/html/2507.01630v2",
        "PDF": "https://arxiv.org/pdf/2507.01630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for Human-Object contact detection using prompt guidance and perception mechanisms. It focuses on image processing for object detection and does not address LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01955",
      "abstract": "Multimodal foundation models, such as GPT-4o, have recently made remarkable progress, but it is not clear where exactly these models stand in terms of understanding vision. In this paper, we benchmark the performance of popular multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0 Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision tasks (semantic segmentation, object detection, image classification, depth and surface normal prediction) using established datasets (e.g., COCO, ImageNet and its variants, etc).\n  The main challenges to performing this are: 1) most models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and 2) many leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via prompt chaining to create a standardized benchmarking framework.\n  We observe that 1) the models are not close to the state-of-the-art specialist models at any task. However, 2) they are respectable generalists; this is remarkable as they are presumably trained on primarily image-text-based tasks. 3) They perform semantic tasks notably better than geometric ones. 4) While the prompt-chaining techniques affect performance, better models exhibit less sensitivity to prompt variations. 5) GPT-4o performs the best among non-reasoning models, securing the top position in 4 out of 6 tasks, 6) reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a preliminary analysis of models with native image generation, like the latest GPT-4o, shows they exhibit quirks like hallucinations and spatial misalignments.",
      "authors": [
        "Rahul Ramachandran",
        "Ali Garjani",
        "Roman Bachmann",
        "Andrei Atanov",
        "O\\u{g}uzhan Fatih Kar",
        "Amir Zamir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:59:07+00:00",
          "link": "https://arxiv.org/abs/2507.01955v1",
          "size": "47029kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:52:38+00:00",
          "link": "https://arxiv.org/abs/2507.01955v2",
          "size": "47030kb",
          "version": "v2"
        }
      ],
      "title": "How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01955",
        "PDF": "https://arxiv.org/pdf/2507.01955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates multimodal foundation models on computer vision tasks. It discusses translating vision tasks into text-promptable tasks but does not cover any training data processing elements relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02591",
      "abstract": "The challenge of long video understanding lies in its high computational complexity and prohibitive memory cost, since the memory and computation required by transformer-based LLMs scale quadratically with input sequence length. We propose AuroraLong to address this challenge by replacing the LLM component in MLLMs with a linear RNN language model that handles input sequence of arbitrary length with constant-size hidden states. To further increase throughput and efficiency, we combine visual token merge with linear RNN models by reordering the visual tokens by their sizes in ascending order. Despite having only 2B parameters and being trained exclusively on public data, AuroraLong achieves performance comparable to Transformer-based models of similar size trained on private datasets across multiple video benchmarks. This demonstrates the potential of efficient, linear RNNs to democratize long video understanding by lowering its computational entry barrier. To our best knowledge, we are the first to use a linear RNN based LLM backbone in a LLaVA-like model for open-ended video understanding.",
      "authors": [
        "Weili Xu",
        "Enxin Song",
        "Wenhao Chai",
        "Xuexiang Wen",
        "Tian Ye",
        "Gaoang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:55:16+00:00",
          "link": "https://arxiv.org/abs/2507.02591v1",
          "size": "2245kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T05:05:19+00:00",
          "link": "https://arxiv.org/abs/2507.02591v2",
          "size": "2222kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T07:25:27+00:00",
          "link": "https://arxiv.org/abs/2507.02591v3",
          "size": "376kb",
          "version": "v3"
        }
      ],
      "title": "AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02591",
        "HTML": "https://arxiv.org/html/2507.02591v3",
        "PDF": "https://arxiv.org/pdf/2507.02591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents AuroraLong, a model using linear RNNs for video understanding. It focuses on model efficiencies rather than LLM training data processing aspects such as dataset creation or data quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03038",
      "abstract": "Next token prediction paradigm has been prevailing for autoregressive models in the era of LLMs. The current default sampling choice for popular LLMs is temperature scaling together with nucleus sampling to balance diversity and coherence. Nevertheless, such approach leads to inferior performance in various NLP tasks when the model is not certain about testing questions. To this end, we propose a brand new training-free decoding strategy, dubbed as Cautious Next Token Prediction (CNTP). In the decoding process, if the model has comparatively high prediction entropy at a certain step, we sample multiple trials starting from the step independently and stop when encountering any punctuation. Then we select the trial with the lowest perplexity score viewed as the most probable and reliable trial path given the model's capacity. The trial number is negatively correlated with the prediction confidence, i.e., the less confident the model is, the more trials it should sample. This is consistent with human beings' behaviour: when feeling uncertain or unconfident, one tends to think more creatively, exploring multiple thinking paths, to cautiously select the path one feels most confident about. Extensive experiments on both LLMs and MLLMs show that our proposed CNTP approach outperforms existing standard decoding strategies consistently by a clear margin. Moreover, the integration of CNTP with self consistency can further improve over vanilla self consistency. We believe our proposed CNTP has the potential to become one of the default choices for LLM decoding. Code is available at https://github.com/wyzjack/CNTP.",
      "authors": [
        "Yizhou Wang",
        "Lingzhi Zhang",
        "Yue Bai",
        "Mang Tik Chiu",
        "Zhengmian Hu",
        "Mingyuan Zhang",
        "Qihua Dong",
        "Yu Yin",
        "Sohrab Amirghodsi and Yun Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:49:18+00:00",
          "link": "https://arxiv.org/abs/2507.03038v1",
          "size": "1312kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.03038v2",
          "size": "1312kb",
          "version": "v2"
        }
      ],
      "title": "Cautious Next Token Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03038",
        "HTML": "https://arxiv.org/html/2507.03038v2",
        "PDF": "https://arxiv.org/pdf/2507.03038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new decoding strategy for next token prediction, but it does not engage with data processing for LLM training or fine-tuning datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03256",
      "abstract": "Talking head generation with arbitrary identities and speech audio remains a crucial problem in the realm of the virtual metaverse. Recently, diffusion models have become a popular generative technique in this field with their strong generation capabilities. However, several challenges remain for diffusion-based methods: 1) inefficient inference and visual artifacts caused by the implicit latent space of Variational Auto-Encoders (VAE), which complicates the diffusion process; 2) a lack of authentic facial expressions and head movements due to inadequate multi-modal information fusion. In this paper, MoDA handles these challenges by: 1) defining a joint parameter space that bridges motion generation and neural rendering, and leveraging flow matching to simplify diffusion learning; 2) introducing a multi-modal diffusion architecture to model the interaction among noisy motion, audio, and auxiliary conditions, enhancing overall facial expressiveness. In addition, a coarse-to-fine fusion strategy is employed to progressively integrate different modalities, ensuring effective feature fusion. Experimental results demonstrate that MoDA improves video diversity, realism, and efficiency, making it suitable for real-world applications. Project Page: https://lixinyyang.github.io/MoDA.github.io/",
      "authors": [
        "Xinyang Li",
        "Gen Li",
        "Zhihui Lin",
        "Yichen Qian",
        "GongXin Yao",
        "Weinan Jia",
        "Aowen Wang",
        "Weihua Chen",
        "Fan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T02:25:10+00:00",
          "link": "https://arxiv.org/abs/2507.03256v1",
          "size": "4613kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:07:10+00:00",
          "link": "https://arxiv.org/abs/2507.03256v2",
          "size": "9346kb",
          "version": "v2"
        }
      ],
      "title": "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03256",
        "HTML": "https://arxiv.org/html/2507.03256v2",
        "PDF": "https://arxiv.org/pdf/2507.03256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the MoDA architecture for talking head generation using diffusion models, focusing on multi-modal fusion, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03379",
      "abstract": "A classical approach to the Calder\\'on problem is to estimate the unknown conductivity by solving a nonlinear least-squares problem. It is generally believed that it leads to a nonconvex optimization problem which is riddled with bad local minimums. This has motivated the development of reconstruction methods based on convex optimization, one recent contribution being the nonlinear convex semidefinite programming approach of Harrach (2023). In this work, we investigate the computational viability of this convex approach in a simple setting where the conductivities are piecewise constant and radial. We implement this convex reconstruction method and compare it extensively to the least squares approach. Our experiments suggest that this convex programming approach only allows to accurately estimate the unknown for problems with a very small size. Moreover, surprisingly, it is consistently outperformed by Newton-type least squares solvers, which are also faster and require less measurements. We revisit the issue of nonconvexity in this piecewise constant radial setting and prove that, contrary to previous claims, there are no local minimums in the case of two scalar unknowns with no measurement noise. We also provide a partial proof of this result in the general setting which holds under a numerically verifiable assumption.",
      "authors": [
        "Giovanni S. Alberti",
        "Romain Petit",
        "Clarice Poon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T08:23:43+00:00",
          "link": "https://arxiv.org/abs/2507.03379v1",
          "size": "336kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:27:46+00:00",
          "link": "https://arxiv.org/abs/2507.03379v2",
          "size": "336kb",
          "version": "v2"
        }
      ],
      "title": "On the non-convexity issue in the radial Calder\\'on problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03379",
        "HTML": "https://arxiv.org/html/2507.03379v2",
        "PDF": "https://arxiv.org/pdf/2507.03379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a nonconvex optimization problem in the setting of radial Calder\u00f3n problems and does not discuss any aspect of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04224",
      "abstract": "As libraries explore large language models (LLMs) for use in virtual reference services, a key question arises: Can LLMs serve all users equitably, regardless of demographics or social status? While they offer great potential for scalable support, LLMs may also reproduce societal biases embedded in their training data, risking the integrity of libraries' commitment to equitable service. To address this concern, we evaluate whether LLMs differentiate responses across user identities by prompting six state-of-the-art LLMs to assist patrons differing in sex, race/ethnicity, and institutional role. We found no evidence of differentiation by race or ethnicity, and only minor evidence of stereotypical bias against women in one model. LLMs demonstrated nuanced accommodation of institutional roles through the use of linguistic choices related to formality, politeness, and domain-specific vocabularies, reflecting professional norms rather than discriminatory treatment. These findings suggest that current LLMs show a promising degree of readiness to support equitable and contextually appropriate communication in academic library reference services.",
      "authors": [
        "Haining Wang",
        "Jason Clark",
        "Yueru Yan",
        "Star Bradley",
        "Ruiyang Chen",
        "Yiqiong Zhang",
        "Hengyi Fu",
        "Zuoyu Tian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T03:28:24+00:00",
          "link": "https://arxiv.org/abs/2507.04224v1",
          "size": "153kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:08:40+00:00",
          "link": "https://arxiv.org/abs/2507.04224v2",
          "size": "153kb",
          "version": "v2"
        }
      ],
      "title": "Fairness Evaluation of Large Language Models in Academic Library Reference Services",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04224",
        "HTML": "https://arxiv.org/html/2507.04224v2",
        "PDF": "https://arxiv.org/pdf/2507.04224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates fairness in LLMs for library reference services and does not make any technical contribution to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04786",
      "abstract": "The NVIDIA Collective Communication Library (NCCL) is a critical software layer enabling high-performance collectives on large-scale GPU clusters. Despite being open source with a documented API, its internal design remains largely opaque. The orchestration of communication channels, selection of protocols, and handling of memory movement across devices and nodes are not well understood, making it difficult to analyze performance or identify bottlenecks. This paper presents a comprehensive analysis of NCCL, focusing on its communication protocol variants (Simple, LL, and LL128), mechanisms governing intra-node and inter-node data movement, and ring- and tree-based collective communication algorithms. The insights obtained from this study serve as the foundation for ATLAHS, an application-trace-driven network simulation toolchain capable of accurately reproducing NCCL communication patterns in large-scale AI training workloads. By demystifying NCCL's internal architecture, this work provides guidance for system researchers and performance engineers working to optimize or simulate collective communication at scale.",
      "authors": [
        "Zhiyi Hu",
        "Siyuan Shen",
        "Tommaso Bonato",
        "Sylvain Jeaugey",
        "Cedell Alexander",
        "Eric Spada",
        "James Dinan",
        "Jeff Hammond",
        "Torsten Hoefler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T09:03:32+00:00",
          "link": "https://arxiv.org/abs/2507.04786v1",
          "size": "2529kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T12:50:23+00:00",
          "link": "https://arxiv.org/abs/2507.04786v2",
          "size": "2528kb",
          "version": "v2"
        }
      ],
      "title": "Demystifying NCCL: An In-depth Analysis of GPU Communication Protocols and Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04786",
        "HTML": "https://arxiv.org/html/2507.04786v2",
        "PDF": "https://arxiv.org/pdf/2507.04786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study provides an analysis of GPU communication protocols within the NCCL library, focusing on performance optimization in AI workloads without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04948",
      "abstract": "The network homology Hk-core decomposition proposed in this article is similar to the k-core decomposition based on node degrees of the network. The C. elegans neural network and the cat cortical network are used as examples to reveal the symmetry of the deep structures of such networks. First, based on the concept of neighborhood in mathematics, some new concepts are introduced, including such as node-neighbor subnetwork and Betti numbers of the neighbor subnetwork, among others. Then, the Betti numbers of the neighbor subnetwork of each node are computed, which are used to perform Hk-core decomposition of the network homology. The construction process is as follows: the initial network is referred to as the H0-core; the H1-core is obtained from the H0-core by deleting some nodes of certain properties; the H2-core is obtained from the H1-core by deleting some nodes or edges of certain properties; the H3-core is obtained from the H2-core by deleting some nodes of certain properties or by retaining the nodes of certain properties, and so on, which will be described in detail in the main text. Throughout the process, the index of node involved in deleting edge needs to be updated in every step. The Hk-core decomposition is easy to implement in parallel. It has a wide range of applications in many fields such as network science, data science, computational topology, and artificial intelligence. In this article, we also show how to use it to simplify homology calculation, e.g. for the C. elegans neural network, whereas the results of decomposition are the H1-core, the H2-core, and the H3-core. Thus, the simplexes consisting of four highest-order cavities in the H3-core subnetwork can also be directly obtained.",
      "authors": [
        "Dinghua Shi",
        "Yang Zhao and Guanrong Chen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T12:47:23+00:00",
          "link": "https://arxiv.org/abs/2507.04948v1",
          "size": "817kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:35:36+00:00",
          "link": "https://arxiv.org/abs/2507.04948v2",
          "size": "875kb",
          "version": "v2"
        }
      ],
      "title": "Node-neighbor subnetworks and Hk-core decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04948",
        "PDF": "https://arxiv.org/pdf/2507.04948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Hk-core decomposition and network homology in complex networks like neural networks but does not address LLM training data processing or related fields."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05515",
      "abstract": "Vision-language models (VLMs) are facing the challenges of understanding and following multimodal assembly instructions, particularly when fine-grained spatial reasoning and precise object state detection are required. In this work, we explore LEGO Co-builder, a hybrid benchmark combining real-world LEGO assembly logic with programmatically generated multimodal scenes. The dataset captures stepwise visual states and procedural instructions, allowing controlled evaluation of instruction-following, object detection, and state detection. We introduce a unified framework and assess leading VLMs such as GPT-4o, Gemini, and Qwen-VL, under zero-shot and fine-tuned settings. Our results reveal that even advanced models like GPT-4o struggle with fine-grained assembly tasks, with a maximum F1 score of just 40.54\\% on state detection, highlighting gaps in fine-grained visual understanding. We release the benchmark, codebase, and generation pipeline to support future research on multimodal assembly assistants grounded in real-world workflows.",
      "authors": [
        "Haochen Huang",
        "Jiahuan Pei",
        "Mohammad Aliannejadi",
        "Xin Sun",
        "Moonisa Ahsan",
        "Chuang Yu",
        "Zhaochun Ren",
        "Pablo Cesar",
        "Junxiao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:29:01+00:00",
          "link": "https://arxiv.org/abs/2507.05515v1",
          "size": "36800kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:20:57+00:00",
          "link": "https://arxiv.org/abs/2507.05515v2",
          "size": "2740kb",
          "version": "v2"
        }
      ],
      "title": "LEGO Co-builder: Exploring Fine-Grained Vision-Language Modeling for Multimodal LEGO Assembly Assistants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05515",
        "HTML": "https://arxiv.org/html/2507.05515v2",
        "PDF": "https://arxiv.org/pdf/2507.05515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces LEGO Co-builder, a benchmark combining real-world assembly logic with generated data to enhance VLMs. While it involves dataset creation for fine-tuning models, the main focus is on vision-language modeling and task evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06565",
      "abstract": "Large language models (LLMs) turn writing into a live exchange between humans and software. We characterize this new medium as a discursive network that treats people and LLMs as equal nodes and tracks how their statements circulate. We define the generation of erroneous information as invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. We develop a general mathematical model of discursive networks that shows that a network governed only by drift and self-repair stabilizes at a modest error rate. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source Flaws-of-Others (FOO) algorithm: a configurable loop in which any set of agents critique one another while a harmonizer merges their verdicts. We identify an ethical transgression, epithesis, that occurs when humans fail to engage in the discursive network. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from connecting imperfect ones into networks that enforce mutual accountability.",
      "authors": [
        "Juan B. Guti\\'errez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.06565v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:34:51+00:00",
          "link": "https://arxiv.org/abs/2507.06565v2",
          "size": "742kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:19:46+00:00",
          "link": "https://arxiv.org/abs/2507.06565v3",
          "size": "849kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T14:44:49+00:00",
          "link": "https://arxiv.org/abs/2507.06565v4",
          "size": "857kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T17:02:53+00:00",
          "link": "https://arxiv.org/abs/2507.06565v5",
          "size": "861kb",
          "version": "v5"
        }
      ],
      "title": "A Mathematical Theory of Discursive Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06565",
        "HTML": "https://arxiv.org/html/2507.06565v5",
        "PDF": "https://arxiv.org/pdf/2507.06565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a mathematical model for discursive networks involving LLM and human interactions in generating information. However, it does not contribute directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07284",
      "abstract": "As the demand for compute power in traditional neural networks has increased significantly, spiking neural networks (SNNs) have emerged as a potential solution to increasingly power-hungry neural networks. By operating on 0/1 spikes emitted by neurons instead of arithmetic multiply-and-accumulate operations, SNNs propagate information temporally and spatially, allowing for more efficient compute power. To this end, many architectures for accelerating and simulating SNNs have been developed, including Loihi, TrueNorth, and SpiNNaker. However, these chips are largely inaccessible to the wider community. Field programmable gate arrays (FPGAs) have been explored to serve as a middle ground between neuromorphic and non-neuromorphic hardware, but many proposed architectures require expensive high-end FPGAs or target a single SNN topology. This paper presents a framework consisting of a robust SNN acceleration architecture and a Pytorch-based SNN model compiler. Targeting any-to-any and/or fully connected SNNs, the FPGA architecture features a synaptic array that tiles across the SNN to propagate spikes. The architecture targets low-end FPGAs and requires very little (6358 LUT, 40.5 BRAM) resources. The framework, tested on a low-end Xilinx Artix-7 FPGA at 100 MHz, achieves competitive speed in recognizing MNIST digits (0.52 ms/img). Further experiments also show accurate simulation of hand coded any-to-any spiking neural networks on toy problems. All code and setup instructions are available at https://github.com/im-afan/snn-fpga}{\\texttt{https://github.com/im-afan/snn-fpga.",
      "authors": [
        "Andrew Fan and Simon D. Levy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:08:28+00:00",
          "link": "https://arxiv.org/abs/2507.07284v1",
          "size": "1193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T00:13:53+00:00",
          "link": "https://arxiv.org/abs/2507.07284v2",
          "size": "763kb",
          "version": "v2"
        }
      ],
      "title": "A Robust, Open-Source Framework for Spiking Neural Networks on Low-End FPGAs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07284",
        "HTML": "https://arxiv.org/html/2507.07284v2",
        "PDF": "https://arxiv.org/pdf/2507.07284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for spiking neural networks on low-end FPGAs, which doesn't pertain to LLM training data processing, but rather focuses on neural network architecture and hardware implementations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07578",
      "abstract": "Weakly-supervised semantic segmentation aims to assign category labels to each pixel using weak annotations, significantly reducing manual annotation costs. Although existing methods have achieved remarkable progress in well-lit scenarios, their performance significantly degrades in low-light environments due to two fundamental limitations: severe image quality degradation (e.g., low contrast, noise, and color distortion) and the inherent constraints of weak supervision. These factors collectively lead to unreliable class activation maps and semantically ambiguous pseudo-labels, ultimately compromising the model's ability to learn discriminative feature representations. To address these problems, we propose Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-light Semantic Segmentation (DGKD-WLSS), a novel framework that synergistically combines Diffusion-Guided Knowledge Distillation (DGKD) with Depth-Guided Feature Fusion (DGF2). DGKD aligns normal-light and low-light features via diffusion-based denoising and knowledge distillation, while DGF2 integrates depth maps as illumination-invariant geometric priors to enhance structural feature learning. Extensive experiments demonstrate the effectiveness of DGKD-WLSS, which achieves state-of-the-art performance in weakly supervised semantic segmentation tasks under low-light conditions. The source codes have been released at:https://github.com/ChunyanWang1/DGKD-WLSS.",
      "authors": [
        "Chunyan Wang",
        "Dong Zhang and Jinhui Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:28:54+00:00",
          "link": "https://arxiv.org/abs/2507.07578v1",
          "size": "456kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.07578v2",
          "size": "456kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-Light Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07578",
        "HTML": "https://arxiv.org/html/2507.07578v2",
        "PDF": "https://arxiv.org/pdf/2507.07578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for weakly-supervised low-light semantic segmentation, involving knowledge distillation and feature fusion. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07901",
      "abstract": "The fragmentation of AI agent ecosystems has created urgent demands for interoperability, trust, and economic coordination that current protocols -- including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al., 2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present the Nanda Unified Architecture, a decentralized framework built around three core innovations: fast DID-based agent discovery through distributed registries, semantic agent cards with verifiable credentials and composability profiles, and a dynamic trust layer that integrates behavioral attestations with policy compliance. The system introduces X42/H42 micropayments for economic coordination and MAESTRO, a security framework incorporating Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure containerization. Real-world deployments demonstrate 99.9 percent compliance in healthcare applications and substantial monthly transaction volumes with strong privacy guarantees. By unifying MIT's trust research with production deployments from Cisco and Synergetics, we show how cryptographic proofs and policy-as-code transform agents into trust-anchored participants in a decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a globally interoperable Internet of Agents where trust becomes the native currency of collaboration across both enterprise and Web3 ecosystems.",
      "authors": [
        "Sree Bhargavi Balija",
        "Rekha Singal",
        "Ramesh Raskar",
        "Erfan Darzi",
        "Raghu Bala",
        "Thomas Hardjono",
        "Ken Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.07901v1",
          "size": "4620kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T03:11:21+00:00",
          "link": "https://arxiv.org/abs/2507.07901v2",
          "size": "4620kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T19:28:06+00:00",
          "link": "https://arxiv.org/abs/2507.07901v3",
          "size": "4620kb",
          "version": "v3"
        }
      ],
      "title": "The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07901",
        "HTML": "https://arxiv.org/html/2507.07901v3",
        "PDF": "https://arxiv.org/pdf/2507.07901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a decentralized framework for interoperability and trust in AI agent ecosystems, with no mention of LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07935",
      "abstract": "Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact.",
      "authors": [
        "Kiran Tomlinson",
        "Sonia Jaffe",
        "Will Wang",
        "Scott Counts",
        "Siddharth Suri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:16:33+00:00",
          "link": "https://arxiv.org/abs/2507.07935v1",
          "size": "859kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.07935v2",
          "size": "859kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T21:32:56+00:00",
          "link": "https://arxiv.org/abs/2507.07935v3",
          "size": "860kb",
          "version": "v3"
        }
      ],
      "title": "Working with AI: Measuring the Occupational Implications of Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07935",
        "PDF": "https://arxiv.org/pdf/2507.07935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the occupational implications of generative AI by analyzing usage patterns. It does not involve any LLM training data processing activities such as data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09068",
      "abstract": "The rapid advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have ushered in remarkable progress in video understanding. However, a fundamental challenge persists: effectively processing and comprehending video content that extends beyond minutes or hours. While recent efforts like Video-XL-2 have demonstrated novel architectural solutions for extreme efficiency, and advancements in positional encoding such as HoPE and VideoRoPE++ aim to improve spatio-temporal understanding over extensive contexts, current state-of-the-art models still encounter significant computational and memory constraints when faced with the sheer volume of visual tokens from lengthy sequences. Furthermore, maintaining temporal coherence, tracking complex events, and preserving fine-grained details over extended periods remain formidable hurdles, despite progress in agentic reasoning systems like Deep Video Discovery. This position paper posits that a logical, albeit ambitious, next frontier for multimedia research is Infinite Video Understanding -- the capability for models to continuously process, understand, and reason about video data of arbitrary, potentially never-ending duration. We argue that framing Infinite Video Understanding as a blue-sky research objective provides a vital north star for the multimedia, and the wider AI, research communities, driving innovation in areas such as streaming architectures, persistent memory mechanisms, hierarchical and adaptive representations, event-centric reasoning, and novel evaluation paradigms. Drawing inspiration from recent work on long/ultra-long video understanding and several closely related fields, we outline the core challenges and key research directions towards achieving this transformative capability.",
      "authors": [
        "Dell Zhang",
        "Xiangyu Chen",
        "Jixiang Luo",
        "Mengxi Jia",
        "Changzhi Sun",
        "Ruilong Ren",
        "Jingren Liu",
        "Hao Sun",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T23:07:04+00:00",
          "link": "https://arxiv.org/abs/2507.09068v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:06:44+00:00",
          "link": "https://arxiv.org/abs/2507.09068v2",
          "size": "61kb",
          "version": "v2"
        }
      ],
      "title": "Infinite Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09068",
        "HTML": "https://arxiv.org/html/2507.09068v2",
        "PDF": "https://arxiv.org/pdf/2507.09068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This position paper focuses on challenges and directions for achieving 'Infinite Video Understanding,' not addressing any LLM training data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09184",
      "abstract": "Hallucinations pose a significant challenge in Large Vision Language Models (LVLMs), with misalignment between multimodal features identified as a key contributing factor. This paper reveals the negative impact of the long-term decay in Rotary Position Encoding (RoPE), used for positional modeling in LVLMs, on multimodal alignment. Concretely, under long-term decay, instruction tokens exhibit uneven perception of image tokens located at different positions within the two-dimensional space: prioritizing image tokens from the bottom-right region since in the one-dimensional sequence, these tokens are positionally closer to the instruction tokens. This biased perception leads to insufficient image-instruction interaction and suboptimal multimodal alignment. We refer to this phenomenon as image alignment bias. To enhance instruction's perception of image tokens at different spatial locations, we propose MCA-LLaVA, based on Manhattan distance, which extends the long-term decay to a two-dimensional, multi-directional spatial decay. MCA-LLaVA integrates the one-dimensional sequence order and two-dimensional spatial position of image tokens for positional modeling, mitigating hallucinations by alleviating image alignment bias. Experimental results of MCA-LLaVA across various hallucination and general benchmarks demonstrate its effectiveness and generality. The code can be accessed in https://github.com/ErikZ719/MCA-LLaVA.",
      "authors": [
        "Qiyan Zhao",
        "Xiaofeng Zhang",
        "Yiheng Li",
        "Yun Xing",
        "Xiaosong Yuan",
        "Feilong Tang",
        "Sinan Fan",
        "Xuhang Chen",
        "Xuyao Zhang",
        "Dahan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:09:35+00:00",
          "link": "https://arxiv.org/abs/2507.09184v1",
          "size": "1832kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T02:46:25+00:00",
          "link": "https://arxiv.org/abs/2507.09184v2",
          "size": "1832kb",
          "version": "v2"
        }
      ],
      "title": "MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09184",
        "HTML": "https://arxiv.org/html/2507.09184v2",
        "PDF": "https://arxiv.org/pdf/2507.09184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes improvements in positional encoding for large vision-language models to reduce hallucinations. It does not involve LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09205",
      "abstract": "Large language models have achieved remarkable progress across many languages. However, Tibetan, as a representative low-resource language, is particularly underrepresented in existing models due to the scarcity of high-quality training corpora. To address this gap, we curate the largest Tibetan pre-training corpus to date, aggregating data from diverse sources and applying a dedicated data cleaning and processing pipeline tailored for Tibetan. With the curated data, we continue pre/post-training a multilingual base model to enhance its generative capabilities in Tibetan. To evaluate the Tibetan capabilities of the model, we create new high-quality Tibetan benchmarks, and complement them with existing public benchmarks. Experimental results demonstrate that our model consistently and significantly outperforms both open-source models of similar scale and Tibetan-tailored models across a wide range of tasks.",
      "authors": [
        "Leiyu Pan",
        "Bojian Xiong",
        "Lei Yang",
        "Renren Jin",
        "Shaowei Zhang",
        "Yue Chen",
        "Ling Shi",
        "Jiang Zhou",
        "Junru Wu",
        "Zhen Wang",
        "Jianxiang Peng",
        "Juesi Xiao",
        "Tianyu Dong",
        "Zhuowen Han",
        "Zhuo Chen",
        "Yuqi Ren",
        "Deyi Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:54:05+00:00",
          "link": "https://arxiv.org/abs/2507.09205v1",
          "size": "225kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T14:15:52+00:00",
          "link": "https://arxiv.org/abs/2507.09205v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T13:30:04+00:00",
          "link": "https://arxiv.org/abs/2507.09205v3",
          "size": "95kb",
          "version": "v3"
        }
      ],
      "title": "Advancing Large Language Models for Tibetan with Curated Data and Continual Pre-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09205",
        "HTML": "https://arxiv.org/html/2507.09205v3",
        "PDF": "https://arxiv.org/pdf/2507.09205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper curates and processes a large pre-training corpus for Tibetan, a low-resource language, to improve LLM performance. It involves data collection and cleaning processes to address the scarcity of high-quality data, directly contributing to LLM training data processing by enhancing data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09822",
      "abstract": "Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at https://darshangm.github.io/papers/active-probing-multimodal-predictions/.",
      "authors": [
        "Darshan Gadginmath",
        "Farhad Nawaz",
        "Minjun Sung",
        "Faizan M Tariq",
        "Sangjae Bae",
        "David Isele",
        "Fabio Pasqualetti",
        "Jovin D'sa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:06:46+00:00",
          "link": "https://arxiv.org/abs/2507.09822v1",
          "size": "653kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.09822v2",
          "size": "653kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T19:53:18+00:00",
          "link": "https://arxiv.org/abs/2507.09822v3",
          "size": "654kb",
          "version": "v3"
        },
        {
          "date": "2025-07-22T23:25:21+00:00",
          "link": "https://arxiv.org/abs/2507.09822v4",
          "size": "654kb",
          "version": "v4"
        }
      ],
      "title": "Active Probing with Multimodal Predictions for Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09822",
        "HTML": "https://arxiv.org/html/2507.09822v4",
        "PDF": "https://arxiv.org/pdf/2507.09822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating trajectory planning with multimodal predictions for motion planning in dynamic environments. It does not address LLM training data processing or relate to data operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09984",
      "abstract": "In spite of the remarkable potential of Latent Diffusion Models (LDMs) in image generation, the desired properties and optimal design of the autoencoders have been underexplored. In this work, we analyze the role of autoencoders in LDMs and identify three key properties: latent smoothness, perceptual compression quality, and reconstruction quality. We demonstrate that existing autoencoders fail to simultaneously satisfy all three properties, and propose Variational Masked AutoEncoders (VMAEs), taking advantage of the hierarchical features maintained by Masked AutoEncoders. We integrate VMAEs into the LDM framework, introducing Latent Diffusion Models with Masked AutoEncoders (LDMAEs).",
      "authors": [
        "Junho Lee",
        "Jeongwoo Shin",
        "Hyungwook Choi",
        "Joonseok Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:00:43+00:00",
          "link": "https://arxiv.org/abs/2507.09984v1",
          "size": "31985kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.09984v2",
          "size": "31986kb",
          "version": "v2"
        }
      ],
      "title": "Latent Diffusion Models with Masked AutoEncoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09984",
        "HTML": "https://arxiv.org/html/2507.09984v2",
        "PDF": "https://arxiv.org/pdf/2507.09984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Latent Diffusion Models in the context of image generation, focusing on autoencoders' properties. It does not relate to LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10054",
      "abstract": "Large Language Models (LLMs) are increasingly used as code assistants, yet their behavior when explicitly asked to generate insecure code remains poorly understood. While prior research has focused on unintended vulnerabilities, this study examines a more direct threat: open-source LLMs generating vulnerable code when prompted. We propose a dual experimental design: (1) Dynamic Prompting, which systematically varies vulnerability type, user persona, and prompt phrasing across structured templates; and (2) Reverse Prompting, which derives natural-language prompts from real vulnerable code samples. We evaluate three open-source 7B-parameter models (Qwen2, Mistral, Gemma) using static analysis to assess both the presence and correctness of generated vulnerabilities. Our results show that all models frequently generate the requested vulnerabilities, though with significant performance differences. Gemma achieves the highest correctness for memory vulnerabilities under Dynamic Prompting (e.g., 98.6% for buffer overflows), while Qwen2 demonstrates the most balanced performance across all tasks. We find that professional personas (e.g., \"DevOps Engineer\") consistently elicit higher success rates than student personas, and that the effectiveness of direct versus indirect phrasing is inverted depending on the prompting strategy. Vulnerability reproduction accuracy follows a non-linear pattern with code complexity, peaking in a moderate range. Our findings expose how LLMs' reliance on pattern recall over semantic reasoning creates significant blind spots in their safety alignments, particularly for requests framed as plausible professional tasks.",
      "authors": [
        "Emir Bosnak",
        "Sahand Moslemi",
        "Mayasah Lami",
        "Anil Koyuncu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:36:26+00:00",
          "link": "https://arxiv.org/abs/2507.10054v1",
          "size": "4239kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:43:29+00:00",
          "link": "https://arxiv.org/abs/2507.10054v2",
          "size": "6853kb",
          "version": "v2"
        }
      ],
      "title": "Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10054",
        "HTML": "https://arxiv.org/html/2507.10054v2",
        "PDF": "https://arxiv.org/pdf/2507.10054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates the capability of LLMs to generate insecure code when prompted, evaluating model behavior rather than focusing on training data processing or improvements in data quality for pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10382",
      "abstract": "With the rise of smart mobility and shared e-mobility services, numerous advanced technologies have been applied to this field. Cloud-based traffic simulation solutions have flourished, offering increasingly realistic representations of the evolving mobility landscape. LLMs have emerged as pioneering tools, providing robust support for various applications, including intelligent decision-making, user interaction, and real-time traffic analysis. As user demand for e-mobility continues to grow, delivering comprehensive end-to-end solutions has become crucial. In this paper, we present a cloud-based, LLM-powered shared e-mobility platform, integrated with a mobile application for personalized route recommendations. The optimization module is evaluated based on travel time and cost across different traffic scenarios. Additionally, the LLM-powered RAG framework is evaluated at the schema level for different users, using various evaluation methods. Schema-level RAG with XiYanSQL achieves an average execution accuracy of 0.81 on system operator queries and 0.98 on user queries.",
      "authors": [
        "Yue Ding",
        "Conor McCarthy",
        "Kevin O'Shea and Mingming Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:23:11+00:00",
          "link": "https://arxiv.org/abs/2507.10382v1",
          "size": "3868kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:02:51+00:00",
          "link": "https://arxiv.org/abs/2507.10382v2",
          "size": "3832kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging RAG-LLMs for Urban Mobility Simulation and Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10382",
        "HTML": "https://arxiv.org/html/2507.10382v2",
        "PDF": "https://arxiv.org/pdf/2507.10382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of LLMs for urban mobility simulation and analysis but does not address LLM training data processing or related data engineering operations. It focuses on applications and system architecture rather than dataset creation or curation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11893",
      "abstract": "High spatial frequency information, including fine details like textures, significantly contributes to the accuracy of semantic segmentation. However, according to the Nyquist-Shannon Sampling Theorem, high-frequency components are vulnerable to aliasing or distortion when propagating through downsampling layers such as strided-convolution. Here, we propose a novel Spatial Frequency Modulation (SFM) that modulates high-frequency features to a lower frequency before downsampling and then demodulates them back during upsampling. Specifically, we implement modulation through adaptive resampling (ARS) and design a lightweight add-on that can densely sample the high-frequency areas to scale up the signal, thereby lowering its frequency in accordance with the Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling (MSAU) to demodulate the modulated feature and recover high-frequency information through non-uniform upsampling This module further improves segmentation by explicitly exploiting information interaction between densely and sparsely resampled areas at multiple scales. Both modules can seamlessly integrate with various architectures, extending from convolutional neural networks to transformers. Feature visualization and analysis confirm that our method effectively alleviates aliasing while successfully retaining details after demodulation. Finally, we validate the broad applicability and effectiveness of SFM by extending it to image classification, adversarial robustness, instance segmentation, and panoptic segmentation tasks. The code is available at https://github.com/Linwei-Chen/SFM.",
      "authors": [
        "Linwei Chen",
        "Ying Fu",
        "Lin Gu",
        "Dezhi Zheng",
        "Jifeng Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:15:53+00:00",
          "link": "https://arxiv.org/abs/2507.11893v1",
          "size": "6192kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:04:09+00:00",
          "link": "https://arxiv.org/abs/2507.11893v2",
          "size": "6192kb",
          "version": "v2"
        }
      ],
      "title": "Spatial Frequency Modulation for Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11893",
        "HTML": "https://arxiv.org/html/2507.11893v2",
        "PDF": "https://arxiv.org/pdf/2507.11893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes Spatial Frequency Modulation to improve semantic segmentation techniques in neural networks. It is primarily concerned with architecture and algorithmic enhancements, not with LLM training data processing or dataset management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12006",
      "abstract": "Vision Transformers (ViTs) have significantly advanced computer vision, demonstrating strong performance across various tasks. However, the attention mechanism in ViTs makes each layer function as a low-pass filter, and the stacked-layer architecture in existing transformers suffers from frequency vanishing. This leads to the loss of critical details and textures. We propose a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly modulates the overall frequency response of ViTs and consists of two techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling (FreqScale). Since circuit theory uses low-pass filters as fundamental elements, we introduce AttInv, a method that generates complementary high-pass filtering by inverting the low-pass filter in the attention matrix, and dynamically combining the two. We further design FreqScale to weight different frequency components for fine-grained adjustments to the target response function. Through feature similarity analysis and effective rank evaluation, we demonstrate that our approach avoids representation collapse, leading to consistent performance improvements across various models, including SegFormer, DeiT, and MaskDINO. These improvements are evident in tasks such as semantic segmentation, object detection, and instance segmentation. Additionally, we apply our method to remote sensing detection, achieving state-of-the-art results in single-scale settings. The code is available at https://github.com/Linwei-Chen/FDAM.",
      "authors": [
        "Linwei Chen",
        "Lin Gu",
        "Ying Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.12006v1",
          "size": "1421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:10:31+00:00",
          "link": "https://arxiv.org/abs/2507.12006v2",
          "size": "1421kb",
          "version": "v2"
        }
      ],
      "title": "Frequency-Dynamic Attention Modulation for Dense Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12006",
        "HTML": "https://arxiv.org/html/2507.12006v2",
        "PDF": "https://arxiv.org/pdf/2507.12006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel attention mechanism for Vision Transformers in dense prediction tasks such as semantic segmentation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12103",
      "abstract": "Heatwaves pose a significant threat to public health, especially as global warming intensifies. However, current routing systems (e.g., online maps) fail to incorporate shade information due to the difficulty of estimating shades directly from noisy satellite imagery and the limited availability of training data for generative models. In this paper, we address these challenges through two main contributions. First, we build an extensive dataset covering diverse longitude-latitude regions, varying levels of building density, and different urban layouts. Leveraging Blender-based 3D simulations alongside building outlines, we capture building shadows under various solar zenith angles throughout the year and at different times of day. These simulated shadows are aligned with satellite images, providing a rich resource for learning shade patterns. Second, we propose the DeepShade, a diffusion-based model designed to learn and synthesize shade variations over time. It emphasizes the nuance of edge features by jointly considering RGB with the Canny edge layer, and incorporates contrastive learning to capture the temporal change rules of shade. Then, by conditioning on textual descriptions of known conditions (e.g., time of day, solar angles), our framework provides improved performance in generating shade images. We demonstrate the utility of our approach by using our shade predictions to calculate shade ratios for real-world route planning in Tempe, Arizona. We believe this work will benefit society by providing a reference for urban planning in extreme heat weather and its potential practical applications in the environment.",
      "authors": [
        "Longchao Da",
        "Xiangrui Liu",
        "Mithun Shivakoti",
        "Thirulogasankar Pranav Kutralingam",
        "Yezhou Yang",
        "Hua Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:19:12+00:00",
          "link": "https://arxiv.org/abs/2507.12103v1",
          "size": "1606kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:36:02+00:00",
          "link": "https://arxiv.org/abs/2507.12103v2",
          "size": "1628kb",
          "version": "v2"
        }
      ],
      "title": "DeepShade: Enable Shade Simulation by Text-conditioned Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12103",
        "HTML": "https://arxiv.org/html/2507.12103v2",
        "PDF": "https://arxiv.org/pdf/2507.12103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about generating shade simulation data for urban planning through 3D simulation and image generation, not pertaining to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12106",
      "abstract": "The efficient design and management of public green spaces is a key factor in promoting the health and well-being of urban population, as emphasized by the WHO, UNEP, and EEA. These areas serve as the \"green lungs\" of the urban ecosystem, playing a vital role in enhancing quality of life thanks to the provision of ecosystem services. In this context, the Smart Green City use case in Campobasso municipality, funded by the Italian Ministry of Enterprises (MIMIT), emerges as an innovative model for the sustainable management of green urban areas through the adoption of an advanced system of emerging technologies integrated and interoperable. The project integrates IoT systems and data-driven governance platforms, enabling real-time monitoring of the health status of trees and green areas via a Decision Support System (DSS). It also facilitates the collection and analysis of data from diverse sources, including weather conditions, air quality, soil moisture, pollution levels. The resulting cloud-based platform supports a holistic real time decision making for green urban managers, technical experts and operational staff. It enables intelligent control and management of urban green spaces using Tree Talker sensors, integrated with soil moisture and water potential monitoring systems. Thanks to predictive models based on machine learning algorithms and real time data provided by IoT sensors, irrigation of public parks can be optimized by providing suggestions on when and how much water to apply. Customized alerts layers are also activated warning users when monitored parameters, such as soil temperature, humidity, or water potential, exceed predefined thresholds. This Use Case demonstrates how digitalization, IoT sensors fusion and technological innovation can support sustainable urban governance, fostering environmental resilience and improving citizens quality of life.",
      "authors": [
        "Antonio Salis",
        "Gabriele Troina",
        "Gianluca Boanelli",
        "Marco Ottaviano",
        "Paola Fortini",
        "Soraya Versace"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.12106v1",
          "size": "1194kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:06:54+00:00",
          "link": "https://arxiv.org/abs/2507.12106v2",
          "size": "1194kb",
          "version": "v2"
        }
      ],
      "title": "Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12106",
        "PDF": "https://arxiv.org/pdf/2507.12106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses IoT-driven management and data analysis for urban green spaces, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12233",
      "abstract": "Solving cell problems in homogenization is hard, and available deep-learning frameworks fail to match the speed and generality of traditional computational frameworks. More to the point, it is generally unclear what to expect of machine-learning approaches, let alone single out which approaches are promising. In the work at hand, we advocate Fourier Neural Operators (FNOs) for micromechanics, empowering them by insights from computational micromechanics methods based on the fast Fourier transform (FFT). We construct an FNO surrogate mimicking the basic scheme foundational for FFT-based methods and show that the resulting operator predicts solutions to cell problems with arbitrary stiffness distribution only subject to a material-contrast constraint up to a desired accuracy. In particular, there are no restrictions on the material symmetry like isotropy, on the number of phases and on the geometry of the interfaces between materials. Also, the provided fidelity is sharp and uniform, providing explicit guarantees leveraging our physical empowerment of FNOs. To show the desired universal approximation property, we construct an FNO explicitly that requires no training to begin with. Still, the obtained neural operator complies with the same memory requirements as the basic scheme and comes with runtimes proportional to classical FFT solvers. In particular, large-scale problems with more than 100 million voxels are readily handled. The goal of this work is to underline the potential of FNOs for solving micromechanical problems, linking FFT-based methods to FNOs. This connection is expected to provide a fruitful exchange between both worlds.",
      "authors": [
        "Binh Huy Nguyen and Matti Schneider"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:47:20+00:00",
          "link": "https://arxiv.org/abs/2507.12233v1",
          "size": "2929kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:07:08+00:00",
          "link": "https://arxiv.org/abs/2507.12233v2",
          "size": "2929kb",
          "version": "v2"
        }
      ],
      "title": "Universal Fourier Neural Operators for Micromechanics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12233",
        "PDF": "https://arxiv.org/pdf/2507.12233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work addresses Fourier Neural Operators for solving micromechanical problems, not involving any aspect of training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12828",
      "abstract": "Food is not only essential to human health but also serves as a medium for cultural identity and emotional connection. In the context of precision nutrition, accurately identifying and classifying food images is critical for dietary monitoring, nutrient estimation, and personalized health management. However, fine-grained food classification remains challenging due to the subtle visual differences among similar dishes. To address this, we propose Feature-Enhanced TResNet (FE-TResNet), a novel deep learning model designed to improve the accuracy of food image recognition in fine-grained scenarios. Built on the TResNet architecture, FE-TResNet integrates a Style-based Recalibration Module (StyleRM) and Deep Channel-wise Attention (DCA) to enhance feature extraction and emphasize subtle distinctions between food items. Evaluated on two benchmark Chinese food datasets-ChineseFoodNet and CNFOOD-241-FE-TResNet achieved high classification accuracies of 81.37% and 80.29%, respectively. These results demonstrate its effectiveness and highlight its potential as a key enabler for intelligent dietary assessment and personalized recommendations in precision nutrition systems.",
      "authors": [
        "Lulu Liu and Zhiyong Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:37:45+00:00",
          "link": "https://arxiv.org/abs/2507.12828v1",
          "size": "5650kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T02:14:58+00:00",
          "link": "https://arxiv.org/abs/2507.12828v2",
          "size": "5650kb",
          "version": "v2"
        }
      ],
      "title": "Feature-Enhanced TResNet for Fine-Grained Food Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12828",
        "HTML": "https://arxiv.org/html/2507.12828v2",
        "PDF": "https://arxiv.org/pdf/2507.12828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on a deep learning model for fine-grained food image classification, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12941",
      "abstract": "Partial differential equations (PDEs) with near singular solutions pose significant challenges for traditional numerical methods, particularly in complex geometries where mesh generation and adaptive refinement become computationally expensive. While deep-learning-based approaches, such as Physics-Informed Neural Networks (PINNs) and the Random Feature Method (RFM), offer mesh-free alternatives, they often lack adaptive resolution in critical regions, limiting their accuracy for solutions with steep gradients or singularities. In this work, we propose the Adaptive Feature Capture Method (AFCM), a novel machine learning framework that adaptively redistributes neurons and collocation points in high-gradient regions to enhance local expressive power. Inspired by adaptive moving mesh techniques, AFCM employs the gradient norm of an approximate solution as a monitor function to guide the reinitialization of feature function parameters. This ensures that partition hyperplanes and collocation points cluster where they are most needed, achieving higher resolution without increasing computational overhead. The AFCM extends the capabilities of RFM to handle PDEs with near-singular solutions while preserving its mesh-free efficiency. Numerical experiments demonstrate the method's effectiveness in accurately resolving near-singular problems, even in complex geometries. By bridging the gap between adaptive mesh refinement and randomized neural networks, AFCM offers a robust and scalable approach for solving challenging PDEs in scientific and engineering applications.",
      "authors": [
        "Yangtao Deng",
        "Qiaolin He",
        "Xiaoping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:29:22+00:00",
          "link": "https://arxiv.org/abs/2507.12941v1",
          "size": "8810kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:29:07+00:00",
          "link": "https://arxiv.org/abs/2507.12941v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T02:57:25+00:00",
          "link": "https://arxiv.org/abs/2507.12941v3",
          "size": "7573kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive feature capture method for solving partial differential equations with near singular solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12941",
        "HTML": "https://arxiv.org/html/2507.12941v3",
        "PDF": "https://arxiv.org/pdf/2507.12941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on solving partial differential equations using a machine learning framework, specifically for PDEs with near singular solutions. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13508",
      "abstract": "The \"Fake or Real\" competition hosted on Kaggle (https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt ) is the second part of a series of follow-up competitions and hackathons related to the \"Assurance for Space Domain AI Applications\" project funded by the European Space Agency (https://assurance-ai.space-codev.org/ ). The competition idea is based on two real-life AI security threats identified within the project -- data poisoning and overreliance in Large Language Models. The task is to distinguish between the proper output from LLM and the output generated under malicious modification of the LLM. As this problem was not extensively researched, participants are required to develop new techniques to address this issue or adjust already existing ones to this problem's statement.",
      "authors": [
        "Agata Kaczmarek",
        "Dawid P{\\l}udowski",
        "Piotr Wilczy\\'nski",
        "Krzysztof Kotowski",
        "Ramez Shendy",
        "Evridiki Ntagiou",
        "Jakub Nalepa",
        "Artur Janicki",
        "Przemys{\\l}aw Biecek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.13508v1",
          "size": "114kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:07:17+00:00",
          "link": "https://arxiv.org/abs/2507.13508v2",
          "size": "114kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T13:48:01+00:00",
          "link": "https://arxiv.org/abs/2507.13508v3",
          "size": "114kb",
          "version": "v3"
        }
      ],
      "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13508",
        "PDF": "https://arxiv.org/pdf/2507.13508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the 'Fake or Real' competition, which involves identifying malicious modifications in LLM outputs. It touches upon data challenges related to LLM security but does not focus on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13708",
      "abstract": "Recent advancements in text-to-image diffusion models have achieved remarkable success in generating realistic and diverse visual content. A critical factor in this process is the model's ability to accurately interpret textual prompts. However, these models often struggle with creative expressions, particularly those involving complex, abstract, or highly descriptive language. In this work, we introduce a novel training-free approach tailored to improve image generation for a unique form of creative language: poetic verse, which frequently features layered, abstract, and dual meanings. Our proposed PoemTale Diffusion approach aims to minimise the information that is lost during poetic text-to-image conversion by integrating a multi stage prompt refinement loop into Language Models to enhance the interpretability of poetic texts. To support this, we adapt existing state-of-the-art diffusion models by modifying their self-attention mechanisms with a consistent self-attention technique to generate multiple consistent images, which are then collectively used to convey the poem's meaning. Moreover, to encourage research in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting of 1111 poems sourced from multiple online and offline resources. We engaged a panel of poetry experts for qualitative assessments. The results from both human and quantitative evaluations validate the efficacy of our method and contribute a novel perspective to poem-to-image generation with enhanced information capture in the generated images.",
      "authors": [
        "Sofia Jamil",
        "Bollampalli Areen Reddy",
        "Raghvendra Kumar",
        "Sriparna Saha",
        "Koustava Goswami",
        "K.J. Joseph"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:33:08+00:00",
          "link": "https://arxiv.org/abs/2507.13708v1",
          "size": "17801kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T13:00:06+00:00",
          "link": "https://arxiv.org/abs/2507.13708v2",
          "size": "17790kb",
          "version": "v2"
        }
      ],
      "title": "PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13708",
        "HTML": "https://arxiv.org/html/2507.13708v2",
        "PDF": "https://arxiv.org/pdf/2507.13708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces the P4I dataset related to poem-to-image generation, its main focus is on improving image generation through LLM prompt refinement rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13833",
      "abstract": "Reinforcement learning (RL) has become the pivotal post-training technique for large language model. Effectively scaling reinforcement learning is now the key to unlocking advanced reasoning capabilities and ensuring safe, goal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually employ a hybrid-controller architecture where a single-controller dispatches the overall execution logic and manages overall data transfer and the multi-controller executes distributed computation. For large-scale reinforcement learning, minor load imbalances can introduce significant bottlenecks, ultimately constraining the scalability of the system. To address this limitation, we introduce DistFlow, a novel, fully distributed RL framework designed to break scaling barrier. We adopt a multi-controller paradigm that dispatches data transfer and execution tasks to all workers, which eliminates the centralized node. This allows each worker to operate independently, leading to near-linear scalability up to thousands of GPUs and dramatic efficiency gains. Furthermore, our architecture decouples resource configuration from execution logic, allowing each worker to have a unique execution flow, offering significant flexibility for rapid and cost-effective algorithmic experimentation. Extensive experiments show that DistFlow achieves excellent linear scalability and up to a 7x end-to-end throughput improvement over state-of-the-art (SOTA) frameworks.",
      "authors": [
        "Zhixin Wang",
        "Tianyi Zhou",
        "Liming Liu",
        "Ao Li",
        "Jiarui Hu",
        "Dian Yang",
        "Jinlong Hou",
        "Siyuan Feng",
        "Yuan Cheng and Yuan Qi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:41:49+00:00",
          "link": "https://arxiv.org/abs/2507.13833v1",
          "size": "642kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T01:58:01+00:00",
          "link": "https://arxiv.org/abs/2507.13833v2",
          "size": "642kb",
          "version": "v2"
        }
      ],
      "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13833",
        "HTML": "https://arxiv.org/html/2507.13833v2",
        "PDF": "https://arxiv.org/pdf/2507.13833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a distributed RL framework, DistFlow, for LLM post-training. However, it does not address the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14000",
      "abstract": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM (PFA), a photonic-enabled switch and memory subsystem that delivers low latency, high bandwidth, and low per-bit energy. By integrating high-bandwidth HBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D electro-optical system-in-package, the PFA offers up to 32 TB of shared memory alongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM enables distributed AI training and inference to execute parallelism strategies more efficiently. The Photonic Fabric removes the silicon beachfront constraint that limits the fixed memory-to-compute ratio observed in virtually all current XPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet that connects to the Photonic Fabric increases its memory capacity and correspondingly its memory bandwidth by offering a flexible path to scaling well beyond the limitations of on-package HBM alone. We introduce CelestiSim, a lightweight analytical simulator validated on NVIDIA H100 and H200 systems. It is used to evaluate the performance of LLM reference and energy savings on PFA, without any significant change to the GPU core design. With the PFA, the simulation results show that up to 3.66x throughput and 1.40x latency improvements in LLM inference at 405B parameters, up to 7.04x throughput and 1.41x latency improvements at 1T parameters, and 60-90% energy savings in data movement for heavy collective operations in all LLM training scenarios. While these results are shown for NVIDIA GPUs, they can be applied similarly to other AI accelerator designs (XPUs) that share the same fundamental limitation of fixed memory to compute.",
      "authors": [
        "Jing Ding and Trung Diep"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Performance (cs.PF)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:14:56+00:00",
          "link": "https://arxiv.org/abs/2507.14000v1",
          "size": "2241kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:03:27+00:00",
          "link": "https://arxiv.org/abs/2507.14000v2",
          "size": "2239kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:07:06+00:00",
          "link": "https://arxiv.org/abs/2507.14000v3",
          "size": "2229kb",
          "version": "v3"
        }
      ],
      "title": "Photonic Fabric Platform for AI Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14000",
        "PDF": "https://arxiv.org/pdf/2507.14000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a photonic platform for AI accelerators, targeting improvements in AI training infrastructure and efficiency, but it does not relate to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14219",
      "abstract": "As nations seek sustainable alternatives to fossil fuels, green hydrogen has emerged as a promising strategic pathway toward decarbonisation, particularly in solar-rich arid regions. However, identifying optimal locations for hydrogen production requires the integration of complex environmental, atmospheric, and infrastructural factors, often compounded by limited availability of direct hydrogen yield data. This study presents a novel Artificial Intelligence (AI) framework for computing green hydrogen yield and site suitability index using mean absolute SHAP (SHapley Additive exPlanations) values. This framework consists of a multi-stage pipeline of unsupervised multi-variable clustering, supervised machine learning classifier and SHAP algorithm. The pipeline trains on an integrated meteorological, topographic and temporal dataset and the results revealed distinct spatial patterns of suitability and relative influence of the variables. With model predictive accuracy of 98%, the result also showed that water proximity, elevation and seasonal variation are the most influential factors determining green hydrogen site suitability in Oman with mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively. Given limited or absence of ground-truth yield data in many countries that have green hydrogen prospects and ambitions, this study offers an objective and reproducible alternative to subjective expert weightings, thus allowing the data to speak for itself and potentially discover novel latent groupings without pre-imposed assumptions. This study offers industry stakeholders and policymakers a replicable and scalable tool for green hydrogen infrastructure planning and other decision making in data-scarce regions.",
      "authors": [
        "Obumneme Zimuzor Nwafor and Mohammed Abdul Majeed Al Hooti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:56:24+00:00",
          "link": "https://arxiv.org/abs/2507.14219v1",
          "size": "1532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:00:49+00:00",
          "link": "https://arxiv.org/abs/2507.14219v2",
          "size": "1532kb",
          "version": "v2"
        }
      ],
      "title": "Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14219",
        "PDF": "https://arxiv.org/pdf/2507.14219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents an AI framework for green hydrogen yield prediction and site suitability, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14270",
      "abstract": "We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both computationally efficient and elegant. The proposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters $\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69% test accuracy in just 20 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and computational efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it.",
      "authors": [
        "Ravin Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:17:40+00:00",
          "link": "https://arxiv.org/abs/2507.14270v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:09:48+00:00",
          "link": "https://arxiv.org/abs/2507.14270v2",
          "size": "55kb",
          "version": "v2"
        }
      ],
      "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14270",
        "HTML": "https://arxiv.org/html/2507.14270v2",
        "PDF": "https://arxiv.org/pdf/2507.14270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the APTx Neuron, a unified neural computation unit, and does not discuss any data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14446",
      "abstract": "In this work, we study how to efficiently apply reinforcement learning (RL) for solving large-scale stochastic optimization problems by leveraging intervention models. The key of the proposed methodology is to better explore the solution space by simulating and composing the stochastic processes using pre-trained deep learning (DL) models. We demonstrate our approach on a challenging real-world application, the multi-sourcing multi-period inventory management problem in supply chain optimization. In particular, we employ deep RL models for learning and forecasting the stochastic supply chain processes under a range of assumptions. Moreover, we also introduce a constraint coordination mechanism, designed to forecast dual costs given the cross-products constraints in the inventory network. We highlight that instead of directly modeling the complex physical constraints into the RL optimization problem and solving the stochastic problem as a whole, our approach breaks down those supply chain processes into scalable and composable DL modules, leading to improved performance on large real-world datasets. We also outline open problems for future research to further investigate the efficacy of such models.",
      "authors": [
        "Defeng Liu",
        "Ying Liu",
        "Carson Eisenach"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:44:45+00:00",
          "link": "https://arxiv.org/abs/2507.14446v1",
          "size": "519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T20:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.14446v2",
          "size": "519kb",
          "version": "v2"
        }
      ],
      "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14446",
        "HTML": "https://arxiv.org/html/2507.14446v2",
        "PDF": "https://arxiv.org/pdf/2507.14446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on inventory management using reinforcement learning for supply chain optimization and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14456",
      "abstract": "End-to-end autonomous driving requires adaptive and robust handling of complex and diverse traffic environments. However, prevalent single-mode planning methods attempt to learn an overall policy while struggling to acquire diversified driving skills to handle diverse scenarios. Therefore, this paper proposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework featuring a Global Expert, a Scene-Adaptive Experts Group, and equipped with a Dual-aware Router. Specifically, the Global Expert is trained on the overall dataset, possessing robust performance. The Scene-Adaptive Experts are trained on corresponding scene subsets, achieving adaptive performance. The Dual-aware Router simultaneously considers scenario-level features and routing uncertainty to dynamically activate expert modules. Through the effective coupling of the Global Expert and the Scene-Adaptive Experts Group via the Dual-aware Router, GEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS outperforms existing methods in the Bench2Drive closed-loop benchmark and achieves state-of-the-art performance in Driving Score and Success Rate, even with only monocular vision input. Furthermore, ablation studies demonstrate significant improvements over the original single-expert baseline: 7.67% in Driving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The code will be available at https://github.com/newbrains1/GEMINUS.",
      "authors": [
        "Chi Wan and Yixin Cui and Jiatong Du and Shuo Yang and Yulong Bai and Yanjun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:04:28+00:00",
          "link": "https://arxiv.org/abs/2507.14456v1",
          "size": "358kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T03:58:25+00:00",
          "link": "https://arxiv.org/abs/2507.14456v2",
          "size": "358kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T08:26:59+00:00",
          "link": "https://arxiv.org/abs/2507.14456v3",
          "size": "358kb",
          "version": "v3"
        }
      ],
      "title": "GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14456",
        "HTML": "https://arxiv.org/html/2507.14456v3",
        "PDF": "https://arxiv.org/pdf/2507.14456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a Mixture-of-Experts framework for autonomous driving and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14687",
      "abstract": "Modified Condition/Decision Coverage (MC/DC) is a mandatory structural coverage criterion for ensuring the reliability and safety of critical systems. While its strictest form, Unique-Cause MC/DC, offers the highest assurance, research on its efficient test generation has been lacking. This gap is particularly significant, as an analysis of large-scale avionics systems shows that 99.7% of all conditional decisions are, in fact, Singular Boolean Expressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This paper proposes 'Robin's Rule', a deterministic algorithm that directly constructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause MC/DC for SBEs with N conditions, without generating a full truth table. To validate our approach, we constructed a benchmark by reformulating the TCAS-II specifications into SBEs and verified the results using an industry-standard, certified commercial tool. The results confirm that our method consistently achieves 100% coverage with the theoretical minimum number of tests and is more efficient than the commercial tool. This work provides a practical and provably optimal solution for verifying safety-critical systems, ensuring both rigor and efficiency.",
      "authors": [
        "Robin Lee",
        "Youngho Nam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:30:39+00:00",
          "link": "https://arxiv.org/abs/2507.14687v1",
          "size": "220kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T19:13:57+00:00",
          "link": "https://arxiv.org/abs/2507.14687v2",
          "size": "232kb",
          "version": "v2"
        }
      ],
      "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14687",
        "HTML": "https://arxiv.org/html/2507.14687v2",
        "PDF": "https://arxiv.org/pdf/2507.14687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a deterministic algorithm for generating MC/DC test cases for Boolean expressions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14792",
      "abstract": "Information processing tasks involve complex cognitive mechanisms that are shaped by various factors, including individual goals, prior experience, and system environments. Understanding such behaviors requires a sophisticated and personalized data capture of how one interacts with modern information systems (e.g., web search engines). Passive sensors, such as wearables, capturing physiological and behavioral data, have the potential to provide solutions in this context. This paper presents a novel dataset, SenseSeek, designed to evaluate the effectiveness of consumer-grade sensors in a complex information processing scenario: searching via systems (e.g., search engines), one of the common strategies users employ for information seeking. The SenseSeek dataset comprises data collected from 20 participants, 235 trials of the stimulated search process, 940 phases of stages in the search process, including the realization of Information Need (IN), Query Formulation (QF), Query Submission by Typing (QS-T) or Speaking (QS-S), and Relevance Judgment by Reading (RJ-R) or Listening (RJ-L). The data includes Electrodermal Activities (EDA), Electroencephalogram (EEG), PUPIL, GAZE, and MOTION data, which were captured using consumer-grade sensors. It also contains 258 features extracted from the sensor data, the gaze-annotated screen recordings, and task responses. We validate the usefulness of the dataset by providing baseline analysis on the impacts of different cognitive intents and interaction modalities on the sensor data, and effectiveness of the data in discriminating the search stages. To our knowledge, SenseSeek is the first dataset that characterizes the multiple stages involved in information seeking with physiological signals collected from multiple sensors. We hope this dataset can serve as a reference for future research on information-seeking behaviors.",
      "authors": [
        "Kaixin Ji",
        "Danula Hettiachchi",
        "Falk Scholer",
        "Flora D. Salim",
        "Damiano Spina"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:35:47+00:00",
          "link": "https://arxiv.org/abs/2507.14792v1",
          "size": "1884kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:42:07+00:00",
          "link": "https://arxiv.org/abs/2507.14792v2",
          "size": "1777kb",
          "version": "v2"
        }
      ],
      "title": "SenseSeek Dataset: Multimodal Sensing to Study Information Seeking Behaviors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14792",
        "HTML": "https://arxiv.org/html/2507.14792v2",
        "PDF": "https://arxiv.org/pdf/2507.14792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents the SenseSeek dataset focused on multimodal sensing for studying information seeking behaviors, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14811",
      "abstract": "Diffusion models have demonstrated exceptional generative capabilities but are computationally intensive, posing significant challenges for deployment in resource-constrained or latency-sensitive environments. Quantization offers an effective means to reduce model size and computational cost, with post-training quantization (PTQ) being particularly appealing due to its compatibility with pre-trained models without requiring retraining or training data. However, existing PTQ methods for diffusion models often rely on architecture-specific heuristics that limit their generalizability and hinder integration with industrial deployment pipelines. To address these limitations, we propose SegQuant, a unified quantization framework that adaptively combines complementary techniques to enhance cross-model versatility. SegQuant consists of a segment-aware, graph-based quantization strategy (SegLinear) that captures structural semantics and spatial heterogeneity, along with a dual-scale quantization scheme (DualScale) that preserves polarity-asymmetric activations, which is crucial for maintaining visual fidelity in generated outputs. SegQuant is broadly applicable beyond Transformer-based diffusion models, achieving strong performance while ensuring seamless compatibility with mainstream deployment tools.",
      "authors": [
        "Jiaji Zhang",
        "Ruichao Sun",
        "Hailiang Zhao",
        "Jiaju Wu",
        "Peng Chen",
        "Hao Li",
        "Yuying Liu",
        "Xinkui Zhao",
        "Kingsum Chow",
        "Gang Xiong",
        "Shuiguang Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:00:53+00:00",
          "link": "https://arxiv.org/abs/2507.14811v1",
          "size": "38338kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:36:08+00:00",
          "link": "https://arxiv.org/abs/2507.14811v2",
          "size": "38338kb",
          "version": "v2"
        }
      ],
      "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14811",
        "HTML": "https://arxiv.org/html/2507.14811v2",
        "PDF": "https://arxiv.org/pdf/2507.14811"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a quantization framework for diffusion models, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14871",
      "abstract": "A prominent achievement of natural language processing (NLP) is its ability to understand and generate meaningful human language. This capability relies on complex feedforward transformer block architectures pre-trained on large language models (LLMs). However, LLM pre-training is currently feasible only for a few dominant companies due to the immense computational resources required, limiting broader research participation. This creates a critical need for more accessible alternatives. In this study, we explore whether tiny language models (TLMs) exhibit the same key qualitative features of LLMs. We demonstrate that TLMs exhibit a clear performance gap between pre-trained and non-pre-trained models across classification tasks, indicating the effectiveness of pre-training, even at a tiny scale. The performance gap increases with the size of the pre-training dataset and with greater overlap between tokens in the pre-training and classification datasets. Furthermore, the classification accuracy achieved by a pre-trained deep TLM architecture can be replicated through a soft committee of multiple, independently pre-trained shallow architectures, enabling low-latency TLMs without affecting classification accuracy. Our results are based on pre-training BERT-6 and variants of BERT-1 on subsets of the Wikipedia dataset and evaluating their performance on FewRel, AGNews, and DBPedia classification tasks. Future research on TLM is expected to further illuminate the mechanisms underlying NLP, especially given that its biologically inspired models suggest that TLMs may be sufficient for children or adolescents to develop language. The data and code that support the findings of this study are openly available on https://github.com/Rg32601/Tiny-Language-Models .",
      "authors": [
        "Ronit D. Gross",
        "Yarden Tzach",
        "Tal Halevi",
        "Ella Koresh and Ido Kanter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T08:49:57+00:00",
          "link": "https://arxiv.org/abs/2507.14871v1",
          "size": "693kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:43:38+00:00",
          "link": "https://arxiv.org/abs/2507.14871v2",
          "size": "1044kb",
          "version": "v2"
        }
      ],
      "title": "Tiny language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14871",
        "PDF": "https://arxiv.org/pdf/2507.14871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses tiny language models and their performance across classification tasks with varying pre-training datasets but does not delve into detailed data processing techniques or create new datasets specifically for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14900",
      "abstract": "Large language models (LLMs) have demonstrated remarkable multilingual capabilities, however, how to evaluate cross-lingual alignment remains underexplored. Existing alignment benchmarks primarily focus on sentence embeddings, but prior research has shown that neural models tend to induce a non-smooth representation space, which impact of semantic alignment evaluation on low-resource languages. Inspired by neuroscientific findings that similar information activates overlapping neuronal regions, we propose a novel Neuron State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a lignment capabilities of LLMs, which offers a more semantically grounded approach to assess cross-lingual alignment. We evaluate NeuronXA on several prominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two transfer tasks and three multilingual benchmarks. The results demonstrate that with only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation of 0.9556 with downstream tasks performance and 0.8514 with transferability. These findings demonstrate NeuronXA's effectiveness in assessing both cross-lingual alignment and transferability, even with a small dataset. This highlights its potential to advance cross-lingual alignment research and to improve the semantic understanding of multilingual LLMs.",
      "authors": [
        "Chongxuan Huang",
        "Yongshi Ye",
        "Biao Fu",
        "Qifeng Su",
        "Xiaodong Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.14900v1",
          "size": "1373kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:32:32+00:00",
          "link": "https://arxiv.org/abs/2507.14900v2",
          "size": "1373kb",
          "version": "v2"
        }
      ],
      "title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14900",
        "HTML": "https://arxiv.org/html/2507.14900v2",
        "PDF": "https://arxiv.org/pdf/2507.14900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating cross-linguistic alignment capabilities of LLMs using a novel alignment method, not on training data processing or dataset improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15120",
      "abstract": "Standard automated planning employs first-order formulas under closed-world semantics to achieve a goal with a given set of actions from an initial state. We follow a line of research that aims to incorporate background knowledge into automated planning problems, for example, by means of ontologies, which are usually interpreted under open-world semantics. We present a new approach for planning with DL-Lite ontologies that combines the advantages of ontology-based action conditions provided by explicit-input knowledge and action bases (eKABs) and ontology-aware action effects under the coherence update semantics. We show that the complexity of the resulting formalism is not higher than that of previous approaches and provide an implementation via a polynomial compilation into classical planning. An evaluation of existing and new benchmarks examines the performance of a planning system on different variants of our compilation.",
      "authors": [
        "Stefan Borgwardt",
        "Duy Nhu",
        "Gabriele R\\\"oger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:49:21+00:00",
          "link": "https://arxiv.org/abs/2507.15120v1",
          "size": "65kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:09:15+00:00",
          "link": "https://arxiv.org/abs/2507.15120v2",
          "size": "65kb",
          "version": "v2"
        }
      ],
      "title": "Automated planning with ontologies under coherence update semantics (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15120",
        "HTML": "https://arxiv.org/html/2507.15120v2",
        "PDF": "https://arxiv.org/pdf/2507.15120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is related to automated planning with ontologies and coherence update semantics, not to LLM training data processing or dataset development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15401",
      "abstract": "Facial expression recognition (FER) is a challenging task due to pervasive occlusion and dataset biases. Especially when facial information is partially occluded, existing FER models struggle to extract effective facial features, leading to inaccurate classifications. In response, we present ORSANet, which introduces the following three key contributions: First, we introduce auxiliary multi-modal semantic guidance to disambiguate facial occlusion and learn high-level semantic knowledge, which is two-fold: 1) we introduce semantic segmentation maps as dense semantics prior to generate semantics-enhanced facial representations; 2) we introduce facial landmarks as sparse geometric prior to mitigate intrinsic noises in FER, such as identity and gender biases. Second, to facilitate the effective incorporation of these two multi-modal priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively fuse the landmark feature and semantics-enhanced representations within different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes, further enhancing the model's ability to distinguish similar expressions. We further construct the first occlusion-oriented FER dataset to facilitate specialized robustness analysis on various real-world occlusion conditions, dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER demonstrate that our proposed ORSANet achieves SOTA recognition performance. Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.",
      "authors": [
        "Huiyu Zhai",
        "Xingxing Yang",
        "Yalan Ye",
        "Chenyang Li",
        "Bin Fan",
        "Changze Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:04:29+00:00",
          "link": "https://arxiv.org/abs/2507.15401v1",
          "size": "1925kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:58:54+00:00",
          "link": "https://arxiv.org/abs/2507.15401v2",
          "size": "1915kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15401",
        "HTML": "https://arxiv.org/html/2507.15401v2",
        "PDF": "https://arxiv.org/pdf/2507.15401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for facial expression recognition using multi-modal semantic guidance, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15455",
      "abstract": "We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.",
      "authors": [
        "Hee Jun Yang",
        "Minjung Gim",
        "Yeoneung Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:06:53+00:00",
          "link": "https://arxiv.org/abs/2507.15455v1",
          "size": "1176kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:44:15+00:00",
          "link": "https://arxiv.org/abs/2507.15455v2",
          "size": "1177kb",
          "version": "v2"
        }
      ],
      "title": "Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15455",
        "HTML": "https://arxiv.org/html/2507.15455v2",
        "PDF": "https://arxiv.org/pdf/2507.15455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a policy iteration framework using physics-informed neural networks to solve Hamilton--Jacobi--Isaacs equations, primarily discussing applications in robotics, finance, and multi-agent reinforcement learning, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15460",
      "abstract": "Personalized News Recommendation systems (PNR) have emerged as a solution to information overload by predicting and suggesting news items tailored to individual user interests. However, traditional PNR systems face several challenges, including an overreliance on textual content, common neglect of short-term user interests, and significant privacy concerns due to centralized data storage. This paper addresses these issues by introducing a novel multimodal federated learning-based approach for news recommendation. First, it integrates both textual and visual features of news items using a multimodal model, enabling a more comprehensive representation of content. Second, it employs a time-aware model that balances users' long-term and short-term interests through multi-head self-attention networks, improving recommendation accuracy. Finally, to enhance privacy, a federated learning framework is implemented, enabling collaborative model training without sharing user data. The framework divides the recommendation model into a large server-maintained news model and a lightweight user model shared between the server and clients. The client requests news representations (vectors) and a user model from the central server, then computes gradients with user local data, and finally sends their locally computed gradients to the server for aggregation. The central server aggregates gradients to update the global user model and news model. The updated news model is further used to infer news representation by the server. To further safeguard user privacy, a secure aggregation algorithm based on Shamir's secret sharing is employed. Experiments on a real-world news dataset demonstrate strong performance compared to existing systems, representing a significant advancement in privacy-preserving personalized news recommendation.",
      "authors": [
        "Mehdi Khalaj",
        "Shahrzad Golestani Najafabadi",
        "Julita Vassileva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:14:00+00:00",
          "link": "https://arxiv.org/abs/2507.15460v1",
          "size": "1411kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T09:04:45+00:00",
          "link": "https://arxiv.org/abs/2507.15460v2",
          "size": "1410kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T03:40:18+00:00",
          "link": "https://arxiv.org/abs/2507.15460v3",
          "size": "1410kb",
          "version": "v3"
        }
      ],
      "title": "Privacy-Preserving Multimodal News Recommendation through Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15460",
        "HTML": "https://arxiv.org/html/2507.15460v3",
        "PDF": "https://arxiv.org/pdf/2507.15460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a privacy-preserving multimodal news recommendation system using federated learning, which primarily revolves around user privacy and recommendation accuracy, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15586",
      "abstract": "Retrieval-Augmented Generation (RAG) effectively improves the accuracy of Large Language Models (LLMs). However, retrieval noises significantly impact the quality of LLMs' generation, necessitating the development of denoising mechanisms. Previous methods extract evidence straightforwardly without explicit thinking, which risks filtering out key clues and struggles with generalization. To this end, we propose LEAR, which learns to extract rational evidence by (1) explicitly reasoning to identify potential cues within retrieval contents first, and then (2) consciously extracting to avoid omitting any key cues helpful for answering questions. Specifically, we frame evidence reasoning and evidence extraction into one unified response for end-to-end training; apply knowledge token masks for disentanglement to derive reasoning-based and extraction-based answers; and devise three types of verifiable reward functions, including answer, length, and format, to update the model via the policy optimization algorithm. Extensive experiments on three benchmark datasets show the effectiveness of LEAR, providing compact and high-quality evidence, improving the accuracy of downstream tasks, and promoting effective application in online RAG systems.",
      "authors": [
        "Xinping Zhao",
        "Shouzheng Huang",
        "Yan Zhong",
        "Xinshuo Hu",
        "Meishan Zhang",
        "Baotian Hu",
        "Min Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.15586v1",
          "size": "4218kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:08:33+00:00",
          "link": "https://arxiv.org/abs/2507.15586v2",
          "size": "4218kb",
          "version": "v2"
        }
      ],
      "title": "Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15586",
        "HTML": "https://arxiv.org/html/2507.15586v2",
        "PDF": "https://arxiv.org/pdf/2507.15586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for evidence extraction in Retrieval-Augmented Generation (RAG) via reinforcement learning, which may indirectly relate to training data processing methods for RAG applications but is not primarily focused on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15680",
      "abstract": "Image Quality Assessment (IQA) is a core task in computer vision. Multimodal methods based on vision-language models, such as CLIP, have demonstrated exceptional generalization capabilities in IQA tasks. To address the issues of excessive parameter burden and insufficient ability to identify local distorted features in CLIP for IQA, this study proposes a visual-language model knowledge distillation method aimed at guiding the training of models with architectural advantages using CLIP's IQA knowledge. First, quality-graded prompt templates were designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned to enhance its capabilities in IQA tasks. Finally, a modality-adaptive knowledge distillation strategy is proposed to achieve guidance from the CLIP teacher model to the student model. Our experiments were conducted on multiple IQA datasets, and the results show that the proposed method significantly reduces model complexity while outperforming existing IQA methods, demonstrating strong potential for practical deployment.",
      "authors": [
        "Yongkang Hou",
        "Jiarun Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:44:46+00:00",
          "link": "https://arxiv.org/abs/2507.15680v1",
          "size": "853kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T14:17:49+00:00",
          "link": "https://arxiv.org/abs/2507.15680v2",
          "size": "871kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T08:20:34+00:00",
          "link": "https://arxiv.org/abs/2507.15680v3",
          "size": "872kb",
          "version": "v3"
        }
      ],
      "title": "Visual-Language Model Knowledge Distillation Method for Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15680",
        "PDF": "https://arxiv.org/pdf/2507.15680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a knowledge distillation method for image quality assessment using CLIP, which concerns vision-language modeling and not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15850",
      "abstract": "Arabic is one of the most widely spoken languages in the world, yet efforts to develop and evaluate Large Language Models (LLMs) for Arabic remain relatively limited. Most existing Arabic benchmarks focus on linguistic, cultural, or religious content, leaving a significant gap in domains like STEM and code which are increasingly relevant for real-world LLM applications. To help bridge this gap, we present 3LM, a suite of three benchmarks designed specifically for Arabic. The first is a set of STEM-related question-answer pairs, naturally sourced from Arabic textbooks and educational worksheets. The second consists of synthetically generated STEM questions, created using the same sources. The third benchmark focuses on code generation, built through a careful translation of two widely used code benchmarks, incorporating a human-in-the-loop process with several rounds of review to ensure high-quality and faithful translations. We release all three benchmarks publicly to support the growth of Arabic LLM research in these essential but underrepresented areas.",
      "authors": [
        "Basma El Amel Boussaha",
        "Leen AlQadi",
        "Mugariya Farooq",
        "Shaikha Alsuwaidi",
        "Giulia Campesan",
        "Ahmed Alzubaidi",
        "Mohammed Alyafeai",
        "Hakim Hacid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:58:27+00:00",
          "link": "https://arxiv.org/abs/2507.15850v1",
          "size": "1481kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T18:43:45+00:00",
          "link": "https://arxiv.org/abs/2507.15850v2",
          "size": "1479kb",
          "version": "v2"
        }
      ],
      "title": "3LM: Bridging Arabic, STEM, and Code through Benchmarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15850",
        "PDF": "https://arxiv.org/pdf/2507.15850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of three benchmarks for Arabic in STEM and code, focusing on linguistic evaluation. While it touches on data generation, the main contribution centers around evaluation and benchmarking rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15917",
      "abstract": "The synergy between symbolic knowledge, often represented by Knowledge Graphs (KGs), and the generative capabilities of neural networks is central to advancing neurosymbolic AI. A primary bottleneck in realizing this potential is the difficulty of automating KG construction, which faces challenges related to output reliability, consistency, and verifiability. These issues can manifest as structural inconsistencies within the generated graphs, such as the formation of disconnected $\\textit{isolated islands}$ of data or the inaccurate conflation of abstract classes with specific instances. To address these challenges, we propose HyDRA, a $\\textbf{Hy}$brid-$\\textbf{D}$riven $\\textbf{R}$easoning $\\textbf{A}$rchitecture designed for verifiable KG automation. Given a domain or an initial set of documents, HyDRA first constructs an ontology via a panel of collaborative neurosymbolic agents. These agents collaboratively agree on a set of competency questions (CQs) that define the scope and requirements the ontology must be able to answer. Given these CQs, we build an ontology graph that subsequently guides the automated extraction of triplets for KG generation from arbitrary documents. Inspired by design-by-contracts (DbC) principles, our method leverages verifiable contracts as the primary control mechanism to steer the generative process of Large Language Models (LLMs). To verify the output of our approach, we extend beyond standard benchmarks and propose an evaluation framework that assesses the functional correctness of the resulting KG by leveraging symbolic verifications as described by the neurosymbolic AI framework, $\\textit{SymbolicAI}$. This work contributes a hybrid-driven architecture for improving the reliability of automated KG construction and the exploration of evaluation methods for measuring the functional integrity of its output. The code is publicly available.",
      "authors": [
        "Adrian Kaiser and Claudiu Leoveanu-Condrei and Ryan Gold and Marius-Constantin Dinu and Markus Hofmarcher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:57:17+00:00",
          "link": "https://arxiv.org/abs/2507.15917v1",
          "size": "952kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:32:44+00:00",
          "link": "https://arxiv.org/abs/2507.15917v2",
          "size": "952kb",
          "version": "v2"
        }
      ],
      "title": "HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15917",
        "HTML": "https://arxiv.org/html/2507.15917v2",
        "PDF": "https://arxiv.org/pdf/2507.15917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work primarily focuses on automating knowledge graph construction and its verification, which does not directly relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16044",
      "abstract": "Large Language Models (LLMs) are evolving from passive text generators into active agents that invoke external tools. To support this shift, scalable protocols for tool integration are essential. The Model Context Protocol (MCP), introduced by Anthropic in 2024, offers a schema-driven standard for dynamic tool discovery and invocation. Yet, building MCP servers remains manual and repetitive, requiring developers to write glue code, handle authentication, and configure schemas by hand-replicating much of the integration effort MCP aims to eliminate.\n  This paper investigates whether MCP server construction can be meaningfully automated. We begin by analyzing adoption trends: among 22,000+ MCP-tagged GitHub repositories created within six months of release, fewer than 5% include servers, typically small, single-maintainer projects dominated by repetitive scaffolding. To address this gap, we present AutoMCP, a compiler that generates MCP servers from OpenAPI 2.0/3.0 specifications. AutoMCP parses REST API definitions and produces complete server implementations, including schema registration and authentication handling.\n  We evaluate AutoMCP on 50 real-world APIs spanning 5,066 endpoints across over 10 domains. From a stratified sample of 1,023 tool calls, 76.5% succeeded out of the box. Manual failure analysis revealed five recurring issues, all attributable to inconsistencies or omissions in the OpenAPI contracts. After minor fixes, averaging 19 lines of spec changes per API, AutoMCP achieved 99.9% success.\n  Our findings (i) analyze MCP adoption and quantify the cost of manual server development, (ii) demonstrate that OpenAPI specifications, despite quality issues, enable near-complete MCP server automation, and (iii) contribute a corpus of 5,066 callable tools along with insights on repairing common specification flaws.",
      "authors": [
        "Meriem Mastouri",
        "Emna Ksontini",
        "and Wael Kessentini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T20:20:31+00:00",
          "link": "https://arxiv.org/abs/2507.16044v1",
          "size": "804kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T16:37:47+00:00",
          "link": "https://arxiv.org/abs/2507.16044v2",
          "size": "811kb",
          "version": "v2"
        }
      ],
      "title": "Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16044",
        "HTML": "https://arxiv.org/html/2507.16044v2",
        "PDF": "https://arxiv.org/pdf/2507.16044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automating the construction of MCP servers from OpenAPI specifications. It addresses tool integration for augmented LLMs rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16089",
      "abstract": "For applications that store structured data in relational databases, there is an impedance mismatch between the flat representations encouraged by relational data models and the deeply nested information that applications expect to receive. In this work, we present the graph-relational database model, which provides a flexible, compositional, and strongly-typed solution to this \"object-relational mismatch.\" We formally define the graph-relational database model and present a static and dynamic semantics for queries. In addition, we discuss the realization of the graph-relational database model in EdgeQL, a general-purpose SQL-style query language, and the Gel system, which compiles EdgeQL schemas and queries into PostgreSQL queries. Gel facilitates the kind of object-shaped data manipulation that is frequently provided inefficiently by object-relational mapping (ORM) technologies, while achieving most of the efficiency that comes from writing complex PostgreSQL queries directly.",
      "authors": [
        "Michael J. Sullivan",
        "Zhibo Chen",
        "Elvis Pranskevichus",
        "Robert J. Simmons",
        "Victor Petrovykh",
        "Alja\\v{z} Mur Er\\v{z}en",
        "Yury Selivanov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T22:02:21+00:00",
          "link": "https://arxiv.org/abs/2507.16089v1",
          "size": "1264kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T01:50:49+00:00",
          "link": "https://arxiv.org/abs/2507.16089v2",
          "size": "1264kb",
          "version": "v2"
        }
      ],
      "title": "Querying Graph-Relational Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16089",
        "PDF": "https://arxiv.org/pdf/2507.16089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a graph-relational database model to address object-relational mismatch issues. It does not discuss aspects related to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16199",
      "abstract": "Large Language Models (LLMs) frequently output the label Unknown, yet current evaluations focus almost exclusively on whether such answers are honest rather than why they arise. This blurs two distinct cases: (i) an input that is genuinely indeterminate and (ii) a solvable problem that the model fails to resolve. We call this phenomenon Vague Perception. And thus we introduce a framework that quantifies the proportion of Unknown responses attributable to model incapacity and tests whether guided stimulation can convert them into either correct Known or correct Unknown with valid reasoning. By separating these sources of uncertainty, our method provides a clearer picture of LLM reasoning limits and their potential for improvement. As we get a theoretical accuracy of reasoning task on different LLMs, we apply different methods to test whether the model can reach the accuracy given a baseline framework. Our work is meaningful in exploring the potential reasoning ability of LLMs and providing a new perspective on solving the Vague Perception phenomenon.",
      "authors": [
        "Zipeng Ling",
        "Yuehao Tang",
        "Shuliang Liu",
        "Junqi Yang",
        "Shenghong Fu",
        "Yao Wan",
        "Kejia Huang",
        "Chen Huang",
        "Zhichao Hou",
        "Xuming Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T03:21:48+00:00",
          "link": "https://arxiv.org/abs/2507.16199v1",
          "size": "800kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T12:41:08+00:00",
          "link": "https://arxiv.org/abs/2507.16199v2",
          "size": "1015kb",
          "version": "v2"
        }
      ],
      "title": "WAKENLLM: Evaluating Reasoning Potential and Stability in LLMs via Fine-Grained Benchmarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16199",
        "HTML": "https://arxiv.org/html/2507.16199v2",
        "PDF": "https://arxiv.org/pdf/2507.16199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLM reasoning potential and stability but does not address any aspect of training data processing for LLMs, such as dataset creation or data engineering improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16242",
      "abstract": "The online caching problem aims to minimize cache misses when serving a sequence of requests under a limited cache size. While naive learning-augmented caching algorithms achieve ideal $1$-consistency, they lack robustness guarantees. Existing robustification methods either sacrifice $1$-consistency or introduce significant computational overhead. In this paper, we introduce Guard, a lightweight robustification framework that enhances the robustness of a broad class of learning-augmented caching algorithms to $2H_k + 2$, while preserving their $1$-consistency. Guard achieves the current best-known trade-off between consistency and robustness, with only $O(1)$ additional per-request overhead, thereby maintaining the original time complexity of the base algorithm. Extensive experiments across multiple real-world datasets and prediction models validate the effectiveness of Guard in practice.",
      "authors": [
        "Peng Chen",
        "Hailiang Zhao",
        "Jiaji Zhang",
        "Xueyan Tang",
        "Yixuan Wang",
        "Shuiguang Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T05:26:28+00:00",
          "link": "https://arxiv.org/abs/2507.16242v1",
          "size": "187kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:59:38+00:00",
          "link": "https://arxiv.org/abs/2507.16242v2",
          "size": "187kb",
          "version": "v2"
        }
      ],
      "title": "Toward a Lightweight and Robust Design for Caching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16242",
        "HTML": "https://arxiv.org/html/2507.16242v2",
        "PDF": "https://arxiv.org/pdf/2507.16242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework to enhance the robustness of caching algorithms, which is unrelated to training data processing or improvements in LLM data quality or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16258",
      "abstract": "Autonomous mobility systems increasingly operate in environments shared with animals, from urban pets to wildlife. However, their design has largely focused on human interaction, with limited understanding of how non-human species perceive, respond to, or are affected by these systems. Motivated by research in Animal-Computer Interaction (ACI) and more-than-human design, this study investigates animal interactions with autonomous mobility through a multi-method approach combining a scoping review (45 articles), online ethnography (39 YouTube videos and 11 Reddit discussions), and expert interviews (8 participants). Our analysis surfaces five key areas of concern: Physical Impact (e.g., collisions, failures to detect), Behavioural Effects (e.g., avoidance, stress), Accessibility Concerns (particularly for service animals), Ethics and Regulations, and Urban Disturbance. We conclude with design and policy directions aimed at supporting multispecies coexistence in the age of autonomous systems. This work underscores the importance of incorporating non-human perspectives to ensure safer, more inclusive futures for all species.",
      "authors": [
        "Tram Thi Minh Tran",
        "Xinyan Yu",
        "Marius Hoggenmueller",
        "Callum Parker",
        "Paul Schmitt",
        "Julie Stephany Berrio Perez",
        "Stewart Worrall",
        "Martin Tomitsch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T06:15:56+00:00",
          "link": "https://arxiv.org/abs/2507.16258v1",
          "size": "197kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T01:48:01+00:00",
          "link": "https://arxiv.org/abs/2507.16258v2",
          "size": "197kb",
          "version": "v2"
        }
      ],
      "title": "Animal Interaction with Autonomous Mobility Systems: Designing for Multi-Species Coexistence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16258",
        "HTML": "https://arxiv.org/html/2507.16258v2",
        "PDF": "https://arxiv.org/pdf/2507.16258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses design for autonomous mobility systems in the context of animal interaction, which is not relevant to LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16284",
      "abstract": "The debate surrounding language identification has gained renewed attention in recent years, especially with the rapid evolution of AI-powered language models. However, the non-AI-based approaches to language identification have been overshadowed. This research explores a mathematical implementation of an algorithm for language determinism by leveraging monograms and bigrams frequency rankings derived from established linguistic research. The datasets used comprise texts varying in length, historical period, and genre, including short stories, fairy tales, and poems. Despite these variations, the method achieves over 80\\% accuracy on texts shorter than 150 characters and reaches 100\\% accuracy for longer texts. These results demonstrate that classical frequency-based approaches remain effective and scalable alternatives to AI-driven models for language detection.",
      "authors": [
        "Paul-Andrei Pog\\u{a}cean",
        "Sanda-Maria Avram"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T07:11:01+00:00",
          "link": "https://arxiv.org/abs/2507.16284v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:23:20+00:00",
          "link": "https://arxiv.org/abs/2507.16284v2",
          "size": "41kb",
          "version": "v2"
        }
      ],
      "title": "Language Detection by Means of the Minkowski Norm: Identification Through Character Bigrams and Frequency Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16284",
        "HTML": "https://arxiv.org/html/2507.16284v2",
        "PDF": "https://arxiv.org/pdf/2507.16284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores an algorithm for language detection using character bigrams and frequency analysis, which does not contribute to LLM training data processing or dataset generation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16391",
      "abstract": "With the wide application of machine learning (ML), privacy concerns arise with user data as they may contain sensitive information. Privacy-preserving ML (PPML) based on cryptographic primitives has emerged as a promising solution in which an ML model is directly computed on the encrypted data to provide a formal privacy guarantee. However, PPML frameworks heavily rely on the oblivious transfer (OT) primitive to compute nonlinear functions. OT mainly involves the computation of single-point correlated OT (SPCOT) and learning parity with noise (LPN) operations. As OT is still computed extensively on general-purpose CPUs, it becomes the latency bottleneck of modern PPML frameworks.\n  In this paper, we propose a novel OT accelerator, dubbed Ironman, to significantly increase the efficiency of OT and the overall PPML framework. We observe that SPCOT is computation-bounded, and thus propose a hardware-friendly SPCOT algorithm with a customized accelerator to improve SPCOT computation throughput. In contrast, LPN is memory-bandwidth-bounded due to irregular memory access patterns. Hence, we further leverage the near-memory processing (NMP) architecture equipped with memory-side cache and index sorting to improve effective memory bandwidth. With extensive experiments, we demonstrate Ironman achieves a 39.2-237.4 times improvement in OT throughput across different NMP configurations compared to the full-thread CPU implementation. For different PPML frameworks, Ironman demonstrates a 2.1-3.4 times reduction in end-to-end latency for both CNN and Transformer models.",
      "authors": [
        "Chenqi Lin",
        "Kang Yang",
        "Tianshi Xu",
        "Ling Liang",
        "Yufei Wang",
        "Zhaohui Chen",
        "Runsheng Wang",
        "Mingyu Gao",
        "Meng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T09:35:59+00:00",
          "link": "https://arxiv.org/abs/2507.16391v1",
          "size": "7524kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.16391v2",
          "size": "7524kb",
          "version": "v2"
        }
      ],
      "title": "Ironman: Accelerating Oblivious Transfer Extension for Privacy-Preserving AI with Near-Memory Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16391",
        "HTML": "https://arxiv.org/html/2507.16391v2",
        "PDF": "https://arxiv.org/pdf/2507.16391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an OT accelerator designed to improve privacy-preserving machine learning frameworks. It does not address LLM training data processing operations or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16450",
      "abstract": "Semantic communication systems introduce a new paradigm in wireless communications, focusing on transmitting the intended meaning rather than ensuring strict bit-level accuracy. These systems often rely on Deep Neural Networks (DNNs) to learn and encode meaning directly from data, enabling more efficient communication. However, in multi-user settings where interacting agents are trained independently-without shared context or joint optimization-divergent latent representations across AI-native devices can lead to semantic mismatches, impeding mutual understanding even in the absence of traditional transmission errors. In this work, we address semantic mismatch in Multiple-Input Multiple-Output (MIMO) channels by proposing a joint physical and semantic channel equalization framework that leverages the presence of Reconfigurable Intelligent Surfaces (RIS). The semantic equalization is implemented as a sequence of transformations: (i) a pre-equalization stage at the transmitter; (ii) propagation through the RIS-aided channel; and (iii) a post-equalization stage at the receiver. We formulate the problem as a constrained Minimum Mean Squared Error (MMSE) optimization and propose two solutions: (i) a linear semantic equalization chain, and (ii) a non-linear DNN-based semantic equalizer. Both methods are designed to operate under semantic compression in the latent space and adhere to transmit power constraints. Through extensive evaluations, we show that the proposed joint equalization strategies consistently outperform conventional, disjoint approaches to physical and semantic channel equalization across a broad range of scenarios and wireless channel conditions.",
      "authors": [
        "Tom\\'as H\\\"uttebr\\\"aucker",
        "Mario Edoardo Pandolfo",
        "Simone Fiorellino",
        "Emilio Calvanese Strinati",
        "Paolo Di Lorenzo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T10:51:35+00:00",
          "link": "https://arxiv.org/abs/2507.16450v1",
          "size": "4718kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:38:58+00:00",
          "link": "https://arxiv.org/abs/2507.16450v2",
          "size": "4718kb",
          "version": "v2"
        }
      ],
      "title": "RIS-aided Latent Space Alignment for Semantic Channel Equalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16450",
        "HTML": "https://arxiv.org/html/2507.16450v2",
        "PDF": "https://arxiv.org/pdf/2507.16450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses semantic mismatch in MIMO channels through a semantic channel equalization framework, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16535",
      "abstract": "Despite the remarkable developments achieved by recent 3D generation works, scaling these methods to geographic extents, such as modeling thousands of square kilometers of Earth's surface, remains an open challenge. We address this through a dual innovation in data infrastructure and model architecture. First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date, consisting of 50k curated scenes (each measuring 600m x 600m) captured across the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene provides pose-annotated multi-view images, depth maps, normals, semantic segmentation, and camera poses, with explicit quality control to ensure terrain diversity. Building on this foundation, we propose EarthCrafter, a tailored framework for large-scale 3D Earth generation via sparse-decoupled latent diffusion. Our architecture separates structural and textural generation: 1) Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the costly computation suffering from vast geographic scales while preserving critical information. 2) We propose condition-aware flow matching models trained on mixed inputs (semantics, images, or neither) to flexibly model latent geometry and texture features independently. Extensive experiments demonstrate that EarthCrafter performs substantially better in extremely large-scale generation. The framework further supports versatile applications, from semantic-guided urban layout generation to unconditional terrain synthesis, while maintaining geographic plausibility through our rich data priors from Aerial-Earth3D. Our project page is available at https://whiteinblue.github.io/earthcrafter/",
      "authors": [
        "Shang Liu",
        "Chenjie Cao",
        "Chaohui Yu",
        "Wen Qian",
        "Jing Wang",
        "Fan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T12:46:48+00:00",
          "link": "https://arxiv.org/abs/2507.16535v1",
          "size": "36782kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T01:59:09+00:00",
          "link": "https://arxiv.org/abs/2507.16535v2",
          "size": "36782kb",
          "version": "v2"
        }
      ],
      "title": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16535",
        "HTML": "https://arxiv.org/html/2507.16535v2",
        "PDF": "https://arxiv.org/pdf/2507.16535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Aerial-Earth3D, a large dataset for 3D Earth generation, which involves data collection and quality control. However, its main focus is on 3D model architecture and geographic plausibility rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16727",
      "abstract": "Improving the reliability of large language models (LLMs) is critical for deploying them in real-world scenarios. In this paper, we propose \\textbf{Deliberative Searcher}, the first framework to integrate certainty calibration with retrieval-based search for open-domain question answering. The agent performs multi-step reflection and verification over Wikipedia data and is trained with a reinforcement learning algorithm that optimizes for accuracy under a soft reliability constraint. Empirical results show that proposed method improves alignment between model confidence and correctness, leading to more trustworthy outputs. This paper will be continuously updated.",
      "authors": [
        "Zhenyun Yin",
        "Shujie Wang",
        "Xuhong Wang",
        "Xingjun Ma",
        "Yinchun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T16:09:34+00:00",
          "link": "https://arxiv.org/abs/2507.16727v1",
          "size": "1085kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T03:52:14+00:00",
          "link": "https://arxiv.org/abs/2507.16727v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16727",
        "PDF": "https://arxiv.org/pdf/2507.16727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving LLM reliability through reinforcement learning and certainty calibration for question answering tasks, without addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16799",
      "abstract": "The rapid advancement of large language models (LLMs) has enabled role-playing language agents to demonstrate significant potential in various applications. However, relying solely on prompts and contextual inputs often proves insufficient for achieving deep immersion in specific roles, particularly well-known fictional or public figures. On the other hand, fine-tuning-based approaches face limitations due to the challenges associated with data collection and the computational resources required for training, thereby restricting their broader applicability. To address these issues, we propose Test-Time-Matching (TTM), a training-free role-playing framework through test-time scaling and context engineering. TTM uses LLM agents to automatically decouple a character's features into personality, memory, and linguistic style. Our framework involves a structured, three-stage generation pipeline that utilizes these features for controlled role-playing. It achieves high-fidelity role-playing performance, also enables seamless combinations across diverse linguistic styles and even variations in personality and memory. We evaluate our framework through human assessment, and the results demonstrate that our method achieves the outstanding performance in generating expressive and stylistically consistent character dialogues.",
      "authors": [
        "Xiaoyu Zhan",
        "Xinyu Fu",
        "Hao Sun",
        "Yuanqi Li",
        "Jie Guo",
        "Yanwen Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T17:47:44+00:00",
          "link": "https://arxiv.org/abs/2507.16799v1",
          "size": "578kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:06:43+00:00",
          "link": "https://arxiv.org/abs/2507.16799v2",
          "size": "578kb",
          "version": "v2"
        }
      ],
      "title": "Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16799",
        "PDF": "https://arxiv.org/pdf/2507.16799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a training-free framework for LLM-based role-playing agents, focusing on decoupling character features and generation strategies rather than LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "asinmhk/TTM_cache",
          "downloads": "0",
          "likes": "0",
          "link": "https://huggingface.co/datasets/asinmhk/TTM_cache"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.16802",
      "abstract": "Large Language Models (LLMs) exhibit considerable promise in financial applications; however, prevailing models frequently demonstrate limitations when confronted with scenarios that necessitate sophisticated reasoning capabilities, stringent trustworthiness criteria, and efficient adaptation to domain-specific requirements. We introduce the Agentar-Fin-R1 series of financial large language models (8B and 32B parameters), specifically engineered based on the Qwen3 foundation model to enhance reasoning capabilities, reliability, and domain specialization for financial applications. Our optimization approach integrates a high-quality, systematic financial task label system with a comprehensive multi-layered trustworthiness assurance framework. This framework encompasses high-quality trustworthy knowledge engineering, multi-agent trustworthy data synthesis, and rigorous data validation governance. Through label-guided automated difficulty-aware optimization, tow-stage training pipeline, and dynamic attribution systems, we achieve substantial improvements in training efficiency. Our models undergo comprehensive evaluation on mainstream financial benchmarks including Fineva, FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500 and GPQA-diamond. To thoroughly assess real-world deployment capabilities, we innovatively propose the Finova evaluation benchmark, which focuses on agent-level financial reasoning and compliance verification. Experimental results demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art performance on financial tasks but also exhibits exceptional general reasoning capabilities, validating its effectiveness as a trustworthy solution for high-stakes financial applications. The Finova bench is available at https://github.com/antgroup/Finova.",
      "authors": [
        "Yanjun Zheng",
        "Xiyang Du",
        "Longfei Liao",
        "Xiaoke Zhao",
        "Zhaowen Zhou",
        "Bo Zhang",
        "Jiawei Liu",
        "Xiang Qi",
        "Zhe Li",
        "Zhiqiang Zhang",
        "Wei Wang and Peng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T17:52:16+00:00",
          "link": "https://arxiv.org/abs/2507.16802v1",
          "size": "1913kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T17:47:01+00:00",
          "link": "https://arxiv.org/abs/2507.16802v2",
          "size": "1986kb",
          "version": "v2"
        }
      ],
      "title": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16802",
        "HTML": "https://arxiv.org/html/2507.16802v2",
        "PDF": "https://arxiv.org/pdf/2507.16802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses optimization in LLMs for financial applications, it includes aspects of data synthesis and validation governance, indirectly touching upon data processing, though the primary focus is on model architecture and application."
      },
      "source": "arXiv"
    },
    {
      "id": "2108.02283",
      "abstract": "We use multi-class machine learning classifiers to identify the stocks that outperform or underperform other stocks. The resulting long-short portfolios achieve annual Sharpe ratios of 1.67 (value-weighted) and 3.35 (equal-weighted), with annual alphas ranging from 29\\% to 48\\%. These results persist after controlling for machine learning regressions and remain robust among large-cap stocks. Machine uncertainty, as measured by predicted probabilities, impairs the prediction performance. Stocks with higher machine uncertainty experience lower returns, particularly when human proxies of information uncertainty align with machine uncertainty. Consistent with the literature, such an effect is driven by the past underperformers.",
      "authors": [
        "Yang Bai and Kuntara Pukthuanthong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Machine Learning (cs.LG)",
        "General Economics (econ.GN)",
        "Computational Finance (q-fin.CP)",
        "Economics (q-fin.EC)",
        "Portfolio Management (q-fin.PM)"
      ],
      "submission_historys": [
        {
          "date": "2021-08-04T20:48:27+00:00",
          "link": "https://arxiv.org/abs/2108.02283v1",
          "size": "44418kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:52:55+00:00",
          "link": "https://arxiv.org/abs/2108.02283v2",
          "size": "124kb",
          "version": "v2"
        }
      ],
      "title": "Machine Learning Classification and Portfolio Allocation: with Implications from Machine Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2108.02283",
        "HTML": "https://arxiv.org/html/2108.02283v2",
        "PDF": "https://arxiv.org/pdf/2108.02283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study uses machine learning classifiers for stock portfolio allocation and examines prediction performance under machine uncertainty. It does not involve any aspect of LLM training data processing."
      },
      "tasks": [
        "BIG-bench Machine Learning",
        "Classification",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2208.13296",
      "abstract": "The problem of computing posterior functionals in general high-dimensional statistical models with possibly non-log-concave likelihood functions is considered. Based on the proof strategy of Nickl and Wang (2022), but using only local likelihood conditions and without relying on M-estimation theory, nonasymptotic statistical and computational guarantees are provided for a gradient based MCMC algorithm. Given a suitable initialiser, these guarantees scale polynomially in key algorithmic quantities. The abstract results are applied to several concrete statistical models, including density estimation, nonparametric regression with generalised linear models and a canonical statistical non-linear inverse problem from PDEs.",
      "authors": [
        "Randolf Altmeyer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (math.NA)",
        "Probability (math.PR)",
        "Computation (stat.CO)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-28T21:49:06+00:00",
          "link": "https://arxiv.org/abs/2208.13296v1",
          "size": "48kb",
          "version": "v1"
        },
        {
          "date": "2024-06-20T11:09:40+00:00",
          "link": "https://arxiv.org/abs/2208.13296v2",
          "size": "51kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T11:53:46+00:00",
          "link": "https://arxiv.org/abs/2208.13296v3",
          "size": "66kb",
          "version": "v3"
        }
      ],
      "title": "Polynomial time guarantees for sampling based posterior inference in high-dimensional generalised linear models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.13296",
        "HTML": "https://arxiv.org/html/2208.13296v3",
        "PDF": "https://arxiv.org/pdf/2208.13296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on statistical and computational guarantees for posterior inference in high-dimensional models via MCMC, which does not relate to language model data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.11962",
      "abstract": "We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also establish complexity bounds for the classes of gradient-dominated objectives, that include convex and strongly convex problems. For Auxiliary Learning, we show that using a helper (auxiliary function) can outperform training alone if a given similarity measure is small.",
      "authors": [
        "El Mahdi Chayti and Nikita Doikov and Martin Jaggi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-23T12:18:28+00:00",
          "link": "https://arxiv.org/abs/2302.11962v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2023-09-06T14:38:35+00:00",
          "link": "https://arxiv.org/abs/2302.11962v2",
          "size": "432kb",
          "version": "v2"
        },
        {
          "date": "2024-08-29T14:31:58+00:00",
          "link": "https://arxiv.org/abs/2302.11962v3",
          "size": "635kb",
          "version": "v3"
        },
        {
          "date": "2024-09-05T13:42:02+00:00",
          "link": "https://arxiv.org/abs/2302.11962v4",
          "size": "631kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T16:01:17+00:00",
          "link": "https://arxiv.org/abs/2302.11962v5",
          "size": "614kb",
          "version": "v5"
        }
      ],
      "title": "Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.11962",
        "HTML": "https://arxiv.org/html/2302.11962v5",
        "PDF": "https://arxiv.org/pdf/2302.11962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses optimization methods for solving minimization problems and does not involve LLM training data processing or dataset-related techniques."
      },
      "tasks": [
        "Auxiliary Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.05263",
      "abstract": "In applied Bayesian inference scenarios, users may have access to a large number of pre-existing model evaluations, for example from maximum-a-posteriori (MAP) optimization runs. However, traditional approximate inference techniques make little to no use of this available information. We propose the framework of post-process Bayesian inference as a means to obtain a quick posterior approximation from existing target density evaluations, with no further model calls. Within this framework, we introduce Variational Sparse Bayesian Quadrature (VSBQ), a method for post-process approximate inference for models with black-box and potentially noisy likelihoods. VSBQ reuses existing target density evaluations to build a sparse Gaussian process (GP) surrogate model of the log posterior density function. Subsequently, we leverage sparse-GP Bayesian quadrature combined with variational inference to achieve fast approximate posterior inference over the surrogate. We validate our method on challenging synthetic scenarios and real-world applications from computational neuroscience. The experiments show that VSBQ builds high-quality posterior approximations by post-processing existing optimization traces, with no further model evaluations.",
      "authors": [
        "Chengkun Li",
        "Gr\\'egoire Clart\\'e",
        "Martin J{\\o}rgensen",
        "Luigi Acerbi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-09T13:58:35+00:00",
          "link": "https://arxiv.org/abs/2303.05263v1",
          "size": "7184kb",
          "version": "v1"
        },
        {
          "date": "2024-06-18T06:53:56+00:00",
          "link": "https://arxiv.org/abs/2303.05263v2",
          "size": "9675kb",
          "version": "v2"
        },
        {
          "date": "2024-11-29T11:49:04+00:00",
          "link": "https://arxiv.org/abs/2303.05263v3",
          "size": "13308kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T13:27:03+00:00",
          "link": "https://arxiv.org/abs/2303.05263v4",
          "size": "13349kb",
          "version": "v4"
        }
      ],
      "title": "Fast post-process Bayesian inference with Variational Sparse Bayesian Quadrature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.05263",
        "HTML": "https://arxiv.org/html/2303.05263v4",
        "PDF": "https://arxiv.org/pdf/2303.05263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for Bayesian inference using variational techniques, not involving dataset generation, processing, or improvement for LLM training."
      },
      "tasks": [
        "Active Learning",
        "Bayesian Inference",
        "Variational Inference"
      ],
      "repo_urls": [
        "https://github.com/acerbilab/vsbq"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.15225",
      "abstract": "Over the past decades, cognitive neuroscientists and behavioral economists have recognized the value of describing the process of decision making in detail and modeling the emergence of decisions over time. For example, the time it takes to decide can reveal more about an agent's true hidden preferences than only the decision itself. Similarly, data that track the ongoing decision process such as eye movements or neural recordings contain critical information that can be exploited, even if no decision is made. Here, we argue that artificial intelligence (AI) research would benefit from a stronger focus on insights about how decisions emerge over time and incorporate related process data to improve AI predictions in general and human-AI interactions in particular. First, we introduce a highly established computational framework that assumes decisions to emerge from the noisy accumulation of evidence, and we present related empirical work in psychology, neuroscience, and economics. Next, we discuss to what extent current approaches in multi-agent AI do or do not incorporate process data and models of decision making. Finally, we outline how a more principled inclusion of the evidence-accumulation framework into the training and use of AI can help to improve human-AI interactions in the future.",
      "authors": [
        "Mrugsen Nagsen Gopnarayan",
        "Jaan Aru",
        "Sebastian Gluth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-29T11:27:22+00:00",
          "link": "https://arxiv.org/abs/2308.15225v1",
          "size": "527kb",
          "version": "v1"
        },
        {
          "date": "2023-09-07T15:54:26+00:00",
          "link": "https://arxiv.org/abs/2308.15225v2",
          "size": "506kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T11:02:12+00:00",
          "link": "https://arxiv.org/abs/2308.15225v3",
          "size": "519kb",
          "version": "v3"
        }
      ],
      "title": "From DDMs to DNNs: Using process data and models of decision-making to improve human-AI interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.15225",
        "PDF": "https://arxiv.org/pdf/2308.15225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes using decision-making models and process data to enhance human-AI interactions, but it does not address training data processing for LLMs."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.07138",
      "abstract": "The task of blind source separation (BSS) involves separating sources from a mixture without prior knowledge of the sources or the mixing system. Single-channel mixtures and non-linear mixtures are a particularly challenging problem in BSS. In this paper, we propose a novel method for addressing BSS with single-channel non-linear mixtures by leveraging the natural feature subspace specialization ability of multi-encoder autoencoders. During the training phase, our method unmixes the input into the separate encoding spaces of the multi-encoder network and then remixes these representations within the decoder for a reconstruction of the input. Then to perform source inference, we introduce a novel encoding masking technique whereby masking out all but one of the encodings enables the decoder to estimate a source signal. To this end, we also introduce a sparse mixing loss that encourages sparse remixing of source encodings throughout the decoder and a so-called zero reconstruction loss on the decoder for coherent source estimations. To analyze and evaluate our method, we conduct experiments on a toy dataset, designed to demonstrate this property of feature subspace specialization, and with real-world biosignal recordings from a polysomnography sleep study for extracting respiration from electrocardiogram and photoplethysmography signals.",
      "authors": [
        "Matthew B. Webster and Joonnyong Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-31T17:35:42+00:00",
          "link": "https://arxiv.org/abs/2309.07138v1",
          "size": "1425kb",
          "version": "v1"
        },
        {
          "date": "2024-02-13T07:40:31+00:00",
          "link": "https://arxiv.org/abs/2309.07138v2",
          "size": "1425kb",
          "version": "v2"
        },
        {
          "date": "2024-03-08T16:45:37+00:00",
          "link": "https://arxiv.org/abs/2309.07138v3",
          "size": "1703kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T05:09:18+00:00",
          "link": "https://arxiv.org/abs/2309.07138v4",
          "size": "1702kb",
          "version": "v4"
        }
      ],
      "title": "Blind Source Separation of Single-Channel Mixtures via Multi-Encoder Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.07138",
        "HTML": "https://arxiv.org/html/2309.07138v4",
        "PDF": "https://arxiv.org/pdf/2309.07138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses blind source separation using multi-encoder autoencoders without mentioning LLM training data processing, data collection, or dataset creation for language models."
      },
      "tasks": [
        "blind source separation",
        "Decoder",
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://github.com/webstah/self-supervised-bss-via-multi-encoder-ae"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.16417",
      "abstract": "With the rapid advancement of Quantum Machine Learning (QML), the critical need to enhance security measures against adversarial attacks and protect QML models becomes increasingly evident. In this work, we outline the connection between quantum noise channels and differential privacy (DP), by constructing a family of noise channels which are inherently $\\epsilon$-DP: $(\\alpha, \\gamma)$-channels. Through this approach, we successfully replicate the $\\epsilon$-DP bounds observed for depolarizing and random rotation channels, thereby affirming the broad generality of our framework. Additionally, we use a semi-definite program to construct an optimally robust channel. In a small-scale experimental evaluation, we demonstrate the benefits of using our optimal noise channel over depolarizing noise, particularly in enhancing adversarial accuracy. Moreover, we assess how the variables $\\alpha$ and $\\gamma$ affect the certifiable robustness and investigate how different encoding methods impact the classifier's robustness.",
      "authors": [
        "David Winderl",
        "Nicola Franco",
        "Jeanette Miriam Lorenz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-25T08:49:29+00:00",
          "link": "https://arxiv.org/abs/2404.16417v1",
          "size": "266kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:23:03+00:00",
          "link": "https://arxiv.org/abs/2404.16417v2",
          "size": "260kb",
          "version": "v2"
        }
      ],
      "title": "Constructing Optimal Noise Channels for Enhanced Robustness in Quantum Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16417",
        "HTML": "https://arxiv.org/html/2404.16417v2",
        "PDF": "https://arxiv.org/pdf/2404.16417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on constructing noise channels to enhance robustness in quantum machine learning, without addressing LLM training data processing operations."
      },
      "tasks": [
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.04044",
      "abstract": "A $\\textit{spherical $t$-design curve}$ was defined by Ehler and Gr\\\"{o}chenig to be a continuous, piecewise smooth, closed curve on the sphere with finitely many self-intersections whose associated line integral applied to any polynomial of degree at most $t$ evaluates to the average of this polynomial on the sphere. These authors posed the problem of proving that there exist sequences $(\\gamma_t)_{t=0}^\\infty$ of $t$-design curves on $S^d$ of asymptotically optimal length $\\ell(\\gamma_t)\\asymp t^{d-1}$ as $t\\to\\infty$ and solved this problem for $d=2$. This work solves the problem for $d=3$ by proving that there exists a constant $\\mathscr C>0$ such that for any $C\\geq\\mathscr C$ and $t\\in\\Bbb N_+$, there exists a simple $t$-design curve on $S^3$ of length $Ct^2$.",
      "authors": [
        "Ayodeji Lindblad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-07T18:52:10+00:00",
          "link": "https://arxiv.org/abs/2408.04044v1",
          "size": "690kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T20:27:11+00:00",
          "link": "https://arxiv.org/abs/2408.04044v2",
          "size": "275kb",
          "version": "v2"
        }
      ],
      "title": "Asymptotically optimal $t$-design curves on $S^3$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04044",
        "HTML": "https://arxiv.org/html/2408.04044v2",
        "PDF": "https://arxiv.org/pdf/2408.04044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses spherical t-design curves and their mathematical properties, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10876",
      "abstract": "Photoacoustic computed tomography (PACT) is a non-invasive imaging modality, similar to ultrasound, with wide-ranging medical applications. Conventional PACT images are degraded by wavefront distortion caused by the heterogeneous speed of sound (SOS) in tissue. Accounting for these effects can improve image quality and provide medically useful information, but measuring the SOS directly is burdensome and the existing joint reconstruction method is computationally expensive. Traditional supervised learning techniques are currently inaccessible in this data-starved domain. In this work, we introduce an efficient, self-supervised joint reconstruction method that recovers SOS and high-quality images for ring array PACT systems. To solve this semi-blind inverse problem, we parametrize the SOS using either a pixel grid or a neural field (NF) and update it directly by backpropagating the gradients through a differentiable imaging forward model. Our method removes SOS aberrations more accurately and 35x faster than the current SOTA. We demonstrate the success of our method quantitatively in simulation and qualitatively on experimentally-collected and in vivo data. Our code and synthetic numerical phantoms are available on our project page: https://lukeli0425.github.io/Coord-SoS-PACT/.",
      "authors": [
        "Tianao Li",
        "Manxiu Cui",
        "Cheng Ma",
        "Emma Alexander"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-17T04:11:20+00:00",
          "link": "https://arxiv.org/abs/2409.10876v1",
          "size": "20286kb",
          "version": "v1"
        },
        {
          "date": "2024-10-02T21:00:38+00:00",
          "link": "https://arxiv.org/abs/2409.10876v2",
          "size": "20298kb",
          "version": "v2"
        },
        {
          "date": "2025-03-09T02:23:39+00:00",
          "link": "https://arxiv.org/abs/2409.10876v3",
          "size": "18533kb",
          "version": "v3"
        },
        {
          "date": "2025-07-22T21:07:26+00:00",
          "link": "https://arxiv.org/abs/2409.10876v4",
          "size": "19322kb",
          "version": "v4"
        }
      ],
      "title": "Coordinate-based Speed of Sound Recovery for Aberration-Corrected Photoacoustic Computed Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10876",
        "HTML": "https://arxiv.org/html/2409.10876v4",
        "PDF": "https://arxiv.org/pdf/2409.10876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on photoacoustic computed tomography and proposes a method for recovering speed of sound in tissue imaging, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Image Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/Lukeli0425/NF-APACT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.19464",
      "abstract": "We tour several Euclidean properties of Poncelet triangles inscribed in an ellipse and circumscribing the incircle, including loci of triangle centers and envelopes of key objects. We also show that a number of degenerate behaviors are triggered by the presence of an equilateral triangle in the family.",
      "authors": [
        "Mark Helman",
        "Ronaldo A. Garcia",
        "Dan Reznik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-28T21:54:47+00:00",
          "link": "https://arxiv.org/abs/2409.19464v1",
          "size": "10666kb",
          "version": "v1"
        },
        {
          "date": "2024-10-02T20:10:19+00:00",
          "link": "https://arxiv.org/abs/2409.19464v2",
          "size": "10667kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T15:30:53+00:00",
          "link": "https://arxiv.org/abs/2409.19464v3",
          "size": "8770kb",
          "version": "v3"
        }
      ],
      "title": "Blown up by an equilateral: Poncelet triangles about the incircle and their degeneracies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.19464",
        "HTML": "https://arxiv.org/html/2409.19464v3",
        "PDF": "https://arxiv.org/pdf/2409.19464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores Euclidean properties of Poncelet triangles, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02846",
      "abstract": "We introduce a novel machine learning model for credit risk by combining tree-boosting with a latent spatio-temporal Gaussian process model accounting for frailty correlation. This allows for modeling non-linearities and interactions among predictor variables in a flexible data-driven manner and for accounting for spatio-temporal variation that is not explained by observable predictor variables. We also show how estimation and prediction can be done in a computationally efficient manner. In an application to a large U.S. mortgage credit risk data set, we find that both predictive default probabilities for individual loans and predictive loan portfolio loss distributions obtained with our novel approach are more accurate compared to conventional independent linear hazard models and also linear spatio-temporal models. Using interpretability tools for machine learning models, we find that the likely reasons for this outperformance are strong interaction and non-linear effects in the predictor variables and the presence of spatio-temporal frailty effects.",
      "authors": [
        "Pascal K\\\"undig",
        "Fabio Sigrist"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Machine Learning (cs.LG)",
        "Statistical Finance (q-fin.ST)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T15:10:55+00:00",
          "link": "https://arxiv.org/abs/2410.02846v1",
          "size": "1453kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:01:02+00:00",
          "link": "https://arxiv.org/abs/2410.02846v2",
          "size": "4371kb",
          "version": "v2"
        }
      ],
      "title": "A Spatio-Temporal Machine Learning Model for Mortgage Credit Risk: Default Probabilities and Loan Portfolios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02846",
        "HTML": "https://arxiv.org/html/2410.02846v2",
        "PDF": "https://arxiv.org/pdf/2410.02846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a machine learning model for predicting mortgage credit risk and does not pertain to any aspect of LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/pkuendig/SpaceTimeFrailty"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.22365",
      "abstract": "Segmentation of medical images is a fundamental task with numerous applications. While MRI, CT, and PET modalities have significantly benefited from deep learning segmentation techniques, more recent modalities, like functional ultrasound (fUS), have seen limited progress. fUS is a non invasive imaging method that measures changes in cerebral blood volume (CBV) with high spatio-temporal resolution. However, distinguishing arterioles from venules in fUS is challenging due to opposing blood flow directions within the same pixel. Ultrasound localization microscopy (ULM) can enhance resolution by tracking microbubble contrast agents but is invasive, and lacks dynamic CBV quantification. In this paper, we introduce the first deep learning-based segmentation tool for fUS images, capable of differentiating signals from different vascular compartments, based on ULM automatic annotation and enabling dynamic CBV quantification. We evaluate various UNet architectures on fUS images of rat brains, achieving competitive segmentation performance, with 90% accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames from a fUS stack. These results are comparable to those from tubular structure segmentation in other imaging modalities. Additionally, models trained on resting-state data generalize well to images captured during visual stimulation, highlighting robustness. This work offers a non-invasive, cost-effective alternative to ULM, enhancing fUS data interpretation and improving understanding of vessel function. Our pipeline shows high linear correlation coefficients between signals from predicted and actual compartments in both cortical and deeper regions, showcasing its ability to accurately capture blood flow dynamics.",
      "authors": [
        "Hana Sebia (AISTROSIGHT)",
        "Thomas Guyet (AISTROSIGHT)",
        "Micka\\\"el Pereira (CERMEP - imagerie du vivant)",
        "Marco Valdebenito (CERMEP - imagerie du vivant)",
        "Hugues Berry (AISTROSIGHT)",
        "Benjamin Vidal (CERMEP - imagerie du vivant",
        "CRNL",
        "UCBL)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T09:00:28+00:00",
          "link": "https://arxiv.org/abs/2410.22365v1",
          "size": "5481kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:53:03+00:00",
          "link": "https://arxiv.org/abs/2410.22365v2",
          "size": "5026kb",
          "version": "v2"
        }
      ],
      "title": "Vascular Segmentation of Functional Ultrasound Images using Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.22365",
        "PDF": "https://arxiv.org/pdf/2410.22365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a deep learning tool for vascular segmentation in functional ultrasound images, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.09549",
      "abstract": "We aim to apply a quantum computing technique to compose artworks. The main idea is to revisit three paintings of different styles and historical periods: ''Narciso'', painted circa 1597-1599 by Michelangelo Merisi (Caravaggio), ''Les fils de l'homme'', painted in 1964 by Rene Magritte and ''192 Farben'', painted in 1966 by Gerard Richter. We utilize the output of a quantum computation to change the composition in the paintings, leading to a paintings series titled ''Quantum Transformation I, II, III''. In particular, the figures are discretized into square lattices and the order of the pieces is changed according to the result of the quantum simulation. We consider an Ising Hamiltonian as the observable in the quantum computation and its time evolution as the final outcome. From a classical subject to abstract forms, we seek to combine classical and quantum aesthetics through these three art pieces. Besides experimenting with hardware runs and circuit noise, our goal is to reproduce these works as physical oil paintings on wooden panels. With this process, we complete a full circle between classical and quantum techniques and contribute to rethinking Art practice in the era of quantum computing technologies.",
      "authors": [
        "Arianna Crippa",
        "Yahui Chai",
        "Omar Costa Hamido",
        "Paulo Itaborai",
        "Karl Jansen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T16:04:53+00:00",
          "link": "https://arxiv.org/abs/2411.09549v1",
          "size": "10805kb",
          "version": "v1"
        },
        {
          "date": "2024-12-10T13:10:56+00:00",
          "link": "https://arxiv.org/abs/2411.09549v2",
          "size": "10805kb",
          "version": "v2"
        },
        {
          "date": "2025-05-06T12:35:34+00:00",
          "link": "https://arxiv.org/abs/2411.09549v3",
          "size": "3232kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T08:27:53+00:00",
          "link": "https://arxiv.org/abs/2411.09549v4",
          "size": "3229kb",
          "version": "v4"
        }
      ],
      "title": "Quantum computing inspired paintings: reinterpreting classical masterpieces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09549",
        "HTML": "https://arxiv.org/html/2411.09549v4",
        "PDF": "https://arxiv.org/pdf/2411.09549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores the use of quantum computing techniques to alter the composition of classical paintings, which is an artistic experiment rather than related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.05102",
      "abstract": "We consider finite-dimensional many-body quantum systems described by time-independent Hamiltonians and Markovian master equations, and present a systematic method for constructing smaller-dimensional, reduced models that exactly reproduce the time evolution of a set of initial conditions or observables of interest. Our approach exploits Krylov operator spaces and their extension to operator algebras, and may be used to obtain reduced linear models of minimal dimension, well-suited for simulation on classical computers, or reduced quantum models that preserve the structural constraints of physically admissible quantum dynamics, as required for simulation on quantum computers. Notably, we prove that the reduced quantum-dynamical generator is still in Lindblad form. By introducing a new type of observable-dependent symmetries, we show that our method provides a non-trivial generalization of techniques that leverage symmetries, unlocking new reduction opportunities. We quantitatively benchmark our method on paradigmatic open many-body systems of relevance to condensed-matter and quantum-information physics. In particular, we demonstrate how our reduced models can quantitatively describe decoherence dynamics in central-spin systems coupled to structured environments, magnetization transport in boundary-driven dissipative spin chains, and unwanted error dynamics on information encoded in a noiseless quantum code.",
      "authors": [
        "Tommaso Grigoletto",
        "Yukuan Tao",
        "Francesco Ticozzi and Lorenza Viola"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T15:00:58+00:00",
          "link": "https://arxiv.org/abs/2412.05102v1",
          "size": "1320kb",
          "version": "v1"
        },
        {
          "date": "2025-04-10T06:35:36+00:00",
          "link": "https://arxiv.org/abs/2412.05102v2",
          "size": "1320kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T13:59:25+00:00",
          "link": "https://arxiv.org/abs/2412.05102v3",
          "size": "1339kb",
          "version": "v3"
        }
      ],
      "title": "Exact Model Reduction for Continuous-Time Open Quantum Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05102",
        "HTML": "https://arxiv.org/html/2412.05102v3",
        "PDF": "https://arxiv.org/pdf/2412.05102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents model reduction techniques for quantum dynamics, unrelated to any processes or operations involved in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.09839",
      "abstract": "This study explored the transformative potential of artificial intelligence (AI) in addressing the challenges posed by terahertz ultra-massive multiple-input multiple-output (UM-MIMO) systems. It begins by outlining the characteristics of terahertz UM-MIMO systems and identifies three primary challenges for transceiver design: computational complexity, modeling difficulty, and measurement limitations. The study posits that AI provides a promising solution to these challenges. Three systematic research roadmaps are proposed for developing AI algorithms tailored to terahertz UM-MIMO systems. The first roadmap, model-driven deep learning (DL), emphasizes the importance of leveraging available domain knowledge and advocates the adoption of AI only to enhance bottleneck modules within an established signal processing or optimization framework. Four essential steps are discussed: algorithmic frameworks, basis algorithms, loss-function design, and neural architecture design. The second roadmap presents channel state information (CSI) foundation models, aimed at unifying the design of different transceiver modules by focusing on their shared foundation, that is, the wireless channel. The training of a single compact foundation model is proposed to estimate the score function of wireless channels, which serve as a versatile prior for designing a wide variety of transceiver modules. Four essential steps are outlined: general frameworks, conditioning, site-specific adaptation, joint design of CSI foundation models, and model-driven DL. The third roadmap aims to explore potential directions for applying pretrained large language models (LLMs) to terahertz UM-MIMO systems. Several application scenarios are envisioned, including LLM-based estimation, optimization, search, network management, and protocol understanding. Finally, the study highlights open problems and future research directions.",
      "authors": [
        "Wentao Yu and Hengtao He and Shenghui Song and Jun Zhang and Linglong Dai and Lizhong Zheng and Khaled B. Letaief"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T04:13:40+00:00",
          "link": "https://arxiv.org/abs/2412.09839v1",
          "size": "1260kb",
          "version": "v1"
        },
        {
          "date": "2025-04-16T21:18:03+00:00",
          "link": "https://arxiv.org/abs/2412.09839v2",
          "size": "1756kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T22:15:22+00:00",
          "link": "https://arxiv.org/abs/2412.09839v3",
          "size": "5699kb",
          "version": "v3"
        }
      ],
      "title": "AI and Deep Learning for Terahertz Ultra-Massive MIMO: From Model-Driven Approaches to Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09839",
        "PDF": "https://arxiv.org/pdf/2412.09839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores AI for terahertz UM-MIMO systems and various AI-driven approaches, but does not relate to LLM training data processing or data engineering operations for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.16867",
      "abstract": "Quantum machine learning has gained attention for its potential to address computational challenges. However, whether those algorithms can effectively solve practical problems and outperform their classical counterparts, especially on current quantum hardware, remains a critical question. In this work, we propose a novel quantum machine learning method, called Parameter-Efficient Quantum Anomaly Detection (PEQAD), for practical image anomaly detection, which aims to achieve both parameter efficiency and superior accuracy compared to classical models. Emulation results indicate that PEQAD demonstrates favourable recognition capabilities compared to classical baselines, achieving an average accuracy of over 90% on benchmarks with significantly fewer trainable parameters. Theoretical analysis confirms that PEQAD has a comparable expressivity to classical counterparts while requiring only a fraction of the parameters. Furthermore, we demonstrate the first implementation of a quantum anomaly detection method for general image datasets on a superconducting quantum processor. Specifically, we achieve an accuracy of over 80% with only 16 parameters on the device, providing initial evidence of PEQAD's practical viability in the noisy intermediate-scale quantum era and highlighting its significant reduction in parameter requirements.",
      "authors": [
        "Maida Wang",
        "Jinyang Jiang",
        "and Peter V. Coveney"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-22T05:36:51+00:00",
          "link": "https://arxiv.org/abs/2412.16867v1",
          "size": "5363kb",
          "version": "v1"
        },
        {
          "date": "2025-01-14T22:01:02+00:00",
          "link": "https://arxiv.org/abs/2412.16867v2",
          "size": "1470kb",
          "version": "v2"
        },
        {
          "date": "2025-03-28T10:57:32+00:00",
          "link": "https://arxiv.org/abs/2412.16867v3",
          "size": "1589kb",
          "version": "v3"
        },
        {
          "date": "2025-07-22T23:46:35+00:00",
          "link": "https://arxiv.org/abs/2412.16867v4",
          "size": "1891kb",
          "version": "v4"
        }
      ],
      "title": "A Parameter-Efficient Quantum Anomaly Detection Method on a Superconducting Quantum Processor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16867",
        "HTML": "https://arxiv.org/html/2412.16867v4",
        "PDF": "https://arxiv.org/pdf/2412.16867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a quantum anomaly detection method, which is focused on quantum computing and anomaly detection for images, not on LLM training data processing."
      },
      "tasks": [
        "Anomaly Detection",
        "Quantum Machine Learning"
      ],
      "repo_urls": [
        "https://github.com/ucl-ccs/qsvdd",
        "https://github.com/UCL-CCS/PEQAD"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02371",
      "abstract": "Accurate identification of druggable pockets and their features is essential for structure-based drug design and effective downstream docking. Here, we present RAPID-Net, a deep learning-based algorithm designed for the accurate prediction of binding pockets and seamless integration with docking pipelines. On the PoseBusters benchmark, RAPID-Net-guided AutoDock Vina achieves 54.9% of Top-1 poses with RMSD < 2 A and satisfying the PoseBusters chemical-validity criterion, compared to 49.1% for DiffBindFR. On the most challenging time split of PoseBusters aiming to assess generalization ability (structures submitted after September 30, 2021), RAPID-Net-guided AutoDock Vina achieves 53.1% of Top-1 poses with RMSD < 2 A and PB-valid, versus 59.5% for AlphaFold 3. Notably, in 92.2% of cases, RAPID-Net-guided Vina samples at least one pose with RMSD < 2 A (regardless of its rank), indicating that pose ranking, rather than sampling, is the primary accuracy bottleneck. The lightweight inference, scalability, and competitive accuracy of RAPID-Net position it as a viable option for large-scale virtual screening campaigns. Across diverse benchmark datasets, RAPID-Net outperforms other pocket prediction tools, including PUResNet and Kalasanty, in both docking accuracy and pocket-ligand intersection rates. Furthermore, we demonstrate the potential of RAPID-Net to accelerate the development of novel therapeutics by highlighting its performance on pharmacologically relevant targets. RAPID-Net accurately identifies distal functional sites, offering new opportunities for allosteric inhibitor design. In the case of the RNA-dependent RNA polymerase of SARS-CoV-2, RAPID-Net uncovers a wider array of potential binding pockets than existing predictors, which typically annotate only the orthosteric pocket and overlook secondary cavities.",
      "authors": [
        "Yaroslav Balytskyi",
        "Inna Hubenko",
        "Alina Balytska",
        "Christopher V. Kelly"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Biological Physics (physics.bio-ph)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T14:52:10+00:00",
          "link": "https://arxiv.org/abs/2502.02371v1",
          "size": "24335kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T16:44:22+00:00",
          "link": "https://arxiv.org/abs/2502.02371v2",
          "size": "22391kb",
          "version": "v2"
        }
      ],
      "title": "RAPID-Net: Accurate Pocket Identification for Binding-Site-Agnostic Docking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02371",
        "HTML": "https://arxiv.org/html/2502.02371v2",
        "PDF": "https://arxiv.org/pdf/2502.02371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "RAPID-Net is centered around identifying druggable pockets for docking, which is outside the scope of LLM training data processing."
      },
      "tasks": [
        "Blind Docking",
        "Drug Design"
      ],
      "repo_urls": [
        "https://github.com/balytskyijaroslaw/rapid-net"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03172",
      "abstract": "Bayesian optimization based on the Gaussian process upper confidence bound (GP-UCB) offers a theoretical guarantee for optimizing black-box functions. In practice, however, black-box functions often involve input uncertainty. To handle such cases, GP-UCB can be extended to optimize evaluation criteria known as robustness measures. However, GP-UCB-based methods for robustness measures require a trade-off parameter, $\\beta$, which, as in the original GP-UCB, must be set sufficiently large to ensure theoretical validity. In this study, we propose randomized robustness measure GP-UCB (RRGP-UCB), a novel method that samples $\\beta$ from a chi-squared-based probability distribution. This approach eliminates the need to explicitly specify $\\beta$. Notably, the expected value of $\\beta$ under this distribution is not excessively large. Furthermore, we show that RRGP-UCB provides tight bounds on the expected regret between the optimal and estimated solutions. Numerical experiments demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Yu Inatsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T05:01:54+00:00",
          "link": "https://arxiv.org/abs/2504.03172v1",
          "size": "540kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:15:01+00:00",
          "link": "https://arxiv.org/abs/2504.03172v2",
          "size": "545kb",
          "version": "v2"
        }
      ],
      "title": "Bayesian Optimization of Robustness Measures under Input Uncertainty: A Randomized Gaussian Process Upper Confidence Bound Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03172",
        "HTML": "https://arxiv.org/html/2504.03172v2",
        "PDF": "https://arxiv.org/pdf/2504.03172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on Bayesian optimization techniques for robustness in the presence of input uncertainty, which does not involve LLM training data processing."
      },
      "tasks": [
        "Bayesian Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.06566",
      "abstract": "Financial scenario simulation is essential for risk management and portfolio optimization, yet it remains challenging especially in high-dimensional and small data settings common in finance. We propose a diffusion factor model that integrates latent factor structure into generative diffusion processes, bridging econometrics with modern generative AI to address the challenges of the curse of dimensionality and data scarcity in financial simulation. By exploiting the low-dimensional factor structure inherent in asset returns, we decompose the score function--a key component in diffusion models--using time-varying orthogonal projections, and this decomposition is incorporated into the design of neural network architectures. We derive rigorous statistical guarantees, establishing nonasymptotic error bounds for both score estimation at O(d^{5/2} n^{-2/(k+5)}) and generated distribution at O(d^{5/4} n^{-1/2(k+5)}), primarily driven by the intrinsic factor dimension k rather than the number of assets d, surpassing the dimension-dependent limits in the classical nonparametric statistics literature and making the framework viable for markets with thousands of assets. Numerical studies confirm superior performance in latent subspace recovery under small data regimes. Empirical analysis demonstrates the economic significance of our framework in constructing mean-variance optimal portfolios and factor portfolios. This work presents the first theoretical integration of factor structure with diffusion models, offering a principled approach for high-dimensional financial simulation with limited data. Our code is available at https://github.com/xymmmm00/diffusion_factor_model.",
      "authors": [
        "Minshuo Chen",
        "Renyuan Xu",
        "Yumin Xu and Ruixun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)",
        "Mathematical Finance (q-fin.MF)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T04:01:35+00:00",
          "link": "https://arxiv.org/abs/2504.06566v1",
          "size": "1267kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T03:29:54+00:00",
          "link": "https://arxiv.org/abs/2504.06566v2",
          "size": "1268kb",
          "version": "v2"
        },
        {
          "date": "2025-07-04T06:02:46+00:00",
          "link": "https://arxiv.org/abs/2504.06566v3",
          "size": "1315kb",
          "version": "v3"
        },
        {
          "date": "2025-07-23T17:18:54+00:00",
          "link": "https://arxiv.org/abs/2504.06566v4",
          "size": "1316kb",
          "version": "v4"
        }
      ],
      "title": "Diffusion Factor Models: Generating High-Dimensional Returns with Factor Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06566",
        "PDF": "https://arxiv.org/pdf/2504.06566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a diffusion factor model for financial scenario simulation, utilizing econometrics and generative AI. It does not make contributions to LLM training data processing or language model datasets."
      },
      "tasks": [
        "Econometrics",
        "Portfolio Optimization"
      ],
      "repo_urls": [
        "https://github.com/xymmmm00/diffusion_factor_model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10352",
      "abstract": "Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and typically require complex designs. In this paper, we introduce a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies AR and NAR modeling. Combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Building on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information.Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at https://microsoft.com/research/project/vall-e-x/palle.",
      "authors": [
        "Yifan Yang",
        "Shujie Liu",
        "Jinyu Li",
        "Yuxuan Hu",
        "Haibin Wu",
        "Hui Wang",
        "Jianwei Yu",
        "Lingwei Meng",
        "Haiyang Sun",
        "Yanqing Liu",
        "Yan Lu",
        "Kai Yu",
        "Xie Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T16:03:21+00:00",
          "link": "https://arxiv.org/abs/2504.10352v1",
          "size": "1410kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T12:27:51+00:00",
          "link": "https://arxiv.org/abs/2504.10352v2",
          "size": "1405kb",
          "version": "v2"
        }
      ],
      "title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10352",
        "HTML": "https://arxiv.org/html/2504.10352v2",
        "PDF": "https://arxiv.org/pdf/2504.10352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel approach for text-to-speech synthesis using a pseudo-autoregressive codec. It focuses on model architecture and TTS systems, not on LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Speech Synthesis",
        "text-to-speech",
        "Text to Speech",
        "Text-To-Speech Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.19155",
      "abstract": "To develop a machine learning-based framework for accurately modeling the anode heel effect in Monte Carlo simulations of X-ray imaging systems, enabling realistic beam intensity profiles with minimal experimental calibration. Multiple regression models were trained to predict spatial intensity variations along the anode-cathode axis using experimentally acquired weights derived from beam measurements across different tube potentials. These weights captured the asymmetry introduced by the anode heel effect. A systematic fine-tuning protocol was established to minimize the number of required measurements while preserving model accuracy. The models were implemented in the OpenGATE 10 and GGEMS Monte Carlo toolkits to evaluate their integration feasibility and predictive performance. Among the tested models, gradient boosting regression (GBR) delivered the highest accuracy, with prediction errors remaining below 5% across all energy levels. The optimized fine-tuning strategy required only six detector positions per energy level, reducing measurement effort by 65%. The maximum error introduced through this fine-tuning process remained below 2%. Dose actor comparisons within Monte Carlo simulations demonstrated that the GBR-based model closely replicated clinical beam profiles and significantly outperformed conventional symmetric beam models. This study presents a robust and generalizable method for incorporating the anode heel effect into Monte Carlo simulations using machine learning. By enabling accurate, energy-dependent beam modeling with limited calibration data, the approach enhances simulation realism for applications in clinical dosimetry, image quality assessment, and radiation protection.",
      "authors": [
        "Hussein Harb",
        "Didier Benoit",
        "Axel Rannou",
        "Chi-Hieu Pham",
        "Valentin Tissot",
        "Bahaa Nasr",
        "Julien Bert"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-27T08:19:47+00:00",
          "link": "https://arxiv.org/abs/2504.19155v1",
          "size": "12074kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T09:16:28+00:00",
          "link": "https://arxiv.org/abs/2504.19155v2",
          "size": "6566kb",
          "version": "v2"
        }
      ],
      "title": "Machine Learning-Based Modeling of the Anode Heel Effect in X-ray Beam Monte Carlo Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19155",
        "HTML": "https://arxiv.org/html/2504.19155v2",
        "PDF": "https://arxiv.org/pdf/2504.19155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study addresses modeling the anode heel effect in X-ray imaging simulations using machine learning, without any relevance to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.20129",
      "abstract": "Snow is an essential input for various land surface models. Seasonal snow estimates are available as snow water equivalent (SWE) from process-based reanalysis products or locally from in situ measurements. While the reanalysis products are computationally expensive and available at only fixed spatial and temporal resolutions, the in situ measurements are highly localized and sparse. To address these issues and enable the analysis of the effect of a large suite of physical, morphological, and geological conditions on the presence and amount of snow, we build a Long Short-Term Memory (LSTM) network, which is able to estimate the SWE based on time series input of the various physical/meteorological factors as well static spatial/morphological factors. Specifically, this model breaks down the SWE estimation into two separate tasks: (i) a classification task that indicates the presence/absence of snow on a specific day and (ii) a regression task that indicates the height of the SWE on a specific day in the case of snow presence. The model is trained using physical/in situ SWE measurements from the SNOw TELemetry (SNOTEL) snow pillows in the western United States. We will show that trained LSTM models have a classification accuracy of $\\geq 93\\%$ for the presence of snow and a coefficient of correlation of $\\sim 0.9$ concerning their SWE estimates. We will also demonstrate that the models can generalize both spatially and temporally to previously unseen data.",
      "authors": [
        "Arun M. Saranathan",
        "Mahmoud Saeedimoghaddam",
        "Brandon Smith",
        "Deepthi Raghunandan",
        "Grey Nearing",
        "and Craig Pelissier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T17:21:16+00:00",
          "link": "https://arxiv.org/abs/2504.20129v1",
          "size": "2592kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:53:46+00:00",
          "link": "https://arxiv.org/abs/2504.20129v2",
          "size": "3009kb",
          "version": "v2"
        }
      ],
      "title": "A Physically Driven Long Short Term Memory Model for Estimating Snow Water Equivalent over the Continental United States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20129",
        "HTML": "https://arxiv.org/html/2504.20129v2",
        "PDF": "https://arxiv.org/pdf/2504.20129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an LSTM model for estimating snow water equivalent, focusing on snow data estimation. It does not relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.20630",
      "abstract": "Multimodal immersive spatial drama generation focuses on creating continuous multi-speaker binaural speech with dramatic prosody based on multimodal prompts, with potential applications in AR, VR, and others. This task requires simultaneous modeling of spatial information and dramatic prosody based on multimodal inputs, with high data collection costs. To the best of our knowledge, our work is the first attempt to address these challenges. We construct MRSDrama, the first multimodal recorded spatial drama dataset, containing binaural drama audios, scripts, videos, geometric poses, and textual prompts. Then, we propose ISDrama, the first immersive spatial drama generation model through multimodal prompting. ISDrama comprises these primary components: 1) Multimodal Pose Encoder, based on contrastive learning, considering the Doppler effect caused by moving speakers to extract unified pose information from multimodal prompts. 2) Immersive Drama Transformer, a flow-based mamba-transformer model that generates high-quality drama, incorporating Drama-MOE to select proper experts for enhanced prosody and pose control. We also design a context-consistent classifier-free guidance strategy to coherently generate complete drama. Experimental results show that ISDrama outperforms baseline models on objective and subjective metrics. The demos are available at https://aaronz345.github.io/ISDramaDemo. We provide the dataset and the evaluation code at https://huggingface.co/datasets/AaronZ345/MRSDrama and https://github.com/AaronZ345/ISDrama.",
      "authors": [
        "Yu Zhang",
        "Wenxiang Guo",
        "Changhao Pan",
        "Zhiyuan Zhu",
        "Tao Jin",
        "Zhou Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T10:56:44+00:00",
          "link": "https://arxiv.org/abs/2504.20630v1",
          "size": "3862kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T10:18:08+00:00",
          "link": "https://arxiv.org/abs/2504.20630v2",
          "size": "3714kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T03:12:00+00:00",
          "link": "https://arxiv.org/abs/2504.20630v3",
          "size": "3651kb",
          "version": "v3"
        },
        {
          "date": "2025-07-22T15:56:17+00:00",
          "link": "https://arxiv.org/abs/2504.20630v4",
          "size": "3651kb",
          "version": "v4"
        },
        {
          "date": "2025-07-23T15:10:29+00:00",
          "link": "https://arxiv.org/abs/2504.20630v5",
          "size": "3651kb",
          "version": "v5"
        }
      ],
      "title": "ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20630",
        "HTML": "https://arxiv.org/html/2504.20630v5",
        "PDF": "https://arxiv.org/pdf/2504.20630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal immersive spatial drama generation and introduces the MRSDrama dataset. It does not relate to LLM training data processing or any of the associated data operations."
      },
      "datasets": [
        {
          "dataset_name": "AaronZ345/MRSDrama",
          "downloads": "45334",
          "likes": "1",
          "link": "https://huggingface.co/datasets/AaronZ345/MRSDrama"
        }
      ],
      "tasks": [
        "Contrastive Learning",
        "Mamba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.03291",
      "abstract": "The all-pay auction, a classic competitive model, is widely applied in scenarios such as political elections, sports competitions, and research and development, where all participants pay their bids regardless of winning or losing. However, in the traditional all-pay auction, players have no budget constraints, whereas in real-world scenarios, players typically face budget constraints. This paper studies the Nash equilibrium of two players with budget constraints across multiple heterogeneous items in a complete-information framework. The main contributions are as follows: (1) a comprehensive characterization of the Nash equilibrium in single-item auctions with asymmetric budgets and valuations; (2) the construction of a joint distribution Nash equilibrium for the two-item scenario; and (3) the construction of a joint distribution Nash equilibrium for the three-item scenario. Unlike the unconstrained all-pay auction, which always has a Nash equilibrium, a Nash equilibrium may not exist when players have budget constraints. Our findings highlight the intricate effects of budget constraints on bidding strategies, providing new perspectives and methodologies for theoretical analysis and practical applications of all-pay auctions.",
      "authors": [
        "Yan Liu and Ying Qin and Zihe Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T08:16:48+00:00",
          "link": "https://arxiv.org/abs/2505.03291v1",
          "size": "134kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T06:02:24+00:00",
          "link": "https://arxiv.org/abs/2505.03291v2",
          "size": "134kb",
          "version": "v2"
        }
      ],
      "title": "Simultaneous All-Pay Auctions with Budget Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03291",
        "HTML": "https://arxiv.org/html/2505.03291v2",
        "PDF": "https://arxiv.org/pdf/2505.03291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores Nash equilibrium in all-pay auctions under budget constraints, lacking any discussion or contribution towards LLM training data processing."
      },
      "tasks": [
        "All"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13621",
      "abstract": "Rigorous performance evaluation is essential for developing robust algorithms for high-throughput computational chemistry. Traditional benchmarking, however, often struggles to account for system-specific variability, making it difficult to form actionable conclusions. We present a Bayesian hierarchical modeling framework that rigorously quantifies performance metrics and their uncertainty, enabling a nuanced comparison of algorithmic strategies. We apply this framework to analyze the Dimer method, comparing Conjugate Gradient (CG) and L-BFGS rotation optimizers, with and without the removal of external rotations, across a benchmark of 500 molecular systems. Our analysis confirms that CG offers higher overall robustness than L-BFGS in this context. While the theoretically-motivated removal of external rotations led to higher computational cost (>40% more energy and force calls) for most systems in this set, our models also reveal a subtle interplay, hinting that this feature may improve the reliability of the L-BFGS optimizer. Rather than identifying a single superior method, our findings support the design of adaptive \"chain of methods\" workflows. This work showcases how a robust statistical paradigm can move beyond simple performance rankings to inform the intelligent, context-dependent application of computational chemistry methods.",
      "authors": [
        "Rohit Goswami (1 and 2) ((1) Science Institute and Faculty of Physical Sciences",
        "University of Iceland",
        "Reykjav\\'ik",
        "Iceland",
        "(2) Department of Mechanical and Materials Engineering",
        "Queen's University",
        "Kingston",
        "Ontario",
        "Canada)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T18:03:26+00:00",
          "link": "https://arxiv.org/abs/2505.13621v1",
          "size": "702kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T22:20:36+00:00",
          "link": "https://arxiv.org/abs/2505.13621v2",
          "size": "4192kb",
          "version": "v2"
        },
        {
          "date": "2025-07-22T18:09:12+00:00",
          "link": "https://arxiv.org/abs/2505.13621v3",
          "size": "4209kb",
          "version": "v3"
        }
      ],
      "title": "Bayesian Hierarchical Models for Quantitative Estimates for Performance metrics applied to Saddle Search Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13621",
        "HTML": "https://arxiv.org/html/2505.13621v3",
        "PDF": "https://arxiv.org/pdf/2505.13621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with Bayesian hierarchical models for performance metrics in chemistry algorithms and does not discuss LLM training data processing or any associated data engineering techniques."
      },
      "repo_urls": [
        "https://github.com/haozeke/brms_idrot_repro"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20863",
      "abstract": "Quantum computing holds immense potential, yet its practical success depends on multiple factors, including advances in quantum circuit design. In this paper, we introduce a generative approach based on denoising diffusion models (DMs) to synthesize parameterized quantum circuits (PQCs). Extending the recent diffusion model pipeline of F\\\"urrutter et al. [1], our model effectively conditions the synthesis process, enabling the simultaneous generation of circuit architectures and their continuous gate parameters. We demonstrate our approach in synthesizing PQCs optimized for generating high-fidelity Greenberger-Horne-Zeilinger (GHZ) states and achieving high accuracy in quantum machine learning (QML) classification tasks. Our results indicate a strong generalization across varying gate sets and scaling qubit counts, highlighting the versatility and computational efficiency of diffusion-based methods. This work illustrates the potential of generative models as a powerful tool for accelerating and optimizing the design of PQCs, supporting the development of more practical and scalable quantum applications.",
      "authors": [
        "Daniel Barta",
        "Darya Martyniuk",
        "Johannes Jung",
        "Adrian Paschke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T08:14:58+00:00",
          "link": "https://arxiv.org/abs/2505.20863v1",
          "size": "2140kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T11:27:22+00:00",
          "link": "https://arxiv.org/abs/2505.20863v2",
          "size": "1770kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T13:04:46+00:00",
          "link": "https://arxiv.org/abs/2505.20863v3",
          "size": "520kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging Diffusion Models for Parameterized Quantum Circuit Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20863",
        "HTML": "https://arxiv.org/html/2505.20863v3",
        "PDF": "https://arxiv.org/pdf/2505.20863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the generation of parameterized quantum circuits using diffusion models. It does not discuss any aspect of LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Denoising",
        "Quantum Circuit Generation",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21767",
      "abstract": "Reconstructing ECG from PPG is a promising yet challenging task. While recent advancements in generative models have significantly improved ECG reconstruction, accurately capturing fine-grained waveform features remains a key challenge. To address this, we propose a novel PPG-to-ECG reconstruction method that leverages a Vision Transformer (ViT) as the core network. Unlike conventional approaches that rely on single-channel PPG, our method employs a four-channel signal image representation, incorporating the original PPG, its first-order difference, second-order difference, and area under the curve. This multi-channel design enriches feature extraction by preserving both temporal and physiological variations within the PPG. By leveraging the self-attention mechanism in ViT, our approach effectively captures both inter-beat and intra-beat dependencies, leading to more robust and accurate ECG reconstruction. Experimental results demonstrate that our method consistently outperforms existing 1D convolution-based approaches, achieving up to 29% reduction in PRD and 15% reduction in RMSE. The proposed approach also produces improvements in other evaluation metrics, highlighting its robustness and effectiveness in reconstructing ECG signals. Furthermore, to ensure a clinically relevant evaluation, we introduce new performance metrics, including QRS area error, PR interval error, RT interval error, and RT amplitude difference error. Our findings suggest that integrating a four-channel signal image representation with the self-attention mechanism of ViT enables more effective extraction of informative PPG features and improved modeling of beat-to-beat variations for PPG-to-ECG mapping. Beyond demonstrating the potential of PPG as a viable alternative for heart activity monitoring, our approach opens new avenues for cyclic signal analysis and prediction.",
      "authors": [
        "Xiaoyan Li and Shixin Xu and Faisal Habib and Arvind Gupta and Huaxiong Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T21:00:46+00:00",
          "link": "https://arxiv.org/abs/2505.21767v1",
          "size": "3357kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T22:06:36+00:00",
          "link": "https://arxiv.org/abs/2505.21767v2",
          "size": "3358kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Single-Channel: Multichannel Signal Imaging for PPG-to-ECG Reconstruction with Vision Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21767",
        "HTML": "https://arxiv.org/html/2505.21767v2",
        "PDF": "https://arxiv.org/pdf/2505.21767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for PPG-to-ECG reconstruction using a Vision Transformer. The study is concentrated on signal processing and does not touch upon LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.07770",
      "abstract": "Reconfigurable intelligent surface (RIS) has been recognized as a promising technology for next-generation wireless communications. However, the performance of RIS-assisted systems critically depends on accurate channel state information (CSI). To address this challenge, this letter proposes a novel channel estimation method for RIS-aided millimeter-wave (mmWave) systems based on diffusion models (DMs). Specifically, the forward diffusion process of the original signal is formulated to model the received signal as a noisy observation within the framework of DMs. Subsequently, the channel estimation task is formulated as the reverse diffusion process, and a sampling algorithm based on denoising diffusion implicit models (DDIMs) is developed to enable effective inference. Furthermore, a lightweight neural network, termed BRCNet, is introduced to replace the conventional U-Net, significantly reducing the number of parameters and computational complexity. Extensive experiments conducted under various scenarios demonstrate that the proposed method consistently outperforms existing baselines.",
      "authors": [
        "Yang Wang",
        "Yin Xu",
        "Cixiao Zhang",
        "Zhiyong Chen",
        "Mingzeng Dai",
        "Haiming Wang",
        "Bingchao Liu",
        "Dazhi He and Meixia Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T13:46:44+00:00",
          "link": "https://arxiv.org/abs/2506.07770v1",
          "size": "107kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T14:10:03+00:00",
          "link": "https://arxiv.org/abs/2506.07770v2",
          "size": "165kb",
          "version": "v2"
        }
      ],
      "title": "Channel Estimation for RIS-Assisted mmWave Systems via Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07770",
        "HTML": "https://arxiv.org/html/2506.07770v2",
        "PDF": "https://arxiv.org/pdf/2506.07770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses channel estimation for RIS-assisted mmWave systems using diffusion models. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12186",
      "abstract": "The widespread use of Magnetic Resonance Imaging (MRI) in combination with deep learning shows promise for many high-impact automated diagnostic and prognostic tools. However, training new models requires large amounts of labeled data, a challenge due to high cost of precise annotations and data privacy. To address this issue, we introduce the MRI-CORE, a vision foundation model trained using more than 6 million slices from over 110 thousand MRI volumes across 18 body locations. Our experiments show notable improvements in performance over state-of-the-art methods in 13 data-restricted segmentation tasks, as well as in image classification, and zero-shot segmentation, showing the strong potential of MRI-CORE to enable data-efficient development of artificial intelligence models. We also present data on which strategies yield most useful foundation models and a novel analysis relating similarity between pre-training and downstream task data with transfer learning performance. Our model is publicly available with a permissive license.",
      "authors": [
        "Haoyu Dong",
        "Yuwen Chen",
        "Hanxue Gu",
        "Nicholas Konz",
        "Yaqian Chen",
        "Qihang Li",
        "Maciej A. Mazurowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T19:26:56+00:00",
          "link": "https://arxiv.org/abs/2506.12186v1",
          "size": "11496kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T19:20:31+00:00",
          "link": "https://arxiv.org/abs/2506.12186v2",
          "size": "20417kb",
          "version": "v2"
        }
      ],
      "title": "MRI-CORE: A Foundation Model for Magnetic Resonance Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12186",
        "HTML": "https://arxiv.org/html/2506.12186v2",
        "PDF": "https://arxiv.org/pdf/2506.12186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "MRI-CORE is a foundation model for MRI imaging, addressing issues with automated diagnostic tools in medical imaging. It does not contribute to LLM training data processing or dataset development for language models."
      },
      "tasks": [
        "Diagnostic",
        "image-classification",
        "Image Classification",
        "Segmentation",
        "Semantic Segmentation",
        "Zero Shot Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15643",
      "abstract": "Combining randomized estimators in an ensemble, such as via random forests, has become a fundamental technique in modern data science, but can be computationally expensive. Furthermore, the mechanism by which this improves predictive performance is poorly understood. We address these issues in the context of sparse linear regression by proposing and analyzing an ensemble of greedy forward selection estimators that are randomized by feature subsampling -- at each iteration, the best feature is selected from within a random subset. We design a novel implementation based on dynamic programming that greatly improves its computational efficiency. Furthermore, we show via careful numerical experiments that our method can outperform popular methods such as lasso and elastic net across a wide range of settings. Next, contrary to prevailing belief that randomized ensembling is analogous to shrinkage, we show via numerical experiments that it can simultaneously reduce training error and degrees of freedom, thereby shifting the entire bias-variance trade-off curve of the base estimator. We prove this fact rigorously in the setting of orthogonal features, in which case, the ensemble estimator rescales the ordinary least squares coefficients with a two-parameter family of logistic weights, thereby enlarging the model search space. These results enhance our understanding of random forests and suggest that implicit regularization in general may have more complicated effects than explicit regularization.",
      "authors": [
        "Xin Chen and Jason M. Klusowski and Yan Shuo Tan and Chang Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T17:13:53+00:00",
          "link": "https://arxiv.org/abs/2506.15643v1",
          "size": "378kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T20:23:35+00:00",
          "link": "https://arxiv.org/abs/2506.15643v2",
          "size": "377kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Randomization in Greedy Model Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15643",
        "PDF": "https://arxiv.org/pdf/2506.15643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes an ensemble approach for improving predictive performance in sparse linear regression using randomized feature subsampling. It involves improving ensemble models but does not address LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01939",
      "abstract": "In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy.",
      "authors": [
        "Xiaosheng Zhao",
        "Yang Huang",
        "Guirong Xue",
        "Xiao Kong",
        "Jifeng Liu",
        "Xiaoyu Tang",
        "Timothy C. Beers",
        "Yuan-Sen Ting",
        "A-Li Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Solar and Stellar Astrophysics (astro-ph.SR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:49:52+00:00",
          "link": "https://arxiv.org/abs/2507.01939v1",
          "size": "19341kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T17:47:04+00:00",
          "link": "https://arxiv.org/abs/2507.01939v2",
          "size": "22725kb",
          "version": "v2"
        }
      ],
      "title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01939",
        "HTML": "https://arxiv.org/html/2507.01939v2",
        "PDF": "https://arxiv.org/pdf/2507.01939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on spectroscopic analysis for stars using a model framework called SpecCLIP, which is unrelated to LLM training data processing. It does not discuss any data processing operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04074",
      "abstract": "This paper presents a novel Darwinian Agent-Based Modeling (ABM) methodology formacroeconomic forecasting that leverages evolutionary principles to achieve remarkablecomputational efficiency and emergent realism. Unlike conventional DSGE and ABM approachesthat rely on complex behavioral rules derived from large firm analysis, our framework employssimple \"common sense\" rules representative of small firms directly serving final consumers. Themethodology treats households as the primary drivers of economic dynamics, with firms adaptingthrough market-based natural selection within limited interaction neighborhoods. We demonstrate that this approach, when constrained by Input-Output table structures,generates realistic economic patterns including wealth distributions, firm size distributions, andsectoral employment patterns without extensive parameter calibration. Using FIGARO Input-Output tables for 46 countries and focusing on Austria as a case study, we show that the modelreproduces empirical regularities while maintaining computational efficiency on standard laptopsrather than requiring supercomputing clusters. Key findings include: (1) emergence of realistic firm and employment distributions fromminimal behavioral assumptions, (2) accurate reproduction of the initial Social Accounting Matrixvalues through evolutionary dynamics, (3) successful calibration using only 5-6 country-specificparameters to complement the FIGARO data, and (4) computational performance enabling fullsimulations on consumer hardware. These results suggest that evolutionary ABM approaches canprovide robust policy insights by capturing decentralized market adaptations while avoiding thecomputational complexity of traditional DSGE and comprehensive ABM models.",
      "authors": [
        "Martin Jaraiz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T15:45:43+00:00",
          "link": "https://arxiv.org/abs/2507.04074v1",
          "size": "2272kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T10:40:45+00:00",
          "link": "https://arxiv.org/abs/2507.04074v2",
          "size": "1582kb",
          "version": "v2"
        }
      ],
      "title": "Efficiency through Evolution, A Darwinian Approach to Agent-Based Economic Forecast Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04074",
        "PDF": "https://arxiv.org/pdf/2507.04074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses an economic forecast modeling methodology using Darwinian principles and agent-based models, which is unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04591",
      "abstract": "Quantitative imaging (QI) is demonstrating strong promise across multiple clinical applications. For clinical translation of QI methods, objective evaluation on clinically relevant tasks is essential. To address this need, multiple evaluation strategies are being developed. In this paper, based on previous literature, we outline four emerging frameworks to perform evaluation studies of QI methods. We first discuss the use of virtual imaging trials (VITs) to evaluate QI methods. Next, we outline a no-gold-standard evaluation framework to clinically evaluate QI methods without ground truth. Third, a framework to evaluate QI methods for joint detection and quantification tasks is outlined. Finally, we outline a framework to evaluate QI methods that output multi-dimensional parameters, such as radiomic features. We review these frameworks, discussing their utilities and limitations. Further, we examine future research areas in evaluation of QI methods. Given the recent advancements in PET, including long axial field-of-view scanners and the development of artificial-intelligence algorithms, we present these frameworks in the context of PET.",
      "authors": [
        "Yan Liu",
        "Huitian Xia",
        "Nancy A. Obuchowski",
        "Richard Laforest",
        "Arman Rahmim",
        "Barry A. Siegel",
        "Abhinav K. Jha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T00:52:52+00:00",
          "link": "https://arxiv.org/abs/2507.04591v1",
          "size": "1017kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T21:47:46+00:00",
          "link": "https://arxiv.org/abs/2507.04591v2",
          "size": "4689kb",
          "version": "v2"
        }
      ],
      "title": "Emerging Frameworks for Objective Task-based Evaluation of Quantitative Medical Imaging Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04591",
        "PDF": "https://arxiv.org/pdf/2507.04591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses evaluation frameworks for quantitative medical imaging methods, which is not related to LLM training data processing or improvements in data quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09898",
      "abstract": "This study investigates the effectiveness of U-Net architectures integrated with various convolutional neural network (CNN) backbones for automated lung cancer detection and segmentation in chest CT images, addressing the critical need for accurate diagnostic tools in clinical settings. A balanced dataset of 832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed using Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to 128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50, VGG16, and Xception, to segment lung regions. After segmentation, CNN-based classifiers and hybrid models combining CNN feature extraction with traditional machine learning classifiers (Support Vector Machine, Random Forest, and Gradient Boosting) were evaluated using 5-fold cross-validation. Metrics included accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC. U-Net with ResNet50 achieved the best performance for cancerous lungs (Dice: 0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for non-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For classification, the CNN model using U-Net with Xception achieved 99.1 percent accuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid CNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent F1-score. Compared to prior methods, our framework consistently outperformed existing models. In conclusion, combining U-Net with advanced CNN backbones provides a powerful method for both segmentation and classification of lung cancer in CT scans, supporting early diagnosis and clinical decision-making.",
      "authors": [
        "Alireza Golkarieh",
        "Kiana Kiashemshaki",
        "Sajjad Rezvani Boroujeni",
        "Nasibeh Asadi Isakan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:08:33+00:00",
          "link": "https://arxiv.org/abs/2507.09898v1",
          "size": "2402kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T23:40:12+00:00",
          "link": "https://arxiv.org/abs/2507.09898v2",
          "size": "2402kb",
          "version": "v2"
        }
      ],
      "title": "Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09898",
        "HTML": "https://arxiv.org/html/2507.09898v2",
        "PDF": "https://arxiv.org/pdf/2507.09898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is dedicated to lung cancer detection using advanced U-Net architectures and CNN backbones for image processing tasks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11588",
      "abstract": "Spatial Transcriptomics (ST) technologies provide biologists with rich insights into single-cell biology by preserving spatial context of cells. Building foundational models for ST can significantly enhance the analysis of vast and complex data sources, unlocking new perspectives on the intricacies of biological tissues. However, modeling ST data is inherently challenging due to the need to extract multi-scale information from tissue slices containing vast numbers of cells. This process requires integrating macro-scale tissue morphology, micro-scale cellular microenvironment, and gene-scale gene expression profile. To address this challenge, we propose SToFM, a multi-scale Spatial Transcriptomics Foundation Model. SToFM first performs multi-scale information extraction on each ST slice, to construct a set of ST sub-slices that aggregate macro-, micro- and gene-scale information. Then an SE(2) Transformer is used to obtain high-quality cell representations from the sub-slices. Additionally, we construct \\textbf{SToCorpus-88M}, the largest high-resolution spatial transcriptomics corpus for pretraining. SToFM achieves outstanding performance on a variety of downstream tasks, such as tissue region semantic segmentation and cell type annotation, demonstrating its comprehensive understanding of ST data through capturing and integrating multi-scale information.",
      "authors": [
        "Suyuan Zhao",
        "Yizhen Luo",
        "Ganbo Yang",
        "Yan Zhong",
        "Hao Zhou",
        "Zaiqing Nie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:47:01+00:00",
          "link": "https://arxiv.org/abs/2507.11588v1",
          "size": "926kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:22:26+00:00",
          "link": "https://arxiv.org/abs/2507.11588v2",
          "size": "926kb",
          "version": "v2"
        }
      ],
      "title": "SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11588",
        "HTML": "https://arxiv.org/html/2507.11588v2",
        "PDF": "https://arxiv.org/pdf/2507.11588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces SToFM, a model for Spatial Transcriptomics, and constructs the SToCorpus-88M dataset for pretraining. While it involves creating a dataset, the focus is more on modeling biological data and its applications rather than LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11799",
      "abstract": "This paper presents a neural network (NN)-based solver for an integro-differential equation that models shrinkage-induced fragmentation. The proposed method directly maps input parameters to the corresponding probability density function without numerically solving the governing equation, thereby significantly reducing computational costs. Specifically, it enables efficient evaluation of the density function in Monte Carlo simulations while maintaining accuracy comparable to or even exceeding that of conventional finite difference schemes. Validatation on synthetic data demonstrates both the method's computational efficiency and predictive reliability. This study establishes a foundation for the data-driven inverse analysis of fragmentation and suggests the potential for extending the framework beyond pre-specified model structures.",
      "authors": [
        "Shin-ichi Ito"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T23:33:05+00:00",
          "link": "https://arxiv.org/abs/2507.11799v1",
          "size": "1548kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T00:44:03+00:00",
          "link": "https://arxiv.org/abs/2507.11799v2",
          "size": "1548kb",
          "version": "v2"
        }
      ],
      "title": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11799",
        "HTML": "https://arxiv.org/html/2507.11799v2",
        "PDF": "https://arxiv.org/pdf/2507.11799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a neural network approach for solving a specific physical modeling problem related to shrinkage-induced fragmentation and does not discuss LLM training data processing or dataset creation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14184",
      "abstract": "We present a novel and interpretable framework for electrocardiogram (ECG)-based disease detection that combines hyperdimensional computing (HDC) with learnable neural encoding. Unlike conventional HDC approaches that rely on static, random projections, our method introduces a rhythm-aware and trainable encoding pipeline based on RR intervals, a physiological signal segmentation strategy that aligns with cardiac cycles. The core of our design is a neural-distilled HDC architecture, featuring a learnable RR-block encoder and a BinaryLinear hyperdimensional projection layer, optimized jointly with cross-entropy and proxy-based metric loss. This hybrid framework preserves the symbolic interpretability of HDC while enabling task-adaptive representation learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model significantly outperforms traditional HDC and classical ML baselines, achieving 73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable robustness on PTB-XL. Our framework offers an efficient and scalable solution for edge-compatible ECG classification, with strong potential for interpretable and personalized health monitoring.",
      "authors": [
        "ZhengXiao He",
        "Jinghao Wen",
        "Huayu Li",
        "Siyuan Tian",
        "Ao Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:22:48+00:00",
          "link": "https://arxiv.org/abs/2507.14184v1",
          "size": "731kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T05:00:46+00:00",
          "link": "https://arxiv.org/abs/2507.14184v2",
          "size": "731kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T05:51:42+00:00",
          "link": "https://arxiv.org/abs/2507.14184v3",
          "size": "731kb",
          "version": "v3"
        }
      ],
      "title": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14184",
        "HTML": "https://arxiv.org/html/2507.14184v3",
        "PDF": "https://arxiv.org/pdf/2507.14184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel method for ECG-based disease detection using hyperdimensional computing and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14534",
      "abstract": "Zero-shot online voice conversion (VC) holds significant promise for real-time communications and entertainment. However, current VC models struggle to preserve semantic fidelity under real-time constraints, deliver natural-sounding conversions, and adapt effectively to unseen speaker characteristics. To address these challenges, we introduce Conan, a chunkwise online zero-shot voice conversion model that preserves the content of the source while matching the voice timbre and styles of reference speech. Conan comprises three core components: 1) a Stream Content Extractor that leverages Emformer for low-latency streaming content encoding; 2) an Adaptive Style Encoder that extracts fine-grained stylistic features from reference speech for enhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully causal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations demonstrate that Conan outperforms baseline models in subjective and objective metrics. Audio samples can be found at https://aaronz345.github.io/ConanDemo.",
      "authors": [
        "Yu Zhang",
        "Baotong Tian",
        "Zhiyao Duan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:32:07+00:00",
          "link": "https://arxiv.org/abs/2507.14534v1",
          "size": "372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T15:54:40+00:00",
          "link": "https://arxiv.org/abs/2507.14534v2",
          "size": "372kb",
          "version": "v2"
        }
      ],
      "title": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14534",
        "HTML": "https://arxiv.org/html/2507.14534v2",
        "PDF": "https://arxiv.org/pdf/2507.14534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on zero-shot voice conversion models and their architecture, without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15292",
      "abstract": "Visualizing subtle vascular motions in endoscopic surgery is crucial for surgical precision and decision-making, yet remains challenging due to the complex and dynamic nature of surgical scenes. To address this, we introduce EndoControlMag, a training-free, Lagrangian-based framework with mask-conditioned vascular motion magnification tailored to endoscopic environments. Our approach features two key modules: a Periodic Reference Resetting (PRR) scheme that divides videos into short overlapping clips with dynamically updated reference frames to prevent error accumulation while maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification (HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores using a pretrained visual tracking model to maintain accurate localization despite occlusions and view changes. It then applies one of two adaptive softening strategies to surrounding tissues: motion-based softening that modulates magnification strength proportional to observed tissue displacement, or distance-based exponential decay that simulates biomechanical force attenuation. This dual-mode approach accommodates diverse surgical scenarios-motion-based softening excels with complex tissue deformations while distance-based softening provides stability during unreliable optical flow conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four different surgery types and various challenging scenarios, including occlusions, instrument disturbance, view changes, and vessel deformations. Quantitative metrics, visual assessments, and expert surgeon evaluations demonstrate that EndoControlMag significantly outperforms existing methods in both magnification accuracy and visual quality while maintaining robustness across challenging surgical conditions. The code, dataset, and video results are available at https://szupc.github.io/EndoControlMag/.",
      "authors": [
        "An Wang",
        "Rulin Zhou",
        "Mengya Xu",
        "Yiru Ye",
        "Longfei Gou",
        "Yiting Chang",
        "Hao Chen",
        "Chwee Ming Lim",
        "Jiankun Wang",
        "Hongliang Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:47:44+00:00",
          "link": "https://arxiv.org/abs/2507.15292v1",
          "size": "1683kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T05:11:23+00:00",
          "link": "https://arxiv.org/abs/2507.15292v2",
          "size": "1672kb",
          "version": "v2"
        },
        {
          "date": "2025-07-23T12:04:57+00:00",
          "link": "https://arxiv.org/abs/2507.15292v3",
          "size": "1677kb",
          "version": "v3"
        }
      ],
      "title": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15292",
        "HTML": "https://arxiv.org/html/2507.15292v3",
        "PDF": "https://arxiv.org/pdf/2507.15292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "EndoControlMag introduces a framework for endoscopic vascular motion magnification, which is unrelated to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15489",
      "abstract": "This paper presents a novel quadratic programming (QP) approach for constrained control allocation that directly incorporates continuous-time actuator rate constraints without requiring slack variables. Over-actuated aircraft configurations, particularly prevalent in eVTOL and military applications, require control allocation algorithms to distribute commanded control moments among available actuators while respecting position and rate constraints. Existing methods such as direct allocation, pseudo-inverse, cascaded generalized inverse, and exact redistributed pseudo-inverse either cannot handle rate constraints in continuous time or require discretization approaches that compromise performance. Current QP methods that incorporate rate constraints rely on slack variables to ensure feasibility, which prevents full utilization of the attainable moment set and degrades allocation performance. The proposed methodology addresses this limitation by calculating the attainable moment set from both position and rate constraints through convex hull operations, then ensuring feasibility by scaling unattainable commanded moments to the boundary of the attainable moment set while preserving their direction. This approach guarantees the feasibility of the optimization problem without slack variables. The method is validated through simulation on an F-18 fighter aircraft control allocation problem, demonstrating equivalent performance to the established exact redistributed pseudo-inverse method while providing smoother actuator behavior and enhanced constraint satisfaction. Results show that incorporating continuous-time rate constraints leads to improved actuator tracking, reduced overshoot, and more precise adherence to position limits, which is essential for aircraft safety, ride comfort, and actuator longevity.",
      "authors": [
        "S\\\"uleyman \\\"Ozkurt and Adrian Grimm and Walter Fichter"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:45:44+00:00",
          "link": "https://arxiv.org/abs/2507.15489v1",
          "size": "871kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T07:41:29+00:00",
          "link": "https://arxiv.org/abs/2507.15489v2",
          "size": "871kb",
          "version": "v2"
        }
      ],
      "title": "Constrained Control Allocation With Continuous-Time Rate Constraints: Three-Dimensional Case",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15489",
        "HTML": "https://arxiv.org/html/2507.15489v2",
        "PDF": "https://arxiv.org/pdf/2507.15489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents a quadratic programming approach for control allocation in aircraft, focusing on actuator constraints and performance improvements, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16036",
      "abstract": "Quantum computers face inherent scaling challenges, a fact that necessitates investigation of distributed quantum computing systems, whereby scaling is achieved through interconnection of smaller quantum processing units. However, connecting large numbers of QPUs will eventually result in connectivity constraints at the network level, where the difficulty of entanglement sharing increases with network path lengths. This increases the complexity of the quantum circuit partitioning problem, since the cost of generating entanglement between end nodes varies with network topologies and existing links. We address this challenge using a simple modification to existing partitioning schemes designed for all-to-all connected networks, that efficiently accounts for both of these factors. We investigate the performance in terms of entanglement requirements and optimisation time of various quantum circuits over different network topologies, achieving lower entanglement costs in the majority of cases than state-of-the-art methods. We provide techniques for scaling to large-scale quantum networks employing both network and problem coarsening. We show that coarsened methods can achieve improved solution quality in most cases with significantly lower run-times than direct partitioning methods.",
      "authors": [
        "Felix Burt",
        "Kuan-Cheng Chen",
        "Kin K. Leung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T19:57:12+00:00",
          "link": "https://arxiv.org/abs/2507.16036v1",
          "size": "362kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T08:24:17+00:00",
          "link": "https://arxiv.org/abs/2507.16036v2",
          "size": "362kb",
          "version": "v2"
        }
      ],
      "title": "Entanglement-Efficient Distribution of Quantum Circuits over Large-Scale Quantum Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16036",
        "PDF": "https://arxiv.org/pdf/2507.16036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses challenges in distributed quantum computing and provides quantum network partitioning techniques. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16267",
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder that predominantly affects the elderly population and currently has no cure. Magnetic Resonance Imaging (MRI), as a non-invasive imaging technique, is essential for the early diagnosis of AD. MRI inherently contains both spatial and frequency information, as raw signals are acquired in the frequency domain and reconstructed into spatial images via the Fourier transform. However, most existing AD diagnostic models extract features from a single domain, limiting their capacity to fully capture the complex neuroimaging characteristics of the disease. While some studies have combined spatial and frequency information, they are mostly confined to 2D MRI, leaving the potential of dual-domain analysis in 3D MRI unexplored. To overcome this limitation, we propose Spatio-Frequency Network (SFNet), the first end-to-end deep learning framework that simultaneously leverages spatial and frequency domain information to enhance 3D MRI-based AD diagnosis. SFNet integrates an enhanced dense convolutional network to extract local spatial features and a global frequency module to capture global frequency-domain representations. Additionally, a novel multi-scale attention module is proposed to further refine spatial feature extraction. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that SFNet outperforms existing baselines and reduces computational overhead in classifying cognitively normal (CN) and AD, achieving an accuracy of 95.1%.",
      "authors": [
        "Xinyue Yang",
        "Meiliang Liu",
        "Yunfang Xu",
        "Xiaoxiao Yang",
        "Zhengye Si",
        "Zijin Li",
        "Zhiwen Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T06:33:00+00:00",
          "link": "https://arxiv.org/abs/2507.16267v1",
          "size": "465kb",
          "version": "v1"
        },
        {
          "date": "2025-07-23T05:53:40+00:00",
          "link": "https://arxiv.org/abs/2507.16267v2",
          "size": "465kb",
          "version": "v2"
        }
      ],
      "title": "SFNet: A Spatial-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16267",
        "HTML": "https://arxiv.org/html/2507.16267v2",
        "PDF": "https://arxiv.org/pdf/2507.16267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on enhancing Alzheimer's disease diagnosis using MRI analysis, with no relation to LLM training data processing or any associated data engineering practices."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08177",
      "abstract": "Objective: Head impact information including impact directions, speeds and force are important to study traumatic brain injury, design and evaluate protective gears. This study presents a deep learning model developed to accurately predict head impact information, including location, speed, orientation, and force, based on head kinematics during helmeted impacts. Methods: Leveraging a dataset of 16,000 simulated helmeted head impacts using the Riddell helmet finite element model, we implemented a Long Short-Term Memory (LSTM) network to process the head kinematics: tri-axial linear accelerations and angular velocities. Results: The models accurately predict the impact parameters describing impact location, direction, speed, and the impact force profile with R2 exceeding 70% for all tasks. Further validation was conducted using an on-field dataset recorded by instrumented mouthguards and videos, consisting of 79 head impacts in which the impact location can be clearly identified. The deep learning model significantly outperformed existing methods, achieving a 79.7% accuracy in identifying impact locations, compared to lower accuracies with traditional methods (the highest accuracy of existing methods is 49.4%). Conclusion: The precision underscores the model's potential in enhancing helmet design and safety in sports by providing more accurate impact data. Future studies should test the models across various helmets and sports on large in vivo datasets to validate the accuracy of the models, employing techniques like transfer learning to broaden its effectiveness.",
      "authors": [
        "Xianghao Zhan",
        "Yuzhe Liu",
        "Nicholas J. Cecchi",
        "Jessica Towns",
        "Ashlyn A. Callan",
        "Olivier Gevaert",
        "Michael M. Zeineh",
        "David B. Camarillo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-12T16:07:15+00:00",
          "link": "https://arxiv.org/abs/2409.08177v1",
          "size": "1813kb",
          "version": "v1"
        }
      ],
      "title": "Identification of head impact locations, speeds, and force based on head kinematics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08177",
        "HTML": "https://arxiv.org/html/2409.08177",
        "PDF": "https://arxiv.org/pdf/2409.08177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study develops a deep learning model for predicting head impact information from kinematics data, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/xzhan96-stf/impact_retriever"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.08577",
      "abstract": "This study is the first to explore the interplay between haptic interaction and avatar representation in Shared Virtual Environments (SVEs). Specifically, how these factors shape users' sense of social presence during dyadic collaborations, while assessing potential effects on task performance. In a series of experiments, participants performed the collaborative task with haptic interaction under four avatar representation conditions: avatars of both participant and partner were displayed, only the participant's avatar was displayed, only the partner's avatar was displayed, and no avatars were displayed. The study finds that avatar representation, especially of the partner, significantly enhances the perception of social presence, which haptic interaction alone does not fully achieve. However, neither the presence nor the type of avatar representation impacts the task performance or participants' force effort of the task, suggesting that haptic interaction provides sufficient interaction cues for the execution of the task. These results underscore the significance of integrating both visual and haptic modalities to optimize remote collaboration experiences in virtual environments, ensuring effective communication and a strong sense of social presence.",
      "authors": [
        "Genki Sasaki",
        "Hiroshi Igarashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T06:52:30+00:00",
          "link": "https://arxiv.org/abs/2409.08577v1",
          "size": "4535kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T06:11:58+00:00",
          "link": "https://arxiv.org/abs/2409.08577v2",
          "size": "3527kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Remote Collaborative Tasks: The Impact of Avatar Representation on Dyadic Haptic Interactions in Shared Virtual Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08577",
        "HTML": "https://arxiv.org/html/2409.08577",
        "PDF": "https://arxiv.org/pdf/2409.08577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores haptic interaction and avatar representation in virtual environments. There is no discussion on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.08159",
      "abstract": "In this letter, we investigate sufficient conditions for the exponential stability of LTI systems driven by controllers derived from parametric optimization problems. Our primary focus is on parametric projection controllers, namely parametric programs whose objective function is the squared distance to a nominal controller. Leveraging the virtual system method of analysis and a novel contractivity result for Lur'e systems, we establish a sufficient LMI condition for the exponential stability of an LTI system with a parametric projection-based controller. Separately, we prove additional results for single-integrator systems. Finally, we apply our results to state-dependent saturated control systems and control barrier function-based control and provide numerical simulations.",
      "authors": [
        "Alexander Davydov and Francesco Bullo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-13T00:56:19+00:00",
          "link": "https://arxiv.org/abs/2403.08159v1",
          "size": "693kb",
          "version": "v1"
        },
        {
          "date": "2024-04-15T19:40:15+00:00",
          "link": "https://arxiv.org/abs/2403.08159v2",
          "size": "693kb",
          "version": "v2"
        }
      ],
      "title": "Exponential Stability of Parametric Optimization-Based Controllers via Lur'e Contractivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08159",
        "HTML": "https://arxiv.org/html/2403.08159",
        "PDF": "https://arxiv.org/pdf/2403.08159"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses stability of control systems using parametric optimization, without any focus on LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11066",
      "abstract": "This paper describes the development of the Four Model Tree Ensemble (FMTE). The FMTE is a composite of machine learning models trained on experimental binding energies from the Atomic Mass Evaluation (AME) 2012. The FMTE predicts binding energy values for all nuclei with N > 7 and Z > 7 from AME 2020 with a standard deviation of 76 keV and a mean average deviation of 34 keV. The FMTE model was developed by combining three new models with one prior model. The new models presented here have been trained on binding energy residuals from mass models using four machine learning approaches. The models presented in this work leverage shape parameters along with other physical features. We have determined the preferred machine learning approach for binding energy residuals is the least-squares boosted ensemble of trees. This approach appears to have a superior ability to both interpolate and extrapolate binding energy residuals. A comparison with the masses of isotopes that were not measured previously and a discussion of extrapolations approaching the neutron drip line have been included.",
      "authors": [
        "I. Bentley",
        "J. Tedder",
        "M. Gebran",
        "and A. Paul"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Nuclear Theory (nucl-th)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T04:19:23+00:00",
          "link": "https://arxiv.org/abs/2503.11066v1",
          "size": "7374kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T11:01:56+00:00",
          "link": "https://arxiv.org/abs/2503.11066v2",
          "size": "7285kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T14:19:32+00:00",
          "link": "https://arxiv.org/abs/2503.11066v3",
          "size": "4931kb",
          "version": "v3"
        }
      ],
      "title": "Further exploration of binding energy residuals using machine learning and the development of a composite ensemble model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11066",
        "PDF": "https://arxiv.org/pdf/2503.11066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on machine learning models for predicting nuclear binding energy values, unrelated to LLM training data processing."
      },
      "tasks": [
        "Physics-informed machine learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.19707",
      "abstract": "This research introduces an extended application of neural networks for solving nonlinear partial differential equations (PDEs). A neural network, combined with a pseudo-arclength continuation, is proposed to construct bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural network approach is also presented for solving eigenvalue problems to analyze solution linear stability, focusing on identifying the largest eigenvalue. The effectiveness of the proposed neural network is examined through experiments on the Bratu equation and the Burgers equation. Results from a finite difference method are also presented as comparison. Varying numbers of grid points are employed in each case to assess the behavior and accuracy of both the neural network and the finite difference method. The experimental results demonstrate that the proposed neural network produces better solutions, generates more accurate bifurcation diagrams, has reasonable computational times, and proves effective for linear stability analysis.",
      "authors": [
        "Muhammad Luthfi Shahab",
        "Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T05:05:13+00:00",
          "link": "https://arxiv.org/abs/2407.19707v1",
          "size": "1004kb",
          "version": "v1"
        },
        {
          "date": "2024-07-30T14:08:43+00:00",
          "link": "https://arxiv.org/abs/2407.19707v2",
          "size": "1004kb",
          "version": "v2"
        },
        {
          "date": "2024-08-05T11:22:34+00:00",
          "link": "https://arxiv.org/abs/2407.19707v3",
          "size": "1004kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T15:19:11+00:00",
          "link": "https://arxiv.org/abs/2407.19707v4",
          "size": "1004kb",
          "version": "v4"
        }
      ],
      "title": "Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19707",
        "HTML": "https://arxiv.org/html/2407.19707",
        "PDF": "https://arxiv.org/pdf/2407.19707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of neural networks for solving partial differential equations and performing bifurcation and stability analysis, which is not relevant to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.12519",
      "abstract": "The task of locating first order saddle points on high-dimensional surfaces describing the variation of energy as a function of atomic coordinates is an essential step for identifying the mechanism and estimating the rate of thermally activated events within the harmonic approximation of transition state theory. When combined directly with electronic structure calculations, the number of energy and atomic force evaluations needed for convergence is a primary issue. Here, we describe an efficient implementation of Gaussian process regression (GPR) acceleration of the minimum mode following method where a dimer is used to estimate the lowest eigenmode of the Hessian. A surrogate energy surface is constructed and updated after each electronic structure calculation. The method is applied to a test set of 500 molecular reactions previously generated by Hermez and coworkers [J. Chem. Theory Comput. 18, 6974 (2022)]. An order of magnitude reduction in the number of electronic structure calculations needed to reach the saddle point configurations is obtained by using the GPR compared to the dimer method. Despite the wide range in stiffness of the molecular degrees of freedom, the calculations are carried out using Cartesian coordinates and are found to require similar number of electronic structure calculations as an elaborate internal coordinate method implemented in the Sella software package. The present implementation of the GPR surrogate model in C++ is efficient enough for the wall time of the saddle point searches to be reduced in 3 out of 4 cases even though the calculations are carried out at a low Hartree-Fock level.",
      "authors": [
        "Rohit Goswami (1)",
        "Maxim Masterov (2)",
        "Satish Kamath (2)",
        "Alejandro Pe\\~na-Torres (1)",
        "Hannes J\\'onsson (1) ((1) Science Institute and Faculty of Physical Sciences",
        "University of Iceland",
        "Reykjav\\'ik",
        "Iceland",
        "(2) SURF",
        "Amsterdam",
        "The Netherlands)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-18T18:42:55+00:00",
          "link": "https://arxiv.org/abs/2505.12519v1",
          "size": "977kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:27:55+00:00",
          "link": "https://arxiv.org/abs/2505.12519v2",
          "size": "978kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Implementation of Gaussian Process Regression Accelerated Saddle Point Searches with Application to Molecular Reactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12519",
        "HTML": "https://arxiv.org/html/2505.12519",
        "PDF": "https://arxiv.org/pdf/2505.12519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Gaussian process regression for saddle point searches in molecular reactions, not on LLM training data processing or any related data operations."
      },
      "tasks": [
        "GPR"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06070",
      "abstract": "Recent advances in song identification leverage deep neural networks to learn compact audio fingerprints directly from raw waveforms. While these methods perform well under controlled conditions, their accuracy drops significantly in real-world scenarios where the audio is captured via mobile devices in noisy environments. In this paper, we introduce a novel evaluation protocol designed to better reflect such real-world conditions. We generate three recordings of the same audio, each with increasing levels of noise, captured using a mobile device's microphone. Our results reveal a substantial performance drop for two state-of-the-art CNN-based models under this protocol, compared to previously reported benchmarks. Additionally, we highlight the critical role of the augmentation pipeline during training with contrastive loss. By introduction low pass and high pass filters in the augmentation pipeline we significantly increase the performance of both systems in our proposed evaluation. Furthermore, we develop a transformer-based model with a tailored projection module and demonstrate that transferring knowledge from a semantically relevant domain yields a more robust solution. The transformer architecture outperforms CNN-based models across all noise levels, and query durations. In low noise conditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in finding the correct song, surpassing by 14%, and by 18.5% the second-best performing model, respectively, Under heavy noise levels, we achieve a detection rate 56.5% for 15-second query duration. All experiments are conducted on public large-scale dataset of over 100K songs, with queries matched against a database of 56 million vectors.",
      "authors": [
        "Christos Nikou and Theodoros Giannakopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:13:26+00:00",
          "link": "https://arxiv.org/abs/2507.06070v1",
          "size": "2029kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06070",
        "PDF": "https://arxiv.org/pdf/2507.06070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers around audio fingerprinting using contrastive and transfer learning, focusing on real-world evaluation of song identification. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2112.10970",
      "abstract": "In this article, we introduce a new method for discretizing micro-macro models of dilute polymeric fluids by integrating a finite element discretization for the macroscopic fluid dynamic equation with a deterministic variational particle scheme for the microscopic Fokker-Planck equation. To address challenges arising from micro-macro coupling, we employ a discrete energetic variational approach to derive a coarse-grained micro-macro model with a particle approximation first and then develop a particle-FEM discretization for the coarse-grained model. The accuracy of the proposed method is evaluated for a Hookean dumbbell model in a Couette flow by comparing the computed velocity field with existing analytical solutions. We also use our method to study nonlinear FENE dumbbell models in different scenarios, such as extension flow, pure shear flow, and lid-driven cavity flow. Numerical examples demonstrate that the proposed deterministic particle approach can accurately capture the various key rheological phenomena in the original FENE model, including hysteresis and {\\delta}-function-like spike behavior in extension flows, velocity overshoot phenomenon in pure shear flow, symmetries breaking, vortex center shifting and vortices weakening in the lid-driven cavity flow, with a small number of particles.",
      "authors": [
        "Xuelian Bao and Chun Liu and Yiwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Soft Condensed Matter (cond-mat.soft)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2021-12-21T03:53:54+00:00",
          "link": "https://arxiv.org/abs/2112.10970v1",
          "size": "12723kb",
          "version": "v1"
        },
        {
          "date": "2021-12-30T05:33:19+00:00",
          "link": "https://arxiv.org/abs/2112.10970v2",
          "size": "25216kb",
          "version": "v2"
        },
        {
          "date": "2022-03-20T03:36:30+00:00",
          "link": "https://arxiv.org/abs/2112.10970v3",
          "size": "12846kb",
          "version": "v3"
        },
        {
          "date": "2022-05-18T01:44:23+00:00",
          "link": "https://arxiv.org/abs/2112.10970v4",
          "size": "12613kb",
          "version": "v4"
        },
        {
          "date": "2023-04-21T02:48:00+00:00",
          "link": "https://arxiv.org/abs/2112.10970v5",
          "size": "6953kb",
          "version": "v5"
        },
        {
          "date": "2024-07-17T01:38:22+00:00",
          "link": "https://arxiv.org/abs/2112.10970v6",
          "size": "2372kb",
          "version": "v6"
        },
        {
          "date": "2024-09-23T03:56:18+00:00",
          "link": "https://arxiv.org/abs/2112.10970v7",
          "size": "6161kb",
          "version": "v7"
        },
        {
          "date": "2025-07-23T01:13:30+00:00",
          "link": "https://arxiv.org/abs/2112.10970v8",
          "size": "1887kb",
          "version": "v8"
        }
      ],
      "title": "A deterministic-particle-based scheme for micro-macro viscoelastic flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2112.10970",
        "HTML": "https://arxiv.org/html/2112.10970",
        "PDF": "https://arxiv.org/pdf/2112.10970"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This article introduces a method for discretizing micro-macro models of fluids, focusing on viscoelastic flows, without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.07217",
      "abstract": "Background: Verbal deception detection research relies on narratives and commonly assumes statements as truthful or deceptive. A more realistic perspective acknowledges that the veracity of statements exists on a continuum with truthful and deceptive parts being embedded within the same statement. However, research on embedded lies has been lagging behind. Methods: We collected a novel dataset of 2,088 truthful and deceptive statements with annotated embedded lies. Using a within-subjects design, participants provided a truthful account of an autobiographical event. They then rewrote their statement in a deceptive manner by including embedded lies, which they highlighted afterwards and judged on lie centrality, deceptiveness, and source. Results: We show that a fined-tuned language model (Llama-3-8B) can classify truthful statements and those containing embedded lies with 64% accuracy. Individual differences, linguistic properties and explainability analysis suggest that the challenge of moving the dial towards embedded lies stems from their resemblance to truthful statements. Typical deceptive statements consisted of 2/3 truthful information and 1/3 embedded lies, largely derived from past personal experiences and with minimal linguistic differences with their truthful counterparts. Conclusion: We present this dataset as a novel resource to address this challenge and foster research on embedded lies in verbal deception detection.",
      "authors": [
        "Riccardo Loconte",
        "Bennett Kleinberg"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-13T11:16:05+00:00",
          "link": "https://arxiv.org/abs/2501.07217v1",
          "size": "789kb",
          "version": "v1"
        }
      ],
      "title": "When lies are mostly truthful: automated verbal deception detection for embedded lies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07217",
        "PDF": "https://arxiv.org/pdf/2501.07217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel dataset related to verbal deception detection. Although it creates a dataset, it's not specifically aimed at LLM training data processing, focusing instead on deception detection."
      },
      "tasks": [
        "Deception Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2110.08298",
      "abstract": "Critical questions in dynamical neuroscience and machine learning are related to the study of continuous-time neural networks and their stability, robustness, and computational efficiency. These properties can be simultaneously established via a contraction analysis. This paper develops a comprehensive non-Euclidean contraction theory for continuous-time neural networks. Specifically, we provide novel sufficient conditions for the contractivity of general classes of continuous-time neural networks including Hopfield, firing rate, Persidskii, Lur'e, and other neural networks with respect to the non-Euclidean $\\ell_1/\\ell_\\infty$ norms. These sufficient conditions are based upon linear programming or, in some special cases, establishing the Hurwitzness of a particular Metzler matrix. To prove these sufficient conditions, we develop novel results on non-Euclidean logarithmic norms and a novel necessary and sufficient condition for contractivity of systems with locally Lipschitz dynamics. For each model, we apply our theoretical results to compute the optimal contraction rate and corresponding weighted non-Euclidean norm with respect to which the neural network is contracting.",
      "authors": [
        "Alexander Davydov",
        "Anton V. Proskurnikov",
        "Francesco Bullo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2021-10-15T18:13:29+00:00",
          "link": "https://arxiv.org/abs/2110.08298v1",
          "size": "147kb",
          "version": "v1"
        },
        {
          "date": "2021-11-05T19:01:07+00:00",
          "link": "https://arxiv.org/abs/2110.08298v2",
          "size": "147kb",
          "version": "v2"
        },
        {
          "date": "2022-03-24T06:14:06+00:00",
          "link": "https://arxiv.org/abs/2110.08298v3",
          "size": "174kb",
          "version": "v3"
        },
        {
          "date": "2022-11-26T01:52:54+00:00",
          "link": "https://arxiv.org/abs/2110.08298v4",
          "size": "191kb",
          "version": "v4"
        },
        {
          "date": "2024-06-29T19:43:40+00:00",
          "link": "https://arxiv.org/abs/2110.08298v5",
          "size": "406kb",
          "version": "v5"
        }
      ],
      "title": "Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.08298",
        "HTML": "https://arxiv.org/html/2110.08298",
        "PDF": "https://arxiv.org/pdf/2110.08298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The aim of this paper is to develop a non-Euclidean contraction theory for continuous-time neural networks, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.15595",
      "abstract": "In this article, we provide a novel and broadly-applicable contraction-theoretic approach to continuous-time time-varying convex optimization. For any parameter-dependent contracting dynamics, we show that the tracking error is asymptotically proportional to the rate of change of the parameter and that the proportionality constant is upper bounded by Lipschitz constant in which the parameter appears divided by the contraction rate of the dynamics squared. We additionally establish that augmenting any parameter-dependent contracting dynamics with a feedforward prediction term ensures that the tracking error vanishes exponentially quickly. To apply these results to time-varying convex optimization, we establish the strong infinitesimal contractivity of dynamics solving three canonical problems: monotone inclusions, linear equality-constrained problems, and composite minimization problems. For each case, we derive the sharpest-known contraction rates and provide explicit bounds on the tracking error between solution trajectories and minimizing trajectories. We validate our theoretical results on two numerical examples and on an application to control barrier function-based controller design that involves real hardware.",
      "authors": [
        "Alexander Davydov and Veronica Centorrino and Anand Gokhale and Giovanni Russo and Francesco Bullo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-24T22:06:37+00:00",
          "link": "https://arxiv.org/abs/2305.15595v1",
          "size": "978kb",
          "version": "v1"
        },
        {
          "date": "2024-05-30T02:04:24+00:00",
          "link": "https://arxiv.org/abs/2305.15595v2",
          "size": "1442kb",
          "version": "v2"
        },
        {
          "date": "2024-07-28T06:06:38+00:00",
          "link": "https://arxiv.org/abs/2305.15595v3",
          "size": "1442kb",
          "version": "v3"
        },
        {
          "date": "2025-01-16T19:25:09+00:00",
          "link": "https://arxiv.org/abs/2305.15595v4",
          "size": "3166kb",
          "version": "v4"
        }
      ],
      "title": "Time-Varying Convex Optimization: A Contraction and Equilibrium Tracking Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.15595",
        "PDF": "https://arxiv.org/pdf/2305.15595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses time-varying convex optimization using contraction-theoretic methodologies, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.15600",
      "abstract": "Sonatype's 2023 report found that 97% of developers and security leads integrate generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), into their development process. Concerns about the security implications of this trend have been raised. Developers are now weighing the benefits and risks of LLMs against other relied-upon information sources, such as StackOverflow (SO), requiring empirical data to inform their choice. In this work, our goal is to raise software developers awareness of the security implications when selecting code snippets by empirically comparing the vulnerabilities of ChatGPT and StackOverflow. To achieve this, we used an existing Java dataset from SO with security-related questions and answers. Then, we asked ChatGPT the same SO questions, gathering the generated code for comparison. After curating the dataset, we analyzed the number and types of Common Weakness Enumeration (CWE) vulnerabilities of 108 snippets from each platform using CodeQL. ChatGPT-generated code contained 248 vulnerabilities compared to the 302 vulnerabilities found in SO snippets, producing 20% fewer vulnerabilities with a statistically significant difference. Additionally, ChatGPT generated 19 types of CWE, fewer than the 22 found in SO. Our findings suggest developers are under-educated on insecure code propagation from both platforms, as we found 274 unique vulnerabilities and 25 types of CWE. Any code copied and pasted, created by AI or humans, cannot be trusted blindly, requiring good software engineering practices to reduce risk. Future work can help minimize insecure code propagation from any platform.",
      "authors": [
        "Sivana Hamer",
        "Marcelo d'Amorim",
        "Laurie Williams"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-22T20:06:41+00:00",
          "link": "https://arxiv.org/abs/2403.15600v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15600",
        "HTML": "https://arxiv.org/html/2403.15600",
        "PDF": "https://arxiv.org/pdf/2403.15600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper compares the security vulnerabilities of code from ChatGPT and StackOverflow without addressing LLM training data processing or data engineering focuses."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2401.12653",
      "abstract": "We study popularity for matchings under preferences. This solution concept captures matchings that do not lose against any other matching in a majority vote by the agents. A popular matching is said to be robust if it is popular among multiple instances. We present a polynomial-time algorithm for deciding whether there exists a robust popular matching if instances only differ with respect to the preferences of a single agent while obtaining NP-completeness if two instances differ only by a downward shift of one alternative by four agents. Moreover, we find a complexity dichotomy based on preference completeness for the case where instances differ by making some options unavailable.",
      "authors": [
        "Martin Bullinger and Rohith Reddy Gangam and Parnian Shahkar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-23T11:03:18+00:00",
          "link": "https://arxiv.org/abs/2401.12653v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Robust Popular Matchings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.12653",
        "PDF": "https://arxiv.org/pdf/2401.12653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces an algorithm for finding robust popular matchings, addressing combinatorial optimization in preference settings rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.16540",
      "abstract": "Detecting security vulnerabilities in source code remains challenging, particularly due to class imbalance in real-world datasets where vulnerable functions are under-represented. Existing learning-based methods often optimise for recall, leading to high false positive rates and reduced usability in development workflows. Furthermore, many approaches lack explainability, limiting their integration into security workflows. This paper presents ExplainVulD, a graph-based framework for vulnerability detection in C/C++ code. The method constructs Code Property Graphs and represents nodes using dual-channel embeddings that capture both semantic and structural information. These are processed by an edge-aware attention mechanism that incorporates edge-type embeddings to distinguish among program relations. To address class imbalance, the model is trained using class-weighted cross-entropy loss. ExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23 percent across 30 independent runs on the ReVeal dataset. These results represent relative improvements of 4.6 percent in accuracy and 16.9 percent in F1 score compared to the ReVeal model, a prior learning-based method. The framework also outperforms static analysis tools, with relative gains of 14.0 to 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond improved detection performance, ExplainVulD produces explainable outputs by identifying the most influential code regions within each function, supporting transparency and trust in security triage.",
      "authors": [
        "Radowanul Haque",
        "Aftab Ali",
        "Sally McClean and Naveed Khan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T12:49:14+00:00",
          "link": "https://arxiv.org/abs/2507.16540v1",
          "size": "395kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16540",
        "HTML": "https://arxiv.org/html/2507.16540",
        "PDF": "https://arxiv.org/pdf/2507.16540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "ExplainVulD addresses security vulnerability detection in C/C++ code using graph attention networks, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.18558",
      "abstract": "The integration of Large Language Models (LLMs) into various software applications raises concerns about their potential biases. Typically, those models are trained on a vast amount of data scrapped from forums, websites, social media and other internet sources, which may instill harmful and discriminating behavior into the model. To address this issue, we present LangBiTe, a testing platform to systematically assess the presence of biases within an LLM. LangBiTe enables development teams to tailor their test scenarios, and automatically generate and execute the test cases according to a set of user-defined ethical requirements. Each test consists of a prompt fed into the LLM and a corresponding test oracle that scrutinizes the LLM's response for the identification of biases. LangBite provides users with the bias evaluation of LLMs, and end-to-end traceability between the initial ethical requirements and the insights obtained.",
      "authors": [
        "Sergio Morales",
        "Robert Claris\\'o",
        "Jordi Cabot"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-29T10:02:45+00:00",
          "link": "https://arxiv.org/abs/2404.18558v1",
          "size": "189kb",
          "version": "v1"
        },
        {
          "date": "2025-07-22T16:10:18+00:00",
          "link": "https://arxiv.org/abs/2404.18558v2",
          "size": "182kb",
          "version": "v2"
        }
      ],
      "title": "LangBiTe: A Platform for Testing Bias in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.18558",
        "HTML": "https://arxiv.org/html/2404.18558",
        "PDF": "https://arxiv.org/pdf/2404.18558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper discusses bias testing in LLMs, it does not address any aspects of data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.06034",
      "abstract": "Semi-directed networks are partially directed graphs that model evolution where the directed edges represent reticulate evolutionary events. We present an algorithm that reconstructs binary $n$-leaf semi-directed level-1 networks in $O( n^2)$ time from its quarnets (4-leaf subnetworks). Our method assumes we have direct access to all quarnets, yet uses only an asymptotically optimal number of $O(n \\log n)$ quarnets. When the network is assumed to contain no triangles, our method instead relies only on four-cycle quarnets and the splits of the other quarnets. A variant of our algorithm works with quartets rather than quarnets and we show that it reconstructs most of a semi-directed level-1 network from an asymptotically optimal $O(n \\log n)$ of the quartets it displays. Additionally, we provide an $O(n^3)$ time algorithm that reconstructs the tree-of-blobs of any binary $n$-leaf semi-directed network with unbounded level from $O(n^3)$ splits of its quarnets.",
      "authors": [
        "Martin Frohn",
        "Niels Holtgrefe",
        "Leo van Iersel",
        "Mark Jones",
        "Steven Kelk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T19:49:20+00:00",
          "link": "https://arxiv.org/abs/2409.06034v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T13:57:22+00:00",
          "link": "https://arxiv.org/abs/2409.06034v2",
          "size": "69kb",
          "version": "v2"
        }
      ],
      "title": "Reconstructing semi-directed level-1 networks using few quarnets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06034",
        "PDF": "https://arxiv.org/pdf/2409.06034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an algorithm for reconstructing binary networks using quarnets. It does not contribute to the field of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.11707",
      "abstract": "Contraction theory is a mathematical framework for studying the convergence, robustness, and modularity properties of dynamical systems and algorithms. In this opinion paper, we provide five main opinions on the virtues of contraction theory. These opinions are (i) contraction theory is a unifying framework emerging from classical and modern works, (ii) contractivity is computationally-friendly, robust, and modular stability, (iii) numerous dynamical systems are contracting, (iv) contraction theory is relevant to modern applications, and (v) contraction theory can be vastly extended in numerous directions. We survey recent theoretical and applied research in each of these five directions.",
      "authors": [
        "Alexander Davydov and Francesco Bullo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-17T19:16:40+00:00",
          "link": "https://arxiv.org/abs/2404.11707v1",
          "size": "9078kb",
          "version": "v1"
        },
        {
          "date": "2024-07-28T20:59:00+00:00",
          "link": "https://arxiv.org/abs/2404.11707v2",
          "size": "9089kb",
          "version": "v2"
        }
      ],
      "title": "Perspectives on Contractivity in Control, Optimization, and Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.11707",
        "HTML": "https://arxiv.org/html/2404.11707",
        "PDF": "https://arxiv.org/pdf/2404.11707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses contraction theory and its applications in dynamical systems and algorithms, without addressing data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2305.04850",
      "abstract": "We consider two variants of the induced subgraph isomorphism problem for two independent binomial random graphs with constant edge-probabilities p_1,p_2. In particular, (i) we prove a sharp threshold result for the appearance of G_{n,p_1} as an induced subgraph of G_{N,p_2}, (ii) we show two-point concentration of the size of the maximum common induced subgraph of G_{N, p_1} and G_{N,p_2}, and (iii) we show that the number of induced copies of G_{n,p_1} in G_{N,p_2} has an unusual limiting distribution.\n  These results confirm simulation-based predictions of McCreesh, Prosser, Solnon and Trimble, and resolve several open problems of Chatterjee and Diaconis. The proofs are based on careful refinements of the first and second moment method, using extra twists to (a) take some non-standard behaviors into account, and (b) work around the large variance issues that prevent standard applications of these methods.",
      "authors": [
        "Erlang Surya",
        "Lutz Warnke",
        "Emily Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-08T16:47:00+00:00",
          "link": "https://arxiv.org/abs/2305.04850v1",
          "size": "177kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T03:15:48+00:00",
          "link": "https://arxiv.org/abs/2305.04850v2",
          "size": "179kb",
          "version": "v2"
        }
      ],
      "title": "Isomorphisms between dense random graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.04850",
        "HTML": "https://arxiv.org/html/2305.04850",
        "PDF": "https://arxiv.org/pdf/2305.04850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the induced subgraph isomorphism problem for dense random graphs, which is unrelated to training data processing for large language models (LLMs)."
      },
      "source": "arXiv"
    },
    {
      "id": "2203.14113",
      "abstract": "We propose a shape fitting/registration method based on a Gaussian Processes formulation, suitable for shapes with extensive regions of missing data. Gaussian Processes are a proven powerful tool, as they provide a unified setting for shape modelling and fitting. While the existing methods in this area prove to work well for the general case of the human head, when looking at more detailed and deformed data, with a high prevalence of missing data, such as the ears, the results are not satisfactory. In order to overcome this, we formulate the shape fitting problem as a multi-annotator Gaussian Process Regression and establish a parallel with the standard probabilistic registration. The achieved method SFGP shows better performance when dealing with extensive areas of missing data when compared to a state-of-the-art registration method and current approaches for registration with pre-existing shape models. Experiments are conducted both for a 2D small dataset with diverse transformations and a 3D dataset of ears.",
      "authors": [
        "Filipa Valdeira and Ricardo Ferreira and Alessandra Micheletti and Cl\\'audia Soares"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-26T16:48:27+00:00",
          "link": "https://arxiv.org/abs/2203.14113v1",
          "size": "598kb",
          "version": "v1"
        },
        {
          "date": "2023-04-24T09:30:43+00:00",
          "link": "https://arxiv.org/abs/2203.14113v2",
          "size": "619kb",
          "version": "v2"
        }
      ],
      "title": "Probabilistic Registration for Gaussian Process 3D shape modelling in the presence of extensive missing data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.14113",
        "PDF": "https://arxiv.org/pdf/2203.14113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents a shape fitting method for 3D modeling, addressing missing data in shape registration, which does not relate to the processing of training data for large language models."
      },
      "tasks": [
        "Gaussian Processes",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.05351",
      "abstract": "In recent years, interest in quantum computing has increased due to technological advances in quantum hardware and algorithms. Despite the promises of quantum advantage, the applicability of quantum devices has been limited to few qubits on hardware that experiences decoherence due to noise. One proposed method to get around this challenge is distributed quantum computing (DQC). Like classical distributed computing, DQC aims at increasing compute power by spreading the compute processes across many devices, with the goal to minimize the noise and circuit depth required by quantum devices. In this paper, we cover the fundamental concepts of DQC and provide insight into where the field of DQC stands with respect to the field of chemistry -- a field which can potentially be used to demonstrate quantum advantage on noisy-intermediate scale quantum devices.",
      "authors": [
        "Grier M. Jones",
        "Hans-Arno Jacobsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-09T21:42:51+00:00",
          "link": "https://arxiv.org/abs/2408.05351v1",
          "size": "17365kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Quantum Computing for Chemical Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05351",
        "HTML": "https://arxiv.org/html/2408.05351",
        "PDF": "https://arxiv.org/pdf/2408.05351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses distributed quantum computing and its applications in chemistry, which has no direct connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02678",
      "abstract": "Accurately modeling chemical reactions in molecular dynamics simulations requires detailed pre- and post-reaction templates, often created through labor-intensive manual workflows. This work introduces a Python-based algorithm that automates the generation of reaction templates for the LAMMPS REACTION package, leveraging graph-theoretical principles and sub-graph isomorphism techniques. By representing molecular systems as mathematical graphs, the method enables automated identification of conserved molecular domains, reaction sites, and atom mappings, significantly reducing manual effort. The algorithm was validated on three case studies: poly-addition, poly-condensation, and chain polymerization, demonstrating its ability to map conserved regions, identify reaction-initiating atoms, and resolve challenges such as symmetric reactants and indistinguishable atoms. Additionally, the generated templates were optimized for computational efficiency by retaining only essential reactive domains, ensuring scalability and consistency in high-throughput workflows for computational chemistry, materials science, and machine learning applications. Future work will focus on extending the method to mixed organic-inorganic systems, incorporating adaptive scoring mechanisms, and integrating quantum mechanical calculations to enhance its applicability.",
      "authors": [
        "Julian Konrad and Robert Mei{\\ss}ner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T14:49:38+00:00",
          "link": "https://arxiv.org/abs/2503.02678v1",
          "size": "2765kb",
          "version": "v1"
        }
      ],
      "title": "Smart Reaction Templating: A Graph-Based Method for Automated Molecular Dynamics Input Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02678",
        "HTML": "https://arxiv.org/html/2503.02678",
        "PDF": "https://arxiv.org/pdf/2503.02678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on automating the generation of reaction templates for molecular dynamics simulations using graph-based methods, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.13407",
      "abstract": "We derive novel deterministic bounds on the approximation error of data-based bilinear surrogate models for unknown nonlinear systems. The surrogate models are constructed using kernel-based extended dynamic mode decomposition to approximate the Koopman operator in a reproducing kernel Hilbert space. Unlike previous methods that require restrictive assumptions on the invariance of the dictionary, our approach leverages kernel-based dictionaries that allow us to control the projection error via pointwise error bounds, overcoming a significant limitation of existing theoretical guarantees. The derived state- and input-dependent error bounds allow for direct integration into Koopman-based robust controller designs with closed-loop guarantees for the unknown nonlinear system. Numerical examples illustrate the effectiveness of the proposed framework.",
      "authors": [
        "Robin Str\\\"asser",
        "Manuel Schaller",
        "Julian Berberich",
        "Karl Worthmann",
        "Frank Allg\\\"ower"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T17:38:19+00:00",
          "link": "https://arxiv.org/abs/2503.13407v1",
          "size": "84kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T14:41:22+00:00",
          "link": "https://arxiv.org/abs/2503.13407v2",
          "size": "85kb",
          "version": "v2"
        },
        {
          "date": "2025-06-20T13:57:59+00:00",
          "link": "https://arxiv.org/abs/2503.13407v3",
          "size": "85kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T11:51:27+00:00",
          "link": "https://arxiv.org/abs/2503.13407v4",
          "size": "85kb",
          "version": "v4"
        }
      ],
      "title": "Kernel-based error bounds of bilinear Koopman surrogate models for nonlinear data-driven control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13407",
        "PDF": "https://arxiv.org/pdf/2503.13407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses error bounds for surrogate models in nonlinear control systems, which is not relevant to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.03799",
      "abstract": "This study investigates the application of novel model architectures and large-scale foundational models in temporal series analysis of lower limb rehabilitation motion data, aiming to leverage advancements in machine learning and artificial intelligence to empower active rehabilitation guidance strategies for post-stroke patients in limb motor function recovery. Utilizing the SIAT-LLMD dataset of lower limb movement data proposed by the Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, we systematically elucidate the implementation and analytical outcomes of the innovative xLSTM architecture and the foundational model Lag-Llama in short-term temporal prediction tasks involving joint kinematics and dynamics parameters. The research provides novel insights for AI-enabled medical rehabilitation applications, demonstrating the potential of cutting-edge model architectures and large-scale models in rehabilitation medicine temporal prediction. These findings establish theoretical foundations for future applications of personalized rehabilitation regimens, offering significant implications for the development of customized therapeutic interventions in clinical practice.",
      "authors": [
        "Hengyu Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T05:40:13+00:00",
          "link": "https://arxiv.org/abs/2504.03799v1",
          "size": "2283kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T13:28:41+00:00",
          "link": "https://arxiv.org/abs/2504.03799v2",
          "size": "2286kb",
          "version": "v2"
        }
      ],
      "title": "Experimental Study on Time Series Analysis of Lower Limb Rehabilitation Exercise Data Driven by Novel Model Architecture and Large Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03799",
        "PDF": "https://arxiv.org/pdf/2504.03799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on temporal series analysis of lower limb rehabilitation motion data using novel model architectures, which does not pertain to LLM training data processing for language models or involve data engineering for LLMs."
      },
      "tasks": [
        "Time Series",
        "Time Series Analysis"
      ],
      "repo_urls": [
        "https://github.com/linhyyy/tsa-ll-rehab-xlstm-lagllama"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17760",
      "abstract": "This overview article makes the case for how topological concepts can enrich research in machine learning. Using the Euler Characteristic Transform (ECT), a geometrical-topological invariant, as a running example, I present different use cases that result in more efficient models for analyzing point clouds, graphs, and meshes. Moreover, I outline a vision for how topological concepts could be used in the future, comprising (1) the learning of functions on topological spaces, (2) the building of hybrid models that imbue neural networks with knowledge about the topological information in data, and (3) the analysis of qualitative properties of neural networks. With current research already addressing some of these aspects, this article thus serves as an introduction and invitation to this nascent area of research.",
      "authors": [
        "Bastian Rieck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Algebraic Topology (math.AT)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T10:56:05+00:00",
          "link": "https://arxiv.org/abs/2410.17760v1",
          "size": "11722kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T09:34:15+00:00",
          "link": "https://arxiv.org/abs/2410.17760v2",
          "size": "7926kb",
          "version": "v2"
        }
      ],
      "title": "Topology meets Machine Learning: An Introduction using the Euler Characteristic Transform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17760",
        "PDF": "https://arxiv.org/pdf/2410.17760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces topological concepts to enhance machine learning models, illustrating through the Euler Characteristic Transform. It does not address data processing for LLM training."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/aidos-lab/ECT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.11985",
      "abstract": "We consider the problem of active learning in the context of spatial sampling for level set estimation (LSE), where the goal is to localize all regions where a function of interest lies above/below a given threshold as quickly as possible. We present a finite-horizon search procedure to perform LSE in one dimension while optimally balancing both the final estimation error and the distance traveled for a fixed number of samples. A tuning parameter is used to trade off between the estimation accuracy and distance traveled. We show that the resulting optimization problem can be solved in closed form and that the resulting policy generalizes existing approaches to this problem. We then show how this approach can be used to perform level set estimation in higher dimensions under the popular Gaussian process model. Empirical results on synthetic data indicate that as the cost of travel increases, our method's ability to treat distance nonmyopically allows it to significantly improve on the state of the art. On real air quality data, our approach achieves roughly one fifth the estimation error at less than half the cost of competing algorithms.",
      "authors": [
        "Phillip Kearns",
        "Bruno Jedynak",
        "John Lipor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-18T14:11:41+00:00",
          "link": "https://arxiv.org/abs/2310.11985v1",
          "size": "3493kb",
          "version": "v1"
        }
      ],
      "title": "A Finite-Horizon Approach to Active Level Set Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.11985",
        "PDF": "https://arxiv.org/pdf/2310.11985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with active level set estimation and spatial sampling, which does not intersect with the realm of LLM training data processing or dataset creation for language models."
      },
      "tasks": [
        "Active Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2105.10362",
      "abstract": "Cloud Native Application CNApp (as a distributed system) is a collection of independent components (micro-services) interacting via communication protocols. This gives rise to present an abstract architecture of CNApp as dynamically re-configurable acyclic directed multi graph where vertices are microservices, and edges are the protocols. Generic mechanisms for such reconfigurations evidently correspond to higher-level functions (functionals). This implies also internal abstract architecture of microservice as a collection of event-triggered serverless functions (including functions implementing the protocols) that are composed into event-dependent data-flow graphs, and dynamically reconfigured at the runtime. Again, generic mechanisms for such compositions and reconfigurations correspond to functionals and higher order type theory like Coq https://coq.inria.fr/about-coq. Our contribution is strictly theoretical and relies on the abstract architecture of CNApp that is closely related to the calculus of functionals and relations. The proposed theoretical approach is an attempt to implement the original idea of programming at the function level postulated by John Backus 1978 \\cite{Backus}; the idea that is still waiting to be implemented as a non-von Neumann programming language.",
      "authors": [
        "Stanislaw Ambroszkiewicz",
        "Waldemar Bartyna and Stanislaw Bylka"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2021-05-21T15:28:49+00:00",
          "link": "https://arxiv.org/abs/2105.10362v1",
          "size": "1557kb",
          "version": "v1"
        },
        {
          "date": "2021-06-02T19:10:02+00:00",
          "link": "https://arxiv.org/abs/2105.10362v2",
          "size": "1614kb",
          "version": "v2"
        },
        {
          "date": "2021-07-29T19:18:04+00:00",
          "link": "https://arxiv.org/abs/2105.10362v3",
          "size": "1668kb",
          "version": "v3"
        },
        {
          "date": "2021-11-24T17:51:47+00:00",
          "link": "https://arxiv.org/abs/2105.10362v4",
          "size": "1698kb",
          "version": "v4"
        },
        {
          "date": "2022-08-25T15:58:50+00:00",
          "link": "https://arxiv.org/abs/2105.10362v5",
          "size": "1698kb",
          "version": "v5"
        },
        {
          "date": "2025-07-22T18:48:48+00:00",
          "link": "https://arxiv.org/abs/2105.10362v6",
          "size": "146kb",
          "version": "v6"
        }
      ],
      "title": "Functionals in the Clouds: An abstract architecture of serverless Cloud-Native Apps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2105.10362",
        "HTML": "https://arxiv.org/html/2105.10362",
        "PDF": "https://arxiv.org/pdf/2105.10362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an abstract architecture for cloud-native applications focusing on microservices and serverless functions. It does not address topics related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.03875",
      "abstract": "In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.",
      "authors": [
        "Robin Str\\\"asser",
        "Julian Berberich",
        "Frank Allg\\\"ower"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T12:44:41+00:00",
          "link": "https://arxiv.org/abs/2411.03875v1",
          "size": "130kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T10:50:59+00:00",
          "link": "https://arxiv.org/abs/2411.03875v2",
          "size": "130kb",
          "version": "v2"
        },
        {
          "date": "2025-03-14T12:36:09+00:00",
          "link": "https://arxiv.org/abs/2411.03875v3",
          "size": "130kb",
          "version": "v3"
        }
      ],
      "title": "Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03875",
        "PDF": "https://arxiv.org/pdf/2411.03875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel controller design approach for nonlinear systems using the Koopman operator, with a focus on data-driven controller design. It is not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10330",
      "abstract": "Despite advancements in Natural Language Processing (NLP), models remain vulnerable to adversarial attacks, such as synonym substitutions. While prior work has focused on improving robustness for feed-forward and convolutional architectures, the robustness of recurrent networks and modern state space models (SSMs), such as S4, remains understudied. These architectures pose unique challenges due to their sequential processing and complex parameter dynamics. In this paper, we introduce a novel regularization technique based on Growth Bound Matrices (GBM) to improve NLP model robustness by reducing the impact of input perturbations on model outputs. We focus on computing the GBM for three architectures: Long Short-Term Memory (LSTM), State Space models (S4), and Convolutional Neural Networks (CNN). Our method aims to (1) enhance resilience against word substitution attacks, (2) improve generalization on clean text, and (3) providing the first systematic analysis of SSM (S4) robustness. Extensive experiments across multiple architectures and benchmark datasets demonstrate that our method improves adversarial robustness by up to 8.8% over existing baselines. These results highlight the effectiveness of our approach, outperforming several state-of-the-art methods in adversarial defense. Codes are available at https://github.com/BouriMohammed/GBM",
      "authors": [
        "Mohammed Bouri",
        "and Adnane Saoud"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:38:48+00:00",
          "link": "https://arxiv.org/abs/2507.10330v1",
          "size": "2839kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10330",
        "HTML": "https://arxiv.org/html/2507.10330",
        "PDF": "https://arxiv.org/pdf/2507.10330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving robustness against word substitution attacks for various NLP models. It discusses a regularization technique called Growth Bound Matrices (GBM), aiming at adversarial robustness and generalization. There is no mention of data processing for LLM training, such as data collection or dataset curation."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.08906",
      "abstract": "Educational games enhance learning experiences by integrating touchscreens, making interactions more engaging and intuitive for learners. However, the cognitive impacts of educational gameplay input modalities, such as the hand and stylus technique, are unclear. We compared the experience of using hands vs. a stylus for touchscreens while playing an educational game by analyzing oxygenated hemoglobin collected by functional Near-Infrared Spectroscopy and self-reported measures. In addition, we measured the hand vs. the stylus modalities of the task and calculated the relative neural efficiency and relative neural involvement using the mental demand and the quiz score. Our findings show that the hand condition had a significantly lower neural involvement, yet higher neural efficiency than the stylus condition. This result suggests the requirement of less cognitive effort while using the hand. Additionally, the self-reported measures show significant differences, and the results suggest that hand-based input is more intuitive, less cognitively demanding, and less frustrating. Conversely, the use of a stylus required higher cognitive effort due to the cognitive balance of controlling the pen and answering questions. These findings highlight the importance of designing educational games that allow learners to engage with the system while minimizing cognitive effort.",
      "authors": [
        "Shayla Sharmin",
        "Elham Bakhshipour",
        "Behdokht Kiafar",
        "Md Fahim Abrar",
        "Pinar Kullu",
        "Nancy Getchell",
        "Roghayeh Leila Barmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-14T18:47:04+00:00",
          "link": "https://arxiv.org/abs/2405.08906v1",
          "size": "8440kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T18:12:09+00:00",
          "link": "https://arxiv.org/abs/2405.08906v2",
          "size": "4544kb",
          "version": "v2"
        },
        {
          "date": "2024-11-15T23:17:21+00:00",
          "link": "https://arxiv.org/abs/2405.08906v3",
          "size": "4544kb",
          "version": "v3"
        },
        {
          "date": "2025-02-03T19:12:29+00:00",
          "link": "https://arxiv.org/abs/2405.08906v4",
          "size": "13721kb",
          "version": "v4"
        },
        {
          "date": "2025-05-29T18:41:07+00:00",
          "link": "https://arxiv.org/abs/2405.08906v5",
          "size": "6261kb",
          "version": "v5"
        },
        {
          "date": "2025-07-18T14:17:15+00:00",
          "link": "https://arxiv.org/abs/2405.08906v6",
          "size": "6212kb",
          "version": "v6"
        }
      ],
      "title": "Functional Near-Infrared Spectroscopy (fNIRS) Analysis of Interaction Techniques in Touchscreen-Based Educational Gaming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.08906",
        "HTML": "https://arxiv.org/html/2405.08906",
        "PDF": "https://arxiv.org/pdf/2405.08906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores cognitive impacts of different interaction techniques in educational gaming using touchscreen devices. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.05565",
      "abstract": "Contact can be conceptualized as a set of constraints imposed on two bodies that are interacting with one another in some way. The nature of a contact, whether a point, line, or surface, dictates how these bodies are able to move with respect to one another given a force, and a set of contacts can provide either partial or full constraint on a body's motion. Decades of work have explored how to explicitly estimate the location of a contact and its dynamics, e.g., frictional properties, but investigated methods have been computationally expensive and there often exists significant uncertainty in the final calculation. This has affected further advancements in contact-rich tasks that are seemingly simple to humans, such as generalized peg-in-hole insertions. In this work, instead of explicitly estimating the individual contact dynamics between an object and its hole, we approach this problem by investigating compliance-enabled contact formations. More formally, contact formations are defined according to the constraints imposed on an object's available degrees-of-freedom. Rather than estimating individual contact positions, we abstract out this calculation to an implicit representation, allowing the robot to either acquire, maintain, or release constraints on the object during the insertion process, by monitoring forces enacted on the end effector through time. Using a compliant robot, our method is desirable in that we are able to complete industry-relevant insertion tasks of tolerances <0.25mm without prior knowledge of the exact hole location or its orientation. We showcase our method on more generalized insertion tasks, such as commercially available non-cylindrical objects and open world plug tasks.",
      "authors": [
        "Andrew S. Morgan",
        "Quentin Bateux",
        "Mei Hao",
        "Aaron M. Dollar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-09T20:16:48+00:00",
          "link": "https://arxiv.org/abs/2303.05565v1",
          "size": "8701kb",
          "version": "v1"
        }
      ],
      "title": "Towards Generalized Robot Assembly through Compliance-Enabled Contact Formations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.05565",
        "PDF": "https://arxiv.org/pdf/2303.05565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is concerned with contact dynamics for robotics tasks and does not address any aspects of LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.18199",
      "abstract": "Semantic Edge Computing (SEC) and Semantic Communications (SemComs) have been proposed as viable approaches to achieve real-time edge-enabled intelligence in sixth-generation (6G) wireless networks. On one hand, SemCom leverages the strength of Deep Neural Networks (DNNs) to encode and communicate the semantic information only, while making it robust to channel distortions by compensating for wireless effects. Ultimately, this leads to an improvement in the communication efficiency. On the other hand, SEC has leveraged distributed DNNs to divide the computation of a DNN across different devices based on their computational and networking constraints. Although significant progress has been made in both fields, the literature lacks a systematic view to connect both fields. In this work, we fulfill the current gap by unifying the SEC and SemCom fields. We summarize the research problems in these two fields and provide a comprehensive review of the state of the art with a focus on their technical strengths and challenges.",
      "authors": [
        "Milin Zhang",
        "Mohammad Abdi",
        "Venkat R. Dasari",
        "Francesco Restuccia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T10:21:10+00:00",
          "link": "https://arxiv.org/abs/2411.18199v1",
          "size": "1630kb",
          "version": "v1"
        },
        {
          "date": "2025-04-24T23:33:33+00:00",
          "link": "https://arxiv.org/abs/2411.18199v2",
          "size": "2357kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T19:22:05+00:00",
          "link": "https://arxiv.org/abs/2411.18199v3",
          "size": "894kb",
          "version": "v3"
        }
      ],
      "title": "Semantic Edge Computing and Semantic Communications in 6G Networks: A Unifying Survey and Research Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18199",
        "HTML": "https://arxiv.org/html/2411.18199",
        "PDF": "https://arxiv.org/pdf/2411.18199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Semantic Edge Computing and Semantic Communications within 6G networks, which are unrelated to the training data processing involved in large language models."
      },
      "tasks": [
        "Edge-computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.13545",
      "abstract": "Homomorphic encryption (HE) allows computations to be directly carried out on ciphertexts and is essential to privacy-preserving computing, such as neural network inference, medical diagnosis, and financial data analysis. Only addition and 2-input multiplication are defined over ciphertexts in popular HE schemes. However, many HE applications involve non-linear functions and they need to be approximated using high-order polynomials to maintain precision. To reduce the complexity of these computations, this paper proposes 3-input ciphertext multiplication. One extra evaluation key is introduced to carry out the relinearization step of ciphertext multiplication, and new formulas are proposed to combine computations and share intermediate results. Compared to using two consecutive 2- input multiplications, computing the product of three ciphertexts utilizing the proposed scheme leads to almost a half of the latency, 29% smaller silicon area, and lower noise without scarifying the throughput.",
      "authors": [
        "Sajjad Akherati",
        "Yok Jye Tang",
        "and Xinmiao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T13:40:49+00:00",
          "link": "https://arxiv.org/abs/2410.13545v1",
          "size": "235kb",
          "version": "v1"
        }
      ],
      "title": "Three-Input Ciphertext Multiplication for Homomorphic Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13545",
        "HTML": "https://arxiv.org/html/2410.13545",
        "PDF": "https://arxiv.org/pdf/2410.13545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on homomorphic encryption techniques and does not address any dimension of LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.11064",
      "abstract": "Homomorphic encryption (HE) allows computations to be directly carried out on ciphertexts and enables privacy-preserving cloud computing. The computations on the coefficients of the polynomials involved in HE are always followed by modular reduction, and the overall complexity of ciphertext multiplication can be reduced by utilizing the quotient. Our previous design considers the cases that the dividend is an integer multiple of the modulus and the modulus is in the format of $2^w-2^u\\pm1$, where $u<w/2$. In this paper, the division is generalized for larger $u$ and dividend not an integer multiple of the modulus. An algorithm is proposed to compute the quotient and vigorous mathematical proofs are provided. Moreover, efficient hardware architecture is developed for implementing the proposed algorithm. Compared to alternative division approaches that utilize the inverse of the divisor, for $w=32$, the proposed design achieves at least 9% shorter latency and 79\\% area reduction for 75% possible values of $u$.",
      "authors": [
        "Sajjad Akherati",
        "Jiaxuan Cai",
        "and Xinmiao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-19T23:53:59+00:00",
          "link": "https://arxiv.org/abs/2401.11064v1",
          "size": "315kb",
          "version": "v1"
        }
      ],
      "title": "Low-Complexity Integer Divider Architecture for Homomorphic Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.11064",
        "HTML": "https://arxiv.org/html/2401.11064",
        "PDF": "https://arxiv.org/pdf/2401.11064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research deals with integer divider architectures for homomorphic encryption, focusing on hardware optimization, not related to LLM training data processing or operations relevant to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.16053",
      "abstract": "With the increasing adoption of digitization, more and more historical visualizations created hundreds of years ago are accessible in digital libraries online. It provides a unique opportunity for visualization and history research. Meanwhile, there is no large-scale digital collection dedicated to historical visualizations. The visualizations are scattered in various collections, which hinders retrieval. In this study, we curate the first large-scale dataset dedicated to historical visualizations. Our dataset comprises 13K historical visualization images with corresponding processed metadata from seven digital libraries. In curating the dataset, we propose a workflow to scrape and process heterogeneous metadata. We develop a semi-automatic labeling approach to distinguish visualizations from other artifacts. Our dataset can be accessed with OldVisOnline, a system we have built to browse and label historical visualizations. We discuss our vision of usage scenarios and research opportunities with our dataset, such as textual criticism for historical visualizations. Drawing upon our experience, we summarize recommendations for future efforts to improve our dataset.",
      "authors": [
        "Yu Zhang",
        "Ruike Jiang",
        "Liwenhan Xie",
        "Yuheng Zhao",
        "Can Liu",
        "Tianhong Ding",
        "Siming Chen",
        "Xiaoru Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-30T14:19:31+00:00",
          "link": "https://arxiv.org/abs/2308.16053v1",
          "size": "20124kb",
          "version": "v1"
        }
      ],
      "title": "OldVisOnline: Curating a Dataset of Historical Visualizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.16053",
        "PDF": "https://arxiv.org/pdf/2308.16053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on curating a dataset of historical visualizations without discussing applications or contributions related to LLM training data processing, pretraining, or fine-tuning."
      },
      "repo_urls": [
        "https://github.com/oldvis/gallery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.18239",
      "abstract": "Precise segmentation of papillary thyroid microcarcinoma (PTMC) during ultrasound-guided radiofrequency ablation (RFA) is critical for effective treatment but remains challenging due to acoustic artifacts, small lesion size, and anatomical variability. In this study, we propose DualSwinUnet++, a dual-decoder transformer-based architecture designed to enhance PTMC segmentation by incorporating thyroid gland context. DualSwinUnet++ employs independent linear projection heads for each decoder and a residual information flow mechanism that passes intermediate features from the first (thyroid) decoder to the second (PTMC) decoder via concatenation and transformation. These design choices allow the model to condition tumor prediction explicitly on gland morphology without shared gradient interference. Trained on a clinical ultrasound dataset with 691 annotated RFA images and evaluated against state-of-the-art models, DualSwinUnet++ achieves superior Dice and Jaccard scores while maintaining sub-200ms inference latency. The results demonstrate the model's suitability for near real-time surgical assistance and its effectiveness in improving segmentation accuracy in challenging PTMC cases.",
      "authors": [
        "Maryam Dialameh",
        "Hossein Rajabzadeh",
        "Moslem Sadeghi-Goughari",
        "Jung Suk Sim",
        "Hyock Ju Kwon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T19:33:33+00:00",
          "link": "https://arxiv.org/abs/2410.18239v1",
          "size": "2537kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T03:11:31+00:00",
          "link": "https://arxiv.org/abs/2410.18239v2",
          "size": "3286kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T16:58:02+00:00",
          "link": "https://arxiv.org/abs/2410.18239v3",
          "size": "3286kb",
          "version": "v3"
        }
      ],
      "title": "DualSwinUnet++: An Enhanced Swin-Unet Architecture With Dual Decoders For PTMC Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18239",
        "HTML": "https://arxiv.org/html/2410.18239",
        "PDF": "https://arxiv.org/pdf/2410.18239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a model architecture for medical image segmentation. It does not involve any LLM training data processing operations."
      },
      "tasks": [
        "Decoder",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06115",
      "abstract": "Trailer parking is a challenging task due to the unstable nature of the vehicle-trailer system in reverse motion and the unintuitive steering actions required at the vehicle to accomplish the parking maneuver. This paper presents a strategy to tackle this kind of maneuver with an advisory graphic aid to help the human driver with the task of manually backing up the vehicle-trailer system. A kinematic vehicle-trailer model is derived to describe the low-speed motion of the vehicle-trailer system, and its inverse kinematics is established by generating an equivalent virtual trailer axle steering command. The advisory system graphics is generated based on the inverse kinematics and displays the expected trailer orientation given the current vehicle steer angle and configuration (hitch angle). Simulation study and animation are set up to test the efficacy of the approach, where the user can select both vehicle speed and vehicle steering angle freely, which allows the user to stop the vehicle-trailer system and experiment with different steering inputs to see their effect on the predicted trailer motion before proceeding with the best one according to the advisory graphics, hence creating a series of piecewise continuous control actions similar to how manual trailer reverse parking is usually carried out. The advisory graphics proves to provide the driver with an intuitive understanding of the trailer motion at any given configuration (hitch angle).",
      "authors": [
        "Xincheng Cao",
        "Haochong Chen",
        "Bilin Aksun Guvenc",
        "Levent Guvenc",
        "Shihong Fan",
        "John Harber",
        "Brian Link",
        "Peter Richmond",
        "Dokyung Yim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T17:12:30+00:00",
          "link": "https://arxiv.org/abs/2501.06115v1",
          "size": "1136kb",
          "version": "v1"
        }
      ],
      "title": "Development of an Advisory System for Parking of a Car and Trailer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06115",
        "PDF": "https://arxiv.org/pdf/2501.06115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system for assisting in trailer parking through an advisory graphic aid, which has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2202.01670",
      "abstract": "In this work, we leverage a generative data model considering comparison noise to develop a fast, precise, and informative ranking algorithm from pairwise comparisons that produces a measure of confidence on each comparison. The problem of ranking a large number of items from noisy and sparse pairwise comparison data arises in diverse applications, like ranking players in online games, document retrieval or ranking human perceptions. Although different algorithms are available, we need fast, large-scale algorithms whose accuracy degrades gracefully when the number of comparisons is too small. Fitting our proposed model entails solving a non-convex optimization problem, which we tightly approximate by a sum of quasi-convex functions and a regularization term. Resorting to an iterative reweighted minimization and the Primal-Dual Hybrid Gradient method, we obtain PD-Rank, achieving a Kendall tau 0.1 higher than all comparing methods, even for 10\\% of wrong comparisons in simulated data matching our data model, and leading in accuracy if data is generated according to the Bradley-Terry model, in both cases faster by one order of magnitude, in seconds. In real data, PD-Rank requires less computational time to achieve the same Kendall tau than active learning methods.",
      "authors": [
        "Filipa Valdeira",
        "Cl\\'audia Soares"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-03T16:36:37+00:00",
          "link": "https://arxiv.org/abs/2202.01670v1",
          "size": "558kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T09:39:13+00:00",
          "link": "https://arxiv.org/abs/2202.01670v2",
          "size": "1620kb",
          "version": "v2"
        }
      ],
      "title": "Ranking with Confidence for Large Scale Comparison Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.01670",
        "HTML": "https://arxiv.org/html/2202.01670",
        "PDF": "https://arxiv.org/pdf/2202.01670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ranking algorithms from pairwise comparison data, which does not contribute to LLM training data processing as it focuses on optimization and ranking rather than dataset creation or improvement."
      },
      "tasks": [
        "Active Learning",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/FilVa/PD-Rank"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.10317",
      "abstract": "Developers rely on open-source packages and must review dependencies to safeguard against vulnerable or malicious upstream code. A careful review of all dependencies changes often does not occur in practice. Therefore, developers need signals to inform of dependency changes that require additional examination. The goal of this study is to help developers prioritize dependency review efforts by analyzing contributor reputation measures as a signal. We use network centrality measures to proxy contributor reputation using collaboration activity. We employ a mixed method methodology from the top 1,644 packages in the Rust ecosystem to build a network of 6,949 developers, survey 285 developers, and model 5 centrality measures. We find that only 24% of respondents often review dependencies before adding or updating a package, mentioning difficulties in the review process. Additionally, 51% of respondents often consider contributor reputation when reviewing dependencies. The closeness centrality measure is a significant factor in explaining how developers review dependencies. Yet, centrality measures alone do not account for how developers choose to review dependencies. We recommend that ecosystems like GitHub, Rust, and npm implement a contributor reputation badge based on our modeled coefficients to aid developers in dependency reviews.",
      "authors": [
        "Sivana Hamer",
        "Nasif Imtiaz",
        "Mahzabin Tamanna",
        "Preya Shabrina",
        "and Laurie Williams"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-14T16:13:58+00:00",
          "link": "https://arxiv.org/abs/2406.10317v1",
          "size": "1621kb",
          "version": "v1"
        }
      ],
      "title": "Trusting code in the wild: Exploring contributor reputation measures to review dependencies in the Rust ecosystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10317",
        "PDF": "https://arxiv.org/pdf/2406.10317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on contributor reputation measures and dependency reviews in the Rust ecosystem, which are not related to LLM training data processing or any aspect of dataset creation or data quality improvement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.15612",
      "abstract": "Inverse reinforcement learning (IRL) aims to learn a reward function and a corresponding policy that best fit the demonstrated trajectories of an expert. However, current IRL works cannot learn incrementally from an ongoing trajectory because they have to wait to collect at least one complete trajectory to learn. To bridge the gap, this paper considers the problem of learning a reward function and a corresponding policy while observing the initial state-action pair of an ongoing trajectory and keeping updating the learned reward and policy when new state-action pairs of the ongoing trajectory are observed. We formulate this problem as an online bi-level optimization problem where the upper level dynamically adjusts the learned reward according to the newly observed state-action pairs with the help of a meta-regularization term, and the lower level learns the corresponding policy. We propose a novel algorithm to solve this problem and guarantee that the algorithm achieves sub-linear local regret $O(\\sqrt{T}+\\log T+\\sqrt{T}\\log T)$. If the reward function is linear, we prove that the proposed algorithm achieves sub-linear regret $O(\\log T)$. Experiments are used to validate the proposed algorithm.",
      "authors": [
        "Shicheng Liu",
        "Minghui Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T03:16:32+00:00",
          "link": "https://arxiv.org/abs/2410.15612v1",
          "size": "1581kb",
          "version": "v1"
        },
        {
          "date": "2024-11-12T19:21:24+00:00",
          "link": "https://arxiv.org/abs/2410.15612v2",
          "size": "822kb",
          "version": "v2"
        },
        {
          "date": "2025-01-02T17:29:43+00:00",
          "link": "https://arxiv.org/abs/2410.15612v3",
          "size": "823kb",
          "version": "v3"
        },
        {
          "date": "2025-01-18T16:22:10+00:00",
          "link": "https://arxiv.org/abs/2410.15612v4",
          "size": "823kb",
          "version": "v4"
        },
        {
          "date": "2025-01-23T14:53:11+00:00",
          "link": "https://arxiv.org/abs/2410.15612v5",
          "size": "823kb",
          "version": "v5"
        },
        {
          "date": "2025-04-05T19:07:11+00:00",
          "link": "https://arxiv.org/abs/2410.15612v6",
          "size": "823kb",
          "version": "v6"
        },
        {
          "date": "2025-07-23T16:56:21+00:00",
          "link": "https://arxiv.org/abs/2410.15612v7",
          "size": "823kb",
          "version": "v7"
        }
      ],
      "title": "In-Trajectory Inverse Reinforcement Learning: Learn Incrementally Before An Ongoing Trajectory Terminates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15612",
        "PDF": "https://arxiv.org/pdf/2410.15612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Inverse Reinforcement Learning and online learning from ongoing trajectories. It does not make a contribution to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.12819",
      "abstract": "Purpose: Enabling a comprehensive and robust assessment of carotid artery plaques in 3D through extraction and visualization of quantitative plaque parameters. These parameters have potential applications in stroke risk analysis, evaluation of therapy effectiveness, and plaque progression prediction. Methods: We propose a novel method for extracting a plaque mesh from 3D vessel wall segmentation using distance encoding on the inner and outer wall mesh for precise plaque structure analysis. A case-specific threshold, derived from the normal vessel wall thickness, was applied to extract plaques from a dataset of 202 T1-weighted black-blood MRI scans of subjects with up to 50% stenosis. Applied to baseline and one-year follow-up data, the method supports detailed plaque morphology analysis over time, including plaque volume quantification, aided by improved visualization via mesh unfolding. Results: We successfully extracted plaque meshes from 341 carotid arteries, capturing a wide range of plaque shapes with volumes ranging from 2.69{\\mu}l to 847.7{\\mu}l. The use of a case-specific threshold effectively eliminated false positives in young, healthy subjects. Conclusion: The proposed method enables precise extraction of plaque meshes from 3D vessel wall segmentation masks enabling a correspondence between baseline and one-year follow-up examinations. Unfolding the plaque meshes enhances visualization, while the mesh-based analysis allows quantification of plaque parameters independent of voxel resolution.",
      "authors": [
        "Hinrich Rahlfs",
        "Markus H\\\"ullebrand",
        "Sebastian Schmitter",
        "Christoph Strecker",
        "Andreas Harloff",
        "Anja Hennemuth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T12:27:06+00:00",
          "link": "https://arxiv.org/abs/2502.12819v1",
          "size": "2495kb",
          "version": "v1"
        }
      ],
      "title": "Carotid Artery Plaque Analysis in 3D Based on Distance Encoding in Mesh Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12819",
        "HTML": "https://arxiv.org/html/2502.12819",
        "PDF": "https://arxiv.org/pdf/2502.12819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is about analyzing carotid artery plaques in 3D using mesh representations, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.16373",
      "abstract": "The preparation of quantum Gibbs states is a fundamental challenge in quantum computing, essential for applications ranging from modeling open quantum systems to quantum machine learning. Building on the Meta-Variational Quantum Eigensolver framework proposed by Cervera-Lierta et al.(2021) and a problem driven ansatz design, we introduce two meta-learning algorithms: Meta-Variational Quantum Thermalizer (Meta-VQT) and Neural Network Meta-VQT (NN-Meta VQT) for efficient thermal state preparation of parametrized Hamiltonians on Noisy Intermediate-Scale Quantum (NISQ) devices. Meta-VQT utilizes a fully quantum ansatz, while NN Meta-VQT integrates a quantum classical hybrid architecture. Both leverage collective optimization over training sets to generalize Gibbs state preparation to unseen parameters. We validate our methods on upto 8-qubit Transverse Field Ising Model and the 2-qubit Heisenberg model with all field terms, demonstrating efficient thermal state generation beyond training data. For larger systems, we show that our meta-learned parameters when combined with appropriately designed ansatz serve as warm start initializations, significantly outperforming random initializations in the optimization tasks. Furthermore, a 3- qubit Kitaev ring example showcases our algorithm's effectiveness across finite-temperature crossover regimes. Finally, we apply our algorithms to train a Quantum Boltzmann Machine (QBM) on a 2-qubit Heisenberg model with all field terms, achieving enhanced training efficiency, improved Gibbs state accuracy, and a 30-fold runtime speedup over existing techniques such as variational quantum imaginary time (VarQITE)-based QBM highlighting the scalability and practicality of meta-algorithm-based QBMs.",
      "authors": [
        "Ruchira V Bhat",
        "Rahul Bhowmick",
        "Avinash Singh",
        "Krishna Kumar Sabapathy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-22T09:17:50+00:00",
          "link": "https://arxiv.org/abs/2507.16373v1",
          "size": "1769kb",
          "version": "v1"
        }
      ],
      "title": "Meta-learning of Gibbs states for many-body Hamiltonians with applications to Quantum Boltzmann Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.16373",
        "HTML": "https://arxiv.org/html/2507.16373",
        "PDF": "https://arxiv.org/pdf/2507.16373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on meta-learning algorithms for preparing quantum Gibbs states and their application in Quantum Boltzmann Machines. It does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2202.06191",
      "abstract": "Participation incentives is a well-known issue inhibiting randomized controlled trials (RCTs) in medicine, as well as a potential cause of user dissatisfaction for RCTs in online platforms. We frame this issue as a non-standard exploration-exploitation tradeoff: an RCT would like to explore as uniformly as possible, whereas each \"agent\" (a patient or a user) prefers \"exploitation\", i.e., treatments that seem best. We incentivize participation by leveraging information asymmetry between the trial and the agents. We measure statistical performance via worst-case estimation error under adversarially generated outcomes, a standard objective for RCTs. We obtain a near-optimal solution in terms of this objective: an incentive-compatible mechanism with a particular guarantee, and a nearly matching impossibility result for any incentive-compatible mechanism. We consider three model variants: homogeneous agents (of the same \"type\" comprising beliefs and preferences), heterogeneous agents, and an extension that leverages estimated type frequencies to mitigate the influence of rare-but-difficult agent types.",
      "authors": [
        "Yingkai Li",
        "Aleksandrs Slivkins"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-13T03:23:55+00:00",
          "link": "https://arxiv.org/abs/2202.06191v1",
          "size": "360kb",
          "version": "v1"
        },
        {
          "date": "2022-02-16T00:21:34+00:00",
          "link": "https://arxiv.org/abs/2202.06191v2",
          "size": "369kb",
          "version": "v2"
        },
        {
          "date": "2022-10-28T02:46:47+00:00",
          "link": "https://arxiv.org/abs/2202.06191v3",
          "size": "540kb",
          "version": "v3"
        },
        {
          "date": "2023-04-21T02:05:36+00:00",
          "link": "https://arxiv.org/abs/2202.06191v4",
          "size": "55kb",
          "version": "v4"
        },
        {
          "date": "2024-03-02T04:49:09+00:00",
          "link": "https://arxiv.org/abs/2202.06191v5",
          "size": "124kb",
          "version": "v5"
        },
        {
          "date": "2024-04-01T21:48:59+00:00",
          "link": "https://arxiv.org/abs/2202.06191v6",
          "size": "136kb",
          "version": "v6"
        },
        {
          "date": "2024-05-21T03:33:51+00:00",
          "link": "https://arxiv.org/abs/2202.06191v7",
          "size": "126kb",
          "version": "v7"
        },
        {
          "date": "2024-08-08T01:08:01+00:00",
          "link": "https://arxiv.org/abs/2202.06191v8",
          "size": "134kb",
          "version": "v8"
        },
        {
          "date": "2025-01-21T03:27:54+00:00",
          "link": "https://arxiv.org/abs/2202.06191v9",
          "size": "138kb",
          "version": "v9"
        },
        {
          "date": "2025-03-09T17:47:13+00:00",
          "link": "https://arxiv.org/abs/2202.06191v10",
          "size": "63kb",
          "version": "v10"
        },
        {
          "date": "2025-07-23T13:58:08+00:00",
          "link": "https://arxiv.org/abs/2202.06191v11",
          "size": "68kb",
          "version": "v11"
        }
      ],
      "title": "Exploration and Incentivizing Participation in Randomized Trials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.06191",
        "HTML": "https://arxiv.org/html/2202.06191",
        "PDF": "https://arxiv.org/pdf/2202.06191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about incentivizing participation in randomized controlled trials, focusing on exploration-exploitation tradeoffs and incentive mechanisms, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.03963",
      "abstract": "We propose a metaphor detection architecture that is structured around two main modules: an expectation component that estimates representations of literal word expectations given a context, and a realization component that computes representations of actual word meanings in context. The overall architecture is trained to learn expectation-realization (ER) patterns that characterize metaphorical uses of words. When evaluated on three metaphor datasets for within distribution, out of distribution, and novel metaphor generalization, the proposed method is shown to obtain results that are competitive or better than state-of-the art. Further increases in metaphor detection accuracy are obtained through ensembling of ER models.",
      "authors": [
        "Oseremen O. Uduehi and Razvan C. Bunescu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-07T13:03:54+00:00",
          "link": "https://arxiv.org/abs/2311.03963v1",
          "size": "317kb",
          "version": "v1"
        }
      ],
      "title": "An Expectation-Realization Model for Metaphor Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.03963",
        "PDF": "https://arxiv.org/pdf/2311.03963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is focused on metaphor detection using expectation-realization patterns. It does not contribute to LLM training data processing or dataset engineering related to language model training."
      },
      "tasks": [
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.05218",
      "abstract": "Transformer models have continuously expanded into all machine learning domains convertible to the underlying sequence-to-sequence representation, including tabular data. However, while ubiquitous, this representation restricts their extension to the more general case of relational databases. In this paper, we introduce a modular neural message-passing scheme that closely adheres to the formal relational model, enabling direct end-to-end learning of tabular Transformers from database storage systems. We address the challenges of appropriate learning data representation and loading, which are critical in the database setting, and compare our approach against a number of representative models from various related fields across a significantly wide range of datasets. Our results demonstrate a superior performance of this newly proposed class of neural architectures.",
      "authors": [
        "Jakub Pele\\v{s}ka and Gustav \\v{S}\\'ir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T17:48:43+00:00",
          "link": "https://arxiv.org/abs/2412.05218v1",
          "size": "194kb",
          "version": "v1"
        }
      ],
      "title": "Transformers Meet Relational Databases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05218",
        "HTML": "https://arxiv.org/html/2412.05218",
        "PDF": "https://arxiv.org/pdf/2412.05218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a neural message-passing scheme for learning from relational databases, focusing on tabular data and database storage systems, without addressing LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/jakubpeleska/deep-db-learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.06777",
      "abstract": "Large Language Models (LLMs) with their strong task-handling capabilities have shown remarkable advancements across a spectrum of fields, moving beyond natural language understanding. However, their proficiency within the chemistry domain remains restricted, especially in solving molecule-related tasks. This challenge is attributed to their inherent limitations in comprehending molecules using only common textual representations, i.e. SMILES strings. In this study, we seek to enhance the ability of LLMs to comprehend molecules by equipping them with a multi-modal external module, termed MolX. Instead of directly using SMILES strings to represent a molecule, we utilize specific encoders to extract fine-grained features from both SMILES string and 2D molecular graph representations for feeding into an LLM. A hand-crafted molecular fingerprint is incorporated to leverage its embedded domain knowledge. To establish an alignment between MolX and the LLM's textual input space, the model in which the LLM is frozen, is pre-trained with a strategy including a diverse set of tasks. Experimental evaluations show that our proposed method outperforms baselines across 4 downstream molecule-related tasks ranging from molecule-to-text translation to retrosynthesis, with and without fine-tuning the LLM, while only introducing a small number of trainable parameters--0.53\\% and 0.82\\%, respectively.",
      "authors": [
        "Khiem Le",
        "Zhichun Guo",
        "Kaiwen Dong",
        "Xiaobao Huang",
        "Bozhao Nan",
        "Roshni Iyer",
        "Xiangliang Zhang",
        "Olaf Wiest",
        "Wei Wang",
        "Ting Hua",
        "Nitesh V. Chawla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-10T20:25:18+00:00",
          "link": "https://arxiv.org/abs/2406.06777v1",
          "size": "579kb",
          "version": "v1"
        },
        {
          "date": "2024-06-13T03:54:49+00:00",
          "link": "https://arxiv.org/abs/2406.06777v2",
          "size": "579kb",
          "version": "v2"
        },
        {
          "date": "2024-06-28T03:07:29+00:00",
          "link": "https://arxiv.org/abs/2406.06777v3",
          "size": "579kb",
          "version": "v3"
        },
        {
          "date": "2024-08-22T02:06:31+00:00",
          "link": "https://arxiv.org/abs/2406.06777v4",
          "size": "1228kb",
          "version": "v4"
        },
        {
          "date": "2025-04-02T22:20:34+00:00",
          "link": "https://arxiv.org/abs/2406.06777v5",
          "size": "1216kb",
          "version": "v5"
        },
        {
          "date": "2025-06-08T10:34:54+00:00",
          "link": "https://arxiv.org/abs/2406.06777v6",
          "size": "655kb",
          "version": "v6"
        },
        {
          "date": "2025-07-07T21:25:24+00:00",
          "link": "https://arxiv.org/abs/2406.06777v7",
          "size": "655kb",
          "version": "v7"
        },
        {
          "date": "2025-07-23T12:32:35+00:00",
          "link": "https://arxiv.org/abs/2406.06777v8",
          "size": "655kb",
          "version": "v8"
        }
      ],
      "title": "MolX: Enhancing Large Language Models for Molecular Understanding With A Multi-Modal Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.06777",
        "HTML": "https://arxiv.org/html/2406.06777",
        "PDF": "https://arxiv.org/pdf/2406.06777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper aims to enhance LLMs' understanding of molecular data via a multi-modal extension, which involves pre-training with a diverse task set. It touches on data processing for task performance in LLMs, but its core focus is not on data processing methods for training these models."
      },
      "tasks": [
        "Natural Language Understanding",
        "Retrosynthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00459",
      "abstract": "Synthesizing realistic microstructure images conditioned on processing parameters is crucial for understanding process-structure relationships in materials design. However, this task remains challenging due to limited training micrographs and the continuous nature of processing variables. To overcome these challenges, we present a novel process-aware generative modeling approach based on Stable Diffusion 3.5 Large (SD3.5-Large), a state-of-the-art text-to-image diffusion model adapted for microstructure generation. Our method introduces numeric-aware embeddings that encode continuous variables (annealing temperature, time, and magnification) directly into the model's conditioning, enabling controlled image generation under specified process conditions and capturing process-driven microstructural variations. To address data scarcity and computational constraints, we fine-tune only a small fraction of the model's weights via DreamBooth and Low-Rank Adaptation (LoRA), efficiently transferring the pre-trained model to the materials domain. We validate realism using a semantic segmentation model based on a fine-tuned U-Net with a VGG16 encoder on 24 labeled micrographs. It achieves 97.1% accuracy and 85.7% mean IoU, outperforming previous methods. Quantitative analyses using physical descriptors and spatial statistics show strong agreement between synthetic and real microstructures. Specifically, two-point correlation and lineal-path errors remain below 2.1% and 0.6%, respectively. Our method represents the first adaptation of SD3.5-Large for process-aware microstructure generation, offering a scalable approach for data-driven materials design.",
      "authors": [
        "Hoang Cuong Phan",
        "Minh Tien Tran",
        "Chihun Lee",
        "Hoheok Kim",
        "Sehyok Oh",
        "Dong-Kyu Kim",
        "Ho Won Lee"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T06:16:53+00:00",
          "link": "https://arxiv.org/abs/2507.00459v1",
          "size": "9175kb",
          "version": "v1"
        }
      ],
      "title": "Process-aware and high-fidelity microstructure generation using stable diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00459",
        "PDF": "https://arxiv.org/pdf/2507.00459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using a text-to-image diffusion model for generating microstructure images conditioned on continuous variables and mentions fine-tuning with DreamBooth and LoRA. While it involves data generation, its primary focus is on materials design rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.11407",
      "abstract": "Multispectral point cloud (MPC) captures 3D spatial-spectral information from the observed scene, which can be used for scene understanding and has a wide range of applications. However, most of the existing classification methods were extensively tested on indoor datasets, and when applied to outdoor datasets they still face problems including sparse labeled targets, differences in land-covers scales, and long-tailed distributions. To address the above issues, an enhanced classification method based on adaptive multi-scale fusion for MPCs with long-tailed distributions is proposed. In the training set generation stage, a grid-balanced sampling strategy is designed to reliably generate training samples from sparse labeled datasets. In the feature learning stage, a multi-scale feature fusion module is proposed to fuse shallow features of land-covers at different scales, addressing the issue of losing fine features due to scale variations in land-covers. In the classification stage, an adaptive hybrid loss module is devised to utilize multi-classification heads with adaptive weights to balance the learning ability of different classes, improving the classification performance of small classes due to various-scales and long-tailed distributions in land-covers. Experimental results on three MPC datasets demonstrate the effectiveness of the proposed method compared with the state-of-the-art methods.",
      "authors": [
        "TianZhu Liu",
        "BangYan Hu",
        "YanFeng Gu",
        "Xian Li",
        "Aleksandra Pi\\v{z}urica"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T03:21:20+00:00",
          "link": "https://arxiv.org/abs/2412.11407v1",
          "size": "7704kb",
          "version": "v1"
        }
      ],
      "title": "An Enhanced Classification Method Based on Adaptive Multi-Scale Fusion for Long-tailed Multispectral Point Clouds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11407",
        "HTML": "https://arxiv.org/html/2412.11407",
        "PDF": "https://arxiv.org/pdf/2412.11407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a classification method for multispectral point clouds using a grid-balanced sampling strategy and other techniques, which involves some aspects of data processing but does not focus on LLM training data."
      },
      "tasks": [
        "Classification",
        "Scene Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02088",
      "abstract": "We investigate the problem of fairly allocating $m$ indivisible items among $n$ sequentially arriving agents with additive valuations, under the sought-after fairness notion of maximin share (MMS). We first observe a strong impossibility: without appropriate knowledge about the valuation functions of the incoming agents, no online algorithm can ensure any non-trivial MMS approximation, even when there are only two agents. Motivated by this impossibility, we introduce OnlineKTypeFD (online $k$-type fair division), a model that balances theoretical tractability with real-world applicability. In this model, each arriving agent belongs to one of $k$ types, with all agents of a given type sharing the same known valuation function. We do not constrain $k$ to be a constant. Upon arrival, an agent reveals her type, receives an irrevocable allocation, and departs. We study the ex-post MMS guarantees of online algorithms under two arrival models:\n  1- Adversarial arrivals: In this model, an adversary determines the type of each arriving agent. We design a $\\frac{1}{k}$-MMS competitive algorithm and complement it with a lower bound, ruling out any $\\Omega(\\frac{1}{\\sqrt{k}})$-MMS-competitive algorithm, even for binary valuations.\n  2- Stochastic arrivals: In this model, the type of each arriving agent is independently drawn from an underlying, possibly unknown distribution. Unlike the adversarial setting where the dependence on $k$ is unavoidable, we surprisingly show that in the stochastic setting, an asymptotic, arbitrarily close-to-$\\frac{1}{2}$-MMS competitive guarantee is achievable under mild distributional assumptions.\n  Our results extend naturally to a learning-augmented framework; when given access to predictions about valuation functions, we show that the competitive ratios of our algorithms degrade gracefully with multiplicative prediction errors.",
      "authors": [
        "Pooja Kulkarni",
        "Ruta Mehta",
        "Parnian Shahkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Data Structures and Algorithms (cs.DS)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T22:14:03+00:00",
          "link": "https://arxiv.org/abs/2503.02088v1",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "title": "Online Fair Division: Towards Ex-Post Constant MMS Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02088",
        "PDF": "https://arxiv.org/pdf/2503.02088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates online fair division algorithms with a focus on maximin share guarantees, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Optimization and Control (math.OC)",
    "Quantum Physics (quant-ph)",
    "Multimedia (cs.MM)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Sound (cs.SD)",
    "Image and Video Processing (eess.IV)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Portfolio Management (q-fin.PM)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Computational Geometry (cs.CG)",
    "Neurons and Cognition (q-bio.NC)",
    "Algebraic Topology (math.AT)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applications (stat.AP)",
    "Applied Physics (physics.app-ph)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Analysis of PDEs (math.AP)",
    "Solar and Stellar Astrophysics (astro-ph.SR)",
    "Quantitative Methods (q-bio.QM)",
    "Computational Complexity (cs.CC)",
    "Statistical Finance (q-fin.ST)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Mathematical Software (cs.MS)",
    "Biological Physics (physics.bio-ph)",
    "Probability (math.PR)",
    "Information Theory (math.IT)",
    "Mathematical Physics (math.MP)",
    "Discrete Mathematics (cs.DM)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Mathematical Finance (q-fin.MF)",
    "Signal Processing (eess.SP)",
    "Computation (stat.CO)",
    "Spectral Theory (math.SP)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "Pattern Formation and Solitons (nlin.PS)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Risk Management (q-fin.RM)",
    "Neural and Evolutionary Computing (cs.NE)",
    "General Finance (q-fin.GN)",
    "Soft Condensed Matter (cond-mat.soft)",
    "Computational Physics (physics.comp-ph)",
    "Computational Finance (q-fin.CP)",
    "Software Engineering (cs.SE)",
    "Nuclear Theory (nucl-th)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Algebraic Geometry (math.AG)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Dynamical Systems (math.DS)",
    "Genomics (q-bio.GN)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to the performance of large language models (LLMs). You are a computer science expert specializing in LLM training data processing. Your task is to analyze a set of arXiv papers and determine their relevance to **LLM training data processing**.\n\n### **Task Objective**\n\nFor each paper, assess whether it makes a technical contribution to **LLM training data processing**.\n\n1. First, the paper must relate to data processing for **pretraining or fine-tuning**, including stages such as LLM pretraining, instruction fine-tuning, supervised fine-tuning (SFT), or alignment fine-tuning.\n2. Second, the paper must involve **training data processing** operations, such as:\n\n   * Data engineering operations, including data collection, data generation, deduplication, filtering, etc.;\n   * Techniques or methods that significantly improve data quality;\n   * Creation or generation of new datasets.\n\n### Answer: **Relevance Classification**\n\n**`core`**: The paper makes a direct contribution to LLM training data processing. Examples include: creation, generation, or synthesis of new datasets; building higher-quality datasets from existing ones; novel data processing techniques; or any data engineering operations that substantially improve data quality.\n\n**`partial`**: The paper briefly discusses training data processing, but the main focus lies elsewhere\u2014such as model architecture, task design, evaluation, or prompt engineering\u2014rather than training data processing.\n\n**`irrelevant`**: The paper does not address any aspect of LLM training data processing.\n\n### **Output Format (strictly follow this JSON structure)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<Paper ID>\",\n      \"answer\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1\u20132 sentence explanation of your classification, citing key content from the abstract or methodology section.\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n\n### Example\n\ninput:\n\n```\n[\n    {\n        \"id\": \"2411.12372\",\n        \"title\": \"RedPajama: an Open Dataset for Training Large Language Models\",\n        \"abstract\": \"Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top-performing models lack transparency in their dataset curation and model development processes, posing an obstacle to the development of fully open language models. In this paper, we identify three core data-related challenges that must be addressed to advance open-source language models. These include (1) transparency in model development, including the data curation process, (2) access to large quantities of high-quality data, and (3) availability of artifacts and metadata for dataset curation and analysis. To address these challenges, we release RedPajama-V1, an open reproduction of the LLaMA training dataset. In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata. Together, the RedPajama datasets comprise over 100 trillion tokens spanning multiple domains and with their quality signals facilitate the filtering of data, aiming to inspire the development of numerous new datasets. To date, these datasets have already been used in the training of strong language models used in production, such as Snowflake Arctic, Salesforce's XGen and AI2's OLMo. To provide insight into the quality of RedPajama, we present a series of analyses and ablation studies with decoder-only language models with up to 1.6B parameters. Our findings demonstrate how quality signals for web data can be effectively leveraged to curate high-quality subsets of the dataset, underscoring the potential of RedPajama to advance the development of transparent and high-performing language models at scale.\"\n    },\n    {\n        \"id\": \"2306.01116\",\n        \"title\": \"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\",\n        \"abstract\": \"Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.\"\n    }\n]\n```\n\noutput:\n\n```\n{\n  \"result\": [\n    {\n      \"id\": \"2411.12372\",\n      \"answer\": \"core\",\n      \"reason\": \"This paper releases RedPajama-V1 and V2 datasets, comprising over 100 trillion tokens, and introduces quality signals for filtering. It involves data collection, deduplication, filtering, and quality assessment, making a significant contribution to LLM training data processing.\"\n    },\n    {\n      \"id\": \"2306.01116\",\n      \"answer\": \"core\",\n      \"reason\": \"The paper presents the RefinedWeb dataset, which uses only deduplicated and filtered web data to train LLMs. It challenges the conventional reliance on mixed curated corpora and publicly releases both the dataset and models, representing a core contribution to high-quality data construction.\"\n    }\n  ]\n}\n\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 666,
    "partial": 106,
    "core": 15
  },
  "arxiv_update_date": "2025-07-24",
  "updated_at": "2025-07-24 10:16:00"
}